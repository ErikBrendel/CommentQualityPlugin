# id;timestamp;commentText;codeText;commentWords;codeWords
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1427367086;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final AbstractJobVertex sender = new AbstractJobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final AbstractJobVertex pipelinedReceiver = new AbstractJobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final AbstractJobVertex blockingReceiver = new AbstractJobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		JobClient.submitJobAndWait(jobGraph, false, jobClient, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,abstract,job,vertex,sender,new,abstract,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,abstract,job,vertex,pipelined,receiver,new,abstract,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,abstract,job,vertex,blocking,receiver,new,abstract,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,job,client,submit,job,and,wait,job,graph,false,job,client,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1428330445;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final AbstractJobVertex sender = new AbstractJobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final AbstractJobVertex pipelinedReceiver = new AbstractJobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final AbstractJobVertex blockingReceiver = new AbstractJobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		JobClient.submitJobAndWait(jobGraph, false, jobClient, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,abstract,job,vertex,sender,new,abstract,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,abstract,job,vertex,pipelined,receiver,new,abstract,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,abstract,job,vertex,blocking,receiver,new,abstract,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,job,client,submit,job,and,wait,job,graph,false,job,client,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1428935901;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final AbstractJobVertex sender = new AbstractJobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final AbstractJobVertex pipelinedReceiver = new AbstractJobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final AbstractJobVertex blockingReceiver = new AbstractJobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.submitJobAndWait(jobGraph, false, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,abstract,job,vertex,sender,new,abstract,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,abstract,job,vertex,pipelined,receiver,new,abstract,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,abstract,job,vertex,blocking,receiver,new,abstract,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,submit,job,and,wait,job,graph,false,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1434467925;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.submitJobAndWait(jobGraph, false, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,submit,job,and,wait,job,graph,false,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1449496469;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.submitJobAndWait(jobGraph, false, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,submit,job,and,wait,job,graph,false,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1453902315;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.submitJobAndWait(jobGraph, false, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,submit,job,and,wait,job,graph,false,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1457737669;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				new ExecutionConfig(),_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.submitJobAndWait(jobGraph, false, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,new,execution,config,sender,pipelined,receiver,blocking,receiver,flink,submit,job,and,wait,job,graph,false,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1463155298;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.submitJobAndWait(jobGraph, false, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,submit,job,and,wait,job,graph,false,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1477989375;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.submitJobAndWait(jobGraph, false, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,submit,job,and,wait,job,graph,false,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1502726910;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.submitJobAndWait(jobGraph, false, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,submit,job,and,wait,job,graph,false,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1513201052;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.submitJobAndWait(jobGraph, false, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,submit,job,and,wait,job,graph,false,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1515519059;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.submitJobAndWait(jobGraph, false, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,submit,job,and,wait,job,graph,false,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1519308961;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.submitJobAndWait(jobGraph, false, TestingUtils.TESTING_DURATION())__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,submit,job,and,wait,job,graph,false,testing,utils
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1522825145;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.executeJobBlocking(jobGraph)__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,execute,job,blocking,job,graph
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1522835035;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.executeJobBlocking(jobGraph)__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,execute,job,blocking,job,graph
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1526494919;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.executeJobBlocking(jobGraph)__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,execute,job,blocking,job,graph
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1538764032;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__<p>The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		flink.executeJobBlocking(jobGraph)__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,p,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,flink,execute,job,blocking,job,graph
ScheduleOrUpdateConsumersTest -> @Test 	public void testMixedPipelinedAndBlockingResults() throws Exception;1540389860;Tests notifications of multiple receivers when a task produces both a pipelined and blocking_result.__<pre>_+----------+_+-- pipelined -> | Receiver |_+--------+ |                +----------+_| Sender |-|_+--------+ |                +----------+_+-- blocking --> | Receiver |_+----------+_</pre>__<p>The pipelined receiver gets deployed after the first buffer is available and the blocking_one after all subtasks are finished.;@Test_	public void testMixedPipelinedAndBlockingResults() throws Exception {_		final JobVertex sender = new JobVertex("Sender")__		sender.setInvokableClass(BinaryRoundRobinSubtaskIndexSender.class)__		sender.getConfiguration().setInteger(BinaryRoundRobinSubtaskIndexSender.CONFIG_KEY, PARALLELISM)__		sender.setParallelism(PARALLELISM)___		final JobVertex pipelinedReceiver = new JobVertex("Pipelined Receiver")__		pipelinedReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		pipelinedReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		pipelinedReceiver.setParallelism(PARALLELISM)___		pipelinedReceiver.connectNewDataSetAsInput(_				sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.PIPELINED)___		final JobVertex blockingReceiver = new JobVertex("Blocking Receiver")__		blockingReceiver.setInvokableClass(SlotCountExceedingParallelismTest.SubtaskIndexReceiver.class)__		blockingReceiver.getConfiguration().setInteger(CONFIG_KEY, PARALLELISM)__		blockingReceiver.setParallelism(PARALLELISM)___		blockingReceiver.connectNewDataSetAsInput(sender,_				DistributionPattern.ALL_TO_ALL,_				ResultPartitionType.BLOCKING)___		SlotSharingGroup slotSharingGroup = new SlotSharingGroup(_				sender.getID(), pipelinedReceiver.getID(), blockingReceiver.getID())___		sender.setSlotSharingGroup(slotSharingGroup)__		pipelinedReceiver.setSlotSharingGroup(slotSharingGroup)__		blockingReceiver.setSlotSharingGroup(slotSharingGroup)___		final JobGraph jobGraph = new JobGraph(_				"Mixed pipelined and blocking result",_				sender,_				pipelinedReceiver,_				blockingReceiver)___		MINI_CLUSTER_RESOURCE.getMiniCluster().executeJobBlocking(jobGraph)__	};tests,notifications,of,multiple,receivers,when,a,task,produces,both,a,pipelined,and,blocking,result,pre,pipelined,receiver,sender,blocking,receiver,pre,p,the,pipelined,receiver,gets,deployed,after,the,first,buffer,is,available,and,the,blocking,one,after,all,subtasks,are,finished;test,public,void,test,mixed,pipelined,and,blocking,results,throws,exception,final,job,vertex,sender,new,job,vertex,sender,sender,set,invokable,class,binary,round,robin,subtask,index,sender,class,sender,get,configuration,set,integer,binary,round,robin,subtask,index,sender,parallelism,sender,set,parallelism,parallelism,final,job,vertex,pipelined,receiver,new,job,vertex,pipelined,receiver,pipelined,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,pipelined,receiver,get,configuration,set,integer,parallelism,pipelined,receiver,set,parallelism,parallelism,pipelined,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,pipelined,final,job,vertex,blocking,receiver,new,job,vertex,blocking,receiver,blocking,receiver,set,invokable,class,slot,count,exceeding,parallelism,test,subtask,index,receiver,class,blocking,receiver,get,configuration,set,integer,parallelism,blocking,receiver,set,parallelism,parallelism,blocking,receiver,connect,new,data,set,as,input,sender,distribution,pattern,result,partition,type,blocking,slot,sharing,group,slot,sharing,group,new,slot,sharing,group,sender,get,id,pipelined,receiver,get,id,blocking,receiver,get,id,sender,set,slot,sharing,group,slot,sharing,group,pipelined,receiver,set,slot,sharing,group,slot,sharing,group,blocking,receiver,set,slot,sharing,group,slot,sharing,group,final,job,graph,job,graph,new,job,graph,mixed,pipelined,and,blocking,result,sender,pipelined,receiver,blocking,receiver,get,mini,cluster,execute,job,blocking,job,graph
