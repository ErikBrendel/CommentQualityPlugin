# id;timestamp;commentText;codeText;commentWords;codeWords
CompactingHashTable -> public void close();1405024514;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join.;public void close() {_		_		if (!this.closed.compareAndSet(false, true)) {_			return__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join;public,void,close,if,this,closed,compare,and,set,false,true,return,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> public void close();1405090423;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join.;public void close() {_		_		if (!this.closed.compareAndSet(false, true)) {_			return__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join;public,void,close,if,this,closed,compare,and,set,false,true,return,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> public void close();1405529391;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;public void close() {_		_		if (!this.closed.compareAndSet(false, true)) {_			return__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;public,void,close,if,this,closed,compare,and,set,false,true,return,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> public void close();1409845762;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;public void close() {_		_		if (!this.closed.compareAndSet(false, true)) {_			return__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;public,void,close,if,this,closed,compare,and,set,false,true,return,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> public void close();1409911022;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;public void close() {_		_		if (!this.closed.compareAndSet(false, true)) {_			return__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;public,void,close,if,this,closed,compare,and,set,false,true,return,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> public void close();1411473593;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;public void close() {_		_		if (!this.closed.compareAndSet(false, true)) {_			return__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;public,void,close,if,this,closed,compare,and,set,false,true,return,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> public void close();1414786554;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;public void close() {_		_		if (!this.closed.compareAndSet(false, true)) {_			return__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;public,void,close,if,this,closed,compare,and,set,false,true,return,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> public void close();1420654570;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;public void close() {_		_		if (!this.closed.compareAndSet(false, true)) {_			return__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;public,void,close,if,this,closed,compare,and,set,false,true,return,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> public void close();1420654570;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;public void close() {_		_		if (!this.closed.compareAndSet(false, true)) {_			return__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;public,void,close,if,this,closed,compare,and,set,false,true,return,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> public void close();1420663430;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;public void close() {_		_		if (!this.closed.compareAndSet(false, true)) {_			return__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;public,void,close,if,this,closed,compare,and,set,false,true,return,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> public void close();1421838095;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;public void close() {_		_		if (!this.closed.compareAndSet(false, true)) {_			return__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;public,void,close,if,this,closed,compare,and,set,false,true,return,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> public void close();1427646862;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;public void close() {_		_		if (!this.closed.compareAndSet(false, true)) {_			return__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;public,void,close,if,this,closed,compare,and,set,false,true,return,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> @SuppressWarnings("unused") 	private void fastCompactPartition(int partitionNumber) throws IOException;1405024514;Compacts partition but may not reclaim all garbage__@param partition partition number_@throws IOException;@SuppressWarnings("unused")_	private void fastCompactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		return__	};compacts,partition,but,may,not,reclaim,all,garbage,param,partition,partition,number,throws,ioexception;suppress,warnings,unused,private,void,fast,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,return,return
CompactingHashTable -> @SuppressWarnings("unused") 	private void fastCompactPartition(int partitionNumber) throws IOException;1405090423;Compacts partition but may not reclaim all garbage__@param partition partition number_@throws IOException;@SuppressWarnings("unused")_	private void fastCompactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		return__	};compacts,partition,but,may,not,reclaim,all,garbage,param,partition,partition,number,throws,ioexception;suppress,warnings,unused,private,void,fast,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,return,return
CompactingHashTable -> @SuppressWarnings("unused") 	private void fastCompactPartition(int partitionNumber) throws IOException;1405529391;Compacts partition but may not reclaim all garbage__@param partitionNumber partition number_@throws IOException;@SuppressWarnings("unused")_	private void fastCompactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		return__	};compacts,partition,but,may,not,reclaim,all,garbage,param,partition,number,partition,number,throws,ioexception;suppress,warnings,unused,private,void,fast,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,return,return
CompactingHashTable -> @SuppressWarnings("unused") 	private void fastCompactPartition(int partitionNumber) throws IOException;1409845762;Compacts partition but may not reclaim all garbage__@param partitionNumber partition number_@throws IOException;@SuppressWarnings("unused")_	private void fastCompactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		return__	};compacts,partition,but,may,not,reclaim,all,garbage,param,partition,number,partition,number,throws,ioexception;suppress,warnings,unused,private,void,fast,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,return,return
CompactingHashTable -> @SuppressWarnings("unused") 	private void fastCompactPartition(int partitionNumber) throws IOException;1409911022;Compacts partition but may not reclaim all garbage__@param partitionNumber partition number_@throws IOException;@SuppressWarnings("unused")_	private void fastCompactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		return__	};compacts,partition,but,may,not,reclaim,all,garbage,param,partition,number,partition,number,throws,ioexception;suppress,warnings,unused,private,void,fast,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,return,return
CompactingHashTable -> @SuppressWarnings("unused") 	private void fastCompactPartition(int partitionNumber) throws IOException;1411473593;Compacts partition but may not reclaim all garbage__@param partitionNumber partition number_@throws IOException;@SuppressWarnings("unused")_	private void fastCompactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		return__	};compacts,partition,but,may,not,reclaim,all,garbage,param,partition,number,partition,number,throws,ioexception;suppress,warnings,unused,private,void,fast,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,return,return
CompactingHashTable -> @SuppressWarnings("unused") 	private void fastCompactPartition(int partitionNumber) throws IOException;1414786554;Compacts partition but may not reclaim all garbage__@param partitionNumber partition number_@throws IOException;@SuppressWarnings("unused")_	private void fastCompactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		return__	};compacts,partition,but,may,not,reclaim,all,garbage,param,partition,number,partition,number,throws,ioexception;suppress,warnings,unused,private,void,fast,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,return,return
CompactingHashTable -> @SuppressWarnings("unused") 	private void fastCompactPartition(int partitionNumber) throws IOException;1420654570;Compacts partition but may not reclaim all garbage__@param partitionNumber partition number_@throws IOException;@SuppressWarnings("unused")_	private void fastCompactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		return__	};compacts,partition,but,may,not,reclaim,all,garbage,param,partition,number,partition,number,throws,ioexception;suppress,warnings,unused,private,void,fast,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,return,return
CompactingHashTable -> @SuppressWarnings("unused") 	private void fastCompactPartition(int partitionNumber) throws IOException;1420654570;Compacts partition but may not reclaim all garbage__@param partitionNumber partition number_@throws IOException;@SuppressWarnings("unused")_	private void fastCompactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		return__	};compacts,partition,but,may,not,reclaim,all,garbage,param,partition,number,partition,number,throws,ioexception;suppress,warnings,unused,private,void,fast,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,return,return
CompactingHashTable -> @SuppressWarnings("unused") 	private void fastCompactPartition(int partitionNumber) throws IOException;1420663430;Compacts partition but may not reclaim all garbage__@param partitionNumber partition number_@throws IOException;@SuppressWarnings("unused")_	private void fastCompactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		return__	};compacts,partition,but,may,not,reclaim,all,garbage,param,partition,number,partition,number,throws,ioexception;suppress,warnings,unused,private,void,fast,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,return,return
CompactingHashTable -> @SuppressWarnings("unused") 	private void fastCompactPartition(int partitionNumber) throws IOException;1421838095;Compacts partition but may not reclaim all garbage__@param partitionNumber partition number_@throws IOException;@SuppressWarnings("unused")_	private void fastCompactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		return__	};compacts,partition,but,may,not,reclaim,all,garbage,param,partition,number,partition,number,throws,ioexception;suppress,warnings,unused,private,void,fast,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,return,return
CompactingHashTable -> @SuppressWarnings("unused") 	private void fastCompactPartition(int partitionNumber) throws IOException;1427646862;Compacts partition but may not reclaim all garbage__@param partitionNumber partition number_@throws IOException;@SuppressWarnings("unused")_	private void fastCompactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		return__	};compacts,partition,but,may,not,reclaim,all,garbage,param,partition,number,partition,number,throws,ioexception;suppress,warnings,unused,private,void,fast,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,return,return
CompactingHashTable -> private long getSize();1405529391;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1409845762;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1409911022;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1411473593;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1414786554;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1420654570;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1420654570;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1420663430;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1421838095;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1427646862;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1438803435;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1439805579;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1441738685;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1456936114;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1460741894;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1468441547;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getSize();1494520945;Size of all memory segments owned by this hash table__@return size in bytes;private long getSize() {_		long numSegments = 0__		numSegments += this.availableMemory.size()__		numSegments += this.buckets.length__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__			numSegments += p.numOverflowSegments__		}_		numSegments += this.compactionMemory.getBlockCount()__		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,this,hash,table,return,size,in,bytes;private,long,get,size,long,num,segments,0,num,segments,this,available,memory,size,num,segments,this,buckets,length,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,num,segments,p,num,overflow,segments,num,segments,this,compaction,memory,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private static final byte assignPartition(int bucket, byte numPartitions);1405024514;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static final byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,final,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static final byte assignPartition(int bucket, byte numPartitions);1405090423;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static final byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,final,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static final byte assignPartition(int bucket, byte numPartitions);1405529391;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static final byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,final,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static final byte assignPartition(int bucket, byte numPartitions);1409845762;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static final byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,final,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static final byte assignPartition(int bucket, byte numPartitions);1409911022;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static final byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,final,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static final byte assignPartition(int bucket, byte numPartitions);1411473593;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static final byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,final,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static final byte assignPartition(int bucket, byte numPartitions);1414786554;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static final byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,final,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static final byte assignPartition(int bucket, byte numPartitions);1420654570;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static final byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,final,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static final byte assignPartition(int bucket, byte numPartitions);1420654570;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static final byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,final,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static final byte assignPartition(int bucket, byte numPartitions);1420663430;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static final byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,final,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static final byte assignPartition(int bucket, byte numPartitions);1421838095;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static final byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,final,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static final byte assignPartition(int bucket, byte numPartitions);1427646862;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static final byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,final,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private String getMemoryConsumptionString();1405529391;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		String result = new String("numPartitions: " + this.partitions.size() + _				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() + _				" Partition memory: " + getPartitionSize())__		return result__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,string,result,new,string,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size,return,result
CompactingHashTable -> private String getMemoryConsumptionString();1409845762;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		String result = new String("numPartitions: " + this.partitions.size() + _				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() + _				" Partition memory: " + getPartitionSize())__		return result__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,string,result,new,string,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size,return,result
CompactingHashTable -> private String getMemoryConsumptionString();1409911022;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		String result = new String("numPartitions: " + this.partitions.size() + _				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() + _				" Partition memory: " + getPartitionSize())__		return result__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,string,result,new,string,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size,return,result
CompactingHashTable -> private String getMemoryConsumptionString();1411473593;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		String result = new String("numPartitions: " + this.partitions.size() + _				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() + _				" Partition memory: " + getPartitionSize())__		return result__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,string,result,new,string,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size,return,result
CompactingHashTable -> private String getMemoryConsumptionString();1414786554;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		String result = new String("numPartitions: " + this.partitions.size() + _				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() + _				" Partition memory: " + getPartitionSize())__		return result__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,string,result,new,string,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size,return,result
CompactingHashTable -> private String getMemoryConsumptionString();1420654570;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		String result = new String("numPartitions: " + this.partitions.size() + _				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() + _				" Partition memory: " + getPartitionSize())__		return result__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,string,result,new,string,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size,return,result
CompactingHashTable -> private String getMemoryConsumptionString();1420654570;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		String result = new String("numPartitions: " + this.partitions.size() + _				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() + _				" Partition memory: " + getPartitionSize())__		return result__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,string,result,new,string,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size,return,result
CompactingHashTable -> private String getMemoryConsumptionString();1420663430;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		String result = new String("numPartitions: " + this.partitions.size() + _				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() + _				" Partition memory: " + getPartitionSize())__		return result__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,string,result,new,string,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size,return,result
CompactingHashTable -> private String getMemoryConsumptionString();1421838095;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		String result = new String("numPartitions: " + this.partitions.size() + _				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() + _				" Partition memory: " + getPartitionSize())__		return result__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,string,result,new,string,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size,return,result
CompactingHashTable -> private String getMemoryConsumptionString();1427646862;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		String result = new String("numPartitions: " + this.partitions.size() + _				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() + _				" Partition memory: " + getPartitionSize())__		return result__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,string,result,new,string,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size,return,result
CompactingHashTable -> private String getMemoryConsumptionString();1438803435;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		return "numPartitions: " + this.partitions.size() +_				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() +_				" Partition memory: " + getPartitionSize()__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,return,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size
CompactingHashTable -> private String getMemoryConsumptionString();1439805579;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		return "numPartitions: " + this.partitions.size() +_				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() +_				" Partition memory: " + getPartitionSize()__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,return,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size
CompactingHashTable -> private String getMemoryConsumptionString();1441738685;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		return "numPartitions: " + this.partitions.size() +_				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() +_				" Partition memory: " + getPartitionSize()__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,return,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size
CompactingHashTable -> private String getMemoryConsumptionString();1456936114;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		return "numPartitions: " + this.partitions.size() +_				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() +_				" Partition memory: " + getPartitionSize()__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,return,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size
CompactingHashTable -> private String getMemoryConsumptionString();1460741894;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		return "numPartitions: " + this.partitions.size() +_				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() +_				" Partition memory: " + getPartitionSize()__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,return,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size
CompactingHashTable -> private String getMemoryConsumptionString();1468441547;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		return "numPartitions: " + this.partitions.size() +_				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() +_				" Partition memory: " + getPartitionSize()__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,return,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size
CompactingHashTable -> private String getMemoryConsumptionString();1494520945;@return String containing a summary of the memory consumption for error messages;private String getMemoryConsumptionString() {_		return "numPartitions: " + this.partitions.size() +_				" minPartition: " + getMinPartition() +_				" maxPartition: " + getMaxPartition() +_				" number of overflow segments: " + getOverflowSegmentCount() +_				" bucketSize: " + this.buckets.length +_				" Overall memory: " + getSize() +_				" Partition memory: " + getPartitionSize()__	};return,string,containing,a,summary,of,the,memory,consumption,for,error,messages;private,string,get,memory,consumption,string,return,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,overall,memory,get,size,partition,memory,get,partition,size
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1405529391;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int)(forwardPointer & 0xffffffff)__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1409845762;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int)(forwardPointer & 0xffffffff)__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1409911022;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int)(forwardPointer & 0xffffffff)__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1411473593;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int)(forwardPointer & 0xffffffff)__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1414786554;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int)(forwardPointer & 0xffffffff)__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1420654570;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int)(forwardPointer & 0xffffffff)__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1420654570;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int)(forwardPointer & 0xffffffff)__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1420663430;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int)(forwardPointer & 0xffffffff)__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1421838095;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int)(forwardPointer & 0xffffffff)__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1427646862;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int)(forwardPointer & 0xffffffff)__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1438803435;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int) forwardPointer__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1439805579;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int) forwardPointer__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1441738685;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int) forwardPointer__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1456936114;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int) forwardPointer__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1460741894;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int) forwardPointer__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1468441547;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int) forwardPointer__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> EntryIterator -> private boolean fillCache() throws IOException;1494520945;utility function that inserts all entries from a bucket and its overflow buckets into the cache__@return true if last bucket was not reached yet_@throws IOException;private boolean fillCache() throws IOException {_			if(currentBucketIndex >= table.numBuckets) {_				return false__			}_			MemorySegment bucket = table.buckets[currentSegmentIndex]__			_			final int partitionNumber = bucket.get(currentBucketOffset + HEADER_PARTITION_OFFSET)__			final InMemoryPartition<T> partition = table.partitions.get(partitionNumber)__			final MemorySegment[] overflowSegments = partition.overflowSegments__			_			int countInSegment = bucket.getInt(currentBucketOffset + HEADER_COUNT_OFFSET)__			int numInSegment = 0__			int posInSegment = currentBucketOffset + BUCKET_POINTER_START_OFFSET__			int bucketOffset = currentBucketOffset___			_			while (true) {_				while (numInSegment < countInSegment) {_					long pointer = bucket.getLong(posInSegment)__					posInSegment += POINTER_LEN__					numInSegment++__					T target = table.buildSideSerializer.createInstance()__					try {_						target = partition.readRecordAt(pointer, target)__						cache.add(target)__					} catch (IOException e) {_							throw new RuntimeException("Error deserializing record from the Hash Table: " + e.getMessage(), e)__					}_				}_				_				final long forwardPointer = bucket.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_					break__				}_				final int overflowSegNum = (int) (forwardPointer >>> 32)__				bucket = overflowSegments[overflowSegNum]__				bucketOffset = (int) forwardPointer__				countInSegment = bucket.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				posInSegment = bucketOffset + BUCKET_POINTER_START_OFFSET__				numInSegment = 0__			}_			currentBucketIndex++__			if(currentBucketIndex % bucketsPerSegment == 0) {_				currentSegmentIndex++__				currentBucketOffset = 0__			} else {_				currentBucketOffset += HASH_BUCKET_SIZE__			}_			return true__		};utility,function,that,inserts,all,entries,from,a,bucket,and,its,overflow,buckets,into,the,cache,return,true,if,last,bucket,was,not,reached,yet,throws,ioexception;private,boolean,fill,cache,throws,ioexception,if,current,bucket,index,table,num,buckets,return,false,memory,segment,bucket,table,buckets,current,segment,index,final,int,partition,number,bucket,get,current,bucket,offset,final,in,memory,partition,t,partition,table,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,int,count,in,segment,bucket,get,int,current,bucket,offset,int,num,in,segment,0,int,pos,in,segment,current,bucket,offset,int,bucket,offset,current,bucket,offset,while,true,while,num,in,segment,count,in,segment,long,pointer,bucket,get,long,pos,in,segment,pos,in,segment,num,in,segment,t,target,table,build,side,serializer,create,instance,try,target,partition,read,record,at,pointer,target,cache,add,target,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hash,table,e,get,message,e,final,long,forward,pointer,bucket,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,bucket,get,int,bucket,offset,pos,in,segment,bucket,offset,num,in,segment,0,current,bucket,index,if,current,bucket,index,buckets,per,segment,0,current,segment,index,current,bucket,offset,0,else,current,bucket,offset,return,true
CompactingHashTable -> @Override 	public void close();1438803435;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;@Override_	public void close() {_		_		synchronized (this.stateLock) {_			if (this.closed) {_				return__			}_			this.closed = true__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;override,public,void,close,synchronized,this,state,lock,if,this,closed,return,this,closed,true,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> @Override 	public void close();1439805579;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;@Override_	public void close() {_		_		synchronized (this.stateLock) {_			if (this.closed) {_				return__			}_			this.closed = true__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;override,public,void,close,synchronized,this,state,lock,if,this,closed,return,this,closed,true,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> @Override 	public void close();1441738685;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;@Override_	public void close() {_		_		synchronized (this.stateLock) {_			if (this.closed) {_				return__			}_			this.closed = true__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;override,public,void,close,synchronized,this,state,lock,if,this,closed,return,this,closed,true,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> @Override 	public void close();1456936114;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;@Override_	public void close() {_		_		synchronized (this.stateLock) {_			if (this.closed) {_				return__			}_			this.closed = true__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;override,public,void,close,synchronized,this,state,lock,if,this,closed,return,this,closed,true,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> @Override 	public void close();1460741894;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;@Override_	public void close() {_		_		synchronized (this.stateLock) {_			if (this.closed) {_				return__			}_			this.closed = true__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;override,public,void,close,synchronized,this,state,lock,if,this,closed,return,this,closed,true,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> @Override 	public void close();1468441547;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;@Override_	public void close() {_		_		synchronized (this.stateLock) {_			if (this.closed) {_				return__			}_			this.closed = true__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;override,public,void,close,synchronized,this,state,lock,if,this,closed,return,this,closed,true,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> @Override 	public void close();1494520945;Closes the hash table. This effectively releases all internal structures and closes all_open files and removes them. The call to this method is valid both as a cleanup after the_complete inputs were properly processed, and as an cancellation call, which cleans up_all resources that are currently held by the hash join. If another process still access the hash_table after close has been called no operations will be performed.;@Override_	public void close() {_		_		synchronized (this.stateLock) {_			if (this.closed) {_				return__			}_			this.closed = true__		}_		_		LOG.debug("Closing hash table and releasing resources.")__		_		_		releaseTable()__		_		_		clearPartitions()__	};closes,the,hash,table,this,effectively,releases,all,internal,structures,and,closes,all,open,files,and,removes,them,the,call,to,this,method,is,valid,both,as,a,cleanup,after,the,complete,inputs,were,properly,processed,and,as,an,cancellation,call,which,cleans,up,all,resources,that,are,currently,held,by,the,hash,join,if,another,process,still,access,the,hash,table,after,close,has,been,called,no,operations,will,be,performed;override,public,void,close,synchronized,this,state,lock,if,this,closed,return,this,closed,true,log,debug,closing,hash,table,and,releasing,resources,release,table,clear,partitions
CompactingHashTable -> private static int getPartitioningFanOutNoEstimates(int numBuffers);1438803435;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static int getPartitioningFanOutNoEstimates(int numBuffers);1439805579;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static int getPartitioningFanOutNoEstimates(int numBuffers);1441738685;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static int getPartitioningFanOutNoEstimates(int numBuffers);1456936114;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static int getPartitioningFanOutNoEstimates(int numBuffers);1460741894;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static int getPartitioningFanOutNoEstimates(int numBuffers);1468441547;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static int getPartitioningFanOutNoEstimates(int numBuffers);1494520945;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> public void insertOrReplaceRecord(T record) throws IOException;1438803435;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@throws IOException;public void insertOrReplaceRecord(T record) throws IOException {_		if (this.closed) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		final MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		final int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		_		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					T valueAtPosition = partition.readRecordAt(pointer)__					if (this.buildSideComparator.equalToReference(valueAtPosition)) {_						long newPointer = insertRecordIntoPartition(record, partition, true)__						bucket.putLong(pointerOffset, newPointer)__						return__					}_				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				long pointer = insertRecordIntoPartition(record, partition, false)___				if (countInSegment < NUM_ENTRIES_PER_BUCKET) {_					_					bucket.putInt(bucketInSegmentOffset + BUCKET_HEADER_LENGTH + (countInSegment * HASH_CODE_LEN), searchHashCode)_ _					bucket.putLong(bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (countInSegment * POINTER_LEN), pointer)_ _					bucket.putInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET, countInSegment + 1)_ _				}_				else {_					insertBucketEntryFromStart(originalBucket, originalBucketOffset, searchHashCode, pointer, partitionNumber)__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) newForwardPointer__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,throws,ioexception;public,void,insert,or,replace,record,t,record,throws,ioexception,if,this,closed,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,final,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,final,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,final,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,t,value,at,position,partition,read,record,at,pointer,if,this,build,side,comparator,equal,to,reference,value,at,position,long,new,pointer,insert,record,into,partition,record,partition,true,bucket,put,long,pointer,offset,new,pointer,return,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,insert,record,into,partition,record,partition,false,if,count,in,segment,bucket,put,int,bucket,in,segment,offset,count,in,segment,search,hash,code,bucket,put,long,bucket,in,segment,offset,count,in,segment,pointer,bucket,put,int,bucket,in,segment,offset,count,in,segment,1,else,insert,bucket,entry,from,start,original,bucket,original,bucket,offset,search,hash,code,pointer,partition,number,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public void insertOrReplaceRecord(T record) throws IOException;1439805579;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@throws IOException;public void insertOrReplaceRecord(T record) throws IOException {_		if (this.closed) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		final MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		final int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		_		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					_					_					T valueAtPosition = partition.readRecordAt(pointer)__					if (this.buildSideComparator.equalToReference(valueAtPosition)) {_						long newPointer = insertRecordIntoPartition(record, partition, true)__						bucket.putLong(pointerOffset, newPointer)__						return__					}_				}_				numInSegment++__			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				long pointer = insertRecordIntoPartition(record, partition, false)___				if (countInSegment < NUM_ENTRIES_PER_BUCKET) {_					_					bucket.putInt(bucketInSegmentOffset + BUCKET_HEADER_LENGTH + (countInSegment * HASH_CODE_LEN), searchHashCode)_ _					bucket.putLong(bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (countInSegment * POINTER_LEN), pointer)_ _					bucket.putInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET, countInSegment + 1)_ _				}_				else {_					insertBucketEntryFromStart(originalBucket, originalBucketOffset, searchHashCode, pointer, partitionNumber)__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) newForwardPointer__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,throws,ioexception;public,void,insert,or,replace,record,t,record,throws,ioexception,if,this,closed,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,final,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,final,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,final,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,t,value,at,position,partition,read,record,at,pointer,if,this,build,side,comparator,equal,to,reference,value,at,position,long,new,pointer,insert,record,into,partition,record,partition,true,bucket,put,long,pointer,offset,new,pointer,return,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,insert,record,into,partition,record,partition,false,if,count,in,segment,bucket,put,int,bucket,in,segment,offset,count,in,segment,search,hash,code,bucket,put,long,bucket,in,segment,offset,count,in,segment,pointer,bucket,put,int,bucket,in,segment,offset,count,in,segment,1,else,insert,bucket,entry,from,start,original,bucket,original,bucket,offset,search,hash,code,pointer,partition,number,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0
CompactingHashTable -> public void insertOrReplaceRecord(T record) throws IOException;1441738685;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@throws IOException;public void insertOrReplaceRecord(T record) throws IOException {_		if (this.closed) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		final MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		final int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		_		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					_					_					T valueAtPosition = partition.readRecordAt(pointer)__					if (this.buildSideComparator.equalToReference(valueAtPosition)) {_						long newPointer = insertRecordIntoPartition(record, partition, true)__						bucket.putLong(pointerOffset, newPointer)__						return__					}_				}_				numInSegment++__			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				long pointer = insertRecordIntoPartition(record, partition, false)___				if (countInSegment < NUM_ENTRIES_PER_BUCKET) {_					_					bucket.putInt(bucketInSegmentOffset + BUCKET_HEADER_LENGTH + (countInSegment * HASH_CODE_LEN), searchHashCode)_ _					bucket.putLong(bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (countInSegment * POINTER_LEN), pointer)_ _					bucket.putInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET, countInSegment + 1)_ _				}_				else {_					insertBucketEntryFromStart(originalBucket, originalBucketOffset, searchHashCode, pointer, partitionNumber)__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) newForwardPointer__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,throws,ioexception;public,void,insert,or,replace,record,t,record,throws,ioexception,if,this,closed,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,final,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,final,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,final,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,t,value,at,position,partition,read,record,at,pointer,if,this,build,side,comparator,equal,to,reference,value,at,position,long,new,pointer,insert,record,into,partition,record,partition,true,bucket,put,long,pointer,offset,new,pointer,return,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,insert,record,into,partition,record,partition,false,if,count,in,segment,bucket,put,int,bucket,in,segment,offset,count,in,segment,search,hash,code,bucket,put,long,bucket,in,segment,offset,count,in,segment,pointer,bucket,put,int,bucket,in,segment,offset,count,in,segment,1,else,insert,bucket,entry,from,start,original,bucket,original,bucket,offset,search,hash,code,pointer,partition,number,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0
CompactingHashTable -> public void insertOrReplaceRecord(T record) throws IOException;1456936114;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@throws IOException;public void insertOrReplaceRecord(T record) throws IOException {_		if (this.closed) {_			return__		}_		_		final int searchHashCode = MathUtils.jenkinsHash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		final MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		final int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		_		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					_					_					T valueAtPosition = partition.readRecordAt(pointer)__					if (this.buildSideComparator.equalToReference(valueAtPosition)) {_						long newPointer = insertRecordIntoPartition(record, partition, true)__						bucket.putLong(pointerOffset, newPointer)__						return__					}_				}_				numInSegment++__			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				long pointer = insertRecordIntoPartition(record, partition, false)___				if (countInSegment < NUM_ENTRIES_PER_BUCKET) {_					_					bucket.putInt(bucketInSegmentOffset + BUCKET_HEADER_LENGTH + (countInSegment * HASH_CODE_LEN), searchHashCode)_ _					bucket.putLong(bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (countInSegment * POINTER_LEN), pointer)_ _					bucket.putInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET, countInSegment + 1)_ _				}_				else {_					insertBucketEntryFromStart(originalBucket, originalBucketOffset, searchHashCode, pointer, partitionNumber)__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) newForwardPointer__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,throws,ioexception;public,void,insert,or,replace,record,t,record,throws,ioexception,if,this,closed,return,final,int,search,hash,code,math,utils,jenkins,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,final,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,final,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,final,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,t,value,at,position,partition,read,record,at,pointer,if,this,build,side,comparator,equal,to,reference,value,at,position,long,new,pointer,insert,record,into,partition,record,partition,true,bucket,put,long,pointer,offset,new,pointer,return,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,insert,record,into,partition,record,partition,false,if,count,in,segment,bucket,put,int,bucket,in,segment,offset,count,in,segment,search,hash,code,bucket,put,long,bucket,in,segment,offset,count,in,segment,pointer,bucket,put,int,bucket,in,segment,offset,count,in,segment,1,else,insert,bucket,entry,from,start,original,bucket,original,bucket,offset,search,hash,code,pointer,partition,number,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0
CompactingHashTable -> public void insertOrReplaceRecord(T record) throws IOException;1460741894;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@throws IOException;public void insertOrReplaceRecord(T record) throws IOException {_		if (this.closed) {_			return__		}_		_		final int searchHashCode = MathUtils.jenkinsHash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		final MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		final int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		_		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					_					_					T valueAtPosition = partition.readRecordAt(pointer)__					if (this.buildSideComparator.equalToReference(valueAtPosition)) {_						long newPointer = insertRecordIntoPartition(record, partition, true)__						bucket.putLong(pointerOffset, newPointer)__						return__					}_				}_				numInSegment++__			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				long pointer = insertRecordIntoPartition(record, partition, false)___				if (countInSegment < NUM_ENTRIES_PER_BUCKET) {_					_					bucket.putInt(bucketInSegmentOffset + BUCKET_HEADER_LENGTH + (countInSegment * HASH_CODE_LEN), searchHashCode)_ _					bucket.putLong(bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (countInSegment * POINTER_LEN), pointer)_ _					bucket.putInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET, countInSegment + 1)_ _				}_				else {_					insertBucketEntryFromStart(originalBucket, originalBucketOffset, searchHashCode, pointer, partitionNumber)__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) newForwardPointer__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,throws,ioexception;public,void,insert,or,replace,record,t,record,throws,ioexception,if,this,closed,return,final,int,search,hash,code,math,utils,jenkins,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,final,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,final,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,final,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,t,value,at,position,partition,read,record,at,pointer,if,this,build,side,comparator,equal,to,reference,value,at,position,long,new,pointer,insert,record,into,partition,record,partition,true,bucket,put,long,pointer,offset,new,pointer,return,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,insert,record,into,partition,record,partition,false,if,count,in,segment,bucket,put,int,bucket,in,segment,offset,count,in,segment,search,hash,code,bucket,put,long,bucket,in,segment,offset,count,in,segment,pointer,bucket,put,int,bucket,in,segment,offset,count,in,segment,1,else,insert,bucket,entry,from,start,original,bucket,original,bucket,offset,search,hash,code,pointer,partition,number,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0
CompactingHashTable -> public void insertOrReplaceRecord(T record) throws IOException;1468441547;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@throws IOException;public void insertOrReplaceRecord(T record) throws IOException {_		if (this.closed) {_			return__		}__		final int searchHashCode = MathUtils.jenkinsHash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		final MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		final int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		_		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					_					_					T valueAtPosition = partition.readRecordAt(pointer)__					if (this.buildSideComparator.equalToReference(valueAtPosition)) {_						long newPointer = insertRecordIntoPartition(record, partition, true)__						bucket.putLong(pointerOffset, newPointer)__						return__					}_				}_				numInSegment++__			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				long pointer = insertRecordIntoPartition(record, partition, false)___				if (countInSegment < NUM_ENTRIES_PER_BUCKET) {_					_					bucket.putInt(bucketInSegmentOffset + BUCKET_HEADER_LENGTH + (countInSegment * HASH_CODE_LEN), searchHashCode)_ _					bucket.putLong(bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (countInSegment * POINTER_LEN), pointer)_ _					bucket.putInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET, countInSegment + 1)_ _				}_				else {_					insertBucketEntryFromStart(originalBucket, originalBucketOffset, searchHashCode, pointer, partitionNumber)__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) newForwardPointer__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,throws,ioexception;public,void,insert,or,replace,record,t,record,throws,ioexception,if,this,closed,return,final,int,search,hash,code,math,utils,jenkins,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,final,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,final,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,final,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,t,value,at,position,partition,read,record,at,pointer,if,this,build,side,comparator,equal,to,reference,value,at,position,long,new,pointer,insert,record,into,partition,record,partition,true,bucket,put,long,pointer,offset,new,pointer,return,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,insert,record,into,partition,record,partition,false,if,count,in,segment,bucket,put,int,bucket,in,segment,offset,count,in,segment,search,hash,code,bucket,put,long,bucket,in,segment,offset,count,in,segment,pointer,bucket,put,int,bucket,in,segment,offset,count,in,segment,1,else,insert,bucket,entry,from,start,original,bucket,original,bucket,offset,search,hash,code,pointer,partition,number,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0
CompactingHashTable -> public void insertOrReplaceRecord(T record) throws IOException;1494520945;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@throws IOException;public void insertOrReplaceRecord(T record) throws IOException {_		if (this.closed) {_			return__		}__		final int searchHashCode = MathUtils.jenkinsHash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		final MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		final int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		_		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					_					_					T valueAtPosition = partition.readRecordAt(pointer)__					if (this.buildSideComparator.equalToReference(valueAtPosition)) {_						long newPointer = insertRecordIntoPartition(record, partition, true)__						bucket.putLong(pointerOffset, newPointer)__						return__					}_				}_				numInSegment++__			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				long pointer = insertRecordIntoPartition(record, partition, false)___				if (countInSegment < NUM_ENTRIES_PER_BUCKET) {_					_					bucket.putInt(bucketInSegmentOffset + BUCKET_HEADER_LENGTH + (countInSegment * HASH_CODE_LEN), searchHashCode)_ _					bucket.putLong(bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (countInSegment * POINTER_LEN), pointer)_ _					bucket.putInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET, countInSegment + 1)_ _				}_				else {_					insertBucketEntryFromStart(originalBucket, originalBucketOffset, searchHashCode, pointer, partitionNumber)__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) newForwardPointer__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,throws,ioexception;public,void,insert,or,replace,record,t,record,throws,ioexception,if,this,closed,return,final,int,search,hash,code,math,utils,jenkins,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,final,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,final,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,final,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,t,value,at,position,partition,read,record,at,pointer,if,this,build,side,comparator,equal,to,reference,value,at,position,long,new,pointer,insert,record,into,partition,record,partition,true,bucket,put,long,pointer,offset,new,pointer,return,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,insert,record,into,partition,record,partition,false,if,count,in,segment,bucket,put,int,bucket,in,segment,offset,count,in,segment,search,hash,code,bucket,put,long,bucket,in,segment,offset,count,in,segment,pointer,bucket,put,int,bucket,in,segment,offset,count,in,segment,1,else,insert,bucket,entry,from,start,original,bucket,original,bucket,offset,search,hash,code,pointer,partition,number,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0
CompactingHashTable -> private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1405529391;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		while(numBuckets % numPartitions != 0) {_			numBuckets++__		}_		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,final,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,while,num,buckets,num,partitions,0,num,buckets,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1409845762;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		while(numBuckets % numPartitions != 0) {_			numBuckets++__		}_		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,final,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,while,num,buckets,num,partitions,0,num,buckets,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1409911022;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		while(numBuckets % numPartitions != 0) {_			numBuckets++__		}_		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,final,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,while,num,buckets,num,partitions,0,num,buckets,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1411473593;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		while(numBuckets % numPartitions != 0) {_			numBuckets++__		}_		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,final,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,while,num,buckets,num,partitions,0,num,buckets,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1414786554;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		while(numBuckets % numPartitions != 0) {_			numBuckets++__		}_		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,final,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,while,num,buckets,num,partitions,0,num,buckets,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1420654570;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		while(numBuckets % numPartitions != 0) {_			numBuckets++__		}_		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,final,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,while,num,buckets,num,partitions,0,num,buckets,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1420654570;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		while(numBuckets % numPartitions != 0) {_			numBuckets++__		}_		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,final,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,while,num,buckets,num,partitions,0,num,buckets,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1420663430;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		while(numBuckets % numPartitions != 0) {_			numBuckets++__		}_		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,final,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,while,num,buckets,num,partitions,0,num,buckets,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1421838095;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		while(numBuckets % numPartitions != 0) {_			numBuckets++__		}_		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,final,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,while,num,buckets,num,partitions,0,num,buckets,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1427646862;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static final int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		while(numBuckets % numPartitions != 0) {_			numBuckets++__		}_		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,final,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,while,num,buckets,num,partitions,0,num,buckets,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1405529391;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if(this.closed.get() || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer = 0L__		int pointerOffset = 0__		int bucketOffset = 0__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int)(forwardPointer & 0xffffffff)__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setCompaction(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,get,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,0l,int,pointer,offset,0,int,bucket,offset,0,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,compaction,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1409845762;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if(this.closed.get() || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer = 0L__		int pointerOffset = 0__		int bucketOffset = 0__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int)(forwardPointer & 0xffffffff)__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setCompaction(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,get,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,0l,int,pointer,offset,0,int,bucket,offset,0,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,compaction,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1409911022;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if(this.closed.get() || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer = 0L__		int pointerOffset = 0__		int bucketOffset = 0__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int)(forwardPointer & 0xffffffff)__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setCompaction(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,get,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,0l,int,pointer,offset,0,int,bucket,offset,0,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,compaction,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1411473593;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if(this.closed.get() || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer = 0L__		int pointerOffset = 0__		int bucketOffset = 0__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int)(forwardPointer & 0xffffffff)__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setCompaction(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,get,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,0l,int,pointer,offset,0,int,bucket,offset,0,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,compaction,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1414786554;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if(this.closed.get() || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer = 0L__		int pointerOffset = 0__		int bucketOffset = 0__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int)(forwardPointer & 0xffffffff)__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setCompaction(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,get,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,0l,int,pointer,offset,0,int,bucket,offset,0,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,compaction,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1420654570;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if(this.closed.get() || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer = 0L__		int pointerOffset = 0__		int bucketOffset = 0__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int)(forwardPointer & 0xffffffff)__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setCompaction(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,get,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,0l,int,pointer,offset,0,int,bucket,offset,0,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,compaction,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1420654570;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if(this.closed.get() || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer = 0L__		int pointerOffset = 0__		int bucketOffset = 0__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int)(forwardPointer & 0xffffffff)__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setCompaction(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,get,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,0l,int,pointer,offset,0,int,bucket,offset,0,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,compaction,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1420663430;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if(this.closed.get() || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer = 0L__		int pointerOffset = 0__		int bucketOffset = 0__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int)(forwardPointer & 0xffffffff)__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setCompaction(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,get,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,0l,int,pointer,offset,0,int,bucket,offset,0,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,compaction,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1421838095;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if(this.closed.get() || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer = 0L__		int pointerOffset = 0__		int bucketOffset = 0__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int)(forwardPointer & 0xffffffff)__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setCompaction(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,get,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,0l,int,pointer,offset,0,int,bucket,offset,0,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,compaction,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1427646862;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if(this.closed.get() || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer = 0L__		int pointerOffset = 0__		int bucketOffset = 0__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int)(forwardPointer & 0xffffffff)__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setCompaction(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,get,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,0l,int,pointer,offset,0,int,bucket,offset,0,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,compaction,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1438803435;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if (this.closed || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer__		int pointerOffset__		int bucketOffset__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int) forwardPointer__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setIsCompacted(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,int,pointer,offset,int,bucket,offset,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,is,compacted,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1439805579;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if (this.closed || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer__		int pointerOffset__		int bucketOffset__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int) forwardPointer__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setIsCompacted(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,int,pointer,offset,int,bucket,offset,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,is,compacted,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1441738685;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if (this.closed || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer__		int pointerOffset__		int bucketOffset__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int) forwardPointer__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setIsCompacted(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,int,pointer,offset,int,bucket,offset,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,is,compacted,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1456936114;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if (this.closed || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer__		int pointerOffset__		int bucketOffset__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int) forwardPointer__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setIsCompacted(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,int,pointer,offset,int,bucket,offset,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,is,compacted,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1460741894;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if (this.closed || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer__		int pointerOffset__		int bucketOffset__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int) forwardPointer__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setIsCompacted(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,int,pointer,offset,int,bucket,offset,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,is,compacted,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1468441547;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if (this.closed || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer__		int pointerOffset__		int bucketOffset__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int) forwardPointer__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setIsCompacted(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,int,pointer,offset,int,bucket,offset,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,is,compacted,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private void compactPartition(final int partitionNumber) throws IOException;1494520945;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partitionNumber partition to compact_@throws IOException;private void compactPartition(final int partitionNumber) throws IOException {_		_		if (this.closed || partitionNumber >= this.partitions.size() || this.partitions.get(partitionNumber).isCompacted()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		this.compactionMemory.pushDownPages()__		T tempHolder = this.buildSideSerializer.createInstance()__		final int numPartitions = this.partitions.size()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		MemorySegment[] overflowSegments = partition.overflowSegments__		long pointer__		int pointerOffset__		int bucketOffset__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! wanted: " + partitionNumber + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__				}_				_				int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				int numInSegment = 0__				pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__				while (true) {_					while (numInSegment < countInSegment) {_						pointer = segment.getLong(pointerOffset)__						tempHolder = partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						segment.putLong(pointerOffset, pointer)__						pointerOffset += POINTER_LEN__						numInSegment++__					}_					_					final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__					if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_						break__					}_					final int overflowSegNum = (int) (forwardPointer >>> 32)__					segment = overflowSegments[overflowSegNum]__					bucketOffset = (int) forwardPointer__					countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__					numInSegment = 0__				}_				segment = this.buckets[i]__			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.partitions.get(partitionNumber).overflowSegments = partition.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = partition.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = partition.nextOverflowBucket__		this.partitions.get(partitionNumber).setIsCompacted(true)__		_		this.compactionMemory = partition__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		this.compactionMemory.overflowSegments = null__		this.compactionMemory.numOverflowSegments = 0__		this.compactionMemory.nextOverflowBucket = 0__		_		this.compactionMemory.clearAllMemory(this.availableMemory)__		int maxSegmentNumber = this.getMaxPartition()__		this.compactionMemory.allocateSegments(maxSegmentNumber)__		this.compactionMemory.resetRWViews()__		this.compactionMemory.pushDownPages()__	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,number,partition,to,compact,throws,ioexception;private,void,compact,partition,final,int,partition,number,throws,ioexception,if,this,closed,partition,number,this,partitions,size,this,partitions,get,partition,number,is,compacted,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,this,compaction,memory,push,down,pages,t,temp,holder,this,build,side,serializer,create,instance,final,int,num,partitions,this,partitions,size,in,memory,partition,t,partition,this,partitions,remove,partition,number,memory,segment,overflow,segments,partition,overflow,segments,long,pointer,int,pointer,offset,int,bucket,offset,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,wanted,partition,number,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,pointer,segment,get,long,pointer,offset,temp,holder,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,pointer,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,num,in,segment,0,segment,this,buckets,i,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,partitions,get,partition,number,overflow,segments,partition,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,partition,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,partition,next,overflow,bucket,this,partitions,get,partition,number,set,is,compacted,true,this,compaction,memory,partition,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,this,compaction,memory,overflow,segments,null,this,compaction,memory,num,overflow,segments,0,this,compaction,memory,next,overflow,bucket,0,this,compaction,memory,clear,all,memory,this,available,memory,int,max,segment,number,this,get,max,partition,this,compaction,memory,allocate,segments,max,segment,number,this,compaction,memory,reset,rwviews,this,compaction,memory,push,down,pages
CompactingHashTable -> private static int hash(int code);1438803435;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static int hash(int code);1439805579;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static int hash(int code);1441738685;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> @Override 	public void open();1438803435;Initialize the hash table;@Override_	public void open() {_		synchronized (stateLock) {_			if (!closed) {_				throw new IllegalStateException("currently not closed.")__			}_			closed = false__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};initialize,the,hash,table;override,public,void,open,synchronized,state,lock,if,closed,throw,new,illegal,state,exception,currently,not,closed,closed,false,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> @Override 	public void open();1439805579;Initialize the hash table;@Override_	public void open() {_		synchronized (stateLock) {_			if (!closed) {_				throw new IllegalStateException("currently not closed.")__			}_			closed = false__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};initialize,the,hash,table;override,public,void,open,synchronized,state,lock,if,closed,throw,new,illegal,state,exception,currently,not,closed,closed,false,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> @Override 	public void open();1441738685;Initialize the hash table;@Override_	public void open() {_		synchronized (stateLock) {_			if (!closed) {_				throw new IllegalStateException("currently not closed.")__			}_			closed = false__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};initialize,the,hash,table;override,public,void,open,synchronized,state,lock,if,closed,throw,new,illegal,state,exception,currently,not,closed,closed,false,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> @Override 	public void open();1456936114;Initialize the hash table;@Override_	public void open() {_		synchronized (stateLock) {_			if (!closed) {_				throw new IllegalStateException("currently not closed.")__			}_			closed = false__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};initialize,the,hash,table;override,public,void,open,synchronized,state,lock,if,closed,throw,new,illegal,state,exception,currently,not,closed,closed,false,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> @Override 	public void open();1460741894;Initialize the hash table;@Override_	public void open() {_		synchronized (stateLock) {_			if (!closed) {_				throw new IllegalStateException("currently not closed.")__			}_			closed = false__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};initialize,the,hash,table;override,public,void,open,synchronized,state,lock,if,closed,throw,new,illegal,state,exception,currently,not,closed,closed,false,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> @Override 	public void open();1468441547;Initialize the hash table;@Override_	public void open() {_		synchronized (stateLock) {_			if (!closed) {_				throw new IllegalStateException("currently not closed.")__			}_			closed = false__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};initialize,the,hash,table;override,public,void,open,synchronized,state,lock,if,closed,throw,new,illegal,state,exception,currently,not,closed,closed,false,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> @Override 	public void open();1494520945;Initialize the hash table;@Override_	public void open() {_		synchronized (stateLock) {_			if (!closed) {_				throw new IllegalStateException("currently not closed.")__			}_			closed = false__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};initialize,the,hash,table;override,public,void,open,synchronized,state,lock,if,closed,throw,new,illegal,state,exception,currently,not,closed,closed,false,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket, 												int originalBucketOffset, int currentBucketOffset, 												int countInCurrentBucket, long originalForwardPointer, 												int hashCode, long pointer, int partitionNumber) throws IOException;1438803435;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket,_												int originalBucketOffset, int currentBucketOffset,_												int countInCurrentBucket, long originalForwardPointer,_												int hashCode, long pointer, int partitionNumber) throws IOException {_		boolean checkForResize = false__		if (countInCurrentBucket < NUM_ENTRIES_PER_BUCKET) {_			_			currentBucket.putInt(currentBucketOffset + BUCKET_HEADER_LENGTH + (countInCurrentBucket * HASH_CODE_LEN), hashCode)_ _			currentBucket.putLong(currentBucketOffset + BUCKET_POINTER_START_OFFSET + (countInCurrentBucket * POINTER_LEN), pointer)_ _			currentBucket.putInt(currentBucketOffset + HEADER_COUNT_OFFSET, countInCurrentBucket + 1)_ _		}_		else {_			_			final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__			MemorySegment overflowSeg__			final int overflowSegmentNum__			final int overflowBucketOffset__			_			_			if (partition.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowSegmentNum = partition.numOverflowSegments__				_				_				if (partition.overflowSegments.length <= partition.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[partition.overflowSegments.length * 2]__					System.arraycopy(partition.overflowSegments, 0, newSegsArray, 0, partition.overflowSegments.length)__					partition.overflowSegments = newSegsArray__				}_				partition.overflowSegments[partition.numOverflowSegments] = overflowSeg__				partition.numOverflowSegments++__				checkForResize = true__			}_			else {_				_				overflowSegmentNum = partition.numOverflowSegments - 1__				overflowSeg = partition.overflowSegments[overflowSegmentNum]__				overflowBucketOffset = partition.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			partition.nextOverflowBucket = (partition.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : partition.nextOverflowBucket + 1)__			_			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, originalForwardPointer)__			final long pointerToNewBucket = (((long) overflowSegmentNum) << 32) | ((long) overflowBucketOffset)__			originalBucket.putLong(originalBucketOffset + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_	_			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			if(checkForResize && !this.isResizing) {_				_				if(this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,search,memory,segment,original,bucket,memory,segment,current,bucket,int,original,bucket,offset,int,current,bucket,offset,int,count,in,current,bucket,long,original,forward,pointer,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,if,count,in,current,bucket,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,hash,code,current,bucket,put,long,current,bucket,offset,count,in,current,bucket,pointer,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,1,else,final,in,memory,partition,t,partition,this,partitions,get,partition,number,memory,segment,overflow,seg,final,int,overflow,segment,num,final,int,overflow,bucket,offset,if,partition,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,segment,num,partition,num,overflow,segments,if,partition,overflow,segments,length,partition,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,partition,overflow,segments,length,2,system,arraycopy,partition,overflow,segments,0,new,segs,array,0,partition,overflow,segments,length,partition,overflow,segments,new,segs,array,partition,overflow,segments,partition,num,overflow,segments,overflow,seg,partition,num,overflow,segments,check,for,resize,true,else,overflow,segment,num,partition,num,overflow,segments,1,overflow,seg,partition,overflow,segments,overflow,segment,num,overflow,bucket,offset,partition,next,overflow,bucket,partition,next,overflow,bucket,partition,next,overflow,bucket,this,buckets,per,segment,mask,0,partition,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,original,forward,pointer,final,long,pointer,to,new,bucket,long,overflow,segment,num,32,long,overflow,bucket,offset,original,bucket,put,long,original,bucket,offset,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket, 												int originalBucketOffset, int currentBucketOffset, 												int countInCurrentBucket, long originalForwardPointer, 												int hashCode, long pointer, int partitionNumber) throws IOException;1439805579;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket,_												int originalBucketOffset, int currentBucketOffset,_												int countInCurrentBucket, long originalForwardPointer,_												int hashCode, long pointer, int partitionNumber) throws IOException {_		boolean checkForResize = false__		if (countInCurrentBucket < NUM_ENTRIES_PER_BUCKET) {_			_			currentBucket.putInt(currentBucketOffset + BUCKET_HEADER_LENGTH + (countInCurrentBucket * HASH_CODE_LEN), hashCode)_ _			currentBucket.putLong(currentBucketOffset + BUCKET_POINTER_START_OFFSET + (countInCurrentBucket * POINTER_LEN), pointer)_ _			currentBucket.putInt(currentBucketOffset + HEADER_COUNT_OFFSET, countInCurrentBucket + 1)_ _		}_		else {_			_			final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__			MemorySegment overflowSeg__			final int overflowSegmentNum__			final int overflowBucketOffset__			_			_			if (partition.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowSegmentNum = partition.numOverflowSegments__				_				_				if (partition.overflowSegments.length <= partition.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[partition.overflowSegments.length * 2]__					System.arraycopy(partition.overflowSegments, 0, newSegsArray, 0, partition.overflowSegments.length)__					partition.overflowSegments = newSegsArray__				}_				partition.overflowSegments[partition.numOverflowSegments] = overflowSeg__				partition.numOverflowSegments++__				checkForResize = true__			}_			else {_				_				overflowSegmentNum = partition.numOverflowSegments - 1__				overflowSeg = partition.overflowSegments[overflowSegmentNum]__				overflowBucketOffset = partition.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			partition.nextOverflowBucket = (partition.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : partition.nextOverflowBucket + 1)__			_			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, originalForwardPointer)__			final long pointerToNewBucket = (((long) overflowSegmentNum) << 32) | ((long) overflowBucketOffset)__			originalBucket.putLong(originalBucketOffset + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_	_			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			if(checkForResize && !this.isResizing) {_				_				if(this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,search,memory,segment,original,bucket,memory,segment,current,bucket,int,original,bucket,offset,int,current,bucket,offset,int,count,in,current,bucket,long,original,forward,pointer,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,if,count,in,current,bucket,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,hash,code,current,bucket,put,long,current,bucket,offset,count,in,current,bucket,pointer,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,1,else,final,in,memory,partition,t,partition,this,partitions,get,partition,number,memory,segment,overflow,seg,final,int,overflow,segment,num,final,int,overflow,bucket,offset,if,partition,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,segment,num,partition,num,overflow,segments,if,partition,overflow,segments,length,partition,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,partition,overflow,segments,length,2,system,arraycopy,partition,overflow,segments,0,new,segs,array,0,partition,overflow,segments,length,partition,overflow,segments,new,segs,array,partition,overflow,segments,partition,num,overflow,segments,overflow,seg,partition,num,overflow,segments,check,for,resize,true,else,overflow,segment,num,partition,num,overflow,segments,1,overflow,seg,partition,overflow,segments,overflow,segment,num,overflow,bucket,offset,partition,next,overflow,bucket,partition,next,overflow,bucket,partition,next,overflow,bucket,this,buckets,per,segment,mask,0,partition,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,original,forward,pointer,final,long,pointer,to,new,bucket,long,overflow,segment,num,32,long,overflow,bucket,offset,original,bucket,put,long,original,bucket,offset,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket, 												int originalBucketOffset, int currentBucketOffset, 												int countInCurrentBucket, long originalForwardPointer, 												int hashCode, long pointer, int partitionNumber) throws IOException;1441738685;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket,_												int originalBucketOffset, int currentBucketOffset,_												int countInCurrentBucket, long originalForwardPointer,_												int hashCode, long pointer, int partitionNumber) throws IOException {_		boolean checkForResize = false__		if (countInCurrentBucket < NUM_ENTRIES_PER_BUCKET) {_			_			currentBucket.putInt(currentBucketOffset + BUCKET_HEADER_LENGTH + (countInCurrentBucket * HASH_CODE_LEN), hashCode)_ _			currentBucket.putLong(currentBucketOffset + BUCKET_POINTER_START_OFFSET + (countInCurrentBucket * POINTER_LEN), pointer)_ _			currentBucket.putInt(currentBucketOffset + HEADER_COUNT_OFFSET, countInCurrentBucket + 1)_ _		}_		else {_			_			final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__			MemorySegment overflowSeg__			final int overflowSegmentNum__			final int overflowBucketOffset__			_			_			if (partition.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowSegmentNum = partition.numOverflowSegments__				_				_				if (partition.overflowSegments.length <= partition.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[partition.overflowSegments.length * 2]__					System.arraycopy(partition.overflowSegments, 0, newSegsArray, 0, partition.overflowSegments.length)__					partition.overflowSegments = newSegsArray__				}_				partition.overflowSegments[partition.numOverflowSegments] = overflowSeg__				partition.numOverflowSegments++__				checkForResize = true__			}_			else {_				_				overflowSegmentNum = partition.numOverflowSegments - 1__				overflowSeg = partition.overflowSegments[overflowSegmentNum]__				overflowBucketOffset = partition.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			partition.nextOverflowBucket = (partition.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : partition.nextOverflowBucket + 1)__			_			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, originalForwardPointer)__			final long pointerToNewBucket = (((long) overflowSegmentNum) << 32) | ((long) overflowBucketOffset)__			originalBucket.putLong(originalBucketOffset + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_	_			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			if(checkForResize && !this.isResizing) {_				_				if(this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,search,memory,segment,original,bucket,memory,segment,current,bucket,int,original,bucket,offset,int,current,bucket,offset,int,count,in,current,bucket,long,original,forward,pointer,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,if,count,in,current,bucket,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,hash,code,current,bucket,put,long,current,bucket,offset,count,in,current,bucket,pointer,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,1,else,final,in,memory,partition,t,partition,this,partitions,get,partition,number,memory,segment,overflow,seg,final,int,overflow,segment,num,final,int,overflow,bucket,offset,if,partition,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,segment,num,partition,num,overflow,segments,if,partition,overflow,segments,length,partition,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,partition,overflow,segments,length,2,system,arraycopy,partition,overflow,segments,0,new,segs,array,0,partition,overflow,segments,length,partition,overflow,segments,new,segs,array,partition,overflow,segments,partition,num,overflow,segments,overflow,seg,partition,num,overflow,segments,check,for,resize,true,else,overflow,segment,num,partition,num,overflow,segments,1,overflow,seg,partition,overflow,segments,overflow,segment,num,overflow,bucket,offset,partition,next,overflow,bucket,partition,next,overflow,bucket,partition,next,overflow,bucket,this,buckets,per,segment,mask,0,partition,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,original,forward,pointer,final,long,pointer,to,new,bucket,long,overflow,segment,num,32,long,overflow,bucket,offset,original,bucket,put,long,original,bucket,offset,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket, 												int originalBucketOffset, int currentBucketOffset, 												int countInCurrentBucket, long originalForwardPointer, 												int hashCode, long pointer, int partitionNumber) throws IOException;1456936114;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket,_												int originalBucketOffset, int currentBucketOffset,_												int countInCurrentBucket, long originalForwardPointer,_												int hashCode, long pointer, int partitionNumber) throws IOException {_		boolean checkForResize = false__		if (countInCurrentBucket < NUM_ENTRIES_PER_BUCKET) {_			_			currentBucket.putInt(currentBucketOffset + BUCKET_HEADER_LENGTH + (countInCurrentBucket * HASH_CODE_LEN), hashCode)_ _			currentBucket.putLong(currentBucketOffset + BUCKET_POINTER_START_OFFSET + (countInCurrentBucket * POINTER_LEN), pointer)_ _			currentBucket.putInt(currentBucketOffset + HEADER_COUNT_OFFSET, countInCurrentBucket + 1)_ _		}_		else {_			_			final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__			MemorySegment overflowSeg__			final int overflowSegmentNum__			final int overflowBucketOffset__			_			_			if (partition.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowSegmentNum = partition.numOverflowSegments__				_				_				if (partition.overflowSegments.length <= partition.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[partition.overflowSegments.length * 2]__					System.arraycopy(partition.overflowSegments, 0, newSegsArray, 0, partition.overflowSegments.length)__					partition.overflowSegments = newSegsArray__				}_				partition.overflowSegments[partition.numOverflowSegments] = overflowSeg__				partition.numOverflowSegments++__				checkForResize = true__			}_			else {_				_				overflowSegmentNum = partition.numOverflowSegments - 1__				overflowSeg = partition.overflowSegments[overflowSegmentNum]__				overflowBucketOffset = partition.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			partition.nextOverflowBucket = (partition.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : partition.nextOverflowBucket + 1)__			_			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, originalForwardPointer)__			final long pointerToNewBucket = (((long) overflowSegmentNum) << 32) | ((long) overflowBucketOffset)__			originalBucket.putLong(originalBucketOffset + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_	_			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			if(checkForResize && !this.isResizing) {_				_				if(this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,search,memory,segment,original,bucket,memory,segment,current,bucket,int,original,bucket,offset,int,current,bucket,offset,int,count,in,current,bucket,long,original,forward,pointer,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,if,count,in,current,bucket,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,hash,code,current,bucket,put,long,current,bucket,offset,count,in,current,bucket,pointer,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,1,else,final,in,memory,partition,t,partition,this,partitions,get,partition,number,memory,segment,overflow,seg,final,int,overflow,segment,num,final,int,overflow,bucket,offset,if,partition,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,segment,num,partition,num,overflow,segments,if,partition,overflow,segments,length,partition,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,partition,overflow,segments,length,2,system,arraycopy,partition,overflow,segments,0,new,segs,array,0,partition,overflow,segments,length,partition,overflow,segments,new,segs,array,partition,overflow,segments,partition,num,overflow,segments,overflow,seg,partition,num,overflow,segments,check,for,resize,true,else,overflow,segment,num,partition,num,overflow,segments,1,overflow,seg,partition,overflow,segments,overflow,segment,num,overflow,bucket,offset,partition,next,overflow,bucket,partition,next,overflow,bucket,partition,next,overflow,bucket,this,buckets,per,segment,mask,0,partition,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,original,forward,pointer,final,long,pointer,to,new,bucket,long,overflow,segment,num,32,long,overflow,bucket,offset,original,bucket,put,long,original,bucket,offset,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket, 												int originalBucketOffset, int currentBucketOffset, 												int countInCurrentBucket, long originalForwardPointer, 												int hashCode, long pointer, int partitionNumber) throws IOException;1460741894;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket,_												int originalBucketOffset, int currentBucketOffset,_												int countInCurrentBucket, long originalForwardPointer,_												int hashCode, long pointer, int partitionNumber) throws IOException {_		boolean checkForResize = false__		if (countInCurrentBucket < NUM_ENTRIES_PER_BUCKET) {_			_			currentBucket.putInt(currentBucketOffset + BUCKET_HEADER_LENGTH + (countInCurrentBucket * HASH_CODE_LEN), hashCode)_ _			currentBucket.putLong(currentBucketOffset + BUCKET_POINTER_START_OFFSET + (countInCurrentBucket * POINTER_LEN), pointer)_ _			currentBucket.putInt(currentBucketOffset + HEADER_COUNT_OFFSET, countInCurrentBucket + 1)_ _		}_		else {_			_			final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__			MemorySegment overflowSeg__			final int overflowSegmentNum__			final int overflowBucketOffset__			_			_			if (partition.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowSegmentNum = partition.numOverflowSegments__				_				_				if (partition.overflowSegments.length <= partition.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[partition.overflowSegments.length * 2]__					System.arraycopy(partition.overflowSegments, 0, newSegsArray, 0, partition.overflowSegments.length)__					partition.overflowSegments = newSegsArray__				}_				partition.overflowSegments[partition.numOverflowSegments] = overflowSeg__				partition.numOverflowSegments++__				checkForResize = true__			}_			else {_				_				overflowSegmentNum = partition.numOverflowSegments - 1__				overflowSeg = partition.overflowSegments[overflowSegmentNum]__				overflowBucketOffset = partition.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			partition.nextOverflowBucket = (partition.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : partition.nextOverflowBucket + 1)__			_			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, originalForwardPointer)__			final long pointerToNewBucket = (((long) overflowSegmentNum) << 32) | ((long) overflowBucketOffset)__			originalBucket.putLong(originalBucketOffset + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_	_			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			if(checkForResize && !this.isResizing) {_				_				if(this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,search,memory,segment,original,bucket,memory,segment,current,bucket,int,original,bucket,offset,int,current,bucket,offset,int,count,in,current,bucket,long,original,forward,pointer,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,if,count,in,current,bucket,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,hash,code,current,bucket,put,long,current,bucket,offset,count,in,current,bucket,pointer,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,1,else,final,in,memory,partition,t,partition,this,partitions,get,partition,number,memory,segment,overflow,seg,final,int,overflow,segment,num,final,int,overflow,bucket,offset,if,partition,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,segment,num,partition,num,overflow,segments,if,partition,overflow,segments,length,partition,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,partition,overflow,segments,length,2,system,arraycopy,partition,overflow,segments,0,new,segs,array,0,partition,overflow,segments,length,partition,overflow,segments,new,segs,array,partition,overflow,segments,partition,num,overflow,segments,overflow,seg,partition,num,overflow,segments,check,for,resize,true,else,overflow,segment,num,partition,num,overflow,segments,1,overflow,seg,partition,overflow,segments,overflow,segment,num,overflow,bucket,offset,partition,next,overflow,bucket,partition,next,overflow,bucket,partition,next,overflow,bucket,this,buckets,per,segment,mask,0,partition,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,original,forward,pointer,final,long,pointer,to,new,bucket,long,overflow,segment,num,32,long,overflow,bucket,offset,original,bucket,put,long,original,bucket,offset,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket, 												int originalBucketOffset, int currentBucketOffset, 												int countInCurrentBucket, long originalForwardPointer, 												int hashCode, long pointer, int partitionNumber) throws IOException;1468441547;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket,_												int originalBucketOffset, int currentBucketOffset,_												int countInCurrentBucket, long originalForwardPointer,_												int hashCode, long pointer, int partitionNumber) throws IOException {_		boolean checkForResize = false__		if (countInCurrentBucket < NUM_ENTRIES_PER_BUCKET) {_			_			currentBucket.putInt(currentBucketOffset + BUCKET_HEADER_LENGTH + (countInCurrentBucket * HASH_CODE_LEN), hashCode)_ _			currentBucket.putLong(currentBucketOffset + BUCKET_POINTER_START_OFFSET + (countInCurrentBucket * POINTER_LEN), pointer)_ _			currentBucket.putInt(currentBucketOffset + HEADER_COUNT_OFFSET, countInCurrentBucket + 1)_ _		}_		else {_			_			final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__			MemorySegment overflowSeg__			final int overflowSegmentNum__			final int overflowBucketOffset__			_			_			if (partition.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowSegmentNum = partition.numOverflowSegments__				_				_				if (partition.overflowSegments.length <= partition.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[partition.overflowSegments.length * 2]__					System.arraycopy(partition.overflowSegments, 0, newSegsArray, 0, partition.overflowSegments.length)__					partition.overflowSegments = newSegsArray__				}_				partition.overflowSegments[partition.numOverflowSegments] = overflowSeg__				partition.numOverflowSegments++__				checkForResize = true__			}_			else {_				_				overflowSegmentNum = partition.numOverflowSegments - 1__				overflowSeg = partition.overflowSegments[overflowSegmentNum]__				overflowBucketOffset = partition.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			partition.nextOverflowBucket = (partition.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : partition.nextOverflowBucket + 1)__			_			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, originalForwardPointer)__			final long pointerToNewBucket = (((long) overflowSegmentNum) << 32) | ((long) overflowBucketOffset)__			originalBucket.putLong(originalBucketOffset + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_	_			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			if(checkForResize && !this.isResizing) {_				_				if(this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,search,memory,segment,original,bucket,memory,segment,current,bucket,int,original,bucket,offset,int,current,bucket,offset,int,count,in,current,bucket,long,original,forward,pointer,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,if,count,in,current,bucket,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,hash,code,current,bucket,put,long,current,bucket,offset,count,in,current,bucket,pointer,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,1,else,final,in,memory,partition,t,partition,this,partitions,get,partition,number,memory,segment,overflow,seg,final,int,overflow,segment,num,final,int,overflow,bucket,offset,if,partition,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,segment,num,partition,num,overflow,segments,if,partition,overflow,segments,length,partition,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,partition,overflow,segments,length,2,system,arraycopy,partition,overflow,segments,0,new,segs,array,0,partition,overflow,segments,length,partition,overflow,segments,new,segs,array,partition,overflow,segments,partition,num,overflow,segments,overflow,seg,partition,num,overflow,segments,check,for,resize,true,else,overflow,segment,num,partition,num,overflow,segments,1,overflow,seg,partition,overflow,segments,overflow,segment,num,overflow,bucket,offset,partition,next,overflow,bucket,partition,next,overflow,bucket,partition,next,overflow,bucket,this,buckets,per,segment,mask,0,partition,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,original,forward,pointer,final,long,pointer,to,new,bucket,long,overflow,segment,num,32,long,overflow,bucket,offset,original,bucket,put,long,original,bucket,offset,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket, 												int originalBucketOffset, int currentBucketOffset, 												int countInCurrentBucket, long originalForwardPointer, 												int hashCode, long pointer, int partitionNumber) throws IOException;1494520945;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromSearch(MemorySegment originalBucket, MemorySegment currentBucket,_												int originalBucketOffset, int currentBucketOffset,_												int countInCurrentBucket, long originalForwardPointer,_												int hashCode, long pointer, int partitionNumber) throws IOException {_		boolean checkForResize = false__		if (countInCurrentBucket < NUM_ENTRIES_PER_BUCKET) {_			_			currentBucket.putInt(currentBucketOffset + BUCKET_HEADER_LENGTH + (countInCurrentBucket * HASH_CODE_LEN), hashCode)_ _			currentBucket.putLong(currentBucketOffset + BUCKET_POINTER_START_OFFSET + (countInCurrentBucket * POINTER_LEN), pointer)_ _			currentBucket.putInt(currentBucketOffset + HEADER_COUNT_OFFSET, countInCurrentBucket + 1)_ _		}_		else {_			_			final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__			MemorySegment overflowSeg__			final int overflowSegmentNum__			final int overflowBucketOffset__			_			_			if (partition.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowSegmentNum = partition.numOverflowSegments__				_				_				if (partition.overflowSegments.length <= partition.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[partition.overflowSegments.length * 2]__					System.arraycopy(partition.overflowSegments, 0, newSegsArray, 0, partition.overflowSegments.length)__					partition.overflowSegments = newSegsArray__				}_				partition.overflowSegments[partition.numOverflowSegments] = overflowSeg__				partition.numOverflowSegments++__				checkForResize = true__			}_			else {_				_				overflowSegmentNum = partition.numOverflowSegments - 1__				overflowSeg = partition.overflowSegments[overflowSegmentNum]__				overflowBucketOffset = partition.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			partition.nextOverflowBucket = (partition.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : partition.nextOverflowBucket + 1)__			_			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, originalForwardPointer)__			final long pointerToNewBucket = (((long) overflowSegmentNum) << 32) | ((long) overflowBucketOffset)__			originalBucket.putLong(originalBucketOffset + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_	_			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			if(checkForResize && !this.isResizing) {_				_				if(this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,search,memory,segment,original,bucket,memory,segment,current,bucket,int,original,bucket,offset,int,current,bucket,offset,int,count,in,current,bucket,long,original,forward,pointer,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,if,count,in,current,bucket,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,hash,code,current,bucket,put,long,current,bucket,offset,count,in,current,bucket,pointer,current,bucket,put,int,current,bucket,offset,count,in,current,bucket,1,else,final,in,memory,partition,t,partition,this,partitions,get,partition,number,memory,segment,overflow,seg,final,int,overflow,segment,num,final,int,overflow,bucket,offset,if,partition,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,segment,num,partition,num,overflow,segments,if,partition,overflow,segments,length,partition,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,partition,overflow,segments,length,2,system,arraycopy,partition,overflow,segments,0,new,segs,array,0,partition,overflow,segments,length,partition,overflow,segments,new,segs,array,partition,overflow,segments,partition,num,overflow,segments,overflow,seg,partition,num,overflow,segments,check,for,resize,true,else,overflow,segment,num,partition,num,overflow,segments,1,overflow,seg,partition,overflow,segments,overflow,segment,num,overflow,bucket,offset,partition,next,overflow,bucket,partition,next,overflow,bucket,partition,next,overflow,bucket,this,buckets,per,segment,mask,0,partition,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,original,forward,pointer,final,long,pointer,to,new,bucket,long,overflow,segment,num,32,long,overflow,bucket,offset,original,bucket,put,long,original,bucket,offset,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> public void insertOrReplaceRecord(T record, T tempHolder) throws IOException;1405024514;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@param tempHolder instance of T that will be overwritten_@throws IOException;public void insertOrReplaceRecord(T record, T tempHolder) throws IOException {_		if(this.closed.get()) {_			return__		}_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					try {_						partition.readRecordAt(pointer, tempHolder)__						if (this.buildSideComparator.equalToReference(tempHolder)) {_							long newPointer = partition.appendRecord(record)__							bucket.putLong(pointerOffset, newPointer)__							partition.setCompaction(false)__							if((newPointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_								this.compactionMemory.allocateSegments((int)(newPointer >> this.pageSizeInBits))__							}_							return__						}_					} catch (EOFException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							newPointer = this.partitions.get(partitionNumber).appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. numPartitions: " + this.partitions.size() + _									" minPartition: " + getMinPartition() +_									" maxPartition: " + getMaxPartition() +_									" number of overflow segments: " + getOverflowSegmentCount() +_									" bucketSize: " + this.buckets.length +_									" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. numPartitions: " + this.partitions.size() + _									" minPartition: " + getMinPartition() +_									" maxPartition: " + getMaxPartition() +_									" number of overflow segments: " + getOverflowSegmentCount() +_									" bucketSize: " + this.buckets.length +_									" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IndexOutOfBoundsException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							newPointer = this.partitions.get(partitionNumber).appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. numPartitions: " + this.partitions.size() + _									" minPartition: " + getMinPartition() +_									" maxPartition: " + getMaxPartition() +_									" number of overflow segments: " + getOverflowSegmentCount() +_									" bucketSize: " + this.buckets.length +_									" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. numPartitions: " + this.partitions.size() + _									" minPartition: " + getMinPartition() +_									" maxPartition: " + getMaxPartition() +_									" number of overflow segments: " + getOverflowSegmentCount() +_									" bucketSize: " + this.buckets.length +_									" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IOException e) {_						throw new RuntimeException("Error deserializing record from the hashtable: " + e.getMessage(), e)__					} _				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				long pointer = partition.appendRecord(record)__				insertBucketEntryFromSearch(partition, originalBucket, bucket, originalBucketOffset, bucketInSegmentOffset, countInSegment, currentForwardPointer, searchHashCode, pointer)__				if((pointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_					this.compactionMemory.allocateSegments((int)(pointer >> this.pageSizeInBits))__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) (newForwardPointer & 0xffffffff)__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,param,temp,holder,instance,of,t,that,will,be,overwritten,throws,ioexception;public,void,insert,or,replace,record,t,record,t,temp,holder,throws,ioexception,if,this,closed,get,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,final,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,try,partition,read,record,at,pointer,temp,holder,if,this,build,side,comparator,equal,to,reference,temp,holder,long,new,pointer,partition,append,record,record,bucket,put,long,pointer,offset,new,pointer,partition,set,compaction,false,if,new,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,new,pointer,this,page,size,in,bits,return,catch,eofexception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,new,pointer,this,partitions,get,partition,number,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,index,out,of,bounds,exception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,new,pointer,this,partitions,get,partition,number,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hashtable,e,get,message,e,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,partition,append,record,record,insert,bucket,entry,from,search,partition,original,bucket,bucket,original,bucket,offset,bucket,in,segment,offset,count,in,segment,current,forward,pointer,search,hash,code,pointer,if,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,pointer,this,page,size,in,bits,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public void insertOrReplaceRecord(T record, T tempHolder) throws IOException;1405090423;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@param tempHolder instance of T that will be overwritten_@throws IOException;public void insertOrReplaceRecord(T record, T tempHolder) throws IOException {_		if(this.closed.get()) {_			return__		}_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		final InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					try {_						partition.readRecordAt(pointer, tempHolder)__						if (this.buildSideComparator.equalToReference(tempHolder)) {_							long newPointer = partition.appendRecord(record)__							bucket.putLong(pointerOffset, newPointer)__							partition.setCompaction(false)__							if((newPointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_								this.compactionMemory.allocateSegments((int)(newPointer >> this.pageSizeInBits))__							}_							return__						}_					} catch (EOFException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							newPointer = this.partitions.get(partitionNumber).appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. numPartitions: " + this.partitions.size() + _									" minPartition: " + getMinPartition() +_									" maxPartition: " + getMaxPartition() +_									" number of overflow segments: " + getOverflowSegmentCount() +_									" bucketSize: " + this.buckets.length +_									" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. numPartitions: " + this.partitions.size() + _									" minPartition: " + getMinPartition() +_									" maxPartition: " + getMaxPartition() +_									" number of overflow segments: " + getOverflowSegmentCount() +_									" bucketSize: " + this.buckets.length +_									" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IndexOutOfBoundsException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							newPointer = this.partitions.get(partitionNumber).appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. numPartitions: " + this.partitions.size() + _									" minPartition: " + getMinPartition() +_									" maxPartition: " + getMaxPartition() +_									" number of overflow segments: " + getOverflowSegmentCount() +_									" bucketSize: " + this.buckets.length +_									" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. numPartitions: " + this.partitions.size() + _									" minPartition: " + getMinPartition() +_									" maxPartition: " + getMaxPartition() +_									" number of overflow segments: " + getOverflowSegmentCount() +_									" bucketSize: " + this.buckets.length +_									" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IOException e) {_						throw new RuntimeException("Error deserializing record from the hashtable: " + e.getMessage(), e)__					} _				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				long pointer = partition.appendRecord(record)__				insertBucketEntryFromSearch(partition, originalBucket, bucket, originalBucketOffset, bucketInSegmentOffset, countInSegment, currentForwardPointer, searchHashCode, pointer)__				if((pointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_					this.compactionMemory.allocateSegments((int)(pointer >> this.pageSizeInBits))__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) (newForwardPointer & 0xffffffff)__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,param,temp,holder,instance,of,t,that,will,be,overwritten,throws,ioexception;public,void,insert,or,replace,record,t,record,t,temp,holder,throws,ioexception,if,this,closed,get,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,final,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,try,partition,read,record,at,pointer,temp,holder,if,this,build,side,comparator,equal,to,reference,temp,holder,long,new,pointer,partition,append,record,record,bucket,put,long,pointer,offset,new,pointer,partition,set,compaction,false,if,new,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,new,pointer,this,page,size,in,bits,return,catch,eofexception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,new,pointer,this,partitions,get,partition,number,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,index,out,of,bounds,exception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,new,pointer,this,partitions,get,partition,number,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,num,partitions,this,partitions,size,min,partition,get,min,partition,max,partition,get,max,partition,number,of,overflow,segments,get,overflow,segment,count,bucket,size,this,buckets,length,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hashtable,e,get,message,e,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,partition,append,record,record,insert,bucket,entry,from,search,partition,original,bucket,bucket,original,bucket,offset,bucket,in,segment,offset,count,in,segment,current,forward,pointer,search,hash,code,pointer,if,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,pointer,this,page,size,in,bits,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public void insertOrReplaceRecord(T record, T tempHolder) throws IOException;1405529391;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@param tempHolder instance of T that will be overwritten_@throws IOException;public void insertOrReplaceRecord(T record, T tempHolder) throws IOException {_		if(this.closed.get()) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					try {_						partition.readRecordAt(pointer, tempHolder)__						if (this.buildSideComparator.equalToReference(tempHolder)) {_							long newPointer = partition.appendRecord(record)__							bucket.putLong(pointerOffset, newPointer)__							partition.setCompaction(false)__							if((newPointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_								this.compactionMemory.allocateSegments((int)(newPointer >> this.pageSizeInBits))__							}_							return__						}_					} catch (EOFException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IndexOutOfBoundsException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IOException e) {_						throw new RuntimeException("Error deserializing record from the hashtable: " + e.getMessage(), e)__					} _				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				long pointer = partition.appendRecord(record)__				_				insertBucketEntryFromSearch(partition, originalBucket, bucket, originalBucketOffset, bucketInSegmentOffset, countInSegment, currentForwardPointer, searchHashCode, pointer)__				if((pointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_					this.compactionMemory.allocateSegments((int)(pointer >> this.pageSizeInBits))__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) (newForwardPointer & 0xffffffff)__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,param,temp,holder,instance,of,t,that,will,be,overwritten,throws,ioexception;public,void,insert,or,replace,record,t,record,t,temp,holder,throws,ioexception,if,this,closed,get,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,try,partition,read,record,at,pointer,temp,holder,if,this,build,side,comparator,equal,to,reference,temp,holder,long,new,pointer,partition,append,record,record,bucket,put,long,pointer,offset,new,pointer,partition,set,compaction,false,if,new,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,new,pointer,this,page,size,in,bits,return,catch,eofexception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,index,out,of,bounds,exception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hashtable,e,get,message,e,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,partition,append,record,record,insert,bucket,entry,from,search,partition,original,bucket,bucket,original,bucket,offset,bucket,in,segment,offset,count,in,segment,current,forward,pointer,search,hash,code,pointer,if,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,pointer,this,page,size,in,bits,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public void insertOrReplaceRecord(T record, T tempHolder) throws IOException;1409845762;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@param tempHolder instance of T that will be overwritten_@throws IOException;public void insertOrReplaceRecord(T record, T tempHolder) throws IOException {_		if(this.closed.get()) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					try {_						tempHolder = partition.readRecordAt(pointer, tempHolder)__						if (this.buildSideComparator.equalToReference(tempHolder)) {_							long newPointer = partition.appendRecord(record)__							bucket.putLong(pointerOffset, newPointer)__							partition.setCompaction(false)__							if((newPointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_								this.compactionMemory.allocateSegments((int)(newPointer >> this.pageSizeInBits))__							}_							return__						}_					} catch (EOFException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IndexOutOfBoundsException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IOException e) {_						throw new RuntimeException("Error deserializing record from the hashtable: " + e.getMessage(), e)__					} _				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				long pointer = partition.appendRecord(record)__				_				insertBucketEntryFromSearch(partition, originalBucket, bucket, originalBucketOffset, bucketInSegmentOffset, countInSegment, currentForwardPointer, searchHashCode, pointer)__				if((pointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_					this.compactionMemory.allocateSegments((int)(pointer >> this.pageSizeInBits))__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) (newForwardPointer & 0xffffffff)__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,param,temp,holder,instance,of,t,that,will,be,overwritten,throws,ioexception;public,void,insert,or,replace,record,t,record,t,temp,holder,throws,ioexception,if,this,closed,get,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,try,temp,holder,partition,read,record,at,pointer,temp,holder,if,this,build,side,comparator,equal,to,reference,temp,holder,long,new,pointer,partition,append,record,record,bucket,put,long,pointer,offset,new,pointer,partition,set,compaction,false,if,new,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,new,pointer,this,page,size,in,bits,return,catch,eofexception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,index,out,of,bounds,exception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hashtable,e,get,message,e,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,partition,append,record,record,insert,bucket,entry,from,search,partition,original,bucket,bucket,original,bucket,offset,bucket,in,segment,offset,count,in,segment,current,forward,pointer,search,hash,code,pointer,if,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,pointer,this,page,size,in,bits,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public void insertOrReplaceRecord(T record, T tempHolder) throws IOException;1409911022;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@param tempHolder instance of T that will be overwritten_@throws IOException;public void insertOrReplaceRecord(T record, T tempHolder) throws IOException {_		if(this.closed.get()) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					try {_						tempHolder = partition.readRecordAt(pointer, tempHolder)__						if (this.buildSideComparator.equalToReference(tempHolder)) {_							long newPointer = partition.appendRecord(record)__							bucket.putLong(pointerOffset, newPointer)__							partition.setCompaction(false)__							if((newPointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_								this.compactionMemory.allocateSegments((int)(newPointer >> this.pageSizeInBits))__							}_							return__						}_					} catch (EOFException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IndexOutOfBoundsException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IOException e) {_						throw new RuntimeException("Error deserializing record from the hashtable: " + e.getMessage(), e)__					} _				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				long pointer = partition.appendRecord(record)__				_				insertBucketEntryFromSearch(partition, originalBucket, bucket, originalBucketOffset, bucketInSegmentOffset, countInSegment, currentForwardPointer, searchHashCode, pointer)__				if((pointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_					this.compactionMemory.allocateSegments((int)(pointer >> this.pageSizeInBits))__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) (newForwardPointer & 0xffffffff)__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,param,temp,holder,instance,of,t,that,will,be,overwritten,throws,ioexception;public,void,insert,or,replace,record,t,record,t,temp,holder,throws,ioexception,if,this,closed,get,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,try,temp,holder,partition,read,record,at,pointer,temp,holder,if,this,build,side,comparator,equal,to,reference,temp,holder,long,new,pointer,partition,append,record,record,bucket,put,long,pointer,offset,new,pointer,partition,set,compaction,false,if,new,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,new,pointer,this,page,size,in,bits,return,catch,eofexception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,index,out,of,bounds,exception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hashtable,e,get,message,e,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,partition,append,record,record,insert,bucket,entry,from,search,partition,original,bucket,bucket,original,bucket,offset,bucket,in,segment,offset,count,in,segment,current,forward,pointer,search,hash,code,pointer,if,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,pointer,this,page,size,in,bits,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public void insertOrReplaceRecord(T record, T tempHolder) throws IOException;1411473593;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@param tempHolder instance of T that will be overwritten_@throws IOException;public void insertOrReplaceRecord(T record, T tempHolder) throws IOException {_		if(this.closed.get()) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					try {_						tempHolder = partition.readRecordAt(pointer, tempHolder)__						if (this.buildSideComparator.equalToReference(tempHolder)) {_							long newPointer = partition.appendRecord(record)__							bucket.putLong(pointerOffset, newPointer)__							partition.setCompaction(false)__							if((newPointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_								this.compactionMemory.allocateSegments((int)(newPointer >> this.pageSizeInBits))__							}_							return__						}_					} catch (EOFException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IndexOutOfBoundsException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IOException e) {_						throw new RuntimeException("Error deserializing record from the hashtable: " + e.getMessage(), e)__					} _				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				long pointer = partition.appendRecord(record)__				_				insertBucketEntryFromSearch(partition, originalBucket, bucket, originalBucketOffset, bucketInSegmentOffset, countInSegment, currentForwardPointer, searchHashCode, pointer)__				if((pointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_					this.compactionMemory.allocateSegments((int)(pointer >> this.pageSizeInBits))__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) (newForwardPointer & 0xffffffff)__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,param,temp,holder,instance,of,t,that,will,be,overwritten,throws,ioexception;public,void,insert,or,replace,record,t,record,t,temp,holder,throws,ioexception,if,this,closed,get,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,try,temp,holder,partition,read,record,at,pointer,temp,holder,if,this,build,side,comparator,equal,to,reference,temp,holder,long,new,pointer,partition,append,record,record,bucket,put,long,pointer,offset,new,pointer,partition,set,compaction,false,if,new,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,new,pointer,this,page,size,in,bits,return,catch,eofexception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,index,out,of,bounds,exception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hashtable,e,get,message,e,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,partition,append,record,record,insert,bucket,entry,from,search,partition,original,bucket,bucket,original,bucket,offset,bucket,in,segment,offset,count,in,segment,current,forward,pointer,search,hash,code,pointer,if,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,pointer,this,page,size,in,bits,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public void insertOrReplaceRecord(T record, T tempHolder) throws IOException;1414786554;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@param tempHolder instance of T that will be overwritten_@throws IOException;public void insertOrReplaceRecord(T record, T tempHolder) throws IOException {_		if(this.closed.get()) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					try {_						tempHolder = partition.readRecordAt(pointer, tempHolder)__						if (this.buildSideComparator.equalToReference(tempHolder)) {_							long newPointer = partition.appendRecord(record)__							bucket.putLong(pointerOffset, newPointer)__							partition.setCompaction(false)__							if((newPointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_								this.compactionMemory.allocateSegments((int)(newPointer >> this.pageSizeInBits))__							}_							return__						}_					} catch (EOFException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IndexOutOfBoundsException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IOException e) {_						throw new RuntimeException("Error deserializing record from the hashtable: " + e.getMessage(), e)__					} _				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				long pointer = partition.appendRecord(record)__				_				insertBucketEntryFromSearch(partition, originalBucket, bucket, originalBucketOffset, bucketInSegmentOffset, countInSegment, currentForwardPointer, searchHashCode, pointer)__				if((pointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_					this.compactionMemory.allocateSegments((int)(pointer >> this.pageSizeInBits))__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) (newForwardPointer & 0xffffffff)__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,param,temp,holder,instance,of,t,that,will,be,overwritten,throws,ioexception;public,void,insert,or,replace,record,t,record,t,temp,holder,throws,ioexception,if,this,closed,get,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,try,temp,holder,partition,read,record,at,pointer,temp,holder,if,this,build,side,comparator,equal,to,reference,temp,holder,long,new,pointer,partition,append,record,record,bucket,put,long,pointer,offset,new,pointer,partition,set,compaction,false,if,new,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,new,pointer,this,page,size,in,bits,return,catch,eofexception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,index,out,of,bounds,exception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hashtable,e,get,message,e,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,partition,append,record,record,insert,bucket,entry,from,search,partition,original,bucket,bucket,original,bucket,offset,bucket,in,segment,offset,count,in,segment,current,forward,pointer,search,hash,code,pointer,if,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,pointer,this,page,size,in,bits,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public void insertOrReplaceRecord(T record, T tempHolder) throws IOException;1420654570;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@param tempHolder instance of T that will be overwritten_@throws IOException;public void insertOrReplaceRecord(T record, T tempHolder) throws IOException {_		if(this.closed.get()) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					try {_						tempHolder = partition.readRecordAt(pointer, tempHolder)__						if (this.buildSideComparator.equalToReference(tempHolder)) {_							long newPointer = partition.appendRecord(record)__							bucket.putLong(pointerOffset, newPointer)__							partition.setCompaction(false)__							if((newPointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_								this.compactionMemory.allocateSegments((int)(newPointer >> this.pageSizeInBits))__							}_							return__						}_					} catch (EOFException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IndexOutOfBoundsException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IOException e) {_						throw new RuntimeException("Error deserializing record from the hashtable: " + e.getMessage(), e)__					} _				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				long pointer = partition.appendRecord(record)__				_				insertBucketEntryFromSearch(partition, originalBucket, bucket, originalBucketOffset, bucketInSegmentOffset, countInSegment, currentForwardPointer, searchHashCode, pointer)__				if((pointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_					this.compactionMemory.allocateSegments((int)(pointer >> this.pageSizeInBits))__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) (newForwardPointer & 0xffffffff)__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,param,temp,holder,instance,of,t,that,will,be,overwritten,throws,ioexception;public,void,insert,or,replace,record,t,record,t,temp,holder,throws,ioexception,if,this,closed,get,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,try,temp,holder,partition,read,record,at,pointer,temp,holder,if,this,build,side,comparator,equal,to,reference,temp,holder,long,new,pointer,partition,append,record,record,bucket,put,long,pointer,offset,new,pointer,partition,set,compaction,false,if,new,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,new,pointer,this,page,size,in,bits,return,catch,eofexception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,index,out,of,bounds,exception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hashtable,e,get,message,e,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,partition,append,record,record,insert,bucket,entry,from,search,partition,original,bucket,bucket,original,bucket,offset,bucket,in,segment,offset,count,in,segment,current,forward,pointer,search,hash,code,pointer,if,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,pointer,this,page,size,in,bits,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public void insertOrReplaceRecord(T record, T tempHolder) throws IOException;1420654570;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@param tempHolder instance of T that will be overwritten_@throws IOException;public void insertOrReplaceRecord(T record, T tempHolder) throws IOException {_		if(this.closed.get()) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					try {_						tempHolder = partition.readRecordAt(pointer, tempHolder)__						if (this.buildSideComparator.equalToReference(tempHolder)) {_							long newPointer = partition.appendRecord(record)__							bucket.putLong(pointerOffset, newPointer)__							partition.setCompaction(false)__							if((newPointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_								this.compactionMemory.allocateSegments((int)(newPointer >> this.pageSizeInBits))__							}_							return__						}_					} catch (EOFException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IndexOutOfBoundsException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IOException e) {_						throw new RuntimeException("Error deserializing record from the hashtable: " + e.getMessage(), e)__					} _				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				long pointer = partition.appendRecord(record)__				_				insertBucketEntryFromSearch(partition, originalBucket, bucket, originalBucketOffset, bucketInSegmentOffset, countInSegment, currentForwardPointer, searchHashCode, pointer)__				if((pointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_					this.compactionMemory.allocateSegments((int)(pointer >> this.pageSizeInBits))__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) (newForwardPointer & 0xffffffff)__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,param,temp,holder,instance,of,t,that,will,be,overwritten,throws,ioexception;public,void,insert,or,replace,record,t,record,t,temp,holder,throws,ioexception,if,this,closed,get,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,try,temp,holder,partition,read,record,at,pointer,temp,holder,if,this,build,side,comparator,equal,to,reference,temp,holder,long,new,pointer,partition,append,record,record,bucket,put,long,pointer,offset,new,pointer,partition,set,compaction,false,if,new,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,new,pointer,this,page,size,in,bits,return,catch,eofexception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,index,out,of,bounds,exception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hashtable,e,get,message,e,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,partition,append,record,record,insert,bucket,entry,from,search,partition,original,bucket,bucket,original,bucket,offset,bucket,in,segment,offset,count,in,segment,current,forward,pointer,search,hash,code,pointer,if,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,pointer,this,page,size,in,bits,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public void insertOrReplaceRecord(T record, T tempHolder) throws IOException;1420663430;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@param tempHolder instance of T that will be overwritten_@throws IOException;public void insertOrReplaceRecord(T record, T tempHolder) throws IOException {_		if(this.closed.get()) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					try {_						tempHolder = partition.readRecordAt(pointer, tempHolder)__						if (this.buildSideComparator.equalToReference(tempHolder)) {_							long newPointer = partition.appendRecord(record)__							bucket.putLong(pointerOffset, newPointer)__							partition.setCompaction(false)__							if((newPointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_								this.compactionMemory.allocateSegments((int)(newPointer >> this.pageSizeInBits))__							}_							return__						}_					} catch (EOFException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IndexOutOfBoundsException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IOException e) {_						throw new RuntimeException("Error deserializing record from the hashtable: " + e.getMessage(), e)__					} _				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				long pointer = partition.appendRecord(record)__				_				insertBucketEntryFromSearch(partition, originalBucket, bucket, originalBucketOffset, bucketInSegmentOffset, countInSegment, currentForwardPointer, searchHashCode, pointer)__				if((pointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_					this.compactionMemory.allocateSegments((int)(pointer >> this.pageSizeInBits))__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) (newForwardPointer & 0xffffffff)__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,param,temp,holder,instance,of,t,that,will,be,overwritten,throws,ioexception;public,void,insert,or,replace,record,t,record,t,temp,holder,throws,ioexception,if,this,closed,get,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,try,temp,holder,partition,read,record,at,pointer,temp,holder,if,this,build,side,comparator,equal,to,reference,temp,holder,long,new,pointer,partition,append,record,record,bucket,put,long,pointer,offset,new,pointer,partition,set,compaction,false,if,new,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,new,pointer,this,page,size,in,bits,return,catch,eofexception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,index,out,of,bounds,exception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hashtable,e,get,message,e,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,partition,append,record,record,insert,bucket,entry,from,search,partition,original,bucket,bucket,original,bucket,offset,bucket,in,segment,offset,count,in,segment,current,forward,pointer,search,hash,code,pointer,if,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,pointer,this,page,size,in,bits,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public void insertOrReplaceRecord(T record, T tempHolder) throws IOException;1421838095;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@param tempHolder instance of T that will be overwritten_@throws IOException;public void insertOrReplaceRecord(T record, T tempHolder) throws IOException {_		if(this.closed.get()) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					try {_						tempHolder = partition.readRecordAt(pointer, tempHolder)__						if (this.buildSideComparator.equalToReference(tempHolder)) {_							long newPointer = partition.appendRecord(record)__							bucket.putLong(pointerOffset, newPointer)__							partition.setCompaction(false)__							if((newPointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_								this.compactionMemory.allocateSegments((int)(newPointer >> this.pageSizeInBits))__							}_							return__						}_					} catch (EOFException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IndexOutOfBoundsException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IOException e) {_						throw new RuntimeException("Error deserializing record from the hashtable: " + e.getMessage(), e)__					} _				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				long pointer = partition.appendRecord(record)__				_				insertBucketEntryFromSearch(partition, originalBucket, bucket, originalBucketOffset, bucketInSegmentOffset, countInSegment, currentForwardPointer, searchHashCode, pointer)__				if((pointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_					this.compactionMemory.allocateSegments((int)(pointer >> this.pageSizeInBits))__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) (newForwardPointer & 0xffffffff)__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,param,temp,holder,instance,of,t,that,will,be,overwritten,throws,ioexception;public,void,insert,or,replace,record,t,record,t,temp,holder,throws,ioexception,if,this,closed,get,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,try,temp,holder,partition,read,record,at,pointer,temp,holder,if,this,build,side,comparator,equal,to,reference,temp,holder,long,new,pointer,partition,append,record,record,bucket,put,long,pointer,offset,new,pointer,partition,set,compaction,false,if,new,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,new,pointer,this,page,size,in,bits,return,catch,eofexception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,index,out,of,bounds,exception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hashtable,e,get,message,e,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,partition,append,record,record,insert,bucket,entry,from,search,partition,original,bucket,bucket,original,bucket,offset,bucket,in,segment,offset,count,in,segment,current,forward,pointer,search,hash,code,pointer,if,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,pointer,this,page,size,in,bits,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public void insertOrReplaceRecord(T record, T tempHolder) throws IOException;1427646862;Replaces record in hash table if record already present or append record if not._May trigger expensive compaction.__@param record record to insert or replace_@param tempHolder instance of T that will be overwritten_@throws IOException;public void insertOrReplaceRecord(T record, T tempHolder) throws IOException {_		if(this.closed.get()) {_			return__		}_		_		final int searchHashCode = hash(this.buildSideComparator.hash(record))__		final int posHashCode = searchHashCode % this.numBuckets__		_		_		MemorySegment originalBucket = this.buckets[posHashCode >> this.bucketsPerSegmentBits]__		int originalBucketOffset = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__		MemorySegment bucket = originalBucket__		int bucketInSegmentOffset = originalBucketOffset__		_		_		final int partitionNumber = bucket.get(bucketInSegmentOffset + HEADER_PARTITION_OFFSET)__		InMemoryPartition<T> partition = this.partitions.get(partitionNumber)__		final MemorySegment[] overflowSegments = partition.overflowSegments__		_		this.buildSideComparator.setReference(record)__		_		int countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__		int numInSegment = 0__		int posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__		_		long currentForwardPointer = BUCKET_FORWARD_POINTER_NOT_SET___		_		while (true) {_			_			while (numInSegment < countInSegment) {_				_				final int thisCode = bucket.getInt(posInSegment)__				posInSegment += HASH_CODE_LEN__					_				_				if (thisCode == searchHashCode) {_					_					final int pointerOffset = bucketInSegmentOffset + BUCKET_POINTER_START_OFFSET + (numInSegment * POINTER_LEN)__					final long pointer = bucket.getLong(pointerOffset)__					numInSegment++__					_					_					try {_						tempHolder = partition.readRecordAt(pointer, tempHolder)__						if (this.buildSideComparator.equalToReference(tempHolder)) {_							long newPointer = partition.appendRecord(record)__							bucket.putLong(pointerOffset, newPointer)__							partition.setCompaction(false)__							if((newPointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_								this.compactionMemory.allocateSegments((int)(newPointer >> this.pageSizeInBits))__							}_							return__						}_					} catch (EOFException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IndexOutOfBoundsException e) {_						_						long newPointer__						try {_							compactPartition(partition.getPartitionNumber())__							_							partition = this.partitions.get(partitionNumber)_ _							newPointer = partition.appendRecord(record)__						} catch (EOFException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						} catch (IndexOutOfBoundsException ex) {_							throw new RuntimeException("Memory ran out. Compaction failed. " + _														getMemoryConsumptionString() +_														" Message: " + ex.getMessage())__						}_						bucket.putLong(pointerOffset, newPointer)__						return__					} catch (IOException e) {_						throw new RuntimeException("Error deserializing record from the hashtable: " + e.getMessage(), e)__					} _				}_				else {_					numInSegment++__				}_			}_			_			_			long newForwardPointer = bucket.getLong(bucketInSegmentOffset + HEADER_FORWARD_OFFSET)__			if (newForwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_				_				long pointer = partition.appendRecord(record)__				_				insertBucketEntryFromSearch(partition, originalBucket, bucket, originalBucketOffset, bucketInSegmentOffset, countInSegment, currentForwardPointer, searchHashCode, pointer)__				if((pointer >> this.pageSizeInBits) > this.compactionMemory.getBlockCount()) {_					this.compactionMemory.allocateSegments((int)(pointer >> this.pageSizeInBits))__				}_				return__			}_			_			final int overflowSegNum = (int) (newForwardPointer >>> 32)__			bucket = overflowSegments[overflowSegNum]__			bucketInSegmentOffset = (int) (newForwardPointer & 0xffffffff)__			countInSegment = bucket.getInt(bucketInSegmentOffset + HEADER_COUNT_OFFSET)__			posInSegment = bucketInSegmentOffset + BUCKET_HEADER_LENGTH__			numInSegment = 0__			currentForwardPointer = newForwardPointer__		}_	};replaces,record,in,hash,table,if,record,already,present,or,append,record,if,not,may,trigger,expensive,compaction,param,record,record,to,insert,or,replace,param,temp,holder,instance,of,t,that,will,be,overwritten,throws,ioexception;public,void,insert,or,replace,record,t,record,t,temp,holder,throws,ioexception,if,this,closed,get,return,final,int,search,hash,code,hash,this,build,side,comparator,hash,record,final,int,pos,hash,code,search,hash,code,this,num,buckets,memory,segment,original,bucket,this,buckets,pos,hash,code,this,buckets,per,segment,bits,int,original,bucket,offset,pos,hash,code,this,buckets,per,segment,mask,memory,segment,bucket,original,bucket,int,bucket,in,segment,offset,original,bucket,offset,final,int,partition,number,bucket,get,bucket,in,segment,offset,in,memory,partition,t,partition,this,partitions,get,partition,number,final,memory,segment,overflow,segments,partition,overflow,segments,this,build,side,comparator,set,reference,record,int,count,in,segment,bucket,get,int,bucket,in,segment,offset,int,num,in,segment,0,int,pos,in,segment,bucket,in,segment,offset,long,current,forward,pointer,while,true,while,num,in,segment,count,in,segment,final,int,this,code,bucket,get,int,pos,in,segment,pos,in,segment,if,this,code,search,hash,code,final,int,pointer,offset,bucket,in,segment,offset,num,in,segment,final,long,pointer,bucket,get,long,pointer,offset,num,in,segment,try,temp,holder,partition,read,record,at,pointer,temp,holder,if,this,build,side,comparator,equal,to,reference,temp,holder,long,new,pointer,partition,append,record,record,bucket,put,long,pointer,offset,new,pointer,partition,set,compaction,false,if,new,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,new,pointer,this,page,size,in,bits,return,catch,eofexception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,index,out,of,bounds,exception,e,long,new,pointer,try,compact,partition,partition,get,partition,number,partition,this,partitions,get,partition,number,new,pointer,partition,append,record,record,catch,eofexception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,catch,index,out,of,bounds,exception,ex,throw,new,runtime,exception,memory,ran,out,compaction,failed,get,memory,consumption,string,message,ex,get,message,bucket,put,long,pointer,offset,new,pointer,return,catch,ioexception,e,throw,new,runtime,exception,error,deserializing,record,from,the,hashtable,e,get,message,e,else,num,in,segment,long,new,forward,pointer,bucket,get,long,bucket,in,segment,offset,if,new,forward,pointer,long,pointer,partition,append,record,record,insert,bucket,entry,from,search,partition,original,bucket,bucket,original,bucket,offset,bucket,in,segment,offset,count,in,segment,current,forward,pointer,search,hash,code,pointer,if,pointer,this,page,size,in,bits,this,compaction,memory,get,block,count,this,compaction,memory,allocate,segments,int,pointer,this,page,size,in,bits,return,final,int,overflow,seg,num,int,new,forward,pointer,32,bucket,overflow,segments,overflow,seg,num,bucket,in,segment,offset,int,new,forward,pointer,0xffffffff,count,in,segment,bucket,get,int,bucket,in,segment,offset,pos,in,segment,bucket,in,segment,offset,num,in,segment,0,current,forward,pointer,new,forward,pointer
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1405024514;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1405090423;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1405529391;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1409845762;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1409911022;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1411473593;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1414786554;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1420654570;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1420654570;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1420663430;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1421838095;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1427646862;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1438803435;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1439805579;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1441738685;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1456936114;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1460741894;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1468441547;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> public MutableObjectIterator<T> getEntryIterator();1494520945;@return Iterator over hash table_@see EntryIterator;public MutableObjectIterator<T> getEntryIterator() {_		return new EntryIterator(this)__	};return,iterator,over,hash,table,see,entry,iterator;public,mutable,object,iterator,t,get,entry,iterator,return,new,entry,iterator,this
CompactingHashTable -> private static final int hash(int code);1405024514;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static final int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,final,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static final int hash(int code);1405090423;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static final int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,final,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static final int hash(int code);1405529391;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static final int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,final,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static final int hash(int code);1409845762;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static final int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,final,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static final int hash(int code);1409911022;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static final int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,final,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static final int hash(int code);1411473593;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static final int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,final,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static final int hash(int code);1414786554;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static final int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,final,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static final int hash(int code);1420654570;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static final int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,final,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static final int hash(int code);1420654570;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static final int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,final,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static final int hash(int code);1420663430;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static final int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,final,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static final int hash(int code);1421838095;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static final int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,final,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> private static final int hash(int code);1427646862;This function hashes an integer value. It is adapted from Bob Jenkins' website_<a href="http://www.burtleburtle.net/bob/hash/integer.html">http://www.burtleburtle.net/bob/hash/integer.html</a>._The hash function has the <i>full avalanche</i> property, meaning that every bit of the value to be hashed_affects every bit of the hash value.__@param code The integer to be hashed._@return The hash code for the integer.;private static final int hash(int code) {_		code = (code + 0x7ed55d16) + (code << 12)__		code = (code ^ 0xc761c23c) ^ (code >>> 19)__		code = (code + 0x165667b1) + (code << 5)__		code = (code + 0xd3a2646c) ^ (code << 9)__		code = (code + 0xfd7046c5) + (code << 3)__		code = (code ^ 0xb55a4f09) ^ (code >>> 16)__		return code >= 0 ? code : -(code + 1)__	};this,function,hashes,an,integer,value,it,is,adapted,from,bob,jenkins,website,a,href,http,www,burtleburtle,net,bob,hash,integer,html,http,www,burtleburtle,net,bob,hash,integer,html,a,the,hash,function,has,the,i,full,avalanche,i,property,meaning,that,every,bit,of,the,value,to,be,hashed,affects,every,bit,of,the,hash,value,param,code,the,integer,to,be,hashed,return,the,hash,code,for,the,integer;private,static,final,int,hash,int,code,code,code,0x7ed55d16,code,12,code,code,0xc761c23c,code,19,code,code,0x165667b1,code,5,code,code,0xd3a2646c,code,9,code,code,0xfd7046c5,code,3,code,code,0xb55a4f09,code,16,return,code,0,code,code,1
CompactingHashTable -> public void open();1405024514;Build the hash table__@throws IOException Thrown, if an I/O problem occurs while spilling a partition.;public void open() {_		_		if (!this.closed.compareAndSet(true, false)) {_			throw new IllegalStateException("Hash Table cannot be opened, because it is currently not closed.")__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};build,the,hash,table,throws,ioexception,thrown,if,an,i,o,problem,occurs,while,spilling,a,partition;public,void,open,if,this,closed,compare,and,set,true,false,throw,new,illegal,state,exception,hash,table,cannot,be,opened,because,it,is,currently,not,closed,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> public void open();1405090423;Build the hash table__@throws IOException Thrown, if an I/O problem occurs while spilling a partition.;public void open() {_		_		if (!this.closed.compareAndSet(true, false)) {_			throw new IllegalStateException("Hash Table cannot be opened, because it is currently not closed.")__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};build,the,hash,table,throws,ioexception,thrown,if,an,i,o,problem,occurs,while,spilling,a,partition;public,void,open,if,this,closed,compare,and,set,true,false,throw,new,illegal,state,exception,hash,table,cannot,be,opened,because,it,is,currently,not,closed,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> public void open();1405529391;Build the hash table;public void open() {_		_		if (!this.closed.compareAndSet(true, false)) {_			throw new IllegalStateException("Hash Table cannot be opened, because it is currently not closed.")__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};build,the,hash,table;public,void,open,if,this,closed,compare,and,set,true,false,throw,new,illegal,state,exception,hash,table,cannot,be,opened,because,it,is,currently,not,closed,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> public void open();1409845762;Build the hash table;public void open() {_		_		if (!this.closed.compareAndSet(true, false)) {_			throw new IllegalStateException("Hash Table cannot be opened, because it is currently not closed.")__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};build,the,hash,table;public,void,open,if,this,closed,compare,and,set,true,false,throw,new,illegal,state,exception,hash,table,cannot,be,opened,because,it,is,currently,not,closed,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> public void open();1409911022;Build the hash table;public void open() {_		_		if (!this.closed.compareAndSet(true, false)) {_			throw new IllegalStateException("Hash Table cannot be opened, because it is currently not closed.")__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};build,the,hash,table;public,void,open,if,this,closed,compare,and,set,true,false,throw,new,illegal,state,exception,hash,table,cannot,be,opened,because,it,is,currently,not,closed,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> public void open();1411473593;Build the hash table;public void open() {_		_		if (!this.closed.compareAndSet(true, false)) {_			throw new IllegalStateException("Hash Table cannot be opened, because it is currently not closed.")__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};build,the,hash,table;public,void,open,if,this,closed,compare,and,set,true,false,throw,new,illegal,state,exception,hash,table,cannot,be,opened,because,it,is,currently,not,closed,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> public void open();1414786554;Build the hash table;public void open() {_		_		if (!this.closed.compareAndSet(true, false)) {_			throw new IllegalStateException("Hash Table cannot be opened, because it is currently not closed.")__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};build,the,hash,table;public,void,open,if,this,closed,compare,and,set,true,false,throw,new,illegal,state,exception,hash,table,cannot,be,opened,because,it,is,currently,not,closed,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> public void open();1420654570;Build the hash table;public void open() {_		_		if (!this.closed.compareAndSet(true, false)) {_			throw new IllegalStateException("Hash Table cannot be opened, because it is currently not closed.")__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};build,the,hash,table;public,void,open,if,this,closed,compare,and,set,true,false,throw,new,illegal,state,exception,hash,table,cannot,be,opened,because,it,is,currently,not,closed,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> public void open();1420654570;Build the hash table;public void open() {_		_		if (!this.closed.compareAndSet(true, false)) {_			throw new IllegalStateException("Hash Table cannot be opened, because it is currently not closed.")__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};build,the,hash,table;public,void,open,if,this,closed,compare,and,set,true,false,throw,new,illegal,state,exception,hash,table,cannot,be,opened,because,it,is,currently,not,closed,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> public void open();1420663430;Build the hash table;public void open() {_		_		if (!this.closed.compareAndSet(true, false)) {_			throw new IllegalStateException("Hash Table cannot be opened, because it is currently not closed.")__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};build,the,hash,table;public,void,open,if,this,closed,compare,and,set,true,false,throw,new,illegal,state,exception,hash,table,cannot,be,opened,because,it,is,currently,not,closed,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> public void open();1421838095;Build the hash table;public void open() {_		_		if (!this.closed.compareAndSet(true, false)) {_			throw new IllegalStateException("Hash Table cannot be opened, because it is currently not closed.")__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};build,the,hash,table;public,void,open,if,this,closed,compare,and,set,true,false,throw,new,illegal,state,exception,hash,table,cannot,be,opened,because,it,is,currently,not,closed,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> public void open();1427646862;Build the hash table;public void open() {_		_		if (!this.closed.compareAndSet(true, false)) {_			throw new IllegalStateException("Hash Table cannot be opened, because it is currently not closed.")__		}_		_		_		final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size())_ _		createPartitions(partitionFanOut)__		_		_		final int numBuckets = getInitialTableSize(this.availableMemory.size(), this.segmentSize, _			partitionFanOut, this.avgRecordLen)__		_		initTable(numBuckets, (byte) partitionFanOut)__	};build,the,hash,table;public,void,open,if,this,closed,compare,and,set,true,false,throw,new,illegal,state,exception,hash,table,cannot,be,opened,because,it,is,currently,not,closed,final,int,partition,fan,out,get,partitioning,fan,out,no,estimates,this,available,memory,size,create,partitions,partition,fan,out,final,int,num,buckets,get,initial,table,size,this,available,memory,size,this,segment,size,partition,fan,out,this,avg,record,len,init,table,num,buckets,byte,partition,fan,out
CompactingHashTable -> private int getMinPartition();1405529391;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1409845762;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1409911022;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1411473593;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1414786554;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1420654570;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1420654570;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1420663430;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1421838095;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1427646862;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1438803435;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1439805579;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1441738685;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1456936114;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1460741894;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1468441547;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMinPartition();1494520945;@return number of memory segments in the smallest partition;private int getMinPartition() {_		int minPartition = Integer.MAX_VALUE__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() < minPartition) {_				minPartition = p1.getBlockCount()__			}_		}_		return minPartition__	};return,number,of,memory,segments,in,the,smallest,partition;private,int,get,min,partition,int,min,partition,integer,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,min,partition,min,partition,p1,get,block,count,return,min,partition
CompactingHashTable -> private int getMaxPartition();1405529391;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1409845762;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1409911022;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1411473593;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1414786554;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1420654570;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1420654570;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1420663430;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1421838095;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1427646862;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1438803435;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1439805579;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1441738685;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1456936114;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1460741894;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1468441547;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private int getMaxPartition();1494520945;@return number of memory segments in the largest partition;private int getMaxPartition() {_		int maxPartition = 0__		for(InMemoryPartition<T> p1 : this.partitions) {_			if(p1.getBlockCount() > maxPartition) {_				maxPartition = p1.getBlockCount()__			}_		}_		return maxPartition__	};return,number,of,memory,segments,in,the,largest,partition;private,int,get,max,partition,int,max,partition,0,for,in,memory,partition,t,p1,this,partitions,if,p1,get,block,count,max,partition,max,partition,p1,get,block,count,return,max,partition
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1405529391;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		if(this.availableMemory.size() < additionalSegments) {_			for(int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		if(this.availableMemory.size() < additionalSegments || this.closed.get()) {_			return false__		} else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			MemorySegment[] newBuckets = new MemorySegment[additionalSegments]__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			System.arraycopy(newBuckets, 0, mergedBuckets, this.buckets.length, newBuckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset = 0__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset = 0__			int hash = 0__			int pointerOffset = 0__			long pointer = 0__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			for(int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				int posHashCode = 0__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int)(forwardPointer & 0xffffffff)__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						int oldBucketCount = 0__						int newBucketCount = 0__						while(!hashList.isEmpty()) {_							hash = hashList.removeInt(hashList.size()-1)__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if(posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, segment, bucketOffset, hash, pointer)__								oldBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, newSegment, bucketOffset, hash, pointer)__								newBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							} else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos = 0__				int bucketInSegmentPos = 0__				MemorySegment bucket = null__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeInt(overflowHashes.size()-1)__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(partition, bucket, bucketInSegmentPos, hash, pointer)__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,get,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,memory,segment,new,buckets,new,memory,segment,additional,segments,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,system,arraycopy,new,buckets,0,merged,buckets,this,buckets,length,new,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,0,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,0,int,hash,0,int,pointer,offset,0,long,pointer,0,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,0,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,int,hash,list,size,1,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,partition,segment,bucket,offset,hash,pointer,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,partition,new,segment,bucket,offset,hash,pointer,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,0,int,bucket,in,segment,pos,0,memory,segment,bucket,null,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,int,overflow,hashes,size,1,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,partition,bucket,bucket,in,segment,pos,hash,pointer,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1409845762;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		if(this.availableMemory.size() < additionalSegments) {_			for(int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		if(this.availableMemory.size() < additionalSegments || this.closed.get()) {_			return false__		} else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			MemorySegment[] newBuckets = new MemorySegment[additionalSegments]__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			System.arraycopy(newBuckets, 0, mergedBuckets, this.buckets.length, newBuckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset = 0__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset = 0__			int hash = 0__			int pointerOffset = 0__			long pointer = 0__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			for(int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				int posHashCode = 0__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int)(forwardPointer & 0xffffffff)__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						int oldBucketCount = 0__						int newBucketCount = 0__						while(!hashList.isEmpty()) {_							hash = hashList.removeInt(hashList.size()-1)__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if(posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, segment, bucketOffset, hash, pointer)__								oldBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, newSegment, bucketOffset, hash, pointer)__								newBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							} else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos = 0__				int bucketInSegmentPos = 0__				MemorySegment bucket = null__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeInt(overflowHashes.size()-1)__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(partition, bucket, bucketInSegmentPos, hash, pointer)__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,get,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,memory,segment,new,buckets,new,memory,segment,additional,segments,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,system,arraycopy,new,buckets,0,merged,buckets,this,buckets,length,new,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,0,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,0,int,hash,0,int,pointer,offset,0,long,pointer,0,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,0,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,int,hash,list,size,1,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,partition,segment,bucket,offset,hash,pointer,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,partition,new,segment,bucket,offset,hash,pointer,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,0,int,bucket,in,segment,pos,0,memory,segment,bucket,null,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,int,overflow,hashes,size,1,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,partition,bucket,bucket,in,segment,pos,hash,pointer,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1409911022;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		if(this.availableMemory.size() < additionalSegments) {_			for(int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		if(this.availableMemory.size() < additionalSegments || this.closed.get()) {_			return false__		} else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			MemorySegment[] newBuckets = new MemorySegment[additionalSegments]__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			System.arraycopy(newBuckets, 0, mergedBuckets, this.buckets.length, newBuckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset = 0__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset = 0__			int hash = 0__			int pointerOffset = 0__			long pointer = 0__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			for(int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				int posHashCode = 0__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int)(forwardPointer & 0xffffffff)__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						int oldBucketCount = 0__						int newBucketCount = 0__						while(!hashList.isEmpty()) {_							hash = hashList.removeInt(hashList.size()-1)__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if(posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, segment, bucketOffset, hash, pointer)__								oldBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, newSegment, bucketOffset, hash, pointer)__								newBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							} else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos = 0__				int bucketInSegmentPos = 0__				MemorySegment bucket = null__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeInt(overflowHashes.size()-1)__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(partition, bucket, bucketInSegmentPos, hash, pointer)__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,get,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,memory,segment,new,buckets,new,memory,segment,additional,segments,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,system,arraycopy,new,buckets,0,merged,buckets,this,buckets,length,new,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,0,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,0,int,hash,0,int,pointer,offset,0,long,pointer,0,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,0,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,int,hash,list,size,1,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,partition,segment,bucket,offset,hash,pointer,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,partition,new,segment,bucket,offset,hash,pointer,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,0,int,bucket,in,segment,pos,0,memory,segment,bucket,null,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,int,overflow,hashes,size,1,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,partition,bucket,bucket,in,segment,pos,hash,pointer,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1411473593;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		if(this.availableMemory.size() < additionalSegments) {_			for(int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		if(this.availableMemory.size() < additionalSegments || this.closed.get()) {_			return false__		} else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			MemorySegment[] newBuckets = new MemorySegment[additionalSegments]__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			System.arraycopy(newBuckets, 0, mergedBuckets, this.buckets.length, newBuckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset = 0__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset = 0__			int hash = 0__			int pointerOffset = 0__			long pointer = 0__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			for(int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				int posHashCode = 0__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int)(forwardPointer & 0xffffffff)__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						int oldBucketCount = 0__						int newBucketCount = 0__						while(!hashList.isEmpty()) {_							hash = hashList.removeInt(hashList.size()-1)__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if(posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, segment, bucketOffset, hash, pointer)__								oldBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, newSegment, bucketOffset, hash, pointer)__								newBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							} else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos = 0__				int bucketInSegmentPos = 0__				MemorySegment bucket = null__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeInt(overflowHashes.size()-1)__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(partition, bucket, bucketInSegmentPos, hash, pointer)__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,get,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,memory,segment,new,buckets,new,memory,segment,additional,segments,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,system,arraycopy,new,buckets,0,merged,buckets,this,buckets,length,new,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,0,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,0,int,hash,0,int,pointer,offset,0,long,pointer,0,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,0,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,int,hash,list,size,1,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,partition,segment,bucket,offset,hash,pointer,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,partition,new,segment,bucket,offset,hash,pointer,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,0,int,bucket,in,segment,pos,0,memory,segment,bucket,null,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,int,overflow,hashes,size,1,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,partition,bucket,bucket,in,segment,pos,hash,pointer,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1414786554;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		if(this.availableMemory.size() < additionalSegments) {_			for(int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		if(this.availableMemory.size() < additionalSegments || this.closed.get()) {_			return false__		} else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			MemorySegment[] newBuckets = new MemorySegment[additionalSegments]__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			System.arraycopy(newBuckets, 0, mergedBuckets, this.buckets.length, newBuckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset = 0__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset = 0__			int hash = 0__			int pointerOffset = 0__			long pointer = 0__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			for(int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				int posHashCode = 0__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int)(forwardPointer & 0xffffffff)__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						int oldBucketCount = 0__						int newBucketCount = 0__						while(!hashList.isEmpty()) {_							hash = hashList.removeInt(hashList.size()-1)__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if(posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, segment, bucketOffset, hash, pointer)__								oldBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, newSegment, bucketOffset, hash, pointer)__								newBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							} else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos = 0__				int bucketInSegmentPos = 0__				MemorySegment bucket = null__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeInt(overflowHashes.size()-1)__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(partition, bucket, bucketInSegmentPos, hash, pointer)__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,get,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,memory,segment,new,buckets,new,memory,segment,additional,segments,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,system,arraycopy,new,buckets,0,merged,buckets,this,buckets,length,new,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,0,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,0,int,hash,0,int,pointer,offset,0,long,pointer,0,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,0,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,int,hash,list,size,1,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,partition,segment,bucket,offset,hash,pointer,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,partition,new,segment,bucket,offset,hash,pointer,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,0,int,bucket,in,segment,pos,0,memory,segment,bucket,null,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,int,overflow,hashes,size,1,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,partition,bucket,bucket,in,segment,pos,hash,pointer,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1420654570;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		if(this.availableMemory.size() < additionalSegments) {_			for(int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		if(this.availableMemory.size() < additionalSegments || this.closed.get()) {_			return false__		} else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			MemorySegment[] newBuckets = new MemorySegment[additionalSegments]__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			System.arraycopy(newBuckets, 0, mergedBuckets, this.buckets.length, newBuckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset = 0__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset = 0__			int hash = 0__			int pointerOffset = 0__			long pointer = 0__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			for(int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				int posHashCode = 0__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int)(forwardPointer & 0xffffffff)__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						int oldBucketCount = 0__						int newBucketCount = 0__						while(!hashList.isEmpty()) {_							hash = hashList.removeInt(hashList.size()-1)__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if(posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, segment, bucketOffset, hash, pointer)__								oldBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, newSegment, bucketOffset, hash, pointer)__								newBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							} else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos = 0__				int bucketInSegmentPos = 0__				MemorySegment bucket = null__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeInt(overflowHashes.size()-1)__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(partition, bucket, bucketInSegmentPos, hash, pointer)__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,get,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,memory,segment,new,buckets,new,memory,segment,additional,segments,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,system,arraycopy,new,buckets,0,merged,buckets,this,buckets,length,new,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,0,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,0,int,hash,0,int,pointer,offset,0,long,pointer,0,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,0,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,int,hash,list,size,1,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,partition,segment,bucket,offset,hash,pointer,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,partition,new,segment,bucket,offset,hash,pointer,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,0,int,bucket,in,segment,pos,0,memory,segment,bucket,null,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,int,overflow,hashes,size,1,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,partition,bucket,bucket,in,segment,pos,hash,pointer,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1420654570;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		if(this.availableMemory.size() < additionalSegments) {_			for(int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		if(this.availableMemory.size() < additionalSegments || this.closed.get()) {_			return false__		} else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			MemorySegment[] newBuckets = new MemorySegment[additionalSegments]__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			System.arraycopy(newBuckets, 0, mergedBuckets, this.buckets.length, newBuckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset = 0__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset = 0__			int hash = 0__			int pointerOffset = 0__			long pointer = 0__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			for(int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				int posHashCode = 0__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int)(forwardPointer & 0xffffffff)__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						int oldBucketCount = 0__						int newBucketCount = 0__						while(!hashList.isEmpty()) {_							hash = hashList.removeInt(hashList.size()-1)__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if(posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, segment, bucketOffset, hash, pointer)__								oldBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, newSegment, bucketOffset, hash, pointer)__								newBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							} else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos = 0__				int bucketInSegmentPos = 0__				MemorySegment bucket = null__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeInt(overflowHashes.size()-1)__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(partition, bucket, bucketInSegmentPos, hash, pointer)__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,get,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,memory,segment,new,buckets,new,memory,segment,additional,segments,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,system,arraycopy,new,buckets,0,merged,buckets,this,buckets,length,new,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,0,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,0,int,hash,0,int,pointer,offset,0,long,pointer,0,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,0,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,int,hash,list,size,1,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,partition,segment,bucket,offset,hash,pointer,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,partition,new,segment,bucket,offset,hash,pointer,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,0,int,bucket,in,segment,pos,0,memory,segment,bucket,null,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,int,overflow,hashes,size,1,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,partition,bucket,bucket,in,segment,pos,hash,pointer,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1420663430;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		if(this.availableMemory.size() < additionalSegments) {_			for(int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		if(this.availableMemory.size() < additionalSegments || this.closed.get()) {_			return false__		} else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			MemorySegment[] newBuckets = new MemorySegment[additionalSegments]__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			System.arraycopy(newBuckets, 0, mergedBuckets, this.buckets.length, newBuckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset = 0__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset = 0__			int hash = 0__			int pointerOffset = 0__			long pointer = 0__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			for(int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				int posHashCode = 0__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int)(forwardPointer & 0xffffffff)__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						int oldBucketCount = 0__						int newBucketCount = 0__						while(!hashList.isEmpty()) {_							hash = hashList.removeInt(hashList.size()-1)__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if(posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, segment, bucketOffset, hash, pointer)__								oldBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, newSegment, bucketOffset, hash, pointer)__								newBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							} else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos = 0__				int bucketInSegmentPos = 0__				MemorySegment bucket = null__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeInt(overflowHashes.size()-1)__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(partition, bucket, bucketInSegmentPos, hash, pointer)__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,get,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,memory,segment,new,buckets,new,memory,segment,additional,segments,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,system,arraycopy,new,buckets,0,merged,buckets,this,buckets,length,new,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,0,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,0,int,hash,0,int,pointer,offset,0,long,pointer,0,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,0,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,int,hash,list,size,1,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,partition,segment,bucket,offset,hash,pointer,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,partition,new,segment,bucket,offset,hash,pointer,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,0,int,bucket,in,segment,pos,0,memory,segment,bucket,null,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,int,overflow,hashes,size,1,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,partition,bucket,bucket,in,segment,pos,hash,pointer,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1421838095;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		if(this.availableMemory.size() < additionalSegments) {_			for(int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		if(this.availableMemory.size() < additionalSegments || this.closed.get()) {_			return false__		} else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			MemorySegment[] newBuckets = new MemorySegment[additionalSegments]__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			System.arraycopy(newBuckets, 0, mergedBuckets, this.buckets.length, newBuckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset = 0__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset = 0__			int hash = 0__			int pointerOffset = 0__			long pointer = 0__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			for(int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				int posHashCode = 0__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int)(forwardPointer & 0xffffffff)__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						int oldBucketCount = 0__						int newBucketCount = 0__						while(!hashList.isEmpty()) {_							hash = hashList.removeLast()__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if(posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, segment, bucketOffset, hash, pointer)__								oldBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, newSegment, bucketOffset, hash, pointer)__								newBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							} else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos = 0__				int bucketInSegmentPos = 0__				MemorySegment bucket = null__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeLast()__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(partition, bucket, bucketInSegmentPos, hash, pointer)__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,get,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,memory,segment,new,buckets,new,memory,segment,additional,segments,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,system,arraycopy,new,buckets,0,merged,buckets,this,buckets,length,new,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,0,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,0,int,hash,0,int,pointer,offset,0,long,pointer,0,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,0,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,last,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,partition,segment,bucket,offset,hash,pointer,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,partition,new,segment,bucket,offset,hash,pointer,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,0,int,bucket,in,segment,pos,0,memory,segment,bucket,null,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,last,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,partition,bucket,bucket,in,segment,pos,hash,pointer,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1427646862;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		if(this.availableMemory.size() < additionalSegments) {_			for(int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		if(this.availableMemory.size() < additionalSegments || this.closed.get()) {_			return false__		} else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			MemorySegment[] newBuckets = new MemorySegment[additionalSegments]__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			System.arraycopy(newBuckets, 0, mergedBuckets, this.buckets.length, newBuckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset = 0__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset = 0__			int hash = 0__			int pointerOffset = 0__			long pointer = 0__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			for(int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				int posHashCode = 0__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int)(forwardPointer & 0xffffffff)__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						int oldBucketCount = 0__						int newBucketCount = 0__						while(!hashList.isEmpty()) {_							hash = hashList.removeLast()__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if(posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, segment, bucketOffset, hash, pointer)__								oldBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(partition, newSegment, bucketOffset, hash, pointer)__								newBucketCount++__							} else if(posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							} else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos = 0__				int bucketInSegmentPos = 0__				MemorySegment bucket = null__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeLast()__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(partition, bucket, bucketInSegmentPos, hash, pointer)__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,get,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,memory,segment,new,buckets,new,memory,segment,additional,segments,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,system,arraycopy,new,buckets,0,merged,buckets,this,buckets,length,new,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,0,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,0,int,hash,0,int,pointer,offset,0,long,pointer,0,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,0,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,0xffffffff,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,last,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,partition,segment,bucket,offset,hash,pointer,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,partition,new,segment,bucket,offset,hash,pointer,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,0,int,bucket,in,segment,pos,0,memory,segment,bucket,null,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,last,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,partition,bucket,bucket,in,segment,pos,hash,pointer,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1438803435;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		_		if (this.availableMemory.size() < additionalSegments) {_			for (int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		_		if (this.availableMemory.size() < additionalSegments || this.closed) {_			return false__		}_		else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE__						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset__			int hash__			int pointerOffset__			long pointer__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			_			for (int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				_				int posHashCode__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int) forwardPointer__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						_						int oldBucketCount = 0__						int newBucketCount = 0__						while (!hashList.isEmpty()) {_							hash = hashList.removeLast()__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if (posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(segment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								oldBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(newSegment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								newBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							}_							else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos__				int bucketInSegmentPos__				MemorySegment bucket__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeLast()__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(bucket, bucketInSegmentPos, hash, pointer, partition.getPartitionNumber())__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,int,hash,int,pointer,offset,long,pointer,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,last,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,segment,bucket,offset,hash,pointer,partition,get,partition,number,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,new,segment,bucket,offset,hash,pointer,partition,get,partition,number,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,int,bucket,in,segment,pos,memory,segment,bucket,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,last,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,bucket,bucket,in,segment,pos,hash,pointer,partition,get,partition,number,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1439805579;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		_		if (this.availableMemory.size() < additionalSegments) {_			for (int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		_		if (this.availableMemory.size() < additionalSegments || this.closed) {_			return false__		}_		else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE__						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset__			int hash__			int pointerOffset__			long pointer__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			_			for (int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				_				int posHashCode__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int) forwardPointer__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						_						int oldBucketCount = 0__						int newBucketCount = 0__						while (!hashList.isEmpty()) {_							hash = hashList.removeLast()__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if (posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(segment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								oldBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(newSegment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								newBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							}_							else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos__				int bucketInSegmentPos__				MemorySegment bucket__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeLast()__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(bucket, bucketInSegmentPos, hash, pointer, partition.getPartitionNumber())__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,int,hash,int,pointer,offset,long,pointer,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,last,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,segment,bucket,offset,hash,pointer,partition,get,partition,number,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,new,segment,bucket,offset,hash,pointer,partition,get,partition,number,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,int,bucket,in,segment,pos,memory,segment,bucket,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,last,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,bucket,bucket,in,segment,pos,hash,pointer,partition,get,partition,number,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1441738685;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		_		if (this.availableMemory.size() < additionalSegments) {_			for (int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		_		if (this.availableMemory.size() < additionalSegments || this.closed) {_			return false__		}_		else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE__						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset__			int hash__			int pointerOffset__			long pointer__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			_			for (int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				_				int posHashCode__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int) forwardPointer__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						_						int oldBucketCount = 0__						int newBucketCount = 0__						while (!hashList.isEmpty()) {_							hash = hashList.removeLast()__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if (posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(segment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								oldBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(newSegment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								newBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							}_							else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos__				int bucketInSegmentPos__				MemorySegment bucket__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeLast()__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(bucket, bucketInSegmentPos, hash, pointer, partition.getPartitionNumber())__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,int,hash,int,pointer,offset,long,pointer,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,last,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,segment,bucket,offset,hash,pointer,partition,get,partition,number,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,new,segment,bucket,offset,hash,pointer,partition,get,partition,number,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,int,bucket,in,segment,pos,memory,segment,bucket,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,last,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,bucket,bucket,in,segment,pos,hash,pointer,partition,get,partition,number,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1456936114;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		_		if (this.availableMemory.size() < additionalSegments) {_			for (int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		_		if (this.availableMemory.size() < additionalSegments || this.closed) {_			return false__		}_		else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE__						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset__			int hash__			int pointerOffset__			long pointer__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			_			for (int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				_				int posHashCode__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int) forwardPointer__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						_						int oldBucketCount = 0__						int newBucketCount = 0__						while (!hashList.isEmpty()) {_							hash = hashList.removeLast()__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if (posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(segment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								oldBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(newSegment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								newBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							}_							else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos__				int bucketInSegmentPos__				MemorySegment bucket__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeLast()__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(bucket, bucketInSegmentPos, hash, pointer, partition.getPartitionNumber())__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,int,hash,int,pointer,offset,long,pointer,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,last,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,segment,bucket,offset,hash,pointer,partition,get,partition,number,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,new,segment,bucket,offset,hash,pointer,partition,get,partition,number,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,int,bucket,in,segment,pos,memory,segment,bucket,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,last,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,bucket,bucket,in,segment,pos,hash,pointer,partition,get,partition,number,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1460741894;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		_		if (this.availableMemory.size() < additionalSegments) {_			for (int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		_		if (this.availableMemory.size() < additionalSegments || this.closed) {_			return false__		}_		else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE__						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset__			int hash__			int pointerOffset__			long pointer__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			_			for (int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				_				int posHashCode__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int) forwardPointer__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						_						int oldBucketCount = 0__						int newBucketCount = 0__						while (!hashList.isEmpty()) {_							hash = hashList.removeLast()__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if (posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(segment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								oldBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(newSegment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								newBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							}_							else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos__				int bucketInSegmentPos__				MemorySegment bucket__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeLast()__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(bucket, bucketInSegmentPos, hash, pointer, partition.getPartitionNumber())__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,int,hash,int,pointer,offset,long,pointer,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,last,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,segment,bucket,offset,hash,pointer,partition,get,partition,number,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,new,segment,bucket,offset,hash,pointer,partition,get,partition,number,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,int,bucket,in,segment,pos,memory,segment,bucket,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,last,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,bucket,bucket,in,segment,pos,hash,pointer,partition,get,partition,number,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1468441547;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		_		if (this.availableMemory.size() < additionalSegments) {_			for (int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		_		if (this.availableMemory.size() < additionalSegments || this.closed) {_			return false__		}_		else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE__						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset__			int hash__			int pointerOffset__			long pointer__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			_			for (int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				_				int posHashCode__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int) forwardPointer__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						_						int oldBucketCount = 0__						int newBucketCount = 0__						while (!hashList.isEmpty()) {_							hash = hashList.removeLast()__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if (posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(segment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								oldBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(newSegment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								newBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							}_							else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos__				int bucketInSegmentPos__				MemorySegment bucket__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeLast()__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(bucket, bucketInSegmentPos, hash, pointer, partition.getPartitionNumber())__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,int,hash,int,pointer,offset,long,pointer,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,last,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,segment,bucket,offset,hash,pointer,partition,get,partition,number,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,new,segment,bucket,offset,hash,pointer,partition,get,partition,number,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,int,bucket,in,segment,pos,memory,segment,bucket,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,last,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,bucket,bucket,in,segment,pos,hash,pointer,partition,get,partition,number,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private boolean resizeHashTable() throws IOException;1494520945;Attempts to double the number of buckets__@return true on success_@throws IOException;private boolean resizeHashTable() throws IOException {_		final int newNumBuckets = 2*this.numBuckets__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		final int newNumSegments = (newNumBuckets + (bucketsPerSegment-1)) / bucketsPerSegment__		final int additionalSegments = newNumSegments-this.buckets.length__		final int numPartitions = this.partitions.size()__		_		if (this.availableMemory.size() < additionalSegments) {_			for (int i = 0_ i < numPartitions_ i++) {_				compactPartition(i)__				if(this.availableMemory.size() >= additionalSegments) {_					break__				}_			}_		}_		_		if (this.availableMemory.size() < additionalSegments || this.closed) {_			return false__		}_		else {_			this.isResizing = true__			_			final int startOffset = (this.numBuckets * HASH_BUCKET_SIZE) % this.segmentSize__			final int oldNumBuckets = this.numBuckets__			final int oldNumSegments = this.buckets.length__			MemorySegment[] mergedBuckets = new MemorySegment[newNumSegments]__			System.arraycopy(this.buckets, 0, mergedBuckets, 0, this.buckets.length)__			this.buckets = mergedBuckets__			this.numBuckets = newNumBuckets__			_			boolean oldSegment = (startOffset != 0)__			final int startSegment = oldSegment ? (oldNumSegments-1) : oldNumSegments__			for (int i = startSegment, bucket = oldNumBuckets_ i < newNumSegments && bucket < this.numBuckets_ i++) {_				MemorySegment seg__				int bucketOffset__				if(oldSegment) { _					seg = this.buckets[i]__					for (int k = (oldNumBuckets % bucketsPerSegment) _ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE_	_						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				} else {_					seg = getNextBuffer()__					_					for (int k = 0_ k < bucketsPerSegment && bucket < this.numBuckets_ k++, bucket++) {_						bucketOffset = k * HASH_BUCKET_SIZE__						_						seg.put(bucketOffset + HEADER_PARTITION_OFFSET, assignPartition(bucket, (byte)numPartitions))__						seg.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						seg.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__					}_				}				_				this.buckets[i] = seg__				oldSegment = false_ _			}_			int hashOffset__			int hash__			int pointerOffset__			long pointer__			IntArrayList hashList = new IntArrayList(NUM_ENTRIES_PER_BUCKET)__			LongArrayList pointerList = new LongArrayList(NUM_ENTRIES_PER_BUCKET)__			IntArrayList overflowHashes = new IntArrayList(64)__			LongArrayList overflowPointers = new LongArrayList(64)__			_			_			for (int i = 0_ i < numPartitions_ i++) {_				InMemoryPartition<T> partition = this.partitions.get(i)__				final MemorySegment[] overflowSegments = partition.overflowSegments__				_				int posHashCode__				for (int j = 0, bucket = i_ j < this.buckets.length && bucket < oldNumBuckets_ j++) {_					MemorySegment segment = this.buckets[j]__					_					for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < oldNumBuckets_ k += numPartitions, bucket += numPartitions) {_						int bucketOffset = k * HASH_BUCKET_SIZE__						if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != i) {_							throw new IOException("Accessed wrong bucket! wanted: " + i + " got: " + segment.get(bucketOffset + HEADER_PARTITION_OFFSET))__						}_						_						int countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__						int numInSegment = 0__						pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__						hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__						while (true) {_							while (numInSegment < countInSegment) {_								hash = segment.getInt(hashOffset)__								if((hash % this.numBuckets) != bucket && (hash % this.numBuckets) != (bucket+oldNumBuckets)) {_									throw new IOException("wanted: " + bucket + " or " + (bucket + oldNumBuckets) + " got: " + hash%this.numBuckets)__								}_								pointer = segment.getLong(pointerOffset)__								hashList.add(hash)__								pointerList.add(pointer)__								pointerOffset += POINTER_LEN__								hashOffset += HASH_CODE_LEN__								numInSegment++__							}_							_							final long forwardPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if (forwardPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							final int overflowSegNum = (int) (forwardPointer >>> 32)__							segment = overflowSegments[overflowSegNum]__							bucketOffset = (int) forwardPointer__							countInSegment = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__							pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET__							hashOffset = bucketOffset + BUCKET_HEADER_LENGTH__							numInSegment = 0__						}_						segment = this.buckets[j]__						bucketOffset = k * HASH_BUCKET_SIZE__						_						segment.putInt(bucketOffset + HEADER_COUNT_OFFSET, 0)__						segment.putLong(bucketOffset + HEADER_FORWARD_OFFSET, BUCKET_FORWARD_POINTER_NOT_SET)__						_						if(hashList.size() != pointerList.size()) {_							throw new IOException("Pointer and hash counts do not match. hashes: " + hashList.size() + " pointer: " + pointerList.size())__						}_						int newSegmentIndex = (bucket + oldNumBuckets) / bucketsPerSegment__						MemorySegment newSegment = this.buckets[newSegmentIndex]__						_						_						int oldBucketCount = 0__						int newBucketCount = 0__						while (!hashList.isEmpty()) {_							hash = hashList.removeLast()__							pointer = pointerList.removeLong(pointerList.size()-1)__							posHashCode = hash % this.numBuckets__							if (posHashCode == bucket && oldBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = (bucket % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(segment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								oldBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) && newBucketCount < NUM_ENTRIES_PER_BUCKET) {_								bucketOffset = ((bucket + oldNumBuckets) % bucketsPerSegment) * HASH_BUCKET_SIZE__								insertBucketEntryFromStart(newSegment, bucketOffset, hash, pointer, partition.getPartitionNumber())__								newBucketCount++__							}_							else if (posHashCode == (bucket + oldNumBuckets) || posHashCode == bucket) {_								overflowHashes.add(hash)__								overflowPointers.add(pointer)__							}_							else {_								throw new IOException("Accessed wrong bucket. Target: " + bucket + " or " + (bucket + oldNumBuckets) + " Hit: " + posHashCode)__							}_						}_						hashList.clear()__						pointerList.clear()__					}_				}_				_				this.availableMemory.addAll(partition.resetOverflowBuckets())__				_				int bucketArrayPos__				int bucketInSegmentPos__				MemorySegment bucket__				while(!overflowHashes.isEmpty()) {_					hash = overflowHashes.removeLast()__					pointer = overflowPointers.removeLong(overflowPointers.size()-1)__					posHashCode = hash % this.numBuckets_ _					bucketArrayPos = posHashCode >>> this.bucketsPerSegmentBits__					bucketInSegmentPos = (posHashCode & this.bucketsPerSegmentMask) << NUM_INTRA_BUCKET_BITS__					bucket = this.buckets[bucketArrayPos]__					insertBucketEntryFromStart(bucket, bucketInSegmentPos, hash, pointer, partition.getPartitionNumber())__				}_				overflowHashes.clear()__				overflowPointers.clear()__			}_			this.isResizing = false__			return true__		}_	};attempts,to,double,the,number,of,buckets,return,true,on,success,throws,ioexception;private,boolean,resize,hash,table,throws,ioexception,final,int,new,num,buckets,2,this,num,buckets,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,final,int,new,num,segments,new,num,buckets,buckets,per,segment,1,buckets,per,segment,final,int,additional,segments,new,num,segments,this,buckets,length,final,int,num,partitions,this,partitions,size,if,this,available,memory,size,additional,segments,for,int,i,0,i,num,partitions,i,compact,partition,i,if,this,available,memory,size,additional,segments,break,if,this,available,memory,size,additional,segments,this,closed,return,false,else,this,is,resizing,true,final,int,start,offset,this,num,buckets,this,segment,size,final,int,old,num,buckets,this,num,buckets,final,int,old,num,segments,this,buckets,length,memory,segment,merged,buckets,new,memory,segment,new,num,segments,system,arraycopy,this,buckets,0,merged,buckets,0,this,buckets,length,this,buckets,merged,buckets,this,num,buckets,new,num,buckets,boolean,old,segment,start,offset,0,final,int,start,segment,old,segment,old,num,segments,1,old,num,segments,for,int,i,start,segment,bucket,old,num,buckets,i,new,num,segments,bucket,this,num,buckets,i,memory,segment,seg,int,bucket,offset,if,old,segment,seg,this,buckets,i,for,int,k,old,num,buckets,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,else,seg,get,next,buffer,for,int,k,0,k,buckets,per,segment,bucket,this,num,buckets,k,bucket,bucket,offset,k,seg,put,bucket,offset,assign,partition,bucket,byte,num,partitions,seg,put,int,bucket,offset,0,seg,put,long,bucket,offset,this,buckets,i,seg,old,segment,false,int,hash,offset,int,hash,int,pointer,offset,long,pointer,int,array,list,hash,list,new,int,array,list,long,array,list,pointer,list,new,long,array,list,int,array,list,overflow,hashes,new,int,array,list,64,long,array,list,overflow,pointers,new,long,array,list,64,for,int,i,0,i,num,partitions,i,in,memory,partition,t,partition,this,partitions,get,i,final,memory,segment,overflow,segments,partition,overflow,segments,int,pos,hash,code,for,int,j,0,bucket,i,j,this,buckets,length,bucket,old,num,buckets,j,memory,segment,segment,this,buckets,j,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,old,num,buckets,k,num,partitions,bucket,num,partitions,int,bucket,offset,k,if,int,segment,get,bucket,offset,i,throw,new,ioexception,accessed,wrong,bucket,wanted,i,got,segment,get,bucket,offset,int,count,in,segment,segment,get,int,bucket,offset,int,num,in,segment,0,pointer,offset,bucket,offset,hash,offset,bucket,offset,while,true,while,num,in,segment,count,in,segment,hash,segment,get,int,hash,offset,if,hash,this,num,buckets,bucket,hash,this,num,buckets,bucket,old,num,buckets,throw,new,ioexception,wanted,bucket,or,bucket,old,num,buckets,got,hash,this,num,buckets,pointer,segment,get,long,pointer,offset,hash,list,add,hash,pointer,list,add,pointer,pointer,offset,hash,offset,num,in,segment,final,long,forward,pointer,segment,get,long,bucket,offset,if,forward,pointer,break,final,int,overflow,seg,num,int,forward,pointer,32,segment,overflow,segments,overflow,seg,num,bucket,offset,int,forward,pointer,count,in,segment,segment,get,int,bucket,offset,pointer,offset,bucket,offset,hash,offset,bucket,offset,num,in,segment,0,segment,this,buckets,j,bucket,offset,k,segment,put,int,bucket,offset,0,segment,put,long,bucket,offset,if,hash,list,size,pointer,list,size,throw,new,ioexception,pointer,and,hash,counts,do,not,match,hashes,hash,list,size,pointer,pointer,list,size,int,new,segment,index,bucket,old,num,buckets,buckets,per,segment,memory,segment,new,segment,this,buckets,new,segment,index,int,old,bucket,count,0,int,new,bucket,count,0,while,hash,list,is,empty,hash,hash,list,remove,last,pointer,pointer,list,remove,long,pointer,list,size,1,pos,hash,code,hash,this,num,buckets,if,pos,hash,code,bucket,old,bucket,count,bucket,offset,bucket,buckets,per,segment,insert,bucket,entry,from,start,segment,bucket,offset,hash,pointer,partition,get,partition,number,old,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,new,bucket,count,bucket,offset,bucket,old,num,buckets,buckets,per,segment,insert,bucket,entry,from,start,new,segment,bucket,offset,hash,pointer,partition,get,partition,number,new,bucket,count,else,if,pos,hash,code,bucket,old,num,buckets,pos,hash,code,bucket,overflow,hashes,add,hash,overflow,pointers,add,pointer,else,throw,new,ioexception,accessed,wrong,bucket,target,bucket,or,bucket,old,num,buckets,hit,pos,hash,code,hash,list,clear,pointer,list,clear,this,available,memory,add,all,partition,reset,overflow,buckets,int,bucket,array,pos,int,bucket,in,segment,pos,memory,segment,bucket,while,overflow,hashes,is,empty,hash,overflow,hashes,remove,last,pointer,overflow,pointers,remove,long,overflow,pointers,size,1,pos,hash,code,hash,this,num,buckets,bucket,array,pos,pos,hash,code,this,buckets,per,segment,bits,bucket,in,segment,pos,pos,hash,code,this,buckets,per,segment,mask,bucket,this,buckets,bucket,array,pos,insert,bucket,entry,from,start,bucket,bucket,in,segment,pos,hash,pointer,partition,get,partition,number,overflow,hashes,clear,overflow,pointers,clear,this,is,resizing,false,return,true
CompactingHashTable -> private void compactPartition(int partitionNumber) throws IOException;1405024514;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partition partition number_@throws IOException;private void compactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted() || this.closed.get()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		T tempHolder = this.buildSideSerializer.createInstance()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		final int numPartitions = this.partitions.size() + 1_ _		long pointer = 0L__		int pointerOffset = 0__		int bucketOffset = 0__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! ")__				}_				int count = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				for (int j = 0_ j < NUM_ENTRIES_PER_BUCKET && j < count_ j++) {_					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET + (j * POINTER_LEN)__					pointer = segment.getLong(pointerOffset)__					partition.readRecordAt(pointer, tempHolder)__					pointer = this.compactionMemory.appendRecord(tempHolder)__					segment.putLong(pointerOffset, pointer)__				}_				long overflowPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if(overflowPointer != BUCKET_FORWARD_POINTER_NOT_SET) {_					_					int current = NUM_ENTRIES_PER_BUCKET__					bucketOffset = (int) (overflowPointer & 0xffffffff)__					pointerOffset = ((int) (overflowPointer & 0xffffffff)) + BUCKET_POINTER_START_OFFSET__					int overflowSegNum = (int) (overflowPointer >>> 32)__					count += partition.overflowSegments[overflowSegNum].getInt(bucketOffset + HEADER_COUNT_OFFSET)__					while(current < count) {_						pointer = partition.overflowSegments[overflowSegNum].getLong(pointerOffset)__						partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						partition.overflowSegments[overflowSegNum].putLong(pointerOffset, pointer)__						current++__						if(current % NUM_ENTRIES_PER_BUCKET == 0) {_							count += partition.overflowSegments[overflowSegNum].getInt(bucketOffset + HEADER_COUNT_OFFSET)__							overflowPointer = partition.overflowSegments[overflowSegNum].getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if(overflowPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							overflowSegNum = (int) (overflowPointer >>> 32)__							bucketOffset = (int) (overflowPointer & 0xffffffff)__							pointerOffset = ((int) (overflowPointer & 0xffffffff)) + BUCKET_POINTER_START_OFFSET__						} else {_							pointerOffset += POINTER_LEN__						}_					}_				}_			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.compactionMemory = partition__		this.partitions.get(partitionNumber).overflowSegments = this.compactionMemory.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = this.compactionMemory.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = this.compactionMemory.nextOverflowBucket__		this.partitions.get(partitionNumber).setCompaction(true)__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		_		int maxSegmentNumber = 0__		for (InMemoryPartition<T> e : this.partitions) {_			if(e.getBlockCount() > maxSegmentNumber) {_				maxSegmentNumber = e.getBlockCount()__			}_		}_		this.compactionMemory.allocateSegments(maxSegmentNumber)__		if(this.compactionMemory.getBlockCount() > maxSegmentNumber) {_			this.compactionMemory.releaseSegments(maxSegmentNumber, availableMemory)__		}_	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,partition,number,throws,ioexception;private,void,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,this,closed,get,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,t,temp,holder,this,build,side,serializer,create,instance,in,memory,partition,t,partition,this,partitions,remove,partition,number,final,int,num,partitions,this,partitions,size,1,long,pointer,0l,int,pointer,offset,0,int,bucket,offset,0,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,int,count,segment,get,int,bucket,offset,for,int,j,0,j,j,count,j,pointer,offset,bucket,offset,j,pointer,segment,get,long,pointer,offset,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,long,overflow,pointer,segment,get,long,bucket,offset,if,overflow,pointer,int,current,bucket,offset,int,overflow,pointer,0xffffffff,pointer,offset,int,overflow,pointer,0xffffffff,int,overflow,seg,num,int,overflow,pointer,32,count,partition,overflow,segments,overflow,seg,num,get,int,bucket,offset,while,current,count,pointer,partition,overflow,segments,overflow,seg,num,get,long,pointer,offset,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,partition,overflow,segments,overflow,seg,num,put,long,pointer,offset,pointer,current,if,current,0,count,partition,overflow,segments,overflow,seg,num,get,int,bucket,offset,overflow,pointer,partition,overflow,segments,overflow,seg,num,get,long,bucket,offset,if,overflow,pointer,break,overflow,seg,num,int,overflow,pointer,32,bucket,offset,int,overflow,pointer,0xffffffff,pointer,offset,int,overflow,pointer,0xffffffff,else,pointer,offset,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,compaction,memory,partition,this,partitions,get,partition,number,overflow,segments,this,compaction,memory,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,this,compaction,memory,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,this,compaction,memory,next,overflow,bucket,this,partitions,get,partition,number,set,compaction,true,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,int,max,segment,number,0,for,in,memory,partition,t,e,this,partitions,if,e,get,block,count,max,segment,number,max,segment,number,e,get,block,count,this,compaction,memory,allocate,segments,max,segment,number,if,this,compaction,memory,get,block,count,max,segment,number,this,compaction,memory,release,segments,max,segment,number,available,memory
CompactingHashTable -> private void compactPartition(int partitionNumber) throws IOException;1405090423;Compacts (garbage collects) partition with copy-compact strategy using compaction partition__@param partition partition number_@throws IOException;private void compactPartition(int partitionNumber) throws IOException {_		_		if(this.partitions.get(partitionNumber).isCompacted() || this.closed.get()) {_			return__		}_		_		this.compactionMemory.clearAllMemory(availableMemory)__		this.compactionMemory.allocateSegments(1)__		T tempHolder = this.buildSideSerializer.createInstance()__		InMemoryPartition<T> partition = this.partitions.remove(partitionNumber)__		final int numPartitions = this.partitions.size() + 1_ _		long pointer = 0L__		int pointerOffset = 0__		int bucketOffset = 0__		final int bucketsPerSegment = this.bucketsPerSegmentMask + 1__		for (int i = 0, bucket = partitionNumber_ i < this.buckets.length && bucket < this.numBuckets_ i++) {_			MemorySegment segment = this.buckets[i]__			_			for (int k = bucket % bucketsPerSegment_ k < bucketsPerSegment && bucket < this.numBuckets_ k += numPartitions, bucket += numPartitions) {_				bucketOffset = k * HASH_BUCKET_SIZE__				if((int)segment.get(bucketOffset + HEADER_PARTITION_OFFSET) != partitionNumber) {_					throw new IOException("Accessed wrong bucket! ")__				}_				int count = segment.getInt(bucketOffset + HEADER_COUNT_OFFSET)__				for (int j = 0_ j < NUM_ENTRIES_PER_BUCKET && j < count_ j++) {_					pointerOffset = bucketOffset + BUCKET_POINTER_START_OFFSET + (j * POINTER_LEN)__					pointer = segment.getLong(pointerOffset)__					partition.readRecordAt(pointer, tempHolder)__					pointer = this.compactionMemory.appendRecord(tempHolder)__					segment.putLong(pointerOffset, pointer)__				}_				long overflowPointer = segment.getLong(bucketOffset + HEADER_FORWARD_OFFSET)__				if(overflowPointer != BUCKET_FORWARD_POINTER_NOT_SET) {_					_					int current = NUM_ENTRIES_PER_BUCKET__					bucketOffset = (int) (overflowPointer & 0xffffffff)__					pointerOffset = ((int) (overflowPointer & 0xffffffff)) + BUCKET_POINTER_START_OFFSET__					int overflowSegNum = (int) (overflowPointer >>> 32)__					count += partition.overflowSegments[overflowSegNum].getInt(bucketOffset + HEADER_COUNT_OFFSET)__					while(current < count) {_						pointer = partition.overflowSegments[overflowSegNum].getLong(pointerOffset)__						partition.readRecordAt(pointer, tempHolder)__						pointer = this.compactionMemory.appendRecord(tempHolder)__						partition.overflowSegments[overflowSegNum].putLong(pointerOffset, pointer)__						current++__						if(current % NUM_ENTRIES_PER_BUCKET == 0) {_							count += partition.overflowSegments[overflowSegNum].getInt(bucketOffset + HEADER_COUNT_OFFSET)__							overflowPointer = partition.overflowSegments[overflowSegNum].getLong(bucketOffset + HEADER_FORWARD_OFFSET)__							if(overflowPointer == BUCKET_FORWARD_POINTER_NOT_SET) {_								break__							}_							overflowSegNum = (int) (overflowPointer >>> 32)__							bucketOffset = (int) (overflowPointer & 0xffffffff)__							pointerOffset = ((int) (overflowPointer & 0xffffffff)) + BUCKET_POINTER_START_OFFSET__						} else {_							pointerOffset += POINTER_LEN__						}_					}_				}_			}_		}_		_		this.compactionMemory.setPartitionNumber(partitionNumber)__		this.partitions.add(partitionNumber, compactionMemory)__		this.compactionMemory = partition__		this.partitions.get(partitionNumber).overflowSegments = this.compactionMemory.overflowSegments__		this.partitions.get(partitionNumber).numOverflowSegments = this.compactionMemory.numOverflowSegments__		this.partitions.get(partitionNumber).nextOverflowBucket = this.compactionMemory.nextOverflowBucket__		this.partitions.get(partitionNumber).setCompaction(true)__		this.compactionMemory.resetRecordCounter()__		this.compactionMemory.setPartitionNumber(-1)__		_		int maxSegmentNumber = 0__		for (InMemoryPartition<T> e : this.partitions) {_			if(e.getBlockCount() > maxSegmentNumber) {_				maxSegmentNumber = e.getBlockCount()__			}_		}_		this.compactionMemory.allocateSegments(maxSegmentNumber)__		if(this.compactionMemory.getBlockCount() > maxSegmentNumber) {_			this.compactionMemory.releaseSegments(maxSegmentNumber, availableMemory)__		}_	};compacts,garbage,collects,partition,with,copy,compact,strategy,using,compaction,partition,param,partition,partition,number,throws,ioexception;private,void,compact,partition,int,partition,number,throws,ioexception,if,this,partitions,get,partition,number,is,compacted,this,closed,get,return,this,compaction,memory,clear,all,memory,available,memory,this,compaction,memory,allocate,segments,1,t,temp,holder,this,build,side,serializer,create,instance,in,memory,partition,t,partition,this,partitions,remove,partition,number,final,int,num,partitions,this,partitions,size,1,long,pointer,0l,int,pointer,offset,0,int,bucket,offset,0,final,int,buckets,per,segment,this,buckets,per,segment,mask,1,for,int,i,0,bucket,partition,number,i,this,buckets,length,bucket,this,num,buckets,i,memory,segment,segment,this,buckets,i,for,int,k,bucket,buckets,per,segment,k,buckets,per,segment,bucket,this,num,buckets,k,num,partitions,bucket,num,partitions,bucket,offset,k,if,int,segment,get,bucket,offset,partition,number,throw,new,ioexception,accessed,wrong,bucket,int,count,segment,get,int,bucket,offset,for,int,j,0,j,j,count,j,pointer,offset,bucket,offset,j,pointer,segment,get,long,pointer,offset,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,segment,put,long,pointer,offset,pointer,long,overflow,pointer,segment,get,long,bucket,offset,if,overflow,pointer,int,current,bucket,offset,int,overflow,pointer,0xffffffff,pointer,offset,int,overflow,pointer,0xffffffff,int,overflow,seg,num,int,overflow,pointer,32,count,partition,overflow,segments,overflow,seg,num,get,int,bucket,offset,while,current,count,pointer,partition,overflow,segments,overflow,seg,num,get,long,pointer,offset,partition,read,record,at,pointer,temp,holder,pointer,this,compaction,memory,append,record,temp,holder,partition,overflow,segments,overflow,seg,num,put,long,pointer,offset,pointer,current,if,current,0,count,partition,overflow,segments,overflow,seg,num,get,int,bucket,offset,overflow,pointer,partition,overflow,segments,overflow,seg,num,get,long,bucket,offset,if,overflow,pointer,break,overflow,seg,num,int,overflow,pointer,32,bucket,offset,int,overflow,pointer,0xffffffff,pointer,offset,int,overflow,pointer,0xffffffff,else,pointer,offset,this,compaction,memory,set,partition,number,partition,number,this,partitions,add,partition,number,compaction,memory,this,compaction,memory,partition,this,partitions,get,partition,number,overflow,segments,this,compaction,memory,overflow,segments,this,partitions,get,partition,number,num,overflow,segments,this,compaction,memory,num,overflow,segments,this,partitions,get,partition,number,next,overflow,bucket,this,compaction,memory,next,overflow,bucket,this,partitions,get,partition,number,set,compaction,true,this,compaction,memory,reset,record,counter,this,compaction,memory,set,partition,number,1,int,max,segment,number,0,for,in,memory,partition,t,e,this,partitions,if,e,get,block,count,max,segment,number,max,segment,number,e,get,block,count,this,compaction,memory,allocate,segments,max,segment,number,if,this,compaction,memory,get,block,count,max,segment,number,this,compaction,memory,release,segments,max,segment,number,available,memory
CompactingHashTable -> private static byte assignPartition(int bucket, byte numPartitions);1438803435;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static byte assignPartition(int bucket, byte numPartitions);1439805579;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static byte assignPartition(int bucket, byte numPartitions);1441738685;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static byte assignPartition(int bucket, byte numPartitions);1456936114;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static byte assignPartition(int bucket, byte numPartitions);1460741894;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static byte assignPartition(int bucket, byte numPartitions);1468441547;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private static byte assignPartition(int bucket, byte numPartitions);1494520945;Assigns a partition to a bucket.__@param bucket bucket index_@param numPartitions number of partitions_@return The hash code for the integer.;private static byte assignPartition(int bucket, byte numPartitions) {_		return (byte) (bucket % numPartitions)__	};assigns,a,partition,to,a,bucket,param,bucket,bucket,index,param,num,partitions,number,of,partitions,return,the,hash,code,for,the,integer;private,static,byte,assign,partition,int,bucket,byte,num,partitions,return,byte,bucket,num,partitions
CompactingHashTable -> private long getPartitionSize();1405529391;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1409845762;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1409911022;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1411473593;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1414786554;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1420654570;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1420654570;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1420663430;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1421838095;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1427646862;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1438803435;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1439805579;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1441738685;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1456936114;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1460741894;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1468441547;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private long getPartitionSize();1494520945;Size of all memory segments owned by the partitions of this hash table excluding the compaction partition__@return size in bytes;private long getPartitionSize() {_		long numSegments = 0__		for(InMemoryPartition<T> p : this.partitions) {_			numSegments += p.getBlockCount()__		}_		return numSegments*this.segmentSize__	};size,of,all,memory,segments,owned,by,the,partitions,of,this,hash,table,excluding,the,compaction,partition,return,size,in,bytes;private,long,get,partition,size,long,num,segments,0,for,in,memory,partition,t,p,this,partitions,num,segments,p,get,block,count,return,num,segments,this,segment,size
CompactingHashTable -> private int getOverflowSegmentCount();1405529391;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for(InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1409845762;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for(InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1409911022;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for(InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1411473593;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for(InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1414786554;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for(InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1420654570;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for(InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1420654570;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for(InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1420663430;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for(InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1421838095;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for(InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1427646862;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for(InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1438803435;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for (InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1439805579;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for (InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1441738685;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for (InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1456936114;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for (InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1460741894;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for (InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1468441547;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for (InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private int getOverflowSegmentCount();1494520945;@return number of memory segments used in overflow buckets;private int getOverflowSegmentCount() {_		int result = 0__		for (InMemoryPartition<T> p : this.partitions) {_			result += p.numOverflowSegments__		}_		return result__	};return,number,of,memory,segments,used,in,overflow,buckets;private,int,get,overflow,segment,count,int,result,0,for,in,memory,partition,t,p,this,partitions,result,p,num,overflow,segments,return,result
CompactingHashTable -> private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1438803435;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		while(numBuckets % numPartitions != 0) {_			numBuckets++__		}_		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,while,num,buckets,num,partitions,0,num,buckets,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1439805579;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		numBuckets += numPartitions - numBuckets % numPartitions__		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,num,buckets,num,partitions,num,buckets,num,partitions,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1441738685;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		numBuckets += numPartitions - numBuckets % numPartitions__		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,num,buckets,num,partitions,num,buckets,num,partitions,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1456936114;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		numBuckets += numPartitions - numBuckets % numPartitions__		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,num,buckets,num,partitions,num,buckets,num,partitions,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1460741894;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		numBuckets += numPartitions - numBuckets % numPartitions__		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,num,buckets,num,partitions,num,buckets,num,partitions,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1468441547;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		numBuckets += numPartitions - numBuckets % numPartitions__		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,num,buckets,num,partitions,num,buckets,num,partitions,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes);1494520945;tries to find a good value for the number of buckets_will ensure that the number of buckets is a multiple of numPartitions__@return number of buckets;private static int getInitialTableSize(int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {_		final long totalSize = ((long) bufferSize) * numBuffers__		final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES)__		final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES__		long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1__		numBuckets += numPartitions - numBuckets % numPartitions__		return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets__	};tries,to,find,a,good,value,for,the,number,of,buckets,will,ensure,that,the,number,of,buckets,is,a,multiple,of,num,partitions,return,number,of,buckets;private,static,int,get,initial,table,size,int,num,buffers,int,buffer,size,int,num,partitions,int,record,len,bytes,final,long,total,size,long,buffer,size,num,buffers,final,long,num,records,storable,total,size,record,len,bytes,final,long,bucket,bytes,num,records,storable,long,num,buckets,bucket,bytes,2,1,num,buckets,num,partitions,num,buckets,num,partitions,return,num,buckets,integer,integer,int,num,buckets
CompactingHashTable -> private static final int getPartitioningFanOutNoEstimates(int numBuffers);1405024514;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 127 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static final int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,127,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,final,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static final int getPartitioningFanOutNoEstimates(int numBuffers);1405090423;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 127 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static final int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,127,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,final,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static final int getPartitioningFanOutNoEstimates(int numBuffers);1405529391;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static final int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,final,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static final int getPartitioningFanOutNoEstimates(int numBuffers);1409845762;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static final int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,final,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static final int getPartitioningFanOutNoEstimates(int numBuffers);1409911022;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static final int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,final,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static final int getPartitioningFanOutNoEstimates(int numBuffers);1411473593;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static final int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,final,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static final int getPartitioningFanOutNoEstimates(int numBuffers);1414786554;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static final int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,final,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static final int getPartitioningFanOutNoEstimates(int numBuffers);1420654570;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static final int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,final,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static final int getPartitioningFanOutNoEstimates(int numBuffers);1420654570;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static final int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,final,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static final int getPartitioningFanOutNoEstimates(int numBuffers);1420663430;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static final int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,final,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static final int getPartitioningFanOutNoEstimates(int numBuffers);1421838095;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static final int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,final,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private static final int getPartitioningFanOutNoEstimates(int numBuffers);1427646862;Gets the number of partitions to be used for an initial hash-table, when no estimates are_available._<p>_The current logic makes sure that there are always between 10 and 32 partitions, and close_to 0.1 of the number of buffers.__@param numBuffers The number of buffers available._@return The number of partitions to use.;private static final int getPartitioningFanOutNoEstimates(int numBuffers) {_		return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS))__	};gets,the,number,of,partitions,to,be,used,for,an,initial,hash,table,when,no,estimates,are,available,p,the,current,logic,makes,sure,that,there,are,always,between,10,and,32,partitions,and,close,to,0,1,of,the,number,of,buffers,param,num,buffers,the,number,of,buffers,available,return,the,number,of,partitions,to,use;private,static,final,int,get,partitioning,fan,out,no,estimates,int,num,buffers,return,math,max,10,math,min,num,buffers,10
CompactingHashTable -> private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos, 											int hashCode, long pointer, int partitionNumber) 	throws IOException;1438803435;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos,_											int hashCode, long pointer, int partitionNumber)_	throws IOException_	{_		boolean checkForResize = false__		_		final int count = bucket.getInt(bucketInSegmentPos + HEADER_COUNT_OFFSET)__		if (count < NUM_ENTRIES_PER_BUCKET) {_			_			bucket.putInt(bucketInSegmentPos + BUCKET_HEADER_LENGTH + (count * HASH_CODE_LEN), hashCode)_	_			bucket.putLong(bucketInSegmentPos + BUCKET_POINTER_START_OFFSET + (count * POINTER_LEN), pointer)_ _			bucket.putInt(bucketInSegmentPos + HEADER_COUNT_OFFSET, count + 1)_ _		}_		else {_			_			final InMemoryPartition<T> p = this.partitions.get(partitionNumber)__			_			final long originalForwardPointer = bucket.getLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET)__			final long forwardForNewBucket__			_			if (originalForwardPointer != BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				final int overflowSegNum = (int) (originalForwardPointer >>> 32)__				final int segOffset = (int) originalForwardPointer__				final MemorySegment seg = p.overflowSegments[overflowSegNum]__				_				final int obCount = seg.getInt(segOffset + HEADER_COUNT_OFFSET)__				_				_				if (obCount < NUM_ENTRIES_PER_BUCKET) {_					_					seg.putInt(segOffset + BUCKET_HEADER_LENGTH + (obCount * HASH_CODE_LEN), hashCode)_	_					seg.putLong(segOffset + BUCKET_POINTER_START_OFFSET + (obCount * POINTER_LEN), pointer)_ _					seg.putInt(segOffset + HEADER_COUNT_OFFSET, obCount + 1)_ _					return__				} else {_					_					_					forwardForNewBucket = originalForwardPointer__				}_			} else {_				_				forwardForNewBucket = BUCKET_FORWARD_POINTER_NOT_SET__			}_			_			_			MemorySegment overflowSeg__			final int overflowBucketNum__			final int overflowBucketOffset__			_			_			if (p.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowBucketNum = p.numOverflowSegments__				_				_				if (p.overflowSegments.length <= p.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[p.overflowSegments.length * 2]__					System.arraycopy(p.overflowSegments, 0, newSegsArray, 0, p.overflowSegments.length)__					p.overflowSegments = newSegsArray__				}_				p.overflowSegments[p.numOverflowSegments] = overflowSeg__				p.numOverflowSegments++__				checkForResize = true__			} else {_				_				overflowBucketNum = p.numOverflowSegments - 1__				overflowSeg = p.overflowSegments[overflowBucketNum]__				overflowBucketOffset = p.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			p.nextOverflowBucket = (p.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : p.nextOverflowBucket + 1)__			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, forwardForNewBucket)__			final long pointerToNewBucket = (((long) overflowBucketNum) << 32) | ((long) overflowBucketOffset)__			bucket.putLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_ _			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			_			if (checkForResize && !this.isResizing) {_				_				if (this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,start,memory,segment,bucket,int,bucket,in,segment,pos,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,final,int,count,bucket,get,int,bucket,in,segment,pos,if,count,bucket,put,int,bucket,in,segment,pos,count,hash,code,bucket,put,long,bucket,in,segment,pos,count,pointer,bucket,put,int,bucket,in,segment,pos,count,1,else,final,in,memory,partition,t,p,this,partitions,get,partition,number,final,long,original,forward,pointer,bucket,get,long,bucket,in,segment,pos,final,long,forward,for,new,bucket,if,original,forward,pointer,final,int,overflow,seg,num,int,original,forward,pointer,32,final,int,seg,offset,int,original,forward,pointer,final,memory,segment,seg,p,overflow,segments,overflow,seg,num,final,int,ob,count,seg,get,int,seg,offset,if,ob,count,seg,put,int,seg,offset,ob,count,hash,code,seg,put,long,seg,offset,ob,count,pointer,seg,put,int,seg,offset,ob,count,1,return,else,forward,for,new,bucket,original,forward,pointer,else,forward,for,new,bucket,memory,segment,overflow,seg,final,int,overflow,bucket,num,final,int,overflow,bucket,offset,if,p,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,bucket,num,p,num,overflow,segments,if,p,overflow,segments,length,p,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,p,overflow,segments,length,2,system,arraycopy,p,overflow,segments,0,new,segs,array,0,p,overflow,segments,length,p,overflow,segments,new,segs,array,p,overflow,segments,p,num,overflow,segments,overflow,seg,p,num,overflow,segments,check,for,resize,true,else,overflow,bucket,num,p,num,overflow,segments,1,overflow,seg,p,overflow,segments,overflow,bucket,num,overflow,bucket,offset,p,next,overflow,bucket,p,next,overflow,bucket,p,next,overflow,bucket,this,buckets,per,segment,mask,0,p,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,forward,for,new,bucket,final,long,pointer,to,new,bucket,long,overflow,bucket,num,32,long,overflow,bucket,offset,bucket,put,long,bucket,in,segment,pos,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos, 											int hashCode, long pointer, int partitionNumber) 	throws IOException;1439805579;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos,_											int hashCode, long pointer, int partitionNumber)_	throws IOException_	{_		boolean checkForResize = false__		_		final int count = bucket.getInt(bucketInSegmentPos + HEADER_COUNT_OFFSET)__		if (count < NUM_ENTRIES_PER_BUCKET) {_			_			bucket.putInt(bucketInSegmentPos + BUCKET_HEADER_LENGTH + (count * HASH_CODE_LEN), hashCode)_	_			bucket.putLong(bucketInSegmentPos + BUCKET_POINTER_START_OFFSET + (count * POINTER_LEN), pointer)_ _			bucket.putInt(bucketInSegmentPos + HEADER_COUNT_OFFSET, count + 1)_ _		}_		else {_			_			final InMemoryPartition<T> p = this.partitions.get(partitionNumber)__			_			final long originalForwardPointer = bucket.getLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET)__			final long forwardForNewBucket__			_			if (originalForwardPointer != BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				final int overflowSegNum = (int) (originalForwardPointer >>> 32)__				final int segOffset = (int) originalForwardPointer__				final MemorySegment seg = p.overflowSegments[overflowSegNum]__				_				final int obCount = seg.getInt(segOffset + HEADER_COUNT_OFFSET)__				_				_				if (obCount < NUM_ENTRIES_PER_BUCKET) {_					_					seg.putInt(segOffset + BUCKET_HEADER_LENGTH + (obCount * HASH_CODE_LEN), hashCode)_	_					seg.putLong(segOffset + BUCKET_POINTER_START_OFFSET + (obCount * POINTER_LEN), pointer)_ _					seg.putInt(segOffset + HEADER_COUNT_OFFSET, obCount + 1)_ _					return__				} else {_					_					_					forwardForNewBucket = originalForwardPointer__				}_			} else {_				_				forwardForNewBucket = BUCKET_FORWARD_POINTER_NOT_SET__			}_			_			_			MemorySegment overflowSeg__			final int overflowBucketNum__			final int overflowBucketOffset__			_			_			if (p.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowBucketNum = p.numOverflowSegments__				_				_				if (p.overflowSegments.length <= p.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[p.overflowSegments.length * 2]__					System.arraycopy(p.overflowSegments, 0, newSegsArray, 0, p.overflowSegments.length)__					p.overflowSegments = newSegsArray__				}_				p.overflowSegments[p.numOverflowSegments] = overflowSeg__				p.numOverflowSegments++__				checkForResize = true__			} else {_				_				overflowBucketNum = p.numOverflowSegments - 1__				overflowSeg = p.overflowSegments[overflowBucketNum]__				overflowBucketOffset = p.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			p.nextOverflowBucket = (p.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : p.nextOverflowBucket + 1)__			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, forwardForNewBucket)__			final long pointerToNewBucket = (((long) overflowBucketNum) << 32) | ((long) overflowBucketOffset)__			bucket.putLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_ _			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			_			if (checkForResize && !this.isResizing) {_				_				if (this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,start,memory,segment,bucket,int,bucket,in,segment,pos,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,final,int,count,bucket,get,int,bucket,in,segment,pos,if,count,bucket,put,int,bucket,in,segment,pos,count,hash,code,bucket,put,long,bucket,in,segment,pos,count,pointer,bucket,put,int,bucket,in,segment,pos,count,1,else,final,in,memory,partition,t,p,this,partitions,get,partition,number,final,long,original,forward,pointer,bucket,get,long,bucket,in,segment,pos,final,long,forward,for,new,bucket,if,original,forward,pointer,final,int,overflow,seg,num,int,original,forward,pointer,32,final,int,seg,offset,int,original,forward,pointer,final,memory,segment,seg,p,overflow,segments,overflow,seg,num,final,int,ob,count,seg,get,int,seg,offset,if,ob,count,seg,put,int,seg,offset,ob,count,hash,code,seg,put,long,seg,offset,ob,count,pointer,seg,put,int,seg,offset,ob,count,1,return,else,forward,for,new,bucket,original,forward,pointer,else,forward,for,new,bucket,memory,segment,overflow,seg,final,int,overflow,bucket,num,final,int,overflow,bucket,offset,if,p,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,bucket,num,p,num,overflow,segments,if,p,overflow,segments,length,p,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,p,overflow,segments,length,2,system,arraycopy,p,overflow,segments,0,new,segs,array,0,p,overflow,segments,length,p,overflow,segments,new,segs,array,p,overflow,segments,p,num,overflow,segments,overflow,seg,p,num,overflow,segments,check,for,resize,true,else,overflow,bucket,num,p,num,overflow,segments,1,overflow,seg,p,overflow,segments,overflow,bucket,num,overflow,bucket,offset,p,next,overflow,bucket,p,next,overflow,bucket,p,next,overflow,bucket,this,buckets,per,segment,mask,0,p,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,forward,for,new,bucket,final,long,pointer,to,new,bucket,long,overflow,bucket,num,32,long,overflow,bucket,offset,bucket,put,long,bucket,in,segment,pos,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos, 											int hashCode, long pointer, int partitionNumber) 	throws IOException;1441738685;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos,_											int hashCode, long pointer, int partitionNumber)_	throws IOException_	{_		boolean checkForResize = false__		_		final int count = bucket.getInt(bucketInSegmentPos + HEADER_COUNT_OFFSET)__		if (count < NUM_ENTRIES_PER_BUCKET) {_			_			bucket.putInt(bucketInSegmentPos + BUCKET_HEADER_LENGTH + (count * HASH_CODE_LEN), hashCode)_	_			bucket.putLong(bucketInSegmentPos + BUCKET_POINTER_START_OFFSET + (count * POINTER_LEN), pointer)_ _			bucket.putInt(bucketInSegmentPos + HEADER_COUNT_OFFSET, count + 1)_ _		}_		else {_			_			final InMemoryPartition<T> p = this.partitions.get(partitionNumber)__			_			final long originalForwardPointer = bucket.getLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET)__			final long forwardForNewBucket__			_			if (originalForwardPointer != BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				final int overflowSegNum = (int) (originalForwardPointer >>> 32)__				final int segOffset = (int) originalForwardPointer__				final MemorySegment seg = p.overflowSegments[overflowSegNum]__				_				final int obCount = seg.getInt(segOffset + HEADER_COUNT_OFFSET)__				_				_				if (obCount < NUM_ENTRIES_PER_BUCKET) {_					_					seg.putInt(segOffset + BUCKET_HEADER_LENGTH + (obCount * HASH_CODE_LEN), hashCode)_	_					seg.putLong(segOffset + BUCKET_POINTER_START_OFFSET + (obCount * POINTER_LEN), pointer)_ _					seg.putInt(segOffset + HEADER_COUNT_OFFSET, obCount + 1)_ _					return__				} else {_					_					_					forwardForNewBucket = originalForwardPointer__				}_			} else {_				_				forwardForNewBucket = BUCKET_FORWARD_POINTER_NOT_SET__			}_			_			_			MemorySegment overflowSeg__			final int overflowBucketNum__			final int overflowBucketOffset__			_			_			if (p.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowBucketNum = p.numOverflowSegments__				_				_				if (p.overflowSegments.length <= p.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[p.overflowSegments.length * 2]__					System.arraycopy(p.overflowSegments, 0, newSegsArray, 0, p.overflowSegments.length)__					p.overflowSegments = newSegsArray__				}_				p.overflowSegments[p.numOverflowSegments] = overflowSeg__				p.numOverflowSegments++__				checkForResize = true__			} else {_				_				overflowBucketNum = p.numOverflowSegments - 1__				overflowSeg = p.overflowSegments[overflowBucketNum]__				overflowBucketOffset = p.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			p.nextOverflowBucket = (p.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : p.nextOverflowBucket + 1)__			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, forwardForNewBucket)__			final long pointerToNewBucket = (((long) overflowBucketNum) << 32) | ((long) overflowBucketOffset)__			bucket.putLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_ _			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			_			if (checkForResize && !this.isResizing) {_				_				if (this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,start,memory,segment,bucket,int,bucket,in,segment,pos,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,final,int,count,bucket,get,int,bucket,in,segment,pos,if,count,bucket,put,int,bucket,in,segment,pos,count,hash,code,bucket,put,long,bucket,in,segment,pos,count,pointer,bucket,put,int,bucket,in,segment,pos,count,1,else,final,in,memory,partition,t,p,this,partitions,get,partition,number,final,long,original,forward,pointer,bucket,get,long,bucket,in,segment,pos,final,long,forward,for,new,bucket,if,original,forward,pointer,final,int,overflow,seg,num,int,original,forward,pointer,32,final,int,seg,offset,int,original,forward,pointer,final,memory,segment,seg,p,overflow,segments,overflow,seg,num,final,int,ob,count,seg,get,int,seg,offset,if,ob,count,seg,put,int,seg,offset,ob,count,hash,code,seg,put,long,seg,offset,ob,count,pointer,seg,put,int,seg,offset,ob,count,1,return,else,forward,for,new,bucket,original,forward,pointer,else,forward,for,new,bucket,memory,segment,overflow,seg,final,int,overflow,bucket,num,final,int,overflow,bucket,offset,if,p,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,bucket,num,p,num,overflow,segments,if,p,overflow,segments,length,p,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,p,overflow,segments,length,2,system,arraycopy,p,overflow,segments,0,new,segs,array,0,p,overflow,segments,length,p,overflow,segments,new,segs,array,p,overflow,segments,p,num,overflow,segments,overflow,seg,p,num,overflow,segments,check,for,resize,true,else,overflow,bucket,num,p,num,overflow,segments,1,overflow,seg,p,overflow,segments,overflow,bucket,num,overflow,bucket,offset,p,next,overflow,bucket,p,next,overflow,bucket,p,next,overflow,bucket,this,buckets,per,segment,mask,0,p,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,forward,for,new,bucket,final,long,pointer,to,new,bucket,long,overflow,bucket,num,32,long,overflow,bucket,offset,bucket,put,long,bucket,in,segment,pos,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos, 											int hashCode, long pointer, int partitionNumber) 	throws IOException;1456936114;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos,_											int hashCode, long pointer, int partitionNumber)_	throws IOException_	{_		boolean checkForResize = false__		_		final int count = bucket.getInt(bucketInSegmentPos + HEADER_COUNT_OFFSET)__		if (count < NUM_ENTRIES_PER_BUCKET) {_			_			bucket.putInt(bucketInSegmentPos + BUCKET_HEADER_LENGTH + (count * HASH_CODE_LEN), hashCode)_	_			bucket.putLong(bucketInSegmentPos + BUCKET_POINTER_START_OFFSET + (count * POINTER_LEN), pointer)_ _			bucket.putInt(bucketInSegmentPos + HEADER_COUNT_OFFSET, count + 1)_ _		}_		else {_			_			final InMemoryPartition<T> p = this.partitions.get(partitionNumber)__			_			final long originalForwardPointer = bucket.getLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET)__			final long forwardForNewBucket__			_			if (originalForwardPointer != BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				final int overflowSegNum = (int) (originalForwardPointer >>> 32)__				final int segOffset = (int) originalForwardPointer__				final MemorySegment seg = p.overflowSegments[overflowSegNum]__				_				final int obCount = seg.getInt(segOffset + HEADER_COUNT_OFFSET)__				_				_				if (obCount < NUM_ENTRIES_PER_BUCKET) {_					_					seg.putInt(segOffset + BUCKET_HEADER_LENGTH + (obCount * HASH_CODE_LEN), hashCode)_	_					seg.putLong(segOffset + BUCKET_POINTER_START_OFFSET + (obCount * POINTER_LEN), pointer)_ _					seg.putInt(segOffset + HEADER_COUNT_OFFSET, obCount + 1)_ _					return__				} else {_					_					_					forwardForNewBucket = originalForwardPointer__				}_			} else {_				_				forwardForNewBucket = BUCKET_FORWARD_POINTER_NOT_SET__			}_			_			_			MemorySegment overflowSeg__			final int overflowBucketNum__			final int overflowBucketOffset__			_			_			if (p.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowBucketNum = p.numOverflowSegments__				_				_				if (p.overflowSegments.length <= p.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[p.overflowSegments.length * 2]__					System.arraycopy(p.overflowSegments, 0, newSegsArray, 0, p.overflowSegments.length)__					p.overflowSegments = newSegsArray__				}_				p.overflowSegments[p.numOverflowSegments] = overflowSeg__				p.numOverflowSegments++__				checkForResize = true__			} else {_				_				overflowBucketNum = p.numOverflowSegments - 1__				overflowSeg = p.overflowSegments[overflowBucketNum]__				overflowBucketOffset = p.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			p.nextOverflowBucket = (p.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : p.nextOverflowBucket + 1)__			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, forwardForNewBucket)__			final long pointerToNewBucket = (((long) overflowBucketNum) << 32) | ((long) overflowBucketOffset)__			bucket.putLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_ _			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			_			if (checkForResize && !this.isResizing) {_				_				if (this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,start,memory,segment,bucket,int,bucket,in,segment,pos,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,final,int,count,bucket,get,int,bucket,in,segment,pos,if,count,bucket,put,int,bucket,in,segment,pos,count,hash,code,bucket,put,long,bucket,in,segment,pos,count,pointer,bucket,put,int,bucket,in,segment,pos,count,1,else,final,in,memory,partition,t,p,this,partitions,get,partition,number,final,long,original,forward,pointer,bucket,get,long,bucket,in,segment,pos,final,long,forward,for,new,bucket,if,original,forward,pointer,final,int,overflow,seg,num,int,original,forward,pointer,32,final,int,seg,offset,int,original,forward,pointer,final,memory,segment,seg,p,overflow,segments,overflow,seg,num,final,int,ob,count,seg,get,int,seg,offset,if,ob,count,seg,put,int,seg,offset,ob,count,hash,code,seg,put,long,seg,offset,ob,count,pointer,seg,put,int,seg,offset,ob,count,1,return,else,forward,for,new,bucket,original,forward,pointer,else,forward,for,new,bucket,memory,segment,overflow,seg,final,int,overflow,bucket,num,final,int,overflow,bucket,offset,if,p,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,bucket,num,p,num,overflow,segments,if,p,overflow,segments,length,p,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,p,overflow,segments,length,2,system,arraycopy,p,overflow,segments,0,new,segs,array,0,p,overflow,segments,length,p,overflow,segments,new,segs,array,p,overflow,segments,p,num,overflow,segments,overflow,seg,p,num,overflow,segments,check,for,resize,true,else,overflow,bucket,num,p,num,overflow,segments,1,overflow,seg,p,overflow,segments,overflow,bucket,num,overflow,bucket,offset,p,next,overflow,bucket,p,next,overflow,bucket,p,next,overflow,bucket,this,buckets,per,segment,mask,0,p,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,forward,for,new,bucket,final,long,pointer,to,new,bucket,long,overflow,bucket,num,32,long,overflow,bucket,offset,bucket,put,long,bucket,in,segment,pos,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos, 											int hashCode, long pointer, int partitionNumber) 	throws IOException;1460741894;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos,_											int hashCode, long pointer, int partitionNumber)_	throws IOException_	{_		boolean checkForResize = false__		_		final int count = bucket.getInt(bucketInSegmentPos + HEADER_COUNT_OFFSET)__		if (count < NUM_ENTRIES_PER_BUCKET) {_			_			bucket.putInt(bucketInSegmentPos + BUCKET_HEADER_LENGTH + (count * HASH_CODE_LEN), hashCode)_	_			bucket.putLong(bucketInSegmentPos + BUCKET_POINTER_START_OFFSET + (count * POINTER_LEN), pointer)_ _			bucket.putInt(bucketInSegmentPos + HEADER_COUNT_OFFSET, count + 1)_ _		}_		else {_			_			final InMemoryPartition<T> p = this.partitions.get(partitionNumber)__			_			final long originalForwardPointer = bucket.getLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET)__			final long forwardForNewBucket__			_			if (originalForwardPointer != BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				final int overflowSegNum = (int) (originalForwardPointer >>> 32)__				final int segOffset = (int) originalForwardPointer__				final MemorySegment seg = p.overflowSegments[overflowSegNum]__				_				final int obCount = seg.getInt(segOffset + HEADER_COUNT_OFFSET)__				_				_				if (obCount < NUM_ENTRIES_PER_BUCKET) {_					_					seg.putInt(segOffset + BUCKET_HEADER_LENGTH + (obCount * HASH_CODE_LEN), hashCode)_	_					seg.putLong(segOffset + BUCKET_POINTER_START_OFFSET + (obCount * POINTER_LEN), pointer)_ _					seg.putInt(segOffset + HEADER_COUNT_OFFSET, obCount + 1)_ _					return__				} else {_					_					_					forwardForNewBucket = originalForwardPointer__				}_			} else {_				_				forwardForNewBucket = BUCKET_FORWARD_POINTER_NOT_SET__			}_			_			_			MemorySegment overflowSeg__			final int overflowBucketNum__			final int overflowBucketOffset__			_			_			if (p.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowBucketNum = p.numOverflowSegments__				_				_				if (p.overflowSegments.length <= p.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[p.overflowSegments.length * 2]__					System.arraycopy(p.overflowSegments, 0, newSegsArray, 0, p.overflowSegments.length)__					p.overflowSegments = newSegsArray__				}_				p.overflowSegments[p.numOverflowSegments] = overflowSeg__				p.numOverflowSegments++__				checkForResize = true__			} else {_				_				overflowBucketNum = p.numOverflowSegments - 1__				overflowSeg = p.overflowSegments[overflowBucketNum]__				overflowBucketOffset = p.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			p.nextOverflowBucket = (p.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : p.nextOverflowBucket + 1)__			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, forwardForNewBucket)__			final long pointerToNewBucket = (((long) overflowBucketNum) << 32) | ((long) overflowBucketOffset)__			bucket.putLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_ _			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			_			if (checkForResize && !this.isResizing) {_				_				if (this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,start,memory,segment,bucket,int,bucket,in,segment,pos,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,final,int,count,bucket,get,int,bucket,in,segment,pos,if,count,bucket,put,int,bucket,in,segment,pos,count,hash,code,bucket,put,long,bucket,in,segment,pos,count,pointer,bucket,put,int,bucket,in,segment,pos,count,1,else,final,in,memory,partition,t,p,this,partitions,get,partition,number,final,long,original,forward,pointer,bucket,get,long,bucket,in,segment,pos,final,long,forward,for,new,bucket,if,original,forward,pointer,final,int,overflow,seg,num,int,original,forward,pointer,32,final,int,seg,offset,int,original,forward,pointer,final,memory,segment,seg,p,overflow,segments,overflow,seg,num,final,int,ob,count,seg,get,int,seg,offset,if,ob,count,seg,put,int,seg,offset,ob,count,hash,code,seg,put,long,seg,offset,ob,count,pointer,seg,put,int,seg,offset,ob,count,1,return,else,forward,for,new,bucket,original,forward,pointer,else,forward,for,new,bucket,memory,segment,overflow,seg,final,int,overflow,bucket,num,final,int,overflow,bucket,offset,if,p,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,bucket,num,p,num,overflow,segments,if,p,overflow,segments,length,p,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,p,overflow,segments,length,2,system,arraycopy,p,overflow,segments,0,new,segs,array,0,p,overflow,segments,length,p,overflow,segments,new,segs,array,p,overflow,segments,p,num,overflow,segments,overflow,seg,p,num,overflow,segments,check,for,resize,true,else,overflow,bucket,num,p,num,overflow,segments,1,overflow,seg,p,overflow,segments,overflow,bucket,num,overflow,bucket,offset,p,next,overflow,bucket,p,next,overflow,bucket,p,next,overflow,bucket,this,buckets,per,segment,mask,0,p,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,forward,for,new,bucket,final,long,pointer,to,new,bucket,long,overflow,bucket,num,32,long,overflow,bucket,offset,bucket,put,long,bucket,in,segment,pos,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos, 											int hashCode, long pointer, int partitionNumber) 	throws IOException;1468441547;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos,_											int hashCode, long pointer, int partitionNumber)_	throws IOException_	{_		boolean checkForResize = false__		_		final int count = bucket.getInt(bucketInSegmentPos + HEADER_COUNT_OFFSET)__		if (count < NUM_ENTRIES_PER_BUCKET) {_			_			bucket.putInt(bucketInSegmentPos + BUCKET_HEADER_LENGTH + (count * HASH_CODE_LEN), hashCode)_	_			bucket.putLong(bucketInSegmentPos + BUCKET_POINTER_START_OFFSET + (count * POINTER_LEN), pointer)_ _			bucket.putInt(bucketInSegmentPos + HEADER_COUNT_OFFSET, count + 1)_ _		}_		else {_			_			final InMemoryPartition<T> p = this.partitions.get(partitionNumber)__			_			final long originalForwardPointer = bucket.getLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET)__			final long forwardForNewBucket__			_			if (originalForwardPointer != BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				final int overflowSegNum = (int) (originalForwardPointer >>> 32)__				final int segOffset = (int) originalForwardPointer__				final MemorySegment seg = p.overflowSegments[overflowSegNum]__				_				final int obCount = seg.getInt(segOffset + HEADER_COUNT_OFFSET)__				_				_				if (obCount < NUM_ENTRIES_PER_BUCKET) {_					_					seg.putInt(segOffset + BUCKET_HEADER_LENGTH + (obCount * HASH_CODE_LEN), hashCode)_	_					seg.putLong(segOffset + BUCKET_POINTER_START_OFFSET + (obCount * POINTER_LEN), pointer)_ _					seg.putInt(segOffset + HEADER_COUNT_OFFSET, obCount + 1)_ _					return__				} else {_					_					_					forwardForNewBucket = originalForwardPointer__				}_			} else {_				_				forwardForNewBucket = BUCKET_FORWARD_POINTER_NOT_SET__			}_			_			_			MemorySegment overflowSeg__			final int overflowBucketNum__			final int overflowBucketOffset__			_			_			if (p.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowBucketNum = p.numOverflowSegments__				_				_				if (p.overflowSegments.length <= p.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[p.overflowSegments.length * 2]__					System.arraycopy(p.overflowSegments, 0, newSegsArray, 0, p.overflowSegments.length)__					p.overflowSegments = newSegsArray__				}_				p.overflowSegments[p.numOverflowSegments] = overflowSeg__				p.numOverflowSegments++__				checkForResize = true__			} else {_				_				overflowBucketNum = p.numOverflowSegments - 1__				overflowSeg = p.overflowSegments[overflowBucketNum]__				overflowBucketOffset = p.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			p.nextOverflowBucket = (p.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : p.nextOverflowBucket + 1)__			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, forwardForNewBucket)__			final long pointerToNewBucket = (((long) overflowBucketNum) << 32) | ((long) overflowBucketOffset)__			bucket.putLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_ _			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			_			if (checkForResize && !this.isResizing) {_				_				if (this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,start,memory,segment,bucket,int,bucket,in,segment,pos,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,final,int,count,bucket,get,int,bucket,in,segment,pos,if,count,bucket,put,int,bucket,in,segment,pos,count,hash,code,bucket,put,long,bucket,in,segment,pos,count,pointer,bucket,put,int,bucket,in,segment,pos,count,1,else,final,in,memory,partition,t,p,this,partitions,get,partition,number,final,long,original,forward,pointer,bucket,get,long,bucket,in,segment,pos,final,long,forward,for,new,bucket,if,original,forward,pointer,final,int,overflow,seg,num,int,original,forward,pointer,32,final,int,seg,offset,int,original,forward,pointer,final,memory,segment,seg,p,overflow,segments,overflow,seg,num,final,int,ob,count,seg,get,int,seg,offset,if,ob,count,seg,put,int,seg,offset,ob,count,hash,code,seg,put,long,seg,offset,ob,count,pointer,seg,put,int,seg,offset,ob,count,1,return,else,forward,for,new,bucket,original,forward,pointer,else,forward,for,new,bucket,memory,segment,overflow,seg,final,int,overflow,bucket,num,final,int,overflow,bucket,offset,if,p,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,bucket,num,p,num,overflow,segments,if,p,overflow,segments,length,p,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,p,overflow,segments,length,2,system,arraycopy,p,overflow,segments,0,new,segs,array,0,p,overflow,segments,length,p,overflow,segments,new,segs,array,p,overflow,segments,p,num,overflow,segments,overflow,seg,p,num,overflow,segments,check,for,resize,true,else,overflow,bucket,num,p,num,overflow,segments,1,overflow,seg,p,overflow,segments,overflow,bucket,num,overflow,bucket,offset,p,next,overflow,bucket,p,next,overflow,bucket,p,next,overflow,bucket,this,buckets,per,segment,mask,0,p,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,forward,for,new,bucket,final,long,pointer,to,new,bucket,long,overflow,bucket,num,32,long,overflow,bucket,offset,bucket,put,long,bucket,in,segment,pos,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
CompactingHashTable -> private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos, 											int hashCode, long pointer, int partitionNumber) 	throws IOException;1494520945;IMPORTANT!!! We pass only the partition number, because we must make sure we get a fresh_partition reference. The partition reference used during search for the key may have become_invalid during the compaction.;private void insertBucketEntryFromStart(MemorySegment bucket, int bucketInSegmentPos,_											int hashCode, long pointer, int partitionNumber)_	throws IOException_	{_		boolean checkForResize = false__		_		final int count = bucket.getInt(bucketInSegmentPos + HEADER_COUNT_OFFSET)__		if (count < NUM_ENTRIES_PER_BUCKET) {_			_			bucket.putInt(bucketInSegmentPos + BUCKET_HEADER_LENGTH + (count * HASH_CODE_LEN), hashCode)_	_			bucket.putLong(bucketInSegmentPos + BUCKET_POINTER_START_OFFSET + (count * POINTER_LEN), pointer)_ _			bucket.putInt(bucketInSegmentPos + HEADER_COUNT_OFFSET, count + 1)_ _		}_		else {_			_			final InMemoryPartition<T> p = this.partitions.get(partitionNumber)__			_			final long originalForwardPointer = bucket.getLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET)__			final long forwardForNewBucket__			_			if (originalForwardPointer != BUCKET_FORWARD_POINTER_NOT_SET) {_				_				_				final int overflowSegNum = (int) (originalForwardPointer >>> 32)__				final int segOffset = (int) originalForwardPointer__				final MemorySegment seg = p.overflowSegments[overflowSegNum]__				_				final int obCount = seg.getInt(segOffset + HEADER_COUNT_OFFSET)__				_				_				if (obCount < NUM_ENTRIES_PER_BUCKET) {_					_					seg.putInt(segOffset + BUCKET_HEADER_LENGTH + (obCount * HASH_CODE_LEN), hashCode)_	_					seg.putLong(segOffset + BUCKET_POINTER_START_OFFSET + (obCount * POINTER_LEN), pointer)_ _					seg.putInt(segOffset + HEADER_COUNT_OFFSET, obCount + 1)_ _					return__				} else {_					_					_					forwardForNewBucket = originalForwardPointer__				}_			} else {_				_				forwardForNewBucket = BUCKET_FORWARD_POINTER_NOT_SET__			}_			_			_			MemorySegment overflowSeg__			final int overflowBucketNum__			final int overflowBucketOffset__			_			_			if (p.nextOverflowBucket == 0) {_				_				overflowSeg = getNextBuffer()__				overflowBucketOffset = 0__				overflowBucketNum = p.numOverflowSegments__				_				_				if (p.overflowSegments.length <= p.numOverflowSegments) {_					MemorySegment[] newSegsArray = new MemorySegment[p.overflowSegments.length * 2]__					System.arraycopy(p.overflowSegments, 0, newSegsArray, 0, p.overflowSegments.length)__					p.overflowSegments = newSegsArray__				}_				p.overflowSegments[p.numOverflowSegments] = overflowSeg__				p.numOverflowSegments++__				checkForResize = true__			} else {_				_				overflowBucketNum = p.numOverflowSegments - 1__				overflowSeg = p.overflowSegments[overflowBucketNum]__				overflowBucketOffset = p.nextOverflowBucket << NUM_INTRA_BUCKET_BITS__			}_			_			_			_			p.nextOverflowBucket = (p.nextOverflowBucket == this.bucketsPerSegmentMask ? 0 : p.nextOverflowBucket + 1)__			_			_			_			_			overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, forwardForNewBucket)__			final long pointerToNewBucket = (((long) overflowBucketNum) << 32) | ((long) overflowBucketOffset)__			bucket.putLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET, pointerToNewBucket)__			_			_			overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode)_ _			overflowSeg.putLong(overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer)_ _			_			_			overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1)__			_			if (checkForResize && !this.isResizing) {_				_				if (this.buckets.length <= getOverflowSegmentCount()) {_					resizeHashTable()__				}_			}_		}_	};important,we,pass,only,the,partition,number,because,we,must,make,sure,we,get,a,fresh,partition,reference,the,partition,reference,used,during,search,for,the,key,may,have,become,invalid,during,the,compaction;private,void,insert,bucket,entry,from,start,memory,segment,bucket,int,bucket,in,segment,pos,int,hash,code,long,pointer,int,partition,number,throws,ioexception,boolean,check,for,resize,false,final,int,count,bucket,get,int,bucket,in,segment,pos,if,count,bucket,put,int,bucket,in,segment,pos,count,hash,code,bucket,put,long,bucket,in,segment,pos,count,pointer,bucket,put,int,bucket,in,segment,pos,count,1,else,final,in,memory,partition,t,p,this,partitions,get,partition,number,final,long,original,forward,pointer,bucket,get,long,bucket,in,segment,pos,final,long,forward,for,new,bucket,if,original,forward,pointer,final,int,overflow,seg,num,int,original,forward,pointer,32,final,int,seg,offset,int,original,forward,pointer,final,memory,segment,seg,p,overflow,segments,overflow,seg,num,final,int,ob,count,seg,get,int,seg,offset,if,ob,count,seg,put,int,seg,offset,ob,count,hash,code,seg,put,long,seg,offset,ob,count,pointer,seg,put,int,seg,offset,ob,count,1,return,else,forward,for,new,bucket,original,forward,pointer,else,forward,for,new,bucket,memory,segment,overflow,seg,final,int,overflow,bucket,num,final,int,overflow,bucket,offset,if,p,next,overflow,bucket,0,overflow,seg,get,next,buffer,overflow,bucket,offset,0,overflow,bucket,num,p,num,overflow,segments,if,p,overflow,segments,length,p,num,overflow,segments,memory,segment,new,segs,array,new,memory,segment,p,overflow,segments,length,2,system,arraycopy,p,overflow,segments,0,new,segs,array,0,p,overflow,segments,length,p,overflow,segments,new,segs,array,p,overflow,segments,p,num,overflow,segments,overflow,seg,p,num,overflow,segments,check,for,resize,true,else,overflow,bucket,num,p,num,overflow,segments,1,overflow,seg,p,overflow,segments,overflow,bucket,num,overflow,bucket,offset,p,next,overflow,bucket,p,next,overflow,bucket,p,next,overflow,bucket,this,buckets,per,segment,mask,0,p,next,overflow,bucket,1,overflow,seg,put,long,overflow,bucket,offset,forward,for,new,bucket,final,long,pointer,to,new,bucket,long,overflow,bucket,num,32,long,overflow,bucket,offset,bucket,put,long,bucket,in,segment,pos,pointer,to,new,bucket,overflow,seg,put,int,overflow,bucket,offset,hash,code,overflow,seg,put,long,overflow,bucket,offset,pointer,overflow,seg,put,int,overflow,bucket,offset,1,if,check,for,resize,this,is,resizing,if,this,buckets,length,get,overflow,segment,count,resize,hash,table
