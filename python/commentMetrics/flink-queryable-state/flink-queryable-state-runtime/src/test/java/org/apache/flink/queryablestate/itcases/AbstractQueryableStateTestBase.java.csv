# id;timestamp;commentText;codeText;commentWords;codeWords
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1509037054;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_					"list",_					BasicTypeInfo.LONG_TYPE_INFO)__			listStateDescriptor.setQueryable("list-queryable")___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 8470749712274833552L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_				private static final long serialVersionUID = -805125545438296619L___				private transient ListState<Long> listState___				@Override_				public void open(Configuration parameters) throws Exception {_					super.open(parameters)__					listState = getRuntimeContext().getListState(listStateDescriptor)__				}__				@Override_				public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_					listState.add(value.f1)__				}_			})___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			__			Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ListState<Long>> future = getKvStateWithRetries(_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							QUERY_RETRY_DELAY,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,list,state,long,future,get,kv,state,with,retries,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1510910970;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_					"list",_					BasicTypeInfo.LONG_TYPE_INFO)__			listStateDescriptor.setQueryable("list-queryable")___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 8470749712274833552L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_				private static final long serialVersionUID = -805125545438296619L___				private transient ListState<Long> listState___				@Override_				public void open(Configuration parameters) throws Exception {_					super.open(parameters)__					listState = getRuntimeContext().getListState(listStateDescriptor)__				}__				@Override_				public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_					listState.add(value.f1)__				}_			})___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			__			Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					final CompletableFuture<ListState<Long>> future = getKvState(_							deadline,_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,final,completable,future,list,state,long,future,get,kv,state,deadline,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1510911968;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_					"list",_					BasicTypeInfo.LONG_TYPE_INFO)__			listStateDescriptor.setQueryable("list-queryable")___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 8470749712274833552L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_				private static final long serialVersionUID = -805125545438296619L___				private transient ListState<Long> listState___				@Override_				public void open(Configuration parameters) throws Exception {_					super.open(parameters)__					listState = getRuntimeContext().getListState(listStateDescriptor)__				}__				@Override_				public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_					listState.add(value.f1)__				}_			})___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			__			Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					final CompletableFuture<ListState<Long>> future = getKvState(_							deadline,_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,final,completable,future,list,state,long,future,get,kv,state,deadline,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1510911970;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_					"list",_					BasicTypeInfo.LONG_TYPE_INFO)__			listStateDescriptor.setQueryable("list-queryable")___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 8470749712274833552L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_				private static final long serialVersionUID = -805125545438296619L___				private transient ListState<Long> listState___				@Override_				public void open(Configuration parameters) throws Exception {_					super.open(parameters)__					listState = getRuntimeContext().getListState(listStateDescriptor)__				}__				@Override_				public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_					listState.add(value.f1)__				}_			})___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			__			Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					final CompletableFuture<ListState<Long>> future = getKvState(_							deadline,_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,final,completable,future,list,state,long,future,get,kv,state,deadline,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1512567208;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_				"list", BasicTypeInfo.LONG_TYPE_INFO)__		listStateDescriptor.setQueryable("list-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient ListState<Long> listState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				listState = getRuntimeContext().getListState(listStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				listState.add(value.f1)__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					final CompletableFuture<ListState<Long>> future = getKvState(_							deadline,_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,final,completable,future,list,state,long,future,get,kv,state,deadline,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1513261599;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_				"list", BasicTypeInfo.LONG_TYPE_INFO)__		listStateDescriptor.setQueryable("list-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient ListState<Long> listState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				listState = getRuntimeContext().getListState(listStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				listState.add(value.f1)__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					final CompletableFuture<ListState<Long>> future = getKvState(_							deadline,_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,final,completable,future,list,state,long,future,get,kv,state,deadline,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1516812618;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_				"list", BasicTypeInfo.LONG_TYPE_INFO)__		listStateDescriptor.setQueryable("list-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient ListState<Long> listState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				listState = getRuntimeContext().getListState(listStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				listState.add(value.f1)__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					final CompletableFuture<ListState<Long>> future = getKvState(_							deadline,_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,final,completable,future,list,state,long,future,get,kv,state,deadline,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1520781441;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_				"list", BasicTypeInfo.LONG_TYPE_INFO)__		listStateDescriptor.setQueryable("list-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient ListState<Long> listState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				listState = getRuntimeContext().getListState(listStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				listState.add(value.f1)__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					final CompletableFuture<ListState<Long>> future = getKvState(_							deadline,_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,final,completable,future,list,state,long,future,get,kv,state,deadline,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1541420597;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_				"list", BasicTypeInfo.LONG_TYPE_INFO)__		listStateDescriptor.setQueryable("list-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient ListState<Long> listState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				listState = getRuntimeContext().getListState(listStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				listState.add(value.f1)__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					final CompletableFuture<ListState<Long>> future = getKvState(_							deadline,_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,final,completable,future,list,state,long,future,get,kv,state,deadline,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1542282018;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_				"list", BasicTypeInfo.LONG_TYPE_INFO)__		listStateDescriptor.setQueryable("list-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient ListState<Long> listState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				listState = getRuntimeContext().getListState(listStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				listState.add(value.f1)__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					final CompletableFuture<ListState<Long>> future = getKvState(_							deadline,_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,final,completable,future,list,state,long,future,get,kv,state,deadline,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1547024365;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_				"list", BasicTypeInfo.LONG_TYPE_INFO)__		listStateDescriptor.setQueryable("list-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient ListState<Long> listState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				listState = getRuntimeContext().getListState(listStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				listState.add(value.f1)__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					final CompletableFuture<ListState<Long>> future = getKvState(_							deadline,_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,final,completable,future,list,state,long,future,get,kv,state,deadline,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1547024365;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_				"list", BasicTypeInfo.LONG_TYPE_INFO)__		listStateDescriptor.setQueryable("list-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient ListState<Long> listState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				listState = getRuntimeContext().getListState(listStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				listState.add(value.f1)__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					final CompletableFuture<ListState<Long>> future = getKvState(_							deadline,_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,final,completable,future,list,state,long,future,get,kv,state,deadline,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i
AbstractQueryableStateTestBase -> @Test 	public void testListState() throws Exception;1547024365;Tests simple list state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The list state instance add the values to the list. The test_succeeds after each subtask index is queried and the list contains_the correct number of distinct elements.;@Test_	public void testListState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final ListStateDescriptor<Long> listStateDescriptor = new ListStateDescriptor<Long>(_				"list", BasicTypeInfo.LONG_TYPE_INFO)__		listStateDescriptor.setQueryable("list-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient ListState<Long> listState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				listState = getRuntimeContext().getListState(listStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				listState.add(value.f1)__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final Map<Integer, Set<Long>> results = new HashMap<>()___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					final CompletableFuture<ListState<Long>> future = getKvState(_							deadline,_							client,_							jobId,_							"list-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							listStateDescriptor,_							false,_							executor)___					Iterable<Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					Set<Long> res = new HashSet<>()__					for (Long v: value) {_						res.add(v)__					}__					_					if (res.size() == numElements + 1L) {_						success = true__						results.put(key, res)__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}__			for (int key = 0_ key < maxParallelism_ key++) {_				Set<Long> values = results.get(key)__				for (long i = 0L_ i <= numElements_ i++) {_					assertTrue(values.contains(i))__				}_			}__		}_	};tests,simple,list,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,list,state,instance,add,the,values,to,the,list,the,test,succeeds,after,each,subtask,index,is,queried,and,the,list,contains,the,correct,number,of,distinct,elements;test,public,void,test,list,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,list,state,descriptor,long,list,state,descriptor,new,list,state,descriptor,long,list,basic,type,info,list,state,descriptor,set,queryable,list,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,list,state,long,list,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,list,state,get,runtime,context,get,list,state,list,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,list,state,add,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,map,integer,set,long,results,new,hash,map,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,final,completable,future,list,state,long,future,get,kv,state,deadline,client,job,id,list,queryable,key,basic,type,info,list,state,descriptor,false,executor,iterable,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,set,long,res,new,hash,set,for,long,v,value,res,add,v,if,res,size,num,elements,1l,success,true,results,put,key,res,else,thread,sleep,assert,true,did,not,succeed,query,success,for,int,key,0,key,max,parallelism,key,set,long,values,results,get,key,for,long,i,0l,i,num,elements,i,assert,true,values,contains,i
AbstractQueryableStateTestBase -> protected abstract StateBackend createStateBackend() throws Exception_;1547024365;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract StateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> protected abstract StateBackend createStateBackend() throws Exception_;1547024365;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract StateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> protected abstract StateBackend createStateBackend() throws Exception_;1547024365;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract StateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> @Test 	@Ignore 	public void testWrongJobIdAndWrongQueryableStateName() throws Exception;1512567208;Tests that the correct exception is thrown if the query_contains a wrong jobId or wrong queryable state name.;@Test_	@Ignore_	public void testWrongJobIdAndWrongQueryableStateName() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))__		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob closableJobGraph = new AutoCancellableJob(cluster, env, deadline)) {__			_			CompletableFuture<TestingJobManagerMessages.JobStatusIs> runningFuture =_					notifyWhenJobStatusIs(closableJobGraph.getJobId(), JobStatus.RUNNING, deadline)___			cluster.submitJobDetached(closableJobGraph.getJobGraph())___			_			TestingJobManagerMessages.JobStatusIs jobStatus =_					runningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			assertEquals(JobStatus.RUNNING, jobStatus.state())___			final JobID wrongJobId = new JobID()___			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownJobFuture = client.getKvState(_					wrongJobId, 						_					"hakuna",_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownJobFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"FlinkJobNotFoundException: Could not find Flink job (" + wrongJobId + ")"))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownQSName = client.getKvState(_					closableJobGraph.getJobId(),_					"wrong-hakuna", _					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownQSName.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"UnknownKvStateLocation: No KvStateLocation found for KvState instance with name 'wrong-hakuna'."))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}_		}_	};tests,that,the,correct,exception,is,thrown,if,the,query,contains,a,wrong,job,id,or,wrong,queryable,state,name;test,ignore,public,void,test,wrong,job,id,and,wrong,queryable,state,name,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,closable,job,graph,new,auto,cancellable,job,cluster,env,deadline,completable,future,testing,job,manager,messages,job,status,is,running,future,notify,when,job,status,is,closable,job,graph,get,job,id,job,status,running,deadline,cluster,submit,job,detached,closable,job,graph,get,job,graph,testing,job,manager,messages,job,status,is,job,status,running,future,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,equals,job,status,running,job,status,state,final,job,id,wrong,job,id,new,job,id,completable,future,value,state,tuple2,integer,long,unknown,job,future,client,get,kv,state,wrong,job,id,hakuna,0,basic,type,info,value,state,try,unknown,job,future,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,flink,job,not,found,exception,could,not,find,flink,job,wrong,job,id,catch,exception,f,fail,unexpected,type,of,exception,f,get,message,completable,future,value,state,tuple2,integer,long,unknown,qsname,client,get,kv,state,closable,job,graph,get,job,id,wrong,hakuna,0,basic,type,info,value,state,try,unknown,qsname,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,unknown,kv,state,location,no,kv,state,location,found,for,kv,state,instance,with,name,wrong,hakuna,catch,exception,f,fail,unexpected,type,of,exception,f,get,message
AbstractQueryableStateTestBase -> @Test 	@Ignore 	public void testWrongJobIdAndWrongQueryableStateName() throws Exception;1513261599;Tests that the correct exception is thrown if the query_contains a wrong jobId or wrong queryable state name.;@Test_	@Ignore_	public void testWrongJobIdAndWrongQueryableStateName() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))__		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob closableJobGraph = new AutoCancellableJob(cluster, env, deadline)) {__			_			CompletableFuture<TestingJobManagerMessages.JobStatusIs> runningFuture =_					notifyWhenJobStatusIs(closableJobGraph.getJobId(), JobStatus.RUNNING, deadline)___			cluster.submitJobDetached(closableJobGraph.getJobGraph())___			_			TestingJobManagerMessages.JobStatusIs jobStatus =_					runningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			assertEquals(JobStatus.RUNNING, jobStatus.state())___			final JobID wrongJobId = new JobID()___			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownJobFuture = client.getKvState(_					wrongJobId, 						_					"hakuna",_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownJobFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"FlinkJobNotFoundException: Could not find Flink job (" + wrongJobId + ")"))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownQSName = client.getKvState(_					closableJobGraph.getJobId(),_					"wrong-hakuna", _					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownQSName.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"UnknownKvStateLocation: No KvStateLocation found for KvState instance with name 'wrong-hakuna'."))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}_		}_	};tests,that,the,correct,exception,is,thrown,if,the,query,contains,a,wrong,job,id,or,wrong,queryable,state,name;test,ignore,public,void,test,wrong,job,id,and,wrong,queryable,state,name,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,closable,job,graph,new,auto,cancellable,job,cluster,env,deadline,completable,future,testing,job,manager,messages,job,status,is,running,future,notify,when,job,status,is,closable,job,graph,get,job,id,job,status,running,deadline,cluster,submit,job,detached,closable,job,graph,get,job,graph,testing,job,manager,messages,job,status,is,job,status,running,future,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,equals,job,status,running,job,status,state,final,job,id,wrong,job,id,new,job,id,completable,future,value,state,tuple2,integer,long,unknown,job,future,client,get,kv,state,wrong,job,id,hakuna,0,basic,type,info,value,state,try,unknown,job,future,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,flink,job,not,found,exception,could,not,find,flink,job,wrong,job,id,catch,exception,f,fail,unexpected,type,of,exception,f,get,message,completable,future,value,state,tuple2,integer,long,unknown,qsname,client,get,kv,state,closable,job,graph,get,job,id,wrong,hakuna,0,basic,type,info,value,state,try,unknown,qsname,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,unknown,kv,state,location,no,kv,state,location,found,for,kv,state,instance,with,name,wrong,hakuna,catch,exception,f,fail,unexpected,type,of,exception,f,get,message
AbstractQueryableStateTestBase -> @Test 	@Ignore 	public void testWrongJobIdAndWrongQueryableStateName() throws Exception;1516812618;Tests that the correct exception is thrown if the query_contains a wrong jobId or wrong queryable state name.;@Test_	@Ignore_	public void testWrongJobIdAndWrongQueryableStateName() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))__		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob closableJobGraph = new AutoCancellableJob(cluster, env, deadline)) {__			_			CompletableFuture<TestingJobManagerMessages.JobStatusIs> runningFuture =_					notifyWhenJobStatusIs(closableJobGraph.getJobId(), JobStatus.RUNNING, deadline)___			cluster.submitJobDetached(closableJobGraph.getJobGraph())___			_			TestingJobManagerMessages.JobStatusIs jobStatus =_					runningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			assertEquals(JobStatus.RUNNING, jobStatus.state())___			final JobID wrongJobId = new JobID()___			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownJobFuture = client.getKvState(_					wrongJobId, 						_					"hakuna",_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownJobFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"FlinkJobNotFoundException: Could not find Flink job (" + wrongJobId + ")"))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownQSName = client.getKvState(_					closableJobGraph.getJobId(),_					"wrong-hakuna", _					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownQSName.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"UnknownKvStateLocation: No KvStateLocation found for KvState instance with name 'wrong-hakuna'."))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}_		}_	};tests,that,the,correct,exception,is,thrown,if,the,query,contains,a,wrong,job,id,or,wrong,queryable,state,name;test,ignore,public,void,test,wrong,job,id,and,wrong,queryable,state,name,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,closable,job,graph,new,auto,cancellable,job,cluster,env,deadline,completable,future,testing,job,manager,messages,job,status,is,running,future,notify,when,job,status,is,closable,job,graph,get,job,id,job,status,running,deadline,cluster,submit,job,detached,closable,job,graph,get,job,graph,testing,job,manager,messages,job,status,is,job,status,running,future,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,equals,job,status,running,job,status,state,final,job,id,wrong,job,id,new,job,id,completable,future,value,state,tuple2,integer,long,unknown,job,future,client,get,kv,state,wrong,job,id,hakuna,0,basic,type,info,value,state,try,unknown,job,future,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,flink,job,not,found,exception,could,not,find,flink,job,wrong,job,id,catch,exception,f,fail,unexpected,type,of,exception,f,get,message,completable,future,value,state,tuple2,integer,long,unknown,qsname,client,get,kv,state,closable,job,graph,get,job,id,wrong,hakuna,0,basic,type,info,value,state,try,unknown,qsname,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,unknown,kv,state,location,no,kv,state,location,found,for,kv,state,instance,with,name,wrong,hakuna,catch,exception,f,fail,unexpected,type,of,exception,f,get,message
AbstractQueryableStateTestBase -> @Test 	@Ignore 	public void testWrongJobIdAndWrongQueryableStateName() throws Exception;1520781441;Tests that the correct exception is thrown if the query_contains a wrong jobId or wrong queryable state name.;@Test_	@Ignore_	public void testWrongJobIdAndWrongQueryableStateName() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))__		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob closableJobGraph = new AutoCancellableJob(deadline, clusterClient, env)) {__			clusterClient.setDetached(true)__			clusterClient.submitJob(_				closableJobGraph.getJobGraph(), AbstractQueryableStateTestBase.class.getClassLoader())___			CompletableFuture<JobStatus> jobStatusFuture =_				clusterClient.getJobStatus(closableJobGraph.getJobId())___			while (deadline.hasTimeLeft() && !jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).equals(JobStatus.RUNNING)) {_				Thread.sleep(50)__				jobStatusFuture =_					clusterClient.getJobStatus(closableJobGraph.getJobId())__			}__			assertEquals(JobStatus.RUNNING, jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS))___			final JobID wrongJobId = new JobID()___			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownJobFuture = client.getKvState(_					wrongJobId, 						_					"hakuna",_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownJobFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"FlinkJobNotFoundException: Could not find Flink job (" + wrongJobId + ")"))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownQSName = client.getKvState(_					closableJobGraph.getJobId(),_					"wrong-hakuna", _					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownQSName.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"UnknownKvStateLocation: No KvStateLocation found for KvState instance with name 'wrong-hakuna'."))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}_		}_	};tests,that,the,correct,exception,is,thrown,if,the,query,contains,a,wrong,job,id,or,wrong,queryable,state,name;test,ignore,public,void,test,wrong,job,id,and,wrong,queryable,state,name,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,closable,job,graph,new,auto,cancellable,job,deadline,cluster,client,env,cluster,client,set,detached,true,cluster,client,submit,job,closable,job,graph,get,job,graph,abstract,queryable,state,test,base,class,get,class,loader,completable,future,job,status,job,status,future,cluster,client,get,job,status,closable,job,graph,get,job,id,while,deadline,has,time,left,job,status,future,get,deadline,time,left,to,millis,time,unit,milliseconds,equals,job,status,running,thread,sleep,50,job,status,future,cluster,client,get,job,status,closable,job,graph,get,job,id,assert,equals,job,status,running,job,status,future,get,deadline,time,left,to,millis,time,unit,milliseconds,final,job,id,wrong,job,id,new,job,id,completable,future,value,state,tuple2,integer,long,unknown,job,future,client,get,kv,state,wrong,job,id,hakuna,0,basic,type,info,value,state,try,unknown,job,future,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,flink,job,not,found,exception,could,not,find,flink,job,wrong,job,id,catch,exception,f,fail,unexpected,type,of,exception,f,get,message,completable,future,value,state,tuple2,integer,long,unknown,qsname,client,get,kv,state,closable,job,graph,get,job,id,wrong,hakuna,0,basic,type,info,value,state,try,unknown,qsname,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,unknown,kv,state,location,no,kv,state,location,found,for,kv,state,instance,with,name,wrong,hakuna,catch,exception,f,fail,unexpected,type,of,exception,f,get,message
AbstractQueryableStateTestBase -> @Test 	@Ignore 	public void testWrongJobIdAndWrongQueryableStateName() throws Exception;1541420597;Tests that the correct exception is thrown if the query_contains a wrong jobId or wrong queryable state name.;@Test_	@Ignore_	public void testWrongJobIdAndWrongQueryableStateName() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))__		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob closableJobGraph = new AutoCancellableJob(deadline, clusterClient, env)) {__			clusterClient.setDetached(true)__			clusterClient.submitJob(_				closableJobGraph.getJobGraph(), AbstractQueryableStateTestBase.class.getClassLoader())___			CompletableFuture<JobStatus> jobStatusFuture =_				clusterClient.getJobStatus(closableJobGraph.getJobId())___			while (deadline.hasTimeLeft() && !jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).equals(JobStatus.RUNNING)) {_				Thread.sleep(50)__				jobStatusFuture =_					clusterClient.getJobStatus(closableJobGraph.getJobId())__			}__			assertEquals(JobStatus.RUNNING, jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS))___			final JobID wrongJobId = new JobID()___			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownJobFuture = client.getKvState(_					wrongJobId, 						_					"hakuna",_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownJobFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"FlinkJobNotFoundException: Could not find Flink job (" + wrongJobId + ")"))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownQSName = client.getKvState(_					closableJobGraph.getJobId(),_					"wrong-hakuna", _					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownQSName.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"UnknownKvStateLocation: No KvStateLocation found for KvState instance with name 'wrong-hakuna'."))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}_		}_	};tests,that,the,correct,exception,is,thrown,if,the,query,contains,a,wrong,job,id,or,wrong,queryable,state,name;test,ignore,public,void,test,wrong,job,id,and,wrong,queryable,state,name,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,closable,job,graph,new,auto,cancellable,job,deadline,cluster,client,env,cluster,client,set,detached,true,cluster,client,submit,job,closable,job,graph,get,job,graph,abstract,queryable,state,test,base,class,get,class,loader,completable,future,job,status,job,status,future,cluster,client,get,job,status,closable,job,graph,get,job,id,while,deadline,has,time,left,job,status,future,get,deadline,time,left,to,millis,time,unit,milliseconds,equals,job,status,running,thread,sleep,50,job,status,future,cluster,client,get,job,status,closable,job,graph,get,job,id,assert,equals,job,status,running,job,status,future,get,deadline,time,left,to,millis,time,unit,milliseconds,final,job,id,wrong,job,id,new,job,id,completable,future,value,state,tuple2,integer,long,unknown,job,future,client,get,kv,state,wrong,job,id,hakuna,0,basic,type,info,value,state,try,unknown,job,future,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,flink,job,not,found,exception,could,not,find,flink,job,wrong,job,id,catch,exception,f,fail,unexpected,type,of,exception,f,get,message,completable,future,value,state,tuple2,integer,long,unknown,qsname,client,get,kv,state,closable,job,graph,get,job,id,wrong,hakuna,0,basic,type,info,value,state,try,unknown,qsname,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,unknown,kv,state,location,no,kv,state,location,found,for,kv,state,instance,with,name,wrong,hakuna,catch,exception,f,fail,unexpected,type,of,exception,f,get,message
AbstractQueryableStateTestBase -> @Test 	@Ignore 	public void testWrongJobIdAndWrongQueryableStateName() throws Exception;1542282018;Tests that the correct exception is thrown if the query_contains a wrong jobId or wrong queryable state name.;@Test_	@Ignore_	public void testWrongJobIdAndWrongQueryableStateName() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))__		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob closableJobGraph = new AutoCancellableJob(deadline, clusterClient, env)) {__			clusterClient.setDetached(true)__			clusterClient.submitJob(_				closableJobGraph.getJobGraph(), AbstractQueryableStateTestBase.class.getClassLoader())___			CompletableFuture<JobStatus> jobStatusFuture =_				clusterClient.getJobStatus(closableJobGraph.getJobId())___			while (deadline.hasTimeLeft() && !jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).equals(JobStatus.RUNNING)) {_				Thread.sleep(50)__				jobStatusFuture =_					clusterClient.getJobStatus(closableJobGraph.getJobId())__			}__			assertEquals(JobStatus.RUNNING, jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS))___			final JobID wrongJobId = new JobID()___			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownJobFuture = client.getKvState(_					wrongJobId, 						_					"hakuna",_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownJobFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"FlinkJobNotFoundException: Could not find Flink job (" + wrongJobId + ")"))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownQSName = client.getKvState(_					closableJobGraph.getJobId(),_					"wrong-hakuna", _					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownQSName.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"UnknownKvStateLocation: No KvStateLocation found for KvState instance with name 'wrong-hakuna'."))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}_		}_	};tests,that,the,correct,exception,is,thrown,if,the,query,contains,a,wrong,job,id,or,wrong,queryable,state,name;test,ignore,public,void,test,wrong,job,id,and,wrong,queryable,state,name,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,closable,job,graph,new,auto,cancellable,job,deadline,cluster,client,env,cluster,client,set,detached,true,cluster,client,submit,job,closable,job,graph,get,job,graph,abstract,queryable,state,test,base,class,get,class,loader,completable,future,job,status,job,status,future,cluster,client,get,job,status,closable,job,graph,get,job,id,while,deadline,has,time,left,job,status,future,get,deadline,time,left,to,millis,time,unit,milliseconds,equals,job,status,running,thread,sleep,50,job,status,future,cluster,client,get,job,status,closable,job,graph,get,job,id,assert,equals,job,status,running,job,status,future,get,deadline,time,left,to,millis,time,unit,milliseconds,final,job,id,wrong,job,id,new,job,id,completable,future,value,state,tuple2,integer,long,unknown,job,future,client,get,kv,state,wrong,job,id,hakuna,0,basic,type,info,value,state,try,unknown,job,future,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,flink,job,not,found,exception,could,not,find,flink,job,wrong,job,id,catch,exception,f,fail,unexpected,type,of,exception,f,get,message,completable,future,value,state,tuple2,integer,long,unknown,qsname,client,get,kv,state,closable,job,graph,get,job,id,wrong,hakuna,0,basic,type,info,value,state,try,unknown,qsname,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,unknown,kv,state,location,no,kv,state,location,found,for,kv,state,instance,with,name,wrong,hakuna,catch,exception,f,fail,unexpected,type,of,exception,f,get,message
AbstractQueryableStateTestBase -> @Test 	@Ignore 	public void testWrongJobIdAndWrongQueryableStateName() throws Exception;1547024365;Tests that the correct exception is thrown if the query_contains a wrong jobId or wrong queryable state name.;@Test_	@Ignore_	public void testWrongJobIdAndWrongQueryableStateName() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))__		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob closableJobGraph = new AutoCancellableJob(deadline, clusterClient, env)) {__			clusterClient.setDetached(true)__			clusterClient.submitJob(_				closableJobGraph.getJobGraph(), AbstractQueryableStateTestBase.class.getClassLoader())___			CompletableFuture<JobStatus> jobStatusFuture =_				clusterClient.getJobStatus(closableJobGraph.getJobId())___			while (deadline.hasTimeLeft() && !jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).equals(JobStatus.RUNNING)) {_				Thread.sleep(50)__				jobStatusFuture =_					clusterClient.getJobStatus(closableJobGraph.getJobId())__			}__			assertEquals(JobStatus.RUNNING, jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS))___			final JobID wrongJobId = new JobID()___			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownJobFuture = client.getKvState(_					wrongJobId, 						_					"hakuna",_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownJobFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"FlinkJobNotFoundException: Could not find Flink job (" + wrongJobId + ")"))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownQSName = client.getKvState(_					closableJobGraph.getJobId(),_					"wrong-hakuna", _					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownQSName.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"UnknownKvStateLocation: No KvStateLocation found for KvState instance with name 'wrong-hakuna'."))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}_		}_	};tests,that,the,correct,exception,is,thrown,if,the,query,contains,a,wrong,job,id,or,wrong,queryable,state,name;test,ignore,public,void,test,wrong,job,id,and,wrong,queryable,state,name,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,closable,job,graph,new,auto,cancellable,job,deadline,cluster,client,env,cluster,client,set,detached,true,cluster,client,submit,job,closable,job,graph,get,job,graph,abstract,queryable,state,test,base,class,get,class,loader,completable,future,job,status,job,status,future,cluster,client,get,job,status,closable,job,graph,get,job,id,while,deadline,has,time,left,job,status,future,get,deadline,time,left,to,millis,time,unit,milliseconds,equals,job,status,running,thread,sleep,50,job,status,future,cluster,client,get,job,status,closable,job,graph,get,job,id,assert,equals,job,status,running,job,status,future,get,deadline,time,left,to,millis,time,unit,milliseconds,final,job,id,wrong,job,id,new,job,id,completable,future,value,state,tuple2,integer,long,unknown,job,future,client,get,kv,state,wrong,job,id,hakuna,0,basic,type,info,value,state,try,unknown,job,future,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,flink,job,not,found,exception,could,not,find,flink,job,wrong,job,id,catch,exception,f,fail,unexpected,type,of,exception,f,get,message,completable,future,value,state,tuple2,integer,long,unknown,qsname,client,get,kv,state,closable,job,graph,get,job,id,wrong,hakuna,0,basic,type,info,value,state,try,unknown,qsname,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,unknown,kv,state,location,no,kv,state,location,found,for,kv,state,instance,with,name,wrong,hakuna,catch,exception,f,fail,unexpected,type,of,exception,f,get,message
AbstractQueryableStateTestBase -> @Test 	@Ignore 	public void testWrongJobIdAndWrongQueryableStateName() throws Exception;1547024365;Tests that the correct exception is thrown if the query_contains a wrong jobId or wrong queryable state name.;@Test_	@Ignore_	public void testWrongJobIdAndWrongQueryableStateName() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))__		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob closableJobGraph = new AutoCancellableJob(deadline, clusterClient, env)) {__			clusterClient.setDetached(true)__			clusterClient.submitJob(_				closableJobGraph.getJobGraph(), AbstractQueryableStateTestBase.class.getClassLoader())___			CompletableFuture<JobStatus> jobStatusFuture =_				clusterClient.getJobStatus(closableJobGraph.getJobId())___			while (deadline.hasTimeLeft() && !jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).equals(JobStatus.RUNNING)) {_				Thread.sleep(50)__				jobStatusFuture =_					clusterClient.getJobStatus(closableJobGraph.getJobId())__			}__			assertEquals(JobStatus.RUNNING, jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS))___			final JobID wrongJobId = new JobID()___			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownJobFuture = client.getKvState(_					wrongJobId, 						_					"hakuna",_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownJobFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"FlinkJobNotFoundException: Could not find Flink job (" + wrongJobId + ")"))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownQSName = client.getKvState(_					closableJobGraph.getJobId(),_					"wrong-hakuna", _					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownQSName.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"UnknownKvStateLocation: No KvStateLocation found for KvState instance with name 'wrong-hakuna'."))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}_		}_	};tests,that,the,correct,exception,is,thrown,if,the,query,contains,a,wrong,job,id,or,wrong,queryable,state,name;test,ignore,public,void,test,wrong,job,id,and,wrong,queryable,state,name,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,closable,job,graph,new,auto,cancellable,job,deadline,cluster,client,env,cluster,client,set,detached,true,cluster,client,submit,job,closable,job,graph,get,job,graph,abstract,queryable,state,test,base,class,get,class,loader,completable,future,job,status,job,status,future,cluster,client,get,job,status,closable,job,graph,get,job,id,while,deadline,has,time,left,job,status,future,get,deadline,time,left,to,millis,time,unit,milliseconds,equals,job,status,running,thread,sleep,50,job,status,future,cluster,client,get,job,status,closable,job,graph,get,job,id,assert,equals,job,status,running,job,status,future,get,deadline,time,left,to,millis,time,unit,milliseconds,final,job,id,wrong,job,id,new,job,id,completable,future,value,state,tuple2,integer,long,unknown,job,future,client,get,kv,state,wrong,job,id,hakuna,0,basic,type,info,value,state,try,unknown,job,future,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,flink,job,not,found,exception,could,not,find,flink,job,wrong,job,id,catch,exception,f,fail,unexpected,type,of,exception,f,get,message,completable,future,value,state,tuple2,integer,long,unknown,qsname,client,get,kv,state,closable,job,graph,get,job,id,wrong,hakuna,0,basic,type,info,value,state,try,unknown,qsname,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,unknown,kv,state,location,no,kv,state,location,found,for,kv,state,instance,with,name,wrong,hakuna,catch,exception,f,fail,unexpected,type,of,exception,f,get,message
AbstractQueryableStateTestBase -> @Test 	@Ignore 	public void testWrongJobIdAndWrongQueryableStateName() throws Exception;1547024365;Tests that the correct exception is thrown if the query_contains a wrong jobId or wrong queryable state name.;@Test_	@Ignore_	public void testWrongJobIdAndWrongQueryableStateName() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))__		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob closableJobGraph = new AutoCancellableJob(deadline, clusterClient, env)) {__			clusterClient.setDetached(true)__			clusterClient.submitJob(_				closableJobGraph.getJobGraph(), AbstractQueryableStateTestBase.class.getClassLoader())___			CompletableFuture<JobStatus> jobStatusFuture =_				clusterClient.getJobStatus(closableJobGraph.getJobId())___			while (deadline.hasTimeLeft() && !jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).equals(JobStatus.RUNNING)) {_				Thread.sleep(50)__				jobStatusFuture =_					clusterClient.getJobStatus(closableJobGraph.getJobId())__			}__			assertEquals(JobStatus.RUNNING, jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS))___			final JobID wrongJobId = new JobID()___			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownJobFuture = client.getKvState(_					wrongJobId, 						_					"hakuna",_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownJobFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"FlinkJobNotFoundException: Could not find Flink job (" + wrongJobId + ")"))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> unknownQSName = client.getKvState(_					closableJobGraph.getJobId(),_					"wrong-hakuna", _					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				unknownQSName.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause() instanceof RuntimeException)__				Assert.assertTrue("GOT: " + e.getCause().getMessage(), e.getCause().getMessage().contains(_						"UnknownKvStateLocation: No KvStateLocation found for KvState instance with name 'wrong-hakuna'."))__			} catch (Exception f) {_				fail("Unexpected type of exception: " + f.getMessage())__			}_		}_	};tests,that,the,correct,exception,is,thrown,if,the,query,contains,a,wrong,job,id,or,wrong,queryable,state,name;test,ignore,public,void,test,wrong,job,id,and,wrong,queryable,state,name,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,closable,job,graph,new,auto,cancellable,job,deadline,cluster,client,env,cluster,client,set,detached,true,cluster,client,submit,job,closable,job,graph,get,job,graph,abstract,queryable,state,test,base,class,get,class,loader,completable,future,job,status,job,status,future,cluster,client,get,job,status,closable,job,graph,get,job,id,while,deadline,has,time,left,job,status,future,get,deadline,time,left,to,millis,time,unit,milliseconds,equals,job,status,running,thread,sleep,50,job,status,future,cluster,client,get,job,status,closable,job,graph,get,job,id,assert,equals,job,status,running,job,status,future,get,deadline,time,left,to,millis,time,unit,milliseconds,final,job,id,wrong,job,id,new,job,id,completable,future,value,state,tuple2,integer,long,unknown,job,future,client,get,kv,state,wrong,job,id,hakuna,0,basic,type,info,value,state,try,unknown,job,future,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,flink,job,not,found,exception,could,not,find,flink,job,wrong,job,id,catch,exception,f,fail,unexpected,type,of,exception,f,get,message,completable,future,value,state,tuple2,integer,long,unknown,qsname,client,get,kv,state,closable,job,graph,get,job,id,wrong,hakuna,0,basic,type,info,value,state,try,unknown,qsname,get,deadline,time,left,to,millis,time,unit,milliseconds,fail,catch,execution,exception,e,assert,assert,true,got,e,get,cause,get,message,e,get,cause,instanceof,runtime,exception,assert,assert,true,got,e,get,cause,get,message,e,get,cause,get,message,contains,unknown,kv,state,location,no,kv,state,location,found,for,kv,state,instance,with,name,wrong,hakuna,catch,exception,f,fail,unexpected,type,of,exception,f,get,message
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1509037054;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = 9168901838808830068L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState("matata")___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_					(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()__			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		} finally {__			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(_						cluster.getLeaderGateway(deadline.timeLeft())_								.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_								.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,matata,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1510910970;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = 9168901838808830068L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState("matata")___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_					(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()__			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		} finally {__			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(_						cluster.getLeaderGateway(deadline.timeLeft())_								.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_								.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,matata,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1510911968;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = 9168901838808830068L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState("matata")___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_					(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()__			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		} finally {__			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(_						cluster.getLeaderGateway(deadline.timeLeft())_								.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_								.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,matata,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1510911970;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = 9168901838808830068L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState("matata")___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_					(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()__			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		} finally {__			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(_						cluster.getLeaderGateway(deadline.timeLeft())_								.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_								.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,matata,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1512567208;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 9168901838808830068L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("matata")___		final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_				(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)__			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,matata,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1513261599;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 9168901838808830068L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("matata")___		final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_				(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)__			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,matata,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1516812618;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 9168901838808830068L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("matata")___		final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_				(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)__			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,matata,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1520781441;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 9168901838808830068L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("matata")___		final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_				(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,matata,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1541420597;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 9168901838808830068L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("matata")___		final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_				(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,matata,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1542282018;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 9168901838808830068L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("matata")___		final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_				(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,matata,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1547024365;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 9168901838808830068L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("matata")___		final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_				(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,matata,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1547024365;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 9168901838808830068L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("matata")___		final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_				(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,matata,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueStateShortcut() throws Exception;1547024365;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).__<p>This is the same as the simple value state test, but uses the API shortcut.;@Test_	public void testValueStateShortcut() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 9168901838808830068L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("matata")___		@SuppressWarnings("unchecked")_		final ValueStateDescriptor<Tuple2<Integer, Long>> stateDesc =_				(ValueStateDescriptor<Tuple2<Integer, Long>>) queryableState.getStateDescriptor()___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "matata", stateDesc, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state,p,this,is,the,same,as,the,simple,value,state,test,but,uses,the,api,shortcut;test,public,void,test,value,state,shortcut,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,9168901838808830068l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,matata,suppress,warnings,unchecked,final,value,state,descriptor,tuple2,integer,long,state,desc,value,state,descriptor,tuple2,integer,long,queryable,state,get,state,descriptor,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,matata,state,desc,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testWrongQueryableStateName() throws Exception;1510910970;Tests that the correct exception is thrown if the query_contains a wrong queryable state name.;@Test_	public void testWrongQueryableStateName() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState =_					new ValueStateDescriptor<>("any", source.getType())___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 7662520075515707428L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			CompletableFuture<TestingJobManagerMessages.JobStatusIs> runningFuture = FutureUtils.toJava(_					cluster.getLeaderGateway(deadline.timeLeft())_							.ask(new TestingJobManagerMessages.NotifyWhenJobStatus(jobId, JobStatus.RUNNING), deadline.timeLeft())_							.mapTo(ClassTag$.MODULE$.<TestingJobManagerMessages.JobStatusIs>apply(TestingJobManagerMessages.JobStatusIs.class)))___			cluster.submitJobDetached(jobGraph)___			_			TestingJobManagerMessages.JobStatusIs jobStatus =_					runningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			assertEquals(JobStatus.RUNNING, jobStatus.state())___			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = client.getKvState(_					jobId,_					"wrong-hankuna", _					0,_					VoidNamespace.INSTANCE,_					BasicTypeInfo.INT_TYPE_INFO,_					VoidNamespaceTypeInfo.INSTANCE,_					valueState)___			try {_				future.get()__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue(e.getCause() instanceof RuntimeException)__				Assert.assertTrue(e.getCause().getMessage().contains(_						"UnknownKvStateLocation: No KvStateLocation found for KvState instance with name 'wrong-hankuna'."))__			} catch (Exception ignored) {_				fail("Unexpected type of exception.")__			}__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,that,the,correct,exception,is,thrown,if,the,query,contains,a,wrong,queryable,state,name;test,public,void,test,wrong,queryable,state,name,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,completable,future,testing,job,manager,messages,job,status,is,running,future,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,testing,job,manager,messages,notify,when,job,status,job,id,job,status,running,deadline,time,left,map,to,class,tag,module,testing,job,manager,messages,job,status,is,apply,testing,job,manager,messages,job,status,is,class,cluster,submit,job,detached,job,graph,testing,job,manager,messages,job,status,is,job,status,running,future,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,equals,job,status,running,job,status,state,completable,future,value,state,tuple2,integer,long,future,client,get,kv,state,job,id,wrong,hankuna,0,void,namespace,instance,basic,type,info,void,namespace,type,info,instance,value,state,try,future,get,fail,catch,execution,exception,e,assert,assert,true,e,get,cause,instanceof,runtime,exception,assert,assert,true,e,get,cause,get,message,contains,unknown,kv,state,location,no,kv,state,location,found,for,kv,state,instance,with,name,wrong,hankuna,catch,exception,ignored,fail,unexpected,type,of,exception,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testWrongQueryableStateName() throws Exception;1510911968;Tests that the correct exception is thrown if the query_contains a wrong queryable state name.;@Test_	public void testWrongQueryableStateName() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState =_					new ValueStateDescriptor<>("any", source.getType())___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 7662520075515707428L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			CompletableFuture<TestingJobManagerMessages.JobStatusIs> runningFuture = FutureUtils.toJava(_					cluster.getLeaderGateway(deadline.timeLeft())_							.ask(new TestingJobManagerMessages.NotifyWhenJobStatus(jobId, JobStatus.RUNNING), deadline.timeLeft())_							.mapTo(ClassTag$.MODULE$.<TestingJobManagerMessages.JobStatusIs>apply(TestingJobManagerMessages.JobStatusIs.class)))___			cluster.submitJobDetached(jobGraph)___			_			TestingJobManagerMessages.JobStatusIs jobStatus =_					runningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			assertEquals(JobStatus.RUNNING, jobStatus.state())___			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = client.getKvState(_					jobId,_					"wrong-hankuna", _					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			try {_				future.get()__				fail()_ _			} catch (ExecutionException e) {_				Assert.assertTrue(e.getCause() instanceof RuntimeException)__				Assert.assertTrue(e.getCause().getMessage().contains(_						"UnknownKvStateLocation: No KvStateLocation found for KvState instance with name 'wrong-hankuna'."))__			} catch (Exception ignored) {_				fail("Unexpected type of exception.")__			}__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,that,the,correct,exception,is,thrown,if,the,query,contains,a,wrong,queryable,state,name;test,public,void,test,wrong,queryable,state,name,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,completable,future,testing,job,manager,messages,job,status,is,running,future,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,testing,job,manager,messages,notify,when,job,status,job,id,job,status,running,deadline,time,left,map,to,class,tag,module,testing,job,manager,messages,job,status,is,apply,testing,job,manager,messages,job,status,is,class,cluster,submit,job,detached,job,graph,testing,job,manager,messages,job,status,is,job,status,running,future,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,equals,job,status,running,job,status,state,completable,future,value,state,tuple2,integer,long,future,client,get,kv,state,job,id,wrong,hankuna,0,basic,type,info,value,state,try,future,get,fail,catch,execution,exception,e,assert,assert,true,e,get,cause,instanceof,runtime,exception,assert,assert,true,e,get,cause,get,message,contains,unknown,kv,state,location,no,kv,state,location,found,for,kv,state,instance,with,name,wrong,hankuna,catch,exception,ignored,fail,unexpected,type,of,exception,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1509037054;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvStateWithRetries(_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						QUERY_RETRY_DELAY,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(50L)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,with,retries,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1510910970;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_						deadline,_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(50L)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1510911968;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_						deadline,_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(50L)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1510911970;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_						deadline,_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(50L)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1512567208;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_						deadline,_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(50L)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1513261599;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_						deadline,_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(RETRY_TIMEOUT)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1516812618;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_						deadline,_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(RETRY_TIMEOUT)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1520781441;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_						deadline,_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(RETRY_TIMEOUT)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1541420597;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_						deadline,_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(RETRY_TIMEOUT)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1542282018;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_						deadline,_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(RETRY_TIMEOUT)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1547024365;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_						deadline,_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(RETRY_TIMEOUT)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1547024365;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_						deadline,_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(RETRY_TIMEOUT)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> private void executeValueQuery( 			final Deadline deadline, 			final QueryableStateClient client, 			final JobID jobId, 			final String queryableStateName, 			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor, 			final long expected) throws Exception;1547024365;Retry a query for state for keys between 0 and {@link #maxParallelism} until_<tt>expected</tt> equals the value of the result tuple's second field.;private void executeValueQuery(_			final Deadline deadline,_			final QueryableStateClient client,_			final JobID jobId,_			final String queryableStateName,_			final ValueStateDescriptor<Tuple2<Integer, Long>> stateDescriptor,_			final long expected) throws Exception {__		for (int key = 0_ key < maxParallelism_ key++) {_			boolean success = false__			while (deadline.hasTimeLeft() && !success) {_				CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_						deadline,_						client,_						jobId,_						queryableStateName,_						key,_						BasicTypeInfo.INT_TYPE_INFO,_						stateDescriptor,_						false,_						executor)___				Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).value()___				assertEquals("Key mismatch", key, value.f0.intValue())__				if (expected == value.f1) {_					success = true__				} else {_					_					Thread.sleep(RETRY_TIMEOUT)__				}_			}__			assertTrue("Did not succeed query", success)__		}_	};retry,a,query,for,state,for,keys,between,0,and,link,max,parallelism,until,tt,expected,tt,equals,the,value,of,the,result,tuple,s,second,field;private,void,execute,value,query,final,deadline,deadline,final,queryable,state,client,client,final,job,id,job,id,final,string,queryable,state,name,final,value,state,descriptor,tuple2,integer,long,state,descriptor,final,long,expected,throws,exception,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,name,key,basic,type,info,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,value,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1509037054;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_					"any",_					source.getType())___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 7662520075515707428L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1510910970;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_					"any",_					source.getType())___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 7662520075515707428L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1510911968;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_					"any",_					source.getType())___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 7662520075515707428L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1510911970;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_					"any",_					source.getType())___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 7662520075515707428L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1512567208;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1513261599;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1516812618;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1520781441;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1541420597;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1542282018;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1547024365;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1547024365;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements
AbstractQueryableStateTestBase -> @Test 	public void testValueState() throws Exception;1547024365;Tests simple value state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The tests succeeds after each subtask index is queried with_value numElements (the latest element updated the state).;@Test_	public void testValueState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		_		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>("any", source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7662520075515707428L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, numElements)__		}_	};tests,simple,value,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,tests,succeeds,after,each,subtask,index,is,queried,with,value,num,elements,the,latest,element,updated,the,state;test,public,void,test,value,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7662520075515707428l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,hakuna,value,state,num,elements
AbstractQueryableStateTestBase -> protected abstract AbstractStateBackend createStateBackend() throws Exception_;1509037054;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract AbstractStateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> protected abstract AbstractStateBackend createStateBackend() throws Exception_;1510910970;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract AbstractStateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> protected abstract AbstractStateBackend createStateBackend() throws Exception_;1510911968;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract AbstractStateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> protected abstract AbstractStateBackend createStateBackend() throws Exception_;1510911970;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract AbstractStateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> protected abstract AbstractStateBackend createStateBackend() throws Exception_;1512567208;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract AbstractStateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> protected abstract AbstractStateBackend createStateBackend() throws Exception_;1513261599;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract AbstractStateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> protected abstract AbstractStateBackend createStateBackend() throws Exception_;1516812618;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract AbstractStateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> protected abstract AbstractStateBackend createStateBackend() throws Exception_;1520781441;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract AbstractStateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> protected abstract AbstractStateBackend createStateBackend() throws Exception_;1541420597;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract AbstractStateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> protected abstract AbstractStateBackend createStateBackend() throws Exception_;1542282018;Creates a state backend instance which is used in the {@link #setUp()} method before each_test case.__@return a state backend instance for each unit test;protected abstract AbstractStateBackend createStateBackend() throws Exception_;creates,a,state,backend,instance,which,is,used,in,the,link,set,up,method,before,each,test,case,return,a,state,backend,instance,for,each,unit,test;protected,abstract,abstract,state,backend,create,state,backend,throws,exception
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1509037054;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final int numElements = 1024___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState =_					new FoldingStateDescriptor<>(_							"any",_							"0",_							new SumFold(),_							StringSerializer.INSTANCE)___			QueryableStateStream<Integer, String> queryableState =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = -842809958106747539L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState("pumba", foldingState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvStateWithRetries(_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							QUERY_RETRY_DELAY,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,from,now,final,int,num,elements,1024,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,queryable,state,stream,integer,string,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,pumba,folding,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,with,retries,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1510910970;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final int numElements = 1024___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState =_					new FoldingStateDescriptor<>(_							"any",_							"0",_							new SumFold(),_							StringSerializer.INSTANCE)___			QueryableStateStream<Integer, String> queryableState =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = -842809958106747539L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState("pumba", foldingState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvState(_							deadline,_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,from,now,final,int,num,elements,1024,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,queryable,state,stream,integer,string,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,pumba,folding,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,deadline,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1510911968;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final int numElements = 1024___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState =_					new FoldingStateDescriptor<>(_							"any",_							"0",_							new SumFold(),_							StringSerializer.INSTANCE)___			QueryableStateStream<Integer, String> queryableState =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = -842809958106747539L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState("pumba", foldingState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvState(_							deadline,_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,from,now,final,int,num,elements,1024,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,queryable,state,stream,integer,string,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,pumba,folding,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,deadline,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1510911970;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final int numElements = 1024___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState =_					new FoldingStateDescriptor<>(_							"any",_							"0",_							new SumFold(),_							StringSerializer.INSTANCE)___			QueryableStateStream<Integer, String> queryableState =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = -842809958106747539L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState("pumba", foldingState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvState(_							deadline,_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,from,now,final,int,num,elements,1024,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,queryable,state,stream,integer,string,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,pumba,folding,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,deadline,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1512567208;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numElements = 1024___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState = new FoldingStateDescriptor<>(_				"any", "0", new SumFold(), StringSerializer.INSTANCE)___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = -842809958106747539L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("pumba", foldingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvState(_							deadline,_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,from,now,final,int,num,elements,1024,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,pumba,folding,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,deadline,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1513261599;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numElements = 1024___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState = new FoldingStateDescriptor<>(_				"any", "0", new SumFold(), StringSerializer.INSTANCE)___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = -842809958106747539L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("pumba", foldingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvState(_							deadline,_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,from,now,final,int,num,elements,1024,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,pumba,folding,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,deadline,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1516812618;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numElements = 1024___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState = new FoldingStateDescriptor<>(_				"any", "0", new SumFold(), StringSerializer.INSTANCE)___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = -842809958106747539L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("pumba", foldingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvState(_							deadline,_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,from,now,final,int,num,elements,1024,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,pumba,folding,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,deadline,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1520781441;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final int numElements = 1024___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState = new FoldingStateDescriptor<>(_				"any", "0", new SumFold(), StringSerializer.INSTANCE)___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = -842809958106747539L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("pumba", foldingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvState(_							deadline,_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,int,num,elements,1024,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,pumba,folding,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,deadline,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1541420597;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final int numElements = 1024___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState = new FoldingStateDescriptor<>(_				"any", "0", new SumFold(), StringSerializer.INSTANCE)___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = -842809958106747539L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("pumba", foldingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvState(_							deadline,_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,int,num,elements,1024,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,pumba,folding,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,deadline,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1542282018;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final int numElements = 1024___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState = new FoldingStateDescriptor<>(_				"any", "0", new SumFold(), StringSerializer.INSTANCE)___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = -842809958106747539L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("pumba", foldingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvState(_							deadline,_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,int,num,elements,1024,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,pumba,folding,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,deadline,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1547024365;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final int numElements = 1024___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState = new FoldingStateDescriptor<>(_				"any", "0", new SumFold(), StringSerializer.INSTANCE)___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = -842809958106747539L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("pumba", foldingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvState(_							deadline,_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,int,num,elements,1024,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,pumba,folding,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,deadline,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1547024365;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final int numElements = 1024___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState = new FoldingStateDescriptor<>(_				"any", "0", new SumFold(), StringSerializer.INSTANCE)___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = -842809958106747539L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("pumba", foldingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvState(_							deadline,_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,int,num,elements,1024,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,pumba,folding,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,deadline,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testFoldingState() throws Exception;1547024365;Tests simple folding state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The folding state sums these up and maps them to Strings. The_test succeeds after each subtask index is queried with result n*(n+1)/2_(as a String).;@Test_	public void testFoldingState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final int numElements = 1024___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		FoldingStateDescriptor<Tuple2<Integer, Long>, String> foldingState = new FoldingStateDescriptor<>(_				"any", "0", new SumFold(), StringSerializer.INSTANCE)___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = -842809958106747539L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("pumba", foldingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final String expected = Integer.toString(numElements * (numElements + 1) / 2)___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<FoldingState<Tuple2<Integer, Long>, String>> future = getKvState(_							deadline,_							client,_							jobId,_							"pumba",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							foldingState,_							false,_							executor)___					String value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					_					if (expected.equals(value)) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,folding,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,folding,state,sums,these,up,and,maps,them,to,strings,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2,as,a,string;test,public,void,test,folding,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,int,num,elements,1024,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,folding,state,descriptor,tuple2,integer,long,string,folding,state,new,folding,state,descriptor,any,0,new,sum,fold,string,serializer,instance,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,842809958106747539l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,pumba,folding,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,string,expected,integer,to,string,num,elements,num,elements,1,2,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,folding,state,tuple2,integer,long,string,future,get,kv,state,deadline,client,job,id,pumba,key,basic,type,info,folding,state,false,executor,string,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,if,expected,equals,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test(timeout = 60_000) 	public void testDuplicateRegistrationFailsJob() throws Exception;1520781441;Tests that duplicate query registrations fail the job at the JobManager.;@Test(timeout = 60_000)_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		_		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name",_				new SumReduce(),_				source.getType())___		final String queryName = "duplicate-me"___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -4126824763829132959L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName, reducingState)___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -6265024000462809436L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName)___		_		final JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		clusterClient.setDetached(false)___		boolean caughtException = false__		try {_			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())__		} catch (ProgramInvocationException e) {_			String failureCause = ExceptionUtils.stringifyException(e)__			assertThat(failureCause, containsString("KvState with name '" + queryName + "' has already been registered by another operator"))__			caughtException = true__		}__		assertTrue(caughtException)__	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager;test,timeout,public,void,test,duplicate,registration,fails,job,throws,exception,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,final,job,graph,job,graph,env,get,stream,graph,get,job,graph,cluster,client,set,detached,false,boolean,caught,exception,false,try,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,catch,program,invocation,exception,e,string,failure,cause,exception,utils,stringify,exception,e,assert,that,failure,cause,contains,string,kv,state,with,name,query,name,has,already,been,registered,by,another,operator,caught,exception,true,assert,true,caught,exception
AbstractQueryableStateTestBase -> @Test(timeout = 60_000) 	public void testDuplicateRegistrationFailsJob() throws Exception;1541420597;Tests that duplicate query registrations fail the job at the JobManager.;@Test(timeout = 60_000)_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		_		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name",_				new SumReduce(),_				source.getType())___		final String queryName = "duplicate-me"___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -4126824763829132959L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName, reducingState)___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -6265024000462809436L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName)___		_		final JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		clusterClient.setDetached(false)___		boolean caughtException = false__		try {_			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())__		} catch (ProgramInvocationException e) {_			String failureCause = ExceptionUtils.stringifyException(e)__			assertThat(failureCause, containsString("KvState with name '" + queryName + "' has already been registered by another operator"))__			caughtException = true__		}__		assertTrue(caughtException)__	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager;test,timeout,public,void,test,duplicate,registration,fails,job,throws,exception,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,final,job,graph,job,graph,env,get,stream,graph,get,job,graph,cluster,client,set,detached,false,boolean,caught,exception,false,try,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,catch,program,invocation,exception,e,string,failure,cause,exception,utils,stringify,exception,e,assert,that,failure,cause,contains,string,kv,state,with,name,query,name,has,already,been,registered,by,another,operator,caught,exception,true,assert,true,caught,exception
AbstractQueryableStateTestBase -> @Test(timeout = 60_000) 	public void testDuplicateRegistrationFailsJob() throws Exception;1542282018;Tests that duplicate query registrations fail the job at the JobManager.;@Test(timeout = 60_000)_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		_		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name",_				new SumReduce(),_				source.getType())___		final String queryName = "duplicate-me"___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -4126824763829132959L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName, reducingState)___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -6265024000462809436L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName)___		_		final JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		clusterClient.setDetached(false)___		boolean caughtException = false__		try {_			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())__		} catch (ProgramInvocationException e) {_			String failureCause = ExceptionUtils.stringifyException(e)__			assertThat(failureCause, containsString("KvState with name '" + queryName + "' has already been registered by another operator"))__			caughtException = true__		}__		assertTrue(caughtException)__	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager;test,timeout,public,void,test,duplicate,registration,fails,job,throws,exception,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,final,job,graph,job,graph,env,get,stream,graph,get,job,graph,cluster,client,set,detached,false,boolean,caught,exception,false,try,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,catch,program,invocation,exception,e,string,failure,cause,exception,utils,stringify,exception,e,assert,that,failure,cause,contains,string,kv,state,with,name,query,name,has,already,been,registered,by,another,operator,caught,exception,true,assert,true,caught,exception
AbstractQueryableStateTestBase -> @Test(timeout = 60_000) 	public void testDuplicateRegistrationFailsJob() throws Exception;1547024365;Tests that duplicate query registrations fail the job at the JobManager.;@Test(timeout = 60_000)_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		_		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name",_				new SumReduce(),_				source.getType())___		final String queryName = "duplicate-me"___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -4126824763829132959L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName, reducingState)___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -6265024000462809436L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName)___		_		final JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		clusterClient.setDetached(false)___		boolean caughtException = false__		try {_			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())__		} catch (ProgramInvocationException e) {_			String failureCause = ExceptionUtils.stringifyException(e)__			assertThat(failureCause, containsString("KvState with name '" + queryName + "' has already been registered by another operator"))__			caughtException = true__		}__		assertTrue(caughtException)__	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager;test,timeout,public,void,test,duplicate,registration,fails,job,throws,exception,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,final,job,graph,job,graph,env,get,stream,graph,get,job,graph,cluster,client,set,detached,false,boolean,caught,exception,false,try,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,catch,program,invocation,exception,e,string,failure,cause,exception,utils,stringify,exception,e,assert,that,failure,cause,contains,string,kv,state,with,name,query,name,has,already,been,registered,by,another,operator,caught,exception,true,assert,true,caught,exception
AbstractQueryableStateTestBase -> @Test(timeout = 60_000) 	public void testDuplicateRegistrationFailsJob() throws Exception;1547024365;Tests that duplicate query registrations fail the job at the JobManager.;@Test(timeout = 60_000)_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		_		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name",_				new SumReduce(),_				source.getType())___		final String queryName = "duplicate-me"___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -4126824763829132959L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName, reducingState)___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -6265024000462809436L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName)___		_		final JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		clusterClient.setDetached(false)___		boolean caughtException = false__		try {_			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())__		} catch (ProgramInvocationException e) {_			String failureCause = ExceptionUtils.stringifyException(e)__			assertThat(failureCause, containsString("KvState with name '" + queryName + "' has already been registered by another operator"))__			caughtException = true__		}__		assertTrue(caughtException)__	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager;test,timeout,public,void,test,duplicate,registration,fails,job,throws,exception,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,final,job,graph,job,graph,env,get,stream,graph,get,job,graph,cluster,client,set,detached,false,boolean,caught,exception,false,try,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,catch,program,invocation,exception,e,string,failure,cause,exception,utils,stringify,exception,e,assert,that,failure,cause,contains,string,kv,state,with,name,query,name,has,already,been,registered,by,another,operator,caught,exception,true,assert,true,caught,exception
AbstractQueryableStateTestBase -> @Test(timeout = 60_000) 	public void testDuplicateRegistrationFailsJob() throws Exception;1547024365;Tests that duplicate query registrations fail the job at the JobManager.;@Test(timeout = 60_000)_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		_		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name",_				new SumReduce(),_				source.getType())___		final String queryName = "duplicate-me"___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -4126824763829132959L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName, reducingState)___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -6265024000462809436L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName)___		_		final JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		clusterClient.setDetached(false)___		boolean caughtException = false__		try {_			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())__		} catch (ProgramInvocationException e) {_			String failureCause = ExceptionUtils.stringifyException(e)__			assertThat(failureCause, containsString("KvState with name '" + queryName + "' has already been registered by another operator"))__			caughtException = true__		}__		assertTrue(caughtException)__	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager;test,timeout,public,void,test,duplicate,registration,fails,job,throws,exception,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,final,job,graph,job,graph,env,get,stream,graph,get,job,graph,cluster,client,set,detached,false,boolean,caught,exception,false,try,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,catch,program,invocation,exception,e,string,failure,cause,exception,utils,stringify,exception,e,assert,that,failure,cause,contains,string,kv,state,with,name,query,name,has,already,been,registered,by,another,operator,caught,exception,true,assert,true,caught,exception
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1509037054;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_				.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any",_				source.getType(),_				null)___			QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			_			long expected = numElements___			_			client.getKvState(_					jobId,_					queryableState.getQueryableStateName(),_					0,_					VoidNamespace.INSTANCE,_					BasicTypeInfo.INT_TYPE_INFO,_					VoidNamespaceTypeInfo.INSTANCE,_					valueState)___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,long,expected,num,elements,client,get,kv,state,job,id,queryable,state,get,queryable,state,name,0,void,namespace,instance,basic,type,info,void,namespace,type,info,instance,value,state,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,expected,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1510910970;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_				.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any",_				source.getType(),_				null)___			QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			_			long expected = numElements___			_			client.getKvState(_					jobId,_					queryableState.getQueryableStateName(),_					0,_					VoidNamespace.INSTANCE,_					BasicTypeInfo.INT_TYPE_INFO,_					VoidNamespaceTypeInfo.INSTANCE,_					valueState)___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,long,expected,num,elements,client,get,kv,state,job,id,queryable,state,get,queryable,state,name,0,void,namespace,instance,basic,type,info,void,namespace,type,info,instance,value,state,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,expected,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1510911968;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_				.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any",_				source.getType(),_				null)___			QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			_			long expected = numElements___			_			client.getKvState(_					jobId,_					queryableState.getQueryableStateName(),_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,long,expected,num,elements,client,get,kv,state,job,id,queryable,state,get,queryable,state,name,0,basic,type,info,value,state,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,expected,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1510911970;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_				.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any",_				source.getType(),_				null)___			QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			_			long expected = numElements___			_			client.getKvState(_					jobId,_					queryableState.getQueryableStateName(),_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,long,expected,num,elements,client,get,kv,state,job,id,queryable,state,get,queryable,state,name,0,basic,type,info,value,state,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,expected,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1512567208;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_			"any", source.getType(), 	null)___		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {__					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			long expected = numElements___			_			client.getKvState(_					autoCancellableJob.getJobId(),_					queryableState.getQueryableStateName(),_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,long,expected,num,elements,client,get,kv,state,auto,cancellable,job,get,job,id,queryable,state,get,queryable,state,name,0,basic,type,info,value,state,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,expected
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1513261599;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_			"any", source.getType(), 	null)___		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {__					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			long expected = numElements___			_			client.getKvState(_					autoCancellableJob.getJobId(),_					queryableState.getQueryableStateName(),_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,long,expected,num,elements,client,get,kv,state,auto,cancellable,job,get,job,id,queryable,state,get,queryable,state,name,0,basic,type,info,value,state,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,expected
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1516812618;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_			"any", source.getType(), 	null)___		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {__					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			long expected = numElements___			_			client.getKvState(_					autoCancellableJob.getJobId(),_					queryableState.getQueryableStateName(),_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			cluster.submitJobDetached(jobGraph)___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,long,expected,num,elements,client,get,kv,state,auto,cancellable,job,get,job,id,queryable,state,get,queryable,state,name,0,basic,type,info,value,state,cluster,submit,job,detached,job,graph,execute,value,query,deadline,client,job,id,hakuna,value,state,expected
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1520781441;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_			"any", source.getType(), 	null)___		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {__					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			long expected = numElements___			_			client.getKvState(_					autoCancellableJob.getJobId(),_					queryableState.getQueryableStateName(),_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,long,expected,num,elements,client,get,kv,state,auto,cancellable,job,get,job,id,queryable,state,get,queryable,state,name,0,basic,type,info,value,state,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,hakuna,value,state,expected
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1541420597;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_			"any", source.getType(), 	null)___		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {__					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			long expected = numElements___			_			client.getKvState(_					autoCancellableJob.getJobId(),_					queryableState.getQueryableStateName(),_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,long,expected,num,elements,client,get,kv,state,auto,cancellable,job,get,job,id,queryable,state,get,queryable,state,name,0,basic,type,info,value,state,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,hakuna,value,state,expected
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1542282018;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_			"any", source.getType(), 	null)___		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {__					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			long expected = numElements___			_			client.getKvState(_					autoCancellableJob.getJobId(),_					queryableState.getQueryableStateName(),_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,long,expected,num,elements,client,get,kv,state,auto,cancellable,job,get,job,id,queryable,state,get,queryable,state,name,0,basic,type,info,value,state,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,hakuna,value,state,expected
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1547024365;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_			"any", source.getType(), 	null)___		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {__					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			long expected = numElements___			_			client.getKvState(_					autoCancellableJob.getJobId(),_					queryableState.getQueryableStateName(),_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,long,expected,num,elements,client,get,kv,state,auto,cancellable,job,get,job,id,queryable,state,get,queryable,state,name,0,basic,type,info,value,state,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,hakuna,value,state,expected
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1547024365;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_			"any", source.getType(), 	null)___		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {__					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			long expected = numElements___			_			client.getKvState(_					autoCancellableJob.getJobId(),_					queryableState.getQueryableStateName(),_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,long,expected,num,elements,client,get,kv,state,auto,cancellable,job,get,job,id,queryable,state,get,queryable,state,name,0,basic,type,info,value,state,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,hakuna,value,state,expected
AbstractQueryableStateTestBase -> @Test 	public void testQueryNonStartedJobState() throws Exception;1547024365;Similar tests as {@link #testValueState()} but before submitting the_job, we already issue one request which fails.;@Test_	public void testQueryNonStartedJobState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_			"any", source.getType(), 	null)___		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {__					private static final long serialVersionUID = 7480503339992214681L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			long expected = numElements___			_			client.getKvState(_					autoCancellableJob.getJobId(),_					queryableState.getQueryableStateName(),_					0,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState)___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			executeValueQuery(deadline, client, jobId, "hakuna", valueState, expected)__		}_	};similar,tests,as,link,test,value,state,but,before,submitting,the,job,we,already,issue,one,request,which,fails;test,public,void,test,query,non,started,job,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,null,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7480503339992214681l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,long,expected,num,elements,client,get,kv,state,auto,cancellable,job,get,job,id,queryable,state,get,queryable,state,name,0,basic,type,info,value,state,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,execute,value,query,deadline,client,job,id,hakuna,value,state,expected
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1509037054;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState =_					new ReducingStateDescriptor<>(_							"any",_							new SumReduce(),_							source.getType())___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 8470749712274833552L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState("jungle", reducingState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvStateWithRetries(_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							QUERY_RETRY_DELAY,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,jungle,reducing,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,with,retries,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1510910970;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState =_					new ReducingStateDescriptor<>(_							"any",_							new SumReduce(),_							source.getType())___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 8470749712274833552L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState("jungle", reducingState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,jungle,reducing,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1510911968;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState =_					new ReducingStateDescriptor<>(_							"any",_							new SumReduce(),_							source.getType())___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 8470749712274833552L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState("jungle", reducingState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,jungle,reducing,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1510911970;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			_			ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState =_					new ReducingStateDescriptor<>(_							"any",_							new SumReduce(),_							source.getType())___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 8470749712274833552L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState("jungle", reducingState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,jungle,reducing,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1512567208;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any", new SumReduce(), source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("jungle", reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,jungle,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1513261599;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any", new SumReduce(), source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("jungle", reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,jungle,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1516812618;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any", new SumReduce(), source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("jungle", reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,jungle,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1520781441;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any", new SumReduce(), source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("jungle", reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,jungle,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1541420597;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any", new SumReduce(), source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("jungle", reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,jungle,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1542282018;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any", new SumReduce(), source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("jungle", reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,jungle,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1547024365;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any", new SumReduce(), source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("jungle", reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,jungle,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1547024365;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any", new SumReduce(), source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("jungle", reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,jungle,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testReducingState() throws Exception;1547024365;Tests simple reducing state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The reducing state instance sums these up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testReducingState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any", new SumReduce(), source.getType())___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState("jungle", reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"jungle",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get()___					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,reducing,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,reducing,state,instance,sums,these,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,reducing,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,new,sum,reduce,source,get,type,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,jungle,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,reducing,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,jungle,key,basic,type,info,reducing,state,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	@SuppressWarnings("unchecked") 	public void testQueryableState() throws Exception;1509037054;Runs a simple topology producing random (key, 1) pairs at the sources (where_number of keys is in fixed in range 0...numKeys). The records are keyed and_a reducing queryable state instance is created, which sums up the records.__<p>After submitting the job in detached mode, the QueryableStateCLient is used_to query the counts of each key in rounds until all keys have non-zero counts.;@Test_	@SuppressWarnings("unchecked")_	public void testQueryableState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		JobID jobId = null___		try {_			_			_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestKeyRangeSource(numKeys))___			_			ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_					"any-name",_					new SumReduce(),_					source.getType())___			final String queryName = "hakuna-matata"___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 7143749578983540352L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState(queryName, reducingState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			cluster.submitJobDetached(jobGraph)___			_			_			_			jobId = jobGraph.getJobID()___			final AtomicLongArray counts = new AtomicLongArray(numKeys)___			boolean allNonZero = false__			while (!allNonZero && deadline.hasTimeLeft()) {_				allNonZero = true___				final List<CompletableFuture<ReducingState<Tuple2<Integer, Long>>>> futures = new ArrayList<>(numKeys)___				for (int i = 0_ i < numKeys_ i++) {_					final int key = i___					if (counts.get(key) > 0L) {_						_						continue__					} else {_						allNonZero = false__					}__					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> result = getKvStateWithRetries(_							client,_							jobId,_							queryName,_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							QUERY_RETRY_DELAY,_							false,_							executor)___					result.thenAccept(response -> {_						try {_							Tuple2<Integer, Long> res = response.get()__							counts.set(key, res.f1)__							assertEquals("Key mismatch", key, res.f0.intValue())__						} catch (Exception e) {_							Assert.fail(e.getMessage())__						}_					})___					futures.add(result)__				}__				_				CompletableFuture_						.allOf(futures.toArray(new CompletableFuture<?>[futures.size()]))_						.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			assertTrue("Not all keys are non-zero", allNonZero)___			_			for (int i = 0_ i < numKeys_ i++) {_				long count = counts.get(i)__				assertTrue("Count at position " + i + " is " + count, count > 0)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};runs,a,simple,topology,producing,random,key,1,pairs,at,the,sources,where,number,of,keys,is,in,fixed,in,range,0,num,keys,the,records,are,keyed,and,a,reducing,queryable,state,instance,is,created,which,sums,up,the,records,p,after,submitting,the,job,in,detached,mode,the,queryable,state,client,is,used,to,query,the,counts,of,each,key,in,rounds,until,all,keys,have,non,zero,counts;test,suppress,warnings,unchecked,public,void,test,queryable,state,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,hakuna,matata,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7143749578983540352l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,query,name,reducing,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,cluster,submit,job,detached,job,graph,job,id,job,graph,get,job,id,final,atomic,long,array,counts,new,atomic,long,array,num,keys,boolean,all,non,zero,false,while,all,non,zero,deadline,has,time,left,all,non,zero,true,final,list,completable,future,reducing,state,tuple2,integer,long,futures,new,array,list,num,keys,for,int,i,0,i,num,keys,i,final,int,key,i,if,counts,get,key,0l,continue,else,all,non,zero,false,completable,future,reducing,state,tuple2,integer,long,result,get,kv,state,with,retries,client,job,id,query,name,key,basic,type,info,reducing,state,false,executor,result,then,accept,response,try,tuple2,integer,long,res,response,get,counts,set,key,res,f1,assert,equals,key,mismatch,key,res,f0,int,value,catch,exception,e,assert,fail,e,get,message,futures,add,result,completable,future,all,of,futures,to,array,new,completable,future,futures,size,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,true,not,all,keys,are,non,zero,all,non,zero,for,int,i,0,i,num,keys,i,long,count,counts,get,i,assert,true,count,at,position,i,is,count,count,0,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	@SuppressWarnings("unchecked") 	public void testQueryableState() throws Exception;1510910970;Runs a simple topology producing random (key, 1) pairs at the sources (where_number of keys is in fixed in range 0...numKeys). The records are keyed and_a reducing queryable state instance is created, which sums up the records.__<p>After submitting the job in detached mode, the QueryableStateCLient is used_to query the counts of each key in rounds until all keys have non-zero counts.;@Test_	@SuppressWarnings("unchecked")_	public void testQueryableState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		JobID jobId = null___		try {_			_			_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestKeyRangeSource(numKeys))___			_			ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_					"any-name",_					new SumReduce(),_					source.getType())___			final String queryName = "hakuna-matata"___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 7143749578983540352L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState(queryName, reducingState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			cluster.submitJobDetached(jobGraph)___			_			_			_			jobId = jobGraph.getJobID()___			final AtomicLongArray counts = new AtomicLongArray(numKeys)___			boolean allNonZero = false__			while (!allNonZero && deadline.hasTimeLeft()) {_				allNonZero = true___				final List<CompletableFuture<ReducingState<Tuple2<Integer, Long>>>> futures = new ArrayList<>(numKeys)___				for (int i = 0_ i < numKeys_ i++) {_					final int key = i___					if (counts.get(key) > 0L) {_						_						continue__					} else {_						allNonZero = false__					}__					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> result = getKvState(_							deadline,_							client,_							jobId,_							queryName,_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					result.thenAccept(response -> {_						try {_							Tuple2<Integer, Long> res = response.get()__							counts.set(key, res.f1)__							assertEquals("Key mismatch", key, res.f0.intValue())__						} catch (Exception e) {_							Assert.fail(e.getMessage())__						}_					})___					futures.add(result)__				}__				_				CompletableFuture_						.allOf(futures.toArray(new CompletableFuture<?>[futures.size()]))_						.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			assertTrue("Not all keys are non-zero", allNonZero)___			_			for (int i = 0_ i < numKeys_ i++) {_				long count = counts.get(i)__				assertTrue("Count at position " + i + " is " + count, count > 0)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};runs,a,simple,topology,producing,random,key,1,pairs,at,the,sources,where,number,of,keys,is,in,fixed,in,range,0,num,keys,the,records,are,keyed,and,a,reducing,queryable,state,instance,is,created,which,sums,up,the,records,p,after,submitting,the,job,in,detached,mode,the,queryable,state,client,is,used,to,query,the,counts,of,each,key,in,rounds,until,all,keys,have,non,zero,counts;test,suppress,warnings,unchecked,public,void,test,queryable,state,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,hakuna,matata,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7143749578983540352l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,query,name,reducing,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,cluster,submit,job,detached,job,graph,job,id,job,graph,get,job,id,final,atomic,long,array,counts,new,atomic,long,array,num,keys,boolean,all,non,zero,false,while,all,non,zero,deadline,has,time,left,all,non,zero,true,final,list,completable,future,reducing,state,tuple2,integer,long,futures,new,array,list,num,keys,for,int,i,0,i,num,keys,i,final,int,key,i,if,counts,get,key,0l,continue,else,all,non,zero,false,completable,future,reducing,state,tuple2,integer,long,result,get,kv,state,deadline,client,job,id,query,name,key,basic,type,info,reducing,state,false,executor,result,then,accept,response,try,tuple2,integer,long,res,response,get,counts,set,key,res,f1,assert,equals,key,mismatch,key,res,f0,int,value,catch,exception,e,assert,fail,e,get,message,futures,add,result,completable,future,all,of,futures,to,array,new,completable,future,futures,size,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,true,not,all,keys,are,non,zero,all,non,zero,for,int,i,0,i,num,keys,i,long,count,counts,get,i,assert,true,count,at,position,i,is,count,count,0,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	@SuppressWarnings("unchecked") 	public void testQueryableState() throws Exception;1510911968;Runs a simple topology producing random (key, 1) pairs at the sources (where_number of keys is in fixed in range 0...numKeys). The records are keyed and_a reducing queryable state instance is created, which sums up the records.__<p>After submitting the job in detached mode, the QueryableStateCLient is used_to query the counts of each key in rounds until all keys have non-zero counts.;@Test_	@SuppressWarnings("unchecked")_	public void testQueryableState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		JobID jobId = null___		try {_			_			_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestKeyRangeSource(numKeys))___			_			ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_					"any-name",_					new SumReduce(),_					source.getType())___			final String queryName = "hakuna-matata"___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 7143749578983540352L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState(queryName, reducingState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			cluster.submitJobDetached(jobGraph)___			_			_			_			jobId = jobGraph.getJobID()___			final AtomicLongArray counts = new AtomicLongArray(numKeys)___			boolean allNonZero = false__			while (!allNonZero && deadline.hasTimeLeft()) {_				allNonZero = true___				final List<CompletableFuture<ReducingState<Tuple2<Integer, Long>>>> futures = new ArrayList<>(numKeys)___				for (int i = 0_ i < numKeys_ i++) {_					final int key = i___					if (counts.get(key) > 0L) {_						_						continue__					} else {_						allNonZero = false__					}__					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> result = getKvState(_							deadline,_							client,_							jobId,_							queryName,_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					result.thenAccept(response -> {_						try {_							Tuple2<Integer, Long> res = response.get()__							counts.set(key, res.f1)__							assertEquals("Key mismatch", key, res.f0.intValue())__						} catch (Exception e) {_							Assert.fail(e.getMessage())__						}_					})___					futures.add(result)__				}__				_				CompletableFuture_						.allOf(futures.toArray(new CompletableFuture<?>[futures.size()]))_						.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			assertTrue("Not all keys are non-zero", allNonZero)___			_			for (int i = 0_ i < numKeys_ i++) {_				long count = counts.get(i)__				assertTrue("Count at position " + i + " is " + count, count > 0)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};runs,a,simple,topology,producing,random,key,1,pairs,at,the,sources,where,number,of,keys,is,in,fixed,in,range,0,num,keys,the,records,are,keyed,and,a,reducing,queryable,state,instance,is,created,which,sums,up,the,records,p,after,submitting,the,job,in,detached,mode,the,queryable,state,client,is,used,to,query,the,counts,of,each,key,in,rounds,until,all,keys,have,non,zero,counts;test,suppress,warnings,unchecked,public,void,test,queryable,state,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,hakuna,matata,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7143749578983540352l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,query,name,reducing,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,cluster,submit,job,detached,job,graph,job,id,job,graph,get,job,id,final,atomic,long,array,counts,new,atomic,long,array,num,keys,boolean,all,non,zero,false,while,all,non,zero,deadline,has,time,left,all,non,zero,true,final,list,completable,future,reducing,state,tuple2,integer,long,futures,new,array,list,num,keys,for,int,i,0,i,num,keys,i,final,int,key,i,if,counts,get,key,0l,continue,else,all,non,zero,false,completable,future,reducing,state,tuple2,integer,long,result,get,kv,state,deadline,client,job,id,query,name,key,basic,type,info,reducing,state,false,executor,result,then,accept,response,try,tuple2,integer,long,res,response,get,counts,set,key,res,f1,assert,equals,key,mismatch,key,res,f0,int,value,catch,exception,e,assert,fail,e,get,message,futures,add,result,completable,future,all,of,futures,to,array,new,completable,future,futures,size,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,true,not,all,keys,are,non,zero,all,non,zero,for,int,i,0,i,num,keys,i,long,count,counts,get,i,assert,true,count,at,position,i,is,count,count,0,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	@SuppressWarnings("unchecked") 	public void testQueryableState() throws Exception;1510911970;Runs a simple topology producing random (key, 1) pairs at the sources (where_number of keys is in fixed in range 0...numKeys). The records are keyed and_a reducing queryable state instance is created, which sums up the records.__<p>After submitting the job in detached mode, the QueryableStateCLient is used_to query the counts of each key in rounds until all keys have non-zero counts.;@Test_	@SuppressWarnings("unchecked")_	public void testQueryableState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		JobID jobId = null___		try {_			_			_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestKeyRangeSource(numKeys))___			_			ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_					"any-name",_					new SumReduce(),_					source.getType())___			final String queryName = "hakuna-matata"___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 7143749578983540352L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).asQueryableState(queryName, reducingState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			cluster.submitJobDetached(jobGraph)___			_			_			_			jobId = jobGraph.getJobID()___			final AtomicLongArray counts = new AtomicLongArray(numKeys)___			boolean allNonZero = false__			while (!allNonZero && deadline.hasTimeLeft()) {_				allNonZero = true___				final List<CompletableFuture<ReducingState<Tuple2<Integer, Long>>>> futures = new ArrayList<>(numKeys)___				for (int i = 0_ i < numKeys_ i++) {_					final int key = i___					if (counts.get(key) > 0L) {_						_						continue__					} else {_						allNonZero = false__					}__					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> result = getKvState(_							deadline,_							client,_							jobId,_							queryName,_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					result.thenAccept(response -> {_						try {_							Tuple2<Integer, Long> res = response.get()__							counts.set(key, res.f1)__							assertEquals("Key mismatch", key, res.f0.intValue())__						} catch (Exception e) {_							Assert.fail(e.getMessage())__						}_					})___					futures.add(result)__				}__				_				CompletableFuture_						.allOf(futures.toArray(new CompletableFuture<?>[futures.size()]))_						.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			assertTrue("Not all keys are non-zero", allNonZero)___			_			for (int i = 0_ i < numKeys_ i++) {_				long count = counts.get(i)__				assertTrue("Count at position " + i + " is " + count, count > 0)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};runs,a,simple,topology,producing,random,key,1,pairs,at,the,sources,where,number,of,keys,is,in,fixed,in,range,0,num,keys,the,records,are,keyed,and,a,reducing,queryable,state,instance,is,created,which,sums,up,the,records,p,after,submitting,the,job,in,detached,mode,the,queryable,state,client,is,used,to,query,the,counts,of,each,key,in,rounds,until,all,keys,have,non,zero,counts;test,suppress,warnings,unchecked,public,void,test,queryable,state,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,hakuna,matata,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7143749578983540352l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,query,name,reducing,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,cluster,submit,job,detached,job,graph,job,id,job,graph,get,job,id,final,atomic,long,array,counts,new,atomic,long,array,num,keys,boolean,all,non,zero,false,while,all,non,zero,deadline,has,time,left,all,non,zero,true,final,list,completable,future,reducing,state,tuple2,integer,long,futures,new,array,list,num,keys,for,int,i,0,i,num,keys,i,final,int,key,i,if,counts,get,key,0l,continue,else,all,non,zero,false,completable,future,reducing,state,tuple2,integer,long,result,get,kv,state,deadline,client,job,id,query,name,key,basic,type,info,reducing,state,false,executor,result,then,accept,response,try,tuple2,integer,long,res,response,get,counts,set,key,res,f1,assert,equals,key,mismatch,key,res,f0,int,value,catch,exception,e,assert,fail,e,get,message,futures,add,result,completable,future,all,of,futures,to,array,new,completable,future,futures,size,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,true,not,all,keys,are,non,zero,all,non,zero,for,int,i,0,i,num,keys,i,long,count,counts,get,i,assert,true,count,at,position,i,is,count,count,0,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	@SuppressWarnings("unchecked") 	public void testQueryableState() throws Exception;1512567208;Runs a simple topology producing random (key, 1) pairs at the sources (where_number of keys is in fixed in range 0...numKeys). The records are keyed and_a reducing queryable state instance is created, which sums up the records.__<p>After submitting the job in detached mode, the QueryableStateCLient is used_to query the counts of each key in rounds until all keys have non-zero counts.;@Test_	@SuppressWarnings("unchecked")_	public void testQueryableState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name", new SumReduce(), 	source.getType())___		final String queryName = "hakuna-matata"___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7143749578983540352L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState(queryName, reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final AtomicLongArray counts = new AtomicLongArray(numKeys)___			boolean allNonZero = false__			while (!allNonZero && deadline.hasTimeLeft()) {_				allNonZero = true___				final List<CompletableFuture<ReducingState<Tuple2<Integer, Long>>>> futures = new ArrayList<>(numKeys)___				for (int i = 0_ i < numKeys_ i++) {_					final int key = i___					if (counts.get(key) > 0L) {_						_						continue__					} else {_						allNonZero = false__					}__					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> result = getKvState(_							deadline,_							client,_							jobId,_							queryName,_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					result.thenAccept(response -> {_						try {_							Tuple2<Integer, Long> res = response.get()__							counts.set(key, res.f1)__							assertEquals("Key mismatch", key, res.f0.intValue())__						} catch (Exception e) {_							Assert.fail(e.getMessage())__						}_					})___					futures.add(result)__				}__				_				CompletableFuture_						.allOf(futures.toArray(new CompletableFuture<?>[futures.size()]))_						.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			assertTrue("Not all keys are non-zero", allNonZero)___			_			for (int i = 0_ i < numKeys_ i++) {_				long count = counts.get(i)__				assertTrue("Count at position " + i + " is " + count, count > 0)__			}_		}_	};runs,a,simple,topology,producing,random,key,1,pairs,at,the,sources,where,number,of,keys,is,in,fixed,in,range,0,num,keys,the,records,are,keyed,and,a,reducing,queryable,state,instance,is,created,which,sums,up,the,records,p,after,submitting,the,job,in,detached,mode,the,queryable,state,client,is,used,to,query,the,counts,of,each,key,in,rounds,until,all,keys,have,non,zero,counts;test,suppress,warnings,unchecked,public,void,test,queryable,state,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,hakuna,matata,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7143749578983540352l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,atomic,long,array,counts,new,atomic,long,array,num,keys,boolean,all,non,zero,false,while,all,non,zero,deadline,has,time,left,all,non,zero,true,final,list,completable,future,reducing,state,tuple2,integer,long,futures,new,array,list,num,keys,for,int,i,0,i,num,keys,i,final,int,key,i,if,counts,get,key,0l,continue,else,all,non,zero,false,completable,future,reducing,state,tuple2,integer,long,result,get,kv,state,deadline,client,job,id,query,name,key,basic,type,info,reducing,state,false,executor,result,then,accept,response,try,tuple2,integer,long,res,response,get,counts,set,key,res,f1,assert,equals,key,mismatch,key,res,f0,int,value,catch,exception,e,assert,fail,e,get,message,futures,add,result,completable,future,all,of,futures,to,array,new,completable,future,futures,size,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,true,not,all,keys,are,non,zero,all,non,zero,for,int,i,0,i,num,keys,i,long,count,counts,get,i,assert,true,count,at,position,i,is,count,count,0
AbstractQueryableStateTestBase -> @Test 	@SuppressWarnings("unchecked") 	public void testQueryableState() throws Exception;1513261599;Runs a simple topology producing random (key, 1) pairs at the sources (where_number of keys is in fixed in range 0...numKeys). The records are keyed and_a reducing queryable state instance is created, which sums up the records.__<p>After submitting the job in detached mode, the QueryableStateCLient is used_to query the counts of each key in rounds until all keys have non-zero counts.;@Test_	@SuppressWarnings("unchecked")_	public void testQueryableState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name", new SumReduce(), 	source.getType())___		final String queryName = "hakuna-matata"___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7143749578983540352L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState(queryName, reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final AtomicLongArray counts = new AtomicLongArray(numKeys)___			final List<CompletableFuture<ReducingState<Tuple2<Integer, Long>>>> futures = new ArrayList<>(numKeys)___			boolean allNonZero = false__			while (!allNonZero && deadline.hasTimeLeft()) {_				allNonZero = true__				futures.clear()___				for (int i = 0_ i < numKeys_ i++) {_					final int key = i___					if (counts.get(key) > 0L) {_						_						continue__					} else {_						allNonZero = false__					}__					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> result = getKvState(_							deadline,_							client,_							jobId,_							queryName,_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					result.thenAccept(response -> {_						try {_							Tuple2<Integer, Long> res = response.get()__							counts.set(key, res.f1)__							assertEquals("Key mismatch", key, res.f0.intValue())__						} catch (Exception e) {_							Assert.fail(e.getMessage())__						}_					})___					futures.add(result)__				}__				_				CompletableFuture_						.allOf(futures.toArray(new CompletableFuture<?>[futures.size()]))_						.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			assertTrue("Not all keys are non-zero", allNonZero)___			_			for (int i = 0_ i < numKeys_ i++) {_				long count = counts.get(i)__				assertTrue("Count at position " + i + " is " + count, count > 0)__			}_		}_	};runs,a,simple,topology,producing,random,key,1,pairs,at,the,sources,where,number,of,keys,is,in,fixed,in,range,0,num,keys,the,records,are,keyed,and,a,reducing,queryable,state,instance,is,created,which,sums,up,the,records,p,after,submitting,the,job,in,detached,mode,the,queryable,state,client,is,used,to,query,the,counts,of,each,key,in,rounds,until,all,keys,have,non,zero,counts;test,suppress,warnings,unchecked,public,void,test,queryable,state,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,hakuna,matata,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7143749578983540352l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,atomic,long,array,counts,new,atomic,long,array,num,keys,final,list,completable,future,reducing,state,tuple2,integer,long,futures,new,array,list,num,keys,boolean,all,non,zero,false,while,all,non,zero,deadline,has,time,left,all,non,zero,true,futures,clear,for,int,i,0,i,num,keys,i,final,int,key,i,if,counts,get,key,0l,continue,else,all,non,zero,false,completable,future,reducing,state,tuple2,integer,long,result,get,kv,state,deadline,client,job,id,query,name,key,basic,type,info,reducing,state,false,executor,result,then,accept,response,try,tuple2,integer,long,res,response,get,counts,set,key,res,f1,assert,equals,key,mismatch,key,res,f0,int,value,catch,exception,e,assert,fail,e,get,message,futures,add,result,completable,future,all,of,futures,to,array,new,completable,future,futures,size,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,true,not,all,keys,are,non,zero,all,non,zero,for,int,i,0,i,num,keys,i,long,count,counts,get,i,assert,true,count,at,position,i,is,count,count,0
AbstractQueryableStateTestBase -> @Test 	@SuppressWarnings("unchecked") 	public void testQueryableState() throws Exception;1516812618;Runs a simple topology producing random (key, 1) pairs at the sources (where_number of keys is in fixed in range 0...numKeys). The records are keyed and_a reducing queryable state instance is created, which sums up the records.__<p>After submitting the job in detached mode, the QueryableStateCLient is used_to query the counts of each key in rounds until all keys have non-zero counts.;@Test_	@SuppressWarnings("unchecked")_	public void testQueryableState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name", new SumReduce(), 	source.getType())___		final String queryName = "hakuna-matata"___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7143749578983540352L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState(queryName, reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final AtomicLongArray counts = new AtomicLongArray(numKeys)___			final List<CompletableFuture<ReducingState<Tuple2<Integer, Long>>>> futures = new ArrayList<>(numKeys)___			boolean allNonZero = false__			while (!allNonZero && deadline.hasTimeLeft()) {_				allNonZero = true__				futures.clear()___				for (int i = 0_ i < numKeys_ i++) {_					final int key = i___					if (counts.get(key) > 0L) {_						_						continue__					} else {_						allNonZero = false__					}__					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> result = getKvState(_							deadline,_							client,_							jobId,_							queryName,_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					result.thenAccept(response -> {_						try {_							Tuple2<Integer, Long> res = response.get()__							counts.set(key, res.f1)__							assertEquals("Key mismatch", key, res.f0.intValue())__						} catch (Exception e) {_							Assert.fail(e.getMessage())__						}_					})___					futures.add(result)__				}__				_				CompletableFuture_						.allOf(futures.toArray(new CompletableFuture<?>[futures.size()]))_						.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			assertTrue("Not all keys are non-zero", allNonZero)___			_			for (int i = 0_ i < numKeys_ i++) {_				long count = counts.get(i)__				assertTrue("Count at position " + i + " is " + count, count > 0)__			}_		}_	};runs,a,simple,topology,producing,random,key,1,pairs,at,the,sources,where,number,of,keys,is,in,fixed,in,range,0,num,keys,the,records,are,keyed,and,a,reducing,queryable,state,instance,is,created,which,sums,up,the,records,p,after,submitting,the,job,in,detached,mode,the,queryable,state,client,is,used,to,query,the,counts,of,each,key,in,rounds,until,all,keys,have,non,zero,counts;test,suppress,warnings,unchecked,public,void,test,queryable,state,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,hakuna,matata,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7143749578983540352l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,atomic,long,array,counts,new,atomic,long,array,num,keys,final,list,completable,future,reducing,state,tuple2,integer,long,futures,new,array,list,num,keys,boolean,all,non,zero,false,while,all,non,zero,deadline,has,time,left,all,non,zero,true,futures,clear,for,int,i,0,i,num,keys,i,final,int,key,i,if,counts,get,key,0l,continue,else,all,non,zero,false,completable,future,reducing,state,tuple2,integer,long,result,get,kv,state,deadline,client,job,id,query,name,key,basic,type,info,reducing,state,false,executor,result,then,accept,response,try,tuple2,integer,long,res,response,get,counts,set,key,res,f1,assert,equals,key,mismatch,key,res,f0,int,value,catch,exception,e,assert,fail,e,get,message,futures,add,result,completable,future,all,of,futures,to,array,new,completable,future,futures,size,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,true,not,all,keys,are,non,zero,all,non,zero,for,int,i,0,i,num,keys,i,long,count,counts,get,i,assert,true,count,at,position,i,is,count,count,0
AbstractQueryableStateTestBase -> @Test 	@SuppressWarnings("unchecked") 	public void testQueryableState() throws Exception;1520781441;Runs a simple topology producing random (key, 1) pairs at the sources (where_number of keys is in fixed in range 0...numKeys). The records are keyed and_a reducing queryable state instance is created, which sums up the records.__<p>After submitting the job in detached mode, the QueryableStateCLient is used_to query the counts of each key in rounds until all keys have non-zero counts.;@Test_	@SuppressWarnings("unchecked")_	public void testQueryableState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name", new SumReduce(), 	source.getType())___		final String queryName = "hakuna-matata"___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7143749578983540352L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState(queryName, reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final AtomicLongArray counts = new AtomicLongArray(numKeys)___			final List<CompletableFuture<ReducingState<Tuple2<Integer, Long>>>> futures = new ArrayList<>(numKeys)___			boolean allNonZero = false__			while (!allNonZero && deadline.hasTimeLeft()) {_				allNonZero = true__				futures.clear()___				for (int i = 0_ i < numKeys_ i++) {_					final int key = i___					if (counts.get(key) > 0L) {_						_						continue__					} else {_						allNonZero = false__					}__					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> result = getKvState(_							deadline,_							client,_							jobId,_							queryName,_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					result.thenAccept(response -> {_						try {_							Tuple2<Integer, Long> res = response.get()__							counts.set(key, res.f1)__							assertEquals("Key mismatch", key, res.f0.intValue())__						} catch (Exception e) {_							Assert.fail(e.getMessage())__						}_					})___					futures.add(result)__				}__				_				CompletableFuture_						.allOf(futures.toArray(new CompletableFuture<?>[futures.size()]))_						.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			assertTrue("Not all keys are non-zero", allNonZero)___			_			for (int i = 0_ i < numKeys_ i++) {_				long count = counts.get(i)__				assertTrue("Count at position " + i + " is " + count, count > 0)__			}_		}_	};runs,a,simple,topology,producing,random,key,1,pairs,at,the,sources,where,number,of,keys,is,in,fixed,in,range,0,num,keys,the,records,are,keyed,and,a,reducing,queryable,state,instance,is,created,which,sums,up,the,records,p,after,submitting,the,job,in,detached,mode,the,queryable,state,client,is,used,to,query,the,counts,of,each,key,in,rounds,until,all,keys,have,non,zero,counts;test,suppress,warnings,unchecked,public,void,test,queryable,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,hakuna,matata,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7143749578983540352l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,atomic,long,array,counts,new,atomic,long,array,num,keys,final,list,completable,future,reducing,state,tuple2,integer,long,futures,new,array,list,num,keys,boolean,all,non,zero,false,while,all,non,zero,deadline,has,time,left,all,non,zero,true,futures,clear,for,int,i,0,i,num,keys,i,final,int,key,i,if,counts,get,key,0l,continue,else,all,non,zero,false,completable,future,reducing,state,tuple2,integer,long,result,get,kv,state,deadline,client,job,id,query,name,key,basic,type,info,reducing,state,false,executor,result,then,accept,response,try,tuple2,integer,long,res,response,get,counts,set,key,res,f1,assert,equals,key,mismatch,key,res,f0,int,value,catch,exception,e,assert,fail,e,get,message,futures,add,result,completable,future,all,of,futures,to,array,new,completable,future,futures,size,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,true,not,all,keys,are,non,zero,all,non,zero,for,int,i,0,i,num,keys,i,long,count,counts,get,i,assert,true,count,at,position,i,is,count,count,0
AbstractQueryableStateTestBase -> @Test 	@SuppressWarnings("unchecked") 	public void testQueryableState() throws Exception;1541420597;Runs a simple topology producing random (key, 1) pairs at the sources (where_number of keys is in fixed in range 0...numKeys). The records are keyed and_a reducing queryable state instance is created, which sums up the records.__<p>After submitting the job in detached mode, the QueryableStateCLient is used_to query the counts of each key in rounds until all keys have non-zero counts.;@Test_	@SuppressWarnings("unchecked")_	public void testQueryableState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name", new SumReduce(), 	source.getType())___		final String queryName = "hakuna-matata"___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7143749578983540352L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState(queryName, reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final AtomicLongArray counts = new AtomicLongArray(numKeys)___			final List<CompletableFuture<ReducingState<Tuple2<Integer, Long>>>> futures = new ArrayList<>(numKeys)___			boolean allNonZero = false__			while (!allNonZero && deadline.hasTimeLeft()) {_				allNonZero = true__				futures.clear()___				for (int i = 0_ i < numKeys_ i++) {_					final int key = i___					if (counts.get(key) > 0L) {_						_						continue__					} else {_						allNonZero = false__					}__					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> result = getKvState(_							deadline,_							client,_							jobId,_							queryName,_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					result.thenAccept(response -> {_						try {_							Tuple2<Integer, Long> res = response.get()__							counts.set(key, res.f1)__							assertEquals("Key mismatch", key, res.f0.intValue())__						} catch (Exception e) {_							Assert.fail(e.getMessage())__						}_					})___					futures.add(result)__				}__				_				CompletableFuture_						.allOf(futures.toArray(new CompletableFuture<?>[futures.size()]))_						.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			assertTrue("Not all keys are non-zero", allNonZero)___			_			for (int i = 0_ i < numKeys_ i++) {_				long count = counts.get(i)__				assertTrue("Count at position " + i + " is " + count, count > 0)__			}_		}_	};runs,a,simple,topology,producing,random,key,1,pairs,at,the,sources,where,number,of,keys,is,in,fixed,in,range,0,num,keys,the,records,are,keyed,and,a,reducing,queryable,state,instance,is,created,which,sums,up,the,records,p,after,submitting,the,job,in,detached,mode,the,queryable,state,client,is,used,to,query,the,counts,of,each,key,in,rounds,until,all,keys,have,non,zero,counts;test,suppress,warnings,unchecked,public,void,test,queryable,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,hakuna,matata,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7143749578983540352l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,atomic,long,array,counts,new,atomic,long,array,num,keys,final,list,completable,future,reducing,state,tuple2,integer,long,futures,new,array,list,num,keys,boolean,all,non,zero,false,while,all,non,zero,deadline,has,time,left,all,non,zero,true,futures,clear,for,int,i,0,i,num,keys,i,final,int,key,i,if,counts,get,key,0l,continue,else,all,non,zero,false,completable,future,reducing,state,tuple2,integer,long,result,get,kv,state,deadline,client,job,id,query,name,key,basic,type,info,reducing,state,false,executor,result,then,accept,response,try,tuple2,integer,long,res,response,get,counts,set,key,res,f1,assert,equals,key,mismatch,key,res,f0,int,value,catch,exception,e,assert,fail,e,get,message,futures,add,result,completable,future,all,of,futures,to,array,new,completable,future,futures,size,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,true,not,all,keys,are,non,zero,all,non,zero,for,int,i,0,i,num,keys,i,long,count,counts,get,i,assert,true,count,at,position,i,is,count,count,0
AbstractQueryableStateTestBase -> @Test 	@SuppressWarnings("unchecked") 	public void testQueryableState() throws Exception;1542282018;Runs a simple topology producing random (key, 1) pairs at the sources (where_number of keys is in fixed in range 0...numKeys). The records are keyed and_a reducing queryable state instance is created, which sums up the records.__<p>After submitting the job in detached mode, the QueryableStateCLient is used_to query the counts of each key in rounds until all keys have non-zero counts.;@Test_	@SuppressWarnings("unchecked")_	public void testQueryableState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name", new SumReduce(), 	source.getType())___		final String queryName = "hakuna-matata"___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7143749578983540352L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState(queryName, reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final AtomicLongArray counts = new AtomicLongArray(numKeys)___			final List<CompletableFuture<ReducingState<Tuple2<Integer, Long>>>> futures = new ArrayList<>(numKeys)___			boolean allNonZero = false__			while (!allNonZero && deadline.hasTimeLeft()) {_				allNonZero = true__				futures.clear()___				for (int i = 0_ i < numKeys_ i++) {_					final int key = i___					if (counts.get(key) > 0L) {_						_						continue__					} else {_						allNonZero = false__					}__					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> result = getKvState(_							deadline,_							client,_							jobId,_							queryName,_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					result.thenAccept(response -> {_						try {_							Tuple2<Integer, Long> res = response.get()__							counts.set(key, res.f1)__							assertEquals("Key mismatch", key, res.f0.intValue())__						} catch (Exception e) {_							Assert.fail(e.getMessage())__						}_					})___					futures.add(result)__				}__				_				CompletableFuture_						.allOf(futures.toArray(new CompletableFuture<?>[futures.size()]))_						.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			assertTrue("Not all keys are non-zero", allNonZero)___			_			for (int i = 0_ i < numKeys_ i++) {_				long count = counts.get(i)__				assertTrue("Count at position " + i + " is " + count, count > 0)__			}_		}_	};runs,a,simple,topology,producing,random,key,1,pairs,at,the,sources,where,number,of,keys,is,in,fixed,in,range,0,num,keys,the,records,are,keyed,and,a,reducing,queryable,state,instance,is,created,which,sums,up,the,records,p,after,submitting,the,job,in,detached,mode,the,queryable,state,client,is,used,to,query,the,counts,of,each,key,in,rounds,until,all,keys,have,non,zero,counts;test,suppress,warnings,unchecked,public,void,test,queryable,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,hakuna,matata,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7143749578983540352l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,atomic,long,array,counts,new,atomic,long,array,num,keys,final,list,completable,future,reducing,state,tuple2,integer,long,futures,new,array,list,num,keys,boolean,all,non,zero,false,while,all,non,zero,deadline,has,time,left,all,non,zero,true,futures,clear,for,int,i,0,i,num,keys,i,final,int,key,i,if,counts,get,key,0l,continue,else,all,non,zero,false,completable,future,reducing,state,tuple2,integer,long,result,get,kv,state,deadline,client,job,id,query,name,key,basic,type,info,reducing,state,false,executor,result,then,accept,response,try,tuple2,integer,long,res,response,get,counts,set,key,res,f1,assert,equals,key,mismatch,key,res,f0,int,value,catch,exception,e,assert,fail,e,get,message,futures,add,result,completable,future,all,of,futures,to,array,new,completable,future,futures,size,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,true,not,all,keys,are,non,zero,all,non,zero,for,int,i,0,i,num,keys,i,long,count,counts,get,i,assert,true,count,at,position,i,is,count,count,0
AbstractQueryableStateTestBase -> @Test 	@SuppressWarnings("unchecked") 	public void testQueryableState() throws Exception;1547024365;Runs a simple topology producing random (key, 1) pairs at the sources (where_number of keys is in fixed in range 0...numKeys). The records are keyed and_a reducing queryable state instance is created, which sums up the records.__<p>After submitting the job in detached mode, the QueryableStateCLient is used_to query the counts of each key in rounds until all keys have non-zero counts.;@Test_	@SuppressWarnings("unchecked")_	public void testQueryableState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name", new SumReduce(), 	source.getType())___		final String queryName = "hakuna-matata"___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7143749578983540352L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState(queryName, reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final AtomicLongArray counts = new AtomicLongArray(numKeys)___			final List<CompletableFuture<ReducingState<Tuple2<Integer, Long>>>> futures = new ArrayList<>(numKeys)___			boolean allNonZero = false__			while (!allNonZero && deadline.hasTimeLeft()) {_				allNonZero = true__				futures.clear()___				for (int i = 0_ i < numKeys_ i++) {_					final int key = i___					if (counts.get(key) > 0L) {_						_						continue__					} else {_						allNonZero = false__					}__					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> result = getKvState(_							deadline,_							client,_							jobId,_							queryName,_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					result.thenAccept(response -> {_						try {_							Tuple2<Integer, Long> res = response.get()__							counts.set(key, res.f1)__							assertEquals("Key mismatch", key, res.f0.intValue())__						} catch (Exception e) {_							Assert.fail(e.getMessage())__						}_					})___					futures.add(result)__				}__				_				CompletableFuture_						.allOf(futures.toArray(new CompletableFuture<?>[futures.size()]))_						.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			assertTrue("Not all keys are non-zero", allNonZero)___			_			for (int i = 0_ i < numKeys_ i++) {_				long count = counts.get(i)__				assertTrue("Count at position " + i + " is " + count, count > 0)__			}_		}_	};runs,a,simple,topology,producing,random,key,1,pairs,at,the,sources,where,number,of,keys,is,in,fixed,in,range,0,num,keys,the,records,are,keyed,and,a,reducing,queryable,state,instance,is,created,which,sums,up,the,records,p,after,submitting,the,job,in,detached,mode,the,queryable,state,client,is,used,to,query,the,counts,of,each,key,in,rounds,until,all,keys,have,non,zero,counts;test,suppress,warnings,unchecked,public,void,test,queryable,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,hakuna,matata,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7143749578983540352l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,atomic,long,array,counts,new,atomic,long,array,num,keys,final,list,completable,future,reducing,state,tuple2,integer,long,futures,new,array,list,num,keys,boolean,all,non,zero,false,while,all,non,zero,deadline,has,time,left,all,non,zero,true,futures,clear,for,int,i,0,i,num,keys,i,final,int,key,i,if,counts,get,key,0l,continue,else,all,non,zero,false,completable,future,reducing,state,tuple2,integer,long,result,get,kv,state,deadline,client,job,id,query,name,key,basic,type,info,reducing,state,false,executor,result,then,accept,response,try,tuple2,integer,long,res,response,get,counts,set,key,res,f1,assert,equals,key,mismatch,key,res,f0,int,value,catch,exception,e,assert,fail,e,get,message,futures,add,result,completable,future,all,of,futures,to,array,new,completable,future,futures,size,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,true,not,all,keys,are,non,zero,all,non,zero,for,int,i,0,i,num,keys,i,long,count,counts,get,i,assert,true,count,at,position,i,is,count,count,0
AbstractQueryableStateTestBase -> @Test 	@SuppressWarnings("unchecked") 	public void testQueryableState() throws Exception;1547024365;Runs a simple topology producing random (key, 1) pairs at the sources (where_number of keys is in fixed in range 0...numKeys). The records are keyed and_a reducing queryable state instance is created, which sums up the records.__<p>After submitting the job in detached mode, the QueryableStateCLient is used_to query the counts of each key in rounds until all keys have non-zero counts.;@Test_	@SuppressWarnings("unchecked")_	public void testQueryableState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name", new SumReduce(), 	source.getType())___		final String queryName = "hakuna-matata"___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 7143749578983540352L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).asQueryableState(queryName, reducingState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final AtomicLongArray counts = new AtomicLongArray(numKeys)___			final List<CompletableFuture<ReducingState<Tuple2<Integer, Long>>>> futures = new ArrayList<>(numKeys)___			boolean allNonZero = false__			while (!allNonZero && deadline.hasTimeLeft()) {_				allNonZero = true__				futures.clear()___				for (int i = 0_ i < numKeys_ i++) {_					final int key = i___					if (counts.get(key) > 0L) {_						_						continue__					} else {_						allNonZero = false__					}__					CompletableFuture<ReducingState<Tuple2<Integer, Long>>> result = getKvState(_							deadline,_							client,_							jobId,_							queryName,_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							reducingState,_							false,_							executor)___					result.thenAccept(response -> {_						try {_							Tuple2<Integer, Long> res = response.get()__							counts.set(key, res.f1)__							assertEquals("Key mismatch", key, res.f0.intValue())__						} catch (Exception e) {_							Assert.fail(e.getMessage())__						}_					})___					futures.add(result)__				}__				_				CompletableFuture_						.allOf(futures.toArray(new CompletableFuture<?>[futures.size()]))_						.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			assertTrue("Not all keys are non-zero", allNonZero)___			_			for (int i = 0_ i < numKeys_ i++) {_				long count = counts.get(i)__				assertTrue("Count at position " + i + " is " + count, count > 0)__			}_		}_	};runs,a,simple,topology,producing,random,key,1,pairs,at,the,sources,where,number,of,keys,is,in,fixed,in,range,0,num,keys,the,records,are,keyed,and,a,reducing,queryable,state,instance,is,created,which,sums,up,the,records,p,after,submitting,the,job,in,detached,mode,the,queryable,state,client,is,used,to,query,the,counts,of,each,key,in,rounds,until,all,keys,have,non,zero,counts;test,suppress,warnings,unchecked,public,void,test,queryable,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,hakuna,matata,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,7143749578983540352l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,atomic,long,array,counts,new,atomic,long,array,num,keys,final,list,completable,future,reducing,state,tuple2,integer,long,futures,new,array,list,num,keys,boolean,all,non,zero,false,while,all,non,zero,deadline,has,time,left,all,non,zero,true,futures,clear,for,int,i,0,i,num,keys,i,final,int,key,i,if,counts,get,key,0l,continue,else,all,non,zero,false,completable,future,reducing,state,tuple2,integer,long,result,get,kv,state,deadline,client,job,id,query,name,key,basic,type,info,reducing,state,false,executor,result,then,accept,response,try,tuple2,integer,long,res,response,get,counts,set,key,res,f1,assert,equals,key,mismatch,key,res,f0,int,value,catch,exception,e,assert,fail,e,get,message,futures,add,result,completable,future,all,of,futures,to,array,new,completable,future,futures,size,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,true,not,all,keys,are,non,zero,all,non,zero,for,int,i,0,i,num,keys,i,long,count,counts,get,i,assert,true,count,at,position,i,is,count,count,0
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1509037054;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {__		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env =_				StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies_				.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_				.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState =_				new ValueStateDescriptor<>(_					"any",_					source.getType(),_					Tuple2.of(0, 1337L))___			_			QueryableStateStream<Integer, Tuple2<Integer, Long>>_				queryableState =_				source.keyBy(_					new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = 4509274556892655887L___						@Override_						public Integer getKey(_							Tuple2<Integer, Long> value) throws_							Exception {_							return 1__						}_					}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvStateWithRetries(_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					QUERY_RETRY_DELAY,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		} finally {__			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,1,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,with,retries,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1510910970;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {__		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env =_				StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies_				.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_				.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState =_				new ValueStateDescriptor<>(_					"any",_					source.getType(),_					Tuple2.of(0, 1337L))___			_			QueryableStateStream<Integer, Tuple2<Integer, Long>>_				queryableState =_				source.keyBy(_					new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = 4509274556892655887L___						@Override_						public Integer getKey(_							Tuple2<Integer, Long> value) throws_							Exception {_							return 1__						}_					}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_					deadline,_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		} finally {__			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,1,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1510911968;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {__		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env =_				StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies_				.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_				.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState =_				new ValueStateDescriptor<>(_					"any",_					source.getType(),_					Tuple2.of(0, 1337L))___			_			QueryableStateStream<Integer, Tuple2<Integer, Long>>_				queryableState =_				source.keyBy(_					new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = 4509274556892655887L___						@Override_						public Integer getKey(_							Tuple2<Integer, Long> value) throws_							Exception {_							return 1__						}_					}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_					deadline,_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		} finally {__			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,1,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1510911970;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {__		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env =_				StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies_				.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_				.addSource(new TestAscendingValueSource(numElements))___			_			ValueStateDescriptor<Tuple2<Integer, Long>> valueState =_				new ValueStateDescriptor<>(_					"any",_					source.getType(),_					Tuple2.of(0, 1337L))___			_			QueryableStateStream<Integer, Tuple2<Integer, Long>>_				queryableState =_				source.keyBy(_					new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = 4509274556892655887L___						@Override_						public Integer getKey(_							Tuple2<Integer, Long> value) throws_							Exception {_							return 1__						}_					}).asQueryableState("hakuna", valueState)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_					deadline,_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		} finally {__			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,1,as,queryable,state,hakuna,value,state,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1512567208;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any", source.getType(), 	Tuple2.of(0, 1337L))___		_		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState = source.keyBy(_				new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 4509274556892655887L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return 1__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_					deadline,_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,return,1,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1513261599;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any", source.getType(), 	Tuple2.of(0, 1337L))___		_		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState = source.keyBy(_				new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 4509274556892655887L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return 1__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_					deadline,_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,return,1,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1516812618;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any", source.getType(), 	Tuple2.of(0, 1337L))___		_		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState = source.keyBy(_				new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 4509274556892655887L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return 1__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_					deadline,_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,return,1,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1520781441;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any", source.getType(), 	Tuple2.of(0, 1337L))___		_		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState = source.keyBy(_				new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 4509274556892655887L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return 1__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_					deadline,_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,return,1,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1541420597;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any", source.getType(), 	Tuple2.of(0, 1337L))___		_		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState = source.keyBy(_				new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 4509274556892655887L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return 1__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_					deadline,_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,return,1,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1542282018;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any", source.getType(), 	Tuple2.of(0, 1337L))___		_		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState = source.keyBy(_				new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 4509274556892655887L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return 1__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_					deadline,_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,return,1,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1547024365;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any", source.getType(), 	Tuple2.of(0, 1337L))___		_		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState = source.keyBy(_				new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 4509274556892655887L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return 1__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_					deadline,_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,return,1,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1547024365;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any", source.getType(), 	Tuple2.of(0, 1337L))___		_		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState = source.keyBy(_				new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 4509274556892655887L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return 1__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_					deadline,_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,return,1,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause
AbstractQueryableStateTestBase -> @Test(expected = UnknownKeyOrNamespaceException.class) 	public void testValueStateDefault() throws Throwable;1547024365;Tests simple value state queryable state instance with a default value_set. Each source emits (subtaskIndex, 0)..(subtaskIndex, numElements)_tuples, the key is mapped to 1 but key 0 is queried which should throw_a {@link UnknownKeyOrNamespaceException} exception.__@throws UnknownKeyOrNamespaceException thrown due querying a non-existent key;@Test(expected = UnknownKeyOrNamespaceException.class)_	public void testValueStateDefault() throws Throwable {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		ValueStateDescriptor<Tuple2<Integer, Long>> valueState = new ValueStateDescriptor<>(_				"any", source.getType(), 	Tuple2.of(0, 1337L))___		_		QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState = source.keyBy(_				new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = 4509274556892655887L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return 1__					}_				}).asQueryableState("hakuna", valueState)___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			_			int key = 0__			CompletableFuture<ValueState<Tuple2<Integer, Long>>> future = getKvState(_					deadline,_					client,_					jobId,_					queryableState.getQueryableStateName(),_					key,_					BasicTypeInfo.INT_TYPE_INFO,_					valueState,_					true,_					executor)___			try {_				future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			} catch (ExecutionException | CompletionException e) {_				_				_				throw e.getCause()__			}_		}_	};tests,simple,value,state,queryable,state,instance,with,a,default,value,set,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,the,key,is,mapped,to,1,but,key,0,is,queried,which,should,throw,a,link,unknown,key,or,namespace,exception,exception,throws,unknown,key,or,namespace,exception,thrown,due,querying,a,non,existent,key;test,expected,unknown,key,or,namespace,exception,class,public,void,test,value,state,default,throws,throwable,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,value,state,descriptor,tuple2,integer,long,value,state,new,value,state,descriptor,any,source,get,type,tuple2,of,0,1337l,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4509274556892655887l,override,public,integer,get,key,tuple2,integer,long,value,return,1,as,queryable,state,hakuna,value,state,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,int,key,0,completable,future,value,state,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,queryable,state,get,queryable,state,name,key,basic,type,info,value,state,true,executor,try,future,get,deadline,time,left,to,millis,time,unit,milliseconds,catch,execution,exception,completion,exception,e,throw,e,get,cause
AbstractQueryableStateTestBase -> @Test 	public void testDuplicateRegistrationFailsJob() throws Exception;1509037054;Tests that duplicate query registrations fail the job at the JobManager.__<b>NOTE: </b> This test is only in the non-HA variant of the tests because_in the HA mode we use the actual JM code which does not recognize the_{@code NotifyWhenJobStatus} message.	 *;@Test_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		JobID jobId = null___		try {_			_			_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestKeyRangeSource(numKeys))___			_			ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_					"any-name",_					new SumReduce(),_					source.getType())___			final String queryName = "duplicate-me"___			final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = -4126824763829132959L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState(queryName, reducingState)___			final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = -6265024000462809436L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState(queryName)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			CompletableFuture<TestingJobManagerMessages.JobStatusIs> failedFuture = FutureUtils.toJava(_					cluster.getLeaderGateway(deadline.timeLeft())_							.ask(new TestingJobManagerMessages.NotifyWhenJobStatus(jobId, JobStatus.FAILED), deadline.timeLeft())_							.mapTo(ClassTag$.MODULE$.<TestingJobManagerMessages.JobStatusIs>apply(TestingJobManagerMessages.JobStatusIs.class)))___			cluster.submitJobDetached(jobGraph)___			TestingJobManagerMessages.JobStatusIs jobStatus =_					failedFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			assertEquals(JobStatus.FAILED, jobStatus.state())___			_			JobManagerMessages.JobFound jobFound = FutureUtils.toJava(_					cluster.getLeaderGateway(deadline.timeLeft())_							.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft())_							.mapTo(ClassTag$.MODULE$.<JobManagerMessages.JobFound>apply(JobManagerMessages.JobFound.class)))_					.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			String failureCause = jobFound.executionGraph().getFailureCause().getExceptionAsString()___			assertTrue("Not instance of SuppressRestartsException", failureCause.startsWith("org.apache.flink.runtime.execution.SuppressRestartsException"))__			int causedByIndex = failureCause.indexOf("Caused by: ")__			String subFailureCause = failureCause.substring(causedByIndex + "Caused by: ".length())__			assertTrue("Not caused by IllegalStateException", subFailureCause.startsWith("java.lang.IllegalStateException"))__			assertTrue("Exception does not contain registration name", subFailureCause.contains(queryName))__		} finally {_			_			if (jobId != null) {_				scala.concurrent.Future<CancellationSuccess> cancellation = cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<JobManagerMessages.CancellationSuccess>apply(JobManagerMessages.CancellationSuccess.class))___				Await.ready(cancellation, deadline.timeLeft())__			}_		}_	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager,b,note,b,this,test,is,only,in,the,non,ha,variant,of,the,tests,because,in,the,ha,mode,we,use,the,actual,jm,code,which,does,not,recognize,the,code,notify,when,job,status,message;test,public,void,test,duplicate,registration,fails,job,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,query,name,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,completable,future,testing,job,manager,messages,job,status,is,failed,future,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,testing,job,manager,messages,notify,when,job,status,job,id,job,status,failed,deadline,time,left,map,to,class,tag,module,testing,job,manager,messages,job,status,is,apply,testing,job,manager,messages,job,status,is,class,cluster,submit,job,detached,job,graph,testing,job,manager,messages,job,status,is,job,status,failed,future,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,equals,job,status,failed,job,status,state,job,manager,messages,job,found,job,found,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,map,to,class,tag,module,job,manager,messages,job,found,apply,job,manager,messages,job,found,class,get,deadline,time,left,to,millis,time,unit,milliseconds,string,failure,cause,job,found,execution,graph,get,failure,cause,get,exception,as,string,assert,true,not,instance,of,suppress,restarts,exception,failure,cause,starts,with,org,apache,flink,runtime,execution,suppress,restarts,exception,int,caused,by,index,failure,cause,index,of,caused,by,string,sub,failure,cause,failure,cause,substring,caused,by,index,caused,by,length,assert,true,not,caused,by,illegal,state,exception,sub,failure,cause,starts,with,java,lang,illegal,state,exception,assert,true,exception,does,not,contain,registration,name,sub,failure,cause,contains,query,name,finally,if,job,id,null,scala,concurrent,future,cancellation,success,cancellation,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,job,manager,messages,cancellation,success,apply,job,manager,messages,cancellation,success,class,await,ready,cancellation,deadline,time,left
AbstractQueryableStateTestBase -> @Test 	public void testDuplicateRegistrationFailsJob() throws Exception;1510910970;Tests that duplicate query registrations fail the job at the JobManager.__<b>NOTE: </b> This test is only in the non-HA variant of the tests because_in the HA mode we use the actual JM code which does not recognize the_{@code NotifyWhenJobStatus} message.;@Test_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		JobID jobId = null___		try {_			_			_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestKeyRangeSource(numKeys))___			_			ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_					"any-name",_					new SumReduce(),_					source.getType())___			final String queryName = "duplicate-me"___			final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = -4126824763829132959L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState(queryName, reducingState)___			final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = -6265024000462809436L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState(queryName)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			CompletableFuture<TestingJobManagerMessages.JobStatusIs> failedFuture = FutureUtils.toJava(_					cluster.getLeaderGateway(deadline.timeLeft())_							.ask(new TestingJobManagerMessages.NotifyWhenJobStatus(jobId, JobStatus.FAILED), deadline.timeLeft())_							.mapTo(ClassTag$.MODULE$.<TestingJobManagerMessages.JobStatusIs>apply(TestingJobManagerMessages.JobStatusIs.class)))___			cluster.submitJobDetached(jobGraph)___			TestingJobManagerMessages.JobStatusIs jobStatus =_					failedFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			assertEquals(JobStatus.FAILED, jobStatus.state())___			_			JobManagerMessages.JobFound jobFound = FutureUtils.toJava(_					cluster.getLeaderGateway(deadline.timeLeft())_							.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft())_							.mapTo(ClassTag$.MODULE$.<JobManagerMessages.JobFound>apply(JobManagerMessages.JobFound.class)))_					.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			String failureCause = jobFound.executionGraph().getFailureCause().getExceptionAsString()___			assertTrue("Not instance of SuppressRestartsException", failureCause.startsWith("org.apache.flink.runtime.execution.SuppressRestartsException"))__			int causedByIndex = failureCause.indexOf("Caused by: ")__			String subFailureCause = failureCause.substring(causedByIndex + "Caused by: ".length())__			assertTrue("Not caused by IllegalStateException", subFailureCause.startsWith("java.lang.IllegalStateException"))__			assertTrue("Exception does not contain registration name", subFailureCause.contains(queryName))__		} finally {_			_			if (jobId != null) {_				scala.concurrent.Future<CancellationSuccess> cancellation = cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<JobManagerMessages.CancellationSuccess>apply(JobManagerMessages.CancellationSuccess.class))___				Await.ready(cancellation, deadline.timeLeft())__			}_		}_	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager,b,note,b,this,test,is,only,in,the,non,ha,variant,of,the,tests,because,in,the,ha,mode,we,use,the,actual,jm,code,which,does,not,recognize,the,code,notify,when,job,status,message;test,public,void,test,duplicate,registration,fails,job,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,query,name,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,completable,future,testing,job,manager,messages,job,status,is,failed,future,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,testing,job,manager,messages,notify,when,job,status,job,id,job,status,failed,deadline,time,left,map,to,class,tag,module,testing,job,manager,messages,job,status,is,apply,testing,job,manager,messages,job,status,is,class,cluster,submit,job,detached,job,graph,testing,job,manager,messages,job,status,is,job,status,failed,future,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,equals,job,status,failed,job,status,state,job,manager,messages,job,found,job,found,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,map,to,class,tag,module,job,manager,messages,job,found,apply,job,manager,messages,job,found,class,get,deadline,time,left,to,millis,time,unit,milliseconds,string,failure,cause,job,found,execution,graph,get,failure,cause,get,exception,as,string,assert,true,not,instance,of,suppress,restarts,exception,failure,cause,starts,with,org,apache,flink,runtime,execution,suppress,restarts,exception,int,caused,by,index,failure,cause,index,of,caused,by,string,sub,failure,cause,failure,cause,substring,caused,by,index,caused,by,length,assert,true,not,caused,by,illegal,state,exception,sub,failure,cause,starts,with,java,lang,illegal,state,exception,assert,true,exception,does,not,contain,registration,name,sub,failure,cause,contains,query,name,finally,if,job,id,null,scala,concurrent,future,cancellation,success,cancellation,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,job,manager,messages,cancellation,success,apply,job,manager,messages,cancellation,success,class,await,ready,cancellation,deadline,time,left
AbstractQueryableStateTestBase -> @Test 	public void testDuplicateRegistrationFailsJob() throws Exception;1510911968;Tests that duplicate query registrations fail the job at the JobManager.__<b>NOTE: </b> This test is only in the non-HA variant of the tests because_in the HA mode we use the actual JM code which does not recognize the_{@code NotifyWhenJobStatus} message.;@Test_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		JobID jobId = null___		try {_			_			_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestKeyRangeSource(numKeys))___			_			ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_					"any-name",_					new SumReduce(),_					source.getType())___			final String queryName = "duplicate-me"___			final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = -4126824763829132959L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState(queryName, reducingState)___			final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = -6265024000462809436L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState(queryName)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			CompletableFuture<TestingJobManagerMessages.JobStatusIs> failedFuture = FutureUtils.toJava(_					cluster.getLeaderGateway(deadline.timeLeft())_							.ask(new TestingJobManagerMessages.NotifyWhenJobStatus(jobId, JobStatus.FAILED), deadline.timeLeft())_							.mapTo(ClassTag$.MODULE$.<TestingJobManagerMessages.JobStatusIs>apply(TestingJobManagerMessages.JobStatusIs.class)))___			cluster.submitJobDetached(jobGraph)___			TestingJobManagerMessages.JobStatusIs jobStatus =_					failedFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			assertEquals(JobStatus.FAILED, jobStatus.state())___			_			JobManagerMessages.JobFound jobFound = FutureUtils.toJava(_					cluster.getLeaderGateway(deadline.timeLeft())_							.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft())_							.mapTo(ClassTag$.MODULE$.<JobManagerMessages.JobFound>apply(JobManagerMessages.JobFound.class)))_					.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			String failureCause = jobFound.executionGraph().getFailureCause().getExceptionAsString()___			assertTrue("Not instance of SuppressRestartsException", failureCause.startsWith("org.apache.flink.runtime.execution.SuppressRestartsException"))__			int causedByIndex = failureCause.indexOf("Caused by: ")__			String subFailureCause = failureCause.substring(causedByIndex + "Caused by: ".length())__			assertTrue("Not caused by IllegalStateException", subFailureCause.startsWith("java.lang.IllegalStateException"))__			assertTrue("Exception does not contain registration name", subFailureCause.contains(queryName))__		} finally {_			_			if (jobId != null) {_				scala.concurrent.Future<CancellationSuccess> cancellation = cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<JobManagerMessages.CancellationSuccess>apply(JobManagerMessages.CancellationSuccess.class))___				Await.ready(cancellation, deadline.timeLeft())__			}_		}_	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager,b,note,b,this,test,is,only,in,the,non,ha,variant,of,the,tests,because,in,the,ha,mode,we,use,the,actual,jm,code,which,does,not,recognize,the,code,notify,when,job,status,message;test,public,void,test,duplicate,registration,fails,job,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,query,name,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,completable,future,testing,job,manager,messages,job,status,is,failed,future,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,testing,job,manager,messages,notify,when,job,status,job,id,job,status,failed,deadline,time,left,map,to,class,tag,module,testing,job,manager,messages,job,status,is,apply,testing,job,manager,messages,job,status,is,class,cluster,submit,job,detached,job,graph,testing,job,manager,messages,job,status,is,job,status,failed,future,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,equals,job,status,failed,job,status,state,job,manager,messages,job,found,job,found,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,map,to,class,tag,module,job,manager,messages,job,found,apply,job,manager,messages,job,found,class,get,deadline,time,left,to,millis,time,unit,milliseconds,string,failure,cause,job,found,execution,graph,get,failure,cause,get,exception,as,string,assert,true,not,instance,of,suppress,restarts,exception,failure,cause,starts,with,org,apache,flink,runtime,execution,suppress,restarts,exception,int,caused,by,index,failure,cause,index,of,caused,by,string,sub,failure,cause,failure,cause,substring,caused,by,index,caused,by,length,assert,true,not,caused,by,illegal,state,exception,sub,failure,cause,starts,with,java,lang,illegal,state,exception,assert,true,exception,does,not,contain,registration,name,sub,failure,cause,contains,query,name,finally,if,job,id,null,scala,concurrent,future,cancellation,success,cancellation,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,job,manager,messages,cancellation,success,apply,job,manager,messages,cancellation,success,class,await,ready,cancellation,deadline,time,left
AbstractQueryableStateTestBase -> @Test 	public void testDuplicateRegistrationFailsJob() throws Exception;1510911970;Tests that duplicate query registrations fail the job at the JobManager.;@Test_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		JobID jobId = null___		try {_			_			_			_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestKeyRangeSource(numKeys))___			_			ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_					"any-name",_					new SumReduce(),_					source.getType())___			final String queryName = "duplicate-me"___			final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = -4126824763829132959L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState(queryName, reducingState)___			final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_					source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_						private static final long serialVersionUID = -6265024000462809436L___						@Override_						public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_							return value.f0__						}_					}).asQueryableState(queryName)___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			CompletableFuture<TestingJobManagerMessages.JobStatusIs> failedFuture = FutureUtils.toJava(_					cluster.getLeaderGateway(deadline.timeLeft())_							.ask(new TestingJobManagerMessages.NotifyWhenJobStatus(jobId, JobStatus.FAILED), deadline.timeLeft())_							.mapTo(ClassTag$.MODULE$.<TestingJobManagerMessages.JobStatusIs>apply(TestingJobManagerMessages.JobStatusIs.class)))___			cluster.submitJobDetached(jobGraph)___			TestingJobManagerMessages.JobStatusIs jobStatus =_					failedFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			assertEquals(JobStatus.FAILED, jobStatus.state())___			_			JobManagerMessages.JobFound jobFound = FutureUtils.toJava(_					cluster.getLeaderGateway(deadline.timeLeft())_							.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft())_							.mapTo(ClassTag$.MODULE$.<JobManagerMessages.JobFound>apply(JobManagerMessages.JobFound.class)))_					.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			String failureCause = jobFound.executionGraph().getFailureCause().getExceptionAsString()___			assertTrue("Not instance of SuppressRestartsException", failureCause.startsWith("org.apache.flink.runtime.execution.SuppressRestartsException"))__			int causedByIndex = failureCause.indexOf("Caused by: ")__			String subFailureCause = failureCause.substring(causedByIndex + "Caused by: ".length())__			assertTrue("Not caused by IllegalStateException", subFailureCause.startsWith("java.lang.IllegalStateException"))__			assertTrue("Exception does not contain registration name", subFailureCause.contains(queryName))__		} finally {_			_			if (jobId != null) {_				scala.concurrent.Future<CancellationSuccess> cancellation = cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<JobManagerMessages.CancellationSuccess>apply(JobManagerMessages.CancellationSuccess.class))___				Await.ready(cancellation, deadline.timeLeft())__			}_		}_	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager;test,public,void,test,duplicate,registration,fails,job,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,as,queryable,state,query,name,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,completable,future,testing,job,manager,messages,job,status,is,failed,future,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,testing,job,manager,messages,notify,when,job,status,job,id,job,status,failed,deadline,time,left,map,to,class,tag,module,testing,job,manager,messages,job,status,is,apply,testing,job,manager,messages,job,status,is,class,cluster,submit,job,detached,job,graph,testing,job,manager,messages,job,status,is,job,status,failed,future,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,equals,job,status,failed,job,status,state,job,manager,messages,job,found,job,found,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,map,to,class,tag,module,job,manager,messages,job,found,apply,job,manager,messages,job,found,class,get,deadline,time,left,to,millis,time,unit,milliseconds,string,failure,cause,job,found,execution,graph,get,failure,cause,get,exception,as,string,assert,true,not,instance,of,suppress,restarts,exception,failure,cause,starts,with,org,apache,flink,runtime,execution,suppress,restarts,exception,int,caused,by,index,failure,cause,index,of,caused,by,string,sub,failure,cause,failure,cause,substring,caused,by,index,caused,by,length,assert,true,not,caused,by,illegal,state,exception,sub,failure,cause,starts,with,java,lang,illegal,state,exception,assert,true,exception,does,not,contain,registration,name,sub,failure,cause,contains,query,name,finally,if,job,id,null,scala,concurrent,future,cancellation,success,cancellation,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,job,manager,messages,cancellation,success,apply,job,manager,messages,cancellation,success,class,await,ready,cancellation,deadline,time,left
AbstractQueryableStateTestBase -> @Test 	public void testDuplicateRegistrationFailsJob() throws Exception;1512567208;Tests that duplicate query registrations fail the job at the JobManager.;@Test_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		_		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name",_				new SumReduce(),_				source.getType())___		final String queryName = "duplicate-me"___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -4126824763829132959L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName, reducingState)___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -6265024000462809436L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName)___		_		final JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		final JobID jobId = jobGraph.getJobID()___		final CompletableFuture<TestingJobManagerMessages.JobStatusIs> failedFuture =_				notifyWhenJobStatusIs(jobId, JobStatus.FAILED, deadline)___		final CompletableFuture<TestingJobManagerMessages.JobStatusIs> cancellationFuture =_				notifyWhenJobStatusIs(jobId, JobStatus.CANCELED, deadline)___		cluster.submitJobDetached(jobGraph)___		try {_			final TestingJobManagerMessages.JobStatusIs jobStatus =_					failedFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			assertEquals(JobStatus.FAILED, jobStatus.state())__		} catch (Exception e) {__			_			_			__			if (jobId != null) {_				cluster.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class))___				cancellationFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			_			throw e__		}__		_		JobManagerMessages.JobFound jobFound = FutureUtils.toJava(_				cluster.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<JobManagerMessages.JobFound>apply(JobManagerMessages.JobFound.class)))_				.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___		String failureCause = jobFound.executionGraph().getFailureCause().getExceptionAsString()___		assertEquals(JobStatus.FAILED, jobFound.executionGraph().getState())__		assertTrue("Not instance of SuppressRestartsException", failureCause.startsWith("org.apache.flink.runtime.execution.SuppressRestartsException"))__		int causedByIndex = failureCause.indexOf("Caused by: ")__		String subFailureCause = failureCause.substring(causedByIndex + "Caused by: ".length())__		assertTrue("Not caused by IllegalStateException", subFailureCause.startsWith("java.lang.IllegalStateException"))__		assertTrue("Exception does not contain registration name", subFailureCause.contains(queryName))__	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager;test,public,void,test,duplicate,registration,fails,job,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,final,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,job,id,job,id,job,graph,get,job,id,final,completable,future,testing,job,manager,messages,job,status,is,failed,future,notify,when,job,status,is,job,id,job,status,failed,deadline,final,completable,future,testing,job,manager,messages,job,status,is,cancellation,future,notify,when,job,status,is,job,id,job,status,canceled,deadline,cluster,submit,job,detached,job,graph,try,final,testing,job,manager,messages,job,status,is,job,status,failed,future,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,equals,job,status,failed,job,status,state,catch,exception,e,if,job,id,null,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,future,get,deadline,time,left,to,millis,time,unit,milliseconds,throw,e,job,manager,messages,job,found,job,found,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,map,to,class,tag,module,job,manager,messages,job,found,apply,job,manager,messages,job,found,class,get,deadline,time,left,to,millis,time,unit,milliseconds,string,failure,cause,job,found,execution,graph,get,failure,cause,get,exception,as,string,assert,equals,job,status,failed,job,found,execution,graph,get,state,assert,true,not,instance,of,suppress,restarts,exception,failure,cause,starts,with,org,apache,flink,runtime,execution,suppress,restarts,exception,int,caused,by,index,failure,cause,index,of,caused,by,string,sub,failure,cause,failure,cause,substring,caused,by,index,caused,by,length,assert,true,not,caused,by,illegal,state,exception,sub,failure,cause,starts,with,java,lang,illegal,state,exception,assert,true,exception,does,not,contain,registration,name,sub,failure,cause,contains,query,name
AbstractQueryableStateTestBase -> @Test 	public void testDuplicateRegistrationFailsJob() throws Exception;1513261599;Tests that duplicate query registrations fail the job at the JobManager.;@Test_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		_		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name",_				new SumReduce(),_				source.getType())___		final String queryName = "duplicate-me"___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -4126824763829132959L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName, reducingState)___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -6265024000462809436L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName)___		_		final JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		final JobID jobId = jobGraph.getJobID()___		final CompletableFuture<TestingJobManagerMessages.JobStatusIs> failedFuture =_				notifyWhenJobStatusIs(jobId, JobStatus.FAILED, deadline)___		final CompletableFuture<TestingJobManagerMessages.JobStatusIs> cancellationFuture =_				notifyWhenJobStatusIs(jobId, JobStatus.CANCELED, deadline)___		cluster.submitJobDetached(jobGraph)___		try {_			final TestingJobManagerMessages.JobStatusIs jobStatus =_					failedFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			assertEquals(JobStatus.FAILED, jobStatus.state())__		} catch (Exception e) {__			_			_			__			if (jobId != null) {_				cluster.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class))___				cancellationFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			_			throw e__		}__		_		JobManagerMessages.JobFound jobFound = FutureUtils.toJava(_				cluster.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<JobManagerMessages.JobFound>apply(JobManagerMessages.JobFound.class)))_				.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___		String failureCause = jobFound.executionGraph().getFailureCause().getExceptionAsString()___		assertEquals(JobStatus.FAILED, jobFound.executionGraph().getState())__		assertTrue("Not instance of SuppressRestartsException", failureCause.startsWith("org.apache.flink.runtime.execution.SuppressRestartsException"))__		int causedByIndex = failureCause.indexOf("Caused by: ")__		String subFailureCause = failureCause.substring(causedByIndex + "Caused by: ".length())__		assertTrue("Not caused by IllegalStateException", subFailureCause.startsWith("java.lang.IllegalStateException"))__		assertTrue("Exception does not contain registration name", subFailureCause.contains(queryName))__	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager;test,public,void,test,duplicate,registration,fails,job,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,final,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,job,id,job,id,job,graph,get,job,id,final,completable,future,testing,job,manager,messages,job,status,is,failed,future,notify,when,job,status,is,job,id,job,status,failed,deadline,final,completable,future,testing,job,manager,messages,job,status,is,cancellation,future,notify,when,job,status,is,job,id,job,status,canceled,deadline,cluster,submit,job,detached,job,graph,try,final,testing,job,manager,messages,job,status,is,job,status,failed,future,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,equals,job,status,failed,job,status,state,catch,exception,e,if,job,id,null,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,future,get,deadline,time,left,to,millis,time,unit,milliseconds,throw,e,job,manager,messages,job,found,job,found,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,map,to,class,tag,module,job,manager,messages,job,found,apply,job,manager,messages,job,found,class,get,deadline,time,left,to,millis,time,unit,milliseconds,string,failure,cause,job,found,execution,graph,get,failure,cause,get,exception,as,string,assert,equals,job,status,failed,job,found,execution,graph,get,state,assert,true,not,instance,of,suppress,restarts,exception,failure,cause,starts,with,org,apache,flink,runtime,execution,suppress,restarts,exception,int,caused,by,index,failure,cause,index,of,caused,by,string,sub,failure,cause,failure,cause,substring,caused,by,index,caused,by,length,assert,true,not,caused,by,illegal,state,exception,sub,failure,cause,starts,with,java,lang,illegal,state,exception,assert,true,exception,does,not,contain,registration,name,sub,failure,cause,contains,query,name
AbstractQueryableStateTestBase -> @Test 	public void testDuplicateRegistrationFailsJob() throws Exception;1516812618;Tests that duplicate query registrations fail the job at the JobManager.;@Test_	public void testDuplicateRegistrationFailsJob() throws Exception {_		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final int numKeys = 256___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestKeyRangeSource(numKeys))___		_		ReducingStateDescriptor<Tuple2<Integer, Long>> reducingState = new ReducingStateDescriptor<>(_				"any-name",_				new SumReduce(),_				source.getType())___		final String queryName = "duplicate-me"___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> queryableState =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -4126824763829132959L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName, reducingState)___		final QueryableStateStream<Integer, Tuple2<Integer, Long>> duplicate =_				source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_					private static final long serialVersionUID = -6265024000462809436L___					@Override_					public Integer getKey(Tuple2<Integer, Long> value) {_						return value.f0__					}_				}).asQueryableState(queryName)___		_		final JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		final JobID jobId = jobGraph.getJobID()___		final CompletableFuture<TestingJobManagerMessages.JobStatusIs> failedFuture =_				notifyWhenJobStatusIs(jobId, JobStatus.FAILED, deadline)___		final CompletableFuture<TestingJobManagerMessages.JobStatusIs> cancellationFuture =_				notifyWhenJobStatusIs(jobId, JobStatus.CANCELED, deadline)___		cluster.submitJobDetached(jobGraph)___		try {_			final TestingJobManagerMessages.JobStatusIs jobStatus =_					failedFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			assertEquals(JobStatus.FAILED, jobStatus.state())__		} catch (Exception e) {__			_			_			__			if (jobId != null) {_				cluster.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class))___				cancellationFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}__			_			throw e__		}__		_		JobManagerMessages.JobFound jobFound = FutureUtils.toJava(_				cluster.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.RequestJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<JobManagerMessages.JobFound>apply(JobManagerMessages.JobFound.class)))_				.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___		String failureCause = jobFound.executionGraph().getFailureInfo().getExceptionAsString()___		assertEquals(JobStatus.FAILED, jobFound.executionGraph().getState())__		assertTrue("Not instance of SuppressRestartsException", failureCause.startsWith("org.apache.flink.runtime.execution.SuppressRestartsException"))__		int causedByIndex = failureCause.indexOf("Caused by: ")__		String subFailureCause = failureCause.substring(causedByIndex + "Caused by: ".length())__		assertTrue("Not caused by IllegalStateException", subFailureCause.startsWith("java.lang.IllegalStateException"))__		assertTrue("Exception does not contain registration name", subFailureCause.contains(queryName))__	};tests,that,duplicate,query,registrations,fail,the,job,at,the,job,manager;test,public,void,test,duplicate,registration,fails,job,throws,exception,final,deadline,deadline,from,now,final,int,num,keys,256,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,key,range,source,num,keys,reducing,state,descriptor,tuple2,integer,long,reducing,state,new,reducing,state,descriptor,any,name,new,sum,reduce,source,get,type,final,string,query,name,duplicate,me,final,queryable,state,stream,integer,tuple2,integer,long,queryable,state,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,4126824763829132959l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,reducing,state,final,queryable,state,stream,integer,tuple2,integer,long,duplicate,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,6265024000462809436l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,as,queryable,state,query,name,final,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,job,id,job,id,job,graph,get,job,id,final,completable,future,testing,job,manager,messages,job,status,is,failed,future,notify,when,job,status,is,job,id,job,status,failed,deadline,final,completable,future,testing,job,manager,messages,job,status,is,cancellation,future,notify,when,job,status,is,job,id,job,status,canceled,deadline,cluster,submit,job,detached,job,graph,try,final,testing,job,manager,messages,job,status,is,job,status,failed,future,get,deadline,time,left,to,millis,time,unit,milliseconds,assert,equals,job,status,failed,job,status,state,catch,exception,e,if,job,id,null,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,future,get,deadline,time,left,to,millis,time,unit,milliseconds,throw,e,job,manager,messages,job,found,job,found,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,request,job,job,id,deadline,time,left,map,to,class,tag,module,job,manager,messages,job,found,apply,job,manager,messages,job,found,class,get,deadline,time,left,to,millis,time,unit,milliseconds,string,failure,cause,job,found,execution,graph,get,failure,info,get,exception,as,string,assert,equals,job,status,failed,job,found,execution,graph,get,state,assert,true,not,instance,of,suppress,restarts,exception,failure,cause,starts,with,org,apache,flink,runtime,execution,suppress,restarts,exception,int,caused,by,index,failure,cause,index,of,caused,by,string,sub,failure,cause,failure,cause,substring,caused,by,index,caused,by,length,assert,true,not,caused,by,illegal,state,exception,sub,failure,cause,starts,with,java,lang,illegal,state,exception,assert,true,exception,does,not,contain,registration,name,sub,failure,cause,contains,query,name
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1509037054;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_					"timon",_					BasicTypeInfo.INT_TYPE_INFO,_					source.getType())__			mapStateDescriptor.setQueryable("timon-queryable")___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 8470749712274833552L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_				private static final long serialVersionUID = -805125545438296619L___				private transient MapState<Integer, Tuple2<Integer, Long>> mapState___				@Override_				public void open(Configuration parameters) throws Exception {_					super.open(parameters)__					mapState = getRuntimeContext().getMapState(mapStateDescriptor)__				}__				@Override_				public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_					Tuple2<Integer, Long> v = mapState.get(value.f0)__					if (v == null) {_						v = new Tuple2<>(value.f0, 0L)__					}_					mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__				}_			})___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvStateWithRetries(_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							QUERY_RETRY_DELAY,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)__					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,with,retries,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1510910970;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_					"timon",_					BasicTypeInfo.INT_TYPE_INFO,_					source.getType())__			mapStateDescriptor.setQueryable("timon-queryable")___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 8470749712274833552L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_				private static final long serialVersionUID = -805125545438296619L___				private transient MapState<Integer, Tuple2<Integer, Long>> mapState___				@Override_				public void open(Configuration parameters) throws Exception {_					super.open(parameters)__					mapState = getRuntimeContext().getMapState(mapStateDescriptor)__				}__				@Override_				public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_					Tuple2<Integer, Long> v = mapState.get(value.f0)__					if (v == null) {_						v = new Tuple2<>(value.f0, 0L)__					}_					mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__				}_			})___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)__					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1510911968;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_					"timon",_					BasicTypeInfo.INT_TYPE_INFO,_					source.getType())__			mapStateDescriptor.setQueryable("timon-queryable")___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 8470749712274833552L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_				private static final long serialVersionUID = -805125545438296619L___				private transient MapState<Integer, Tuple2<Integer, Long>> mapState___				@Override_				public void open(Configuration parameters) throws Exception {_					super.open(parameters)__					mapState = getRuntimeContext().getMapState(mapStateDescriptor)__				}__				@Override_				public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_					Tuple2<Integer, Long> v = mapState.get(value.f0)__					if (v == null) {_						v = new Tuple2<>(value.f0, 0L)__					}_					mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__				}_			})___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)__					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1510911970;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {_		_		final Deadline deadline = TEST_TIMEOUT.fromNow()___		final long numElements = 1024L___		JobID jobId = null__		try {_			StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__			env.setStateBackend(stateBackend)__			env.setParallelism(maxParallelism)__			_			_			_			env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___			DataStream<Tuple2<Integer, Long>> source = env_					.addSource(new TestAscendingValueSource(numElements))___			final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_					"timon",_					BasicTypeInfo.INT_TYPE_INFO,_					source.getType())__			mapStateDescriptor.setQueryable("timon-queryable")___			source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_				private static final long serialVersionUID = 8470749712274833552L___				@Override_				public Integer getKey(Tuple2<Integer, Long> value) throws Exception {_					return value.f0__				}_			}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_				private static final long serialVersionUID = -805125545438296619L___				private transient MapState<Integer, Tuple2<Integer, Long>> mapState___				@Override_				public void open(Configuration parameters) throws Exception {_					super.open(parameters)__					mapState = getRuntimeContext().getMapState(mapStateDescriptor)__				}__				@Override_				public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_					Tuple2<Integer, Long> v = mapState.get(value.f0)__					if (v == null) {_						v = new Tuple2<>(value.f0, 0L)__					}_					mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__				}_			})___			_			JobGraph jobGraph = env.getStreamGraph().getJobGraph()__			jobId = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)__					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		} finally {_			_			if (jobId != null) {_				CompletableFuture<CancellationSuccess> cancellation = FutureUtils.toJava(cluster_						.getLeaderGateway(deadline.timeLeft())_						.ask(new JobManagerMessages.CancelJob(jobId), deadline.timeLeft())_						.mapTo(ClassTag$.MODULE$.<CancellationSuccess>apply(CancellationSuccess.class)))___				cancellation.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,job,id,job,id,null,try,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,throws,exception,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success,finally,if,job,id,null,completable,future,cancellation,success,cancellation,future,utils,to,java,cluster,get,leader,gateway,deadline,time,left,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,map,to,class,tag,module,cancellation,success,apply,cancellation,success,class,cancellation,get,deadline,time,left,to,millis,time,unit,milliseconds
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1512567208;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_				"timon", BasicTypeInfo.INT_TYPE_INFO, source.getType())__		mapStateDescriptor.setQueryable("timon-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient MapState<Integer, Tuple2<Integer, Long>> mapState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				mapState = getRuntimeContext().getMapState(mapStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				Tuple2<Integer, Long> v = mapState.get(value.f0)__				if (v == null) {_					v = new Tuple2<>(value.f0, 0L)__				}_				mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)__					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(50L)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,50l,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1513261599;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_				"timon", BasicTypeInfo.INT_TYPE_INFO, source.getType())__		mapStateDescriptor.setQueryable("timon-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient MapState<Integer, Tuple2<Integer, Long>> mapState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				mapState = getRuntimeContext().getMapState(mapStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				Tuple2<Integer, Long> v = mapState.get(value.f0)__				if (v == null) {_					v = new Tuple2<>(value.f0, 0L)__				}_				mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)__					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1516812618;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {__		final Deadline deadline = TEST_TIMEOUT.fromNow()__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_				"timon", BasicTypeInfo.INT_TYPE_INFO, source.getType())__		mapStateDescriptor.setQueryable("timon-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient MapState<Integer, Tuple2<Integer, Long>> mapState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				mapState = getRuntimeContext().getMapState(mapStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				Tuple2<Integer, Long> v = mapState.get(value.f0)__				if (v == null) {_					v = new Tuple2<>(value.f0, 0L)__				}_				mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(cluster, env, deadline)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			cluster.submitJobDetached(jobGraph)___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)__					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,from,now,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,cluster,env,deadline,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,submit,job,detached,job,graph,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1520781441;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_				"timon", BasicTypeInfo.INT_TYPE_INFO, source.getType())__		mapStateDescriptor.setQueryable("timon-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient MapState<Integer, Tuple2<Integer, Long>> mapState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				mapState = getRuntimeContext().getMapState(mapStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				Tuple2<Integer, Long> v = mapState.get(value.f0)__				if (v == null) {_					v = new Tuple2<>(value.f0, 0L)__				}_				mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							false,_							executor)___					Tuple2<Integer, Long> value = future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)__					assertEquals("Key mismatch", key, value.f0.intValue())__					if (expected == value.f1) {_						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,assert,equals,key,mismatch,key,value,f0,int,value,if,expected,value,f1,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1541420597;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_				"timon", BasicTypeInfo.INT_TYPE_INFO, source.getType())__		mapStateDescriptor.setQueryable("timon-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient MapState<Integer, Tuple2<Integer, Long>> mapState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				mapState = getRuntimeContext().getMapState(mapStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				Tuple2<Integer, Long> v = mapState.get(value.f0)__				if (v == null) {_					v = new Tuple2<>(value.f0, 0L)__				}_				mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							false,_							executor)___					Tuple2<Integer, Long> value =_						future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)___					if (value != null && value.f0 != null && expected == value.f1) {_						assertEquals("Key mismatch", key, value.f0.intValue())__						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,if,value,null,value,f0,null,expected,value,f1,assert,equals,key,mismatch,key,value,f0,int,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1542282018;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_				"timon", BasicTypeInfo.INT_TYPE_INFO, source.getType())__		mapStateDescriptor.setQueryable("timon-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient MapState<Integer, Tuple2<Integer, Long>> mapState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				mapState = getRuntimeContext().getMapState(mapStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				Tuple2<Integer, Long> v = mapState.get(value.f0)__				if (v == null) {_					v = new Tuple2<>(value.f0, 0L)__				}_				mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							false,_							executor)___					Tuple2<Integer, Long> value =_						future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)___					if (value != null && value.f0 != null && expected == value.f1) {_						assertEquals("Key mismatch", key, value.f0.intValue())__						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,if,value,null,value,f0,null,expected,value,f1,assert,equals,key,mismatch,key,value,f0,int,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1547024365;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_				"timon", BasicTypeInfo.INT_TYPE_INFO, source.getType())__		mapStateDescriptor.setQueryable("timon-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient MapState<Integer, Tuple2<Integer, Long>> mapState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				mapState = getRuntimeContext().getMapState(mapStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				Tuple2<Integer, Long> v = mapState.get(value.f0)__				if (v == null) {_					v = new Tuple2<>(value.f0, 0L)__				}_				mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							false,_							executor)___					Tuple2<Integer, Long> value =_						future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)___					if (value != null && value.f0 != null && expected == value.f1) {_						assertEquals("Key mismatch", key, value.f0.intValue())__						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,if,value,null,value,f0,null,expected,value,f1,assert,equals,key,mismatch,key,value,f0,int,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1547024365;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_				"timon", BasicTypeInfo.INT_TYPE_INFO, source.getType())__		mapStateDescriptor.setQueryable("timon-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient MapState<Integer, Tuple2<Integer, Long>> mapState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				mapState = getRuntimeContext().getMapState(mapStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				Tuple2<Integer, Long> v = mapState.get(value.f0)__				if (v == null) {_					v = new Tuple2<>(value.f0, 0L)__				}_				mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							false,_							executor)___					Tuple2<Integer, Long> value =_						future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)___					if (value != null && value.f0 != null && expected == value.f1) {_						assertEquals("Key mismatch", key, value.f0.intValue())__						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,if,value,null,value,f0,null,expected,value,f1,assert,equals,key,mismatch,key,value,f0,int,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
AbstractQueryableStateTestBase -> @Test 	public void testMapState() throws Exception;1547024365;Tests simple map state queryable state instance. Each source emits_(subtaskIndex, 0)..(subtaskIndex, numElements) tuples, which are then_queried. The map state instance sums the values up. The test succeeds_after each subtask index is queried with result n*(n+1)/2.;@Test_	public void testMapState() throws Exception {_		final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT)__		final long numElements = 1024L___		StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.setStateBackend(stateBackend)__		env.setParallelism(maxParallelism)__		_		_		_		env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 1000L))___		DataStream<Tuple2<Integer, Long>> source = env.addSource(new TestAscendingValueSource(numElements))___		final MapStateDescriptor<Integer, Tuple2<Integer, Long>> mapStateDescriptor = new MapStateDescriptor<>(_				"timon", BasicTypeInfo.INT_TYPE_INFO, source.getType())__		mapStateDescriptor.setQueryable("timon-queryable")___		source.keyBy(new KeySelector<Tuple2<Integer, Long>, Integer>() {_			private static final long serialVersionUID = 8470749712274833552L___			@Override_			public Integer getKey(Tuple2<Integer, Long> value) {_				return value.f0__			}_		}).process(new ProcessFunction<Tuple2<Integer, Long>, Object>() {_			private static final long serialVersionUID = -805125545438296619L___			private transient MapState<Integer, Tuple2<Integer, Long>> mapState___			@Override_			public void open(Configuration parameters) throws Exception {_				super.open(parameters)__				mapState = getRuntimeContext().getMapState(mapStateDescriptor)__			}__			@Override_			public void processElement(Tuple2<Integer, Long> value, Context ctx, Collector<Object> out) throws Exception {_				Tuple2<Integer, Long> v = mapState.get(value.f0)__				if (v == null) {_					v = new Tuple2<>(value.f0, 0L)__				}_				mapState.put(value.f0, new Tuple2<>(v.f0, v.f1 + value.f1))__			}_		})___		try (AutoCancellableJob autoCancellableJob = new AutoCancellableJob(deadline, clusterClient, env)) {__			final JobID jobId = autoCancellableJob.getJobId()__			final JobGraph jobGraph = autoCancellableJob.getJobGraph()___			clusterClient.setDetached(true)__			clusterClient.submitJob(jobGraph, AbstractQueryableStateTestBase.class.getClassLoader())___			final long expected = numElements * (numElements + 1L) / 2L___			for (int key = 0_ key < maxParallelism_ key++) {_				boolean success = false__				while (deadline.hasTimeLeft() && !success) {_					CompletableFuture<MapState<Integer, Tuple2<Integer, Long>>> future = getKvState(_							deadline,_							client,_							jobId,_							"timon-queryable",_							key,_							BasicTypeInfo.INT_TYPE_INFO,_							mapStateDescriptor,_							false,_							executor)___					Tuple2<Integer, Long> value =_						future.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).get(key)___					if (value != null && value.f0 != null && expected == value.f1) {_						assertEquals("Key mismatch", key, value.f0.intValue())__						success = true__					} else {_						_						Thread.sleep(RETRY_TIMEOUT)__					}_				}__				assertTrue("Did not succeed query", success)__			}_		}_	};tests,simple,map,state,queryable,state,instance,each,source,emits,subtask,index,0,subtask,index,num,elements,tuples,which,are,then,queried,the,map,state,instance,sums,the,values,up,the,test,succeeds,after,each,subtask,index,is,queried,with,result,n,n,1,2;test,public,void,test,map,state,throws,exception,final,deadline,deadline,deadline,now,plus,final,long,num,elements,1024l,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,set,state,backend,state,backend,env,set,parallelism,max,parallelism,env,set,restart,strategy,restart,strategies,fixed,delay,restart,integer,1000l,data,stream,tuple2,integer,long,source,env,add,source,new,test,ascending,value,source,num,elements,final,map,state,descriptor,integer,tuple2,integer,long,map,state,descriptor,new,map,state,descriptor,timon,basic,type,info,source,get,type,map,state,descriptor,set,queryable,timon,queryable,source,key,by,new,key,selector,tuple2,integer,long,integer,private,static,final,long,serial,version,uid,8470749712274833552l,override,public,integer,get,key,tuple2,integer,long,value,return,value,f0,process,new,process,function,tuple2,integer,long,object,private,static,final,long,serial,version,uid,805125545438296619l,private,transient,map,state,integer,tuple2,integer,long,map,state,override,public,void,open,configuration,parameters,throws,exception,super,open,parameters,map,state,get,runtime,context,get,map,state,map,state,descriptor,override,public,void,process,element,tuple2,integer,long,value,context,ctx,collector,object,out,throws,exception,tuple2,integer,long,v,map,state,get,value,f0,if,v,null,v,new,tuple2,value,f0,0l,map,state,put,value,f0,new,tuple2,v,f0,v,f1,value,f1,try,auto,cancellable,job,auto,cancellable,job,new,auto,cancellable,job,deadline,cluster,client,env,final,job,id,job,id,auto,cancellable,job,get,job,id,final,job,graph,job,graph,auto,cancellable,job,get,job,graph,cluster,client,set,detached,true,cluster,client,submit,job,job,graph,abstract,queryable,state,test,base,class,get,class,loader,final,long,expected,num,elements,num,elements,1l,2l,for,int,key,0,key,max,parallelism,key,boolean,success,false,while,deadline,has,time,left,success,completable,future,map,state,integer,tuple2,integer,long,future,get,kv,state,deadline,client,job,id,timon,queryable,key,basic,type,info,map,state,descriptor,false,executor,tuple2,integer,long,value,future,get,deadline,time,left,to,millis,time,unit,milliseconds,get,key,if,value,null,value,f0,null,expected,value,f1,assert,equals,key,mismatch,key,value,f0,int,value,success,true,else,thread,sleep,assert,true,did,not,succeed,query,success
