# id;timestamp;commentText;codeText;commentWords;codeWords
BranchingPlansCompilerTest -> @SuppressWarnings("unchecked") 	@Test 	public void testBranchingWithMultipleDataSinks2();1426843274;<pre>_(SRC A)__(MAP A)_/         \_(MAP B)      (MAP C)_/           /     \_(SINK A)    (SINK B)  (SINK C)_</pre>;@SuppressWarnings("unchecked")_	@Test_	public void testBranchingWithMultipleDataSinks2() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setDegreeOfParallelism(DEFAULT_PARALLELISM)___			DataSet<Long> source = env.generateSequence(1, 10000)___			DataSet<Long> mappedA = source.map(new IdentityMapper<Long>())__			DataSet<Long> mappedB = mappedA.map(new IdentityMapper<Long>())__			DataSet<Long> mappedC = mappedA.map(new IdentityMapper<Long>())___			mappedB.output(new DiscardingOutputFormat<Long>())__			mappedC.output(new DiscardingOutputFormat<Long>())__			mappedC.output(new DiscardingOutputFormat<Long>())___			Plan plan = env.createProgramPlan()__			Set<Operator<?>> sinks = new HashSet<Operator<?>>(plan.getDataSinks())___			OptimizedPlan oPlan = compileNoStats(plan)___			__			_			assertEquals("Wrong number of data sinks.", 3, oPlan.getDataSinks().size())___			_			for (SinkPlanNode sink : oPlan.getDataSinks()) {_				assertTrue(sinks.remove(sink.getProgramOperator()))__			}_			assertTrue(sinks.isEmpty())___			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,src,a,map,a,map,b,map,c,sink,a,sink,b,sink,c,pre;suppress,warnings,unchecked,test,public,void,test,branching,with,multiple,data,sinks2,try,execution,environment,env,execution,environment,get,execution,environment,env,set,degree,of,parallelism,data,set,long,source,env,generate,sequence,1,10000,data,set,long,mapped,a,source,map,new,identity,mapper,long,data,set,long,mapped,b,mapped,a,map,new,identity,mapper,long,data,set,long,mapped,c,mapped,a,map,new,identity,mapper,long,mapped,b,output,new,discarding,output,format,long,mapped,c,output,new,discarding,output,format,long,mapped,c,output,new,discarding,output,format,long,plan,plan,env,create,program,plan,set,operator,sinks,new,hash,set,operator,plan,get,data,sinks,optimized,plan,o,plan,compile,no,stats,plan,assert,equals,wrong,number,of,data,sinks,3,o,plan,get,data,sinks,size,for,sink,plan,node,sink,o,plan,get,data,sinks,assert,true,sinks,remove,sink,get,program,operator,assert,true,sinks,is,empty,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @SuppressWarnings("unchecked") 	@Test 	public void testBranchingWithMultipleDataSinks2();1427097830;<pre>_(SRC A)__(MAP A)_/         \_(MAP B)      (MAP C)_/           /     \_(SINK A)    (SINK B)  (SINK C)_</pre>;@SuppressWarnings("unchecked")_	@Test_	public void testBranchingWithMultipleDataSinks2() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Long> source = env.generateSequence(1, 10000)___			DataSet<Long> mappedA = source.map(new IdentityMapper<Long>())__			DataSet<Long> mappedB = mappedA.map(new IdentityMapper<Long>())__			DataSet<Long> mappedC = mappedA.map(new IdentityMapper<Long>())___			mappedB.output(new DiscardingOutputFormat<Long>())__			mappedC.output(new DiscardingOutputFormat<Long>())__			mappedC.output(new DiscardingOutputFormat<Long>())___			Plan plan = env.createProgramPlan()__			Set<Operator<?>> sinks = new HashSet<Operator<?>>(plan.getDataSinks())___			OptimizedPlan oPlan = compileNoStats(plan)___			__			_			assertEquals("Wrong number of data sinks.", 3, oPlan.getDataSinks().size())___			_			for (SinkPlanNode sink : oPlan.getDataSinks()) {_				assertTrue(sinks.remove(sink.getProgramOperator()))__			}_			assertTrue(sinks.isEmpty())___			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,src,a,map,a,map,b,map,c,sink,a,sink,b,sink,c,pre;suppress,warnings,unchecked,test,public,void,test,branching,with,multiple,data,sinks2,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source,env,generate,sequence,1,10000,data,set,long,mapped,a,source,map,new,identity,mapper,long,data,set,long,mapped,b,mapped,a,map,new,identity,mapper,long,data,set,long,mapped,c,mapped,a,map,new,identity,mapper,long,mapped,b,output,new,discarding,output,format,long,mapped,c,output,new,discarding,output,format,long,mapped,c,output,new,discarding,output,format,long,plan,plan,env,create,program,plan,set,operator,sinks,new,hash,set,operator,plan,get,data,sinks,optimized,plan,o,plan,compile,no,stats,plan,assert,equals,wrong,number,of,data,sinks,3,o,plan,get,data,sinks,size,for,sink,plan,node,sink,o,plan,get,data,sinks,assert,true,sinks,remove,sink,get,program,operator,assert,true,sinks,is,empty,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @SuppressWarnings("unchecked") 	@Test 	public void testBranchingWithMultipleDataSinks2();1427784999;<pre>_(SRC A)__(MAP A)_/         \_(MAP B)      (MAP C)_/           /     \_(SINK A)    (SINK B)  (SINK C)_</pre>;@SuppressWarnings("unchecked")_	@Test_	public void testBranchingWithMultipleDataSinks2() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Long> source = env.generateSequence(1, 10000)___			DataSet<Long> mappedA = source.map(new IdentityMapper<Long>())__			DataSet<Long> mappedB = mappedA.map(new IdentityMapper<Long>())__			DataSet<Long> mappedC = mappedA.map(new IdentityMapper<Long>())___			mappedB.output(new DiscardingOutputFormat<Long>())__			mappedC.output(new DiscardingOutputFormat<Long>())__			mappedC.output(new DiscardingOutputFormat<Long>())___			Plan plan = env.createProgramPlan()__			Set<Operator<?>> sinks = new HashSet<Operator<?>>(plan.getDataSinks())___			OptimizedPlan oPlan = compileNoStats(plan)___			__			_			assertEquals("Wrong number of data sinks.", 3, oPlan.getDataSinks().size())___			_			for (SinkPlanNode sink : oPlan.getDataSinks()) {_				assertTrue(sinks.remove(sink.getProgramOperator()))__			}_			assertTrue(sinks.isEmpty())___			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,src,a,map,a,map,b,map,c,sink,a,sink,b,sink,c,pre;suppress,warnings,unchecked,test,public,void,test,branching,with,multiple,data,sinks2,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source,env,generate,sequence,1,10000,data,set,long,mapped,a,source,map,new,identity,mapper,long,data,set,long,mapped,b,mapped,a,map,new,identity,mapper,long,data,set,long,mapped,c,mapped,a,map,new,identity,mapper,long,mapped,b,output,new,discarding,output,format,long,mapped,c,output,new,discarding,output,format,long,mapped,c,output,new,discarding,output,format,long,plan,plan,env,create,program,plan,set,operator,sinks,new,hash,set,operator,plan,get,data,sinks,optimized,plan,o,plan,compile,no,stats,plan,assert,equals,wrong,number,of,data,sinks,3,o,plan,get,data,sinks,size,for,sink,plan,node,sink,o,plan,get,data,sinks,assert,true,sinks,remove,sink,get,program,operator,assert,true,sinks,is,empty,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @SuppressWarnings("unchecked") 	@Test 	public void testBranchingWithMultipleDataSinks2();1430859707;<pre>_(SRC A)__(MAP A)_/         \_(MAP B)      (MAP C)_/           /     \_(SINK A)    (SINK B)  (SINK C)_</pre>;@SuppressWarnings("unchecked")_	@Test_	public void testBranchingWithMultipleDataSinks2() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Long> source = env.generateSequence(1, 10000)___			DataSet<Long> mappedA = source.map(new IdentityMapper<Long>())__			DataSet<Long> mappedB = mappedA.map(new IdentityMapper<Long>())__			DataSet<Long> mappedC = mappedA.map(new IdentityMapper<Long>())___			mappedB.output(new DiscardingOutputFormat<Long>())__			mappedC.output(new DiscardingOutputFormat<Long>())__			mappedC.output(new DiscardingOutputFormat<Long>())___			Plan plan = env.createProgramPlan()__			Set<Operator<?>> sinks = new HashSet<Operator<?>>(plan.getDataSinks())___			OptimizedPlan oPlan = compileNoStats(plan)___			__			_			assertEquals("Wrong number of data sinks.", 3, oPlan.getDataSinks().size())___			_			for (SinkPlanNode sink : oPlan.getDataSinks()) {_				assertTrue(sinks.remove(sink.getProgramOperator()))__			}_			assertTrue(sinks.isEmpty())___			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,src,a,map,a,map,b,map,c,sink,a,sink,b,sink,c,pre;suppress,warnings,unchecked,test,public,void,test,branching,with,multiple,data,sinks2,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source,env,generate,sequence,1,10000,data,set,long,mapped,a,source,map,new,identity,mapper,long,data,set,long,mapped,b,mapped,a,map,new,identity,mapper,long,data,set,long,mapped,c,mapped,a,map,new,identity,mapper,long,mapped,b,output,new,discarding,output,format,long,mapped,c,output,new,discarding,output,format,long,mapped,c,output,new,discarding,output,format,long,plan,plan,env,create,program,plan,set,operator,sinks,new,hash,set,operator,plan,get,data,sinks,optimized,plan,o,plan,compile,no,stats,plan,assert,equals,wrong,number,of,data,sinks,3,o,plan,get,data,sinks,size,for,sink,plan,node,sink,o,plan,get,data,sinks,assert,true,sinks,remove,sink,get,program,operator,assert,true,sinks,is,empty,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @SuppressWarnings("unchecked") 	@Test 	public void testBranchingWithMultipleDataSinks2();1449526184;<pre>_(SRC A)__(MAP A)_/         \_(MAP B)      (MAP C)_/           /     \_(SINK A)    (SINK B)  (SINK C)_</pre>;@SuppressWarnings("unchecked")_	@Test_	public void testBranchingWithMultipleDataSinks2() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Long> source = env.generateSequence(1, 10000)___			DataSet<Long> mappedA = source.map(new IdentityMapper<Long>())__			DataSet<Long> mappedB = mappedA.map(new IdentityMapper<Long>())__			DataSet<Long> mappedC = mappedA.map(new IdentityMapper<Long>())___			mappedB.output(new DiscardingOutputFormat<Long>())__			mappedC.output(new DiscardingOutputFormat<Long>())__			mappedC.output(new DiscardingOutputFormat<Long>())___			Plan plan = env.createProgramPlan()__			Set<Operator<?>> sinks = new HashSet<Operator<?>>(plan.getDataSinks())___			OptimizedPlan oPlan = compileNoStats(plan)___			__			_			assertEquals("Wrong number of data sinks.", 3, oPlan.getDataSinks().size())___			_			for (SinkPlanNode sink : oPlan.getDataSinks()) {_				assertTrue(sinks.remove(sink.getProgramOperator()))__			}_			assertTrue(sinks.isEmpty())___			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,src,a,map,a,map,b,map,c,sink,a,sink,b,sink,c,pre;suppress,warnings,unchecked,test,public,void,test,branching,with,multiple,data,sinks2,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source,env,generate,sequence,1,10000,data,set,long,mapped,a,source,map,new,identity,mapper,long,data,set,long,mapped,b,mapped,a,map,new,identity,mapper,long,data,set,long,mapped,c,mapped,a,map,new,identity,mapper,long,mapped,b,output,new,discarding,output,format,long,mapped,c,output,new,discarding,output,format,long,mapped,c,output,new,discarding,output,format,long,plan,plan,env,create,program,plan,set,operator,sinks,new,hash,set,operator,plan,get,data,sinks,optimized,plan,o,plan,compile,no,stats,plan,assert,equals,wrong,number,of,data,sinks,3,o,plan,get,data,sinks,size,for,sink,plan,node,sink,o,plan,get,data,sinks,assert,true,sinks,remove,sink,get,program,operator,assert,true,sinks,is,empty,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @SuppressWarnings("unchecked") 	@Test 	public void testBranchingWithMultipleDataSinks2();1475688973;<pre>_(SRC A)__(MAP A)_/         \_(MAP B)      (MAP C)_/           /     \_(SINK A)    (SINK B)  (SINK C)_</pre>;@SuppressWarnings("unchecked")_	@Test_	public void testBranchingWithMultipleDataSinks2() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Long> source = env.generateSequence(1, 10000)___			DataSet<Long> mappedA = source.map(new IdentityMapper<Long>())__			DataSet<Long> mappedB = mappedA.map(new IdentityMapper<Long>())__			DataSet<Long> mappedC = mappedA.map(new IdentityMapper<Long>())___			mappedB.output(new DiscardingOutputFormat<Long>())__			mappedC.output(new DiscardingOutputFormat<Long>())__			mappedC.output(new DiscardingOutputFormat<Long>())___			Plan plan = env.createProgramPlan()__			Set<Operator<?>> sinks = new HashSet<Operator<?>>(plan.getDataSinks())___			OptimizedPlan oPlan = compileNoStats(plan)___			__			_			assertEquals("Wrong number of data sinks.", 3, oPlan.getDataSinks().size())___			_			for (SinkPlanNode sink : oPlan.getDataSinks()) {_				assertTrue(sinks.remove(sink.getProgramOperator()))__			}_			assertTrue(sinks.isEmpty())___			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,src,a,map,a,map,b,map,c,sink,a,sink,b,sink,c,pre;suppress,warnings,unchecked,test,public,void,test,branching,with,multiple,data,sinks2,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source,env,generate,sequence,1,10000,data,set,long,mapped,a,source,map,new,identity,mapper,long,data,set,long,mapped,b,mapped,a,map,new,identity,mapper,long,data,set,long,mapped,c,mapped,a,map,new,identity,mapper,long,mapped,b,output,new,discarding,output,format,long,mapped,c,output,new,discarding,output,format,long,mapped,c,output,new,discarding,output,format,long,plan,plan,env,create,program,plan,set,operator,sinks,new,hash,set,operator,plan,get,data,sinks,optimized,plan,o,plan,compile,no,stats,plan,assert,equals,wrong,number,of,data,sinks,3,o,plan,get,data,sinks,size,for,sink,plan,node,sink,o,plan,get,data,sinks,assert,true,sinks,remove,sink,get,program,operator,assert,true,sinks,is,empty,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testClosureDeltaIteration();1426843274;<pre>_(SRC A)         (SRC B)          (SRC C)_/       \       /                /       \_(SINK 1) (DELTA ITERATION)          |     (SINK 2)_/    |   \               /_(SINK 3) |   (CROSS => NEXT WORKSET)_|             |_(JOIN => SOLUTION SET DELTA)_</pre>;@Test_	public void testClosureDeltaIteration() {_		FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 1")__		FileDataSource sourceB = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 2")__		FileDataSource sourceC = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 3")___		FileDataSink sink1 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceA, "Sink 1")__		FileDataSink sink2 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceC, "Sink 2")___		DeltaIteration iteration = new DeltaIteration(0, "Loop")__		iteration.setInitialSolutionSet(sourceA)__		iteration.setInitialWorkset(sourceB)__		iteration.setMaximumNumberOfIterations(10)___		CrossOperator nextWorkset = CrossOperator.builder(DummyCrossStub.class).name("Next workset")._				input1(iteration.getWorkset())._				input2(sourceC)._				build()___		JoinOperator solutionSetDelta = JoinOperator.builder(DummyMatchStub.class, LongValue.class,0,0)._				name("Next solution set.")._				input1(nextWorkset)._				input2(iteration.getSolutionSet())._				build()___		iteration.setNextWorkset(nextWorkset)__		iteration.setSolutionSetDelta(solutionSetDelta)___		FileDataSink sink3 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, iteration, "Sink 3")___		List<FileDataSink> sinks = new ArrayList<FileDataSink>()__		sinks.add(sink1)__		sinks.add(sink2)__		sinks.add(sink3)___		Plan plan = new Plan(sinks)___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,src,a,src,b,src,c,sink,1,delta,iteration,sink,2,sink,3,cross,next,workset,join,solution,set,delta,pre;test,public,void,test,closure,delta,iteration,file,data,source,source,a,new,file,data,source,dummy,input,format,class,source,1,file,data,source,source,b,new,file,data,source,dummy,input,format,class,source,2,file,data,source,source,c,new,file,data,source,dummy,input,format,class,source,3,file,data,sink,sink1,new,file,data,sink,dummy,output,format,class,source,a,sink,1,file,data,sink,sink2,new,file,data,sink,dummy,output,format,class,source,c,sink,2,delta,iteration,iteration,new,delta,iteration,0,loop,iteration,set,initial,solution,set,source,a,iteration,set,initial,workset,source,b,iteration,set,maximum,number,of,iterations,10,cross,operator,next,workset,cross,operator,builder,dummy,cross,stub,class,name,next,workset,input1,iteration,get,workset,input2,source,c,build,join,operator,solution,set,delta,join,operator,builder,dummy,match,stub,class,long,value,class,0,0,name,next,solution,set,input1,next,workset,input2,iteration,get,solution,set,build,iteration,set,next,workset,next,workset,iteration,set,solution,set,delta,solution,set,delta,file,data,sink,sink3,new,file,data,sink,dummy,output,format,class,iteration,sink,3,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink1,sinks,add,sink2,sinks,add,sink3,plan,plan,new,plan,sinks,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testClosureDeltaIteration();1427097830;<pre>_(SRC A)         (SRC B)          (SRC C)_/       \       /                /       \_(SINK 1) (DELTA ITERATION)          |     (SINK 2)_/    |   \               /_(SINK 3) |   (CROSS => NEXT WORKSET)_|             |_(JOIN => SOLUTION SET DELTA)_</pre>;@Test_	public void testClosureDeltaIteration() {_		FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 1")__		FileDataSource sourceB = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 2")__		FileDataSource sourceC = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 3")___		FileDataSink sink1 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceA, "Sink 1")__		FileDataSink sink2 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceC, "Sink 2")___		DeltaIteration iteration = new DeltaIteration(0, "Loop")__		iteration.setInitialSolutionSet(sourceA)__		iteration.setInitialWorkset(sourceB)__		iteration.setMaximumNumberOfIterations(10)___		CrossOperator nextWorkset = CrossOperator.builder(DummyCrossStub.class).name("Next workset")._				input1(iteration.getWorkset())._				input2(sourceC)._				build()___		JoinOperator solutionSetDelta = JoinOperator.builder(DummyMatchStub.class, LongValue.class,0,0)._				name("Next solution set.")._				input1(nextWorkset)._				input2(iteration.getSolutionSet())._				build()___		iteration.setNextWorkset(nextWorkset)__		iteration.setSolutionSetDelta(solutionSetDelta)___		FileDataSink sink3 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, iteration, "Sink 3")___		List<FileDataSink> sinks = new ArrayList<FileDataSink>()__		sinks.add(sink1)__		sinks.add(sink2)__		sinks.add(sink3)___		Plan plan = new Plan(sinks)___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,src,a,src,b,src,c,sink,1,delta,iteration,sink,2,sink,3,cross,next,workset,join,solution,set,delta,pre;test,public,void,test,closure,delta,iteration,file,data,source,source,a,new,file,data,source,dummy,input,format,class,source,1,file,data,source,source,b,new,file,data,source,dummy,input,format,class,source,2,file,data,source,source,c,new,file,data,source,dummy,input,format,class,source,3,file,data,sink,sink1,new,file,data,sink,dummy,output,format,class,source,a,sink,1,file,data,sink,sink2,new,file,data,sink,dummy,output,format,class,source,c,sink,2,delta,iteration,iteration,new,delta,iteration,0,loop,iteration,set,initial,solution,set,source,a,iteration,set,initial,workset,source,b,iteration,set,maximum,number,of,iterations,10,cross,operator,next,workset,cross,operator,builder,dummy,cross,stub,class,name,next,workset,input1,iteration,get,workset,input2,source,c,build,join,operator,solution,set,delta,join,operator,builder,dummy,match,stub,class,long,value,class,0,0,name,next,solution,set,input1,next,workset,input2,iteration,get,solution,set,build,iteration,set,next,workset,next,workset,iteration,set,solution,set,delta,solution,set,delta,file,data,sink,sink3,new,file,data,sink,dummy,output,format,class,iteration,sink,3,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink1,sinks,add,sink2,sinks,add,sink3,plan,plan,new,plan,sinks,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testClosureDeltaIteration();1427784999;<pre>_(SRC A)         (SRC B)          (SRC C)_/       \       /                /       \_(SINK 1) (DELTA ITERATION)          |     (SINK 2)_/    |   \               /_(SINK 3) |   (CROSS => NEXT WORKSET)_|             |_(JOIN => SOLUTION SET DELTA)_</pre>;@Test_	public void testClosureDeltaIteration() {_		FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 1")__		FileDataSource sourceB = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 2")__		FileDataSource sourceC = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 3")___		FileDataSink sink1 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceA, "Sink 1")__		FileDataSink sink2 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceC, "Sink 2")___		DeltaIteration iteration = new DeltaIteration(0, "Loop")__		iteration.setInitialSolutionSet(sourceA)__		iteration.setInitialWorkset(sourceB)__		iteration.setMaximumNumberOfIterations(10)___		CrossOperator nextWorkset = CrossOperator.builder(DummyCrossStub.class).name("Next workset")._				input1(iteration.getWorkset())._				input2(sourceC)._				build()___		JoinOperator solutionSetDelta = JoinOperator.builder(DummyMatchStub.class, LongValue.class,0,0)._				name("Next solution set.")._				input1(nextWorkset)._				input2(iteration.getSolutionSet())._				build()___		iteration.setNextWorkset(nextWorkset)__		iteration.setSolutionSetDelta(solutionSetDelta)___		FileDataSink sink3 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, iteration, "Sink 3")___		List<FileDataSink> sinks = new ArrayList<FileDataSink>()__		sinks.add(sink1)__		sinks.add(sink2)__		sinks.add(sink3)___		Plan plan = new Plan(sinks)___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,src,a,src,b,src,c,sink,1,delta,iteration,sink,2,sink,3,cross,next,workset,join,solution,set,delta,pre;test,public,void,test,closure,delta,iteration,file,data,source,source,a,new,file,data,source,dummy,input,format,class,source,1,file,data,source,source,b,new,file,data,source,dummy,input,format,class,source,2,file,data,source,source,c,new,file,data,source,dummy,input,format,class,source,3,file,data,sink,sink1,new,file,data,sink,dummy,output,format,class,source,a,sink,1,file,data,sink,sink2,new,file,data,sink,dummy,output,format,class,source,c,sink,2,delta,iteration,iteration,new,delta,iteration,0,loop,iteration,set,initial,solution,set,source,a,iteration,set,initial,workset,source,b,iteration,set,maximum,number,of,iterations,10,cross,operator,next,workset,cross,operator,builder,dummy,cross,stub,class,name,next,workset,input1,iteration,get,workset,input2,source,c,build,join,operator,solution,set,delta,join,operator,builder,dummy,match,stub,class,long,value,class,0,0,name,next,solution,set,input1,next,workset,input2,iteration,get,solution,set,build,iteration,set,next,workset,next,workset,iteration,set,solution,set,delta,solution,set,delta,file,data,sink,sink3,new,file,data,sink,dummy,output,format,class,iteration,sink,3,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink1,sinks,add,sink2,sinks,add,sink3,plan,plan,new,plan,sinks,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testClosureDeltaIteration();1430859707;<pre>_(SRC A)         (SRC B)          (SRC C)_/       \       /                /       \_(SINK 1) (DELTA ITERATION)          |     (SINK 2)_/    |   \               /_(SINK 3) |   (CROSS => NEXT WORKSET)_|             |_(JOIN => SOLUTION SET DELTA)_</pre>;@Test_	public void testClosureDeltaIteration() {_		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(DEFAULT_PARALLELISM)__		DataSet<Tuple2<Long, Long>> sourceA = env.generateSequence(0,1).map(new Duplicator<Long>())__		DataSet<Tuple2<Long, Long>> sourceB = env.generateSequence(0,1).map(new Duplicator<Long>())__		DataSet<Tuple2<Long, Long>> sourceC = env.generateSequence(0,1).map(new Duplicator<Long>())___		sourceA.output(new DiscardingOutputFormat<Tuple2<Long,Long>>())__		sourceC.output(new DiscardingOutputFormat<Tuple2<Long,Long>>())___		DeltaIteration<Tuple2<Long, Long>, Tuple2<Long, Long>> loop = sourceA.iterateDelta(sourceB, 10, 0)___		DataSet<Tuple2<Long, Long>> workset = loop.getWorkset().cross(sourceB).with(new IdentityCrosser<Tuple2<Long, Long>>()).name("Next work set")__		DataSet<Tuple2<Long, Long>> delta = workset.join(loop.getSolutionSet()).where(0).equalTo(0).with(new IdentityJoiner<Tuple2<Long, Long>>()).name("Solution set delta")___		DataSet<Tuple2<Long, Long>> result = loop.closeWith(delta, workset)__		result.output(new DiscardingOutputFormat<Tuple2<Long,Long>>())___		JavaPlan plan = env.createProgramPlan()___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,src,a,src,b,src,c,sink,1,delta,iteration,sink,2,sink,3,cross,next,workset,join,solution,set,delta,pre;test,public,void,test,closure,delta,iteration,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,a,env,generate,sequence,0,1,map,new,duplicator,long,data,set,tuple2,long,long,source,b,env,generate,sequence,0,1,map,new,duplicator,long,data,set,tuple2,long,long,source,c,env,generate,sequence,0,1,map,new,duplicator,long,source,a,output,new,discarding,output,format,tuple2,long,long,source,c,output,new,discarding,output,format,tuple2,long,long,delta,iteration,tuple2,long,long,tuple2,long,long,loop,source,a,iterate,delta,source,b,10,0,data,set,tuple2,long,long,workset,loop,get,workset,cross,source,b,with,new,identity,crosser,tuple2,long,long,name,next,work,set,data,set,tuple2,long,long,delta,workset,join,loop,get,solution,set,where,0,equal,to,0,with,new,identity,joiner,tuple2,long,long,name,solution,set,delta,data,set,tuple2,long,long,result,loop,close,with,delta,workset,result,output,new,discarding,output,format,tuple2,long,long,java,plan,plan,env,create,program,plan,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testClosureDeltaIteration();1449526184;<pre>_(SRC A)         (SRC B)          (SRC C)_/       \       /                /       \_(SINK 1) (DELTA ITERATION)          |     (SINK 2)_/    |   \               /_(SINK 3) |   (CROSS => NEXT WORKSET)_|             |_(JOIN => SOLUTION SET DELTA)_</pre>;@Test_	public void testClosureDeltaIteration() {_		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(DEFAULT_PARALLELISM)__		DataSet<Tuple2<Long, Long>> sourceA = env.generateSequence(0,1).map(new Duplicator<Long>())__		DataSet<Tuple2<Long, Long>> sourceB = env.generateSequence(0,1).map(new Duplicator<Long>())__		DataSet<Tuple2<Long, Long>> sourceC = env.generateSequence(0,1).map(new Duplicator<Long>())___		sourceA.output(new DiscardingOutputFormat<Tuple2<Long,Long>>())__		sourceC.output(new DiscardingOutputFormat<Tuple2<Long,Long>>())___		DeltaIteration<Tuple2<Long, Long>, Tuple2<Long, Long>> loop = sourceA.iterateDelta(sourceB, 10, 0)___		DataSet<Tuple2<Long, Long>> workset = loop.getWorkset().cross(sourceB).with(new IdentityCrosser<Tuple2<Long, Long>>()).name("Next work set")__		DataSet<Tuple2<Long, Long>> delta = workset.join(loop.getSolutionSet()).where(0).equalTo(0).with(new IdentityJoiner<Tuple2<Long, Long>>()).name("Solution set delta")___		DataSet<Tuple2<Long, Long>> result = loop.closeWith(delta, workset)__		result.output(new DiscardingOutputFormat<Tuple2<Long,Long>>())___		Plan plan = env.createProgramPlan()___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,src,a,src,b,src,c,sink,1,delta,iteration,sink,2,sink,3,cross,next,workset,join,solution,set,delta,pre;test,public,void,test,closure,delta,iteration,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,a,env,generate,sequence,0,1,map,new,duplicator,long,data,set,tuple2,long,long,source,b,env,generate,sequence,0,1,map,new,duplicator,long,data,set,tuple2,long,long,source,c,env,generate,sequence,0,1,map,new,duplicator,long,source,a,output,new,discarding,output,format,tuple2,long,long,source,c,output,new,discarding,output,format,tuple2,long,long,delta,iteration,tuple2,long,long,tuple2,long,long,loop,source,a,iterate,delta,source,b,10,0,data,set,tuple2,long,long,workset,loop,get,workset,cross,source,b,with,new,identity,crosser,tuple2,long,long,name,next,work,set,data,set,tuple2,long,long,delta,workset,join,loop,get,solution,set,where,0,equal,to,0,with,new,identity,joiner,tuple2,long,long,name,solution,set,delta,data,set,tuple2,long,long,result,loop,close,with,delta,workset,result,output,new,discarding,output,format,tuple2,long,long,plan,plan,env,create,program,plan,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testClosureDeltaIteration();1475688973;<pre>_(SRC A)         (SRC B)          (SRC C)_/       \       /                /       \_(SINK 1) (DELTA ITERATION)          |     (SINK 2)_/    |   \               /_(SINK 3) |   (CROSS => NEXT WORKSET)_|             |_(JOIN => SOLUTION SET DELTA)_</pre>;@Test_	public void testClosureDeltaIteration() {_		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(DEFAULT_PARALLELISM)__		DataSet<Tuple2<Long, Long>> sourceA = env.generateSequence(0,1).map(new Duplicator<Long>())__		DataSet<Tuple2<Long, Long>> sourceB = env.generateSequence(0,1).map(new Duplicator<Long>())__		DataSet<Tuple2<Long, Long>> sourceC = env.generateSequence(0,1).map(new Duplicator<Long>())___		sourceA.output(new DiscardingOutputFormat<Tuple2<Long,Long>>())__		sourceC.output(new DiscardingOutputFormat<Tuple2<Long,Long>>())___		DeltaIteration<Tuple2<Long, Long>, Tuple2<Long, Long>> loop = sourceA.iterateDelta(sourceB, 10, 0)___		DataSet<Tuple2<Long, Long>> workset = loop.getWorkset().cross(sourceB).with(new IdentityCrosser<Tuple2<Long, Long>>()).name("Next work set")__		DataSet<Tuple2<Long, Long>> delta = workset.join(loop.getSolutionSet()).where(0).equalTo(0).with(new IdentityJoiner<Tuple2<Long, Long>>()).name("Solution set delta")___		DataSet<Tuple2<Long, Long>> result = loop.closeWith(delta, workset)__		result.output(new DiscardingOutputFormat<Tuple2<Long,Long>>())___		Plan plan = env.createProgramPlan()___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,src,a,src,b,src,c,sink,1,delta,iteration,sink,2,sink,3,cross,next,workset,join,solution,set,delta,pre;test,public,void,test,closure,delta,iteration,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,a,env,generate,sequence,0,1,map,new,duplicator,long,data,set,tuple2,long,long,source,b,env,generate,sequence,0,1,map,new,duplicator,long,data,set,tuple2,long,long,source,c,env,generate,sequence,0,1,map,new,duplicator,long,source,a,output,new,discarding,output,format,tuple2,long,long,source,c,output,new,discarding,output,format,tuple2,long,long,delta,iteration,tuple2,long,long,tuple2,long,long,loop,source,a,iterate,delta,source,b,10,0,data,set,tuple2,long,long,workset,loop,get,workset,cross,source,b,with,new,identity,crosser,tuple2,long,long,name,next,work,set,data,set,tuple2,long,long,delta,workset,join,loop,get,solution,set,where,0,equal,to,0,with,new,identity,joiner,tuple2,long,long,name,solution,set,delta,data,set,tuple2,long,long,result,loop,close,with,delta,workset,result,output,new,discarding,output,format,tuple2,long,long,plan,plan,env,create,program,plan,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingDisjointPlan();1426843274;<pre>_(SINK 3) (SINK 1)   (SINK 2) (SINK 4)_\     /             \     /_(SRC A)             (SRC B)_</pre>__NOTE: this case is currently not caught by the compiler. we should enable the test once it is caught.;@Test_	public void testBranchingDisjointPlan() {_		_		final String out1Path = "file:///test/1"__		final String out2Path = "file:///test/2"__		final String out3Path = "file:///test/3"__		final String out4Path = "file:///test/4"___		FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE)__		FileDataSource sourceB = new FileDataSource(DummyInputFormat.class, IN_FILE)__		_		FileDataSink sink1 = new FileDataSink(DummyOutputFormat.class, out1Path, sourceA, "1")__		FileDataSink sink2 = new FileDataSink(DummyOutputFormat.class, out2Path, sourceB, "2")__		FileDataSink sink3 = new FileDataSink(DummyOutputFormat.class, out3Path, sourceA, "3")__		FileDataSink sink4 = new FileDataSink(DummyOutputFormat.class, out4Path, sourceB, "4")__		_		_		List<FileDataSink> sinks = new ArrayList<FileDataSink>()__		sinks.add(sink1)__		sinks.add(sink2)__		sinks.add(sink3)__		sinks.add(sink4)__		_		_		Plan plan = new Plan(sinks, "Disjoint plan with multiple data sinks and branches")__		compileNoStats(plan)__	};pre,sink,3,sink,1,sink,2,sink,4,src,a,src,b,pre,note,this,case,is,currently,not,caught,by,the,compiler,we,should,enable,the,test,once,it,is,caught;test,public,void,test,branching,disjoint,plan,final,string,out1path,file,test,1,final,string,out2path,file,test,2,final,string,out3path,file,test,3,final,string,out4path,file,test,4,file,data,source,source,a,new,file,data,source,dummy,input,format,class,file,data,source,source,b,new,file,data,source,dummy,input,format,class,file,data,sink,sink1,new,file,data,sink,dummy,output,format,class,out1path,source,a,1,file,data,sink,sink2,new,file,data,sink,dummy,output,format,class,out2path,source,b,2,file,data,sink,sink3,new,file,data,sink,dummy,output,format,class,out3path,source,a,3,file,data,sink,sink4,new,file,data,sink,dummy,output,format,class,out4path,source,b,4,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink1,sinks,add,sink2,sinks,add,sink3,sinks,add,sink4,plan,plan,new,plan,sinks,disjoint,plan,with,multiple,data,sinks,and,branches,compile,no,stats,plan
BranchingPlansCompilerTest -> @Test 	public void testBranchingDisjointPlan();1427097830;<pre>_(SINK 3) (SINK 1)   (SINK 2) (SINK 4)_\     /             \     /_(SRC A)             (SRC B)_</pre>__NOTE: this case is currently not caught by the compiler. we should enable the test once it is caught.;@Test_	public void testBranchingDisjointPlan() {_		_		final String out1Path = "file:///test/1"__		final String out2Path = "file:///test/2"__		final String out3Path = "file:///test/3"__		final String out4Path = "file:///test/4"___		FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE)__		FileDataSource sourceB = new FileDataSource(DummyInputFormat.class, IN_FILE)__		_		FileDataSink sink1 = new FileDataSink(DummyOutputFormat.class, out1Path, sourceA, "1")__		FileDataSink sink2 = new FileDataSink(DummyOutputFormat.class, out2Path, sourceB, "2")__		FileDataSink sink3 = new FileDataSink(DummyOutputFormat.class, out3Path, sourceA, "3")__		FileDataSink sink4 = new FileDataSink(DummyOutputFormat.class, out4Path, sourceB, "4")__		_		_		List<FileDataSink> sinks = new ArrayList<FileDataSink>()__		sinks.add(sink1)__		sinks.add(sink2)__		sinks.add(sink3)__		sinks.add(sink4)__		_		_		Plan plan = new Plan(sinks, "Disjoint plan with multiple data sinks and branches")__		compileNoStats(plan)__	};pre,sink,3,sink,1,sink,2,sink,4,src,a,src,b,pre,note,this,case,is,currently,not,caught,by,the,compiler,we,should,enable,the,test,once,it,is,caught;test,public,void,test,branching,disjoint,plan,final,string,out1path,file,test,1,final,string,out2path,file,test,2,final,string,out3path,file,test,3,final,string,out4path,file,test,4,file,data,source,source,a,new,file,data,source,dummy,input,format,class,file,data,source,source,b,new,file,data,source,dummy,input,format,class,file,data,sink,sink1,new,file,data,sink,dummy,output,format,class,out1path,source,a,1,file,data,sink,sink2,new,file,data,sink,dummy,output,format,class,out2path,source,b,2,file,data,sink,sink3,new,file,data,sink,dummy,output,format,class,out3path,source,a,3,file,data,sink,sink4,new,file,data,sink,dummy,output,format,class,out4path,source,b,4,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink1,sinks,add,sink2,sinks,add,sink3,sinks,add,sink4,plan,plan,new,plan,sinks,disjoint,plan,with,multiple,data,sinks,and,branches,compile,no,stats,plan
BranchingPlansCompilerTest -> @Test 	public void testBranchingDisjointPlan();1427784999;<pre>_(SINK 3) (SINK 1)   (SINK 2) (SINK 4)_\     /             \     /_(SRC A)             (SRC B)_</pre>__NOTE: this case is currently not caught by the compiler. we should enable the test once it is caught.;@Test_	public void testBranchingDisjointPlan() {_		_		final String out1Path = "file:///test/1"__		final String out2Path = "file:///test/2"__		final String out3Path = "file:///test/3"__		final String out4Path = "file:///test/4"___		FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE)__		FileDataSource sourceB = new FileDataSource(DummyInputFormat.class, IN_FILE)__		_		FileDataSink sink1 = new FileDataSink(DummyOutputFormat.class, out1Path, sourceA, "1")__		FileDataSink sink2 = new FileDataSink(DummyOutputFormat.class, out2Path, sourceB, "2")__		FileDataSink sink3 = new FileDataSink(DummyOutputFormat.class, out3Path, sourceA, "3")__		FileDataSink sink4 = new FileDataSink(DummyOutputFormat.class, out4Path, sourceB, "4")__		_		_		List<FileDataSink> sinks = new ArrayList<FileDataSink>()__		sinks.add(sink1)__		sinks.add(sink2)__		sinks.add(sink3)__		sinks.add(sink4)__		_		_		Plan plan = new Plan(sinks, "Disjoint plan with multiple data sinks and branches")__		compileNoStats(plan)__	};pre,sink,3,sink,1,sink,2,sink,4,src,a,src,b,pre,note,this,case,is,currently,not,caught,by,the,compiler,we,should,enable,the,test,once,it,is,caught;test,public,void,test,branching,disjoint,plan,final,string,out1path,file,test,1,final,string,out2path,file,test,2,final,string,out3path,file,test,3,final,string,out4path,file,test,4,file,data,source,source,a,new,file,data,source,dummy,input,format,class,file,data,source,source,b,new,file,data,source,dummy,input,format,class,file,data,sink,sink1,new,file,data,sink,dummy,output,format,class,out1path,source,a,1,file,data,sink,sink2,new,file,data,sink,dummy,output,format,class,out2path,source,b,2,file,data,sink,sink3,new,file,data,sink,dummy,output,format,class,out3path,source,a,3,file,data,sink,sink4,new,file,data,sink,dummy,output,format,class,out4path,source,b,4,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink1,sinks,add,sink2,sinks,add,sink3,sinks,add,sink4,plan,plan,new,plan,sinks,disjoint,plan,with,multiple,data,sinks,and,branches,compile,no,stats,plan
BranchingPlansCompilerTest -> @Test 	public void testBranchingDisjointPlan();1430859707;<pre>_(SINK 3) (SINK 1)   (SINK 2) (SINK 4)_\     /             \     /_(SRC A)             (SRC B)_</pre>__NOTE: this case is currently not caught by the compiler. we should enable the test once it is caught.;@Test_	public void testBranchingDisjointPlan() {_		_		final String out1Path = "file:///test/1"__		final String out2Path = "file:///test/2"__		final String out3Path = "file:///test/3"__		final String out4Path = "file:///test/4"___		_		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(DEFAULT_PARALLELISM)__		DataSet<Long> sourceA = env.generateSequence(0,1)__		DataSet<Long> sourceB = env.generateSequence(0,1)___		sourceA.writeAsText(out1Path)__		sourceB.writeAsText(out2Path)__		sourceA.writeAsText(out3Path)__		sourceB.writeAsText(out4Path)___		JavaPlan plan = env.createProgramPlan()__		compileNoStats(plan)___	};pre,sink,3,sink,1,sink,2,sink,4,src,a,src,b,pre,note,this,case,is,currently,not,caught,by,the,compiler,we,should,enable,the,test,once,it,is,caught;test,public,void,test,branching,disjoint,plan,final,string,out1path,file,test,1,final,string,out2path,file,test,2,final,string,out3path,file,test,3,final,string,out4path,file,test,4,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source,a,env,generate,sequence,0,1,data,set,long,source,b,env,generate,sequence,0,1,source,a,write,as,text,out1path,source,b,write,as,text,out2path,source,a,write,as,text,out3path,source,b,write,as,text,out4path,java,plan,plan,env,create,program,plan,compile,no,stats,plan
BranchingPlansCompilerTest -> @Test 	public void testBranchingDisjointPlan();1449526184;<pre>_(SINK 3) (SINK 1)   (SINK 2) (SINK 4)_\     /             \     /_(SRC A)             (SRC B)_</pre>__NOTE: this case is currently not caught by the compiler. we should enable the test once it is caught.;@Test_	public void testBranchingDisjointPlan() {_		_		final String out1Path = "file:///test/1"__		final String out2Path = "file:///test/2"__		final String out3Path = "file:///test/3"__		final String out4Path = "file:///test/4"___		_		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(DEFAULT_PARALLELISM)__		DataSet<Long> sourceA = env.generateSequence(0,1)__		DataSet<Long> sourceB = env.generateSequence(0,1)___		sourceA.writeAsText(out1Path)__		sourceB.writeAsText(out2Path)__		sourceA.writeAsText(out3Path)__		sourceB.writeAsText(out4Path)___		Plan plan = env.createProgramPlan()__		compileNoStats(plan)___	};pre,sink,3,sink,1,sink,2,sink,4,src,a,src,b,pre,note,this,case,is,currently,not,caught,by,the,compiler,we,should,enable,the,test,once,it,is,caught;test,public,void,test,branching,disjoint,plan,final,string,out1path,file,test,1,final,string,out2path,file,test,2,final,string,out3path,file,test,3,final,string,out4path,file,test,4,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source,a,env,generate,sequence,0,1,data,set,long,source,b,env,generate,sequence,0,1,source,a,write,as,text,out1path,source,b,write,as,text,out2path,source,a,write,as,text,out3path,source,b,write,as,text,out4path,plan,plan,env,create,program,plan,compile,no,stats,plan
BranchingPlansCompilerTest -> @Test 	public void testBranchingDisjointPlan();1475688973;<pre>_(SINK 3) (SINK 1)   (SINK 2) (SINK 4)_\     /             \     /_(SRC A)             (SRC B)_</pre>__NOTE: this case is currently not caught by the compiler. we should enable the test once it is caught.;@Test_	public void testBranchingDisjointPlan() {_		_		final String out1Path = "file:///test/1"__		final String out2Path = "file:///test/2"__		final String out3Path = "file:///test/3"__		final String out4Path = "file:///test/4"___		_		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(DEFAULT_PARALLELISM)__		DataSet<Long> sourceA = env.generateSequence(0,1)__		DataSet<Long> sourceB = env.generateSequence(0,1)___		sourceA.writeAsText(out1Path)__		sourceB.writeAsText(out2Path)__		sourceA.writeAsText(out3Path)__		sourceB.writeAsText(out4Path)___		Plan plan = env.createProgramPlan()__		compileNoStats(plan)___	};pre,sink,3,sink,1,sink,2,sink,4,src,a,src,b,pre,note,this,case,is,currently,not,caught,by,the,compiler,we,should,enable,the,test,once,it,is,caught;test,public,void,test,branching,disjoint,plan,final,string,out1path,file,test,1,final,string,out2path,file,test,2,final,string,out3path,file,test,3,final,string,out4path,file,test,4,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source,a,env,generate,sequence,0,1,data,set,long,source,b,env,generate,sequence,0,1,source,a,write,as,text,out1path,source,b,write,as,text,out2path,source,a,write,as,text,out3path,source,b,write,as,text,out4path,plan,plan,env,create,program,plan,compile,no,stats,plan
BranchingPlansCompilerTest -> @Test 	public void testDeltaIterationWithStaticInput();1426843274;<pre>_+----Iteration-------+_|                    |_/---------< >---------join-----< >---sink_/ (Solution)|           /        |_/            |          /         |_/--map-------< >----\   /       /--|_/     (Workset)|      \ /       /   |_src-map          |     join------/    |_\              |      /             |_\             +-----/--------------+_\                 /_\--reduce-------/_</pre>;@Test_	public void testDeltaIterationWithStaticInput() {_		FileDataSource source = new FileDataSource(DummyInputFormat.class, IN_FILE, "source")___		MapOperator mappedSource = MapOperator.builder(IdentityMap.class)._				input(source)._				name("Identity mapped source")._				build()___		ReduceOperator reducedSource = ReduceOperator.builder(IdentityReduce.class)._				input(source)._				name("Identity reduce source")._				build()___		DeltaIteration iteration = new DeltaIteration(0,"Loop")__		iteration.setMaximumNumberOfIterations(10)__		iteration.setInitialSolutionSet(source)__		iteration.setInitialWorkset(mappedSource)___		JoinOperator nextWorkset = JoinOperator.builder(DummyNonPreservingMatchStub.class, IntValue.class, 0,0)._				input1(iteration.getWorkset())._				input2(reducedSource)._				name("Next work set")._				build()___		JoinOperator solutionSetDelta = JoinOperator.builder(DummyNonPreservingMatchStub.class, IntValue.class, 0,_				0)._				input1(iteration.getSolutionSet())._				input2(nextWorkset)._				name("Solution set delta")._				build()___		iteration.setNextWorkset(nextWorkset)__		iteration.setSolutionSetDelta(solutionSetDelta)___		FileDataSink sink = new FileDataSink(DummyOutputFormat.class, OUT_FILE, iteration, "Iteration sink")__		List<FileDataSink> sinks = new ArrayList<FileDataSink>()__		sinks.add(sink)___		Plan plan = new Plan(sinks)___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,iteration,join,sink,solution,map,workset,src,map,join,reduce,pre;test,public,void,test,delta,iteration,with,static,input,file,data,source,source,new,file,data,source,dummy,input,format,class,source,map,operator,mapped,source,map,operator,builder,identity,map,class,input,source,name,identity,mapped,source,build,reduce,operator,reduced,source,reduce,operator,builder,identity,reduce,class,input,source,name,identity,reduce,source,build,delta,iteration,iteration,new,delta,iteration,0,loop,iteration,set,maximum,number,of,iterations,10,iteration,set,initial,solution,set,source,iteration,set,initial,workset,mapped,source,join,operator,next,workset,join,operator,builder,dummy,non,preserving,match,stub,class,int,value,class,0,0,input1,iteration,get,workset,input2,reduced,source,name,next,work,set,build,join,operator,solution,set,delta,join,operator,builder,dummy,non,preserving,match,stub,class,int,value,class,0,0,input1,iteration,get,solution,set,input2,next,workset,name,solution,set,delta,build,iteration,set,next,workset,next,workset,iteration,set,solution,set,delta,solution,set,delta,file,data,sink,sink,new,file,data,sink,dummy,output,format,class,iteration,iteration,sink,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink,plan,plan,new,plan,sinks,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testDeltaIterationWithStaticInput();1427097830;<pre>_+----Iteration-------+_|                    |_/---------< >---------join-----< >---sink_/ (Solution)|           /        |_/            |          /         |_/--map-------< >----\   /       /--|_/     (Workset)|      \ /       /   |_src-map          |     join------/    |_\              |      /             |_\             +-----/--------------+_\                 /_\--reduce-------/_</pre>;@Test_	public void testDeltaIterationWithStaticInput() {_		FileDataSource source = new FileDataSource(DummyInputFormat.class, IN_FILE, "source")___		MapOperator mappedSource = MapOperator.builder(IdentityMap.class)._				input(source)._				name("Identity mapped source")._				build()___		ReduceOperator reducedSource = ReduceOperator.builder(IdentityReduce.class)._				input(source)._				name("Identity reduce source")._				build()___		DeltaIteration iteration = new DeltaIteration(0,"Loop")__		iteration.setMaximumNumberOfIterations(10)__		iteration.setInitialSolutionSet(source)__		iteration.setInitialWorkset(mappedSource)___		JoinOperator nextWorkset = JoinOperator.builder(DummyNonPreservingMatchStub.class, IntValue.class, 0,0)._				input1(iteration.getWorkset())._				input2(reducedSource)._				name("Next work set")._				build()___		JoinOperator solutionSetDelta = JoinOperator.builder(DummyNonPreservingMatchStub.class, IntValue.class, 0,_				0)._				input1(iteration.getSolutionSet())._				input2(nextWorkset)._				name("Solution set delta")._				build()___		iteration.setNextWorkset(nextWorkset)__		iteration.setSolutionSetDelta(solutionSetDelta)___		FileDataSink sink = new FileDataSink(DummyOutputFormat.class, OUT_FILE, iteration, "Iteration sink")__		List<FileDataSink> sinks = new ArrayList<FileDataSink>()__		sinks.add(sink)___		Plan plan = new Plan(sinks)___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,iteration,join,sink,solution,map,workset,src,map,join,reduce,pre;test,public,void,test,delta,iteration,with,static,input,file,data,source,source,new,file,data,source,dummy,input,format,class,source,map,operator,mapped,source,map,operator,builder,identity,map,class,input,source,name,identity,mapped,source,build,reduce,operator,reduced,source,reduce,operator,builder,identity,reduce,class,input,source,name,identity,reduce,source,build,delta,iteration,iteration,new,delta,iteration,0,loop,iteration,set,maximum,number,of,iterations,10,iteration,set,initial,solution,set,source,iteration,set,initial,workset,mapped,source,join,operator,next,workset,join,operator,builder,dummy,non,preserving,match,stub,class,int,value,class,0,0,input1,iteration,get,workset,input2,reduced,source,name,next,work,set,build,join,operator,solution,set,delta,join,operator,builder,dummy,non,preserving,match,stub,class,int,value,class,0,0,input1,iteration,get,solution,set,input2,next,workset,name,solution,set,delta,build,iteration,set,next,workset,next,workset,iteration,set,solution,set,delta,solution,set,delta,file,data,sink,sink,new,file,data,sink,dummy,output,format,class,iteration,iteration,sink,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink,plan,plan,new,plan,sinks,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testDeltaIterationWithStaticInput();1427784999;<pre>_+----Iteration-------+_|                    |_/---------< >---------join-----< >---sink_/ (Solution)|           /        |_/            |          /         |_/--map-------< >----\   /       /--|_/     (Workset)|      \ /       /   |_src-map          |     join------/    |_\              |      /             |_\             +-----/--------------+_\                 /_\--reduce-------/_</pre>;@Test_	public void testDeltaIterationWithStaticInput() {_		FileDataSource source = new FileDataSource(DummyInputFormat.class, IN_FILE, "source")___		MapOperator mappedSource = MapOperator.builder(IdentityMap.class)._				input(source)._				name("Identity mapped source")._				build()___		ReduceOperator reducedSource = ReduceOperator.builder(IdentityReduce.class)._				input(source)._				name("Identity reduce source")._				build()___		DeltaIteration iteration = new DeltaIteration(0,"Loop")__		iteration.setMaximumNumberOfIterations(10)__		iteration.setInitialSolutionSet(source)__		iteration.setInitialWorkset(mappedSource)___		JoinOperator nextWorkset = JoinOperator.builder(DummyNonPreservingMatchStub.class, IntValue.class, 0,0)._				input1(iteration.getWorkset())._				input2(reducedSource)._				name("Next work set")._				build()___		JoinOperator solutionSetDelta = JoinOperator.builder(DummyNonPreservingMatchStub.class, IntValue.class, 0,_				0)._				input1(iteration.getSolutionSet())._				input2(nextWorkset)._				name("Solution set delta")._				build()___		iteration.setNextWorkset(nextWorkset)__		iteration.setSolutionSetDelta(solutionSetDelta)___		FileDataSink sink = new FileDataSink(DummyOutputFormat.class, OUT_FILE, iteration, "Iteration sink")__		List<FileDataSink> sinks = new ArrayList<FileDataSink>()__		sinks.add(sink)___		Plan plan = new Plan(sinks)___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,iteration,join,sink,solution,map,workset,src,map,join,reduce,pre;test,public,void,test,delta,iteration,with,static,input,file,data,source,source,new,file,data,source,dummy,input,format,class,source,map,operator,mapped,source,map,operator,builder,identity,map,class,input,source,name,identity,mapped,source,build,reduce,operator,reduced,source,reduce,operator,builder,identity,reduce,class,input,source,name,identity,reduce,source,build,delta,iteration,iteration,new,delta,iteration,0,loop,iteration,set,maximum,number,of,iterations,10,iteration,set,initial,solution,set,source,iteration,set,initial,workset,mapped,source,join,operator,next,workset,join,operator,builder,dummy,non,preserving,match,stub,class,int,value,class,0,0,input1,iteration,get,workset,input2,reduced,source,name,next,work,set,build,join,operator,solution,set,delta,join,operator,builder,dummy,non,preserving,match,stub,class,int,value,class,0,0,input1,iteration,get,solution,set,input2,next,workset,name,solution,set,delta,build,iteration,set,next,workset,next,workset,iteration,set,solution,set,delta,solution,set,delta,file,data,sink,sink,new,file,data,sink,dummy,output,format,class,iteration,iteration,sink,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink,plan,plan,new,plan,sinks,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testDeltaIterationWithStaticInput();1430859707;<pre>_+----Iteration-------+_|                    |_/---------< >---------join-----< >---sink_/ (Solution)|           /        |_/            |          /         |_/--map-------< >----\   /       /--|_/     (Workset)|      \ /       /   |_src-map          |     join------/    |_\              |      /             |_\             +-----/--------------+_\                 /_\--reduce-------/_</pre>;@Test_	public void testDeltaIterationWithStaticInput() {_		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(DEFAULT_PARALLELISM)__		DataSet<Tuple2<Long, Long>> source = env.generateSequence(0,1).map(new Duplicator<Long>())___		DataSet<Tuple2<Long,Long>> map = source_				.map(new IdentityMapper<Tuple2<Long, Long>>())__		DataSet<Tuple2<Long,Long>> reduce = source_				.reduceGroup(new IdentityGroupReducer<Tuple2<Long, Long>>())___		DeltaIteration<Tuple2<Long, Long>, Tuple2<Long, Long>> loop = source.iterateDelta(map, 10, 0)___		DataSet<Tuple2<Long, Long>> workset = loop.getWorkset().join(reduce).where(0).equalTo(0)_				.with(new IdentityJoiner<Tuple2<Long, Long>>()).name("Next work set")__		DataSet<Tuple2<Long, Long>> delta = loop.getSolutionSet().join(workset).where(0).equalTo(0)_				.with(new IdentityJoiner<Tuple2<Long, Long>>()).name("Solution set delta")___		DataSet<Tuple2<Long, Long>> result = loop.closeWith(delta, workset)__		result.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())___		JavaPlan plan = env.createProgramPlan()___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,iteration,join,sink,solution,map,workset,src,map,join,reduce,pre;test,public,void,test,delta,iteration,with,static,input,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,env,generate,sequence,0,1,map,new,duplicator,long,data,set,tuple2,long,long,map,source,map,new,identity,mapper,tuple2,long,long,data,set,tuple2,long,long,reduce,source,reduce,group,new,identity,group,reducer,tuple2,long,long,delta,iteration,tuple2,long,long,tuple2,long,long,loop,source,iterate,delta,map,10,0,data,set,tuple2,long,long,workset,loop,get,workset,join,reduce,where,0,equal,to,0,with,new,identity,joiner,tuple2,long,long,name,next,work,set,data,set,tuple2,long,long,delta,loop,get,solution,set,join,workset,where,0,equal,to,0,with,new,identity,joiner,tuple2,long,long,name,solution,set,delta,data,set,tuple2,long,long,result,loop,close,with,delta,workset,result,output,new,discarding,output,format,tuple2,long,long,java,plan,plan,env,create,program,plan,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testDeltaIterationWithStaticInput();1449526184;<pre>_+----Iteration-------+_|                    |_/---------< >---------join-----< >---sink_/ (Solution)|           /        |_/            |          /         |_/--map-------< >----\   /       /--|_/     (Workset)|      \ /       /   |_src-map          |     join------/    |_\              |      /             |_\             +-----/--------------+_\                 /_\--reduce-------/_</pre>;@Test_	public void testDeltaIterationWithStaticInput() {_		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(DEFAULT_PARALLELISM)__		DataSet<Tuple2<Long, Long>> source = env.generateSequence(0,1).map(new Duplicator<Long>())___		DataSet<Tuple2<Long,Long>> map = source_				.map(new IdentityMapper<Tuple2<Long, Long>>())__		DataSet<Tuple2<Long,Long>> reduce = source_				.reduceGroup(new IdentityGroupReducer<Tuple2<Long, Long>>())___		DeltaIteration<Tuple2<Long, Long>, Tuple2<Long, Long>> loop = source.iterateDelta(map, 10, 0)___		DataSet<Tuple2<Long, Long>> workset = loop.getWorkset().join(reduce).where(0).equalTo(0)_				.with(new IdentityJoiner<Tuple2<Long, Long>>()).name("Next work set")__		DataSet<Tuple2<Long, Long>> delta = loop.getSolutionSet().join(workset).where(0).equalTo(0)_				.with(new IdentityJoiner<Tuple2<Long, Long>>()).name("Solution set delta")___		DataSet<Tuple2<Long, Long>> result = loop.closeWith(delta, workset)__		result.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())___		Plan plan = env.createProgramPlan()___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,iteration,join,sink,solution,map,workset,src,map,join,reduce,pre;test,public,void,test,delta,iteration,with,static,input,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,env,generate,sequence,0,1,map,new,duplicator,long,data,set,tuple2,long,long,map,source,map,new,identity,mapper,tuple2,long,long,data,set,tuple2,long,long,reduce,source,reduce,group,new,identity,group,reducer,tuple2,long,long,delta,iteration,tuple2,long,long,tuple2,long,long,loop,source,iterate,delta,map,10,0,data,set,tuple2,long,long,workset,loop,get,workset,join,reduce,where,0,equal,to,0,with,new,identity,joiner,tuple2,long,long,name,next,work,set,data,set,tuple2,long,long,delta,loop,get,solution,set,join,workset,where,0,equal,to,0,with,new,identity,joiner,tuple2,long,long,name,solution,set,delta,data,set,tuple2,long,long,result,loop,close,with,delta,workset,result,output,new,discarding,output,format,tuple2,long,long,plan,plan,env,create,program,plan,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testDeltaIterationWithStaticInput();1475688973;<pre>_+----Iteration-------+_|                    |_/---------< >---------join-----< >---sink_/ (Solution)|           /        |_/            |          /         |_/--map-------< >----\   /       /--|_/     (Workset)|      \ /       /   |_src-map          |     join------/    |_\              |      /             |_\             +-----/--------------+_\                 /_\--reduce-------/_</pre>;@Test_	public void testDeltaIterationWithStaticInput() {_		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(DEFAULT_PARALLELISM)__		DataSet<Tuple2<Long, Long>> source = env.generateSequence(0,1).map(new Duplicator<Long>())___		DataSet<Tuple2<Long,Long>> map = source_				.map(new IdentityMapper<Tuple2<Long, Long>>())__		DataSet<Tuple2<Long,Long>> reduce = source_				.reduceGroup(new IdentityGroupReducer<Tuple2<Long, Long>>())___		DeltaIteration<Tuple2<Long, Long>, Tuple2<Long, Long>> loop = source.iterateDelta(map, 10, 0)___		DataSet<Tuple2<Long, Long>> workset = loop.getWorkset().join(reduce).where(0).equalTo(0)_				.with(new IdentityJoiner<Tuple2<Long, Long>>()).name("Next work set")__		DataSet<Tuple2<Long, Long>> delta = loop.getSolutionSet().join(workset).where(0).equalTo(0)_				.with(new IdentityJoiner<Tuple2<Long, Long>>()).name("Solution set delta")___		DataSet<Tuple2<Long, Long>> result = loop.closeWith(delta, workset)__		result.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())___		Plan plan = env.createProgramPlan()___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,iteration,join,sink,solution,map,workset,src,map,join,reduce,pre;test,public,void,test,delta,iteration,with,static,input,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,env,generate,sequence,0,1,map,new,duplicator,long,data,set,tuple2,long,long,map,source,map,new,identity,mapper,tuple2,long,long,data,set,tuple2,long,long,reduce,source,reduce,group,new,identity,group,reducer,tuple2,long,long,delta,iteration,tuple2,long,long,tuple2,long,long,loop,source,iterate,delta,map,10,0,data,set,tuple2,long,long,workset,loop,get,workset,join,reduce,where,0,equal,to,0,with,new,identity,joiner,tuple2,long,long,name,next,work,set,data,set,tuple2,long,long,delta,loop,get,solution,set,join,workset,where,0,equal,to,0,with,new,identity,joiner,tuple2,long,long,name,solution,set,delta,data,set,tuple2,long,long,result,loop,close,with,delta,workset,result,output,new,discarding,output,format,tuple2,long,long,plan,plan,env,create,program,plan,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingWithMultipleDataSinksSmall();1426843274;<pre>_(SRC A)_/     \_(SINK A)    (SINK B)_</pre>;@Test_	public void testBranchingWithMultipleDataSinksSmall() {_		try {_			_			final String out1Path = "file:///test/1"__			final String out2Path = "file:///test/2"__	_			FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE)__			_			FileDataSink sinkA = new FileDataSink(DummyOutputFormat.class, out1Path, sourceA)__			FileDataSink sinkB = new FileDataSink(DummyOutputFormat.class, out2Path, sourceA)__			_			List<FileDataSink> sinks = new ArrayList<FileDataSink>()__			sinks.add(sinkA)__			sinks.add(sinkB)__			_			_			Plan plan = new Plan(sinks, "Plans With Multiple Data Sinks")__			_			OptimizedPlan oPlan = compileNoStats(plan)__			_			_			_			_			Assert.assertEquals("Wrong number of data sinks.", 2, oPlan.getDataSinks().size())__			_			_			Set<String> allSinks = new HashSet<String>()__			allSinks.add(out1Path)__			allSinks.add(out2Path)__			_			for (SinkPlanNode n : oPlan.getDataSinks()) {_				String path = ((FileDataSink) n.getSinkNode().getOperator()).getFilePath()__				Assert.assertTrue("Invalid data sink.", allSinks.remove(path))__			}_			_			_			_			JobGraphGenerator jobGen = new JobGraphGenerator()__			jobGen.compileJobGraph(oPlan)__		} catch (Exception e) {_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,src,a,sink,a,sink,b,pre;test,public,void,test,branching,with,multiple,data,sinks,small,try,final,string,out1path,file,test,1,final,string,out2path,file,test,2,file,data,source,source,a,new,file,data,source,dummy,input,format,class,file,data,sink,sink,a,new,file,data,sink,dummy,output,format,class,out1path,source,a,file,data,sink,sink,b,new,file,data,sink,dummy,output,format,class,out2path,source,a,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink,a,sinks,add,sink,b,plan,plan,new,plan,sinks,plans,with,multiple,data,sinks,optimized,plan,o,plan,compile,no,stats,plan,assert,assert,equals,wrong,number,of,data,sinks,2,o,plan,get,data,sinks,size,set,string,all,sinks,new,hash,set,string,all,sinks,add,out1path,all,sinks,add,out2path,for,sink,plan,node,n,o,plan,get,data,sinks,string,path,file,data,sink,n,get,sink,node,get,operator,get,file,path,assert,assert,true,invalid,data,sink,all,sinks,remove,path,job,graph,generator,job,gen,new,job,graph,generator,job,gen,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingWithMultipleDataSinksSmall();1427097830;<pre>_(SRC A)_/     \_(SINK A)    (SINK B)_</pre>;@Test_	public void testBranchingWithMultipleDataSinksSmall() {_		try {_			_			final String out1Path = "file:///test/1"__			final String out2Path = "file:///test/2"__	_			FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE)__			_			FileDataSink sinkA = new FileDataSink(DummyOutputFormat.class, out1Path, sourceA)__			FileDataSink sinkB = new FileDataSink(DummyOutputFormat.class, out2Path, sourceA)__			_			List<FileDataSink> sinks = new ArrayList<FileDataSink>()__			sinks.add(sinkA)__			sinks.add(sinkB)__			_			_			Plan plan = new Plan(sinks, "Plans With Multiple Data Sinks")__			_			OptimizedPlan oPlan = compileNoStats(plan)__			_			_			_			_			Assert.assertEquals("Wrong number of data sinks.", 2, oPlan.getDataSinks().size())__			_			_			Set<String> allSinks = new HashSet<String>()__			allSinks.add(out1Path)__			allSinks.add(out2Path)__			_			for (SinkPlanNode n : oPlan.getDataSinks()) {_				String path = ((FileDataSink) n.getSinkNode().getOperator()).getFilePath()__				Assert.assertTrue("Invalid data sink.", allSinks.remove(path))__			}_			_			_			_			JobGraphGenerator jobGen = new JobGraphGenerator()__			jobGen.compileJobGraph(oPlan)__		} catch (Exception e) {_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,src,a,sink,a,sink,b,pre;test,public,void,test,branching,with,multiple,data,sinks,small,try,final,string,out1path,file,test,1,final,string,out2path,file,test,2,file,data,source,source,a,new,file,data,source,dummy,input,format,class,file,data,sink,sink,a,new,file,data,sink,dummy,output,format,class,out1path,source,a,file,data,sink,sink,b,new,file,data,sink,dummy,output,format,class,out2path,source,a,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink,a,sinks,add,sink,b,plan,plan,new,plan,sinks,plans,with,multiple,data,sinks,optimized,plan,o,plan,compile,no,stats,plan,assert,assert,equals,wrong,number,of,data,sinks,2,o,plan,get,data,sinks,size,set,string,all,sinks,new,hash,set,string,all,sinks,add,out1path,all,sinks,add,out2path,for,sink,plan,node,n,o,plan,get,data,sinks,string,path,file,data,sink,n,get,sink,node,get,operator,get,file,path,assert,assert,true,invalid,data,sink,all,sinks,remove,path,job,graph,generator,job,gen,new,job,graph,generator,job,gen,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingWithMultipleDataSinksSmall();1427784999;<pre>_(SRC A)_/     \_(SINK A)    (SINK B)_</pre>;@Test_	public void testBranchingWithMultipleDataSinksSmall() {_		try {_			_			final String out1Path = "file:///test/1"__			final String out2Path = "file:///test/2"__	_			FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE)__			_			FileDataSink sinkA = new FileDataSink(DummyOutputFormat.class, out1Path, sourceA)__			FileDataSink sinkB = new FileDataSink(DummyOutputFormat.class, out2Path, sourceA)__			_			List<FileDataSink> sinks = new ArrayList<FileDataSink>()__			sinks.add(sinkA)__			sinks.add(sinkB)__			_			_			Plan plan = new Plan(sinks, "Plans With Multiple Data Sinks")__			_			OptimizedPlan oPlan = compileNoStats(plan)__			_			_			_			_			Assert.assertEquals("Wrong number of data sinks.", 2, oPlan.getDataSinks().size())__			_			_			Set<String> allSinks = new HashSet<String>()__			allSinks.add(out1Path)__			allSinks.add(out2Path)__			_			for (SinkPlanNode n : oPlan.getDataSinks()) {_				String path = ((FileDataSink) n.getSinkNode().getOperator()).getFilePath()__				Assert.assertTrue("Invalid data sink.", allSinks.remove(path))__			}_			_			_			_			JobGraphGenerator jobGen = new JobGraphGenerator()__			jobGen.compileJobGraph(oPlan)__		} catch (Exception e) {_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,src,a,sink,a,sink,b,pre;test,public,void,test,branching,with,multiple,data,sinks,small,try,final,string,out1path,file,test,1,final,string,out2path,file,test,2,file,data,source,source,a,new,file,data,source,dummy,input,format,class,file,data,sink,sink,a,new,file,data,sink,dummy,output,format,class,out1path,source,a,file,data,sink,sink,b,new,file,data,sink,dummy,output,format,class,out2path,source,a,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink,a,sinks,add,sink,b,plan,plan,new,plan,sinks,plans,with,multiple,data,sinks,optimized,plan,o,plan,compile,no,stats,plan,assert,assert,equals,wrong,number,of,data,sinks,2,o,plan,get,data,sinks,size,set,string,all,sinks,new,hash,set,string,all,sinks,add,out1path,all,sinks,add,out2path,for,sink,plan,node,n,o,plan,get,data,sinks,string,path,file,data,sink,n,get,sink,node,get,operator,get,file,path,assert,assert,true,invalid,data,sink,all,sinks,remove,path,job,graph,generator,job,gen,new,job,graph,generator,job,gen,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingWithMultipleDataSinksSmall();1430859707;<pre>_(SRC A)_/     \_(SINK A)    (SINK B)_</pre>;@Test_	public void testBranchingWithMultipleDataSinksSmall() {_		try {_			String outPath1 = "/tmp/out1"__			String outPath2 = "/tmp/out2"___			_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)__			DataSet<Long> source1 = env.generateSequence(0,1)___			source1.writeAsText(outPath1)__			source1.writeAsText(outPath2)___			JavaPlan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			_			_			_			_			Assert.assertEquals("Wrong number of data sinks.", 2, oPlan.getDataSinks().size())__			_			_			Set<String> allSinks = new HashSet<String>()__			allSinks.add(outPath1)__			allSinks.add(outPath2)__			_			for (SinkPlanNode n : oPlan.getDataSinks()) {_				String path = ((TextOutputFormat<String>)n.getSinkNode().getOperator()_						.getFormatWrapper().getUserCodeObject()).getOutputFilePath().toString()__				Assert.assertTrue("Invalid data sink.", allSinks.remove(path))__			}_			_			_			_			JobGraphGenerator jobGen = new JobGraphGenerator()__			jobGen.compileJobGraph(oPlan)__		} catch (Exception e) {_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,src,a,sink,a,sink,b,pre;test,public,void,test,branching,with,multiple,data,sinks,small,try,string,out,path1,tmp,out1,string,out,path2,tmp,out2,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source1,env,generate,sequence,0,1,source1,write,as,text,out,path1,source1,write,as,text,out,path2,java,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,assert,assert,equals,wrong,number,of,data,sinks,2,o,plan,get,data,sinks,size,set,string,all,sinks,new,hash,set,string,all,sinks,add,out,path1,all,sinks,add,out,path2,for,sink,plan,node,n,o,plan,get,data,sinks,string,path,text,output,format,string,n,get,sink,node,get,operator,get,format,wrapper,get,user,code,object,get,output,file,path,to,string,assert,assert,true,invalid,data,sink,all,sinks,remove,path,job,graph,generator,job,gen,new,job,graph,generator,job,gen,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingWithMultipleDataSinksSmall();1449526184;<pre>_(SRC A)_/     \_(SINK A)    (SINK B)_</pre>;@Test_	public void testBranchingWithMultipleDataSinksSmall() {_		try {_			String outPath1 = "/tmp/out1"__			String outPath2 = "/tmp/out2"___			_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)__			DataSet<Long> source1 = env.generateSequence(0,1)___			source1.writeAsText(outPath1)__			source1.writeAsText(outPath2)___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			_			_			_			_			Assert.assertEquals("Wrong number of data sinks.", 2, oPlan.getDataSinks().size())__			_			_			Set<String> allSinks = new HashSet<String>()__			allSinks.add(outPath1)__			allSinks.add(outPath2)__			_			for (SinkPlanNode n : oPlan.getDataSinks()) {_				String path = ((TextOutputFormat<String>)n.getSinkNode().getOperator()_						.getFormatWrapper().getUserCodeObject()).getOutputFilePath().toString()__				Assert.assertTrue("Invalid data sink.", allSinks.remove(path))__			}_			_			_			_			JobGraphGenerator jobGen = new JobGraphGenerator()__			jobGen.compileJobGraph(oPlan)__		} catch (Exception e) {_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,src,a,sink,a,sink,b,pre;test,public,void,test,branching,with,multiple,data,sinks,small,try,string,out,path1,tmp,out1,string,out,path2,tmp,out2,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source1,env,generate,sequence,0,1,source1,write,as,text,out,path1,source1,write,as,text,out,path2,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,assert,assert,equals,wrong,number,of,data,sinks,2,o,plan,get,data,sinks,size,set,string,all,sinks,new,hash,set,string,all,sinks,add,out,path1,all,sinks,add,out,path2,for,sink,plan,node,n,o,plan,get,data,sinks,string,path,text,output,format,string,n,get,sink,node,get,operator,get,format,wrapper,get,user,code,object,get,output,file,path,to,string,assert,assert,true,invalid,data,sink,all,sinks,remove,path,job,graph,generator,job,gen,new,job,graph,generator,job,gen,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingWithMultipleDataSinksSmall();1475688973;<pre>_(SRC A)_/     \_(SINK A)    (SINK B)_</pre>;@Test_	public void testBranchingWithMultipleDataSinksSmall() {_		try {_			String outPath1 = "/tmp/out1"__			String outPath2 = "/tmp/out2"___			_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)__			DataSet<Long> source1 = env.generateSequence(0,1)___			source1.writeAsText(outPath1)__			source1.writeAsText(outPath2)___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			_			_			_			_			Assert.assertEquals("Wrong number of data sinks.", 2, oPlan.getDataSinks().size())__			_			_			Set<String> allSinks = new HashSet<String>()__			allSinks.add(outPath1)__			allSinks.add(outPath2)__			_			for (SinkPlanNode n : oPlan.getDataSinks()) {_				String path = ((TextOutputFormat<String>)n.getSinkNode().getOperator()_						.getFormatWrapper().getUserCodeObject()).getOutputFilePath().toString()__				Assert.assertTrue("Invalid data sink.", allSinks.remove(path))__			}_			_			_			_			JobGraphGenerator jobGen = new JobGraphGenerator()__			jobGen.compileJobGraph(oPlan)__		} catch (Exception e) {_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};pre,src,a,sink,a,sink,b,pre;test,public,void,test,branching,with,multiple,data,sinks,small,try,string,out,path1,tmp,out1,string,out,path2,tmp,out2,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source1,env,generate,sequence,0,1,source1,write,as,text,out,path1,source1,write,as,text,out,path2,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,assert,assert,equals,wrong,number,of,data,sinks,2,o,plan,get,data,sinks,size,set,string,all,sinks,new,hash,set,string,all,sinks,add,out,path1,all,sinks,add,out,path2,for,sink,plan,node,n,o,plan,get,data,sinks,string,path,text,output,format,string,n,get,sink,node,get,operator,get,format,wrapper,get,user,code,object,get,output,file,path,to,string,assert,assert,true,invalid,data,sink,all,sinks,remove,path,job,graph,generator,job,gen,new,job,graph,generator,job,gen,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingSourceMultipleTimes();1426843274;<pre>_SINK__COGROUP_+---/    \----+_/               \_/             MATCH10_/               |    \_/                |  MATCH9_MATCH5               |  |   \_|   \                |  | MATCH8_| MATCH4             |  |  |   \_|  |   \             |  |  | MATCH7_|  | MATCH3          |  |  |  |   \_|  |  |   \          |  |  |  | MATCH6_|  |  | MATCH2       |  |  |  |  |  |_|  |  |  |   \       +--+--+--+--+--+_|  |  |  | MATCH1            MAP_\  |  |  |  |  | /-----------/_(DATA SOURCE ONE)_</pre>;@Test_	public void testBranchingSourceMultipleTimes() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setDegreeOfParallelism(DEFAULT_PARALLELISM)___			DataSet<Tuple2<Long, Long>> source = env.generateSequence(1, 10000000)_				.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> joined1 = source.join(source).where(0).equalTo(0)_														.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined2 = source.join(joined1).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined3 = source.join(joined2).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined4 = source.join(joined3).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined5 = source.join(joined4).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> mapped = source.map(_					new MapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>() {_						@Override_						public Tuple2<Long, Long> map(Tuple2<Long, Long> value) {_							return null__						}_			})___			DataSet<Tuple2<Long, Long>> joined6 = mapped.join(mapped).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined7 = mapped.join(joined6).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined8 = mapped.join(joined7).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined9 = mapped.join(joined8).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined10 = mapped.join(joined9).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())____			joined5.coGroup(joined10)_					.where(1).equalTo(1)_					.with(new DummyCoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>())__				.output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,sink,cogroup,match10,match9,match5,match8,match4,match7,match3,match6,match2,match1,map,data,source,one,pre;test,public,void,test,branching,source,multiple,times,try,execution,environment,env,execution,environment,get,execution,environment,env,set,degree,of,parallelism,data,set,tuple2,long,long,source,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,joined1,source,join,source,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined2,source,join,joined1,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined3,source,join,joined2,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined4,source,join,joined3,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined5,source,join,joined4,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,mapped,source,map,new,map,function,tuple2,long,long,tuple2,long,long,override,public,tuple2,long,long,map,tuple2,long,long,value,return,null,data,set,tuple2,long,long,joined6,mapped,join,mapped,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined7,mapped,join,joined6,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined8,mapped,join,joined7,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined9,mapped,join,joined8,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined10,mapped,join,joined9,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,joined5,co,group,joined10,where,1,equal,to,1,with,new,dummy,co,group,function,tuple2,long,long,tuple2,long,long,output,new,discarding,output,format,tuple2,tuple2,long,long,tuple2,long,long,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingSourceMultipleTimes();1427097830;<pre>_SINK__COGROUP_+---/    \----+_/               \_/             MATCH10_/               |    \_/                |  MATCH9_MATCH5               |  |   \_|   \                |  | MATCH8_| MATCH4             |  |  |   \_|  |   \             |  |  | MATCH7_|  | MATCH3          |  |  |  |   \_|  |  |   \          |  |  |  | MATCH6_|  |  | MATCH2       |  |  |  |  |  |_|  |  |  |   \       +--+--+--+--+--+_|  |  |  | MATCH1            MAP_\  |  |  |  |  | /-----------/_(DATA SOURCE ONE)_</pre>;@Test_	public void testBranchingSourceMultipleTimes() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Tuple2<Long, Long>> source = env.generateSequence(1, 10000000)_				.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> joined1 = source.join(source).where(0).equalTo(0)_														.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined2 = source.join(joined1).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined3 = source.join(joined2).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined4 = source.join(joined3).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined5 = source.join(joined4).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> mapped = source.map(_					new MapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>() {_						@Override_						public Tuple2<Long, Long> map(Tuple2<Long, Long> value) {_							return null__						}_			})___			DataSet<Tuple2<Long, Long>> joined6 = mapped.join(mapped).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined7 = mapped.join(joined6).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined8 = mapped.join(joined7).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined9 = mapped.join(joined8).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined10 = mapped.join(joined9).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())____			joined5.coGroup(joined10)_					.where(1).equalTo(1)_					.with(new DummyCoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>())__				.output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,sink,cogroup,match10,match9,match5,match8,match4,match7,match3,match6,match2,match1,map,data,source,one,pre;test,public,void,test,branching,source,multiple,times,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,joined1,source,join,source,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined2,source,join,joined1,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined3,source,join,joined2,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined4,source,join,joined3,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined5,source,join,joined4,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,mapped,source,map,new,map,function,tuple2,long,long,tuple2,long,long,override,public,tuple2,long,long,map,tuple2,long,long,value,return,null,data,set,tuple2,long,long,joined6,mapped,join,mapped,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined7,mapped,join,joined6,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined8,mapped,join,joined7,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined9,mapped,join,joined8,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined10,mapped,join,joined9,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,joined5,co,group,joined10,where,1,equal,to,1,with,new,dummy,co,group,function,tuple2,long,long,tuple2,long,long,output,new,discarding,output,format,tuple2,tuple2,long,long,tuple2,long,long,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingSourceMultipleTimes();1427784999;<pre>_SINK__COGROUP_+---/    \----+_/               \_/             MATCH10_/               |    \_/                |  MATCH9_MATCH5               |  |   \_|   \                |  | MATCH8_| MATCH4             |  |  |   \_|  |   \             |  |  | MATCH7_|  | MATCH3          |  |  |  |   \_|  |  |   \          |  |  |  | MATCH6_|  |  | MATCH2       |  |  |  |  |  |_|  |  |  |   \       +--+--+--+--+--+_|  |  |  | MATCH1            MAP_\  |  |  |  |  | /-----------/_(DATA SOURCE ONE)_</pre>;@Test_	public void testBranchingSourceMultipleTimes() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Tuple2<Long, Long>> source = env.generateSequence(1, 10000000)_				.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> joined1 = source.join(source).where(0).equalTo(0)_														.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined2 = source.join(joined1).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined3 = source.join(joined2).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined4 = source.join(joined3).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined5 = source.join(joined4).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> mapped = source.map(_					new MapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>() {_						@Override_						public Tuple2<Long, Long> map(Tuple2<Long, Long> value) {_							return null__						}_			})___			DataSet<Tuple2<Long, Long>> joined6 = mapped.join(mapped).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined7 = mapped.join(joined6).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined8 = mapped.join(joined7).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined9 = mapped.join(joined8).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined10 = mapped.join(joined9).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())____			joined5.coGroup(joined10)_					.where(1).equalTo(1)_					.with(new DummyCoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>())__				.output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,sink,cogroup,match10,match9,match5,match8,match4,match7,match3,match6,match2,match1,map,data,source,one,pre;test,public,void,test,branching,source,multiple,times,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,joined1,source,join,source,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined2,source,join,joined1,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined3,source,join,joined2,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined4,source,join,joined3,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined5,source,join,joined4,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,mapped,source,map,new,map,function,tuple2,long,long,tuple2,long,long,override,public,tuple2,long,long,map,tuple2,long,long,value,return,null,data,set,tuple2,long,long,joined6,mapped,join,mapped,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined7,mapped,join,joined6,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined8,mapped,join,joined7,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined9,mapped,join,joined8,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined10,mapped,join,joined9,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,joined5,co,group,joined10,where,1,equal,to,1,with,new,dummy,co,group,function,tuple2,long,long,tuple2,long,long,output,new,discarding,output,format,tuple2,tuple2,long,long,tuple2,long,long,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingSourceMultipleTimes();1430859707;<pre>_SINK__COGROUP_+---/    \----+_/               \_/             MATCH10_/               |    \_/                |  MATCH9_MATCH5               |  |   \_|   \                |  | MATCH8_| MATCH4             |  |  |   \_|  |   \             |  |  | MATCH7_|  | MATCH3          |  |  |  |   \_|  |  |   \          |  |  |  | MATCH6_|  |  | MATCH2       |  |  |  |  |  |_|  |  |  |   \       +--+--+--+--+--+_|  |  |  | MATCH1            MAP_\  |  |  |  |  | /-----------/_(DATA SOURCE ONE)_</pre>;@Test_	public void testBranchingSourceMultipleTimes() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Tuple2<Long, Long>> source = env.generateSequence(1, 10000000)_				.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> joined1 = source.join(source).where(0).equalTo(0)_														.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined2 = source.join(joined1).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined3 = source.join(joined2).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined4 = source.join(joined3).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined5 = source.join(joined4).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> mapped = source.map(_					new MapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>() {_						@Override_						public Tuple2<Long, Long> map(Tuple2<Long, Long> value) {_							return null__						}_			})___			DataSet<Tuple2<Long, Long>> joined6 = mapped.join(mapped).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined7 = mapped.join(joined6).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined8 = mapped.join(joined7).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined9 = mapped.join(joined8).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined10 = mapped.join(joined9).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())____			joined5.coGroup(joined10)_					.where(1).equalTo(1)_					.with(new DummyCoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>())__				.output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,sink,cogroup,match10,match9,match5,match8,match4,match7,match3,match6,match2,match1,map,data,source,one,pre;test,public,void,test,branching,source,multiple,times,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,joined1,source,join,source,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined2,source,join,joined1,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined3,source,join,joined2,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined4,source,join,joined3,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined5,source,join,joined4,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,mapped,source,map,new,map,function,tuple2,long,long,tuple2,long,long,override,public,tuple2,long,long,map,tuple2,long,long,value,return,null,data,set,tuple2,long,long,joined6,mapped,join,mapped,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined7,mapped,join,joined6,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined8,mapped,join,joined7,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined9,mapped,join,joined8,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined10,mapped,join,joined9,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,joined5,co,group,joined10,where,1,equal,to,1,with,new,dummy,co,group,function,tuple2,long,long,tuple2,long,long,output,new,discarding,output,format,tuple2,tuple2,long,long,tuple2,long,long,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingSourceMultipleTimes();1449526184;<pre>_SINK__COGROUP_+---/    \----+_/               \_/             MATCH10_/               |    \_/                |  MATCH9_MATCH5               |  |   \_|   \                |  | MATCH8_| MATCH4             |  |  |   \_|  |   \             |  |  | MATCH7_|  | MATCH3          |  |  |  |   \_|  |  |   \          |  |  |  | MATCH6_|  |  | MATCH2       |  |  |  |  |  |_|  |  |  |   \       +--+--+--+--+--+_|  |  |  | MATCH1            MAP_\  |  |  |  |  | /-----------/_(DATA SOURCE ONE)_</pre>;@Test_	public void testBranchingSourceMultipleTimes() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Tuple2<Long, Long>> source = env.generateSequence(1, 10000000)_				.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> joined1 = source.join(source).where(0).equalTo(0)_														.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined2 = source.join(joined1).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined3 = source.join(joined2).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined4 = source.join(joined3).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined5 = source.join(joined4).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> mapped = source.map(_					new MapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>() {_						@Override_						public Tuple2<Long, Long> map(Tuple2<Long, Long> value) {_							return null__						}_			})___			DataSet<Tuple2<Long, Long>> joined6 = mapped.join(mapped).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined7 = mapped.join(joined6).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined8 = mapped.join(joined7).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined9 = mapped.join(joined8).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined10 = mapped.join(joined9).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())____			joined5.coGroup(joined10)_					.where(1).equalTo(1)_					.with(new DummyCoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>())__				.output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,sink,cogroup,match10,match9,match5,match8,match4,match7,match3,match6,match2,match1,map,data,source,one,pre;test,public,void,test,branching,source,multiple,times,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,joined1,source,join,source,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined2,source,join,joined1,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined3,source,join,joined2,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined4,source,join,joined3,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined5,source,join,joined4,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,mapped,source,map,new,map,function,tuple2,long,long,tuple2,long,long,override,public,tuple2,long,long,map,tuple2,long,long,value,return,null,data,set,tuple2,long,long,joined6,mapped,join,mapped,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined7,mapped,join,joined6,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined8,mapped,join,joined7,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined9,mapped,join,joined8,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined10,mapped,join,joined9,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,joined5,co,group,joined10,where,1,equal,to,1,with,new,dummy,co,group,function,tuple2,long,long,tuple2,long,long,output,new,discarding,output,format,tuple2,tuple2,long,long,tuple2,long,long,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingSourceMultipleTimes();1475688973;<pre>_SINK__COGROUP_+---/    \----+_/               \_/             MATCH10_/               |    \_/                |  MATCH9_MATCH5               |  |   \_|   \                |  | MATCH8_| MATCH4             |  |  |   \_|  |   \             |  |  | MATCH7_|  | MATCH3          |  |  |  |   \_|  |  |   \          |  |  |  | MATCH6_|  |  | MATCH2       |  |  |  |  |  |_|  |  |  |   \       +--+--+--+--+--+_|  |  |  | MATCH1            MAP_\  |  |  |  |  | /-----------/_(DATA SOURCE ONE)_</pre>;@Test_	public void testBranchingSourceMultipleTimes() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Tuple2<Long, Long>> source = env.generateSequence(1, 10000000)_				.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> joined1 = source.join(source).where(0).equalTo(0)_														.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined2 = source.join(joined1).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined3 = source.join(joined2).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined4 = source.join(joined3).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined5 = source.join(joined4).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> mapped = source.map(_					new MapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>() {_						@Override_						public Tuple2<Long, Long> map(Tuple2<Long, Long> value) {_							return null__						}_			})___			DataSet<Tuple2<Long, Long>> joined6 = mapped.join(mapped).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined7 = mapped.join(joined6).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined8 = mapped.join(joined7).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined9 = mapped.join(joined8).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined10 = mapped.join(joined9).where(0).equalTo(0)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())____			joined5.coGroup(joined10)_					.where(1).equalTo(1)_					.with(new DummyCoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>())__				.output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,sink,cogroup,match10,match9,match5,match8,match4,match7,match3,match6,match2,match1,map,data,source,one,pre;test,public,void,test,branching,source,multiple,times,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,joined1,source,join,source,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined2,source,join,joined1,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined3,source,join,joined2,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined4,source,join,joined3,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined5,source,join,joined4,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,mapped,source,map,new,map,function,tuple2,long,long,tuple2,long,long,override,public,tuple2,long,long,map,tuple2,long,long,value,return,null,data,set,tuple2,long,long,joined6,mapped,join,mapped,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined7,mapped,join,joined6,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined8,mapped,join,joined7,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined9,mapped,join,joined8,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined10,mapped,join,joined9,where,0,equal,to,0,with,new,dummy,flat,join,function,tuple2,long,long,joined5,co,group,joined10,where,1,equal,to,1,with,new,dummy,co,group,function,tuple2,long,long,tuple2,long,long,output,new,discarding,output,format,tuple2,tuple2,long,long,tuple2,long,long,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testIterationWithStaticInput();1426843274;<pre>_+---------Iteration-------+_|                         |_/--map--< >----\                   |_/         |      \         /-------< >---sink_src-map     |     join------/         |_\         |      /                  |_\        +-----/-------------------+_\            /_\--reduce--/_</pre>;@Test_	public void testIterationWithStaticInput() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setDegreeOfParallelism(100)___			DataSet<Long> source = env.generateSequence(1, 1000000)___			DataSet<Long> mapped = source.map(new IdentityMapper<Long>())___			DataSet<Long> reduced = source.groupBy(new IdentityKeyExtractor<Long>()).reduce(new SelectOneReducer<Long>())___			IterativeDataSet<Long> iteration = mapped.iterate(10)__			iteration.closeWith(_					iteration.join(reduced)_							.where(new IdentityKeyExtractor<Long>())_							.equalTo(new IdentityKeyExtractor<Long>())_							.with(new DummyFlatJoinFunction<Long>()))_					.output(new DiscardingOutputFormat<Long>())___			compileNoStats(env.createProgramPlan())__		}_		catch(Exception e){_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,iteration,map,sink,src,map,join,reduce,pre;test,public,void,test,iteration,with,static,input,try,execution,environment,env,execution,environment,get,execution,environment,env,set,degree,of,parallelism,100,data,set,long,source,env,generate,sequence,1,1000000,data,set,long,mapped,source,map,new,identity,mapper,long,data,set,long,reduced,source,group,by,new,identity,key,extractor,long,reduce,new,select,one,reducer,long,iterative,data,set,long,iteration,mapped,iterate,10,iteration,close,with,iteration,join,reduced,where,new,identity,key,extractor,long,equal,to,new,identity,key,extractor,long,with,new,dummy,flat,join,function,long,output,new,discarding,output,format,long,compile,no,stats,env,create,program,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testIterationWithStaticInput();1427097830;<pre>_+---------Iteration-------+_|                         |_/--map--< >----\                   |_/         |      \         /-------< >---sink_src-map     |     join------/         |_\         |      /                  |_\        +-----/-------------------+_\            /_\--reduce--/_</pre>;@Test_	public void testIterationWithStaticInput() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(100)___			DataSet<Long> source = env.generateSequence(1, 1000000)___			DataSet<Long> mapped = source.map(new IdentityMapper<Long>())___			DataSet<Long> reduced = source.groupBy(new IdentityKeyExtractor<Long>()).reduce(new SelectOneReducer<Long>())___			IterativeDataSet<Long> iteration = mapped.iterate(10)__			iteration.closeWith(_					iteration.join(reduced)_							.where(new IdentityKeyExtractor<Long>())_							.equalTo(new IdentityKeyExtractor<Long>())_							.with(new DummyFlatJoinFunction<Long>()))_					.output(new DiscardingOutputFormat<Long>())___			compileNoStats(env.createProgramPlan())__		}_		catch(Exception e){_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,iteration,map,sink,src,map,join,reduce,pre;test,public,void,test,iteration,with,static,input,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,100,data,set,long,source,env,generate,sequence,1,1000000,data,set,long,mapped,source,map,new,identity,mapper,long,data,set,long,reduced,source,group,by,new,identity,key,extractor,long,reduce,new,select,one,reducer,long,iterative,data,set,long,iteration,mapped,iterate,10,iteration,close,with,iteration,join,reduced,where,new,identity,key,extractor,long,equal,to,new,identity,key,extractor,long,with,new,dummy,flat,join,function,long,output,new,discarding,output,format,long,compile,no,stats,env,create,program,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testIterationWithStaticInput();1427784999;<pre>_+---------Iteration-------+_|                         |_/--map--< >----\                   |_/         |      \         /-------< >---sink_src-map     |     join------/         |_\         |      /                  |_\        +-----/-------------------+_\            /_\--reduce--/_</pre>;@Test_	public void testIterationWithStaticInput() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(100)___			DataSet<Long> source = env.generateSequence(1, 1000000)___			DataSet<Long> mapped = source.map(new IdentityMapper<Long>())___			DataSet<Long> reduced = source.groupBy(new IdentityKeyExtractor<Long>()).reduce(new SelectOneReducer<Long>())___			IterativeDataSet<Long> iteration = mapped.iterate(10)__			iteration.closeWith(_					iteration.join(reduced)_							.where(new IdentityKeyExtractor<Long>())_							.equalTo(new IdentityKeyExtractor<Long>())_							.with(new DummyFlatJoinFunction<Long>()))_					.output(new DiscardingOutputFormat<Long>())___			compileNoStats(env.createProgramPlan())__		}_		catch(Exception e){_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,iteration,map,sink,src,map,join,reduce,pre;test,public,void,test,iteration,with,static,input,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,100,data,set,long,source,env,generate,sequence,1,1000000,data,set,long,mapped,source,map,new,identity,mapper,long,data,set,long,reduced,source,group,by,new,identity,key,extractor,long,reduce,new,select,one,reducer,long,iterative,data,set,long,iteration,mapped,iterate,10,iteration,close,with,iteration,join,reduced,where,new,identity,key,extractor,long,equal,to,new,identity,key,extractor,long,with,new,dummy,flat,join,function,long,output,new,discarding,output,format,long,compile,no,stats,env,create,program,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testIterationWithStaticInput();1430859707;<pre>_+---------Iteration-------+_|                         |_/--map--< >----\                   |_/         |      \         /-------< >---sink_src-map     |     join------/         |_\         |      /                  |_\        +-----/-------------------+_\            /_\--reduce--/_</pre>;@Test_	public void testIterationWithStaticInput() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(100)___			DataSet<Long> source = env.generateSequence(1, 1000000)___			DataSet<Long> mapped = source.map(new IdentityMapper<Long>())___			DataSet<Long> reduced = source.groupBy(new IdentityKeyExtractor<Long>()).reduce(new SelectOneReducer<Long>())___			IterativeDataSet<Long> iteration = mapped.iterate(10)__			iteration.closeWith(_					iteration.join(reduced)_							.where(new IdentityKeyExtractor<Long>())_							.equalTo(new IdentityKeyExtractor<Long>())_							.with(new DummyFlatJoinFunction<Long>()))_					.output(new DiscardingOutputFormat<Long>())___			compileNoStats(env.createProgramPlan())__		}_		catch(Exception e){_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,iteration,map,sink,src,map,join,reduce,pre;test,public,void,test,iteration,with,static,input,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,100,data,set,long,source,env,generate,sequence,1,1000000,data,set,long,mapped,source,map,new,identity,mapper,long,data,set,long,reduced,source,group,by,new,identity,key,extractor,long,reduce,new,select,one,reducer,long,iterative,data,set,long,iteration,mapped,iterate,10,iteration,close,with,iteration,join,reduced,where,new,identity,key,extractor,long,equal,to,new,identity,key,extractor,long,with,new,dummy,flat,join,function,long,output,new,discarding,output,format,long,compile,no,stats,env,create,program,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testIterationWithStaticInput();1449526184;<pre>_+---------Iteration-------+_|                         |_/--map--< >----\                   |_/         |      \         /-------< >---sink_src-map     |     join------/         |_\         |      /                  |_\        +-----/-------------------+_\            /_\--reduce--/_</pre>;@Test_	public void testIterationWithStaticInput() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(100)___			DataSet<Long> source = env.generateSequence(1, 1000000)___			DataSet<Long> mapped = source.map(new IdentityMapper<Long>())___			DataSet<Long> reduced = source.groupBy(new IdentityKeyExtractor<Long>()).reduce(new SelectOneReducer<Long>())___			IterativeDataSet<Long> iteration = mapped.iterate(10)__			iteration.closeWith(_					iteration.join(reduced)_							.where(new IdentityKeyExtractor<Long>())_							.equalTo(new IdentityKeyExtractor<Long>())_							.with(new DummyFlatJoinFunction<Long>()))_					.output(new DiscardingOutputFormat<Long>())___			compileNoStats(env.createProgramPlan())__		}_		catch(Exception e){_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,iteration,map,sink,src,map,join,reduce,pre;test,public,void,test,iteration,with,static,input,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,100,data,set,long,source,env,generate,sequence,1,1000000,data,set,long,mapped,source,map,new,identity,mapper,long,data,set,long,reduced,source,group,by,new,identity,key,extractor,long,reduce,new,select,one,reducer,long,iterative,data,set,long,iteration,mapped,iterate,10,iteration,close,with,iteration,join,reduced,where,new,identity,key,extractor,long,equal,to,new,identity,key,extractor,long,with,new,dummy,flat,join,function,long,output,new,discarding,output,format,long,compile,no,stats,env,create,program,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testIterationWithStaticInput();1475688973;<pre>_+---------Iteration-------+_|                         |_/--map--< >----\                   |_/         |      \         /-------< >---sink_src-map     |     join------/         |_\         |      /                  |_\        +-----/-------------------+_\            /_\--reduce--/_</pre>;@Test_	public void testIterationWithStaticInput() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(100)___			DataSet<Long> source = env.generateSequence(1, 1000000)___			DataSet<Long> mapped = source.map(new IdentityMapper<Long>())___			DataSet<Long> reduced = source.groupBy(new IdentityKeyExtractor<Long>()).reduce(new SelectOneReducer<Long>())___			IterativeDataSet<Long> iteration = mapped.iterate(10)__			iteration.closeWith(_					iteration.join(reduced)_							.where(new IdentityKeyExtractor<Long>())_							.equalTo(new IdentityKeyExtractor<Long>())_							.with(new DummyFlatJoinFunction<Long>()))_					.output(new DiscardingOutputFormat<Long>())___			compileNoStats(env.createProgramPlan())__		}_		catch(Exception e){_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,iteration,map,sink,src,map,join,reduce,pre;test,public,void,test,iteration,with,static,input,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,100,data,set,long,source,env,generate,sequence,1,1000000,data,set,long,mapped,source,map,new,identity,mapper,long,data,set,long,reduced,source,group,by,new,identity,key,extractor,long,reduce,new,select,one,reducer,long,iterative,data,set,long,iteration,mapped,iterate,10,iteration,close,with,iteration,join,reduced,where,new,identity,key,extractor,long,equal,to,new,identity,key,extractor,long,with,new,dummy,flat,join,function,long,output,new,discarding,output,format,long,compile,no,stats,env,create,program,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testClosure();1426843274;Test to ensure that sourceA is inside as well as outside of the iteration the same_node.__<pre>_(SRC A)               (SRC B)_/       \             /       \_(SINK 1)   (ITERATION)    |     (SINK 2)_/        \     /_(SINK 3)     (CROSS => NEXT PARTIAL SOLUTION)_</pre>;@Test_	public void testClosure() {_		FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 1")__		FileDataSource sourceB = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 2")___		FileDataSink sink1 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceA, "Sink 1")__		FileDataSink sink2 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceB, "Sink 2")___		BulkIteration iteration = new BulkIteration("Loop")__		iteration.setInput(sourceA)__		iteration.setMaximumNumberOfIterations(10)___		CrossOperator stepFunction = CrossOperator.builder(DummyCrossStub.class).name("StepFunction")._				input1(iteration.getPartialSolution())._				input2(sourceB)._				build()___		iteration.setNextPartialSolution(stepFunction)___		FileDataSink sink3 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, iteration, "Sink 3")___		List<FileDataSink> sinks = new ArrayList<FileDataSink>()__		sinks.add(sink1)__		sinks.add(sink2)__		sinks.add(sink3)___		Plan plan = new Plan(sinks)___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};test,to,ensure,that,source,a,is,inside,as,well,as,outside,of,the,iteration,the,same,node,pre,src,a,src,b,sink,1,iteration,sink,2,sink,3,cross,next,partial,solution,pre;test,public,void,test,closure,file,data,source,source,a,new,file,data,source,dummy,input,format,class,source,1,file,data,source,source,b,new,file,data,source,dummy,input,format,class,source,2,file,data,sink,sink1,new,file,data,sink,dummy,output,format,class,source,a,sink,1,file,data,sink,sink2,new,file,data,sink,dummy,output,format,class,source,b,sink,2,bulk,iteration,iteration,new,bulk,iteration,loop,iteration,set,input,source,a,iteration,set,maximum,number,of,iterations,10,cross,operator,step,function,cross,operator,builder,dummy,cross,stub,class,name,step,function,input1,iteration,get,partial,solution,input2,source,b,build,iteration,set,next,partial,solution,step,function,file,data,sink,sink3,new,file,data,sink,dummy,output,format,class,iteration,sink,3,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink1,sinks,add,sink2,sinks,add,sink3,plan,plan,new,plan,sinks,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testClosure();1427097830;Test to ensure that sourceA is inside as well as outside of the iteration the same_node.__<pre>_(SRC A)               (SRC B)_/       \             /       \_(SINK 1)   (ITERATION)    |     (SINK 2)_/        \     /_(SINK 3)     (CROSS => NEXT PARTIAL SOLUTION)_</pre>;@Test_	public void testClosure() {_		FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 1")__		FileDataSource sourceB = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 2")___		FileDataSink sink1 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceA, "Sink 1")__		FileDataSink sink2 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceB, "Sink 2")___		BulkIteration iteration = new BulkIteration("Loop")__		iteration.setInput(sourceA)__		iteration.setMaximumNumberOfIterations(10)___		CrossOperator stepFunction = CrossOperator.builder(DummyCrossStub.class).name("StepFunction")._				input1(iteration.getPartialSolution())._				input2(sourceB)._				build()___		iteration.setNextPartialSolution(stepFunction)___		FileDataSink sink3 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, iteration, "Sink 3")___		List<FileDataSink> sinks = new ArrayList<FileDataSink>()__		sinks.add(sink1)__		sinks.add(sink2)__		sinks.add(sink3)___		Plan plan = new Plan(sinks)___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};test,to,ensure,that,source,a,is,inside,as,well,as,outside,of,the,iteration,the,same,node,pre,src,a,src,b,sink,1,iteration,sink,2,sink,3,cross,next,partial,solution,pre;test,public,void,test,closure,file,data,source,source,a,new,file,data,source,dummy,input,format,class,source,1,file,data,source,source,b,new,file,data,source,dummy,input,format,class,source,2,file,data,sink,sink1,new,file,data,sink,dummy,output,format,class,source,a,sink,1,file,data,sink,sink2,new,file,data,sink,dummy,output,format,class,source,b,sink,2,bulk,iteration,iteration,new,bulk,iteration,loop,iteration,set,input,source,a,iteration,set,maximum,number,of,iterations,10,cross,operator,step,function,cross,operator,builder,dummy,cross,stub,class,name,step,function,input1,iteration,get,partial,solution,input2,source,b,build,iteration,set,next,partial,solution,step,function,file,data,sink,sink3,new,file,data,sink,dummy,output,format,class,iteration,sink,3,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink1,sinks,add,sink2,sinks,add,sink3,plan,plan,new,plan,sinks,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testClosure();1427784999;Test to ensure that sourceA is inside as well as outside of the iteration the same_node.__<pre>_(SRC A)               (SRC B)_/       \             /       \_(SINK 1)   (ITERATION)    |     (SINK 2)_/        \     /_(SINK 3)     (CROSS => NEXT PARTIAL SOLUTION)_</pre>;@Test_	public void testClosure() {_		FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 1")__		FileDataSource sourceB = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 2")___		FileDataSink sink1 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceA, "Sink 1")__		FileDataSink sink2 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceB, "Sink 2")___		BulkIteration iteration = new BulkIteration("Loop")__		iteration.setInput(sourceA)__		iteration.setMaximumNumberOfIterations(10)___		CrossOperator stepFunction = CrossOperator.builder(DummyCrossStub.class).name("StepFunction")._				input1(iteration.getPartialSolution())._				input2(sourceB)._				build()___		iteration.setNextPartialSolution(stepFunction)___		FileDataSink sink3 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, iteration, "Sink 3")___		List<FileDataSink> sinks = new ArrayList<FileDataSink>()__		sinks.add(sink1)__		sinks.add(sink2)__		sinks.add(sink3)___		Plan plan = new Plan(sinks)___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};test,to,ensure,that,source,a,is,inside,as,well,as,outside,of,the,iteration,the,same,node,pre,src,a,src,b,sink,1,iteration,sink,2,sink,3,cross,next,partial,solution,pre;test,public,void,test,closure,file,data,source,source,a,new,file,data,source,dummy,input,format,class,source,1,file,data,source,source,b,new,file,data,source,dummy,input,format,class,source,2,file,data,sink,sink1,new,file,data,sink,dummy,output,format,class,source,a,sink,1,file,data,sink,sink2,new,file,data,sink,dummy,output,format,class,source,b,sink,2,bulk,iteration,iteration,new,bulk,iteration,loop,iteration,set,input,source,a,iteration,set,maximum,number,of,iterations,10,cross,operator,step,function,cross,operator,builder,dummy,cross,stub,class,name,step,function,input1,iteration,get,partial,solution,input2,source,b,build,iteration,set,next,partial,solution,step,function,file,data,sink,sink3,new,file,data,sink,dummy,output,format,class,iteration,sink,3,list,file,data,sink,sinks,new,array,list,file,data,sink,sinks,add,sink1,sinks,add,sink2,sinks,add,sink3,plan,plan,new,plan,sinks,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testClosure();1430859707;Test to ensure that sourceA is inside as well as outside of the iteration the same_node.__<pre>_(SRC A)               (SRC B)_/       \             /       \_(SINK 1)   (ITERATION)    |     (SINK 2)_/        \     /_(SINK 3)     (CROSS => NEXT PARTIAL SOLUTION)_</pre>;@Test_	public void testClosure() {_		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(DEFAULT_PARALLELISM)__		DataSet<Long> sourceA = env.generateSequence(0,1)__		DataSet<Long> sourceB = env.generateSequence(0,1)___		sourceA.output(new DiscardingOutputFormat<Long>())__		sourceB.output(new DiscardingOutputFormat<Long>())___		IterativeDataSet<Long> loopHead = sourceA.iterate(10).name("Loop")___		DataSet<Long> loopTail = loopHead.cross(sourceB).with(new IdentityCrosser<Long>())__		DataSet<Long> loopRes = loopHead.closeWith(loopTail)___		loopRes.output(new DiscardingOutputFormat<Long>())___		JavaPlan plan = env.createProgramPlan()___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};test,to,ensure,that,source,a,is,inside,as,well,as,outside,of,the,iteration,the,same,node,pre,src,a,src,b,sink,1,iteration,sink,2,sink,3,cross,next,partial,solution,pre;test,public,void,test,closure,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source,a,env,generate,sequence,0,1,data,set,long,source,b,env,generate,sequence,0,1,source,a,output,new,discarding,output,format,long,source,b,output,new,discarding,output,format,long,iterative,data,set,long,loop,head,source,a,iterate,10,name,loop,data,set,long,loop,tail,loop,head,cross,source,b,with,new,identity,crosser,long,data,set,long,loop,res,loop,head,close,with,loop,tail,loop,res,output,new,discarding,output,format,long,java,plan,plan,env,create,program,plan,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testClosure();1449526184;Test to ensure that sourceA is inside as well as outside of the iteration the same_node.__<pre>_(SRC A)               (SRC B)_/       \             /       \_(SINK 1)   (ITERATION)    |     (SINK 2)_/        \     /_(SINK 3)     (CROSS => NEXT PARTIAL SOLUTION)_</pre>;@Test_	public void testClosure() {_		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(DEFAULT_PARALLELISM)__		DataSet<Long> sourceA = env.generateSequence(0,1)__		DataSet<Long> sourceB = env.generateSequence(0,1)___		sourceA.output(new DiscardingOutputFormat<Long>())__		sourceB.output(new DiscardingOutputFormat<Long>())___		IterativeDataSet<Long> loopHead = sourceA.iterate(10).name("Loop")___		DataSet<Long> loopTail = loopHead.cross(sourceB).with(new IdentityCrosser<Long>())__		DataSet<Long> loopRes = loopHead.closeWith(loopTail)___		loopRes.output(new DiscardingOutputFormat<Long>())___		Plan plan = env.createProgramPlan()___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};test,to,ensure,that,source,a,is,inside,as,well,as,outside,of,the,iteration,the,same,node,pre,src,a,src,b,sink,1,iteration,sink,2,sink,3,cross,next,partial,solution,pre;test,public,void,test,closure,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source,a,env,generate,sequence,0,1,data,set,long,source,b,env,generate,sequence,0,1,source,a,output,new,discarding,output,format,long,source,b,output,new,discarding,output,format,long,iterative,data,set,long,loop,head,source,a,iterate,10,name,loop,data,set,long,loop,tail,loop,head,cross,source,b,with,new,identity,crosser,long,data,set,long,loop,res,loop,head,close,with,loop,tail,loop,res,output,new,discarding,output,format,long,plan,plan,env,create,program,plan,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testClosure();1475688973;Test to ensure that sourceA is inside as well as outside of the iteration the same_node.__<pre>_(SRC A)               (SRC B)_/       \             /       \_(SINK 1)   (ITERATION)    |     (SINK 2)_/        \     /_(SINK 3)     (CROSS => NEXT PARTIAL SOLUTION)_</pre>;@Test_	public void testClosure() {_		ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__		env.setParallelism(DEFAULT_PARALLELISM)__		DataSet<Long> sourceA = env.generateSequence(0,1)__		DataSet<Long> sourceB = env.generateSequence(0,1)___		sourceA.output(new DiscardingOutputFormat<Long>())__		sourceB.output(new DiscardingOutputFormat<Long>())___		IterativeDataSet<Long> loopHead = sourceA.iterate(10).name("Loop")___		DataSet<Long> loopTail = loopHead.cross(sourceB).with(new IdentityCrosser<Long>())__		DataSet<Long> loopRes = loopHead.closeWith(loopTail)___		loopRes.output(new DiscardingOutputFormat<Long>())___		Plan plan = env.createProgramPlan()___		try{_			compileNoStats(plan)__		}catch(Exception e){_			e.printStackTrace()__			Assert.fail(e.getMessage())__		}_	};test,to,ensure,that,source,a,is,inside,as,well,as,outside,of,the,iteration,the,same,node,pre,src,a,src,b,sink,1,iteration,sink,2,sink,3,cross,next,partial,solution,pre;test,public,void,test,closure,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,long,source,a,env,generate,sequence,0,1,data,set,long,source,b,env,generate,sequence,0,1,source,a,output,new,discarding,output,format,long,source,b,output,new,discarding,output,format,long,iterative,data,set,long,loop,head,source,a,iterate,10,name,loop,data,set,long,loop,tail,loop,head,cross,source,b,with,new,identity,crosser,long,data,set,long,loop,res,loop,head,close,with,loop,tail,loop,res,output,new,discarding,output,format,long,plan,plan,env,create,program,plan,try,compile,no,stats,plan,catch,exception,e,e,print,stack,trace,assert,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingWithMultipleDataSinks();1426843274;<pre>__(SINK A)_|    (SINK B)    (SINK C)_CROSS    /          /_/     \   |  +------+_/       \  | /_REDUCE      MATCH2_|    +---/    \_\  /          |_MAP          |_|           |_COGROUP      MATCH1_/     \     /     \_(SRC A)    (SRC B)    (SRC C)_</pre>;@Test_	public void testBranchingWithMultipleDataSinks() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setDegreeOfParallelism(DEFAULT_PARALLELISM)___			DataSet<Tuple2<Long, Long>> sourceA = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> sourceB = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> sourceC = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> mapped = sourceA.coGroup(sourceB)_					.where(0).equalTo(1)_					.with(new CoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>, Tuple2<Long, Long>>() {_							@Override_							public void coGroup(Iterable<Tuple2<Long, Long>> first,_													Iterable<Tuple2<Long, Long>> second,_													Collector<Tuple2<Long, Long>> out) {_							  }_					})_					.map(new IdentityMapper<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined = sourceB.join(sourceC)_					.where(0).equalTo(1)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined2 = mapped.join(joined)_					.where(1).equalTo(1)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> reduced = mapped_					.groupBy(1)_					.reduceGroup(new Top1GroupReducer<Tuple2<Long, Long>>())___			reduced.cross(joined2)_					.output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())___			joined2.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())__			joined2.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,sink,a,sink,b,sink,c,cross,reduce,match2,map,cogroup,match1,src,a,src,b,src,c,pre;test,public,void,test,branching,with,multiple,data,sinks,try,execution,environment,env,execution,environment,get,execution,environment,env,set,degree,of,parallelism,data,set,tuple2,long,long,source,a,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,source,b,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,source,c,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,mapped,source,a,co,group,source,b,where,0,equal,to,1,with,new,co,group,function,tuple2,long,long,tuple2,long,long,tuple2,long,long,override,public,void,co,group,iterable,tuple2,long,long,first,iterable,tuple2,long,long,second,collector,tuple2,long,long,out,map,new,identity,mapper,tuple2,long,long,data,set,tuple2,long,long,joined,source,b,join,source,c,where,0,equal,to,1,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined2,mapped,join,joined,where,1,equal,to,1,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,reduced,mapped,group,by,1,reduce,group,new,top1group,reducer,tuple2,long,long,reduced,cross,joined2,output,new,discarding,output,format,tuple2,tuple2,long,long,tuple2,long,long,joined2,output,new,discarding,output,format,tuple2,long,long,joined2,output,new,discarding,output,format,tuple2,long,long,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingWithMultipleDataSinks();1427097830;<pre>__(SINK A)_|    (SINK B)    (SINK C)_CROSS    /          /_/     \   |  +------+_/       \  | /_REDUCE      MATCH2_|    +---/    \_\  /          |_MAP          |_|           |_COGROUP      MATCH1_/     \     /     \_(SRC A)    (SRC B)    (SRC C)_</pre>;@Test_	public void testBranchingWithMultipleDataSinks() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Tuple2<Long, Long>> sourceA = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> sourceB = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> sourceC = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> mapped = sourceA.coGroup(sourceB)_					.where(0).equalTo(1)_					.with(new CoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>, Tuple2<Long, Long>>() {_							@Override_							public void coGroup(Iterable<Tuple2<Long, Long>> first,_													Iterable<Tuple2<Long, Long>> second,_													Collector<Tuple2<Long, Long>> out) {_							  }_					})_					.map(new IdentityMapper<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined = sourceB.join(sourceC)_					.where(0).equalTo(1)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined2 = mapped.join(joined)_					.where(1).equalTo(1)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> reduced = mapped_					.groupBy(1)_					.reduceGroup(new Top1GroupReducer<Tuple2<Long, Long>>())___			reduced.cross(joined2)_					.output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())___			joined2.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())__			joined2.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,sink,a,sink,b,sink,c,cross,reduce,match2,map,cogroup,match1,src,a,src,b,src,c,pre;test,public,void,test,branching,with,multiple,data,sinks,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,a,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,source,b,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,source,c,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,mapped,source,a,co,group,source,b,where,0,equal,to,1,with,new,co,group,function,tuple2,long,long,tuple2,long,long,tuple2,long,long,override,public,void,co,group,iterable,tuple2,long,long,first,iterable,tuple2,long,long,second,collector,tuple2,long,long,out,map,new,identity,mapper,tuple2,long,long,data,set,tuple2,long,long,joined,source,b,join,source,c,where,0,equal,to,1,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined2,mapped,join,joined,where,1,equal,to,1,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,reduced,mapped,group,by,1,reduce,group,new,top1group,reducer,tuple2,long,long,reduced,cross,joined2,output,new,discarding,output,format,tuple2,tuple2,long,long,tuple2,long,long,joined2,output,new,discarding,output,format,tuple2,long,long,joined2,output,new,discarding,output,format,tuple2,long,long,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingWithMultipleDataSinks();1427784999;<pre>__(SINK A)_|    (SINK B)    (SINK C)_CROSS    /          /_/     \   |  +------+_/       \  | /_REDUCE      MATCH2_|    +---/    \_\  /          |_MAP          |_|           |_COGROUP      MATCH1_/     \     /     \_(SRC A)    (SRC B)    (SRC C)_</pre>;@Test_	public void testBranchingWithMultipleDataSinks() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Tuple2<Long, Long>> sourceA = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> sourceB = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> sourceC = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> mapped = sourceA.coGroup(sourceB)_					.where(0).equalTo(1)_					.with(new CoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>, Tuple2<Long, Long>>() {_							@Override_							public void coGroup(Iterable<Tuple2<Long, Long>> first,_													Iterable<Tuple2<Long, Long>> second,_													Collector<Tuple2<Long, Long>> out) {_							  }_					})_					.map(new IdentityMapper<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined = sourceB.join(sourceC)_					.where(0).equalTo(1)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined2 = mapped.join(joined)_					.where(1).equalTo(1)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> reduced = mapped_					.groupBy(1)_					.reduceGroup(new Top1GroupReducer<Tuple2<Long, Long>>())___			reduced.cross(joined2)_					.output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())___			joined2.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())__			joined2.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,sink,a,sink,b,sink,c,cross,reduce,match2,map,cogroup,match1,src,a,src,b,src,c,pre;test,public,void,test,branching,with,multiple,data,sinks,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,a,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,source,b,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,source,c,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,mapped,source,a,co,group,source,b,where,0,equal,to,1,with,new,co,group,function,tuple2,long,long,tuple2,long,long,tuple2,long,long,override,public,void,co,group,iterable,tuple2,long,long,first,iterable,tuple2,long,long,second,collector,tuple2,long,long,out,map,new,identity,mapper,tuple2,long,long,data,set,tuple2,long,long,joined,source,b,join,source,c,where,0,equal,to,1,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined2,mapped,join,joined,where,1,equal,to,1,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,reduced,mapped,group,by,1,reduce,group,new,top1group,reducer,tuple2,long,long,reduced,cross,joined2,output,new,discarding,output,format,tuple2,tuple2,long,long,tuple2,long,long,joined2,output,new,discarding,output,format,tuple2,long,long,joined2,output,new,discarding,output,format,tuple2,long,long,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingWithMultipleDataSinks();1430859707;<pre>__(SINK A)_|    (SINK B)    (SINK C)_CROSS    /          /_/     \   |  +------+_/       \  | /_REDUCE      MATCH2_|    +---/    \_\  /          |_MAP          |_|           |_COGROUP      MATCH1_/     \     /     \_(SRC A)    (SRC B)    (SRC C)_</pre>;@Test_	public void testBranchingWithMultipleDataSinks() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Tuple2<Long, Long>> sourceA = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> sourceB = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> sourceC = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> mapped = sourceA.coGroup(sourceB)_					.where(0).equalTo(1)_					.with(new CoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>, Tuple2<Long, Long>>() {_							@Override_							public void coGroup(Iterable<Tuple2<Long, Long>> first,_													Iterable<Tuple2<Long, Long>> second,_													Collector<Tuple2<Long, Long>> out) {_							  }_					})_					.map(new IdentityMapper<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined = sourceB.join(sourceC)_					.where(0).equalTo(1)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined2 = mapped.join(joined)_					.where(1).equalTo(1)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> reduced = mapped_					.groupBy(1)_					.reduceGroup(new Top1GroupReducer<Tuple2<Long, Long>>())___			reduced.cross(joined2)_					.output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())___			joined2.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())__			joined2.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,sink,a,sink,b,sink,c,cross,reduce,match2,map,cogroup,match1,src,a,src,b,src,c,pre;test,public,void,test,branching,with,multiple,data,sinks,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,a,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,source,b,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,source,c,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,mapped,source,a,co,group,source,b,where,0,equal,to,1,with,new,co,group,function,tuple2,long,long,tuple2,long,long,tuple2,long,long,override,public,void,co,group,iterable,tuple2,long,long,first,iterable,tuple2,long,long,second,collector,tuple2,long,long,out,map,new,identity,mapper,tuple2,long,long,data,set,tuple2,long,long,joined,source,b,join,source,c,where,0,equal,to,1,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined2,mapped,join,joined,where,1,equal,to,1,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,reduced,mapped,group,by,1,reduce,group,new,top1group,reducer,tuple2,long,long,reduced,cross,joined2,output,new,discarding,output,format,tuple2,tuple2,long,long,tuple2,long,long,joined2,output,new,discarding,output,format,tuple2,long,long,joined2,output,new,discarding,output,format,tuple2,long,long,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingWithMultipleDataSinks();1449526184;<pre>__(SINK A)_|    (SINK B)    (SINK C)_CROSS    /          /_/     \   |  +------+_/       \  | /_REDUCE      MATCH2_|    +---/    \_\  /          |_MAP          |_|           |_COGROUP      MATCH1_/     \     /     \_(SRC A)    (SRC B)    (SRC C)_</pre>;@Test_	public void testBranchingWithMultipleDataSinks() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Tuple2<Long, Long>> sourceA = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> sourceB = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> sourceC = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> mapped = sourceA.coGroup(sourceB)_					.where(0).equalTo(1)_					.with(new CoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>, Tuple2<Long, Long>>() {_							@Override_							public void coGroup(Iterable<Tuple2<Long, Long>> first,_													Iterable<Tuple2<Long, Long>> second,_													Collector<Tuple2<Long, Long>> out) {_							  }_					})_					.map(new IdentityMapper<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined = sourceB.join(sourceC)_					.where(0).equalTo(1)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined2 = mapped.join(joined)_					.where(1).equalTo(1)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> reduced = mapped_					.groupBy(1)_					.reduceGroup(new Top1GroupReducer<Tuple2<Long, Long>>())___			reduced.cross(joined2)_					.output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())___			joined2.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())__			joined2.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,sink,a,sink,b,sink,c,cross,reduce,match2,map,cogroup,match1,src,a,src,b,src,c,pre;test,public,void,test,branching,with,multiple,data,sinks,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,a,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,source,b,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,source,c,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,mapped,source,a,co,group,source,b,where,0,equal,to,1,with,new,co,group,function,tuple2,long,long,tuple2,long,long,tuple2,long,long,override,public,void,co,group,iterable,tuple2,long,long,first,iterable,tuple2,long,long,second,collector,tuple2,long,long,out,map,new,identity,mapper,tuple2,long,long,data,set,tuple2,long,long,joined,source,b,join,source,c,where,0,equal,to,1,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined2,mapped,join,joined,where,1,equal,to,1,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,reduced,mapped,group,by,1,reduce,group,new,top1group,reducer,tuple2,long,long,reduced,cross,joined2,output,new,discarding,output,format,tuple2,tuple2,long,long,tuple2,long,long,joined2,output,new,discarding,output,format,tuple2,long,long,joined2,output,new,discarding,output,format,tuple2,long,long,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
BranchingPlansCompilerTest -> @Test 	public void testBranchingWithMultipleDataSinks();1475688973;<pre>__(SINK A)_|    (SINK B)    (SINK C)_CROSS    /          /_/     \   |  +------+_/       \  | /_REDUCE      MATCH2_|    +---/    \_\  /          |_MAP          |_|           |_COGROUP      MATCH1_/     \     /     \_(SRC A)    (SRC B)    (SRC C)_</pre>;@Test_	public void testBranchingWithMultipleDataSinks() {_		try {_			ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment()__			env.setParallelism(DEFAULT_PARALLELISM)___			DataSet<Tuple2<Long, Long>> sourceA = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> sourceB = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> sourceC = env.generateSequence(1, 10000000)_					.map(new Duplicator<Long>())___			DataSet<Tuple2<Long, Long>> mapped = sourceA.coGroup(sourceB)_					.where(0).equalTo(1)_					.with(new CoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>, Tuple2<Long, Long>>() {_							@Override_							public void coGroup(Iterable<Tuple2<Long, Long>> first,_													Iterable<Tuple2<Long, Long>> second,_													Collector<Tuple2<Long, Long>> out) {_							  }_					})_					.map(new IdentityMapper<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined = sourceB.join(sourceC)_					.where(0).equalTo(1)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> joined2 = mapped.join(joined)_					.where(1).equalTo(1)_					.with(new DummyFlatJoinFunction<Tuple2<Long, Long>>())___			DataSet<Tuple2<Long, Long>> reduced = mapped_					.groupBy(1)_					.reduceGroup(new Top1GroupReducer<Tuple2<Long, Long>>())___			reduced.cross(joined2)_					.output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())___			joined2.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())__			joined2.output(new DiscardingOutputFormat<Tuple2<Long, Long>>())___			Plan plan = env.createProgramPlan()__			OptimizedPlan oPlan = compileNoStats(plan)__			new JobGraphGenerator().compileJobGraph(oPlan)__		}_		catch (Exception e) {_			e.printStackTrace()__			fail(e.getMessage())__		}_	};pre,sink,a,sink,b,sink,c,cross,reduce,match2,map,cogroup,match1,src,a,src,b,src,c,pre;test,public,void,test,branching,with,multiple,data,sinks,try,execution,environment,env,execution,environment,get,execution,environment,env,set,parallelism,data,set,tuple2,long,long,source,a,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,source,b,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,source,c,env,generate,sequence,1,10000000,map,new,duplicator,long,data,set,tuple2,long,long,mapped,source,a,co,group,source,b,where,0,equal,to,1,with,new,co,group,function,tuple2,long,long,tuple2,long,long,tuple2,long,long,override,public,void,co,group,iterable,tuple2,long,long,first,iterable,tuple2,long,long,second,collector,tuple2,long,long,out,map,new,identity,mapper,tuple2,long,long,data,set,tuple2,long,long,joined,source,b,join,source,c,where,0,equal,to,1,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,joined2,mapped,join,joined,where,1,equal,to,1,with,new,dummy,flat,join,function,tuple2,long,long,data,set,tuple2,long,long,reduced,mapped,group,by,1,reduce,group,new,top1group,reducer,tuple2,long,long,reduced,cross,joined2,output,new,discarding,output,format,tuple2,tuple2,long,long,tuple2,long,long,joined2,output,new,discarding,output,format,tuple2,long,long,joined2,output,new,discarding,output,format,tuple2,long,long,plan,plan,env,create,program,plan,optimized,plan,o,plan,compile,no,stats,plan,new,job,graph,generator,compile,job,graph,o,plan,catch,exception,e,e,print,stack,trace,fail,e,get,message
