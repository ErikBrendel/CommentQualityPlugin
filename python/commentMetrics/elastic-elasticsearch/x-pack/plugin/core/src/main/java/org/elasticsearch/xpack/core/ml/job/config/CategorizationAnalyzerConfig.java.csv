commented;modifiers;parameterAmount;loc;comment;code
true;public,static;2;15;/**  * This method is only used in the unit tests - in production code this config is always parsed as a fragment.  */ ;/**  * This method is only used in the unit tests - in production code this config is always parsed as a fragment.  */ public static CategorizationAnalyzerConfig buildFromXContentObject(XContentParser parser, boolean ignoreUnknownFields) throws IOException {     if (parser.nextToken() != XContentParser.Token.START_OBJECT) {         throw new IllegalArgumentException("Expected start object but got [" + parser.currentToken() + "]").     }     if (parser.nextToken() != XContentParser.Token.FIELD_NAME || CATEGORIZATION_ANALYZER.match(parser.currentName(), parser.getDeprecationHandler()) == false) {         throw new IllegalArgumentException("Expected [" + CATEGORIZATION_ANALYZER + "] field but got [" + parser.currentToken() + "]").     }     parser.nextToken().     CategorizationAnalyzerConfig categorizationAnalyzerConfig = buildFromXContentFragment(parser, ignoreUnknownFields).     parser.nextToken().     return categorizationAnalyzerConfig. }
true;static;2;57;/**  * Parse a <code>categorization_analyzer</code> from configuration or cluster state.  A custom parser is needed  * due to the complexity of the format, with many elements able to be specified as either the name of a built-in  * element or an object containing a custom definition.  *  * The parser is strict when parsing config and lenient when parsing cluster state.  */ ;/**  * Parse a <code>categorization_analyzer</code> from configuration or cluster state.  A custom parser is needed  * due to the complexity of the format, with many elements able to be specified as either the name of a built-in  * element or an object containing a custom definition.  *  * The parser is strict when parsing config and lenient when parsing cluster state.  */ static CategorizationAnalyzerConfig buildFromXContentFragment(XContentParser parser, boolean ignoreUnknownFields) throws IOException {     CategorizationAnalyzerConfig.Builder builder = new CategorizationAnalyzerConfig.Builder().     XContentParser.Token token = parser.currentToken().     if (token == XContentParser.Token.VALUE_STRING) {         builder.setAnalyzer(parser.text()).     } else if (token != XContentParser.Token.START_OBJECT) {         throw new IllegalArgumentException("[" + CATEGORIZATION_ANALYZER + "] should be analyzer's name or settings [" + token + "]").     } else {         String currentFieldName = null.         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {             if (token == XContentParser.Token.FIELD_NAME) {                 currentFieldName = parser.currentName().             } else if (CHAR_FILTERS.match(currentFieldName, parser.getDeprecationHandler()) && token == XContentParser.Token.START_ARRAY) {                 while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {                     if (token == XContentParser.Token.VALUE_STRING) {                         builder.addCharFilter(parser.text()).                     } else if (token == XContentParser.Token.START_OBJECT) {                         builder.addCharFilter(parser.map()).                     } else {                         throw new IllegalArgumentException("[" + currentFieldName + "] in [" + CATEGORIZATION_ANALYZER + "] array element should contain char_filter's name or settings [" + token + "]").                     }                 }             } else if (TOKENIZER.match(currentFieldName, parser.getDeprecationHandler())) {                 if (token == XContentParser.Token.VALUE_STRING) {                     builder.setTokenizer(parser.text()).                 } else if (token == XContentParser.Token.START_OBJECT) {                     builder.setTokenizer(parser.map()).                 } else {                     throw new IllegalArgumentException("[" + currentFieldName + "] in [" + CATEGORIZATION_ANALYZER + "] should be tokenizer's name or settings [" + token + "]").                 }             } else if (TOKEN_FILTERS.match(currentFieldName, parser.getDeprecationHandler()) && token == XContentParser.Token.START_ARRAY) {                 while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {                     if (token == XContentParser.Token.VALUE_STRING) {                         builder.addTokenFilter(parser.text()).                     } else if (token == XContentParser.Token.START_OBJECT) {                         builder.addTokenFilter(parser.map()).                     } else {                         throw new IllegalArgumentException("[" + currentFieldName + "] in [" + CATEGORIZATION_ANALYZER + "] array element should contain token_filter's name or settings [" + token + "]").                     }                 }             // Be lenient when parsing cluster state - assume unknown fields are from future versions             } else if (ignoreUnknownFields == false) {                 throw new IllegalArgumentException("Parameter [" + currentFieldName + "] in [" + CATEGORIZATION_ANALYZER + "] is unknown or of the wrong type [" + token + "]").             }         }     }     return builder.build(). }
true;public,static;1;27;/**  * Create a <code>categorization_analyzer</code> that mimics what the tokenizer and filters built into the ML C++  * code do.  This is the default analyzer for categorization to ensure that people upgrading from previous versions  * get the same behaviour from their categorization jobs before and after upgrade.  * @param categorizationFilters Categorization filters (if any) from the <code>analysis_config</code>.  * @return The default categorization analyzer.  */ ;/**  * Create a <code>categorization_analyzer</code> that mimics what the tokenizer and filters built into the ML C++  * code do.  This is the default analyzer for categorization to ensure that people upgrading from previous versions  * get the same behaviour from their categorization jobs before and after upgrade.  * @param categorizationFilters Categorization filters (if any) from the <code>analysis_config</code>.  * @return The default categorization analyzer.  */ public static CategorizationAnalyzerConfig buildDefaultCategorizationAnalyzer(List<String> categorizationFilters) {     CategorizationAnalyzerConfig.Builder builder = new CategorizationAnalyzerConfig.Builder().     if (categorizationFilters != null) {         for (String categorizationFilter : categorizationFilters) {             Map<String, Object> charFilter = new HashMap<>().             charFilter.put("type", "pattern_replace").             charFilter.put("pattern", categorizationFilter).             builder.addCharFilter(charFilter).         }     }     builder.setTokenizer("ml_classic").     Map<String, Object> tokenFilter = new HashMap<>().     tokenFilter.put("type", "stop").     tokenFilter.put("stopwords", Arrays.asList("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun", "January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December", "Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec", "GMT", "UTC")).     builder.addTokenFilter(tokenFilter).     return builder.build(). }
false;public;1;9;;@Override public void writeTo(StreamOutput out) throws IOException {     out.writeOptionalString(name).     boolean isNotNullDefinition = this.definition != null.     out.writeBoolean(isNotNullDefinition).     if (isNotNullDefinition) {         Settings.writeSettingsToStream(definition, out).     } }
false;public;2;11;;@Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {     if (definition == null) {         builder.value(name).     } else {         builder.startObject().         definition.toXContent(builder, params).         builder.endObject().     }     return builder. }
false;public;1;8;;@Override public boolean equals(Object o) {     if (this == o)         return true.     if (o == null || getClass() != o.getClass())         return false.     NameOrDefinition that = (NameOrDefinition) o.     return Objects.equals(name, that.name) && Objects.equals(definition, that.definition). }
false;public;0;4;;@Override public int hashCode() {     return Objects.hash(name, definition). }
false;public;0;8;;@Override public String toString() {     if (definition == null) {         return name.     } else {         return definition.toDelimitedString('.').     } }
false;public;1;7;;@Override public void writeTo(StreamOutput out) throws IOException {     out.writeOptionalString(analyzer).     out.writeList(charFilters).     out.writeOptionalWriteable(tokenizer).     out.writeList(tokenFilters). }
false;public;0;3;;public String getAnalyzer() {     return analyzer. }
false;public;0;3;;public List<NameOrDefinition> getCharFilters() {     return charFilters. }
false;public;0;3;;public NameOrDefinition getTokenizer() {     return tokenizer. }
false;public;0;3;;public List<NameOrDefinition> getTokenFilters() {     return tokenFilters. }
false;public;2;27;;@Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {     if (analyzer != null) {         builder.field(CATEGORIZATION_ANALYZER.getPreferredName(), analyzer).     } else {         builder.startObject(CATEGORIZATION_ANALYZER.getPreferredName()).         if (charFilters.isEmpty() == false) {             builder.startArray(CHAR_FILTERS.getPreferredName()).             for (NameOrDefinition charFilter : charFilters) {                 charFilter.toXContent(builder, params).             }             builder.endArray().         }         if (tokenizer != null) {             builder.field(TOKENIZER.getPreferredName(), tokenizer).         }         if (tokenFilters.isEmpty() == false) {             builder.startArray(TOKEN_FILTERS.getPreferredName()).             for (NameOrDefinition tokenFilter : tokenFilters) {                 tokenFilter.toXContent(builder, params).             }             builder.endArray().         }         builder.endObject().     }     return builder. }
false;public;1;10;;@Override public boolean equals(Object o) {     if (this == o)         return true.     if (o == null || getClass() != o.getClass())         return false.     CategorizationAnalyzerConfig that = (CategorizationAnalyzerConfig) o.     return Objects.equals(analyzer, that.analyzer) && Objects.equals(charFilters, that.charFilters) && Objects.equals(tokenizer, that.tokenizer) && Objects.equals(tokenFilters, that.tokenFilters). }
false;public;0;4;;@Override public int hashCode() {     return Objects.hash(analyzer, charFilters, tokenizer, tokenFilters). }
false;public;1;4;;public Builder setAnalyzer(String analyzer) {     this.analyzer = analyzer.     return this. }
false;public;1;4;;public Builder addCharFilter(String charFilter) {     this.charFilters.add(new NameOrDefinition(charFilter)).     return this. }
false;public;1;4;;public Builder addCharFilter(Map<String, Object> charFilter) {     this.charFilters.add(new NameOrDefinition(CHAR_FILTERS, charFilter)).     return this. }
false;public;1;4;;public Builder setTokenizer(String tokenizer) {     this.tokenizer = new NameOrDefinition(tokenizer).     return this. }
false;public;1;4;;public Builder setTokenizer(Map<String, Object> tokenizer) {     this.tokenizer = new NameOrDefinition(TOKENIZER, tokenizer).     return this. }
false;public;1;4;;public Builder addTokenFilter(String tokenFilter) {     this.tokenFilters.add(new NameOrDefinition(tokenFilter)).     return this. }
false;public;1;4;;public Builder addTokenFilter(Map<String, Object> tokenFilter) {     this.tokenFilters.add(new NameOrDefinition(TOKEN_FILTERS, tokenFilter)).     return this. }
true;public;0;19;/**  * Create a config validating only structure, not exact analyzer/tokenizer/filter names  */ ;/**  * Create a config validating only structure, not exact analyzer/tokenizer/filter names  */ public CategorizationAnalyzerConfig build() {     if (analyzer == null && tokenizer == null) {         throw new IllegalArgumentException(CATEGORIZATION_ANALYZER + " that is not a global analyzer must specify a [" + TOKENIZER + "] field").     }     if (analyzer != null && charFilters.isEmpty() == false) {         throw new IllegalArgumentException(CATEGORIZATION_ANALYZER + " that is a global analyzer cannot also specify a [" + CHAR_FILTERS + "] field").     }     if (analyzer != null && tokenizer != null) {         throw new IllegalArgumentException(CATEGORIZATION_ANALYZER + " that is a global analyzer cannot also specify a [" + TOKENIZER + "] field").     }     if (analyzer != null && tokenFilters.isEmpty() == false) {         throw new IllegalArgumentException(CATEGORIZATION_ANALYZER + " that is a global analyzer cannot also specify a [" + TOKEN_FILTERS + "] field").     }     return new CategorizationAnalyzerConfig(analyzer, charFilters, tokenizer, tokenFilters). }
