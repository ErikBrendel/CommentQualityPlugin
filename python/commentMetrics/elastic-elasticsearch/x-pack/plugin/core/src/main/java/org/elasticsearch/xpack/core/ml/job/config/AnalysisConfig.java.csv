commented;modifiers;parameterAmount;loc;comment;code
false;private,static;1;24;;@SuppressWarnings("unchecked") private static ConstructingObjectParser<AnalysisConfig.Builder, Void> createParser(boolean ignoreUnknownFields) {     ConstructingObjectParser<AnalysisConfig.Builder, Void> parser = new ConstructingObjectParser<>(ANALYSIS_CONFIG.getPreferredName(), ignoreUnknownFields, a -> new AnalysisConfig.Builder((List<Detector>) a[0])).     parser.declareObjectArray(ConstructingObjectParser.constructorArg(), (p, c) -> (ignoreUnknownFields ? Detector.LENIENT_PARSER : Detector.STRICT_PARSER).apply(p, c).build(), DETECTORS).     parser.declareString((builder, val) -> builder.setBucketSpan(TimeValue.parseTimeValue(val, BUCKET_SPAN.getPreferredName())), BUCKET_SPAN).     parser.declareString(Builder::setCategorizationFieldName, CATEGORIZATION_FIELD_NAME).     parser.declareStringArray(Builder::setCategorizationFilters, CATEGORIZATION_FILTERS).     // This one is nasty - the syntax for analyzers takes either names or objects at many levels, hence it's not     // possible to simply declare whether the field is a string or object and a completely custom parser is required     parser.declareField(Builder::setCategorizationAnalyzerConfig, (p, c) -> CategorizationAnalyzerConfig.buildFromXContentFragment(p, ignoreUnknownFields), CATEGORIZATION_ANALYZER, ObjectParser.ValueType.OBJECT_OR_STRING).     parser.declareString((builder, val) -> builder.setLatency(TimeValue.parseTimeValue(val, LATENCY.getPreferredName())), LATENCY).     parser.declareString(Builder::setSummaryCountFieldName, SUMMARY_COUNT_FIELD_NAME).     parser.declareStringArray(Builder::setInfluencers, INFLUENCERS).     parser.declareBoolean(Builder::setMultivariateByFields, MULTIVARIATE_BY_FIELDS).     return parser. }
false;public;1;20;;@Override public void writeTo(StreamOutput out) throws IOException {     out.writeTimeValue(bucketSpan).     out.writeOptionalString(categorizationFieldName).     if (categorizationFilters != null) {         out.writeBoolean(true).         out.writeStringCollection(categorizationFilters).     } else {         out.writeBoolean(false).     }     if (out.getVersion().onOrAfter(Version.V_6_2_0)) {         out.writeOptionalWriteable(categorizationAnalyzerConfig).     }     out.writeOptionalTimeValue(latency).     out.writeOptionalString(summaryCountFieldName).     out.writeList(detectors).     out.writeStringCollection(influencers).     out.writeOptionalBoolean(multivariateByFields). }
true;public;0;3;/**  * The analysis bucket span  *  * @return The bucketspan or <code>null</code> if not set  */ ;/**  * The analysis bucket span  *  * @return The bucketspan or <code>null</code> if not set  */ public TimeValue getBucketSpan() {     return bucketSpan. }
false;public;0;3;;public String getCategorizationFieldName() {     return categorizationFieldName. }
false;public;0;3;;public List<String> getCategorizationFilters() {     return categorizationFilters. }
false;public;0;3;;public CategorizationAnalyzerConfig getCategorizationAnalyzerConfig() {     return categorizationAnalyzerConfig. }
true;public;0;3;/**  * The latency interval during which out-of-order records should be handled.  *  * @return The latency interval or <code>null</code> if not set  */ ;/**  * The latency interval during which out-of-order records should be handled.  *  * @return The latency interval or <code>null</code> if not set  */ public TimeValue getLatency() {     return latency. }
true;public;0;3;/**  * The name of the field that contains counts for pre-summarised input  *  * @return The field name or <code>null</code> if not set  */ ;/**  * The name of the field that contains counts for pre-summarised input  *  * @return The field name or <code>null</code> if not set  */ public String getSummaryCountFieldName() {     return summaryCountFieldName. }
true;public;0;3;/**  * The list of analysis detectors. In a valid configuration the list should  * contain at least 1 {@link Detector}  *  * @return The Detectors used in this job  */ ;/**  * The list of analysis detectors. In a valid configuration the list should  * contain at least 1 {@link Detector}  *  * @return The Detectors used in this job  */ public List<Detector> getDetectors() {     return detectors. }
true;public;0;3;/**  * The list of influence field names  */ ;/**  * The list of influence field names  */ public List<String> getInfluencers() {     return influencers. }
true;public;0;3;/**  * Return the list of term fields.  * These are the influencer fields, partition field,  * by field and over field of each detector.  * <code>null</code> and empty strings are filtered from the  * config.  *  * @return Set of term fields - never <code>null</code>  */ ;/**  * Return the list of term fields.  * These are the influencer fields, partition field,  * by field and over field of each detector.  * <code>null</code> and empty strings are filtered from the  * config.  *  * @return Set of term fields - never <code>null</code>  */ public Set<String> termFields() {     return termFields(getDetectors(), getInfluencers()). }
false;static;2;14;;static SortedSet<String> termFields(List<Detector> detectors, List<String> influencers) {     SortedSet<String> termFields = new TreeSet<>().     detectors.forEach(d -> termFields.addAll(d.getByOverPartitionTerms())).     for (String i : influencers) {         addIfNotNull(termFields, i).     }     // remove empty strings     termFields.remove("").     return termFields. }
false;public;0;4;;public Set<String> extractReferencedFilters() {     return detectors.stream().map(Detector::extractReferencedFilters).flatMap(Set::stream).collect(Collectors.toSet()). }
false;public;0;3;;public Boolean getMultivariateByFields() {     return multivariateByFields. }
true;public;0;15;/**  * Return the set of fields required by the analysis.  * These are the influencer fields, metric field, partition field,  * by field and over field of each detector, plus the summary count  * field and the categorization field name of the job.  * <code>null</code> and empty strings are filtered from the  * config.  *  * @return Set of required analysis fields - never <code>null</code>  */ ;/**  * Return the set of fields required by the analysis.  * These are the influencer fields, metric field, partition field,  * by field and over field of each detector, plus the summary count  * field and the categorization field name of the job.  * <code>null</code> and empty strings are filtered from the  * config.  *  * @return Set of required analysis fields - never <code>null</code>  */ public Set<String> analysisFields() {     Set<String> analysisFields = termFields().     addIfNotNull(analysisFields, categorizationFieldName).     addIfNotNull(analysisFields, summaryCountFieldName).     for (Detector d : getDetectors()) {         addIfNotNull(analysisFields, d.getFieldName()).     }     // remove empty strings     analysisFields.remove("").     return analysisFields. }
false;private,static;2;5;;private static void addIfNotNull(Set<String> fields, String field) {     if (field != null) {         fields.add(field).     } }
false;public;0;3;;public List<String> fields() {     return collectNonNullAndNonEmptyDetectorFields(Detector::getFieldName). }
false;private;1;13;;private List<String> collectNonNullAndNonEmptyDetectorFields(Function<Detector, String> fieldGetter) {     Set<String> fields = new HashSet<>().     for (Detector d : getDetectors()) {         addIfNotNull(fields, fieldGetter.apply(d)).     }     // remove empty strings     fields.remove("").     return new ArrayList<>(fields). }
false;public;0;3;;public List<String> byFields() {     return collectNonNullAndNonEmptyDetectorFields(Detector::getByFieldName). }
false;public;0;3;;public List<String> overFields() {     return collectNonNullAndNonEmptyDetectorFields(Detector::getOverFieldName). }
false;public;0;3;;public List<String> partitionFields() {     return collectNonNullAndNonEmptyDetectorFields(Detector::getPartitionFieldName). }
false;public;2;34;;@Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {     builder.startObject().     builder.field(BUCKET_SPAN.getPreferredName(), bucketSpan.getStringRep()).     if (categorizationFieldName != null) {         builder.field(CATEGORIZATION_FIELD_NAME.getPreferredName(), categorizationFieldName).     }     if (categorizationFilters != null) {         builder.field(CATEGORIZATION_FILTERS.getPreferredName(), categorizationFilters).     }     if (categorizationAnalyzerConfig != null) {         // This cannot be builder.field(CATEGORIZATION_ANALYZER.getPreferredName(), categorizationAnalyzerConfig, params).         // because that always writes categorizationAnalyzerConfig as an object, and in the case of a global analyzer it         // gets written as a single string.         categorizationAnalyzerConfig.toXContent(builder, params).     }     if (latency != null) {         builder.field(LATENCY.getPreferredName(), latency.getStringRep()).     }     if (summaryCountFieldName != null) {         builder.field(SUMMARY_COUNT_FIELD_NAME.getPreferredName(), summaryCountFieldName).     }     builder.startArray(DETECTORS.getPreferredName()).     for (Detector detector : detectors) {         detector.toXContent(builder, params).     }     builder.endArray().     builder.field(INFLUENCERS.getPreferredName(), influencers).     if (multivariateByFields != null) {         builder.field(MULTIVARIATE_BY_FIELDS.getPreferredName(), multivariateByFields).     }     builder.endObject().     return builder. }
false;public;1;15;;@Override public boolean equals(Object o) {     if (this == o)         return true.     if (o == null || getClass() != o.getClass())         return false.     AnalysisConfig that = (AnalysisConfig) o.     return Objects.equals(latency, that.latency) && Objects.equals(bucketSpan, that.bucketSpan) && Objects.equals(categorizationFieldName, that.categorizationFieldName) && Objects.equals(categorizationFilters, that.categorizationFilters) && Objects.equals(categorizationAnalyzerConfig, that.categorizationAnalyzerConfig) && Objects.equals(summaryCountFieldName, that.summaryCountFieldName) && Objects.equals(detectors, that.detectors) && Objects.equals(influencers, that.influencers) && Objects.equals(multivariateByFields, that.multivariateByFields). }
false;public;0;6;;@Override public int hashCode() {     return Objects.hash(bucketSpan, categorizationFieldName, categorizationFilters, categorizationAnalyzerConfig, latency, summaryCountFieldName, detectors, influencers, multivariateByFields). }
false;public;1;15;;public void setDetectors(List<Detector> detectors) {     if (detectors == null) {         this.detectors = null.         return.     }     // We always assign sequential IDs to the detectors that are correct for this analysis config     int detectorIndex = 0.     List<Detector> sequentialIndexDetectors = new ArrayList<>(detectors.size()).     for (Detector origDetector : detectors) {         Detector.Builder builder = new Detector.Builder(origDetector).         builder.setDetectorIndex(detectorIndex++).         sequentialIndexDetectors.add(builder.build()).     }     this.detectors = sequentialIndexDetectors. }
false;public;2;3;;public void setDetector(int detectorIndex, Detector detector) {     detectors.set(detectorIndex, detector). }
false;public;1;3;;public void setBucketSpan(TimeValue bucketSpan) {     this.bucketSpan = bucketSpan. }
false;public;1;3;;public void setLatency(TimeValue latency) {     this.latency = latency. }
false;public;1;3;;public void setCategorizationFieldName(String categorizationFieldName) {     this.categorizationFieldName = categorizationFieldName. }
false;public;1;3;;public void setCategorizationFilters(List<String> categorizationFilters) {     this.categorizationFilters = categorizationFilters. }
false;public;1;3;;public void setCategorizationAnalyzerConfig(CategorizationAnalyzerConfig categorizationAnalyzerConfig) {     this.categorizationAnalyzerConfig = categorizationAnalyzerConfig. }
false;public;1;3;;public void setSummaryCountFieldName(String summaryCountFieldName) {     this.summaryCountFieldName = summaryCountFieldName. }
false;public;1;3;;public void setInfluencers(List<String> influencers) {     this.influencers = ExceptionsHelper.requireNonNull(influencers, INFLUENCERS.getPreferredName()). }
false;public;1;3;;public void setMultivariateByFields(Boolean multivariateByFields) {     this.multivariateByFields = multivariateByFields. }
true;public;0;21;/**  * Checks the configuration is valid  * <ol>  * <li>Check that if non-null BucketSpan and Latency are &gt.= 0</li>  * <li>Check that if non-null Latency is &lt.= MAX_LATENCY</li>  * <li>Check there is at least one detector configured</li>  * <li>Check all the detectors are configured correctly</li>  * <li>Check that MULTIPLE_BUCKETSPANS are set appropriately</li>  * <li>If Per Partition normalization is configured at least one detector  * must have a partition field and no influences can be used</li>  * </ol>  */ ;/**  * Checks the configuration is valid  * <ol>  * <li>Check that if non-null BucketSpan and Latency are &gt.= 0</li>  * <li>Check that if non-null Latency is &lt.= MAX_LATENCY</li>  * <li>Check there is at least one detector configured</li>  * <li>Check all the detectors are configured correctly</li>  * <li>Check that MULTIPLE_BUCKETSPANS are set appropriately</li>  * <li>If Per Partition normalization is configured at least one detector  * must have a partition field and no influences can be used</li>  * </ol>  */ public AnalysisConfig build() {     TimeUtils.checkPositiveMultiple(bucketSpan, TimeUnit.SECONDS, BUCKET_SPAN).     if (latency != null) {         TimeUtils.checkNonNegativeMultiple(latency, TimeUnit.SECONDS, LATENCY).     }     verifyDetectorAreDefined().     Detector.Builder.verifyFieldName(summaryCountFieldName).     Detector.Builder.verifyFieldName(categorizationFieldName).     verifyMlCategoryIsUsedWhenCategorizationFieldNameIsSet().     verifyCategorizationAnalyzer().     verifyCategorizationFilters().     verifyNoMetricFunctionsWhenSummaryCountFieldNameIsSet().     verifyNoInconsistentNestedFieldNames().     return new AnalysisConfig(bucketSpan, categorizationFieldName, categorizationFilters, categorizationAnalyzerConfig, latency, summaryCountFieldName, detectors, influencers, multivariateByFields). }
false;private;0;7;;private void verifyNoMetricFunctionsWhenSummaryCountFieldNameIsSet() {     if (Strings.isNullOrEmpty(summaryCountFieldName) == false && detectors.stream().anyMatch(d -> DetectorFunction.METRIC.equals(d.getFunction()))) {         throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.JOB_CONFIG_FUNCTION_INCOMPATIBLE_PRESUMMARIZED, DetectorFunction.METRIC)).     } }
false;private;0;5;;private void verifyDetectorAreDefined() {     if (detectors == null || detectors.isEmpty()) {         throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.JOB_CONFIG_NO_DETECTORS)).     } }
false;private;0;22;;private void verifyNoInconsistentNestedFieldNames() {     SortedSet<String> termFields = termFields(detectors, influencers).     // We want to outlaw nested fields where a less nested field clashes with one of the nested levels.     // For example, this is not allowed:     // - a     // - a.b     // Nor is this:     // - a.b     // - a.b.c     // But this is OK:     // - a.b     // - a.c     // The sorted set makes it relatively easy to detect the situations we want to avoid.     String prevTermField = null.     for (String termField : termFields) {         if (prevTermField != null && termField.startsWith(prevTermField + ".")) {             throw ExceptionsHelper.badRequestException("Fields [" + prevTermField + "] and [" + termField + "] cannot both be used in the same analysis_config").         }         prevTermField = termField.     } }
false;private;0;13;;private void verifyMlCategoryIsUsedWhenCategorizationFieldNameIsSet() {     Set<String> byOverPartitionFields = new TreeSet<>().     detectors.forEach(d -> byOverPartitionFields.addAll(d.getByOverPartitionTerms())).     boolean isMlCategoryUsed = byOverPartitionFields.contains(ML_CATEGORY_FIELD).     if (isMlCategoryUsed && categorizationFieldName == null) {         throw ExceptionsHelper.badRequestException(CATEGORIZATION_FIELD_NAME.getPreferredName() + " must be set for " + ML_CATEGORY_FIELD + " to be available").     }     if (categorizationFieldName != null && isMlCategoryUsed == false) {         throw ExceptionsHelper.badRequestException(CATEGORIZATION_FIELD_NAME.getPreferredName() + " is set but " + ML_CATEGORY_FIELD + " is not used in any detector by/over/partition field").     } }
false;private;0;7;;private void verifyCategorizationAnalyzer() {     if (categorizationAnalyzerConfig == null) {         return.     }     verifyCategorizationFieldNameSetIfAnalyzerIsSet(). }
false;private;0;6;;private void verifyCategorizationFieldNameSetIfAnalyzerIsSet() {     if (categorizationFieldName == null) {         throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.JOB_CONFIG_CATEGORIZATION_ANALYZER_REQUIRES_CATEGORIZATION_FIELD_NAME)).     } }
false;private;0;11;;private void verifyCategorizationFilters() {     if (categorizationFilters == null || categorizationFilters.isEmpty()) {         return.     }     verifyCategorizationAnalyzerNotSetIfFiltersAreSet().     verifyCategorizationFieldNameSetIfFiltersAreSet().     verifyCategorizationFiltersAreDistinct().     verifyCategorizationFiltersContainNoneEmpty().     verifyCategorizationFiltersAreValidRegex(). }
false;private;0;6;;private void verifyCategorizationAnalyzerNotSetIfFiltersAreSet() {     if (categorizationAnalyzerConfig != null) {         throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.JOB_CONFIG_CATEGORIZATION_FILTERS_INCOMPATIBLE_WITH_CATEGORIZATION_ANALYZER)).     } }
false;private;0;6;;private void verifyCategorizationFieldNameSetIfFiltersAreSet() {     if (categorizationFieldName == null) {         throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.JOB_CONFIG_CATEGORIZATION_FILTERS_REQUIRE_CATEGORIZATION_FIELD_NAME)).     } }
false;private;0;6;;private void verifyCategorizationFiltersAreDistinct() {     if (categorizationFilters.stream().distinct().count() != categorizationFilters.size()) {         throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.JOB_CONFIG_CATEGORIZATION_FILTERS_CONTAINS_DUPLICATES)).     } }
false;private;0;5;;private void verifyCategorizationFiltersContainNoneEmpty() {     if (categorizationFilters.stream().anyMatch(String::isEmpty)) {         throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.JOB_CONFIG_CATEGORIZATION_FILTERS_CONTAINS_EMPTY)).     } }
false;private;0;8;;private void verifyCategorizationFiltersAreValidRegex() {     for (String filter : categorizationFilters) {         if (!isValidRegex(filter)) {             throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.JOB_CONFIG_CATEGORIZATION_FILTERS_CONTAINS_INVALID_REGEX, filter)).         }     } }
false;private,static;1;8;;private static boolean isValidRegex(String exp) {     try {         Pattern.compile(exp).         return true.     } catch (PatternSyntaxException e) {         return false.     } }
