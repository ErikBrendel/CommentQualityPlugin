commented;modifiers;parameterAmount;loc;comment;code
true;public,static;1;9;/* *      * Read and discard the old (prior to 6.5) perPartitionNormalization values      */ ;/* *      * Read and discard the old (prior to 6.5) perPartitionNormalization values      */ public static Bucket readOldPerPartitionNormalization(StreamInput in) throws IOException {     in.readString().     in.readString().     in.readDouble().     in.readDouble().     in.readDouble().     return null. }
false;private,static;1;22;;private static ConstructingObjectParser<Bucket, Void> createParser(boolean ignoreUnknownFields) {     ConstructingObjectParser<Bucket, Void> parser = new ConstructingObjectParser<>(RESULT_TYPE_VALUE, ignoreUnknownFields, a -> new Bucket((String) a[0], (Date) a[1], (long) a[2])).     parser.declareString(ConstructingObjectParser.constructorArg(), JOB_ID).     parser.declareField(ConstructingObjectParser.constructorArg(), p -> TimeUtils.parseTimeField(p, Result.TIMESTAMP.getPreferredName()), Result.TIMESTAMP, ValueType.VALUE).     parser.declareLong(ConstructingObjectParser.constructorArg(), BUCKET_SPAN).     parser.declareDouble(Bucket::setAnomalyScore, ANOMALY_SCORE).     parser.declareDouble(Bucket::setInitialAnomalyScore, INITIAL_ANOMALY_SCORE).     parser.declareBoolean(Bucket::setInterim, Result.IS_INTERIM).     parser.declareLong(Bucket::setEventCount, EVENT_COUNT).     parser.declareObjectArray(Bucket::setRecords, ignoreUnknownFields ? AnomalyRecord.LENIENT_PARSER : AnomalyRecord.STRICT_PARSER, RECORDS).     parser.declareObjectArray(Bucket::setBucketInfluencers, ignoreUnknownFields ? BucketInfluencer.LENIENT_PARSER : BucketInfluencer.STRICT_PARSER, BUCKET_INFLUENCERS).     parser.declareLong(Bucket::setProcessingTimeMs, PROCESSING_TIME_MS).     parser.declareString((bucket, s) -> {     }, Result.RESULT_TYPE).     parser.declareStringArray(Bucket::setScheduledEvents, SCHEDULED_EVENTS).     return parser. }
false;public;1;20;;@Override public void writeTo(StreamOutput out) throws IOException {     out.writeString(jobId).     out.writeLong(timestamp.getTime()).     out.writeDouble(anomalyScore).     out.writeLong(bucketSpan).     out.writeDouble(initialAnomalyScore).     out.writeList(records).     out.writeLong(eventCount).     out.writeBoolean(isInterim).     out.writeList(bucketInfluencers).     out.writeLong(processingTimeMs).     // bwc for perPartitionNormalization     if (out.getVersion().before(Version.V_6_5_0)) {         out.writeList(Collections.emptyList()).     }     if (out.getVersion().onOrAfter(Version.V_6_2_0)) {         out.writeStringCollection(scheduledEvents).     } }
false;public;2;23;;@Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {     builder.startObject().     builder.field(JOB_ID.getPreferredName(), jobId).     builder.timeField(Result.TIMESTAMP.getPreferredName(), Result.TIMESTAMP.getPreferredName() + "_string", timestamp.getTime()).     builder.field(ANOMALY_SCORE.getPreferredName(), anomalyScore).     builder.field(BUCKET_SPAN.getPreferredName(), bucketSpan).     builder.field(INITIAL_ANOMALY_SCORE.getPreferredName(), initialAnomalyScore).     if (records.isEmpty() == false) {         builder.field(RECORDS.getPreferredName(), records).     }     builder.field(EVENT_COUNT.getPreferredName(), eventCount).     builder.field(Result.IS_INTERIM.getPreferredName(), isInterim).     builder.field(BUCKET_INFLUENCERS.getPreferredName(), bucketInfluencers).     builder.field(PROCESSING_TIME_MS.getPreferredName(), processingTimeMs).     if (scheduledEvents.isEmpty() == false) {         builder.field(SCHEDULED_EVENTS.getPreferredName(), scheduledEvents).     }     builder.field(Result.RESULT_TYPE.getPreferredName(), RESULT_TYPE_VALUE).     builder.endObject().     return builder. }
false;public;0;3;;public String getJobId() {     return jobId. }
false;public;0;3;;public String getId() {     return jobId + "_bucket_" + timestamp.getTime() + "_" + bucketSpan. }
true;public;0;3;/**  * Timestamp expressed in seconds since the epoch (rather than Java's  * convention of milliseconds).  */ ;/**  * Timestamp expressed in seconds since the epoch (rather than Java's  * convention of milliseconds).  */ public long getEpoch() {     return timestamp.getTime() / 1000. }
false;public;0;3;;public Date getTimestamp() {     return timestamp. }
true;public;0;3;/**  * Bucketspan expressed in seconds  */ ;/**  * Bucketspan expressed in seconds  */ public long getBucketSpan() {     return bucketSpan. }
false;public;0;3;;public double getAnomalyScore() {     return anomalyScore. }
false;public;1;3;;public void setAnomalyScore(double anomalyScore) {     this.anomalyScore = anomalyScore. }
false;public;0;3;;public double getInitialAnomalyScore() {     return initialAnomalyScore. }
false;public;1;3;;public void setInitialAnomalyScore(double initialAnomalyScore) {     this.initialAnomalyScore = initialAnomalyScore. }
true;public;0;3;/**  * Get all the anomaly records associated with this bucket.  * The records are not part of the bucket document. They will  * only be present when the bucket was retrieved and expanded  * to contain the associated records.  *  * @return the anomaly records for the bucket IF the bucket was expanded.  */ ;/**  * Get all the anomaly records associated with this bucket.  * The records are not part of the bucket document. They will  * only be present when the bucket was retrieved and expanded  * to contain the associated records.  *  * @return the anomaly records for the bucket IF the bucket was expanded.  */ public List<AnomalyRecord> getRecords() {     return records. }
false;public;1;3;;public void setRecords(List<AnomalyRecord> records) {     this.records = Objects.requireNonNull(records). }
true;public;0;3;/**  * The number of records (events) actually processed in this bucket.  */ ;/**  * The number of records (events) actually processed in this bucket.  */ public long getEventCount() {     return eventCount. }
false;public;1;3;;public void setEventCount(long value) {     eventCount = value. }
false;public;0;3;;public boolean isInterim() {     return isInterim. }
false;public;1;3;;public void setInterim(boolean isInterim) {     this.isInterim = isInterim. }
false;public;0;3;;public long getProcessingTimeMs() {     return processingTimeMs. }
false;public;1;3;;public void setProcessingTimeMs(long timeMs) {     processingTimeMs = timeMs. }
false;public;0;3;;public List<BucketInfluencer> getBucketInfluencers() {     return bucketInfluencers. }
false;public;1;3;;public void setBucketInfluencers(List<BucketInfluencer> bucketInfluencers) {     this.bucketInfluencers = Objects.requireNonNull(bucketInfluencers). }
false;public;1;3;;public void addBucketInfluencer(BucketInfluencer bucketInfluencer) {     bucketInfluencers.add(bucketInfluencer). }
false;public;0;3;;public List<String> getScheduledEvents() {     return scheduledEvents. }
false;public;1;3;;public void setScheduledEvents(List<String> scheduledEvents) {     this.scheduledEvents = ExceptionsHelper.requireNonNull(scheduledEvents, SCHEDULED_EVENTS.getPreferredName()). }
false;public;0;5;;@Override public int hashCode() {     return Objects.hash(jobId, timestamp, eventCount, initialAnomalyScore, anomalyScore, records, isInterim, bucketSpan, bucketInfluencers, processingTimeMs, scheduledEvents). }
true;public;1;20;/**  * Compare all the fields and embedded anomaly records (if any)  */ ;/**  * Compare all the fields and embedded anomaly records (if any)  */ @Override public boolean equals(Object other) {     if (this == other) {         return true.     }     if (other instanceof Bucket == false) {         return false.     }     Bucket that = (Bucket) other.     return Objects.equals(this.jobId, that.jobId) && Objects.equals(this.timestamp, that.timestamp) && (this.eventCount == that.eventCount) && (this.bucketSpan == that.bucketSpan) && (this.anomalyScore == that.anomalyScore) && (this.initialAnomalyScore == that.initialAnomalyScore) && Objects.equals(this.records, that.records) && Objects.equals(this.isInterim, that.isInterim) && Objects.equals(this.bucketInfluencers, that.bucketInfluencers) && (this.processingTimeMs == that.processingTimeMs) && Objects.equals(this.scheduledEvents, that.scheduledEvents). }
true;public;0;3;/**  * This method encapsulated the logic for whether a bucket should be normalized.  * Buckets that have a zero anomaly score themselves and no partition scores with  * non-zero score should not be normalized as their score will not change and they  * will just add overhead.  *  * @return true if the bucket should be normalized or false otherwise  */ ;/**  * This method encapsulated the logic for whether a bucket should be normalized.  * Buckets that have a zero anomaly score themselves and no partition scores with  * non-zero score should not be normalized as their score will not change and they  * will just add overhead.  *  * @return true if the bucket should be normalized or false otherwise  */ public boolean isNormalizable() {     return anomalyScore > 0.0. }
