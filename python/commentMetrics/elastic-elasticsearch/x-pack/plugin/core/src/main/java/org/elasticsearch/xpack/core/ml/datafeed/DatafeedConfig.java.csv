commented;modifiers;parameterAmount;loc;comment;code
false;public,static;1;14;;public static void validateAggregations(AggregatorFactories.Builder aggregations) {     if (aggregations == null) {         return.     }     Collection<AggregationBuilder> aggregatorFactories = aggregations.getAggregatorFactories().     if (aggregatorFactories.isEmpty()) {         throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_REQUIRES_DATE_HISTOGRAM).     }     AggregationBuilder histogramAggregation = ExtractorUtils.getHistogramAggregation(aggregatorFactories).     Builder.checkNoMoreHistogramAggregations(histogramAggregation.getSubAggregations()).     Builder.checkHistogramAggregationHasChildMaxTimeAgg(histogramAggregation).     Builder.checkHistogramIntervalIsPositive(histogramAggregation). }
false;private,static;1;39;;private static ObjectParser<Builder, Void> createParser(boolean ignoreUnknownFields) {     ObjectParser<Builder, Void> parser = new ObjectParser<>("datafeed_config", ignoreUnknownFields, Builder::new).     parser.declareString(Builder::setId, ID).     parser.declareString((c, s) -> {     }, CONFIG_TYPE).     parser.declareString(Builder::setJobId, Job.ID).     parser.declareStringArray(Builder::setIndices, INDEXES).     parser.declareStringArray(Builder::setIndices, INDICES).     parser.declareString((builder, val) -> builder.setQueryDelay(TimeValue.parseTimeValue(val, QUERY_DELAY.getPreferredName())), QUERY_DELAY).     parser.declareString((builder, val) -> builder.setFrequency(TimeValue.parseTimeValue(val, FREQUENCY.getPreferredName())), FREQUENCY).     parser.declareObject((builder, val) -> builder.setQuery(val, ignoreUnknownFields), (p, c) -> p.mapOrdered(), QUERY).     parser.declareObject((builder, val) -> builder.setAggregationsSafe(val, ignoreUnknownFields), (p, c) -> p.mapOrdered(), AGGREGATIONS).     parser.declareObject((builder, val) -> builder.setAggregationsSafe(val, ignoreUnknownFields), (p, c) -> p.mapOrdered(), AGGS).     parser.declareObject(Builder::setScriptFields, (p, c) -> {         List<SearchSourceBuilder.ScriptField> parsedScriptFields = new ArrayList<>().         while (p.nextToken() != XContentParser.Token.END_OBJECT) {             parsedScriptFields.add(new SearchSourceBuilder.ScriptField(p)).         }         parsedScriptFields.sort(Comparator.comparing(SearchSourceBuilder.ScriptField::fieldName)).         return parsedScriptFields.     }, SCRIPT_FIELDS).     parser.declareInt(Builder::setScrollSize, SCROLL_SIZE).     parser.declareObject(Builder::setChunkingConfig, ignoreUnknownFields ? ChunkingConfig.LENIENT_PARSER : ChunkingConfig.STRICT_PARSER, CHUNKING_CONFIG).     if (ignoreUnknownFields) {         // Headers are not parsed by the strict (config) parser, so headers supplied in the _body_ of a REST request will be rejected.         // (For config, headers are explicitly transferred from the auth headers by code in the put/update datafeed actions.)         parser.declareObject(Builder::setHeaders, (p, c) -> p.mapStrings(), HEADERS).     }     parser.declareObject(Builder::setDelayedDataCheckConfig, ignoreUnknownFields ? DelayedDataCheckConfig.LENIENT_PARSER : DelayedDataCheckConfig.STRICT_PARSER, DELAYED_DATA_CHECK_CONFIG).     return parser. }
true;public,static;1;3;/**  * The name of datafeed configuration document name from the datafeed ID.  *  * @param datafeedId The datafeed ID  * @return The ID of document the datafeed config is persisted in  */ ;/**  * The name of datafeed configuration document name from the datafeed ID.  *  * @param datafeedId The datafeed ID  * @return The ID of document the datafeed config is persisted in  */ public static String documentId(String datafeedId) {     return TYPE + "-" + datafeedId. }
false;public;0;3;;public String getId() {     return id. }
false;public;0;3;;public String getJobId() {     return jobId. }
false;public;0;3;;public String getConfigType() {     return TYPE. }
false;public;0;3;;public TimeValue getQueryDelay() {     return queryDelay. }
false;public;0;3;;public TimeValue getFrequency() {     return frequency. }
false;public;0;3;;public List<String> getIndices() {     return indices. }
false;public;0;3;;public Integer getScrollSize() {     return scrollSize. }
false;public;0;3;;public QueryBuilder getParsedQuery() {     return querySupplier.get(). }
true;public;0;3;/**  * Calls the lazy parser and returns any gathered deprecations  * @return The deprecations from parsing the query  */ ;/**  * Calls the lazy parser and returns any gathered deprecations  * @return The deprecations from parsing the query  */ public List<String> getQueryDeprecations() {     return getQueryDeprecations(lazyQueryParser). }
false;;1;5;;List<String> getQueryDeprecations(TriFunction<Map<String, Object>, String, List<String>, QueryBuilder> parser) {     List<String> deprecations = new ArrayList<>().     parser.apply(query, id, deprecations).     return deprecations. }
false;public;0;3;;public Map<String, Object> getQuery() {     return query. }
false;public;0;3;;public AggregatorFactories.Builder getParsedAggregations() {     return aggSupplier.get(). }
true;public;0;3;/**  * Calls the lazy parser and returns any gathered deprecations  * @return The deprecations from parsing the aggregations  */ ;/**  * Calls the lazy parser and returns any gathered deprecations  * @return The deprecations from parsing the aggregations  */ public List<String> getAggDeprecations() {     return getAggDeprecations(lazyAggParser). }
false;;1;5;;List<String> getAggDeprecations(TriFunction<Map<String, Object>, String, List<String>, AggregatorFactories.Builder> parser) {     List<String> deprecations = new ArrayList<>().     parser.apply(aggregations, id, deprecations).     return deprecations. }
false;public;0;3;;public Map<String, Object> getAggregations() {     return aggregations. }
true;public;0;3;/**  * Returns the histogram's interval as epoch millis.  */ ;/**  * Returns the histogram's interval as epoch millis.  */ public long getHistogramIntervalMillis() {     return ExtractorUtils.getHistogramIntervalMillis(getParsedAggregations()). }
true;public;0;3;/**  * @return {@code true} when there are non-empty aggregations, {@code false} otherwise  */ ;/**  * @return {@code true} when there are non-empty aggregations, {@code false} otherwise  */ public boolean hasAggregations() {     return aggregations != null && aggregations.size() > 0. }
false;public;0;3;;public List<SearchSourceBuilder.ScriptField> getScriptFields() {     return scriptFields == null ? Collections.emptyList() : scriptFields. }
false;public;0;3;;public ChunkingConfig getChunkingConfig() {     return chunkingConfig. }
false;public;0;3;;public Map<String, String> getHeaders() {     return headers. }
false;public;0;3;;public DelayedDataCheckConfig getDelayedDataCheckConfig() {     return delayedDataCheckConfig. }
false;public;1;43;;@Override public void writeTo(StreamOutput out) throws IOException {     out.writeString(id).     out.writeString(jobId).     out.writeOptionalTimeValue(queryDelay).     out.writeOptionalTimeValue(frequency).     if (indices != null) {         out.writeBoolean(true).         out.writeStringCollection(indices).     } else {         out.writeBoolean(false).     }     // An empty list is expected     if (out.getVersion().before(Version.V_7_0_0)) {         out.writeBoolean(true).         out.writeStringCollection(Collections.emptyList()).     }     if (out.getVersion().before(Version.V_6_6_0)) {         out.writeNamedWriteable(getParsedQuery()).         out.writeOptionalWriteable(getParsedAggregations()).     } else {         out.writeMap(query).         out.writeBoolean(aggregations != null).         if (aggregations != null) {             out.writeMap(aggregations).         }     }     if (scriptFields != null) {         out.writeBoolean(true).         out.writeList(scriptFields).     } else {         out.writeBoolean(false).     }     out.writeOptionalVInt(scrollSize).     out.writeOptionalWriteable(chunkingConfig).     if (out.getVersion().onOrAfter(Version.V_6_2_0)) {         out.writeMap(headers, StreamOutput::writeString, StreamOutput::writeString).     }     if (out.getVersion().onOrAfter(Version.V_6_6_0)) {         out.writeOptionalWriteable(delayedDataCheckConfig).     } }
false;public;2;37;;@Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {     builder.startObject().     builder.field(ID.getPreferredName(), id).     builder.field(Job.ID.getPreferredName(), jobId).     if (params.paramAsBoolean(ToXContentParams.INCLUDE_TYPE, false) == true) {         builder.field(CONFIG_TYPE.getPreferredName(), TYPE).     }     builder.field(QUERY_DELAY.getPreferredName(), queryDelay.getStringRep()).     if (frequency != null) {         builder.field(FREQUENCY.getPreferredName(), frequency.getStringRep()).     }     builder.field(INDICES.getPreferredName(), indices).     builder.field(QUERY.getPreferredName(), query).     if (aggregations != null) {         builder.field(AGGREGATIONS.getPreferredName(), aggregations).     }     if (scriptFields != null) {         builder.startObject(SCRIPT_FIELDS.getPreferredName()).         for (SearchSourceBuilder.ScriptField scriptField : scriptFields) {             scriptField.toXContent(builder, params).         }         builder.endObject().     }     builder.field(SCROLL_SIZE.getPreferredName(), scrollSize).     if (chunkingConfig != null) {         builder.field(CHUNKING_CONFIG.getPreferredName(), chunkingConfig).     }     if (headers.isEmpty() == false && params.paramAsBoolean(ToXContentParams.FOR_INTERNAL_STORAGE, false) == true) {         builder.field(HEADERS.getPreferredName(), headers).     }     if (delayedDataCheckConfig != null) {         builder.field(DELAYED_DATA_CHECK_CONFIG.getPreferredName(), delayedDataCheckConfig).     }     builder.endObject().     return builder. }
true;public;1;25;/**  * The lists of indices and types are compared for equality but they are not  * sorted first so this test could fail simply because the indices and types  * lists are in different orders.  */ ;/**  * The lists of indices and types are compared for equality but they are not  * sorted first so this test could fail simply because the indices and types  * lists are in different orders.  */ @Override public boolean equals(Object other) {     if (this == other) {         return true.     }     if (other instanceof DatafeedConfig == false) {         return false.     }     DatafeedConfig that = (DatafeedConfig) other.     return Objects.equals(this.id, that.id) && Objects.equals(this.jobId, that.jobId) && Objects.equals(this.frequency, that.frequency) && Objects.equals(this.queryDelay, that.queryDelay) && Objects.equals(this.indices, that.indices) && Objects.equals(this.query, that.query) && Objects.equals(this.scrollSize, that.scrollSize) && Objects.equals(this.aggregations, that.aggregations) && Objects.equals(this.scriptFields, that.scriptFields) && Objects.equals(this.chunkingConfig, that.chunkingConfig) && Objects.equals(this.headers, that.headers) && Objects.equals(this.delayedDataCheckConfig, that.delayedDataCheckConfig). }
false;public;0;5;;@Override public int hashCode() {     return Objects.hash(id, jobId, frequency, queryDelay, indices, query, scrollSize, aggregations, scriptFields, chunkingConfig, headers, delayedDataCheckConfig). }
false;public;0;4;;@Override public String toString() {     return Strings.toString(this). }
true;public;1;11;/**  * Calculates a sensible default frequency for a given bucket span.  * <p>  * The default depends on the bucket span:  * <ul>  * <li> &lt.= 2 mins -&gt. 1 min</li>  * <li> &lt.= 20 mins -&gt. bucket span / 2</li>  * <li> &lt.= 12 hours -&gt. 10 mins</li>  * <li> &gt. 12 hours -&gt. 1 hour</li>  * </ul>  *  * If the datafeed has aggregations, the default frequency is the  * closest multiple of the histogram interval based on the rules above.  *  * @param bucketSpan the bucket span  * @return the default frequency  */ ;/**  * Calculates a sensible default frequency for a given bucket span.  * <p>  * The default depends on the bucket span:  * <ul>  * <li> &lt.= 2 mins -&gt. 1 min</li>  * <li> &lt.= 20 mins -&gt. bucket span / 2</li>  * <li> &lt.= 12 hours -&gt. 10 mins</li>  * <li> &gt. 12 hours -&gt. 1 hour</li>  * </ul>  *  * If the datafeed has aggregations, the default frequency is the  * closest multiple of the histogram interval based on the rules above.  *  * @param bucketSpan the bucket span  * @return the default frequency  */ public TimeValue defaultFrequency(TimeValue bucketSpan) {     TimeValue defaultFrequency = defaultFrequencyTarget(bucketSpan).     if (hasAggregations()) {         long histogramIntervalMillis = getHistogramIntervalMillis().         long targetFrequencyMillis = defaultFrequency.millis().         long defaultFrequencyMillis = histogramIntervalMillis > targetFrequencyMillis ? histogramIntervalMillis : (targetFrequencyMillis / histogramIntervalMillis) * histogramIntervalMillis.         defaultFrequency = TimeValue.timeValueMillis(defaultFrequencyMillis).     }     return defaultFrequency. }
false;private;1;17;;private TimeValue defaultFrequencyTarget(TimeValue bucketSpan) {     long bucketSpanSeconds = bucketSpan.seconds().     if (bucketSpanSeconds <= 0) {         throw new IllegalArgumentException("Bucket span has to be > 0").     }     if (bucketSpanSeconds <= TWO_MINS_SECONDS) {         return TimeValue.timeValueSeconds(SECONDS_IN_MINUTE).     }     if (bucketSpanSeconds <= TWENTY_MINS_SECONDS) {         return TimeValue.timeValueSeconds(bucketSpanSeconds / 2).     }     if (bucketSpanSeconds <= HALF_DAY_SECONDS) {         return TimeValue.timeValueMinutes(10).     }     return TimeValue.timeValueHours(1). }
false;public;1;3;;public void setId(String datafeedId) {     id = ExceptionsHelper.requireNonNull(datafeedId, ID.getPreferredName()). }
false;public;0;3;;public String getId() {     return id. }
false;public;1;3;;public void setJobId(String jobId) {     this.jobId = ExceptionsHelper.requireNonNull(jobId, Job.ID.getPreferredName()). }
false;public;1;3;;public void setHeaders(Map<String, String> headers) {     this.headers = ExceptionsHelper.requireNonNull(headers, HEADERS.getPreferredName()). }
false;public;1;3;;public void setIndices(List<String> indices) {     this.indices = ExceptionsHelper.requireNonNull(indices, INDICES.getPreferredName()). }
false;public;1;4;;public void setQueryDelay(TimeValue queryDelay) {     TimeUtils.checkNonNegativeMultiple(queryDelay, TimeUnit.MILLISECONDS, QUERY_DELAY).     this.queryDelay = queryDelay. }
false;public;1;4;;public void setFrequency(TimeValue frequency) {     TimeUtils.checkPositiveMultiple(frequency, TimeUnit.SECONDS, FREQUENCY).     this.frequency = frequency. }
false;public;1;3;;public void setQuery(Map<String, Object> query) {     setQuery(query, true). }
false;public;2;18;;public void setQuery(Map<String, Object> query, boolean lenient) {     this.query = ExceptionsHelper.requireNonNull(query, QUERY.getPreferredName()).     try {         QUERY_TRANSFORMER.fromMap(query).     } catch (Exception ex) {         String msg = Messages.getMessage(Messages.DATAFEED_CONFIG_QUERY_BAD_FORMAT, id).         if (ex.getCause() instanceof IllegalArgumentException) {             ex = (Exception) ex.getCause().         }         if (lenient) {             logger.warn(msg, ex).         } else {             throw ExceptionsHelper.badRequestException(msg, ex).         }     } }
true;public;1;12;// Kept for easier testing ;// Kept for easier testing public void setParsedAggregations(AggregatorFactories.Builder aggregations) {     try {         setAggregations(AGG_TRANSFORMER.toMap(aggregations)).     } catch (Exception exception) {         // Certain thrown exceptions wrap up the real Illegal argument making it hard to determine cause for the user         if (exception.getCause() instanceof IllegalArgumentException) {             exception = (Exception) exception.getCause().         }         throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.DATAFEED_CONFIG_AGG_BAD_FORMAT, id), exception).     } }
false;private;2;6;;private void setAggregationsSafe(Map<String, Object> aggregations, boolean lenient) {     if (this.aggregations != null) {         throw ExceptionsHelper.badRequestException("Found two aggregation definitions: [aggs] and [aggregations]").     }     setAggregations(aggregations, lenient). }
false;;1;3;;void setAggregations(Map<String, Object> aggregations) {     setAggregations(aggregations, true). }
false;;2;21;;void setAggregations(Map<String, Object> aggregations, boolean lenient) {     this.aggregations = aggregations.     try {         if (aggregations != null && aggregations.isEmpty()) {             throw new Exception("[aggregations] are empty").         }         AGG_TRANSFORMER.fromMap(aggregations).     } catch (Exception ex) {         String msg = Messages.getMessage(Messages.DATAFEED_CONFIG_AGG_BAD_FORMAT, id).         if (ex.getCause() instanceof IllegalArgumentException) {             ex = (Exception) ex.getCause().         }         if (lenient) {             logger.warn(msg, ex).         } else {             throw ExceptionsHelper.badRequestException(msg, ex).         }     } }
false;public;1;8;;public void setScriptFields(List<SearchSourceBuilder.ScriptField> scriptFields) {     List<SearchSourceBuilder.ScriptField> sorted = new ArrayList<>().     for (SearchSourceBuilder.ScriptField scriptField : scriptFields) {         sorted.add(scriptField).     }     sorted.sort(Comparator.comparing(SearchSourceBuilder.ScriptField::fieldName)).     this.scriptFields = sorted. }
false;public;1;8;;public void setScrollSize(int scrollSize) {     if (scrollSize < 0) {         String msg = Messages.getMessage(Messages.DATAFEED_CONFIG_INVALID_OPTION_VALUE, DatafeedConfig.SCROLL_SIZE.getPreferredName(), scrollSize).         throw ExceptionsHelper.badRequestException(msg).     }     this.scrollSize = scrollSize. }
false;public;1;3;;public void setChunkingConfig(ChunkingConfig chunkingConfig) {     this.chunkingConfig = chunkingConfig. }
false;public;1;3;;public void setDelayedDataCheckConfig(DelayedDataCheckConfig delayedDataCheckConfig) {     this.delayedDataCheckConfig = delayedDataCheckConfig. }
false;public;0;17;;public DatafeedConfig build() {     ExceptionsHelper.requireNonNull(id, ID.getPreferredName()).     ExceptionsHelper.requireNonNull(jobId, Job.ID.getPreferredName()).     if (!MlStrings.isValidId(id)) {         throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.INVALID_ID, ID.getPreferredName(), id)).     }     if (indices == null || indices.isEmpty() || indices.contains(null) || indices.contains("")) {         throw invalidOptionValue(INDICES.getPreferredName(), indices).     }     validateScriptFields().     setDefaultChunkingConfig().     setDefaultQueryDelay().     return new DatafeedConfig(id, jobId, queryDelay, frequency, indices, query, aggregations, scriptFields, scrollSize, chunkingConfig, headers, delayedDataCheckConfig). }
false;;0;9;;void validateScriptFields() {     if (aggregations == null) {         return.     }     if (scriptFields != null && !scriptFields.isEmpty()) {         throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.DATAFEED_CONFIG_CANNOT_USE_SCRIPT_FIELDS_WITH_AGGS)).     } }
false;private,static;1;8;;private static void checkNoMoreHistogramAggregations(Collection<AggregationBuilder> aggregations) {     for (AggregationBuilder agg : aggregations) {         if (ExtractorUtils.isHistogram(agg)) {             throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_MAX_ONE_DATE_HISTOGRAM).         }         checkNoMoreHistogramAggregations(agg.getSubAggregations()).     } }
false;static;1;18;;static void checkHistogramAggregationHasChildMaxTimeAgg(AggregationBuilder histogramAggregation) {     String timeField = null.     if (histogramAggregation instanceof ValuesSourceAggregationBuilder) {         timeField = ((ValuesSourceAggregationBuilder) histogramAggregation).field().     }     for (AggregationBuilder agg : histogramAggregation.getSubAggregations()) {         if (agg instanceof MaxAggregationBuilder) {             MaxAggregationBuilder maxAgg = (MaxAggregationBuilder) agg.             if (maxAgg.field().equals(timeField)) {                 return.             }         }     }     throw ExceptionsHelper.badRequestException(Messages.getMessage(Messages.DATAFEED_DATA_HISTOGRAM_MUST_HAVE_NESTED_MAX_AGGREGATION, timeField)). }
false;private,static;1;6;;private static void checkHistogramIntervalIsPositive(AggregationBuilder histogramAggregation) {     long interval = ExtractorUtils.getHistogramIntervalMillis(histogramAggregation).     if (interval <= 0) {         throw ExceptionsHelper.badRequestException(Messages.DATAFEED_AGGREGATIONS_INTERVAL_MUST_BE_GREATER_THAN_ZERO).     } }
false;private;0;12;;private void setDefaultChunkingConfig() {     if (chunkingConfig == null) {         if (aggregations == null) {             chunkingConfig = ChunkingConfig.newAuto().         } else {             long histogramIntervalMillis = ExtractorUtils.getHistogramIntervalMillis(lazyAggParser.apply(aggregations, id, new ArrayList<>())).             chunkingConfig = ChunkingConfig.newManual(TimeValue.timeValueMillis(DEFAULT_AGGREGATION_CHUNKING_BUCKETS * histogramIntervalMillis)).         }     } }
false;private;0;8;;private void setDefaultQueryDelay() {     if (queryDelay == null) {         Random random = new Random(jobId.hashCode()).         long delayMillis = random.longs(MIN_DEFAULT_QUERY_DELAY.millis(), MAX_DEFAULT_QUERY_DELAY.millis()).findFirst().getAsLong().         queryDelay = TimeValue.timeValueMillis(delayMillis).     } }
false;private,static;2;4;;private static ElasticsearchException invalidOptionValue(String fieldName, Object value) {     String msg = Messages.getMessage(Messages.DATAFEED_CONFIG_INVALID_OPTION_VALUE, fieldName, value).     throw ExceptionsHelper.badRequestException(msg). }
