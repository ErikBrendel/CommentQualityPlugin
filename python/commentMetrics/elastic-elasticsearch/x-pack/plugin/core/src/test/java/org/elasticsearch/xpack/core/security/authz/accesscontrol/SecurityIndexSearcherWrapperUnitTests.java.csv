commented;modifiers;parameterAmount;loc;comment;code
false;public;0;20;;@Before public void setup() throws Exception {     Index index = new Index("_index", "testUUID").     scriptService = mock(ScriptService.class).     indexSettings = IndexSettingsModule.newIndexSettings(index, Settings.EMPTY).     ShardId shardId = new ShardId(index, 0).     licenseState = mock(XPackLicenseState.class).     when(licenseState.isDocumentAndFieldLevelSecurityAllowed()).thenReturn(true).     threadContext = new ThreadContext(Settings.EMPTY).     IndexShard indexShard = mock(IndexShard.class).     when(indexShard.shardId()).thenReturn(shardId).     Directory directory = new MMapDirectory(createTempDir()).     IndexWriter writer = new IndexWriter(directory, newIndexWriterConfig()).     writer.close().     // unfortunately DirectoryReader isn't mock friendly     DirectoryReader in = DirectoryReader.open(directory).     esIn = ElasticsearchDirectoryReader.wrap(in, shardId). }
false;public;0;5;;@After public void tearDown() throws Exception {     super.tearDown().     esIn.close(). }
false;protected;0;6;;@Override protected IndicesAccessControl getIndicesAccessControl() {     IndicesAccessControl.IndexAccessControl indexAccessControl = new IndicesAccessControl.IndexAccessControl(true, new FieldPermissions(fieldPermissionDef(new String[] {}, null)), DocumentPermissions.allowAll()).     return new IndicesAccessControl(true, singletonMap("_index", indexAccessControl)). }
false;public;0;28;;public void testDefaultMetaFields() throws Exception {     securityIndexSearcherWrapper = new SecurityIndexSearcherWrapper(null, null, threadContext, licenseState, scriptService) {          @Override         protected IndicesAccessControl getIndicesAccessControl() {             IndicesAccessControl.IndexAccessControl indexAccessControl = new IndicesAccessControl.IndexAccessControl(true, new FieldPermissions(fieldPermissionDef(new String[] {}, null)), DocumentPermissions.allowAll()).             return new IndicesAccessControl(true, singletonMap("_index", indexAccessControl)).         }     }.     FieldSubsetReader.FieldSubsetDirectoryReader result = (FieldSubsetReader.FieldSubsetDirectoryReader) securityIndexSearcherWrapper.wrap(esIn).     assertThat(result.getFilter().run("_uid"), is(true)).     assertThat(result.getFilter().run("_id"), is(true)).     assertThat(result.getFilter().run("_version"), is(true)).     assertThat(result.getFilter().run("_type"), is(true)).     assertThat(result.getFilter().run("_source"), is(true)).     assertThat(result.getFilter().run("_routing"), is(true)).     assertThat(result.getFilter().run("_timestamp"), is(true)).     assertThat(result.getFilter().run("_ttl"), is(true)).     assertThat(result.getFilter().run("_size"), is(true)).     assertThat(result.getFilter().run("_index"), is(true)).     assertThat(result.getFilter().run("_field_names"), is(true)).     assertThat(result.getFilter().run("_seq_no"), is(true)).     assertThat(result.getFilter().run("_some_random_meta_field"), is(true)).     assertThat(result.getFilter().run("some_random_regular_field"), is(false)). }
false;public;0;7;;public void testWrapReaderWhenFeatureDisabled() throws Exception {     when(licenseState.isDocumentAndFieldLevelSecurityAllowed()).thenReturn(false).     securityIndexSearcherWrapper = new SecurityIndexSearcherWrapper(null, null, threadContext, licenseState, scriptService).     DirectoryReader reader = securityIndexSearcherWrapper.wrap(esIn).     assertThat(reader, sameInstance(esIn)). }
false;public;0;7;;public void testWrapSearcherWhenFeatureDisabled() throws Exception {     securityIndexSearcherWrapper = new SecurityIndexSearcherWrapper(null, null, threadContext, licenseState, scriptService).     IndexSearcher indexSearcher = new IndexSearcher(esIn).     IndexSearcher result = securityIndexSearcherWrapper.wrap(indexSearcher).     assertThat(result, sameInstance(indexSearcher)). }
false;public;0;7;;public void testWildcards() throws Exception {     Set<String> expected = new HashSet<>(META_FIELDS).     expected.add("field1_a").     expected.add("field1_b").     expected.add("field1_c").     assertResolved(new FieldPermissions(fieldPermissionDef(new String[] { "field1*" }, null)), expected, "field", "field2"). }
false;public;0;9;;public void testDotNotion() throws Exception {     Set<String> expected = new HashSet<>(META_FIELDS).     expected.add("foo.bar").     assertResolved(new FieldPermissions(fieldPermissionDef(new String[] { "foo.bar" }, null)), expected, "foo", "foo.baz", "bar.foo").     expected = new HashSet<>(META_FIELDS).     expected.add("foo.bar").     assertResolved(new FieldPermissions(fieldPermissionDef(new String[] { "foo.*" }, null)), expected, "foo", "bar"). }
false;public;2;3;;@Override public void onCache(ShardId shardId, Accountable accountable) { }
false;public;2;4;;@Override public void onRemoval(ShardId shardId, Accountable accountable) { }
false;public;0;21;;public void testDelegateSimilarity() throws Exception {     IndexSettings settings = IndexSettingsModule.newIndexSettings("_index", Settings.EMPTY).     BitsetFilterCache bitsetFilterCache = new BitsetFilterCache(settings, new BitsetFilterCache.Listener() {          @Override         public void onCache(ShardId shardId, Accountable accountable) {         }          @Override         public void onRemoval(ShardId shardId, Accountable accountable) {         }     }).     DirectoryReader directoryReader = DocumentSubsetReader.wrap(esIn, bitsetFilterCache, new MatchAllDocsQuery()).     IndexSearcher indexSearcher = new IndexSearcher(directoryReader).     securityIndexSearcherWrapper = new SecurityIndexSearcherWrapper(null, null, threadContext, licenseState, scriptService).     IndexSearcher result = securityIndexSearcherWrapper.wrap(indexSearcher).     assertThat(result, not(sameInstance(indexSearcher))).     assertThat(result.getSimilarity(), sameInstance(indexSearcher.getSimilarity())).     bitsetFilterCache.close(). }
false;public;2;4;;@Override public void collect(int doc, long bucket) throws IOException {     assertThat(doc, equalTo(0)). }
false;public;2;4;;@Override public void collect(int doc, long bucket) throws IOException {     assertThat(doc, equalTo(1)). }
false;public;2;4;;@Override public void collect(int doc, long bucket) throws IOException {     fail("docId [" + doc + "] should have been deleted"). }
false;public;2;4;;@Override public void collect(int doc, long bucket) throws IOException {     assertThat(doc, equalTo(3)). }
false;public;0;79;;public void testIntersectScorerAndRoleBits() throws Exception {     securityIndexSearcherWrapper = new SecurityIndexSearcherWrapper(null, null, threadContext, licenseState, scriptService).     final Directory directory = newDirectory().     IndexWriter iw = new IndexWriter(directory, new IndexWriterConfig(new StandardAnalyzer()).setMergePolicy(NoMergePolicy.INSTANCE)).     Document document = new Document().     document.add(new StringField("field1", "value1", Field.Store.NO)).     document.add(new StringField("field2", "value1", Field.Store.NO)).     iw.addDocument(document).     document = new Document().     document.add(new StringField("field1", "value2", Field.Store.NO)).     document.add(new StringField("field2", "value1", Field.Store.NO)).     iw.addDocument(document).     document = new Document().     document.add(new StringField("field1", "value3", Field.Store.NO)).     document.add(new StringField("field2", "value1", Field.Store.NO)).     iw.addDocument(document).     document = new Document().     document.add(new StringField("field1", "value4", Field.Store.NO)).     document.add(new StringField("field2", "value1", Field.Store.NO)).     iw.addDocument(document).     iw.commit().     iw.deleteDocuments(new Term("field1", "value3")).     iw.close().     DirectoryReader directoryReader = DirectoryReader.open(directory).     IndexSearcher searcher = new IndexSearcher(directoryReader).     Weight weight = searcher.createWeight(new TermQuery(new Term("field2", "value1")), org.apache.lucene.search.ScoreMode.COMPLETE_NO_SCORES, 1f).     LeafReaderContext leaf = directoryReader.leaves().get(0).     SparseFixedBitSet sparseFixedBitSet = query(leaf, "field1", "value1").     LeafCollector leafCollector = new LeafBucketCollector() {          @Override         public void collect(int doc, long bucket) throws IOException {             assertThat(doc, equalTo(0)).         }     }.     intersectScorerAndRoleBits(weight.scorer(leaf), sparseFixedBitSet, leafCollector, leaf.reader().getLiveDocs()).     sparseFixedBitSet = query(leaf, "field1", "value2").     leafCollector = new LeafBucketCollector() {          @Override         public void collect(int doc, long bucket) throws IOException {             assertThat(doc, equalTo(1)).         }     }.     intersectScorerAndRoleBits(weight.scorer(leaf), sparseFixedBitSet, leafCollector, leaf.reader().getLiveDocs()).     sparseFixedBitSet = query(leaf, "field1", "value3").     leafCollector = new LeafBucketCollector() {          @Override         public void collect(int doc, long bucket) throws IOException {             fail("docId [" + doc + "] should have been deleted").         }     }.     intersectScorerAndRoleBits(weight.scorer(leaf), sparseFixedBitSet, leafCollector, leaf.reader().getLiveDocs()).     sparseFixedBitSet = query(leaf, "field1", "value4").     leafCollector = new LeafBucketCollector() {          @Override         public void collect(int doc, long bucket) throws IOException {             assertThat(doc, equalTo(3)).         }     }.     intersectScorerAndRoleBits(weight.scorer(leaf), sparseFixedBitSet, leafCollector, leaf.reader().getLiveDocs()).     directoryReader.close().     directory.close(). }
false;private;3;8;;private void assertResolved(FieldPermissions permissions, Set<String> expected, String... fieldsToTest) {     for (String field : expected) {         assertThat(field, permissions.grantsAccessTo(field), is(true)).     }     for (String field : fieldsToTest) {         assertThat(field, permissions.grantsAccessTo(field), is(expected.contains(field))).     } }
false;public;0;72;;public void testFieldPermissionsWithFieldExceptions() throws Exception {     securityIndexSearcherWrapper = new SecurityIndexSearcherWrapper(null, null, threadContext, licenseState, null).     String[] grantedFields = new String[] {}.     String[] deniedFields.     Set<String> expected = new HashSet<>(META_FIELDS).     // Presence of fields in a role with an empty array implies access to no fields except the meta fields     assertResolved(new FieldPermissions(fieldPermissionDef(grantedFields, randomBoolean() ? null : new String[] {})), expected, "foo", "bar").     // make sure meta fields cannot be denied access to     deniedFields = META_FIELDS.toArray(new String[0]).     assertResolved(new FieldPermissions(fieldPermissionDef(null, deniedFields)), new HashSet<>(Arrays.asList("foo", "bar", "_some_plugin_meta_field"))).     // check we can add all fields with *     grantedFields = new String[] { "*" }.     expected = new HashSet<>(META_FIELDS).     expected.add("foo").     assertResolved(new FieldPermissions(fieldPermissionDef(grantedFields, randomBoolean() ? null : new String[] {})), expected).     // same with null     grantedFields = null.     assertResolved(new FieldPermissions(fieldPermissionDef(grantedFields, randomBoolean() ? null : new String[] {})), expected).     // check we remove only excluded fields     grantedFields = new String[] { "*" }.     deniedFields = new String[] { "xfield" }.     expected = new HashSet<>(META_FIELDS).     expected.add("foo").     assertResolved(new FieldPermissions(fieldPermissionDef(grantedFields, deniedFields)), expected, "xfield").     // same with null     grantedFields = null.     assertResolved(new FieldPermissions(fieldPermissionDef(grantedFields, deniedFields)), expected, "xfield").     // some other checks     grantedFields = new String[] { "field*" }.     deniedFields = new String[] { "field1", "field2" }.     expected = new HashSet<>(META_FIELDS).     expected.add("field3").     assertResolved(new FieldPermissions(fieldPermissionDef(grantedFields, deniedFields)), expected, "field1", "field2").     grantedFields = new String[] { "field1", "field2" }.     deniedFields = new String[] { "field2" }.     expected = new HashSet<>(META_FIELDS).     expected.add("field1").     assertResolved(new FieldPermissions(fieldPermissionDef(grantedFields, deniedFields)), expected, "field1", "field2").     grantedFields = new String[] { "field*" }.     deniedFields = new String[] { "field2" }.     expected = new HashSet<>(META_FIELDS).     expected.add("field1").     assertResolved(new FieldPermissions(fieldPermissionDef(grantedFields, deniedFields)), expected, "field2").     deniedFields = new String[] { "field*" }.     assertResolved(new FieldPermissions(fieldPermissionDef(grantedFields, deniedFields)), META_FIELDS, "field1", "field2").     // empty array for allowed fields always means no field is allowed     grantedFields = new String[] {}.     deniedFields = new String[] {}.     assertResolved(new FieldPermissions(fieldPermissionDef(grantedFields, deniedFields)), META_FIELDS, "field1", "field2").     // make sure all field can be explicitly allowed     grantedFields = new String[] { "*" }.     deniedFields = randomBoolean() ? null : new String[] {}.     expected = new HashSet<>(META_FIELDS).     expected.add("field1").     assertResolved(new FieldPermissions(fieldPermissionDef(grantedFields, deniedFields)), expected). }
false;private;3;9;;private SparseFixedBitSet query(LeafReaderContext leaf, String field, String value) throws IOException {     SparseFixedBitSet sparseFixedBitSet = new SparseFixedBitSet(leaf.reader().maxDoc()).     TermsEnum tenum = leaf.reader().terms(field).iterator().     while (tenum.next().utf8ToString().equals(value) == false) {     }     PostingsEnum penum = tenum.postings(null).     sparseFixedBitSet.or(penum).     return sparseFixedBitSet. }
false;public;0;3;;public void testIndexSearcherWrapperSparseNoDeletions() throws IOException {     doTestIndexSearcherWrapper(true, false). }
false;public;0;3;;public void testIndexSearcherWrapperDenseNoDeletions() throws IOException {     doTestIndexSearcherWrapper(false, false). }
false;public;0;3;;public void testIndexSearcherWrapperSparseWithDeletions() throws IOException {     doTestIndexSearcherWrapper(true, true). }
false;public;0;3;;public void testIndexSearcherWrapperDenseWithDeletions() throws IOException {     doTestIndexSearcherWrapper(false, true). }
false;public;1;4;;@Override public void extractTerms(Set<Term> terms) {     weight.extractTerms(terms). }
false;public;2;4;;@Override public Explanation explain(LeafReaderContext context, int doc) throws IOException {     return weight.explain(context, doc). }
false;public;1;5;;@Override public Scorer scorer(LeafReaderContext context) throws IOException {     assertTrue(seenLeaves.add(context.reader().getCoreCacheHelper().getKey())).     return weight.scorer(context). }
false;public;1;6;;@Override public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {     assertTrue(seenLeaves.add(context.reader().getCoreCacheHelper().getKey())).     return weight.bulkScorer(context). }
false;public;1;4;;@Override public boolean isCacheable(LeafReaderContext ctx) {     return true. }
false;public;1;4;;@Override public String toString(String field) {     return query.toString(field). }
false;public;1;8;;@Override public Query rewrite(IndexReader reader) throws IOException {     Query queryRewritten = query.rewrite(reader).     if (query != queryRewritten) {         return new CreateScorerOnceQuery(queryRewritten).     }     return super.rewrite(reader). }
false;public;3;4;;@Override public Weight createWeight(IndexSearcher searcher, org.apache.lucene.search.ScoreMode scoreMode, float boost) throws IOException {     return new CreateScorerOnceWeight(query.createWeight(searcher, scoreMode, boost)). }
false;public;1;4;;@Override public boolean equals(Object obj) {     return sameClassAs(obj) && query.equals(((CreateScorerOnceQuery) obj).query). }
false;public;0;4;;@Override public int hashCode() {     return 31 * classHash() + query.hashCode(). }
false;public;2;4;;@Override public void onCache(ShardId shardId, Accountable accountable) { }
false;public;2;4;;@Override public void onRemoval(ShardId shardId, Accountable accountable) { }
false;public;2;61;;public void doTestIndexSearcherWrapper(boolean sparse, boolean deletions) throws IOException {     Directory dir = newDirectory().     IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(null)).     Document doc = new Document().     StringField allowedField = new StringField("allowed", "yes", Store.NO).     doc.add(allowedField).     StringField fooField = new StringField("foo", "bar", Store.NO).     doc.add(fooField).     StringField deleteField = new StringField("delete", "no", Store.NO).     doc.add(deleteField).     w.addDocument(doc).     if (deletions) {         // add a document that matches foo:bar but will be deleted         deleteField.setStringValue("yes").         w.addDocument(doc).         deleteField.setStringValue("no").     }     allowedField.setStringValue("no").     w.addDocument(doc).     if (sparse) {         for (int i = 0. i < 1000. ++i) {             w.addDocument(doc).         }         w.forceMerge(1).     }     w.deleteDocuments(new Term("delete", "yes")).     IndexSettings settings = IndexSettingsModule.newIndexSettings("_index", Settings.EMPTY).     BitsetFilterCache.Listener listener = new BitsetFilterCache.Listener() {          @Override         public void onCache(ShardId shardId, Accountable accountable) {         }          @Override         public void onRemoval(ShardId shardId, Accountable accountable) {         }     }.     DirectoryReader reader = ElasticsearchDirectoryReader.wrap(DirectoryReader.open(w), new ShardId(indexSettings.getIndex(), 0)).     BitsetFilterCache cache = new BitsetFilterCache(settings, listener).     Query roleQuery = new TermQuery(new Term("allowed", "yes")).     BitSet bitSet = cache.getBitSetProducer(roleQuery).getBitSet(reader.leaves().get(0)).     if (sparse) {         assertThat(bitSet, instanceOf(SparseFixedBitSet.class)).     } else {         assertThat(bitSet, instanceOf(FixedBitSet.class)).     }     DocumentSubsetDirectoryReader filteredReader = DocumentSubsetReader.wrap(reader, cache, roleQuery).     IndexSearcher searcher = new SecurityIndexSearcherWrapper.IndexSearcherWrapper(filteredReader).     // Searching a non-existing term will trigger a null scorer     assertEquals(0, searcher.count(new TermQuery(new Term("non_existing_field", "non_existing_value")))).     assertEquals(1, searcher.count(new TermQuery(new Term("foo", "bar")))).     // make sure scorers are created only once, see #1725     assertEquals(1, searcher.count(new CreateScorerOnceQuery(new MatchAllDocsQuery()))).     IOUtils.close(reader, w, dir). }
false;private,static;2;3;;private static FieldPermissionsDefinition fieldPermissionDef(String[] granted, String[] denied) {     return new FieldPermissionsDefinition(granted, denied). }
