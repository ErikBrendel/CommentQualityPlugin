commented;modifiers;parameterAmount;loc;comment;code
false;protected;0;4;;@Override protected String executor() {     return ThreadPool.Names.SAME. }
false;protected;0;4;;@Override protected PutDataFrameTransformAction.Response newResponse() {     return new PutDataFrameTransformAction.Response(). }
false;protected;3;75;;@Override protected void masterOperation(Request request, ClusterState clusterState, ActionListener<Response> listener) throws Exception {     if (!licenseState.isDataFrameAllowed()) {         listener.onFailure(LicenseUtils.newComplianceException(XPackField.DATA_FRAME)).         return.     }     XPackPlugin.checkReadyForXPackCustomMetadata(clusterState).     // set headers to run data frame transform as calling user     Map<String, String> filteredHeaders = threadPool.getThreadContext().getHeaders().entrySet().stream().filter(e -> ClientHelper.SECURITY_HEADER_FILTERS.contains(e.getKey())).collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue)).     DataFrameTransformConfig config = request.getConfig().     config.setHeaders(filteredHeaders).     String transformId = config.getId().     // quick check whether a transform has already been created under that name     if (PersistentTasksCustomMetaData.getTaskWithId(clusterState, transformId) != null) {         listener.onFailure(new ResourceAlreadyExistsException(DataFrameMessages.getMessage(DataFrameMessages.REST_PUT_DATA_FRAME_TRANSFORM_EXISTS, transformId))).         return.     }     // create the transform, for now we only have pivot and no support for custom queries     Pivot pivot = new Pivot(config.getSource(), new MatchAllQueryBuilder(), config.getPivotConfig()).     // the non-state creating steps are done first, so we minimize the chance to end up with orphaned state transform validation     pivot.validate(client, ActionListener.wrap(validationResult -> {         // deduce target mappings         pivot.deduceMappings(client, ActionListener.wrap(mappings -> {             // create the destination index             DataframeIndex.createDestinationIndex(client, config, mappings, ActionListener.wrap(createIndexResult -> {                 DataFrameTransform transform = createDataFrameTransform(transformId, threadPool).                 // create the transform configuration and store it in the internal index                 dataFrameTransformsConfigManager.putTransformConfiguration(config, ActionListener.wrap(r -> {                     // finally start the persistent task                     persistentTasksService.sendStartRequest(transform.getId(), DataFrameTransform.NAME, transform, ActionListener.wrap(persistentTask -> {                         listener.onResponse(new PutDataFrameTransformAction.Response(true)).                     }, startPersistentTaskException -> {                         // delete the otherwise orphaned transform configuration, for now we do not delete the destination index                         dataFrameTransformsConfigManager.deleteTransformConfiguration(transformId, ActionListener.wrap(r2 -> {                             logger.debug("Deleted data frame transform [{}] configuration from data frame configuration index", transformId).                             listener.onFailure(new RuntimeException(DataFrameMessages.getMessage(DataFrameMessages.REST_PUT_DATA_FRAME_FAILED_TO_START_PERSISTENT_TASK, r2), startPersistentTaskException)).                         }, deleteTransformFromIndexException -> {                             logger.error("Failed to cleanup orphaned data frame transform [{}] configuration", transformId).                             listener.onFailure(new RuntimeException(DataFrameMessages.getMessage(DataFrameMessages.REST_PUT_DATA_FRAME_FAILED_TO_START_PERSISTENT_TASK, false), startPersistentTaskException)).                         })).                     })).                 }, listener::onFailure)).             }, createDestinationIndexException -> {                 listener.onFailure(new RuntimeException(DataFrameMessages.REST_PUT_DATA_FRAME_FAILED_TO_CREATE_TARGET_INDEX, createDestinationIndexException)).             })).         }, deduceTargetMappingsException -> {             listener.onFailure(new RuntimeException(DataFrameMessages.REST_PUT_DATA_FRAME_FAILED_TO_DEDUCE_TARGET_MAPPINGS, deduceTargetMappingsException)).         })).     }, validationException -> {         listener.onFailure(new RuntimeException(DataFrameMessages.REST_PUT_DATA_FRAME_FAILED_TO_VALIDATE_DATA_FRAME_CONFIGURATION, validationException)).     })). }
false;private,static;2;3;;private static DataFrameTransform createDataFrameTransform(String transformId, ThreadPool threadPool) {     return new DataFrameTransform(transformId). }
false;protected;2;4;;@Override protected ClusterBlockException checkBlock(PutDataFrameTransformAction.Request request, ClusterState state) {     return state.blocks().globalBlockedException(ClusterBlockLevel.METADATA_WRITE). }
