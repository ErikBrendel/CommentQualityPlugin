commented;modifiers;parameterAmount;loc;comment;code
true;public;1;34;/**  * Ensure that watcher can be reloaded, by checking if all indices are marked as up and ready in the cluster state  * @param state The current cluster state  * @return true if everything is good to go, so that the service can be started  */ ;/**  * Ensure that watcher can be reloaded, by checking if all indices are marked as up and ready in the cluster state  * @param state The current cluster state  * @return true if everything is good to go, so that the service can be started  */ public boolean validate(ClusterState state) {     // template check makes only sense for non existing indices, we could refine this     boolean hasValidWatcherTemplates = WatcherIndexTemplateRegistry.validate(state).     if (hasValidWatcherTemplates == false) {         logger.debug("missing watcher index templates, not starting watcher service").         return false.     }     IndexMetaData watcherIndexMetaData = WatchStoreUtils.getConcreteIndex(Watch.INDEX, state.metaData()).     IndexMetaData triggeredWatchesIndexMetaData = WatchStoreUtils.getConcreteIndex(TriggeredWatchStoreField.INDEX_NAME, state.metaData()).     boolean isIndexInternalFormatWatchIndex = watcherIndexMetaData == null || UpgradeField.checkInternalIndexFormat(watcherIndexMetaData).     boolean isIndexInternalFormatTriggeredWatchIndex = triggeredWatchesIndexMetaData == null || UpgradeField.checkInternalIndexFormat(triggeredWatchesIndexMetaData).     if (isIndexInternalFormatTriggeredWatchIndex == false || isIndexInternalFormatWatchIndex == false) {         logger.warn("not starting watcher, upgrade API run required: .watches[{}], .triggered_watches[{}]", isIndexInternalFormatWatchIndex, isIndexInternalFormatTriggeredWatchIndex).         return false.     }     try {         boolean storesValid = TriggeredWatchStore.validate(state) && HistoryStore.validate(state).         if (storesValid == false) {             return false.         }         return watcherIndexMetaData == null || (watcherIndexMetaData.getState() == IndexMetaData.State.OPEN && state.routingTable().index(watcherIndexMetaData.getIndex()).allPrimaryShardsActive()).     } catch (IllegalStateException e) {         logger.debug("error validating to start watcher", e).         return false.     } }
true;public;1;5;/**  * Stops the watcher service and marks its services as paused  */ ;/**  * Stops the watcher service and marks its services as paused  */ public void stop(String reason) {     logger.info("stopping watch service, reason [{}]", reason).     executionService.pause().     triggerService.pauseExecution(). }
true;;0;7;/**  * shuts down the trigger service as well to make sure there are no lingering threads  * also no need to check anything, as this is final, we just can go to status STOPPED  */ ;/**  * shuts down the trigger service as well to make sure there are no lingering threads  * also no need to check anything, as this is final, we just can go to status STOPPED  */ void shutDown() {     logger.info("stopping watch service, reason [shutdown initiated]").     executionService.pause().     triggerService.stop().     stopExecutor().     logger.debug("watch service has stopped"). }
false;;0;3;;void stopExecutor() {     ThreadPool.terminate(executor, 10L, TimeUnit.SECONDS). }
true;;2;19;/**  * Reload the watcher service, does not switch the state from stopped to started, just keep going  * @param state cluster state, which is needed to find out about local shards  */ ;/**  * Reload the watcher service, does not switch the state from stopped to started, just keep going  * @param state cluster state, which is needed to find out about local shards  */ void reload(ClusterState state, String reason) {     // this method contains the only async code block, being called by the cluster state listener     // the reason for this is, that loading he watches is done in a sync manner and thus cannot be done on the cluster state listener     // thread     //      // this method itself is called by the cluster state listener, so will never be called in parallel     // setting the cluster state version allows us to know if the async method has been overtaken by another async method     // this is unlikely, but can happen, if the thread pool schedules two of those runnables at the same time     // by checking the cluster state version before and after loading the watches we can potentially just exit without applying the     // changes     processedClusterStateVersion.set(state.getVersion()).     triggerService.pauseExecution().     int cancelledTaskCount = executionService.clearExecutionsAndQueue().     logger.info("reloading watcher, reason [{}], cancelled [{}] queued tasks", reason, cancelledTaskCount).     executor.execute(wrapWatcherService(() -> reloadInner(state, reason, false), e -> logger.error("error reloading watcher", e))). }
true;public;2;10;/**  * start the watcher service, load watches in the background  *  * @param state                     the current cluster state  * @param postWatchesLoadedCallback the callback to be triggered, when watches where loaded successfully  */ ;/**  * start the watcher service, load watches in the background  *  * @param state                     the current cluster state  * @param postWatchesLoadedCallback the callback to be triggered, when watches where loaded successfully  */ public void start(ClusterState state, Runnable postWatchesLoadedCallback) {     executionService.unPause().     processedClusterStateVersion.set(state.getVersion()).     executor.execute(wrapWatcherService(() -> {         if (reloadInner(state, "starting", true)) {             postWatchesLoadedCallback.run().         }     }, e -> logger.error("error starting watcher", e))). }
true;private,synchronized;3;32;/**  * reload watches and start scheduling them  *  * @param state                 the current cluster state  * @param reason                the reason for reloading, will be logged  * @param loadTriggeredWatches  should triggered watches be loaded in this run, not needed for reloading, only for starting  * @return                      true if no other loading of a newer cluster state happened in parallel, false otherwise  */ ;/**  * reload watches and start scheduling them  *  * @param state                 the current cluster state  * @param reason                the reason for reloading, will be logged  * @param loadTriggeredWatches  should triggered watches be loaded in this run, not needed for reloading, only for starting  * @return                      true if no other loading of a newer cluster state happened in parallel, false otherwise  */ private synchronized boolean reloadInner(ClusterState state, String reason, boolean loadTriggeredWatches) {     // exit early if another thread has come in between     if (processedClusterStateVersion.get() != state.getVersion()) {         logger.debug("watch service has not been reloaded for state [{}], another reload for state [{}] in progress", state.getVersion(), processedClusterStateVersion.get()).         return false.     }     Collection<Watch> watches = loadWatches(state).     Collection<TriggeredWatch> triggeredWatches = Collections.emptyList().     if (loadTriggeredWatches) {         triggeredWatches = triggeredWatchStore.findTriggeredWatches(watches, state).     }     // that existing executions finish, but no new ones are executed     if (processedClusterStateVersion.get() == state.getVersion()) {         executionService.unPause().         triggerService.start(watches).         if (triggeredWatches.isEmpty() == false) {             executionService.executeTriggeredWatches(triggeredWatches).         }         logger.debug("watch service has been reloaded, reason [{}]", reason).         return true.     } else {         logger.debug("watch service has not been reloaded for state [{}], another reload for state [{}] in progress", state.getVersion(), processedClusterStateVersion.get()).         return false.     } }
true;public;1;5;/**  * Stop execution of watches on this node, do not try to reload anything, but still allow  * manual watch execution, i.e. via the execute watch API  */ ;/**  * Stop execution of watches on this node, do not try to reload anything, but still allow  * manual watch execution, i.e. via the execute watch API  */ public void pauseExecution(String reason) {     triggerService.pauseExecution().     int cancelledTaskCount = executionService.pause().     logger.info("paused watch execution, reason [{}], cancelled [{}] queued tasks", reason, cancelledTaskCount). }
true;private;1;102;/**  * This reads all watches from the .watches index/alias and puts them into memory for a short period of time,  * before they are fed into the trigger service.  */ ;/**  * This reads all watches from the .watches index/alias and puts them into memory for a short period of time,  * before they are fed into the trigger service.  */ private Collection<Watch> loadWatches(ClusterState clusterState) {     IndexMetaData indexMetaData = WatchStoreUtils.getConcreteIndex(INDEX, clusterState.metaData()).     // no index exists, all good, we can start     if (indexMetaData == null) {         return Collections.emptyList().     }     SearchResponse response = null.     List<Watch> watches = new ArrayList<>().     try {         RefreshResponse refreshResponse = client.admin().indices().refresh(new RefreshRequest(INDEX)).actionGet(TimeValue.timeValueSeconds(5)).         if (refreshResponse.getSuccessfulShards() < indexMetaData.getNumberOfShards()) {             throw illegalState("not all required shards have been refreshed").         }         // find out local shards         String watchIndexName = indexMetaData.getIndex().getName().         RoutingNode routingNode = clusterState.getRoutingNodes().node(clusterState.nodes().getLocalNodeId()).         // yes, this can happen, if the state is not recovered         if (routingNode == null) {             return Collections.emptyList().         }         List<ShardRouting> localShards = routingNode.shardsWithState(watchIndexName, RELOCATING, STARTED).         // find out all allocation ids         List<ShardRouting> watchIndexShardRoutings = clusterState.getRoutingTable().allShards(watchIndexName).         SearchRequest searchRequest = new SearchRequest(INDEX).scroll(scrollTimeout).preference(Preference.ONLY_LOCAL.toString()).source(new SearchSourceBuilder().size(scrollSize).sort(SortBuilders.fieldSort("_doc")).seqNoAndPrimaryTerm(true)).         response = client.search(searchRequest).actionGet(defaultSearchTimeout).         if (response.getTotalShards() != response.getSuccessfulShards()) {             throw new ElasticsearchException("Partial response while loading watches").         }         if (response.getHits().getTotalHits().value == 0) {             return Collections.emptyList().         }         Map<Integer, List<String>> sortedShards = new HashMap<>(localShards.size()).         for (ShardRouting localShardRouting : localShards) {             List<String> sortedAllocationIds = watchIndexShardRoutings.stream().filter(sr -> localShardRouting.getId() == sr.getId()).map(ShardRouting::allocationId).filter(Objects::nonNull).map(AllocationId::getId).filter(Objects::nonNull).sorted().collect(Collectors.toList()).             sortedShards.put(localShardRouting.getId(), sortedAllocationIds).         }         while (response.getHits().getHits().length != 0) {             for (SearchHit hit : response.getHits()) {                 // find out if this hit should be processed locally                 Optional<ShardRouting> correspondingShardOptional = localShards.stream().filter(sr -> sr.shardId().equals(hit.getShard().getShardId())).findFirst().                 if (correspondingShardOptional.isPresent() == false) {                     continue.                 }                 ShardRouting correspondingShard = correspondingShardOptional.get().                 List<String> shardAllocationIds = sortedShards.get(hit.getShard().getShardId().id()).                 // based on the shard allocation ids, get the bucket of the shard, this hit was in                 int bucket = shardAllocationIds.indexOf(correspondingShard.allocationId().getId()).                 String id = hit.getId().                 if (parseWatchOnThisNode(hit.getId(), shardAllocationIds.size(), bucket) == false) {                     continue.                 }                 try {                     Watch watch = parser.parse(id, true, hit.getSourceRef(), XContentType.JSON, hit.getSeqNo(), hit.getPrimaryTerm()).                     if (watch.status().state().isActive()) {                         watches.add(watch).                     }                 } catch (Exception e) {                     logger.error((org.apache.logging.log4j.util.Supplier<?>) () -> new ParameterizedMessage("couldn't load watch [{}], ignoring it...", id), e).                 }             }             SearchScrollRequest request = new SearchScrollRequest(response.getScrollId()).             request.scroll(scrollTimeout).             response = client.searchScroll(request).actionGet(defaultSearchTimeout).         }     } finally {         if (response != null) {             ClearScrollRequest clearScrollRequest = new ClearScrollRequest().             clearScrollRequest.addScrollId(response.getScrollId()).             client.clearScroll(clearScrollRequest).actionGet(scrollTimeout).         }     }     logger.debug("Loaded [{}] watches for execution", watches.size()).     return watches. }
true;private;3;5;/**  * Find out if the watch with this id, should be parsed and triggered on this node  *  * @param id              The id of the watch  * @param totalShardCount The count of all primary shards of the current watches index  * @param index           The index of the local shard  * @return true if the we should parse the watch on this node, false otherwise  */ ;/**  * Find out if the watch with this id, should be parsed and triggered on this node  *  * @param id              The id of the watch  * @param totalShardCount The count of all primary shards of the current watches index  * @param index           The index of the local shard  * @return true if the we should parse the watch on this node, false otherwise  */ private boolean parseWatchOnThisNode(String id, int totalShardCount, int index) {     int hash = Murmur3HashFunction.hash(id).     int shardIndex = Math.floorMod(hash, totalShardCount).     return shardIndex == index. }
false;public;1;4;;@Override public void onFailure(Exception e) {     exceptionConsumer.accept(e). }
false;protected;0;4;;@Override protected void doRun() throws Exception {     run.run(). }
true;private,static;2;13;/**  * Wraps an abstract runnable to easier supply onFailure and doRun methods via lambdas  * This ensures that the uncaught exception handler in the executing threadpool does not get called  *  * @param run                 The code to be executed in the runnable  * @param exceptionConsumer   The exception handling code to be executed, if the runnable fails  * @return                    The AbstractRunnable instance to pass to the executor  */ ;/**  * Wraps an abstract runnable to easier supply onFailure and doRun methods via lambdas  * This ensures that the uncaught exception handler in the executing threadpool does not get called  *  * @param run                 The code to be executed in the runnable  * @param exceptionConsumer   The exception handling code to be executed, if the runnable fails  * @return                    The AbstractRunnable instance to pass to the executor  */ private static AbstractRunnable wrapWatcherService(Runnable run, Consumer<Exception> exceptionConsumer) {     return new AbstractRunnable() {          @Override         public void onFailure(Exception e) {             exceptionConsumer.accept(e).         }          @Override         protected void doRun() throws Exception {             run.run().         }     }. }
