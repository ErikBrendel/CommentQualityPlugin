commented;modifiers;parameterAmount;loc;comment;code
false;public;0;4;;@Override public Response newResponse() {     return new Response(). }
false;public;0;3;;public ShardId getShard() {     return shardId. }
false;public;0;3;;public long getFromSeqNo() {     return fromSeqNo. }
false;public;1;3;;public void setFromSeqNo(long fromSeqNo) {     this.fromSeqNo = fromSeqNo. }
false;public;0;3;;public int getMaxOperationCount() {     return maxOperationCount. }
false;public;1;3;;public void setMaxOperationCount(int maxOperationCount) {     this.maxOperationCount = maxOperationCount. }
false;public;0;3;;public ByteSizeValue getMaxBatchSize() {     return maxBatchSize. }
false;public;1;3;;public void setMaxBatchSize(ByteSizeValue maxBatchSize) {     this.maxBatchSize = maxBatchSize. }
false;public;0;3;;public String getExpectedHistoryUUID() {     return expectedHistoryUUID. }
false;public;0;3;;public TimeValue getPollTimeout() {     return pollTimeout. }
false;public;1;3;;public void setPollTimeout(final TimeValue pollTimeout) {     this.pollTimeout = Objects.requireNonNull(pollTimeout, "pollTimeout"). }
false;public;0;16;;@Override public ActionRequestValidationException validate() {     ActionRequestValidationException validationException = null.     if (fromSeqNo < 0) {         validationException = addValidationError("fromSeqNo [" + fromSeqNo + "] cannot be lower than 0", validationException).     }     if (maxOperationCount < 0) {         validationException = addValidationError("maxOperationCount [" + maxOperationCount + "] cannot be lower than 0", validationException).     }     if (maxBatchSize.compareTo(ByteSizeValue.ZERO) <= 0) {         validationException = addValidationError("maxBatchSize [" + maxBatchSize.getStringRep() + "] must be larger than 0", validationException).     }     return validationException. }
false;public;1;13;;@Override public void readFrom(StreamInput in) throws IOException {     super.readFrom(in).     fromSeqNo = in.readVLong().     maxOperationCount = in.readVInt().     shardId = ShardId.readShardId(in).     expectedHistoryUUID = in.readString().     pollTimeout = in.readTimeValue().     maxBatchSize = new ByteSizeValue(in).     // Starting the clock in order to know how much time is spent on fetching operations:     relativeStartNanos = System.nanoTime(). }
false;public;1;10;;@Override public void writeTo(StreamOutput out) throws IOException {     super.writeTo(out).     out.writeVLong(fromSeqNo).     out.writeVInt(maxOperationCount).     shardId.writeTo(out).     out.writeString(expectedHistoryUUID).     out.writeTimeValue(pollTimeout).     maxBatchSize.writeTo(out). }
false;public;1;12;;@Override public boolean equals(final Object o) {     if (this == o)         return true.     if (o == null || getClass() != o.getClass())         return false.     final Request request = (Request) o.     return fromSeqNo == request.fromSeqNo && maxOperationCount == request.maxOperationCount && Objects.equals(shardId, request.shardId) && Objects.equals(expectedHistoryUUID, request.expectedHistoryUUID) && Objects.equals(pollTimeout, request.pollTimeout) && maxBatchSize.equals(request.maxBatchSize). }
false;public;0;4;;@Override public int hashCode() {     return Objects.hash(fromSeqNo, maxOperationCount, shardId, expectedHistoryUUID, pollTimeout, maxBatchSize). }
false;public;0;11;;@Override public String toString() {     return "Request{" + "fromSeqNo=" + fromSeqNo + ", maxOperationCount=" + maxOperationCount + ", shardId=" + shardId + ", expectedHistoryUUID=" + expectedHistoryUUID + ", pollTimeout=" + pollTimeout + ", maxBatchSize=" + maxBatchSize.getStringRep() + '}'. }
false;public;0;3;;public long getMappingVersion() {     return mappingVersion. }
false;public;0;3;;public long getSettingsVersion() {     return settingsVersion. }
false;public;0;3;;public long getGlobalCheckpoint() {     return globalCheckpoint. }
false;public;0;3;;public long getMaxSeqNo() {     return maxSeqNo. }
false;public;0;3;;public long getMaxSeqNoOfUpdatesOrDeletes() {     return maxSeqNoOfUpdatesOrDeletes. }
false;public;0;3;;public Translog.Operation[] getOperations() {     return operations. }
false;public;0;3;;public long getTookInMillis() {     return tookInMillis. }
false;public;1;11;;@Override public void readFrom(final StreamInput in) throws IOException {     super.readFrom(in).     mappingVersion = in.readVLong().     settingsVersion = in.readVLong().     globalCheckpoint = in.readZLong().     maxSeqNo = in.readZLong().     maxSeqNoOfUpdatesOrDeletes = in.readZLong().     operations = in.readArray(Translog.Operation::readOperation, Translog.Operation[]::new).     tookInMillis = in.readVLong(). }
false;public;1;11;;@Override public void writeTo(final StreamOutput out) throws IOException {     super.writeTo(out).     out.writeVLong(mappingVersion).     out.writeVLong(settingsVersion).     out.writeZLong(globalCheckpoint).     out.writeZLong(maxSeqNo).     out.writeZLong(maxSeqNoOfUpdatesOrDeletes).     out.writeArray(Translog.Operation::writeOperation, operations).     out.writeVLong(tookInMillis). }
false;public;1;13;;@Override public boolean equals(final Object o) {     if (this == o)         return true.     if (o == null || getClass() != o.getClass())         return false.     final Response that = (Response) o.     return mappingVersion == that.mappingVersion && settingsVersion == that.settingsVersion && globalCheckpoint == that.globalCheckpoint && maxSeqNo == that.maxSeqNo && maxSeqNoOfUpdatesOrDeletes == that.maxSeqNoOfUpdatesOrDeletes && Arrays.equals(operations, that.operations) && tookInMillis == that.tookInMillis. }
false;public;0;11;;@Override public int hashCode() {     return Objects.hash(mappingVersion, settingsVersion, globalCheckpoint, maxSeqNo, maxSeqNoOfUpdatesOrDeletes, Arrays.hashCode(operations), tookInMillis). }
false;protected;2;28;;@Override protected Response shardOperation(Request request, ShardId shardId) throws IOException {     final IndexService indexService = indicesService.indexServiceSafe(request.getShard().getIndex()).     final IndexShard indexShard = indexService.getShard(request.getShard().id()).     final SeqNoStats seqNoStats = indexShard.seqNoStats().     final Translog.Operation[] operations = getOperations(indexShard, seqNoStats.getGlobalCheckpoint(), request.getFromSeqNo(), request.getMaxOperationCount(), request.getExpectedHistoryUUID(), request.getMaxBatchSize()).     // must capture after snapshotting operations to ensure this MUS is at least the highest MUS of any of these operations.     final long maxSeqNoOfUpdatesOrDeletes = indexShard.getMaxSeqNoOfUpdatesOrDeletes().     // must capture IndexMetaData after snapshotting operations to ensure the returned mapping version is at least as up-to-date     // as the mapping version that these operations used. Here we must not use IndexMetaData from ClusterService for we expose     // a new cluster state to ClusterApplier(s) before exposing it in the ClusterService.     final IndexMetaData indexMetaData = indexService.getMetaData().     final long mappingVersion = indexMetaData.getMappingVersion().     final long settingsVersion = indexMetaData.getSettingsVersion().     return getResponse(mappingVersion, settingsVersion, seqNoStats, maxSeqNoOfUpdatesOrDeletes, operations, request.relativeStartNanos). }
false;protected;3;32;;@Override protected void asyncShardOperation(final Request request, final ShardId shardId, final ActionListener<Response> listener) throws IOException {     final IndexService indexService = indicesService.indexServiceSafe(request.getShard().getIndex()).     final IndexShard indexShard = indexService.getShard(request.getShard().id()).     final SeqNoStats seqNoStats = indexShard.seqNoStats().     if (request.getFromSeqNo() > seqNoStats.getGlobalCheckpoint()) {         logger.trace("{} waiting for global checkpoint advancement from [{}] to [{}]", shardId, seqNoStats.getGlobalCheckpoint(), request.getFromSeqNo()).         indexShard.addGlobalCheckpointListener(request.getFromSeqNo(), (g, e) -> {             if (g != UNASSIGNED_SEQ_NO) {                 assert request.getFromSeqNo() <= g : shardId + " only advanced to [" + g + "] while waiting for [" + request.getFromSeqNo() + "]".                 globalCheckpointAdvanced(shardId, g, request, listener).             } else {                 assert e != null.                 globalCheckpointAdvancementFailure(shardId, e, request, listener, indexShard).             }         }, request.getPollTimeout()).     } else {         super.asyncShardOperation(request, shardId, listener).     } }
false;private;4;12;;private void globalCheckpointAdvanced(final ShardId shardId, final long globalCheckpoint, final Request request, final ActionListener<Response> listener) {     logger.trace("{} global checkpoint advanced to [{}] after waiting for [{}]", shardId, globalCheckpoint, request.getFromSeqNo()).     try {         super.asyncShardOperation(request, shardId, listener).     } catch (final IOException caught) {         listener.onFailure(caught).     } }
false;private;5;38;;private void globalCheckpointAdvancementFailure(final ShardId shardId, final Exception e, final Request request, final ActionListener<Response> listener, final IndexShard indexShard) {     logger.trace(() -> new ParameterizedMessage("{} exception waiting for global checkpoint advancement to [{}]", shardId, request.getFromSeqNo()), e).     if (e instanceof TimeoutException) {         try {             final IndexMetaData indexMetaData = clusterService.state().metaData().index(shardId.getIndex()).             if (indexMetaData == null) {                 listener.onFailure(new IndexNotFoundException(shardId.getIndex())).                 return.             }             final long mappingVersion = indexMetaData.getMappingVersion().             final long settingsVersion = indexMetaData.getSettingsVersion().             final SeqNoStats latestSeqNoStats = indexShard.seqNoStats().             final long maxSeqNoOfUpdatesOrDeletes = indexShard.getMaxSeqNoOfUpdatesOrDeletes().             listener.onResponse(getResponse(mappingVersion, settingsVersion, latestSeqNoStats, maxSeqNoOfUpdatesOrDeletes, EMPTY_OPERATIONS_ARRAY, request.relativeStartNanos)).         } catch (final Exception caught) {             caught.addSuppressed(e).             listener.onFailure(caught).         }     } else {         listener.onFailure(e).     } }
false;protected;1;4;;@Override protected boolean resolveIndex(Request request) {     return false. }
false;protected;2;7;;@Override protected ShardsIterator shards(ClusterState state, InternalRequest request) {     return state.routingTable().shardRoutingTable(request.concreteIndex(), request.request().getShard().id()).activeInitializingShardsRandomIt(). }
false;protected;0;4;;@Override protected Response newResponse() {     return new Response(). }
true;static;6;44;/**  * Returns at most the specified maximum number of operations from the specified from sequence number. This method will never return  * operations above the specified global checkpoint.  *  * Also if the sum of collected operations size is above the specified maximum batch size then this method stops collecting more  * operations and returns what has been collected so far.  *  * @param indexShard the shard  * @param globalCheckpoint the global checkpoint  * @param fromSeqNo the starting sequence number  * @param maxOperationCount the maximum number of operations  * @param expectedHistoryUUID the expected history UUID for the shard  * @param maxBatchSize the maximum batch size  * @return the operations  * @throws IOException if an I/O exception occurs reading the operations  */ ;/**  * Returns at most the specified maximum number of operations from the specified from sequence number. This method will never return  * operations above the specified global checkpoint.  *  * Also if the sum of collected operations size is above the specified maximum batch size then this method stops collecting more  * operations and returns what has been collected so far.  *  * @param indexShard the shard  * @param globalCheckpoint the global checkpoint  * @param fromSeqNo the starting sequence number  * @param maxOperationCount the maximum number of operations  * @param expectedHistoryUUID the expected history UUID for the shard  * @param maxBatchSize the maximum batch size  * @return the operations  * @throws IOException if an I/O exception occurs reading the operations  */ static Translog.Operation[] getOperations(final IndexShard indexShard, final long globalCheckpoint, final long fromSeqNo, final int maxOperationCount, final String expectedHistoryUUID, final ByteSizeValue maxBatchSize) throws IOException {     if (indexShard.state() != IndexShardState.STARTED) {         throw new IndexShardNotStartedException(indexShard.shardId(), indexShard.state()).     }     final String historyUUID = indexShard.getHistoryUUID().     if (historyUUID.equals(expectedHistoryUUID) == false) {         throw new IllegalStateException("unexpected history uuid, expected [" + expectedHistoryUUID + "], actual [" + historyUUID + "]").     }     if (fromSeqNo > globalCheckpoint) {         throw new IllegalStateException("not exposing operations from [" + fromSeqNo + "] greater than the global checkpoint [" + globalCheckpoint + "]").     }     int seenBytes = 0.     // - 1 is needed, because toSeqNo is inclusive     long toSeqNo = Math.min(globalCheckpoint, (fromSeqNo + maxOperationCount) - 1).     assert fromSeqNo <= toSeqNo : "invalid range from_seqno[" + fromSeqNo + "] > to_seqno[" + toSeqNo + "]".     final List<Translog.Operation> operations = new ArrayList<>().     try (Translog.Snapshot snapshot = indexShard.newChangesSnapshot("ccr", fromSeqNo, toSeqNo, true)) {         Translog.Operation op.         while ((op = snapshot.next()) != null) {             operations.add(op).             seenBytes += op.estimateSize().             if (seenBytes > maxBatchSize.getBytes()) {                 break.             }         }     } catch (MissingHistoryOperationsException e) {         String message = "Operations are no longer available for replicating. Maybe increase the retention setting [" + IndexSettings.INDEX_SOFT_DELETES_RETENTION_OPERATIONS_SETTING.getKey() + "]?".         // Make it easy to detect this error in ShardFollowNodeTask:         // (adding a metadata header instead of introducing a new exception that extends ElasticsearchException)         ResourceNotFoundException wrapper = new ResourceNotFoundException(message, e).         wrapper.addMetadata(Ccr.REQUESTED_OPS_MISSING_METADATA_KEY, Long.toString(fromSeqNo), Long.toString(toSeqNo)).         throw wrapper.     }     return operations.toArray(EMPTY_OPERATIONS_ARRAY). }
false;static;6;18;;static Response getResponse(final long mappingVersion, final long settingsVersion, final SeqNoStats seqNoStats, final long maxSeqNoOfUpdates, final Translog.Operation[] operations, long relativeStartNanos) {     long tookInNanos = System.nanoTime() - relativeStartNanos.     long tookInMillis = TimeUnit.NANOSECONDS.toMillis(tookInNanos).     return new Response(mappingVersion, settingsVersion, seqNoStats.getGlobalCheckpoint(), seqNoStats.getMaxSeqNo(), maxSeqNoOfUpdates, operations, tookInMillis). }
