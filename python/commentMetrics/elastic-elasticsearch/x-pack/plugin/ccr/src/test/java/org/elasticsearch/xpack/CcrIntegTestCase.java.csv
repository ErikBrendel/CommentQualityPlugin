commented;modifiers;parameterAmount;loc;comment;code
false;protected;0;3;;protected Collection<Class<? extends Plugin>> nodePlugins() {     return Collections.emptyList(). }
false;protected;0;3;;protected Settings leaderClusterSettings() {     return Settings.EMPTY. }
false;protected;0;3;;protected Settings followerClusterSettings() {     return Settings.EMPTY. }
false;public,final;0;36;;@Before public final void startClusters() throws Exception {     if (clusterGroup != null && reuseClusters()) {         clusterGroup.leaderCluster.ensureAtMostNumDataNodes(numberOfNodesPerCluster()).         clusterGroup.followerCluster.ensureAtMostNumDataNodes(numberOfNodesPerCluster()).         return.     }     stopClusters().     Collection<Class<? extends Plugin>> mockPlugins = Arrays.asList(ESIntegTestCase.TestSeedPlugin.class, MockHttpTransport.TestPlugin.class, MockTransportService.TestPlugin.class, MockNioTransportPlugin.class, InternalSettingsPlugin.class).     InternalTestCluster leaderCluster = new InternalTestCluster(randomLong(), createTempDir(), true, true, numberOfNodesPerCluster(), numberOfNodesPerCluster(), "leader_cluster", createNodeConfigurationSource(null, true), 0, "leader", mockPlugins, Function.identity()).     leaderCluster.beforeTest(random(), 0.0D).     leaderCluster.ensureAtLeastNumDataNodes(numberOfNodesPerCluster()).     assertBusy(() -> {         ClusterService clusterService = leaderCluster.getInstance(ClusterService.class).         assertNotNull(clusterService.state().metaData().custom(LicensesMetaData.TYPE)).     }).     String address = leaderCluster.getDataNodeInstance(TransportService.class).boundAddress().publishAddress().toString().     InternalTestCluster followerCluster = new InternalTestCluster(randomLong(), createTempDir(), true, true, numberOfNodesPerCluster(), numberOfNodesPerCluster(), "follower_cluster", createNodeConfigurationSource(address, false), 0, "follower", mockPlugins, Function.identity()).     clusterGroup = new ClusterGroup(leaderCluster, followerCluster).     followerCluster.beforeTest(random(), 0.0D).     followerCluster.ensureAtLeastNumDataNodes(numberOfNodesPerCluster()).     assertBusy(() -> {         ClusterService clusterService = followerCluster.getInstance(ClusterService.class).         assertNotNull(clusterService.state().metaData().custom(LicensesMetaData.TYPE)).     }). }
true;protected;1;7;/**  * Follower indices don't get all the settings from leader, for example 'index.unassigned.node_left.delayed_timeout'  * is not replicated and if tests kill nodes, we have to wait 60s by default...  */ ;/**  * Follower indices don't get all the settings from leader, for example 'index.unassigned.node_left.delayed_timeout'  * is not replicated and if tests kill nodes, we have to wait 60s by default...  */ protected void disableDelayedAllocation(String index) {     UpdateSettingsRequest updateSettingsRequest = new UpdateSettingsRequest(index).     Settings.Builder settingsBuilder = Settings.builder().     settingsBuilder.put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), 0).     updateSettingsRequest.settings(settingsBuilder).     assertAcked(followerClient().admin().indices().updateSettings(updateSettingsRequest).actionGet()). }
false;public;0;22;;@After public void afterTest() throws Exception {     ensureEmptyWriteBuffers().     String masterNode = clusterGroup.followerCluster.getMasterName().     ClusterService clusterService = clusterGroup.followerCluster.getInstance(ClusterService.class, masterNode).     removeCCRRelatedMetadataFromClusterState(clusterService).     try {         clusterGroup.leaderCluster.beforeIndexDeletion().         clusterGroup.leaderCluster.assertSeqNos().         clusterGroup.leaderCluster.assertSameDocIdsOnShards().         clusterGroup.leaderCluster.assertConsistentHistoryBetweenTranslogAndLuceneIndex().         clusterGroup.followerCluster.beforeIndexDeletion().         clusterGroup.followerCluster.assertSeqNos().         clusterGroup.followerCluster.assertSameDocIdsOnShards().         clusterGroup.followerCluster.assertConsistentHistoryBetweenTranslogAndLuceneIndex().     } finally {         clusterGroup.leaderCluster.wipe(Collections.emptySet()).         clusterGroup.followerCluster.wipe(Collections.emptySet()).     } }
false;public;1;4;;@Override public Settings nodeSettings(int nodeOrdinal) {     return builder.build(). }
false;public;1;4;;@Override public Path nodeConfigPath(int nodeOrdinal) {     return null. }
false;public;0;7;;@Override public Collection<Class<? extends Plugin>> nodePlugins() {     return Stream.concat(Stream.of(LocalStateCcr.class, CommonAnalysisPlugin.class), CcrIntegTestCase.this.nodePlugins().stream()).collect(Collectors.toList()). }
false;public;0;4;;@Override public Settings transportClientSettings() {     return super.transportClientSettings(). }
false;public;0;4;;@Override public Collection<Class<? extends Plugin>> transportClientPlugins() {     return Arrays.asList(LocalStateCcr.class, getTestTransportPlugin()). }
false;private;2;60;;private NodeConfigurationSource createNodeConfigurationSource(final String leaderSeedAddress, final boolean leaderCluster) {     Settings.Builder builder = Settings.builder().     builder.put(NodeEnvironment.MAX_LOCAL_STORAGE_NODES_SETTING.getKey(), Integer.MAX_VALUE).     // Default the watermarks to absurdly low to prevent the tests     // from failing on nodes without enough disk space     builder.put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK_SETTING.getKey(), "1b").     builder.put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK_SETTING.getKey(), "1b").     builder.put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_DISK_FLOOD_STAGE_WATERMARK_SETTING.getKey(), "1b").     builder.put(ScriptService.SCRIPT_MAX_COMPILATIONS_RATE.getKey(), "2048/1m").     // wait short time for other active shards before actually deleting, default 30s not needed in tests     builder.put(IndicesStore.INDICES_STORE_DELETE_SHARD_TIMEOUT.getKey(), new TimeValue(1, TimeUnit.SECONDS)).     // empty list disables a port scan for other nodes     builder.putList(DISCOVERY_SEED_HOSTS_SETTING.getKey()).     builder.putList(DISCOVERY_SEED_PROVIDERS_SETTING.getKey(), "file").     builder.put(NetworkModule.TRANSPORT_TYPE_KEY, getTestTransportType()).     builder.put(XPackSettings.SECURITY_ENABLED.getKey(), false).     builder.put(XPackSettings.MONITORING_ENABLED.getKey(), false).     builder.put(XPackSettings.WATCHER_ENABLED.getKey(), false).     builder.put(XPackSettings.MACHINE_LEARNING_ENABLED.getKey(), false).     builder.put(XPackSettings.LOGSTASH_ENABLED.getKey(), false).     builder.put(LicenseService.SELF_GENERATED_LICENSE_TYPE.getKey(), "trial").     // Let cluster state api return quickly in order to speed up auto follow tests:     builder.put(CcrSettings.CCR_WAIT_FOR_METADATA_TIMEOUT.getKey(), TimeValue.timeValueMillis(100)).     if (leaderCluster) {         builder.put(leaderClusterSettings()).     } else {         builder.put(followerClusterSettings()).     }     if (configureRemoteClusterViaNodeSettings() && leaderSeedAddress != null) {         builder.put("cluster.remote.leader_cluster.seeds", leaderSeedAddress).     }     return new NodeConfigurationSource() {          @Override         public Settings nodeSettings(int nodeOrdinal) {             return builder.build().         }          @Override         public Path nodeConfigPath(int nodeOrdinal) {             return null.         }          @Override         public Collection<Class<? extends Plugin>> nodePlugins() {             return Stream.concat(Stream.of(LocalStateCcr.class, CommonAnalysisPlugin.class), CcrIntegTestCase.this.nodePlugins().stream()).collect(Collectors.toList()).         }          @Override         public Settings transportClientSettings() {             return super.transportClientSettings().         }          @Override         public Collection<Class<? extends Plugin>> transportClientPlugins() {             return Arrays.asList(LocalStateCcr.class, getTestTransportPlugin()).         }     }. }
false;public,static;0;5;;@AfterClass public static void stopClusters() throws IOException {     IOUtils.close(clusterGroup).     clusterGroup = null. }
false;protected;0;3;;protected int numberOfNodesPerCluster() {     return 2. }
false;protected;0;3;;protected boolean reuseClusters() {     return true. }
false;protected;0;3;;protected boolean configureRemoteClusterViaNodeSettings() {     return true. }
false;protected,final;0;3;;protected final Client leaderClient() {     return clusterGroup.leaderCluster.client(). }
false;protected,final;0;3;;protected final Client followerClient() {     return clusterGroup.followerCluster.client(). }
false;protected,final;0;3;;protected final InternalTestCluster getLeaderCluster() {     return clusterGroup.leaderCluster. }
false;protected,final;0;3;;protected final InternalTestCluster getFollowerCluster() {     return clusterGroup.followerCluster. }
false;protected,final;1;3;;protected final ClusterHealthStatus ensureLeaderYellow(String... indices) {     return ensureColor(clusterGroup.leaderCluster, ClusterHealthStatus.YELLOW, TimeValue.timeValueSeconds(30), false, indices). }
false;protected,final;1;4;;protected final ClusterHealthStatus ensureLeaderGreen(String... indices) {     logger.info("ensure green leader indices {}", Arrays.toString(indices)).     return ensureColor(clusterGroup.leaderCluster, ClusterHealthStatus.GREEN, TimeValue.timeValueSeconds(30), false, indices). }
false;protected,final;1;3;;protected final ClusterHealthStatus ensureFollowerGreen(String... indices) {     return ensureFollowerGreen(false, indices). }
false;protected,final;2;5;;protected final ClusterHealthStatus ensureFollowerGreen(boolean waitForNoInitializingShards, String... indices) {     logger.info("ensure green follower indices {}", Arrays.toString(indices)).     return ensureColor(clusterGroup.followerCluster, ClusterHealthStatus.GREEN, TimeValue.timeValueSeconds(30), waitForNoInitializingShards, indices). }
false;private;5;29;;private ClusterHealthStatus ensureColor(TestCluster testCluster, ClusterHealthStatus clusterHealthStatus, TimeValue timeout, boolean waitForNoInitializingShards, String... indices) {     String color = clusterHealthStatus.name().toLowerCase(Locale.ROOT).     String method = "ensure" + Strings.capitalize(color).     ClusterHealthRequest healthRequest = Requests.clusterHealthRequest(indices).timeout(timeout).waitForStatus(clusterHealthStatus).waitForEvents(Priority.LANGUID).waitForNoRelocatingShards(true).waitForNoInitializingShards(waitForNoInitializingShards).waitForNodes(Integer.toString(testCluster.size())).     ClusterHealthResponse actionGet = testCluster.client().admin().cluster().health(healthRequest).actionGet().     if (actionGet.isTimedOut()) {         logger.info("{} timed out, cluster state:\n{}\n{}", method, testCluster.client().admin().cluster().prepareState().get().getState(), testCluster.client().admin().cluster().preparePendingClusterTasks().get()).         fail("timed out waiting for " + color + " state").     }     assertThat("Expected at least " + clusterHealthStatus + " but got " + actionGet.getStatus(), actionGet.getStatus().value(), lessThanOrEqualTo(clusterHealthStatus.value())).     logger.debug("indices {} are {}", indices.length == 0 ? "[_all]" : indices, color).     return actionGet.getStatus(). }
false;protected,final;1;6;;protected final Index resolveLeaderIndex(String index) {     GetIndexResponse getIndexResponse = leaderClient().admin().indices().prepareGetIndex().setIndices(index).get().     assertTrue("index " + index + " not found", getIndexResponse.getSettings().containsKey(index)).     String uuid = getIndexResponse.getSettings().get(index).get(IndexMetaData.SETTING_INDEX_UUID).     return new Index(index, uuid). }
false;protected,final;1;6;;protected final Index resolveFollowerIndex(String index) {     GetIndexResponse getIndexResponse = followerClient().admin().indices().prepareGetIndex().setIndices(index).get().     assertTrue("index " + index + " not found", getIndexResponse.getSettings().containsKey(index)).     String uuid = getIndexResponse.getSettings().get(index).get(IndexMetaData.SETTING_INDEX_UUID).     return new Index(index, uuid). }
false;protected,final;2;5;;protected final RefreshResponse refresh(Client client, String... indices) {     RefreshResponse actionGet = client.admin().indices().prepareRefresh(indices).execute().actionGet().     assertNoFailures(actionGet).     return actionGet. }
false;protected;0;11;;protected void ensureEmptyWriteBuffers() throws Exception {     assertBusy(() -> {         FollowStatsAction.StatsResponses statsResponses = leaderClient().execute(FollowStatsAction.INSTANCE, new FollowStatsAction.StatsRequest()).actionGet().         for (FollowStatsAction.StatsResponse statsResponse : statsResponses.getStatsResponses()) {             ShardFollowNodeTaskStatus status = statsResponse.status().             assertThat(status.writeBufferOperationCount(), equalTo(0)).             assertThat(status.writeBufferSizeInBytes(), equalTo(0L)).         }     }). }
false;protected;1;7;;protected void pauseFollow(String... indices) throws Exception {     for (String index : indices) {         final PauseFollowAction.Request unfollowRequest = new PauseFollowAction.Request(index).         assertAcked(followerClient().execute(PauseFollowAction.INSTANCE, unfollowRequest).actionGet()).     }     ensureNoCcrTasks(). }
false;protected;0;23;;protected void ensureNoCcrTasks() throws Exception {     assertBusy(() -> {         CcrStatsAction.Response statsResponse = followerClient().execute(CcrStatsAction.INSTANCE, new CcrStatsAction.Request()).actionGet().         assertThat("Follow stats not empty: " + Strings.toString(statsResponse.getFollowStats()), statsResponse.getFollowStats().getStatsResponses(), empty()).         final ClusterState clusterState = followerClient().admin().cluster().prepareState().get().getState().         final PersistentTasksCustomMetaData tasks = clusterState.getMetaData().custom(PersistentTasksCustomMetaData.TYPE).         assertThat(tasks.tasks(), empty()).         ListTasksRequest listTasksRequest = new ListTasksRequest().         listTasksRequest.setDetailed(true).         ListTasksResponse listTasksResponse = followerClient().admin().cluster().listTasks(listTasksRequest).get().         int numNodeTasks = 0.         for (TaskInfo taskInfo : listTasksResponse.getTasks()) {             if (taskInfo.getAction().startsWith(ListTasksAction.NAME) == false) {                 numNodeTasks++.             }         }         assertThat(numNodeTasks, equalTo(0)).     }, 30, TimeUnit.SECONDS). }
false;protected;3;40;;protected String getIndexSettings(final int numberOfShards, final int numberOfReplicas, final Map<String, String> additionalIndexSettings) throws IOException {     final String settings.     try (XContentBuilder builder = jsonBuilder()) {         builder.startObject().         {             builder.startObject("settings").             {                 builder.field(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), 0).                 builder.field(IndexService.GLOBAL_CHECKPOINT_SYNC_INTERVAL_SETTING.getKey(), "1s").                 builder.field("index.number_of_shards", numberOfShards).                 builder.field("index.number_of_replicas", numberOfReplicas).                 for (final Map.Entry<String, String> additionalSetting : additionalIndexSettings.entrySet()) {                     builder.field(additionalSetting.getKey(), additionalSetting.getValue()).                 }             }             builder.endObject().             builder.startObject("mappings").             {                 builder.startObject("doc").                 {                     builder.startObject("properties").                     {                         builder.startObject("f").                         {                             builder.field("type", "integer").                         }                         builder.endObject().                     }                     builder.endObject().                 }                 builder.endObject().             }             builder.endObject().         }         builder.endObject().         settings = BytesReference.bytes(builder).utf8ToString().     }     return settings. }
false;public,static;2;3;;public static PutFollowAction.Request putFollow(String leaderIndex, String followerIndex) {     return putFollow(leaderIndex, followerIndex, ActiveShardCount.ONE). }
false;public,static;3;10;;public static PutFollowAction.Request putFollow(String leaderIndex, String followerIndex, ActiveShardCount waitForActiveShards) {     PutFollowAction.Request request = new PutFollowAction.Request().     request.setRemoteCluster("leader_cluster").     request.setLeaderIndex(leaderIndex).     request.setFollowerIndex(followerIndex).     request.getParameters().setMaxRetryDelay(TimeValue.timeValueMillis(10)).     request.getParameters().setReadPollTimeout(TimeValue.timeValueMillis(10)).     request.waitForActiveShards(waitForActiveShards).     return request. }
false;public,static;1;7;;public static ResumeFollowAction.Request resumeFollow(String followerIndex) {     ResumeFollowAction.Request request = new ResumeFollowAction.Request().     request.setFollowerIndex(followerIndex).     request.getParameters().setMaxRetryDelay(TimeValue.timeValueMillis(10)).     request.getParameters().setReadPollTimeout(TimeValue.timeValueMillis(10)).     return request. }
true;protected;2;37;/**  * This asserts the index is fully replicated from the leader index to the follower index. It first verifies that the seq_no_stats  * on the follower equal the leader's. then verifies the existing pairs of (docId, seqNo) on the follower also equal the leader.  */ ;/**  * This asserts the index is fully replicated from the leader index to the follower index. It first verifies that the seq_no_stats  * on the follower equal the leader's. then verifies the existing pairs of (docId, seqNo) on the follower also equal the leader.  */ protected void assertIndexFullyReplicatedToFollower(String leaderIndex, String followerIndex) throws Exception {     logger.info("--> asserting <<docId,seqNo>> between {} and {}", leaderIndex, followerIndex).     assertBusy(() -> {         Map<Integer, List<DocIdSeqNoAndTerm>> docsOnFollower = getDocIdAndSeqNos(clusterGroup.followerCluster, followerIndex).         Map<Integer, List<DocIdSeqNoAndTerm>> docsOnLeader = getDocIdAndSeqNos(clusterGroup.leaderCluster, leaderIndex).         Map<Integer, Set<DocIdSeqNoAndTerm>> mismatchedDocs = new HashMap<>().         for (Map.Entry<Integer, List<DocIdSeqNoAndTerm>> fe : docsOnFollower.entrySet()) {             Set<DocIdSeqNoAndTerm> d1 = Sets.difference(Sets.newHashSet(fe.getValue()), Sets.newHashSet(docsOnLeader.getOrDefault(fe.getKey(), Collections.emptyList()))).             Set<DocIdSeqNoAndTerm> d2 = Sets.difference(Sets.newHashSet(docsOnLeader.getOrDefault(fe.getKey(), Collections.emptyList())), Sets.newHashSet(fe.getValue())).             if (d1.isEmpty() == false || d2.isEmpty() == false) {                 mismatchedDocs.put(fe.getKey(), Sets.union(d1, d2)).             }         }         assertThat("mismatched documents [" + mismatchedDocs + "]", docsOnFollower, equalTo(docsOnLeader)).     }, 120, TimeUnit.SECONDS).     logger.info("--> asserting seq_no_stats between {} and {}", leaderIndex, followerIndex).     assertBusy(() -> {         Map<Integer, SeqNoStats> leaderStats = new HashMap<>().         for (ShardStats shardStat : leaderClient().admin().indices().prepareStats(leaderIndex).clear().get().getShards()) {             if (shardStat.getSeqNoStats() == null) {                 throw new AssertionError("leader seq_no_stats is not available [" + Strings.toString(shardStat) + "]").             }             leaderStats.put(shardStat.getShardRouting().shardId().id(), shardStat.getSeqNoStats()).         }         Map<Integer, SeqNoStats> followerStats = new HashMap<>().         for (ShardStats shardStat : followerClient().admin().indices().prepareStats(followerIndex).clear().get().getShards()) {             if (shardStat.getSeqNoStats() == null) {                 throw new AssertionError("follower seq_no_stats is not available [" + Strings.toString(shardStat) + "]").             }             followerStats.put(shardStat.getShardRouting().shardId().id(), shardStat.getSeqNoStats()).         }         assertThat(followerStats, equalTo(leaderStats)).     }, 120, TimeUnit.SECONDS). }
false;private;2;24;;private Map<Integer, List<DocIdSeqNoAndTerm>> getDocIdAndSeqNos(InternalTestCluster cluster, String index) throws IOException {     final ClusterState state = cluster.client().admin().cluster().prepareState().get().getState().     List<ShardRouting> shardRoutings = state.routingTable().allShards(index).     Randomness.shuffle(shardRoutings).     final Map<Integer, List<DocIdSeqNoAndTerm>> docs = new HashMap<>().     for (ShardRouting shardRouting : shardRoutings) {         if (shardRouting == null || shardRouting.assignedToNode() == false) {             continue.         }         IndexShard indexShard = cluster.getInstance(IndicesService.class, state.nodes().get(shardRouting.currentNodeId()).getName()).indexServiceSafe(shardRouting.index()).getShard(shardRouting.id()).         try {             final List<DocIdSeqNoAndTerm> docsOnShard = IndexShardTestCase.getDocIdAndSeqNos(indexShard).             logger.info("--> shard {} docs {} seq_no_stats {}", shardRouting, docsOnShard, indexShard.seqNoStats()).             docs.put(shardRouting.shardId().id(), docsOnShard.stream().map(d -> new DocIdSeqNoAndTerm(d.getId(), d.getSeqNo(), 1L)).collect(Collectors.toList())).         } catch (AlreadyClosedException e) {         // Ignore this exception and try getting List<DocIdSeqNoAndTerm> from other IndexShard instance.         }     }     return docs. }
false;protected;3;11;;protected void atLeastDocsIndexed(Client client, String index, long numDocsReplicated) throws Exception {     logger.info("waiting for at least [{}] documents to be indexed into index [{}]", numDocsReplicated, index).     assertBusy(() -> {         refresh(client, index).         SearchRequest request = new SearchRequest(index).         request.source(new SearchSourceBuilder().size(0)).         SearchResponse response = client.search(request).actionGet().         assertNotNull(response.getHits().getTotalHits()).         assertThat(response.getHits().getTotalHits().value, greaterThanOrEqualTo(numDocsReplicated)).     }, 60, TimeUnit.SECONDS). }
false;protected;3;13;;protected void awaitGlobalCheckpointAtLeast(Client client, ShardId shardId, long minimumGlobalCheckpoint) throws Exception {     logger.info("waiting for the global checkpoint on [{}] at least [{}]", shardId, minimumGlobalCheckpoint).     assertBusy(() -> {         ShardStats stats = client.admin().indices().prepareStats(shardId.getIndexName()).clear().get().asMap().entrySet().stream().filter(e -> e.getKey().shardId().equals(shardId)).map(Map.Entry::getValue).findFirst().orElse(null).         if (stats == null || stats.getSeqNoStats() == null) {             // causes assertBusy to retry             throw new AssertionError("seq_no_stats for shard [" + shardId + "] is not found").         }         assertThat(Strings.toString(stats.getSeqNoStats()), stats.getSeqNoStats().getGlobalCheckpoint(), greaterThanOrEqualTo(minimumGlobalCheckpoint)).     }, 60, TimeUnit.SECONDS). }
false;protected;3;37;;protected void assertMaxSeqNoOfUpdatesIsTransferred(Index leaderIndex, Index followerIndex, int numberOfShards) throws Exception {     assertBusy(() -> {         long[] msuOnLeader = new long[numberOfShards].         for (int i = 0. i < msuOnLeader.length. i++) {             msuOnLeader[i] = SequenceNumbers.UNASSIGNED_SEQ_NO.         }         Set<String> leaderNodes = getLeaderCluster().nodesInclude(leaderIndex.getName()).         for (String leaderNode : leaderNodes) {             IndicesService indicesService = getLeaderCluster().getInstance(IndicesService.class, leaderNode).             for (int i = 0. i < numberOfShards. i++) {                 IndexShard shard = indicesService.getShardOrNull(new ShardId(leaderIndex, i)).                 if (shard != null) {                     try {                         msuOnLeader[i] = SequenceNumbers.max(msuOnLeader[i], shard.getMaxSeqNoOfUpdatesOrDeletes()).                     } catch (AlreadyClosedException ignored) {                         return.                     }                 }             }         }         Set<String> followerNodes = getFollowerCluster().nodesInclude(followerIndex.getName()).         for (String followerNode : followerNodes) {             IndicesService indicesService = getFollowerCluster().getInstance(IndicesService.class, followerNode).             for (int i = 0. i < numberOfShards. i++) {                 IndexShard shard = indicesService.getShardOrNull(new ShardId(leaderIndex, i)).                 if (shard != null) {                     try {                         assertThat(shard.getMaxSeqNoOfUpdatesOrDeletes(), equalTo(msuOnLeader[i])).                     } catch (AlreadyClosedException ignored) {                     }                 }             }         }     }). }
true;public;2;4;/**  * Waits until at least a give number of document is visible for searchers  *  * @param numDocs number of documents to wait for  * @param indexer a {@link org.elasticsearch.test.BackgroundIndexer}. Will be first checked for documents indexed.  *                This saves on unneeded searches.  * @return the actual number of docs seen.  */ ;/**  * Waits until at least a give number of document is visible for searchers  *  * @param numDocs number of documents to wait for  * @param indexer a {@link org.elasticsearch.test.BackgroundIndexer}. Will be first checked for documents indexed.  *                This saves on unneeded searches.  * @return the actual number of docs seen.  */ public long waitForDocs(final long numDocs, final BackgroundIndexer indexer) throws InterruptedException {     // indexing threads can wait for up to ~1m before retrying when they first try to index into a shard which is not STARTED.     return waitForDocs(numDocs, 90, TimeUnit.SECONDS, indexer). }
true;public;4;40;/**  * Waits until at least a give number of document is visible for searchers  *  * @param numDocs         number of documents to wait for  * @param maxWaitTime     if not progress have been made during this time, fail the test  * @param maxWaitTimeUnit the unit in which maxWaitTime is specified  * @param indexer         Will be first checked for documents indexed.  *                        This saves on unneeded searches.  * @return the actual number of docs seen.  */ ;/**  * Waits until at least a give number of document is visible for searchers  *  * @param numDocs         number of documents to wait for  * @param maxWaitTime     if not progress have been made during this time, fail the test  * @param maxWaitTimeUnit the unit in which maxWaitTime is specified  * @param indexer         Will be first checked for documents indexed.  *                        This saves on unneeded searches.  * @return the actual number of docs seen.  */ public long waitForDocs(final long numDocs, int maxWaitTime, TimeUnit maxWaitTimeUnit, final BackgroundIndexer indexer) throws InterruptedException {     final AtomicLong lastKnownCount = new AtomicLong(-1).     long lastStartCount = -1.     BooleanSupplier testDocs = () -> {         lastKnownCount.set(indexer.totalIndexedDocs()).         if (lastKnownCount.get() >= numDocs) {             try {                 long count = indexer.getClient().prepareSearch().setTrackTotalHits(true).setSize(0).setQuery(QueryBuilders.matchAllQuery()).get().getHits().getTotalHits().value.                 if (count == lastKnownCount.get()) {                     // no progress - try to refresh for the next time                     indexer.getClient().admin().indices().prepareRefresh().get().                 }                 lastKnownCount.set(count).             } catch (Exception e) {                 // count now acts like search and barfs if all shards failed...                 logger.debug("failed to executed count", e).                 return false.             }             logger.debug("[{}] docs visible for search. waiting for [{}]", lastKnownCount.get(), numDocs).         } else {             logger.debug("[{}] docs indexed. waiting for [{}]", lastKnownCount.get(), numDocs).         }         return lastKnownCount.get() >= numDocs.     }.     while (!awaitBusy(testDocs, maxWaitTime, maxWaitTimeUnit)) {         if (lastStartCount == lastKnownCount.get()) {             // we didn't make any progress             fail("failed to reach " + numDocs + "docs").         }         lastStartCount = lastKnownCount.get().     }     return lastKnownCount.get(). }
false;public;1;25;;@Override public void clusterChanged(ClusterChangedEvent changedEvent) {     final RestoreInProgress.Entry prevEntry = restoreInProgress(changedEvent.previousState(), uuid).     final RestoreInProgress.Entry newEntry = restoreInProgress(changedEvent.state(), uuid).     if (prevEntry == null) {         /*                                  * When there is a master failure after a restore has been started, this listener might not be registered                                  * on the current master and as such it might miss some intermediary cluster states due to batching.                                  * Clean up the listener in that case and acknowledge completion of restore operation to client.                                  */         clusterService.removeListener(this).         listener.onResponse(null).     } else if (newEntry == null) {         clusterService.removeListener(this).         ImmutableOpenMap<ShardId, RestoreInProgress.ShardRestoreStatus> shards = prevEntry.shards().         RestoreInfo ri = new RestoreInfo(prevEntry.snapshot().getSnapshotId().getName(), prevEntry.indices(), shards.size(), shards.size() - RestoreService.failedShards(shards)).         logger.debug("restore of [{}] completed", snapshot).         listener.onResponse(ri).     } else {     // restore not completed yet, wait for next cluster state update     } }
false;public;1;41;;@Override public void onResponse(RestoreService.RestoreCompletionResponse restoreCompletionResponse) {     if (restoreCompletionResponse.getRestoreInfo() == null) {         final Snapshot snapshot = restoreCompletionResponse.getSnapshot().         final String uuid = restoreCompletionResponse.getUuid().         final ClusterStateListener clusterStateListener = new ClusterStateListener() {              @Override             public void clusterChanged(ClusterChangedEvent changedEvent) {                 final RestoreInProgress.Entry prevEntry = restoreInProgress(changedEvent.previousState(), uuid).                 final RestoreInProgress.Entry newEntry = restoreInProgress(changedEvent.state(), uuid).                 if (prevEntry == null) {                     /*                                  * When there is a master failure after a restore has been started, this listener might not be registered                                  * on the current master and as such it might miss some intermediary cluster states due to batching.                                  * Clean up the listener in that case and acknowledge completion of restore operation to client.                                  */                     clusterService.removeListener(this).                     listener.onResponse(null).                 } else if (newEntry == null) {                     clusterService.removeListener(this).                     ImmutableOpenMap<ShardId, RestoreInProgress.ShardRestoreStatus> shards = prevEntry.shards().                     RestoreInfo ri = new RestoreInfo(prevEntry.snapshot().getSnapshotId().getName(), prevEntry.indices(), shards.size(), shards.size() - RestoreService.failedShards(shards)).                     logger.debug("restore of [{}] completed", snapshot).                     listener.onResponse(ri).                 } else {                 // restore not completed yet, wait for next cluster state update                 }             }         }.         clusterService.addListener(clusterStateListener).     } else {         listener.onResponse(restoreCompletionResponse.getRestoreInfo()).     } }
false;public;1;4;;@Override public void onFailure(Exception t) {     listener.onFailure(t). }
false;protected;2;54;;protected ActionListener<RestoreService.RestoreCompletionResponse> waitForRestore(final ClusterService clusterService, final ActionListener<RestoreInfo> listener) {     return new ActionListener<RestoreService.RestoreCompletionResponse>() {          @Override         public void onResponse(RestoreService.RestoreCompletionResponse restoreCompletionResponse) {             if (restoreCompletionResponse.getRestoreInfo() == null) {                 final Snapshot snapshot = restoreCompletionResponse.getSnapshot().                 final String uuid = restoreCompletionResponse.getUuid().                 final ClusterStateListener clusterStateListener = new ClusterStateListener() {                      @Override                     public void clusterChanged(ClusterChangedEvent changedEvent) {                         final RestoreInProgress.Entry prevEntry = restoreInProgress(changedEvent.previousState(), uuid).                         final RestoreInProgress.Entry newEntry = restoreInProgress(changedEvent.state(), uuid).                         if (prevEntry == null) {                             /*                                  * When there is a master failure after a restore has been started, this listener might not be registered                                  * on the current master and as such it might miss some intermediary cluster states due to batching.                                  * Clean up the listener in that case and acknowledge completion of restore operation to client.                                  */                             clusterService.removeListener(this).                             listener.onResponse(null).                         } else if (newEntry == null) {                             clusterService.removeListener(this).                             ImmutableOpenMap<ShardId, RestoreInProgress.ShardRestoreStatus> shards = prevEntry.shards().                             RestoreInfo ri = new RestoreInfo(prevEntry.snapshot().getSnapshotId().getName(), prevEntry.indices(), shards.size(), shards.size() - RestoreService.failedShards(shards)).                             logger.debug("restore of [{}] completed", snapshot).                             listener.onResponse(ri).                         } else {                         // restore not completed yet, wait for next cluster state update                         }                     }                 }.                 clusterService.addListener(clusterStateListener).             } else {                 listener.onResponse(restoreCompletionResponse.getRestoreInfo()).             }         }          @Override         public void onFailure(Exception t) {             listener.onFailure(t).         }     }. }
false;public;1;11;;@Override public ClusterState execute(ClusterState currentState) throws Exception {     AutoFollowMetadata empty = new AutoFollowMetadata(Collections.emptyMap(), Collections.emptyMap(), Collections.emptyMap()).     ClusterState.Builder newState = ClusterState.builder(currentState).     newState.metaData(MetaData.builder(currentState.getMetaData()).putCustom(AutoFollowMetadata.TYPE, empty).removeCustom(PersistentTasksCustomMetaData.TYPE).build()).     return newState.build(). }
false;public;2;4;;@Override public void onFailure(String source, Exception e) {     latch.countDown(). }
false;public;3;4;;@Override public void clusterStateProcessed(String source, ClusterState oldState, ClusterState newState) {     latch.countDown(). }
false;static;1;27;;static void removeCCRRelatedMetadataFromClusterState(ClusterService clusterService) throws Exception {     CountDownLatch latch = new CountDownLatch(1).     clusterService.submitStateUpdateTask("remove-ccr-related-metadata", new ClusterStateUpdateTask() {          @Override         public ClusterState execute(ClusterState currentState) throws Exception {             AutoFollowMetadata empty = new AutoFollowMetadata(Collections.emptyMap(), Collections.emptyMap(), Collections.emptyMap()).             ClusterState.Builder newState = ClusterState.builder(currentState).             newState.metaData(MetaData.builder(currentState.getMetaData()).putCustom(AutoFollowMetadata.TYPE, empty).removeCustom(PersistentTasksCustomMetaData.TYPE).build()).             return newState.build().         }          @Override         public void onFailure(String source, Exception e) {             latch.countDown().         }          @Override         public void clusterStateProcessed(String source, ClusterState oldState, ClusterState newState) {             latch.countDown().         }     }).     latch.await(). }
false;public;0;4;;@Override public void close() throws IOException {     IOUtils.close(leaderCluster, followerCluster). }
