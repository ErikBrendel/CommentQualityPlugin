commented;modifiers;parameterAmount;loc;comment;code
true;public;2;25;/**  * Increment the number of records written by 1 and increment  * the total number of fields read.  *  * @param inputFieldCount Number of fields in the record.  *                        Note this is not the number of processed fields (by field etc)  *                        but the actual number of fields in the record  * @param recordTimeMs    The time of the record written  *                        in milliseconds from the epoch.  */ ;/**  * Increment the number of records written by 1 and increment  * the total number of fields read.  *  * @param inputFieldCount Number of fields in the record.  *                        Note this is not the number of processed fields (by field etc)  *                        but the actual number of fields in the record  * @param recordTimeMs    The time of the record written  *                        in milliseconds from the epoch.  */ public void reportRecordWritten(long inputFieldCount, long recordTimeMs) {     Date recordDate = new Date(recordTimeMs).     totalRecordStats.incrementInputFieldCount(inputFieldCount).     totalRecordStats.incrementProcessedRecordCount(1).     totalRecordStats.setLatestRecordTimeStamp(recordDate).     incrementalRecordStats.incrementInputFieldCount(inputFieldCount).     incrementalRecordStats.incrementProcessedRecordCount(1).     incrementalRecordStats.setLatestRecordTimeStamp(recordDate).     boolean isFirstReport = totalRecordStats.getEarliestRecordTimeStamp() == null.     if (isFirstReport) {         totalRecordStats.setEarliestRecordTimeStamp(recordDate).         incrementalRecordStats.setEarliestRecordTimeStamp(recordDate).     }     // report at various boundaries     long totalRecords = getInputRecordCount().     if (reportingBoundaryFunction.apply(totalRecords)) {         logStatus(totalRecords).     }     diagnostics.checkRecord(recordTimeMs). }
true;public;1;3;/**  * Update only the incremental stats with the newest record time  *  * @param latestRecordTimeMs latest record time as epoch millis  */ ;/**  * Update only the incremental stats with the newest record time  *  * @param latestRecordTimeMs latest record time as epoch millis  */ public void reportLatestTimeIncrementalStats(long latestRecordTimeMs) {     incrementalRecordStats.setLatestRecordTimeStamp(new Date(latestRecordTimeMs)). }
true;public;1;7;/**  * Increments the date parse error count  */ ;/**  * Increments the date parse error count  */ public void reportDateParseError(long inputFieldCount) {     totalRecordStats.incrementInvalidDateCount(1).     totalRecordStats.incrementInputFieldCount(inputFieldCount).     incrementalRecordStats.incrementInvalidDateCount(1).     incrementalRecordStats.incrementInputFieldCount(inputFieldCount). }
true;public;0;4;/**  * Increments the missing field count  * Records with missing fields are still processed  */ ;/**  * Increments the missing field count  * Records with missing fields are still processed  */ public void reportMissingField() {     totalRecordStats.incrementMissingFieldCount(1).     incrementalRecordStats.incrementMissingFieldCount(1). }
false;public;1;4;;public void reportMissingFields(long missingCount) {     totalRecordStats.incrementMissingFieldCount(missingCount).     incrementalRecordStats.incrementMissingFieldCount(missingCount). }
true;public;1;4;/**  * Add <code>newBytes</code> to the total volume processed  */ ;/**  * Add <code>newBytes</code> to the total volume processed  */ public void reportBytesRead(long newBytes) {     totalRecordStats.incrementInputBytes(newBytes).     incrementalRecordStats.incrementInputBytes(newBytes). }
true;public;1;7;/**  * Increments the out of order record count  */ ;/**  * Increments the out of order record count  */ public void reportOutOfOrderRecord(long inputFieldCount) {     totalRecordStats.incrementOutOfOrderTimeStampCount(1).     totalRecordStats.incrementInputFieldCount(inputFieldCount).     incrementalRecordStats.incrementOutOfOrderTimeStampCount(1).     incrementalRecordStats.incrementInputFieldCount(inputFieldCount). }
true;public;0;3;/**  * Total records seen = records written to the Engine (processed record  * count) + date parse error records count + out of order record count.  * <p>  * Records with missing fields are counted as they are still written.  */ ;/**  * Total records seen = records written to the Engine (processed record  * count) + date parse error records count + out of order record count.  * <p>  * Records with missing fields are counted as they are still written.  */ public long getInputRecordCount() {     return totalRecordStats.getInputRecordCount(). }
false;public;0;3;;public long getProcessedRecordCount() {     return totalRecordStats.getProcessedRecordCount(). }
false;public;0;3;;public long getDateParseErrorsCount() {     return totalRecordStats.getInvalidDateCount(). }
false;public;0;3;;public long getMissingFieldErrorCount() {     return totalRecordStats.getMissingFieldCount(). }
false;public;0;3;;public long getOutOfOrderRecordCount() {     return totalRecordStats.getOutOfOrderTimeStampCount(). }
false;public;0;3;;public long getEmptyBucketCount() {     return totalRecordStats.getEmptyBucketCount(). }
false;public;0;3;;public long getSparseBucketCount() {     return totalRecordStats.getSparseBucketCount(). }
false;public;0;3;;public long getBucketCount() {     return totalRecordStats.getBucketCount(). }
false;public;0;3;;public long getBytesRead() {     return totalRecordStats.getInputBytes(). }
false;public;0;3;;public Date getLatestRecordTime() {     return totalRecordStats.getLatestRecordTimeStamp(). }
false;public;0;3;;public Date getLatestEmptyBucketTime() {     return totalRecordStats.getLatestEmptyBucketTimeStamp(). }
false;public;0;3;;public Date getLatestSparseBucketTime() {     return totalRecordStats.getLatestSparseBucketTimeStamp(). }
false;public;0;4;;public long getProcessedFieldCount() {     totalRecordStats.calcProcessedFieldCount(getAnalysedFieldsPerRecord()).     return totalRecordStats.getProcessedFieldCount(). }
false;public;0;3;;public long getInputFieldCount() {     return totalRecordStats.getInputFieldCount(). }
false;public;1;3;;public void setAnalysedFieldsPerRecord(long value) {     analyzedFieldsPerRecord = value. }
false;public;0;3;;public long getAnalysedFieldsPerRecord() {     return analyzedFieldsPerRecord. }
true;public;1;8;/**  * Report the counts now regardless of whether or not we are at a reporting boundary.  */ ;/**  * Report the counts now regardless of whether or not we are at a reporting boundary.  */ public void finishReporting(ActionListener<Boolean> listener) {     Date now = new Date().     incrementalRecordStats.setLastDataTimeStamp(now).     totalRecordStats.setLastDataTimeStamp(now).     diagnostics.flush().     retrieveDiagnosticsIntermediateResults().     dataCountsPersister.persistDataCounts(job.getId(), runningTotalStats(), listener). }
true;protected;1;19;/**  * Log the status.  This is done progressively less frequently as the job  * processes more data.  Logging every 10000 records when the data rate is  * 40000 per second quickly rolls the logs.  */ ;/**  * Log the status.  This is done progressively less frequently as the job  * processes more data.  Logging every 10000 records when the data rate is  * 40000 per second quickly rolls the logs.  */ protected boolean logStatus(long totalRecords) {     if (++logCount % logEvery != 0) {         return false.     }     String status = String.format(Locale.ROOT, "[%s] %d records written to autodetect. missingFieldCount=%d, invalidDateCount=%d, outOfOrderCount=%d", job.getId(), getProcessedRecordCount(), getMissingFieldErrorCount(), getDateParseErrorsCount(), getOutOfOrderRecordCount()).     logger.info(status).     int log10TotalRecords = (int) Math.floor(Math.log10(totalRecords)).     // Start reducing the logging rate after a million records have been seen     if (log10TotalRecords > 5) {         logEvery = (int) Math.pow(10.0, log10TotalRecords - 5).         logCount = 0.     }     return true. }
false;private;1;15;;private boolean reportEvery10000Records(long totalRecords) {     if (totalRecords > 100_000) {         lastRecordCountQuotient = totalRecords / 100_000.         reportingBoundaryFunction = this::reportEvery100000Records.         return false.     }     long quotient = totalRecords / 10_000.     if (quotient > lastRecordCountQuotient) {         lastRecordCountQuotient = quotient.         return true.     }     return false. }
false;private;1;9;;private boolean reportEvery100000Records(long totalRecords) {     long quotient = totalRecords / 100_000.     if (quotient > lastRecordCountQuotient) {         lastRecordCountQuotient = quotient.         return true.     }     return false. }
false;public;0;4;;public void startNewIncrementalCount() {     incrementalRecordStats = new DataCounts(job.getId()).     retrieveDiagnosticsIntermediateResults(). }
false;public;0;4;;public DataCounts incrementalStats() {     incrementalRecordStats.calcProcessedFieldCount(getAnalysedFieldsPerRecord()).     return incrementalRecordStats. }
false;public,synchronized;0;4;;public synchronized DataCounts runningTotalStats() {     totalRecordStats.calcProcessedFieldCount(getAnalysedFieldsPerRecord()).     return totalRecordStats. }
false;private;0;15;;private void retrieveDiagnosticsIntermediateResults() {     totalRecordStats.incrementBucketCount(diagnostics.getBucketCount()).     totalRecordStats.incrementEmptyBucketCount(diagnostics.getEmptyBucketCount()).     totalRecordStats.incrementSparseBucketCount(diagnostics.getSparseBucketCount()).     totalRecordStats.updateLatestEmptyBucketTimeStamp(diagnostics.getLatestEmptyBucketTime()).     totalRecordStats.updateLatestSparseBucketTimeStamp(diagnostics.getLatestSparseBucketTime()).     incrementalRecordStats.incrementBucketCount(diagnostics.getBucketCount()).     incrementalRecordStats.incrementEmptyBucketCount(diagnostics.getEmptyBucketCount()).     incrementalRecordStats.incrementSparseBucketCount(diagnostics.getSparseBucketCount()).     incrementalRecordStats.updateLatestEmptyBucketTimeStamp(diagnostics.getLatestEmptyBucketTime()).     incrementalRecordStats.updateLatestSparseBucketTimeStamp(diagnostics.getLatestSparseBucketTime()).     diagnostics.resetCounts(). }
