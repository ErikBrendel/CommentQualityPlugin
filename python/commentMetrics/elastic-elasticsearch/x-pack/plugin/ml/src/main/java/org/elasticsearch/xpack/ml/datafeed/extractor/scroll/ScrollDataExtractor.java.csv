commented;modifiers;parameterAmount;loc;comment;code
false;public;0;4;;@Override public boolean hasNext() {     return hasNext. }
false;public;0;4;;@Override public boolean isCancelled() {     return isCancelled. }
false;public;0;5;;@Override public void cancel() {     LOGGER.trace("[{}] Data extractor received cancel request", context.jobId).     isCancelled = true. }
false;public;0;12;;@Override public Optional<InputStream> next() throws IOException {     if (!hasNext()) {         throw new NoSuchElementException().     }     Optional<InputStream> stream = scrollId == null ? Optional.ofNullable(initScroll(context.start)) : Optional.ofNullable(continueScroll()).     if (!stream.isPresent()) {         hasNext = false.     }     return stream. }
false;protected;1;6;;protected InputStream initScroll(long startTimestamp) throws IOException {     LOGGER.debug("[{}] Initializing scroll", context.jobId).     SearchResponse searchResponse = executeSearchRequest(buildSearchRequest(startTimestamp)).     LOGGER.debug("[{}] Search response was obtained", context.jobId).     return processSearchResponse(searchResponse). }
false;protected;1;3;;protected SearchResponse executeSearchRequest(SearchRequestBuilder searchRequestBuilder) {     return ClientHelper.executeWithHeaders(context.headers, ClientHelper.ML_ORIGIN, client, searchRequestBuilder::get). }
false;private;1;22;;private SearchRequestBuilder buildSearchRequest(long start) {     SearchRequestBuilder searchRequestBuilder = new SearchRequestBuilder(client, SearchAction.INSTANCE).setScroll(SCROLL_TIMEOUT).addSort(context.extractedFields.timeField(), SortOrder.ASC).setIndices(context.indices).setSize(context.scrollSize).setQuery(ExtractorUtils.wrapInTimeRangeQuery(context.query, context.extractedFields.timeField(), start, context.end)).     for (ExtractedField docValueField : context.extractedFields.getDocValueFields()) {         searchRequestBuilder.addDocValueField(docValueField.getName(), docValueField.getDocValueFormat()).     }     String[] sourceFields = context.extractedFields.getSourceFields().     if (sourceFields.length == 0) {         searchRequestBuilder.setFetchSource(false).         searchRequestBuilder.storedFields(StoredFieldsContext._NONE_).     } else {         searchRequestBuilder.setFetchSource(sourceFields, null).     }     context.scriptFields.forEach(f -> searchRequestBuilder.addScriptField(f.fieldName(), f.script())).     return searchRequestBuilder. }
false;private;1;38;;private InputStream processSearchResponse(SearchResponse searchResponse) throws IOException {     if (searchResponse.getFailedShards() > 0 && searchHasShardFailure == false) {         LOGGER.debug("[{}] Resetting scroll search after shard failure", context.jobId).         markScrollAsErrored().         return initScroll(lastTimestamp == null ? context.start : lastTimestamp).     }     ExtractorUtils.checkSearchWasSuccessful(context.jobId, searchResponse).     scrollId = searchResponse.getScrollId().     if (searchResponse.getHits().getHits().length == 0) {         hasNext = false.         clearScroll(scrollId).         return null.     }     ByteArrayOutputStream outputStream = new ByteArrayOutputStream().     try (SearchHitToJsonProcessor hitProcessor = new SearchHitToJsonProcessor(context.extractedFields, outputStream)) {         for (SearchHit hit : searchResponse.getHits().getHits()) {             if (isCancelled) {                 Long timestamp = context.extractedFields.timeFieldValue(hit).                 if (timestamp != null) {                     if (timestampOnCancel == null) {                         timestampOnCancel = timestamp.                     } else if (timestamp.equals(timestampOnCancel) == false) {                         hasNext = false.                         clearScroll(scrollId).                         break.                     }                 }             }             hitProcessor.process(hit).         }         SearchHit lastHit = searchResponse.getHits().getHits()[searchResponse.getHits().getHits().length - 1].         lastTimestamp = context.extractedFields.timeFieldValue(lastHit).     }     return new ByteArrayInputStream(outputStream.toByteArray()). }
false;private;0;17;;private InputStream continueScroll() throws IOException {     LOGGER.debug("[{}] Continuing scroll with id [{}]", context.jobId, scrollId).     SearchResponse searchResponse.     try {         searchResponse = executeSearchScrollRequest(scrollId).     } catch (SearchPhaseExecutionException searchExecutionException) {         if (searchHasShardFailure == false) {             LOGGER.debug("[{}] Reinitializing scroll due to SearchPhaseExecutionException", context.jobId).             markScrollAsErrored().             searchResponse = executeSearchRequest(buildSearchRequest(lastTimestamp == null ? context.start : lastTimestamp)).         } else {             throw searchExecutionException.         }     }     LOGGER.debug("[{}] Search response was obtained", context.jobId).     return processSearchResponse(searchResponse). }
false;private;0;9;;private void markScrollAsErrored() {     // This could be a transient error with the scroll Id.     // Reinitialise the scroll and try again but only once.     resetScroll().     if (lastTimestamp != null) {         lastTimestamp++.     }     searchHasShardFailure = true. }
false;protected;1;7;;protected SearchResponse executeSearchScrollRequest(String scrollId) {     return ClientHelper.executeWithHeaders(context.headers, ClientHelper.ML_ORIGIN, client, () -> new SearchScrollRequestBuilder(client, SearchScrollAction.INSTANCE).setScroll(SCROLL_TIMEOUT).setScrollId(scrollId).get()). }
false;private;0;4;;private void resetScroll() {     clearScroll(scrollId).     scrollId = null. }
false;private;1;8;;private void clearScroll(String scrollId) {     if (scrollId != null) {         ClearScrollRequest request = new ClearScrollRequest().         request.addScrollId(scrollId).         ClientHelper.executeWithHeaders(context.headers, ClientHelper.ML_ORIGIN, client, () -> client.execute(ClearScrollAction.INSTANCE, request).actionGet()).     } }
