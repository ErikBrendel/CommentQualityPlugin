# id;timestamp;commentText;codeText;commentWords;codeWords
StateStreamer -> public void cancel();1524684173;Cancels the state streaming at the first opportunity.;public void cancel() {_        isCancelled = true__    };cancels,the,state,streaming,at,the,first,opportunity;public,void,cancel,is,cancelled,true
StateStreamer -> public void cancel();1540847035;Cancels the state streaming at the first opportunity.;public void cancel() {_        isCancelled = true__    };cancels,the,state,streaming,at,the,first,opportunity;public,void,cancel,is,cancelled,true
StateStreamer -> public void cancel();1547215421;Cancels the state streaming at the first opportunity.;public void cancel() {_        isCancelled = true__    };cancels,the,state,streaming,at,the,first,opportunity;public,void,cancel,is,cancelled,true
StateStreamer -> public void restoreStateToStream(String jobId, ModelSnapshot modelSnapshot, OutputStream restoreStream) throws IOException;1524684173;Given a model snapshot, get the corresponding state and write it to the supplied_stream.  If there are multiple state documents they are separated using <code>'\0'</code>_when written to the stream.__Because we have a rule that we will not open a legacy job in the current product version_we don't have to worry about legacy document IDs here.__@param jobId         the job id_@param modelSnapshot the model snapshot to be restored_@param restoreStream the stream to write the state to;public void restoreStateToStream(String jobId, ModelSnapshot modelSnapshot, OutputStream restoreStream) throws IOException {_        String indexName = AnomalyDetectorsIndex.jobStateIndexName()___        _        for (String stateDocId : modelSnapshot.stateDocumentIds()) {_            if (isCancelled) {_                return__            }__            LOGGER.trace("ES API CALL: get ID {} from index {}", stateDocId, indexName)___            try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN)) {_                GetResponse stateResponse = client.prepareGet(indexName, ElasticsearchMappings.DOC_TYPE, stateDocId).get()__                if (!stateResponse.isExists()) {_                    LOGGER.error("Expected {} documents for model state for {} snapshot {} but failed to find {}",_                            modelSnapshot.getSnapshotDocCount(), jobId, modelSnapshot.getSnapshotId(), stateDocId)__                    break__                }_                writeStateToStream(stateResponse.getSourceAsBytesRef(), restoreStream)__            }_        }__        _        _        _        int docNum = 0__        while (true) {_            if (isCancelled) {_                return__            }__            String docId = CategorizerState.documentId(jobId, ++docNum)___            LOGGER.trace("ES API CALL: get ID {} from index {}", docId, indexName)___            try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN)) {_                GetResponse stateResponse = client.prepareGet(indexName, ElasticsearchMappings.DOC_TYPE, docId).get()__                if (!stateResponse.isExists()) {_                    break__                }_                writeStateToStream(stateResponse.getSourceAsBytesRef(), restoreStream)__            }_        }__    };given,a,model,snapshot,get,the,corresponding,state,and,write,it,to,the,supplied,stream,if,there,are,multiple,state,documents,they,are,separated,using,code,0,code,when,written,to,the,stream,because,we,have,a,rule,that,we,will,not,open,a,legacy,job,in,the,current,product,version,we,don,t,have,to,worry,about,legacy,document,ids,here,param,job,id,the,job,id,param,model,snapshot,the,model,snapshot,to,be,restored,param,restore,stream,the,stream,to,write,the,state,to;public,void,restore,state,to,stream,string,job,id,model,snapshot,model,snapshot,output,stream,restore,stream,throws,ioexception,string,index,name,anomaly,detectors,index,job,state,index,name,for,string,state,doc,id,model,snapshot,state,document,ids,if,is,cancelled,return,logger,trace,es,api,call,get,id,from,index,state,doc,id,index,name,try,thread,context,stored,context,ignore,stash,with,origin,client,thread,pool,get,thread,context,get,response,state,response,client,prepare,get,index,name,elasticsearch,mappings,state,doc,id,get,if,state,response,is,exists,logger,error,expected,documents,for,model,state,for,snapshot,but,failed,to,find,model,snapshot,get,snapshot,doc,count,job,id,model,snapshot,get,snapshot,id,state,doc,id,break,write,state,to,stream,state,response,get,source,as,bytes,ref,restore,stream,int,doc,num,0,while,true,if,is,cancelled,return,string,doc,id,categorizer,state,document,id,job,id,doc,num,logger,trace,es,api,call,get,id,from,index,doc,id,index,name,try,thread,context,stored,context,ignore,stash,with,origin,client,thread,pool,get,thread,context,get,response,state,response,client,prepare,get,index,name,elasticsearch,mappings,doc,id,get,if,state,response,is,exists,break,write,state,to,stream,state,response,get,source,as,bytes,ref,restore,stream
StateStreamer -> public void restoreStateToStream(String jobId, ModelSnapshot modelSnapshot, OutputStream restoreStream) throws IOException;1540847035;Given a model snapshot, get the corresponding state and write it to the supplied_stream.  If there are multiple state documents they are separated using <code>'\0'</code>_when written to the stream.__Because we have a rule that we will not open a legacy job in the current product version_we don't have to worry about legacy document IDs here.__@param jobId         the job id_@param modelSnapshot the model snapshot to be restored_@param restoreStream the stream to write the state to;public void restoreStateToStream(String jobId, ModelSnapshot modelSnapshot, OutputStream restoreStream) throws IOException {_        String indexName = AnomalyDetectorsIndex.jobStateIndexName()___        _        for (String stateDocId : modelSnapshot.stateDocumentIds()) {_            if (isCancelled) {_                return__            }__            LOGGER.trace("ES API CALL: get ID {} from index {}", stateDocId, indexName)___            try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN)) {_                GetResponse stateResponse = client.prepareGet(indexName, ElasticsearchMappings.DOC_TYPE, stateDocId).get()__                if (!stateResponse.isExists()) {_                    LOGGER.error("Expected {} documents for model state for {} snapshot {} but failed to find {}",_                            modelSnapshot.getSnapshotDocCount(), jobId, modelSnapshot.getSnapshotId(), stateDocId)__                    break__                }_                writeStateToStream(stateResponse.getSourceAsBytesRef(), restoreStream)__            }_        }__        _        _        _        int docNum = 0__        while (true) {_            if (isCancelled) {_                return__            }__            String docId = CategorizerState.documentId(jobId, ++docNum)___            LOGGER.trace("ES API CALL: get ID {} from index {}", docId, indexName)___            try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN)) {_                GetResponse stateResponse = client.prepareGet(indexName, ElasticsearchMappings.DOC_TYPE, docId).get()__                if (!stateResponse.isExists()) {_                    break__                }_                writeStateToStream(stateResponse.getSourceAsBytesRef(), restoreStream)__            }_        }__    };given,a,model,snapshot,get,the,corresponding,state,and,write,it,to,the,supplied,stream,if,there,are,multiple,state,documents,they,are,separated,using,code,0,code,when,written,to,the,stream,because,we,have,a,rule,that,we,will,not,open,a,legacy,job,in,the,current,product,version,we,don,t,have,to,worry,about,legacy,document,ids,here,param,job,id,the,job,id,param,model,snapshot,the,model,snapshot,to,be,restored,param,restore,stream,the,stream,to,write,the,state,to;public,void,restore,state,to,stream,string,job,id,model,snapshot,model,snapshot,output,stream,restore,stream,throws,ioexception,string,index,name,anomaly,detectors,index,job,state,index,name,for,string,state,doc,id,model,snapshot,state,document,ids,if,is,cancelled,return,logger,trace,es,api,call,get,id,from,index,state,doc,id,index,name,try,thread,context,stored,context,ignore,stash,with,origin,client,thread,pool,get,thread,context,get,response,state,response,client,prepare,get,index,name,elasticsearch,mappings,state,doc,id,get,if,state,response,is,exists,logger,error,expected,documents,for,model,state,for,snapshot,but,failed,to,find,model,snapshot,get,snapshot,doc,count,job,id,model,snapshot,get,snapshot,id,state,doc,id,break,write,state,to,stream,state,response,get,source,as,bytes,ref,restore,stream,int,doc,num,0,while,true,if,is,cancelled,return,string,doc,id,categorizer,state,document,id,job,id,doc,num,logger,trace,es,api,call,get,id,from,index,doc,id,index,name,try,thread,context,stored,context,ignore,stash,with,origin,client,thread,pool,get,thread,context,get,response,state,response,client,prepare,get,index,name,elasticsearch,mappings,doc,id,get,if,state,response,is,exists,break,write,state,to,stream,state,response,get,source,as,bytes,ref,restore,stream
StateStreamer -> public void restoreStateToStream(String jobId, ModelSnapshot modelSnapshot, OutputStream restoreStream) throws IOException;1547215421;Given a model snapshot, get the corresponding state and write it to the supplied_stream.  If there are multiple state documents they are separated using <code>'\0'</code>_when written to the stream.__Because we have a rule that we will not open a legacy job in the current product version_we don't have to worry about legacy document IDs here.__@param jobId         the job id_@param modelSnapshot the model snapshot to be restored_@param restoreStream the stream to write the state to;public void restoreStateToStream(String jobId, ModelSnapshot modelSnapshot, OutputStream restoreStream) throws IOException {_        String indexName = AnomalyDetectorsIndex.jobStateIndexPattern()___        _        for (String stateDocId : modelSnapshot.stateDocumentIds()) {_            if (isCancelled) {_                return__            }__            LOGGER.trace("ES API CALL: get ID {} from index {}", stateDocId, indexName)___            try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN)) {_                SearchResponse stateResponse = client.prepareSearch(indexName)_                    .setTypes(ElasticsearchMappings.DOC_TYPE)_                    .setSize(1)_                    .setQuery(QueryBuilders.idsQuery().addIds(stateDocId)).get()__                if (stateResponse.getHits().getHits().length == 0) {_                    LOGGER.error("Expected {} documents for model state for {} snapshot {} but failed to find {}",_                            modelSnapshot.getSnapshotDocCount(), jobId, modelSnapshot.getSnapshotId(), stateDocId)__                    break__                }_                writeStateToStream(stateResponse.getHits().getAt(0).getSourceRef(), restoreStream)__            }_        }__        _        _        _        int docNum = 0__        while (true) {_            if (isCancelled) {_                return__            }__            String docId = CategorizerState.documentId(jobId, ++docNum)___            LOGGER.trace("ES API CALL: get ID {} from index {}", docId, indexName)___            try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN)) {_                SearchResponse stateResponse = client.prepareSearch(indexName)_                    .setTypes(ElasticsearchMappings.DOC_TYPE)_                    .setSize(1)_                    .setQuery(QueryBuilders.idsQuery().addIds(docId)).get()__                if (stateResponse.getHits().getHits().length == 0) {_                    break__                }_                writeStateToStream(stateResponse.getHits().getAt(0).getSourceRef(), restoreStream)__            }_        }__    };given,a,model,snapshot,get,the,corresponding,state,and,write,it,to,the,supplied,stream,if,there,are,multiple,state,documents,they,are,separated,using,code,0,code,when,written,to,the,stream,because,we,have,a,rule,that,we,will,not,open,a,legacy,job,in,the,current,product,version,we,don,t,have,to,worry,about,legacy,document,ids,here,param,job,id,the,job,id,param,model,snapshot,the,model,snapshot,to,be,restored,param,restore,stream,the,stream,to,write,the,state,to;public,void,restore,state,to,stream,string,job,id,model,snapshot,model,snapshot,output,stream,restore,stream,throws,ioexception,string,index,name,anomaly,detectors,index,job,state,index,pattern,for,string,state,doc,id,model,snapshot,state,document,ids,if,is,cancelled,return,logger,trace,es,api,call,get,id,from,index,state,doc,id,index,name,try,thread,context,stored,context,ignore,stash,with,origin,client,thread,pool,get,thread,context,search,response,state,response,client,prepare,search,index,name,set,types,elasticsearch,mappings,set,size,1,set,query,query,builders,ids,query,add,ids,state,doc,id,get,if,state,response,get,hits,get,hits,length,0,logger,error,expected,documents,for,model,state,for,snapshot,but,failed,to,find,model,snapshot,get,snapshot,doc,count,job,id,model,snapshot,get,snapshot,id,state,doc,id,break,write,state,to,stream,state,response,get,hits,get,at,0,get,source,ref,restore,stream,int,doc,num,0,while,true,if,is,cancelled,return,string,doc,id,categorizer,state,document,id,job,id,doc,num,logger,trace,es,api,call,get,id,from,index,doc,id,index,name,try,thread,context,stored,context,ignore,stash,with,origin,client,thread,pool,get,thread,context,search,response,state,response,client,prepare,search,index,name,set,types,elasticsearch,mappings,set,size,1,set,query,query,builders,ids,query,add,ids,doc,id,get,if,state,response,get,hits,get,hits,length,0,break,write,state,to,stream,state,response,get,hits,get,at,0,get,source,ref,restore,stream
