commented;modifiers;parameterAmount;loc;comment;code
false;static;1;3;;static boolean isRunningOnMlPlatform(boolean fatalIfNot) {     return isRunningOnMlPlatform(Constants.OS_NAME, Constants.OS_ARCH, fatalIfNot). }
false;static;3;11;;static boolean isRunningOnMlPlatform(String osName, String osArch, boolean fatalIfNot) {     String platformName = Platforms.platformName(osName, osArch).     if (mlPlatforms.contains(platformName)) {         return true.     }     if (fatalIfNot) {         throw new ElasticsearchException("X-Pack is not supported and Machine Learning is not available for [" + platformName + "]. you can use the other X-Pack features (unsupported) by setting xpack.ml.enabled: false in elasticsearch.yml").     }     return false. }
false;public;0;4;;@Override public String name() {     return XPackField.MACHINE_LEARNING. }
false;public;0;4;;@Override public String description() {     return "Machine Learning for the Elastic Stack". }
false;public;0;4;;@Override public boolean available() {     return licenseState != null && licenseState.isMachineLearningAllowed(). }
false;public;0;4;;@Override public boolean enabled() {     return enabled. }
false;public;0;4;;@Override public Map<String, Object> nativeCodeInfo() {     return nativeCodeInfo. }
false;public;1;5;;@Override public void usage(ActionListener<XPackFeatureSet.Usage> listener) {     ClusterState state = clusterService.state().     new Retriever(client, jobManagerHolder, available(), enabled(), mlNodeCount(state)).execute(listener). }
false;private;1;13;;private int mlNodeCount(final ClusterState clusterState) {     if (enabled == false) {         return 0.     }     int mlNodeCount = 0.     for (DiscoveryNode node : clusterState.getNodes()) {         if (MachineLearning.isMlNode(node)) {             ++mlNodeCount.         }     }     return mlNodeCount. }
false;public;1;33;;public void execute(ActionListener<Usage> listener) {     // empty holder means either ML disabled or transport client mode     if (jobManagerHolder.isEmpty()) {         listener.onResponse(new MachineLearningFeatureSetUsage(available, enabled, Collections.emptyMap(), Collections.emptyMap(), 0)).         return.     }     // Step 2. Extract usage from datafeeds stats and return usage response     ActionListener<GetDatafeedsStatsAction.Response> datafeedStatsListener = ActionListener.wrap(response -> {         addDatafeedsUsage(response).         listener.onResponse(new MachineLearningFeatureSetUsage(available, enabled, jobsUsage, datafeedsUsage, nodeCount)).     }, listener::onFailure).     // Step 1. Extract usage from jobs stats and then request stats for all datafeeds     GetJobsStatsAction.Request jobStatsRequest = new GetJobsStatsAction.Request(MetaData.ALL).     ActionListener<GetJobsStatsAction.Response> jobStatsListener = ActionListener.wrap(response -> {         jobManagerHolder.getJobManager().expandJobs(MetaData.ALL, true, ActionListener.wrap(jobs -> {             addJobsUsage(response, jobs.results()).             GetDatafeedsStatsAction.Request datafeedStatsRequest = new GetDatafeedsStatsAction.Request(GetDatafeedsStatsAction.ALL).             client.execute(GetDatafeedsStatsAction.INSTANCE, datafeedStatsRequest, datafeedStatsListener).         }, listener::onFailure)).     }, listener::onFailure).     // Step 0. Kick off the chain of callbacks by requesting jobs stats     client.execute(GetJobsStatsAction.INSTANCE, jobStatsRequest, jobStatsListener). }
false;private;2;42;;private void addJobsUsage(GetJobsStatsAction.Response response, List<Job> jobs) {     StatsAccumulator allJobsDetectorsStats = new StatsAccumulator().     StatsAccumulator allJobsModelSizeStats = new StatsAccumulator().     ForecastStats allJobsForecastStats = new ForecastStats().     Map<JobState, Counter> jobCountByState = new HashMap<>().     Map<JobState, StatsAccumulator> detectorStatsByState = new HashMap<>().     Map<JobState, StatsAccumulator> modelSizeStatsByState = new HashMap<>().     Map<JobState, ForecastStats> forecastStatsByState = new HashMap<>().     List<GetJobsStatsAction.Response.JobStats> jobsStats = response.getResponse().results().     Map<String, Job> jobMap = jobs.stream().collect(Collectors.toMap(Job::getId, item -> item)).     for (GetJobsStatsAction.Response.JobStats jobStats : jobsStats) {         ModelSizeStats modelSizeStats = jobStats.getModelSizeStats().         int detectorsCount = jobMap.get(jobStats.getJobId()).getAnalysisConfig().getDetectors().size().         double modelSize = modelSizeStats == null ? 0.0 : jobStats.getModelSizeStats().getModelBytes().         allJobsForecastStats.merge(jobStats.getForecastStats()).         allJobsDetectorsStats.add(detectorsCount).         allJobsModelSizeStats.add(modelSize).         JobState jobState = jobStats.getState().         jobCountByState.computeIfAbsent(jobState, js -> Counter.newCounter()).addAndGet(1).         detectorStatsByState.computeIfAbsent(jobState, js -> new StatsAccumulator()).add(detectorsCount).         modelSizeStatsByState.computeIfAbsent(jobState, js -> new StatsAccumulator()).add(modelSize).         forecastStatsByState.merge(jobState, jobStats.getForecastStats(), (f1, f2) -> f1.merge(f2)).     }     jobsUsage.put(MachineLearningFeatureSetUsage.ALL, createJobUsageEntry(jobs.size(), allJobsDetectorsStats, allJobsModelSizeStats, allJobsForecastStats)).     for (JobState jobState : jobCountByState.keySet()) {         jobsUsage.put(jobState.name().toLowerCase(Locale.ROOT), createJobUsageEntry(jobCountByState.get(jobState).get(), detectorStatsByState.get(jobState), modelSizeStatsByState.get(jobState), forecastStatsByState.get(jobState))).     } }
false;private;4;10;;private Map<String, Object> createJobUsageEntry(long count, StatsAccumulator detectorStats, StatsAccumulator modelSizeStats, ForecastStats forecastStats) {     Map<String, Object> usage = new HashMap<>().     usage.put(MachineLearningFeatureSetUsage.COUNT, count).     usage.put(MachineLearningFeatureSetUsage.DETECTORS, detectorStats.asMap()).     usage.put(MachineLearningFeatureSetUsage.MODEL_SIZE, modelSizeStats.asMap()).     usage.put(MachineLearningFeatureSetUsage.FORECASTS, forecastStats.asMap()).     return usage. }
false;private;1;15;;private void addDatafeedsUsage(GetDatafeedsStatsAction.Response response) {     Map<DatafeedState, Counter> datafeedCountByState = new HashMap<>().     List<GetDatafeedsStatsAction.Response.DatafeedStats> datafeedsStats = response.getResponse().results().     for (GetDatafeedsStatsAction.Response.DatafeedStats datafeedStats : datafeedsStats) {         datafeedCountByState.computeIfAbsent(datafeedStats.getDatafeedState(), ds -> Counter.newCounter()).addAndGet(1).     }     datafeedsUsage.put(MachineLearningFeatureSetUsage.ALL, createDatafeedUsageEntry(response.getResponse().count())).     for (DatafeedState datafeedState : datafeedCountByState.keySet()) {         datafeedsUsage.put(datafeedState.name().toLowerCase(Locale.ROOT), createDatafeedUsageEntry(datafeedCountByState.get(datafeedState).get())).     } }
false;private;1;5;;private Map<String, Object> createDatafeedUsageEntry(long count) {     Map<String, Object> usage = new HashMap<>().     usage.put(MachineLearningFeatureSetUsage.COUNT, count).     return usage. }
