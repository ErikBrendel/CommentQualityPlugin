# id;timestamp;commentText;codeText;commentWords;codeWords
AggregationToJsonProcessor -> private boolean processLeaf(Aggregation agg) throws IOException;1524684173;Adds a leaf key-value. It returns the name of the key added or {@code null} when nothing was added._Non-finite metric values are not added.;private boolean processLeaf(Aggregation agg) throws IOException {_        if (agg instanceof NumericMetricsAggregation.SingleValue) {_            return processSingleValue((NumericMetricsAggregation.SingleValue) agg)__        } else if (agg instanceof Percentiles) {_            return processPercentiles((Percentiles) agg)__        } else {_            throw new IllegalArgumentException("Unsupported aggregation type [" + agg.getName() + "]")__        }_    };adds,a,leaf,key,value,it,returns,the,name,of,the,key,added,or,code,null,when,nothing,was,added,non,finite,metric,values,are,not,added;private,boolean,process,leaf,aggregation,agg,throws,ioexception,if,agg,instanceof,numeric,metrics,aggregation,single,value,return,process,single,value,numeric,metrics,aggregation,single,value,agg,else,if,agg,instanceof,percentiles,return,process,percentiles,percentiles,agg,else,throw,new,illegal,argument,exception,unsupported,aggregation,type,agg,get,name
AggregationToJsonProcessor -> private boolean processLeaf(Aggregation agg) throws IOException;1536314350;Adds a leaf key-value. It returns the name of the key added or {@code null} when nothing was added._Non-finite metric values are not added.;private boolean processLeaf(Aggregation agg) throws IOException {_        if (agg instanceof NumericMetricsAggregation.SingleValue) {_            return processSingleValue((NumericMetricsAggregation.SingleValue) agg)__        } else if (agg instanceof Percentiles) {_            return processPercentiles((Percentiles) agg)__        } else {_            throw new IllegalArgumentException("Unsupported aggregation type [" + agg.getName() + "]")__        }_    };adds,a,leaf,key,value,it,returns,the,name,of,the,key,added,or,code,null,when,nothing,was,added,non,finite,metric,values,are,not,added;private,boolean,process,leaf,aggregation,agg,throws,ioexception,if,agg,instanceof,numeric,metrics,aggregation,single,value,return,process,single,value,numeric,metrics,aggregation,single,value,agg,else,if,agg,instanceof,percentiles,return,process,percentiles,percentiles,agg,else,throw,new,illegal,argument,exception,unsupported,aggregation,type,agg,get,name
AggregationToJsonProcessor -> private boolean processLeaf(Aggregation agg) throws IOException;1540847035;Adds a leaf key-value. It returns the name of the key added or {@code null} when nothing was added._Non-finite metric values are not added.;private boolean processLeaf(Aggregation agg) throws IOException {_        if (agg instanceof NumericMetricsAggregation.SingleValue) {_            return processSingleValue((NumericMetricsAggregation.SingleValue) agg)__        } else if (agg instanceof Percentiles) {_            return processPercentiles((Percentiles) agg)__        } else {_            throw new IllegalArgumentException("Unsupported aggregation type [" + agg.getName() + "]")__        }_    };adds,a,leaf,key,value,it,returns,the,name,of,the,key,added,or,code,null,when,nothing,was,added,non,finite,metric,values,are,not,added;private,boolean,process,leaf,aggregation,agg,throws,ioexception,if,agg,instanceof,numeric,metrics,aggregation,single,value,return,process,single,value,numeric,metrics,aggregation,single,value,agg,else,if,agg,instanceof,percentiles,return,process,percentiles,percentiles,agg,else,throw,new,illegal,argument,exception,unsupported,aggregation,type,agg,get,name
AggregationToJsonProcessor -> private boolean processLeaf(Aggregation agg) throws IOException;1547845733;Adds a leaf key-value. It returns the name of the key added or {@code null} when nothing was added._Non-finite metric values are not added.;private boolean processLeaf(Aggregation agg) throws IOException {_        if (agg instanceof NumericMetricsAggregation.SingleValue) {_            return processSingleValue((NumericMetricsAggregation.SingleValue) agg)__        } else if (agg instanceof Percentiles) {_            return processPercentiles((Percentiles) agg)__        } else {_            throw new IllegalArgumentException("Unsupported aggregation type [" + agg.getName() + "]")__        }_    };adds,a,leaf,key,value,it,returns,the,name,of,the,key,added,or,code,null,when,nothing,was,added,non,finite,metric,values,are,not,added;private,boolean,process,leaf,aggregation,agg,throws,ioexception,if,agg,instanceof,numeric,metrics,aggregation,single,value,return,process,single,value,numeric,metrics,aggregation,single,value,agg,else,if,agg,instanceof,percentiles,return,process,percentiles,percentiles,agg,else,throw,new,illegal,argument,exception,unsupported,aggregation,type,agg,get,name
AggregationToJsonProcessor -> private boolean processLeaf(Aggregation agg) throws IOException;1548236405;Adds a leaf key-value. It returns the name of the key added or {@code null} when nothing was added._Non-finite metric values are not added.;private boolean processLeaf(Aggregation agg) throws IOException {_        if (agg instanceof NumericMetricsAggregation.SingleValue) {_            return processSingleValue((NumericMetricsAggregation.SingleValue) agg)__        } else if (agg instanceof Percentiles) {_            return processPercentiles((Percentiles) agg)__        } else {_            throw new IllegalArgumentException("Unsupported aggregation type [" + agg.getName() + "]")__        }_    };adds,a,leaf,key,value,it,returns,the,name,of,the,key,added,or,code,null,when,nothing,was,added,non,finite,metric,values,are,not,added;private,boolean,process,leaf,aggregation,agg,throws,ioexception,if,agg,instanceof,numeric,metrics,aggregation,single,value,return,process,single,value,numeric,metrics,aggregation,single,value,agg,else,if,agg,instanceof,percentiles,return,process,percentiles,percentiles,agg,else,throw,new,illegal,argument,exception,unsupported,aggregation,type,agg,get,name
AggregationToJsonProcessor -> private void processAggs(long docCount, List<Aggregation> aggregations) throws IOException;1524684173;Processes a list of {@link Aggregation}s and writes a flat JSON document for each of its leaf aggregations._Supported sub-aggregations include:_<ul>_<li>{@link MultiBucketsAggregation}</li>_<li>{@link NumericMetricsAggregation.SingleValue}</li>_<li>{@link Percentiles}</li>_</ul>;private void processAggs(long docCount, List<Aggregation> aggregations) throws IOException {_        if (aggregations.isEmpty()) {_            _            queueDocToWrite(keyValuePairs, docCount)__            return__        }__        List<Aggregation> leafAggregations = new ArrayList<>()__        List<MultiBucketsAggregation> bucketAggregations = new ArrayList<>()___        _        _        for (Aggregation agg : aggregations) {_            if (agg instanceof MultiBucketsAggregation) {_                bucketAggregations.add((MultiBucketsAggregation)agg)__            } else {_                leafAggregations.add(agg)__            }_        }__        if (bucketAggregations.size() > 1) {_            throw new IllegalArgumentException("Multiple bucket aggregations at the same level are not supported")__        }__        List<String> addedLeafKeys = new ArrayList<>()__        for (Aggregation leafAgg : leafAggregations) {_            if (timeField.equals(leafAgg.getName())) {_                processTimeField(leafAgg)__            } else if (fields.contains(leafAgg.getName())) {_                boolean leafAdded = processLeaf(leafAgg)__                if (leafAdded) {_                    addedLeafKeys.add(leafAgg.getName())__                }_            }_        }__        boolean noMoreBucketsToProcess = bucketAggregations.isEmpty()__        if (noMoreBucketsToProcess == false) {_            MultiBucketsAggregation bucketAgg = bucketAggregations.get(0)__            if (bucketAgg instanceof Histogram) {_                processDateHistogram((Histogram) bucketAgg)__            } else {_                _                _                _                _                if (bucketAggContainsRequiredAgg(bucketAgg)) {_                    processBucket(bucketAgg, fields.contains(bucketAgg.getName()))__                } else {_                    noMoreBucketsToProcess = true__                }_            }_        }__        _        _        if (noMoreBucketsToProcess) {_            queueDocToWrite(keyValuePairs, docCount)__        }__        addedLeafKeys.forEach(k -> keyValuePairs.remove(k))__    };processes,a,list,of,link,aggregation,s,and,writes,a,flat,json,document,for,each,of,its,leaf,aggregations,supported,sub,aggregations,include,ul,li,link,multi,buckets,aggregation,li,li,link,numeric,metrics,aggregation,single,value,li,li,link,percentiles,li,ul;private,void,process,aggs,long,doc,count,list,aggregation,aggregations,throws,ioexception,if,aggregations,is,empty,queue,doc,to,write,key,value,pairs,doc,count,return,list,aggregation,leaf,aggregations,new,array,list,list,multi,buckets,aggregation,bucket,aggregations,new,array,list,for,aggregation,agg,aggregations,if,agg,instanceof,multi,buckets,aggregation,bucket,aggregations,add,multi,buckets,aggregation,agg,else,leaf,aggregations,add,agg,if,bucket,aggregations,size,1,throw,new,illegal,argument,exception,multiple,bucket,aggregations,at,the,same,level,are,not,supported,list,string,added,leaf,keys,new,array,list,for,aggregation,leaf,agg,leaf,aggregations,if,time,field,equals,leaf,agg,get,name,process,time,field,leaf,agg,else,if,fields,contains,leaf,agg,get,name,boolean,leaf,added,process,leaf,leaf,agg,if,leaf,added,added,leaf,keys,add,leaf,agg,get,name,boolean,no,more,buckets,to,process,bucket,aggregations,is,empty,if,no,more,buckets,to,process,false,multi,buckets,aggregation,bucket,agg,bucket,aggregations,get,0,if,bucket,agg,instanceof,histogram,process,date,histogram,histogram,bucket,agg,else,if,bucket,agg,contains,required,agg,bucket,agg,process,bucket,bucket,agg,fields,contains,bucket,agg,get,name,else,no,more,buckets,to,process,true,if,no,more,buckets,to,process,queue,doc,to,write,key,value,pairs,doc,count,added,leaf,keys,for,each,k,key,value,pairs,remove,k
AggregationToJsonProcessor -> private void processAggs(long docCount, List<Aggregation> aggregations) throws IOException;1536314350;Processes a list of {@link Aggregation}s and writes a flat JSON document for each of its leaf aggregations._Supported sub-aggregations include:_<ul>_<li>{@link MultiBucketsAggregation}</li>_<li>{@link NumericMetricsAggregation.SingleValue}</li>_<li>{@link Percentiles}</li>_</ul>;private void processAggs(long docCount, List<Aggregation> aggregations) throws IOException {_        if (aggregations.isEmpty()) {_            _            queueDocToWrite(keyValuePairs, docCount)__            return__        }__        List<Aggregation> leafAggregations = new ArrayList<>()__        List<MultiBucketsAggregation> bucketAggregations = new ArrayList<>()___        _        _        for (Aggregation agg : aggregations) {_            if (agg instanceof MultiBucketsAggregation) {_                bucketAggregations.add((MultiBucketsAggregation)agg)__            } else {_                leafAggregations.add(agg)__            }_        }__        if (bucketAggregations.size() > 1) {_            throw new IllegalArgumentException("Multiple bucket aggregations at the same level are not supported")__        }__        List<String> addedLeafKeys = new ArrayList<>()__        for (Aggregation leafAgg : leafAggregations) {_            if (timeField.equals(leafAgg.getName())) {_                processTimeField(leafAgg)__            } else if (fields.contains(leafAgg.getName())) {_                boolean leafAdded = processLeaf(leafAgg)__                if (leafAdded) {_                    addedLeafKeys.add(leafAgg.getName())__                }_            }_        }__        boolean noMoreBucketsToProcess = bucketAggregations.isEmpty()__        if (noMoreBucketsToProcess == false) {_            MultiBucketsAggregation bucketAgg = bucketAggregations.get(0)__            if (bucketAgg instanceof Histogram) {_                processDateHistogram((Histogram) bucketAgg)__            } else {_                _                _                _                _                if (bucketAggContainsRequiredAgg(bucketAgg)) {_                    processBucket(bucketAgg, fields.contains(bucketAgg.getName()))__                } else {_                    noMoreBucketsToProcess = true__                }_            }_        }__        _        _        if (noMoreBucketsToProcess) {_            queueDocToWrite(keyValuePairs, docCount)__        }__        addedLeafKeys.forEach(k -> keyValuePairs.remove(k))__    };processes,a,list,of,link,aggregation,s,and,writes,a,flat,json,document,for,each,of,its,leaf,aggregations,supported,sub,aggregations,include,ul,li,link,multi,buckets,aggregation,li,li,link,numeric,metrics,aggregation,single,value,li,li,link,percentiles,li,ul;private,void,process,aggs,long,doc,count,list,aggregation,aggregations,throws,ioexception,if,aggregations,is,empty,queue,doc,to,write,key,value,pairs,doc,count,return,list,aggregation,leaf,aggregations,new,array,list,list,multi,buckets,aggregation,bucket,aggregations,new,array,list,for,aggregation,agg,aggregations,if,agg,instanceof,multi,buckets,aggregation,bucket,aggregations,add,multi,buckets,aggregation,agg,else,leaf,aggregations,add,agg,if,bucket,aggregations,size,1,throw,new,illegal,argument,exception,multiple,bucket,aggregations,at,the,same,level,are,not,supported,list,string,added,leaf,keys,new,array,list,for,aggregation,leaf,agg,leaf,aggregations,if,time,field,equals,leaf,agg,get,name,process,time,field,leaf,agg,else,if,fields,contains,leaf,agg,get,name,boolean,leaf,added,process,leaf,leaf,agg,if,leaf,added,added,leaf,keys,add,leaf,agg,get,name,boolean,no,more,buckets,to,process,bucket,aggregations,is,empty,if,no,more,buckets,to,process,false,multi,buckets,aggregation,bucket,agg,bucket,aggregations,get,0,if,bucket,agg,instanceof,histogram,process,date,histogram,histogram,bucket,agg,else,if,bucket,agg,contains,required,agg,bucket,agg,process,bucket,bucket,agg,fields,contains,bucket,agg,get,name,else,no,more,buckets,to,process,true,if,no,more,buckets,to,process,queue,doc,to,write,key,value,pairs,doc,count,added,leaf,keys,for,each,k,key,value,pairs,remove,k
AggregationToJsonProcessor -> private void processAggs(long docCount, List<Aggregation> aggregations) throws IOException;1540847035;Processes a list of {@link Aggregation}s and writes a flat JSON document for each of its leaf aggregations._Supported sub-aggregations include:_<ul>_<li>{@link MultiBucketsAggregation}</li>_<li>{@link NumericMetricsAggregation.SingleValue}</li>_<li>{@link Percentiles}</li>_</ul>;private void processAggs(long docCount, List<Aggregation> aggregations) throws IOException {_        if (aggregations.isEmpty()) {_            _            queueDocToWrite(keyValuePairs, docCount)__            return__        }__        List<Aggregation> leafAggregations = new ArrayList<>()__        List<MultiBucketsAggregation> bucketAggregations = new ArrayList<>()___        _        _        for (Aggregation agg : aggregations) {_            if (agg instanceof MultiBucketsAggregation) {_                bucketAggregations.add((MultiBucketsAggregation)agg)__            } else {_                leafAggregations.add(agg)__            }_        }__        if (bucketAggregations.size() > 1) {_            throw new IllegalArgumentException("Multiple bucket aggregations at the same level are not supported")__        }__        List<String> addedLeafKeys = new ArrayList<>()__        for (Aggregation leafAgg : leafAggregations) {_            if (timeField.equals(leafAgg.getName())) {_                processTimeField(leafAgg)__            } else if (fields.contains(leafAgg.getName())) {_                boolean leafAdded = processLeaf(leafAgg)__                if (leafAdded) {_                    addedLeafKeys.add(leafAgg.getName())__                }_            }_        }__        boolean noMoreBucketsToProcess = bucketAggregations.isEmpty()__        if (noMoreBucketsToProcess == false) {_            MultiBucketsAggregation bucketAgg = bucketAggregations.get(0)__            if (bucketAgg instanceof Histogram) {_                processDateHistogram((Histogram) bucketAgg)__            } else {_                _                _                _                _                if (bucketAggContainsRequiredAgg(bucketAgg)) {_                    processBucket(bucketAgg, fields.contains(bucketAgg.getName()))__                } else {_                    noMoreBucketsToProcess = true__                }_            }_        }__        _        _        if (noMoreBucketsToProcess) {_            queueDocToWrite(keyValuePairs, docCount)__        }__        addedLeafKeys.forEach(k -> keyValuePairs.remove(k))__    };processes,a,list,of,link,aggregation,s,and,writes,a,flat,json,document,for,each,of,its,leaf,aggregations,supported,sub,aggregations,include,ul,li,link,multi,buckets,aggregation,li,li,link,numeric,metrics,aggregation,single,value,li,li,link,percentiles,li,ul;private,void,process,aggs,long,doc,count,list,aggregation,aggregations,throws,ioexception,if,aggregations,is,empty,queue,doc,to,write,key,value,pairs,doc,count,return,list,aggregation,leaf,aggregations,new,array,list,list,multi,buckets,aggregation,bucket,aggregations,new,array,list,for,aggregation,agg,aggregations,if,agg,instanceof,multi,buckets,aggregation,bucket,aggregations,add,multi,buckets,aggregation,agg,else,leaf,aggregations,add,agg,if,bucket,aggregations,size,1,throw,new,illegal,argument,exception,multiple,bucket,aggregations,at,the,same,level,are,not,supported,list,string,added,leaf,keys,new,array,list,for,aggregation,leaf,agg,leaf,aggregations,if,time,field,equals,leaf,agg,get,name,process,time,field,leaf,agg,else,if,fields,contains,leaf,agg,get,name,boolean,leaf,added,process,leaf,leaf,agg,if,leaf,added,added,leaf,keys,add,leaf,agg,get,name,boolean,no,more,buckets,to,process,bucket,aggregations,is,empty,if,no,more,buckets,to,process,false,multi,buckets,aggregation,bucket,agg,bucket,aggregations,get,0,if,bucket,agg,instanceof,histogram,process,date,histogram,histogram,bucket,agg,else,if,bucket,agg,contains,required,agg,bucket,agg,process,bucket,bucket,agg,fields,contains,bucket,agg,get,name,else,no,more,buckets,to,process,true,if,no,more,buckets,to,process,queue,doc,to,write,key,value,pairs,doc,count,added,leaf,keys,for,each,k,key,value,pairs,remove,k
AggregationToJsonProcessor -> private void processAggs(long docCount, List<Aggregation> aggregations) throws IOException;1547845733;Processes a list of {@link Aggregation}s and writes a flat JSON document for each of its leaf aggregations._Supported sub-aggregations include:_<ul>_<li>{@link MultiBucketsAggregation}</li>_<li>{@link NumericMetricsAggregation.SingleValue}</li>_<li>{@link Percentiles}</li>_</ul>;private void processAggs(long docCount, List<Aggregation> aggregations) throws IOException {_        if (aggregations.isEmpty()) {_            _            queueDocToWrite(keyValuePairs, docCount)__            return__        }__        List<Aggregation> leafAggregations = new ArrayList<>()__        List<MultiBucketsAggregation> bucketAggregations = new ArrayList<>()__        List<SingleBucketAggregation> singleBucketAggregations = new ArrayList<>()___        _        _        for (Aggregation agg : aggregations) {_            if (agg instanceof MultiBucketsAggregation) {_                bucketAggregations.add((MultiBucketsAggregation)agg)__            } else if (agg instanceof SingleBucketAggregation){_                _                _                SingleBucketAggregation singleBucketAggregation = (SingleBucketAggregation)agg__                for (Aggregation subAgg : singleBucketAggregation.getAggregations()) {_                    if (subAgg instanceof MultiBucketsAggregation || subAgg instanceof SingleBucketAggregation) {_                        singleBucketAggregations.add(singleBucketAggregation)__                    } else {_                        leafAggregations.add(subAgg)__                    }_                }_            } else {_                leafAggregations.add(agg)__            }_        }__        _        _        _        _        int bucketAggLevelCount = Math.max(bucketAggregations.size(), (int)singleBucketAggregations.stream()_            .flatMap(s -> asList(s.getAggregations()).stream())_            .filter(MultiBucketsAggregation.class::isInstance)_            .count())___        if (bucketAggLevelCount > 1) {_            throw new IllegalArgumentException("Multiple bucket aggregations at the same level are not supported")__        }__        List<String> addedLeafKeys = new ArrayList<>()__        for (Aggregation leafAgg : leafAggregations) {_            if (timeField.equals(leafAgg.getName())) {_                processTimeField(leafAgg)__            } else if (fields.contains(leafAgg.getName())) {_                boolean leafAdded = processLeaf(leafAgg)__                if (leafAdded) {_                    addedLeafKeys.add(leafAgg.getName())__                }_            }_        }__        boolean noMoreBucketsToProcess = bucketAggregations.isEmpty()__        if (noMoreBucketsToProcess == false) {_            MultiBucketsAggregation bucketAgg = bucketAggregations.get(0)__            if (bucketAgg instanceof Histogram) {_                processDateHistogram((Histogram) bucketAgg)__            } else {_                _                _                _                _                if (bucketAggContainsRequiredAgg(bucketAgg)) {_                    processBucket(bucketAgg, fields.contains(bucketAgg.getName()))__                } else {_                    noMoreBucketsToProcess = true__                }_            }_        }_        noMoreBucketsToProcess = singleBucketAggregations.isEmpty() && noMoreBucketsToProcess__        _        _        _        for (SingleBucketAggregation singleBucketAggregation : singleBucketAggregations) {_            processAggs(singleBucketAggregation.getDocCount(),_                asList(singleBucketAggregation.getAggregations())_                    .stream()_                    .filter(_                        aggregation -> (aggregation instanceof MultiBucketsAggregation || aggregation instanceof SingleBucketAggregation))_                    .collect(Collectors.toList()))__        }__        _        _        if (noMoreBucketsToProcess) {_            queueDocToWrite(keyValuePairs, docCount)__        }__        addedLeafKeys.forEach(k -> keyValuePairs.remove(k))__    };processes,a,list,of,link,aggregation,s,and,writes,a,flat,json,document,for,each,of,its,leaf,aggregations,supported,sub,aggregations,include,ul,li,link,multi,buckets,aggregation,li,li,link,numeric,metrics,aggregation,single,value,li,li,link,percentiles,li,ul;private,void,process,aggs,long,doc,count,list,aggregation,aggregations,throws,ioexception,if,aggregations,is,empty,queue,doc,to,write,key,value,pairs,doc,count,return,list,aggregation,leaf,aggregations,new,array,list,list,multi,buckets,aggregation,bucket,aggregations,new,array,list,list,single,bucket,aggregation,single,bucket,aggregations,new,array,list,for,aggregation,agg,aggregations,if,agg,instanceof,multi,buckets,aggregation,bucket,aggregations,add,multi,buckets,aggregation,agg,else,if,agg,instanceof,single,bucket,aggregation,single,bucket,aggregation,single,bucket,aggregation,single,bucket,aggregation,agg,for,aggregation,sub,agg,single,bucket,aggregation,get,aggregations,if,sub,agg,instanceof,multi,buckets,aggregation,sub,agg,instanceof,single,bucket,aggregation,single,bucket,aggregations,add,single,bucket,aggregation,else,leaf,aggregations,add,sub,agg,else,leaf,aggregations,add,agg,int,bucket,agg,level,count,math,max,bucket,aggregations,size,int,single,bucket,aggregations,stream,flat,map,s,as,list,s,get,aggregations,stream,filter,multi,buckets,aggregation,class,is,instance,count,if,bucket,agg,level,count,1,throw,new,illegal,argument,exception,multiple,bucket,aggregations,at,the,same,level,are,not,supported,list,string,added,leaf,keys,new,array,list,for,aggregation,leaf,agg,leaf,aggregations,if,time,field,equals,leaf,agg,get,name,process,time,field,leaf,agg,else,if,fields,contains,leaf,agg,get,name,boolean,leaf,added,process,leaf,leaf,agg,if,leaf,added,added,leaf,keys,add,leaf,agg,get,name,boolean,no,more,buckets,to,process,bucket,aggregations,is,empty,if,no,more,buckets,to,process,false,multi,buckets,aggregation,bucket,agg,bucket,aggregations,get,0,if,bucket,agg,instanceof,histogram,process,date,histogram,histogram,bucket,agg,else,if,bucket,agg,contains,required,agg,bucket,agg,process,bucket,bucket,agg,fields,contains,bucket,agg,get,name,else,no,more,buckets,to,process,true,no,more,buckets,to,process,single,bucket,aggregations,is,empty,no,more,buckets,to,process,for,single,bucket,aggregation,single,bucket,aggregation,single,bucket,aggregations,process,aggs,single,bucket,aggregation,get,doc,count,as,list,single,bucket,aggregation,get,aggregations,stream,filter,aggregation,aggregation,instanceof,multi,buckets,aggregation,aggregation,instanceof,single,bucket,aggregation,collect,collectors,to,list,if,no,more,buckets,to,process,queue,doc,to,write,key,value,pairs,doc,count,added,leaf,keys,for,each,k,key,value,pairs,remove,k
AggregationToJsonProcessor -> private void processAggs(long docCount, List<Aggregation> aggregations) throws IOException;1548236405;Processes a list of {@link Aggregation}s and writes a flat JSON document for each of its leaf aggregations._Supported sub-aggregations include:_<ul>_<li>{@link MultiBucketsAggregation}</li>_<li>{@link NumericMetricsAggregation.SingleValue}</li>_<li>{@link Percentiles}</li>_</ul>;private void processAggs(long docCount, List<Aggregation> aggregations) throws IOException {_        if (aggregations.isEmpty()) {_            _            queueDocToWrite(keyValuePairs, docCount)__            return__        }__        List<Aggregation> leafAggregations = new ArrayList<>()__        List<MultiBucketsAggregation> bucketAggregations = new ArrayList<>()__        List<SingleBucketAggregation> singleBucketAggregations = new ArrayList<>()___        _        _        for (Aggregation agg : aggregations) {_            if (agg instanceof MultiBucketsAggregation) {_                bucketAggregations.add((MultiBucketsAggregation)agg)__            } else if (agg instanceof SingleBucketAggregation){_                _                _                SingleBucketAggregation singleBucketAggregation = (SingleBucketAggregation)agg__                for (Aggregation subAgg : singleBucketAggregation.getAggregations()) {_                    if (subAgg instanceof MultiBucketsAggregation || subAgg instanceof SingleBucketAggregation) {_                        singleBucketAggregations.add(singleBucketAggregation)__                    } else {_                        leafAggregations.add(subAgg)__                    }_                }_            } else {_                leafAggregations.add(agg)__            }_        }__        _        _        _        _        int bucketAggLevelCount = Math.max(bucketAggregations.size(), (int)singleBucketAggregations.stream()_            .flatMap(s -> asList(s.getAggregations()).stream())_            .filter(MultiBucketsAggregation.class::isInstance)_            .count())___        if (bucketAggLevelCount > 1) {_            throw new IllegalArgumentException("Multiple bucket aggregations at the same level are not supported")__        }__        List<String> addedLeafKeys = new ArrayList<>()__        for (Aggregation leafAgg : leafAggregations) {_            if (timeField.equals(leafAgg.getName())) {_                processTimeField(leafAgg)__            } else if (fields.contains(leafAgg.getName())) {_                boolean leafAdded = processLeaf(leafAgg)__                if (leafAdded) {_                    addedLeafKeys.add(leafAgg.getName())__                }_            }_        }__        boolean noMoreBucketsToProcess = bucketAggregations.isEmpty()__        if (noMoreBucketsToProcess == false) {_            MultiBucketsAggregation bucketAgg = bucketAggregations.get(0)__            if (bucketAgg instanceof Histogram) {_                processDateHistogram((Histogram) bucketAgg)__            } else {_                _                _                _                _                if (bucketAggContainsRequiredAgg(bucketAgg)) {_                    processBucket(bucketAgg, fields.contains(bucketAgg.getName()))__                } else {_                    noMoreBucketsToProcess = true__                }_            }_        }_        noMoreBucketsToProcess = singleBucketAggregations.isEmpty() && noMoreBucketsToProcess__        _        _        _        for (SingleBucketAggregation singleBucketAggregation : singleBucketAggregations) {_            processAggs(singleBucketAggregation.getDocCount(),_                asList(singleBucketAggregation.getAggregations())_                    .stream()_                    .filter(_                        aggregation -> (aggregation instanceof MultiBucketsAggregation || aggregation instanceof SingleBucketAggregation))_                    .collect(Collectors.toList()))__        }__        _        _        if (noMoreBucketsToProcess) {_            queueDocToWrite(keyValuePairs, docCount)__        }__        addedLeafKeys.forEach(k -> keyValuePairs.remove(k))__    };processes,a,list,of,link,aggregation,s,and,writes,a,flat,json,document,for,each,of,its,leaf,aggregations,supported,sub,aggregations,include,ul,li,link,multi,buckets,aggregation,li,li,link,numeric,metrics,aggregation,single,value,li,li,link,percentiles,li,ul;private,void,process,aggs,long,doc,count,list,aggregation,aggregations,throws,ioexception,if,aggregations,is,empty,queue,doc,to,write,key,value,pairs,doc,count,return,list,aggregation,leaf,aggregations,new,array,list,list,multi,buckets,aggregation,bucket,aggregations,new,array,list,list,single,bucket,aggregation,single,bucket,aggregations,new,array,list,for,aggregation,agg,aggregations,if,agg,instanceof,multi,buckets,aggregation,bucket,aggregations,add,multi,buckets,aggregation,agg,else,if,agg,instanceof,single,bucket,aggregation,single,bucket,aggregation,single,bucket,aggregation,single,bucket,aggregation,agg,for,aggregation,sub,agg,single,bucket,aggregation,get,aggregations,if,sub,agg,instanceof,multi,buckets,aggregation,sub,agg,instanceof,single,bucket,aggregation,single,bucket,aggregations,add,single,bucket,aggregation,else,leaf,aggregations,add,sub,agg,else,leaf,aggregations,add,agg,int,bucket,agg,level,count,math,max,bucket,aggregations,size,int,single,bucket,aggregations,stream,flat,map,s,as,list,s,get,aggregations,stream,filter,multi,buckets,aggregation,class,is,instance,count,if,bucket,agg,level,count,1,throw,new,illegal,argument,exception,multiple,bucket,aggregations,at,the,same,level,are,not,supported,list,string,added,leaf,keys,new,array,list,for,aggregation,leaf,agg,leaf,aggregations,if,time,field,equals,leaf,agg,get,name,process,time,field,leaf,agg,else,if,fields,contains,leaf,agg,get,name,boolean,leaf,added,process,leaf,leaf,agg,if,leaf,added,added,leaf,keys,add,leaf,agg,get,name,boolean,no,more,buckets,to,process,bucket,aggregations,is,empty,if,no,more,buckets,to,process,false,multi,buckets,aggregation,bucket,agg,bucket,aggregations,get,0,if,bucket,agg,instanceof,histogram,process,date,histogram,histogram,bucket,agg,else,if,bucket,agg,contains,required,agg,bucket,agg,process,bucket,bucket,agg,fields,contains,bucket,agg,get,name,else,no,more,buckets,to,process,true,no,more,buckets,to,process,single,bucket,aggregations,is,empty,no,more,buckets,to,process,for,single,bucket,aggregation,single,bucket,aggregation,single,bucket,aggregations,process,aggs,single,bucket,aggregation,get,doc,count,as,list,single,bucket,aggregation,get,aggregations,stream,filter,aggregation,aggregation,instanceof,multi,buckets,aggregation,aggregation,instanceof,single,bucket,aggregation,collect,collectors,to,list,if,no,more,buckets,to,process,queue,doc,to,write,key,value,pairs,doc,count,added,leaf,keys,for,each,k,key,value,pairs,remove,k
AggregationToJsonProcessor -> AggregationToJsonProcessor(String timeField, Set<String> fields, boolean includeDocCount, long startTime)             throws IOException;1524684173;Constructs a processor that processes aggregations into JSON__@param timeField the time field_@param fields the fields to convert into JSON_@param includeDocCount whether to include the doc_count_@param startTime buckets with a timestamp before this time are discarded;AggregationToJsonProcessor(String timeField, Set<String> fields, boolean includeDocCount, long startTime)_            throws IOException {_        this.timeField = Objects.requireNonNull(timeField)__        this.fields = Objects.requireNonNull(fields)__        this.includeDocCount = includeDocCount__        keyValuePairs = new LinkedHashMap<>()__        docsByBucketTimestamp = new TreeMap<>()__        keyValueWrittenCount = 0__        this.startTime = startTime__    };constructs,a,processor,that,processes,aggregations,into,json,param,time,field,the,time,field,param,fields,the,fields,to,convert,into,json,param,include,doc,count,whether,to,include,the,param,start,time,buckets,with,a,timestamp,before,this,time,are,discarded;aggregation,to,json,processor,string,time,field,set,string,fields,boolean,include,doc,count,long,start,time,throws,ioexception,this,time,field,objects,require,non,null,time,field,this,fields,objects,require,non,null,fields,this,include,doc,count,include,doc,count,key,value,pairs,new,linked,hash,map,docs,by,bucket,timestamp,new,tree,map,key,value,written,count,0,this,start,time,start,time
AggregationToJsonProcessor -> AggregationToJsonProcessor(String timeField, Set<String> fields, boolean includeDocCount, long startTime)             throws IOException;1536314350;Constructs a processor that processes aggregations into JSON__@param timeField the time field_@param fields the fields to convert into JSON_@param includeDocCount whether to include the doc_count_@param startTime buckets with a timestamp before this time are discarded;AggregationToJsonProcessor(String timeField, Set<String> fields, boolean includeDocCount, long startTime)_            throws IOException {_        this.timeField = Objects.requireNonNull(timeField)__        this.fields = Objects.requireNonNull(fields)__        this.includeDocCount = includeDocCount__        keyValuePairs = new LinkedHashMap<>()__        docsByBucketTimestamp = new TreeMap<>()__        keyValueWrittenCount = 0__        this.startTime = startTime__    };constructs,a,processor,that,processes,aggregations,into,json,param,time,field,the,time,field,param,fields,the,fields,to,convert,into,json,param,include,doc,count,whether,to,include,the,param,start,time,buckets,with,a,timestamp,before,this,time,are,discarded;aggregation,to,json,processor,string,time,field,set,string,fields,boolean,include,doc,count,long,start,time,throws,ioexception,this,time,field,objects,require,non,null,time,field,this,fields,objects,require,non,null,fields,this,include,doc,count,include,doc,count,key,value,pairs,new,linked,hash,map,docs,by,bucket,timestamp,new,tree,map,key,value,written,count,0,this,start,time,start,time
AggregationToJsonProcessor -> AggregationToJsonProcessor(String timeField, Set<String> fields, boolean includeDocCount, long startTime)             throws IOException;1540847035;Constructs a processor that processes aggregations into JSON__@param timeField the time field_@param fields the fields to convert into JSON_@param includeDocCount whether to include the doc_count_@param startTime buckets with a timestamp before this time are discarded;AggregationToJsonProcessor(String timeField, Set<String> fields, boolean includeDocCount, long startTime)_            throws IOException {_        this.timeField = Objects.requireNonNull(timeField)__        this.fields = Objects.requireNonNull(fields)__        this.includeDocCount = includeDocCount__        keyValuePairs = new LinkedHashMap<>()__        docsByBucketTimestamp = new TreeMap<>()__        keyValueWrittenCount = 0__        this.startTime = startTime__    };constructs,a,processor,that,processes,aggregations,into,json,param,time,field,the,time,field,param,fields,the,fields,to,convert,into,json,param,include,doc,count,whether,to,include,the,param,start,time,buckets,with,a,timestamp,before,this,time,are,discarded;aggregation,to,json,processor,string,time,field,set,string,fields,boolean,include,doc,count,long,start,time,throws,ioexception,this,time,field,objects,require,non,null,time,field,this,fields,objects,require,non,null,fields,this,include,doc,count,include,doc,count,key,value,pairs,new,linked,hash,map,docs,by,bucket,timestamp,new,tree,map,key,value,written,count,0,this,start,time,start,time
AggregationToJsonProcessor -> AggregationToJsonProcessor(String timeField, Set<String> fields, boolean includeDocCount, long startTime)             throws IOException;1547845733;Constructs a processor that processes aggregations into JSON__@param timeField the time field_@param fields the fields to convert into JSON_@param includeDocCount whether to include the doc_count_@param startTime buckets with a timestamp before this time are discarded;AggregationToJsonProcessor(String timeField, Set<String> fields, boolean includeDocCount, long startTime)_            throws IOException {_        this.timeField = Objects.requireNonNull(timeField)__        this.fields = Objects.requireNonNull(fields)__        this.includeDocCount = includeDocCount__        keyValuePairs = new LinkedHashMap<>()__        docsByBucketTimestamp = new TreeMap<>()__        keyValueWrittenCount = 0__        this.startTime = startTime__    };constructs,a,processor,that,processes,aggregations,into,json,param,time,field,the,time,field,param,fields,the,fields,to,convert,into,json,param,include,doc,count,whether,to,include,the,param,start,time,buckets,with,a,timestamp,before,this,time,are,discarded;aggregation,to,json,processor,string,time,field,set,string,fields,boolean,include,doc,count,long,start,time,throws,ioexception,this,time,field,objects,require,non,null,time,field,this,fields,objects,require,non,null,fields,this,include,doc,count,include,doc,count,key,value,pairs,new,linked,hash,map,docs,by,bucket,timestamp,new,tree,map,key,value,written,count,0,this,start,time,start,time
AggregationToJsonProcessor -> AggregationToJsonProcessor(String timeField, Set<String> fields, boolean includeDocCount, long startTime)             throws IOException;1548236405;Constructs a processor that processes aggregations into JSON__@param timeField the time field_@param fields the fields to convert into JSON_@param includeDocCount whether to include the doc_count_@param startTime buckets with a timestamp before this time are discarded;AggregationToJsonProcessor(String timeField, Set<String> fields, boolean includeDocCount, long startTime)_            throws IOException {_        this.timeField = Objects.requireNonNull(timeField)__        this.fields = Objects.requireNonNull(fields)__        this.includeDocCount = includeDocCount__        keyValuePairs = new LinkedHashMap<>()__        docsByBucketTimestamp = new TreeMap<>()__        keyValueWrittenCount = 0__        this.startTime = startTime__    };constructs,a,processor,that,processes,aggregations,into,json,param,time,field,the,time,field,param,fields,the,fields,to,convert,into,json,param,include,doc,count,whether,to,include,the,param,start,time,buckets,with,a,timestamp,before,this,time,are,discarded;aggregation,to,json,processor,string,time,field,set,string,fields,boolean,include,doc,count,long,start,time,throws,ioexception,this,time,field,objects,require,non,null,time,field,this,fields,objects,require,non,null,fields,this,include,doc,count,include,doc,count,key,value,pairs,new,linked,hash,map,docs,by,bucket,timestamp,new,tree,map,key,value,written,count,0,this,start,time,start,time
AggregationToJsonProcessor -> public long getKeyValueCount();1524684173;The key-value pairs that have been written so far;public long getKeyValueCount() {_        return keyValueWrittenCount__    };the,key,value,pairs,that,have,been,written,so,far;public,long,get,key,value,count,return,key,value,written,count
AggregationToJsonProcessor -> public long getKeyValueCount();1536314350;The key-value pairs that have been written so far;public long getKeyValueCount() {_        return keyValueWrittenCount__    };the,key,value,pairs,that,have,been,written,so,far;public,long,get,key,value,count,return,key,value,written,count
AggregationToJsonProcessor -> public long getKeyValueCount();1540847035;The key-value pairs that have been written so far;public long getKeyValueCount() {_        return keyValueWrittenCount__    };the,key,value,pairs,that,have,been,written,so,far;public,long,get,key,value,count,return,key,value,written,count
AggregationToJsonProcessor -> public long getKeyValueCount();1547845733;The key-value pairs that have been written so far;public long getKeyValueCount() {_        return keyValueWrittenCount__    };the,key,value,pairs,that,have,been,written,so,far;public,long,get,key,value,count,return,key,value,written,count
AggregationToJsonProcessor -> public long getKeyValueCount();1548236405;The key-value pairs that have been written so far;public long getKeyValueCount() {_        return keyValueWrittenCount__    };the,key,value,pairs,that,have,been,written,so,far;public,long,get,key,value,count,return,key,value,written,count
AggregationToJsonProcessor -> boolean writeDocs(int batchSize, OutputStream outputStream) throws IOException;1524684173;Write the aggregated documents one bucket at a time until {@code batchSize}_key-value pairs have been written. Buckets are written in their entirety and_the check on {@code batchSize} run after the bucket has been written so more_than {@code batchSize} key-value pairs could be written._The function should be called repeatedly until it returns false, at that point_there are no more documents to write.__@param batchSize The number of key-value pairs to write._@return True if there are any more documents to write after the call._False if there are no documents to write._@throws IOException If an error occurs serialising the JSON;boolean writeDocs(int batchSize, OutputStream outputStream) throws IOException {__        if (docsByBucketTimestamp.isEmpty()) {_            return false__        }__        try (XContentBuilder jsonBuilder = new XContentBuilder(JsonXContent.jsonXContent, outputStream)) {_            long previousWrittenCount = keyValueWrittenCount__            Iterator<Map.Entry<Long, List<Map<String, Object>>>> iterator = docsByBucketTimestamp.entrySet().iterator()__            while (iterator.hasNext()) {_                Map.Entry<Long, List<Map<String, Object>>> entry = iterator.next()__                for (Map<String, Object> map : entry.getValue()) {_                    writeJsonObject(jsonBuilder, map)__                }_                iterator.remove()___                if (keyValueWrittenCount - previousWrittenCount >= batchSize) {_                    break__                }_            }_        }__        return docsByBucketTimestamp.isEmpty() == false__    };write,the,aggregated,documents,one,bucket,at,a,time,until,code,batch,size,key,value,pairs,have,been,written,buckets,are,written,in,their,entirety,and,the,check,on,code,batch,size,run,after,the,bucket,has,been,written,so,more,than,code,batch,size,key,value,pairs,could,be,written,the,function,should,be,called,repeatedly,until,it,returns,false,at,that,point,there,are,no,more,documents,to,write,param,batch,size,the,number,of,key,value,pairs,to,write,return,true,if,there,are,any,more,documents,to,write,after,the,call,false,if,there,are,no,documents,to,write,throws,ioexception,if,an,error,occurs,serialising,the,json;boolean,write,docs,int,batch,size,output,stream,output,stream,throws,ioexception,if,docs,by,bucket,timestamp,is,empty,return,false,try,xcontent,builder,json,builder,new,xcontent,builder,json,xcontent,json,xcontent,output,stream,long,previous,written,count,key,value,written,count,iterator,map,entry,long,list,map,string,object,iterator,docs,by,bucket,timestamp,entry,set,iterator,while,iterator,has,next,map,entry,long,list,map,string,object,entry,iterator,next,for,map,string,object,map,entry,get,value,write,json,object,json,builder,map,iterator,remove,if,key,value,written,count,previous,written,count,batch,size,break,return,docs,by,bucket,timestamp,is,empty,false
AggregationToJsonProcessor -> boolean writeDocs(int batchSize, OutputStream outputStream) throws IOException;1536314350;Write the aggregated documents one bucket at a time until {@code batchSize}_key-value pairs have been written. Buckets are written in their entirety and_the check on {@code batchSize} run after the bucket has been written so more_than {@code batchSize} key-value pairs could be written._The function should be called repeatedly until it returns false, at that point_there are no more documents to write.__@param batchSize The number of key-value pairs to write._@return True if there are any more documents to write after the call._False if there are no documents to write._@throws IOException If an error occurs serialising the JSON;boolean writeDocs(int batchSize, OutputStream outputStream) throws IOException {__        if (docsByBucketTimestamp.isEmpty()) {_            return false__        }__        try (XContentBuilder jsonBuilder = new XContentBuilder(JsonXContent.jsonXContent, outputStream)) {_            long previousWrittenCount = keyValueWrittenCount__            Iterator<Map.Entry<Long, List<Map<String, Object>>>> iterator = docsByBucketTimestamp.entrySet().iterator()__            while (iterator.hasNext()) {_                Map.Entry<Long, List<Map<String, Object>>> entry = iterator.next()__                for (Map<String, Object> map : entry.getValue()) {_                    writeJsonObject(jsonBuilder, map)__                }_                iterator.remove()___                if (keyValueWrittenCount - previousWrittenCount >= batchSize) {_                    break__                }_            }_        }__        return docsByBucketTimestamp.isEmpty() == false__    };write,the,aggregated,documents,one,bucket,at,a,time,until,code,batch,size,key,value,pairs,have,been,written,buckets,are,written,in,their,entirety,and,the,check,on,code,batch,size,run,after,the,bucket,has,been,written,so,more,than,code,batch,size,key,value,pairs,could,be,written,the,function,should,be,called,repeatedly,until,it,returns,false,at,that,point,there,are,no,more,documents,to,write,param,batch,size,the,number,of,key,value,pairs,to,write,return,true,if,there,are,any,more,documents,to,write,after,the,call,false,if,there,are,no,documents,to,write,throws,ioexception,if,an,error,occurs,serialising,the,json;boolean,write,docs,int,batch,size,output,stream,output,stream,throws,ioexception,if,docs,by,bucket,timestamp,is,empty,return,false,try,xcontent,builder,json,builder,new,xcontent,builder,json,xcontent,json,xcontent,output,stream,long,previous,written,count,key,value,written,count,iterator,map,entry,long,list,map,string,object,iterator,docs,by,bucket,timestamp,entry,set,iterator,while,iterator,has,next,map,entry,long,list,map,string,object,entry,iterator,next,for,map,string,object,map,entry,get,value,write,json,object,json,builder,map,iterator,remove,if,key,value,written,count,previous,written,count,batch,size,break,return,docs,by,bucket,timestamp,is,empty,false
AggregationToJsonProcessor -> boolean writeDocs(int batchSize, OutputStream outputStream) throws IOException;1540847035;Write the aggregated documents one bucket at a time until {@code batchSize}_key-value pairs have been written. Buckets are written in their entirety and_the check on {@code batchSize} run after the bucket has been written so more_than {@code batchSize} key-value pairs could be written._The function should be called repeatedly until it returns false, at that point_there are no more documents to write.__@param batchSize The number of key-value pairs to write._@return True if there are any more documents to write after the call._False if there are no documents to write._@throws IOException If an error occurs serialising the JSON;boolean writeDocs(int batchSize, OutputStream outputStream) throws IOException {__        if (docsByBucketTimestamp.isEmpty()) {_            return false__        }__        try (XContentBuilder jsonBuilder = new XContentBuilder(JsonXContent.jsonXContent, outputStream)) {_            long previousWrittenCount = keyValueWrittenCount__            Iterator<Map.Entry<Long, List<Map<String, Object>>>> iterator = docsByBucketTimestamp.entrySet().iterator()__            while (iterator.hasNext()) {_                Map.Entry<Long, List<Map<String, Object>>> entry = iterator.next()__                for (Map<String, Object> map : entry.getValue()) {_                    writeJsonObject(jsonBuilder, map)__                }_                iterator.remove()___                if (keyValueWrittenCount - previousWrittenCount >= batchSize) {_                    break__                }_            }_        }__        return docsByBucketTimestamp.isEmpty() == false__    };write,the,aggregated,documents,one,bucket,at,a,time,until,code,batch,size,key,value,pairs,have,been,written,buckets,are,written,in,their,entirety,and,the,check,on,code,batch,size,run,after,the,bucket,has,been,written,so,more,than,code,batch,size,key,value,pairs,could,be,written,the,function,should,be,called,repeatedly,until,it,returns,false,at,that,point,there,are,no,more,documents,to,write,param,batch,size,the,number,of,key,value,pairs,to,write,return,true,if,there,are,any,more,documents,to,write,after,the,call,false,if,there,are,no,documents,to,write,throws,ioexception,if,an,error,occurs,serialising,the,json;boolean,write,docs,int,batch,size,output,stream,output,stream,throws,ioexception,if,docs,by,bucket,timestamp,is,empty,return,false,try,xcontent,builder,json,builder,new,xcontent,builder,json,xcontent,json,xcontent,output,stream,long,previous,written,count,key,value,written,count,iterator,map,entry,long,list,map,string,object,iterator,docs,by,bucket,timestamp,entry,set,iterator,while,iterator,has,next,map,entry,long,list,map,string,object,entry,iterator,next,for,map,string,object,map,entry,get,value,write,json,object,json,builder,map,iterator,remove,if,key,value,written,count,previous,written,count,batch,size,break,return,docs,by,bucket,timestamp,is,empty,false
AggregationToJsonProcessor -> boolean writeDocs(int batchSize, OutputStream outputStream) throws IOException;1547845733;Write the aggregated documents one bucket at a time until {@code batchSize}_key-value pairs have been written. Buckets are written in their entirety and_the check on {@code batchSize} run after the bucket has been written so more_than {@code batchSize} key-value pairs could be written._The function should be called repeatedly until it returns false, at that point_there are no more documents to write.__@param batchSize The number of key-value pairs to write._@return True if there are any more documents to write after the call._False if there are no documents to write._@throws IOException If an error occurs serialising the JSON;boolean writeDocs(int batchSize, OutputStream outputStream) throws IOException {__        if (docsByBucketTimestamp.isEmpty()) {_            return false__        }__        try (XContentBuilder jsonBuilder = new XContentBuilder(JsonXContent.jsonXContent, outputStream)) {_            long previousWrittenCount = keyValueWrittenCount__            Iterator<Map.Entry<Long, List<Map<String, Object>>>> iterator = docsByBucketTimestamp.entrySet().iterator()__            while (iterator.hasNext()) {_                Map.Entry<Long, List<Map<String, Object>>> entry = iterator.next()__                for (Map<String, Object> map : entry.getValue()) {_                    writeJsonObject(jsonBuilder, map)__                }_                iterator.remove()___                if (keyValueWrittenCount - previousWrittenCount >= batchSize) {_                    break__                }_            }_        }__        return docsByBucketTimestamp.isEmpty() == false__    };write,the,aggregated,documents,one,bucket,at,a,time,until,code,batch,size,key,value,pairs,have,been,written,buckets,are,written,in,their,entirety,and,the,check,on,code,batch,size,run,after,the,bucket,has,been,written,so,more,than,code,batch,size,key,value,pairs,could,be,written,the,function,should,be,called,repeatedly,until,it,returns,false,at,that,point,there,are,no,more,documents,to,write,param,batch,size,the,number,of,key,value,pairs,to,write,return,true,if,there,are,any,more,documents,to,write,after,the,call,false,if,there,are,no,documents,to,write,throws,ioexception,if,an,error,occurs,serialising,the,json;boolean,write,docs,int,batch,size,output,stream,output,stream,throws,ioexception,if,docs,by,bucket,timestamp,is,empty,return,false,try,xcontent,builder,json,builder,new,xcontent,builder,json,xcontent,json,xcontent,output,stream,long,previous,written,count,key,value,written,count,iterator,map,entry,long,list,map,string,object,iterator,docs,by,bucket,timestamp,entry,set,iterator,while,iterator,has,next,map,entry,long,list,map,string,object,entry,iterator,next,for,map,string,object,map,entry,get,value,write,json,object,json,builder,map,iterator,remove,if,key,value,written,count,previous,written,count,batch,size,break,return,docs,by,bucket,timestamp,is,empty,false
AggregationToJsonProcessor -> boolean writeDocs(int batchSize, OutputStream outputStream) throws IOException;1548236405;Write the aggregated documents one bucket at a time until {@code batchSize}_key-value pairs have been written. Buckets are written in their entirety and_the check on {@code batchSize} run after the bucket has been written so more_than {@code batchSize} key-value pairs could be written._The function should be called repeatedly until it returns false, at that point_there are no more documents to write.__@param batchSize The number of key-value pairs to write._@return True if there are any more documents to write after the call._False if there are no documents to write._@throws IOException If an error occurs serialising the JSON;boolean writeDocs(int batchSize, OutputStream outputStream) throws IOException {__        if (docsByBucketTimestamp.isEmpty()) {_            return false__        }__        try (XContentBuilder jsonBuilder = new XContentBuilder(JsonXContent.jsonXContent, outputStream)) {_            long previousWrittenCount = keyValueWrittenCount__            Iterator<Map.Entry<Long, List<Map<String, Object>>>> iterator = docsByBucketTimestamp.entrySet().iterator()__            while (iterator.hasNext()) {_                Map.Entry<Long, List<Map<String, Object>>> entry = iterator.next()__                for (Map<String, Object> map : entry.getValue()) {_                    writeJsonObject(jsonBuilder, map)__                }_                iterator.remove()___                if (keyValueWrittenCount - previousWrittenCount >= batchSize) {_                    break__                }_            }_        }__        return docsByBucketTimestamp.isEmpty() == false__    };write,the,aggregated,documents,one,bucket,at,a,time,until,code,batch,size,key,value,pairs,have,been,written,buckets,are,written,in,their,entirety,and,the,check,on,code,batch,size,run,after,the,bucket,has,been,written,so,more,than,code,batch,size,key,value,pairs,could,be,written,the,function,should,be,called,repeatedly,until,it,returns,false,at,that,point,there,are,no,more,documents,to,write,param,batch,size,the,number,of,key,value,pairs,to,write,return,true,if,there,are,any,more,documents,to,write,after,the,call,false,if,there,are,no,documents,to,write,throws,ioexception,if,an,error,occurs,serialising,the,json;boolean,write,docs,int,batch,size,output,stream,output,stream,throws,ioexception,if,docs,by,bucket,timestamp,is,empty,return,false,try,xcontent,builder,json,builder,new,xcontent,builder,json,xcontent,json,xcontent,output,stream,long,previous,written,count,key,value,written,count,iterator,map,entry,long,list,map,string,object,iterator,docs,by,bucket,timestamp,entry,set,iterator,while,iterator,has,next,map,entry,long,list,map,string,object,entry,iterator,next,for,map,string,object,map,entry,get,value,write,json,object,json,builder,map,iterator,remove,if,key,value,written,count,previous,written,count,batch,size,break,return,docs,by,bucket,timestamp,is,empty,false
