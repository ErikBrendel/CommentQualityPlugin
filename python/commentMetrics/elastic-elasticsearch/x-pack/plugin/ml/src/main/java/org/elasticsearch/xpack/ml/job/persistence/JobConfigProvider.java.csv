commented;modifiers;parameterAmount;loc;comment;code
true;public;2;24;/**  * Persist the anomaly detector job configuration to the configuration index.  * It is an error if an job with the same Id already exists - the config will  * not be overwritten.  *  * @param job The anomaly detector job configuration  * @param listener Index response listener  */ ;/**  * Persist the anomaly detector job configuration to the configuration index.  * It is an error if an job with the same Id already exists - the config will  * not be overwritten.  *  * @param job The anomaly detector job configuration  * @param listener Index response listener  */ public void putJob(Job job, ActionListener<IndexResponse> listener) {     try (XContentBuilder builder = XContentFactory.jsonBuilder()) {         XContentBuilder source = job.toXContent(builder, new ToXContent.MapParams(TO_XCONTENT_PARAMS)).         IndexRequest indexRequest = new IndexRequest(AnomalyDetectorsIndex.configIndexName()).id(Job.documentId(job.getId())).source(source).opType(DocWriteRequest.OpType.CREATE).setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE).         executeAsyncWithOrigin(client, ML_ORIGIN, IndexAction.INSTANCE, indexRequest, ActionListener.wrap(listener::onResponse, e -> {             if (e instanceof VersionConflictEngineException) {                 // the job already exists                 listener.onFailure(ExceptionsHelper.jobAlreadyExists(job.getId())).             } else {                 listener.onFailure(e).             }         })).     } catch (IOException e) {         listener.onFailure(new ElasticsearchParseException("Failed to serialise job with id [" + job.getId() + "]", e)).     } }
false;public;1;10;;@Override public void onResponse(GetResponse getResponse) {     if (getResponse.isExists() == false) {         jobListener.onFailure(ExceptionsHelper.missingJobException(jobId)).         return.     }     BytesReference source = getResponse.getSourceAsBytesRef().     parseJobLenientlyFromSource(source, jobListener). }
false;public;1;8;;@Override public void onFailure(Exception e) {     if (e.getClass() == IndexNotFoundException.class) {         jobListener.onFailure(ExceptionsHelper.missingJobException(jobId)).     } else {         jobListener.onFailure(e).     } }
true;public;2;25;/**  * Get the anomaly detector job specified by {@code jobId}.  * If the job is missing a {@code ResourceNotFoundException} is returned  * via the listener.  *  * If the .ml-config index does not exist it is treated as a missing job  * error.  *  * @param jobId The job ID  * @param jobListener Job listener  */ ;/**  * Get the anomaly detector job specified by {@code jobId}.  * If the job is missing a {@code ResourceNotFoundException} is returned  * via the listener.  *  * If the .ml-config index does not exist it is treated as a missing job  * error.  *  * @param jobId The job ID  * @param jobListener Job listener  */ public void getJob(String jobId, ActionListener<Job.Builder> jobListener) {     GetRequest getRequest = new GetRequest(AnomalyDetectorsIndex.configIndexName(), Job.documentId(jobId)).     executeAsyncWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN, getRequest, new ActionListener<GetResponse>() {          @Override         public void onResponse(GetResponse getResponse) {             if (getResponse.isExists() == false) {                 jobListener.onFailure(ExceptionsHelper.missingJobException(jobId)).                 return.             }             BytesReference source = getResponse.getSourceAsBytesRef().             parseJobLenientlyFromSource(source, jobListener).         }          @Override         public void onFailure(Exception e) {             if (e.getClass() == IndexNotFoundException.class) {                 jobListener.onFailure(ExceptionsHelper.missingJobException(jobId)).             } else {                 jobListener.onFailure(e).             }         }     }, client::get). }
false;public;1;11;;@Override public void onResponse(DeleteResponse deleteResponse) {     if (errorIfMissing) {         if (deleteResponse.getResult() == DocWriteResponse.Result.NOT_FOUND) {             actionListener.onFailure(ExceptionsHelper.missingJobException(jobId)).             return.         }         assert deleteResponse.getResult() == DocWriteResponse.Result.DELETED.     }     actionListener.onResponse(deleteResponse). }
false;public;1;4;;@Override public void onFailure(Exception e) {     actionListener.onFailure(e). }
true;public;3;22;/**  * Delete the anomaly detector job config document.  * {@code errorIfMissing} controls whether or not an error is returned  * if the document does not exist.  *  * @param jobId The job id  * @param errorIfMissing If the job document does not exist and this is true  *                       listener fails with a ResourceNotFoundException else  *                       the DeleteResponse is always return.  * @param actionListener Deleted job listener  */ ;/**  * Delete the anomaly detector job config document.  * {@code errorIfMissing} controls whether or not an error is returned  * if the document does not exist.  *  * @param jobId The job id  * @param errorIfMissing If the job document does not exist and this is true  *                       listener fails with a ResourceNotFoundException else  *                       the DeleteResponse is always return.  * @param actionListener Deleted job listener  */ public void deleteJob(String jobId, boolean errorIfMissing, ActionListener<DeleteResponse> actionListener) {     DeleteRequest request = new DeleteRequest(AnomalyDetectorsIndex.configIndexName(), Job.documentId(jobId)).     request.setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE).     executeAsyncWithOrigin(client, ML_ORIGIN, DeleteAction.INSTANCE, request, new ActionListener<DeleteResponse>() {          @Override         public void onResponse(DeleteResponse deleteResponse) {             if (errorIfMissing) {                 if (deleteResponse.getResult() == DocWriteResponse.Result.NOT_FOUND) {                     actionListener.onFailure(ExceptionsHelper.missingJobException(jobId)).                     return.                 }                 assert deleteResponse.getResult() == DocWriteResponse.Result.DELETED.             }             actionListener.onResponse(deleteResponse).         }          @Override         public void onFailure(Exception e) {             actionListener.onFailure(e).         }     }). }
false;public;1;31;;@Override public void onResponse(GetResponse getResponse) {     if (getResponse.isExists() == false) {         updatedJobListener.onFailure(ExceptionsHelper.missingJobException(jobId)).         return.     }     final long version = getResponse.getVersion().     final long seqNo = getResponse.getSeqNo().     final long primaryTerm = getResponse.getPrimaryTerm().     BytesReference source = getResponse.getSourceAsBytesRef().     Job.Builder jobBuilder.     try {         jobBuilder = parseJobLenientlyFromSource(source).     } catch (IOException e) {         updatedJobListener.onFailure(new ElasticsearchParseException("Failed to parse job configuration [" + jobId + "]", e)).         return.     }     Job updatedJob.     try {         // Applying the update may result in a validation error         updatedJob = update.mergeWithJob(jobBuilder.build(), maxModelMemoryLimit).     } catch (Exception e) {         updatedJobListener.onFailure(e).         return.     }     indexUpdatedJob(updatedJob, seqNo, primaryTerm, updatedJobListener). }
false;public;1;4;;@Override public void onFailure(Exception e) {     updatedJobListener.onFailure(e). }
true;public;4;43;/**  * Get the job and update it by applying {@code update} then index the changed job  * setting the version in the request. Applying the update may cause a validation error  * which is returned via {@code updatedJobListener}  *  * @param jobId The Id of the job to update  * @param update The job update  * @param maxModelMemoryLimit The maximum model memory allowed. This can be {@code null}  *                            if the job's {@link org.elasticsearch.xpack.core.ml.job.config.AnalysisLimits}  *                            are not changed.  * @param updatedJobListener Updated job listener  */ ;/**  * Get the job and update it by applying {@code update} then index the changed job  * setting the version in the request. Applying the update may cause a validation error  * which is returned via {@code updatedJobListener}  *  * @param jobId The Id of the job to update  * @param update The job update  * @param maxModelMemoryLimit The maximum model memory allowed. This can be {@code null}  *                            if the job's {@link org.elasticsearch.xpack.core.ml.job.config.AnalysisLimits}  *                            are not changed.  * @param updatedJobListener Updated job listener  */ public void updateJob(String jobId, JobUpdate update, ByteSizeValue maxModelMemoryLimit, ActionListener<Job> updatedJobListener) {     GetRequest getRequest = new GetRequest(AnomalyDetectorsIndex.configIndexName(), Job.documentId(jobId)).     executeAsyncWithOrigin(client, ML_ORIGIN, GetAction.INSTANCE, getRequest, new ActionListener<GetResponse>() {          @Override         public void onResponse(GetResponse getResponse) {             if (getResponse.isExists() == false) {                 updatedJobListener.onFailure(ExceptionsHelper.missingJobException(jobId)).                 return.             }             final long version = getResponse.getVersion().             final long seqNo = getResponse.getSeqNo().             final long primaryTerm = getResponse.getPrimaryTerm().             BytesReference source = getResponse.getSourceAsBytesRef().             Job.Builder jobBuilder.             try {                 jobBuilder = parseJobLenientlyFromSource(source).             } catch (IOException e) {                 updatedJobListener.onFailure(new ElasticsearchParseException("Failed to parse job configuration [" + jobId + "]", e)).                 return.             }             Job updatedJob.             try {                 // Applying the update may result in a validation error                 updatedJob = update.mergeWithJob(jobBuilder.build(), maxModelMemoryLimit).             } catch (Exception e) {                 updatedJobListener.onFailure(e).                 return.             }             indexUpdatedJob(updatedJob, seqNo, primaryTerm, updatedJobListener).         }          @Override         public void onFailure(Exception e) {             updatedJobListener.onFailure(e).         }     }). }
false;;3;1;;void validate(Job job, JobUpdate update, ActionListener<Void> updatedListener).
false;public;1;36;;@Override public void onResponse(GetResponse getResponse) {     if (getResponse.isExists() == false) {         updatedJobListener.onFailure(ExceptionsHelper.missingJobException(jobId)).         return.     }     final long version = getResponse.getVersion().     final long seqNo = getResponse.getSeqNo().     final long primaryTerm = getResponse.getPrimaryTerm().     BytesReference source = getResponse.getSourceAsBytesRef().     Job originalJob.     try {         originalJob = parseJobLenientlyFromSource(source).build().     } catch (Exception e) {         updatedJobListener.onFailure(new ElasticsearchParseException("Failed to parse job configuration [" + jobId + "]", e)).         return.     }     validator.validate(originalJob, update, ActionListener.wrap(validated -> {         Job updatedJob.         try {             // Applying the update may result in a validation error             updatedJob = update.mergeWithJob(originalJob, maxModelMemoryLimit).         } catch (Exception e) {             updatedJobListener.onFailure(e).             return.         }         indexUpdatedJob(updatedJob, seqNo, primaryTerm, updatedJobListener).     }, updatedJobListener::onFailure)). }
false;public;1;4;;@Override public void onFailure(Exception e) {     updatedJobListener.onFailure(e). }
true;public;5;48;/**  * Similar to {@link #updateJob(String, JobUpdate, ByteSizeValue, ActionListener)} but  * with an extra validation step which is called before the updated is applied.  *  * @param jobId The Id of the job to update  * @param update The job update  * @param maxModelMemoryLimit The maximum model memory allowed  * @param validator The job update validator  * @param updatedJobListener Updated job listener  */ ;/**  * Similar to {@link #updateJob(String, JobUpdate, ByteSizeValue, ActionListener)} but  * with an extra validation step which is called before the updated is applied.  *  * @param jobId The Id of the job to update  * @param update The job update  * @param maxModelMemoryLimit The maximum model memory allowed  * @param validator The job update validator  * @param updatedJobListener Updated job listener  */ public void updateJobWithValidation(String jobId, JobUpdate update, ByteSizeValue maxModelMemoryLimit, UpdateValidator validator, ActionListener<Job> updatedJobListener) {     GetRequest getRequest = new GetRequest(AnomalyDetectorsIndex.configIndexName(), Job.documentId(jobId)).     executeAsyncWithOrigin(client, ML_ORIGIN, GetAction.INSTANCE, getRequest, new ActionListener<GetResponse>() {          @Override         public void onResponse(GetResponse getResponse) {             if (getResponse.isExists() == false) {                 updatedJobListener.onFailure(ExceptionsHelper.missingJobException(jobId)).                 return.             }             final long version = getResponse.getVersion().             final long seqNo = getResponse.getSeqNo().             final long primaryTerm = getResponse.getPrimaryTerm().             BytesReference source = getResponse.getSourceAsBytesRef().             Job originalJob.             try {                 originalJob = parseJobLenientlyFromSource(source).build().             } catch (Exception e) {                 updatedJobListener.onFailure(new ElasticsearchParseException("Failed to parse job configuration [" + jobId + "]", e)).                 return.             }             validator.validate(originalJob, update, ActionListener.wrap(validated -> {                 Job updatedJob.                 try {                     // Applying the update may result in a validation error                     updatedJob = update.mergeWithJob(originalJob, maxModelMemoryLimit).                 } catch (Exception e) {                     updatedJobListener.onFailure(e).                     return.                 }                 indexUpdatedJob(updatedJob, seqNo, primaryTerm, updatedJobListener).             }, updatedJobListener::onFailure)).         }          @Override         public void onFailure(Exception e) {             updatedJobListener.onFailure(e).         }     }). }
false;private;4;24;;private void indexUpdatedJob(Job updatedJob, long seqNo, long primaryTerm, ActionListener<Job> updatedJobListener) {     try (XContentBuilder builder = XContentFactory.jsonBuilder()) {         XContentBuilder updatedSource = updatedJob.toXContent(builder, ToXContent.EMPTY_PARAMS).         IndexRequest indexRequest = new IndexRequest(AnomalyDetectorsIndex.configIndexName()).id(Job.documentId(updatedJob.getId())).source(updatedSource).setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE).         indexRequest.setIfSeqNo(seqNo).         indexRequest.setIfPrimaryTerm(primaryTerm).         executeAsyncWithOrigin(client, ML_ORIGIN, IndexAction.INSTANCE, indexRequest, ActionListener.wrap(indexResponse -> {             assert indexResponse.getResult() == DocWriteResponse.Result.UPDATED.             updatedJobListener.onResponse(updatedJob).         }, updatedJobListener::onFailure)).     } catch (IOException e) {         updatedJobListener.onFailure(new ElasticsearchParseException("Failed to serialise job with id [" + updatedJob.getId() + "]", e)).     } }
false;public;1;12;;@Override public void onResponse(GetResponse getResponse) {     if (getResponse.isExists() == false) {         if (errorIfMissing) {             listener.onFailure(ExceptionsHelper.missingJobException(jobId)).         } else {             listener.onResponse(Boolean.FALSE).         }     } else {         listener.onResponse(Boolean.TRUE).     } }
false;public;1;12;;@Override public void onFailure(Exception e) {     if (e.getClass() == IndexNotFoundException.class) {         if (errorIfMissing) {             listener.onFailure(ExceptionsHelper.missingJobException(jobId)).         } else {             listener.onResponse(Boolean.FALSE).         }     } else {         listener.onFailure(e).     } }
true;public;3;32;/**  * Check a job exists. A job exists if it has a configuration document.  * If the .ml-config index does not exist it is treated as a missing job  * error.  *  * Depending on the value of {@code errorIfMissing} if the job does not  * exist a ResourceNotFoundException is returned to the listener,  * otherwise false is returned in the response.  *  * @param jobId             The jobId to check  * @param errorIfMissing    If true and the job is missing the listener fails with  *                          a ResourceNotFoundException else false is returned.  * @param listener          Exists listener  */ ;/**  * Check a job exists. A job exists if it has a configuration document.  * If the .ml-config index does not exist it is treated as a missing job  * error.  *  * Depending on the value of {@code errorIfMissing} if the job does not  * exist a ResourceNotFoundException is returned to the listener,  * otherwise false is returned in the response.  *  * @param jobId             The jobId to check  * @param errorIfMissing    If true and the job is missing the listener fails with  *                          a ResourceNotFoundException else false is returned.  * @param listener          Exists listener  */ public void jobExists(String jobId, boolean errorIfMissing, ActionListener<Boolean> listener) {     GetRequest getRequest = new GetRequest(AnomalyDetectorsIndex.configIndexName(), Job.documentId(jobId)).     getRequest.fetchSourceContext(FetchSourceContext.DO_NOT_FETCH_SOURCE).     executeAsyncWithOrigin(client, ML_ORIGIN, GetAction.INSTANCE, getRequest, new ActionListener<GetResponse>() {          @Override         public void onResponse(GetResponse getResponse) {             if (getResponse.isExists() == false) {                 if (errorIfMissing) {                     listener.onFailure(ExceptionsHelper.missingJobException(jobId)).                 } else {                     listener.onResponse(Boolean.FALSE).                 }             } else {                 listener.onResponse(Boolean.TRUE).             }         }          @Override         public void onFailure(Exception e) {             if (e.getClass() == IndexNotFoundException.class) {                 if (errorIfMissing) {                     listener.onFailure(ExceptionsHelper.missingJobException(jobId)).                 } else {                     listener.onResponse(Boolean.FALSE).                 }             } else {                 listener.onFailure(e).             }         }     }). }
true;public;2;28;/**  * For the list of job Ids find all that match existing jobs Ids.  * The repsonse is all the job Ids in {@code ids} that match an existing  * job Id.  * @param ids Job Ids to find  * @param listener The matched Ids listener  */ ;/**  * For the list of job Ids find all that match existing jobs Ids.  * The repsonse is all the job Ids in {@code ids} that match an existing  * job Id.  * @param ids Job Ids to find  * @param listener The matched Ids listener  */ public void jobIdMatches(List<String> ids, ActionListener<List<String>> listener) {     BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder().     boolQueryBuilder.filter(new TermQueryBuilder(Job.JOB_TYPE.getPreferredName(), Job.ANOMALY_DETECTOR_JOB_TYPE)).     boolQueryBuilder.filter(new TermsQueryBuilder(Job.ID.getPreferredName(), ids)).     SearchSourceBuilder sourceBuilder = new SearchSourceBuilder().query(boolQueryBuilder).     sourceBuilder.fetchSource(false).     sourceBuilder.docValueField(Job.ID.getPreferredName(), null).     SearchRequest searchRequest = client.prepareSearch(AnomalyDetectorsIndex.configIndexName()).setIndicesOptions(IndicesOptions.lenientExpandOpen()).setSource(sourceBuilder).setSize(ids.size()).request().     executeAsyncWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN, searchRequest, ActionListener.<SearchResponse>wrap(response -> {         SearchHit[] hits = response.getHits().getHits().         List<String> matchedIds = new ArrayList<>().         for (SearchHit hit : hits) {             matchedIds.add(hit.field(Job.ID.getPreferredName()).getValue()).         }         listener.onResponse(matchedIds).     }, listener::onFailure), client::search). }
true;public;2;22;/**  * Sets the job's {@code deleting} field to true  * @param jobId     The job to mark as deleting  * @param listener  Responds with true if successful else an error  */ ;/**  * Sets the job's {@code deleting} field to true  * @param jobId     The job to mark as deleting  * @param listener  Responds with true if successful else an error  */ public void markJobAsDeleting(String jobId, ActionListener<Boolean> listener) {     UpdateRequest updateRequest = new UpdateRequest(AnomalyDetectorsIndex.configIndexName(), Job.documentId(jobId)).     updateRequest.retryOnConflict(3).     updateRequest.setRefreshPolicy(WriteRequest.RefreshPolicy.IMMEDIATE).     updateRequest.doc(Collections.singletonMap(Job.DELETING.getPreferredName(), Boolean.TRUE)).     executeAsyncWithOrigin(client, ML_ORIGIN, UpdateAction.INSTANCE, updateRequest, ActionListener.wrap(response -> {         assert (response.getResult() == DocWriteResponse.Result.UPDATED) || (response.getResult() == DocWriteResponse.Result.NOOP).         listener.onResponse(Boolean.TRUE).     }, e -> {         ElasticsearchException[] causes = ElasticsearchException.guessRootCauses(e).         if (causes[0] instanceof DocumentMissingException) {             listener.onFailure(ExceptionsHelper.missingJobException(jobId)).         } else {             listener.onFailure(e).         }     })). }
true;public;4;44;/**  * Expands an expression into the set of matching names. {@code expresssion}  * may be a wildcard, a job group, a job Id or a list of those.  * If {@code expression} == 'ALL', '*' or the empty string then all  * job Ids are returned.  * Job groups are expanded to all the jobs Ids in that group.  *  * If {@code expression} contains a job Id or a Group name then it  * is an error if the job or group do not exist.  *  * For example, given a set of names ["foo-1", "foo-2", "bar-1", bar-2"],  * expressions resolve follows:  * <ul>  *     <li>"foo-1" : ["foo-1"]</li>  *     <li>"bar-1" : ["bar-1"]</li>  *     <li>"foo-1,foo-2" : ["foo-1", "foo-2"]</li>  *     <li>"foo-*" : ["foo-1", "foo-2"]</li>  *     <li>"*-1" : ["bar-1", "foo-1"]</li>  *     <li>"*" : ["bar-1", "bar-2", "foo-1", "foo-2"]</li>  *     <li>"_all" : ["bar-1", "bar-2", "foo-1", "foo-2"]</li>  * </ul>  *  * @param expression the expression to resolve  * @param allowNoJobs if {@code false}, an error is thrown when no name matches the {@code expression}.  *                     This only applies to wild card expressions, if {@code expression} is not a  *                     wildcard then setting this true will not suppress the exception  * @param excludeDeleting If true exclude jobs marked as deleting  * @param listener The expanded job Ids listener  */ ;/**  * Expands an expression into the set of matching names. {@code expresssion}  * may be a wildcard, a job group, a job Id or a list of those.  * If {@code expression} == 'ALL', '*' or the empty string then all  * job Ids are returned.  * Job groups are expanded to all the jobs Ids in that group.  *  * If {@code expression} contains a job Id or a Group name then it  * is an error if the job or group do not exist.  *  * For example, given a set of names ["foo-1", "foo-2", "bar-1", bar-2"],  * expressions resolve follows:  * <ul>  *     <li>"foo-1" : ["foo-1"]</li>  *     <li>"bar-1" : ["bar-1"]</li>  *     <li>"foo-1,foo-2" : ["foo-1", "foo-2"]</li>  *     <li>"foo-*" : ["foo-1", "foo-2"]</li>  *     <li>"*-1" : ["bar-1", "foo-1"]</li>  *     <li>"*" : ["bar-1", "bar-2", "foo-1", "foo-2"]</li>  *     <li>"_all" : ["bar-1", "bar-2", "foo-1", "foo-2"]</li>  * </ul>  *  * @param expression the expression to resolve  * @param allowNoJobs if {@code false}, an error is thrown when no name matches the {@code expression}.  *                     This only applies to wild card expressions, if {@code expression} is not a  *                     wildcard then setting this true will not suppress the exception  * @param excludeDeleting If true exclude jobs marked as deleting  * @param listener The expanded job Ids listener  */ public void expandJobsIds(String expression, boolean allowNoJobs, boolean excludeDeleting, ActionListener<SortedSet<String>> listener) {     String[] tokens = ExpandedIdsMatcher.tokenizeExpression(expression).     SearchSourceBuilder sourceBuilder = new SearchSourceBuilder().query(buildQuery(tokens, excludeDeleting)).     sourceBuilder.sort(Job.ID.getPreferredName()).     sourceBuilder.fetchSource(false).     sourceBuilder.docValueField(Job.ID.getPreferredName(), null).     sourceBuilder.docValueField(Job.GROUPS.getPreferredName(), null).     SearchRequest searchRequest = client.prepareSearch(AnomalyDetectorsIndex.configIndexName()).setIndicesOptions(IndicesOptions.lenientExpandOpen()).setSource(sourceBuilder).setSize(AnomalyDetectorsIndex.CONFIG_INDEX_MAX_RESULTS_WINDOW).request().     ExpandedIdsMatcher requiredMatches = new ExpandedIdsMatcher(tokens, allowNoJobs).     executeAsyncWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN, searchRequest, ActionListener.<SearchResponse>wrap(response -> {         SortedSet<String> jobIds = new TreeSet<>().         SortedSet<String> groupsIds = new TreeSet<>().         SearchHit[] hits = response.getHits().getHits().         for (SearchHit hit : hits) {             jobIds.add(hit.field(Job.ID.getPreferredName()).getValue()).             List<Object> groups = hit.field(Job.GROUPS.getPreferredName()).getValues().             if (groups != null) {                 groupsIds.addAll(groups.stream().map(Object::toString).collect(Collectors.toList())).             }         }         groupsIds.addAll(jobIds).         requiredMatches.filterMatchedIds(groupsIds).         if (requiredMatches.hasUnmatchedIds()) {             // some required jobs were not found             listener.onFailure(ExceptionsHelper.missingJobException(requiredMatches.unmatchedIdsString())).             return.         }         listener.onResponse(jobIds).     }, listener::onFailure), client::search). }
false;private;2;14;;private SearchRequest makeExpandIdsSearchRequest(String expression, boolean excludeDeleting) {     String[] tokens = ExpandedIdsMatcher.tokenizeExpression(expression).     SearchSourceBuilder sourceBuilder = new SearchSourceBuilder().query(buildQuery(tokens, excludeDeleting)).     sourceBuilder.sort(Job.ID.getPreferredName()).     sourceBuilder.fetchSource(false).     sourceBuilder.docValueField(Job.ID.getPreferredName(), null).     sourceBuilder.docValueField(Job.GROUPS.getPreferredName(), null).     return client.prepareSearch(AnomalyDetectorsIndex.configIndexName()).setIndicesOptions(IndicesOptions.lenientExpandOpen()).setSource(sourceBuilder).setSize(AnomalyDetectorsIndex.CONFIG_INDEX_MAX_RESULTS_WINDOW).request(). }
true;public;4;46;/**  * The same logic as {@link #expandJobsIds(String, boolean, boolean, ActionListener)} but  * the full anomaly detector job configuration is returned.  *  * See {@link #expandJobsIds(String, boolean, boolean, ActionListener)}  *  * @param expression the expression to resolve  * @param allowNoJobs if {@code false}, an error is thrown when no name matches the {@code expression}.  *                     This only applies to wild card expressions, if {@code expression} is not a  *                     wildcard then setting this true will not suppress the exception  * @param excludeDeleting If true exclude jobs marked as deleting  * @param listener The expanded jobs listener  */ ;/**  * The same logic as {@link #expandJobsIds(String, boolean, boolean, ActionListener)} but  * the full anomaly detector job configuration is returned.  *  * See {@link #expandJobsIds(String, boolean, boolean, ActionListener)}  *  * @param expression the expression to resolve  * @param allowNoJobs if {@code false}, an error is thrown when no name matches the {@code expression}.  *                     This only applies to wild card expressions, if {@code expression} is not a  *                     wildcard then setting this true will not suppress the exception  * @param excludeDeleting If true exclude jobs marked as deleting  * @param listener The expanded jobs listener  */ public void expandJobs(String expression, boolean allowNoJobs, boolean excludeDeleting, ActionListener<List<Job.Builder>> listener) {     String[] tokens = ExpandedIdsMatcher.tokenizeExpression(expression).     SearchSourceBuilder sourceBuilder = new SearchSourceBuilder().query(buildQuery(tokens, excludeDeleting)).     sourceBuilder.sort(Job.ID.getPreferredName()).     SearchRequest searchRequest = client.prepareSearch(AnomalyDetectorsIndex.configIndexName()).setIndicesOptions(IndicesOptions.lenientExpandOpen()).setSource(sourceBuilder).setSize(AnomalyDetectorsIndex.CONFIG_INDEX_MAX_RESULTS_WINDOW).request().     ExpandedIdsMatcher requiredMatches = new ExpandedIdsMatcher(tokens, allowNoJobs).     executeAsyncWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN, searchRequest, ActionListener.<SearchResponse>wrap(response -> {         List<Job.Builder> jobs = new ArrayList<>().         Set<String> jobAndGroupIds = new HashSet<>().         SearchHit[] hits = response.getHits().getHits().         for (SearchHit hit : hits) {             try {                 BytesReference source = hit.getSourceRef().                 Job.Builder job = parseJobLenientlyFromSource(source).                 jobs.add(job).                 jobAndGroupIds.add(job.getId()).                 jobAndGroupIds.addAll(job.getGroups()).             } catch (IOException e) {                 // TODO A better way to handle this rather than just ignoring the error?                 logger.error("Error parsing anomaly detector job configuration [" + hit.getId() + "]", e).             }         }         requiredMatches.filterMatchedIds(jobAndGroupIds).         if (requiredMatches.hasUnmatchedIds()) {             // some required jobs were not found             listener.onFailure(ExceptionsHelper.missingJobException(requiredMatches.unmatchedIdsString())).             return.         }         listener.onResponse(jobs).     }, listener::onFailure), client::search). }
true;public;2;27;/**  * Expands the list of job group Ids to the set of jobs which are members of the groups.  * Unlike {@link #expandJobsIds(String, boolean, boolean, ActionListener)} it is not an error  * if a group Id does not exist.  * Wildcard expansion of group Ids is not supported.  *  * @param groupIds Group Ids to expand  * @param listener Expanded job Ids listener  */ ;/**  * Expands the list of job group Ids to the set of jobs which are members of the groups.  * Unlike {@link #expandJobsIds(String, boolean, boolean, ActionListener)} it is not an error  * if a group Id does not exist.  * Wildcard expansion of group Ids is not supported.  *  * @param groupIds Group Ids to expand  * @param listener Expanded job Ids listener  */ public void expandGroupIds(List<String> groupIds, ActionListener<SortedSet<String>> listener) {     SearchSourceBuilder sourceBuilder = new SearchSourceBuilder().query(new TermsQueryBuilder(Job.GROUPS.getPreferredName(), groupIds)).     sourceBuilder.sort(Job.ID.getPreferredName(), SortOrder.DESC).     sourceBuilder.fetchSource(false).     sourceBuilder.docValueField(Job.ID.getPreferredName(), null).     SearchRequest searchRequest = client.prepareSearch(AnomalyDetectorsIndex.configIndexName()).setIndicesOptions(IndicesOptions.lenientExpandOpen()).setSource(sourceBuilder).setSize(AnomalyDetectorsIndex.CONFIG_INDEX_MAX_RESULTS_WINDOW).request().     executeAsyncWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN, searchRequest, ActionListener.<SearchResponse>wrap(response -> {         SortedSet<String> jobIds = new TreeSet<>().         SearchHit[] hits = response.getHits().getHits().         for (SearchHit hit : hits) {             jobIds.add(hit.field(Job.ID.getPreferredName()).getValue()).         }         listener.onResponse(jobIds).     }, listener::onFailure), client::search). }
true;public;2;22;/**  * Check if a group exists, that is there exists a job that is a member of  * the group. If there are one or more jobs that define the group then  * the listener responds with true else false.  *  * @param groupId The group Id  * @param listener Returns true, false or a failure  */ ;/**  * Check if a group exists, that is there exists a job that is a member of  * the group. If there are one or more jobs that define the group then  * the listener responds with true else false.  *  * @param groupId The group Id  * @param listener Returns true, false or a failure  */ public void groupExists(String groupId, ActionListener<Boolean> listener) {     BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder().     boolQueryBuilder.filter(new TermQueryBuilder(Job.JOB_TYPE.getPreferredName(), Job.ANOMALY_DETECTOR_JOB_TYPE)).     boolQueryBuilder.filter(new TermQueryBuilder(Job.GROUPS.getPreferredName(), groupId)).     SearchSourceBuilder sourceBuilder = new SearchSourceBuilder().query(boolQueryBuilder).     sourceBuilder.fetchSource(false).     SearchRequest searchRequest = client.prepareSearch(AnomalyDetectorsIndex.configIndexName()).setSize(0).setIndicesOptions(IndicesOptions.lenientExpandOpen()).setSource(sourceBuilder).request().     executeAsyncWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN, searchRequest, ActionListener.<SearchResponse>wrap(response -> {         listener.onResponse(response.getHits().getTotalHits().value > 0).     }, listener::onFailure), client::search). }
true;public;1;34;/**  * Find jobs with custom rules defined.  * @param listener Jobs listener  */ ;/**  * Find jobs with custom rules defined.  * @param listener Jobs listener  */ public void findJobsWithCustomRules(ActionListener<List<Job>> listener) {     String customRulesPath = Strings.collectionToDelimitedString(Arrays.asList(Job.ANALYSIS_CONFIG.getPreferredName(), AnalysisConfig.DETECTORS.getPreferredName(), Detector.CUSTOM_RULES_FIELD.getPreferredName()), ".").     SearchSourceBuilder sourceBuilder = new SearchSourceBuilder().query(QueryBuilders.nestedQuery(customRulesPath, QueryBuilders.existsQuery(customRulesPath), ScoreMode.None)).     SearchRequest searchRequest = client.prepareSearch(AnomalyDetectorsIndex.configIndexName()).setIndicesOptions(IndicesOptions.lenientExpandOpen()).setSource(sourceBuilder).setSize(AnomalyDetectorsIndex.CONFIG_INDEX_MAX_RESULTS_WINDOW).request().     executeAsyncWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN, searchRequest, ActionListener.<SearchResponse>wrap(response -> {         List<Job> jobs = new ArrayList<>().         SearchHit[] hits = response.getHits().getHits().         for (SearchHit hit : hits) {             try {                 BytesReference source = hit.getSourceRef().                 Job job = parseJobLenientlyFromSource(source).build().                 jobs.add(job).             } catch (IOException e) {                 // TODO A better way to handle this rather than just ignoring the error?                 logger.error("Error parsing anomaly detector job configuration [" + hit.getId() + "]", e).             }         }         listener.onResponse(jobs).     }, listener::onFailure), client::search). }
true;public;2;13;/**  * Get the job reference by the datafeed and validate the datafeed config against it  * @param config  Datafeed config  * @param listener Validation listener  */ ;/**  * Get the job reference by the datafeed and validate the datafeed config against it  * @param config  Datafeed config  * @param listener Validation listener  */ public void validateDatafeedJob(DatafeedConfig config, ActionListener<Boolean> listener) {     getJob(config.getJobId(), ActionListener.wrap(jobBuilder -> {         try {             DatafeedJobValidator.validate(config, jobBuilder.build()).             listener.onResponse(Boolean.TRUE).         } catch (Exception e) {             listener.onFailure(e).         }     }, listener::onFailure)). }
false;private;2;9;;private void parseJobLenientlyFromSource(BytesReference source, ActionListener<Job.Builder> jobListener) {     try (InputStream stream = source.streamInput().         XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, stream)) {         jobListener.onResponse(Job.LENIENT_PARSER.apply(parser, null)).     } catch (Exception e) {         jobListener.onFailure(e).     } }
false;private;1;7;;private Job.Builder parseJobLenientlyFromSource(BytesReference source) throws IOException {     try (InputStream stream = source.streamInput().         XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, stream)) {         return Job.LENIENT_PARSER.apply(parser, null).     } }
false;private;2;42;;private QueryBuilder buildQuery(String[] tokens, boolean excludeDeleting) {     QueryBuilder jobQuery = new TermQueryBuilder(Job.JOB_TYPE.getPreferredName(), Job.ANOMALY_DETECTOR_JOB_TYPE).     if (Strings.isAllOrWildcard(tokens) && excludeDeleting == false) {         // match all         return jobQuery.     }     BoolQueryBuilder boolQueryBuilder = new BoolQueryBuilder().     boolQueryBuilder.filter(jobQuery).     BoolQueryBuilder shouldQueries = new BoolQueryBuilder().     if (excludeDeleting) {         // field exists only when the job is marked as deleting         shouldQueries.mustNot(new ExistsQueryBuilder(Job.DELETING.getPreferredName())).         if (Strings.isAllOrWildcard(tokens)) {             boolQueryBuilder.filter(shouldQueries).             return boolQueryBuilder.         }     }     List<String> terms = new ArrayList<>().     for (String token : tokens) {         if (Regex.isSimpleMatchPattern(token)) {             shouldQueries.should(new WildcardQueryBuilder(Job.ID.getPreferredName(), token)).             shouldQueries.should(new WildcardQueryBuilder(Job.GROUPS.getPreferredName(), token)).         } else {             terms.add(token).         }     }     if (terms.isEmpty() == false) {         shouldQueries.should(new TermsQueryBuilder(Job.ID.getPreferredName(), terms)).         shouldQueries.should(new TermsQueryBuilder(Job.GROUPS.getPreferredName(), terms)).     }     if (shouldQueries.should().isEmpty() == false) {         boolQueryBuilder.filter(shouldQueries).     }     return boolQueryBuilder. }
