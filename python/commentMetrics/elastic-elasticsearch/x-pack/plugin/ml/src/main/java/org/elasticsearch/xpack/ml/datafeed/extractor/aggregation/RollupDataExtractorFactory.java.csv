commented;modifiers;parameterAmount;loc;comment;code
false;public;2;16;;@Override public DataExtractor newExtractor(long start, long end) {     long histogramInterval = datafeedConfig.getHistogramIntervalMillis().     AggregationDataExtractorContext dataExtractorContext = new AggregationDataExtractorContext(job.getId(), job.getDataDescription().getTimeField(), job.getAnalysisConfig().analysisFields(), datafeedConfig.getIndices(), datafeedConfig.getParsedQuery(), datafeedConfig.getParsedAggregations(), Intervals.alignToCeil(start, histogramInterval), Intervals.alignToFloor(end, histogramInterval), job.getAnalysisConfig().getSummaryCountFieldName().equals(DatafeedConfig.DOC_COUNT), datafeedConfig.getHeaders()).     return new RollupDataExtractor(client, dataExtractorContext). }
false;public,static;5;49;;public static void create(Client client, DatafeedConfig datafeed, Job job, Map<String, RollableIndexCaps> rollupJobsWithCaps, ActionListener<DataExtractorFactory> listener) {     final AggregationBuilder datafeedHistogramAggregation = getHistogramAggregation(datafeed.getParsedAggregations().getAggregatorFactories()).     if ((datafeedHistogramAggregation instanceof DateHistogramAggregationBuilder) == false) {         listener.onFailure(new IllegalArgumentException("Rollup requires that the datafeed configuration use a [date_histogram] aggregation," + " not a [histogram] aggregation over the time field.")).         return.     }     final String timeField = ((ValuesSourceAggregationBuilder) datafeedHistogramAggregation).field().     Set<ParsedRollupCaps> rollupCapsSet = rollupJobsWithCaps.values().stream().flatMap(rollableIndexCaps -> rollableIndexCaps.getJobCaps().stream()).map(rollupJobCaps -> ParsedRollupCaps.fromJobFieldCaps(rollupJobCaps.getFieldCaps(), timeField)).collect(Collectors.toSet()).     final long datafeedInterval = getHistogramIntervalMillis(datafeedHistogramAggregation).     List<ParsedRollupCaps> validIntervalCaps = rollupCapsSet.stream().filter(rollupCaps -> validInterval(datafeedInterval, rollupCaps)).collect(Collectors.toList()).     if (validIntervalCaps.isEmpty()) {         listener.onFailure(new IllegalArgumentException("Rollup capabilities do not have a [date_histogram] aggregation with an interval " + "that is a multiple of the datafeed's interval.")).         return.     }     final List<ValuesSourceAggregationBuilder> flattenedAggs = new ArrayList<>().     flattenAggregations(datafeed.getParsedAggregations().getAggregatorFactories(), datafeedHistogramAggregation, flattenedAggs).     if (validIntervalCaps.stream().noneMatch(rollupJobConfig -> hasAggregations(rollupJobConfig, flattenedAggs))) {         listener.onFailure(new IllegalArgumentException("Rollup capabilities do not support all the datafeed aggregations at the desired interval.")).         return.     }     listener.onResponse(new RollupDataExtractorFactory(client, datafeed, job)). }
false;private,static;2;14;;private static boolean validInterval(long datafeedInterval, ParsedRollupCaps rollupJobGroupConfig) {     if (rollupJobGroupConfig.hasDatehistogram() == false) {         return false.     }     if ("UTC".equalsIgnoreCase(rollupJobGroupConfig.getTimezone()) == false) {         return false.     }     try {         long jobInterval = validateAndGetCalendarInterval(rollupJobGroupConfig.getInterval()).         return datafeedInterval % jobInterval == 0.     } catch (ElasticsearchStatusException exception) {         return false.     } }
false;private,static;3;10;;private static void flattenAggregations(final Collection<AggregationBuilder> datafeedAggregations, final AggregationBuilder datafeedHistogramAggregation, final List<ValuesSourceAggregationBuilder> flattenedAggregations) {     for (AggregationBuilder aggregationBuilder : datafeedAggregations) {         if (aggregationBuilder.equals(datafeedHistogramAggregation) == false) {             flattenedAggregations.add((ValuesSourceAggregationBuilder) aggregationBuilder).         }         flattenAggregations(aggregationBuilder.getSubAggregations(), datafeedHistogramAggregation, flattenedAggregations).     } }
false;private,static;2;16;;private static boolean hasAggregations(ParsedRollupCaps rollupCaps, List<ValuesSourceAggregationBuilder> datafeedAggregations) {     for (ValuesSourceAggregationBuilder aggregationBuilder : datafeedAggregations) {         String type = aggregationBuilder.getType().         String field = aggregationBuilder.field().         if (aggregationBuilder instanceof TermsAggregationBuilder) {             if (rollupCaps.supportedTerms.contains(field) == false) {                 return false.             }         } else {             if (rollupCaps.supportedMetrics.contains(field + "_" + type) == false) {                 return false.             }         }     }     return true. }
false;private,static;2;24;;private static ParsedRollupCaps fromJobFieldCaps(Map<String, RollupFieldCaps> rollupFieldCaps, String timeField) {     Map<String, Object> datehistogram = null.     RollupFieldCaps timeFieldCaps = rollupFieldCaps.get(timeField).     if (timeFieldCaps != null) {         for (Map<String, Object> agg : timeFieldCaps.getAggs()) {             if (agg.get("agg").equals(DateHistogramAggregationBuilder.NAME)) {                 datehistogram = agg.             }         }     }     Set<String> supportedMetrics = new HashSet<>().     Set<String> supportedTerms = new HashSet<>().     rollupFieldCaps.forEach((field, fieldCaps) -> {         fieldCaps.getAggs().forEach(agg -> {             String type = (String) agg.get("agg").             if (type.equals(TermsAggregationBuilder.NAME)) {                 supportedTerms.add(field).             } else if (aggsToIgnore.contains(type) == false) {                 supportedMetrics.add(field + "_" + type).             }         }).     }).     return new ParsedRollupCaps(supportedMetrics, supportedTerms, datehistogram). }
false;private;0;6;;private String getInterval() {     if (datehistogramAgg == null) {         return null.     }     return (String) datehistogramAgg.get(DateHistogramGroupConfig.INTERVAL). }
false;private;0;6;;private String getTimezone() {     if (datehistogramAgg == null) {         return null.     }     return (String) datehistogramAgg.get(DateHistogramGroupConfig.TIME_ZONE). }
false;private;0;3;;private boolean hasDatehistogram() {     return datehistogramAgg != null. }
