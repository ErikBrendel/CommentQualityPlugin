# id;timestamp;commentText;codeText;commentWords;codeWords
MlConfigMigrator -> public void migrateConfigsWithoutTasks(ClusterState clusterState, ActionListener<Boolean> listener);1545155131;Migrate ml job and datafeed configurations from the clusterstate_to index documents.__Configs to be migrated are read from the cluster state then bulk_indexed into .ml-config. Those successfully indexed are then removed_from the clusterstate.__Migrated jobs have the job version set to v6.6.0 and the custom settings_map has an entry added recording the fact the job was migrated and its_original version e.g._"migrated from version" : v6.1.0___@param clusterState The current clusterstate_@param listener     The success listener;public void migrateConfigsWithoutTasks(ClusterState clusterState, ActionListener<Boolean> listener) {__        if (migrationEligibilityCheck.canStartMigration(clusterState) == false) {_            listener.onResponse(false)__            return__        }__        if (migrationInProgress.compareAndSet(false, true) == false) {_            listener.onResponse(Boolean.FALSE)__            return__        }__        logger.debug("migrating ml configurations")___        ActionListener<Boolean> unMarkMigrationInProgress = ActionListener.wrap(_                response -> {_                    migrationInProgress.set(false)__                    listener.onResponse(response)__                },_                e -> {_                    migrationInProgress.set(false)__                    listener.onFailure(e)__                }_        )___        snapshotMlMeta(MlMetadata.getMlMetadata(clusterState), ActionListener.wrap(_            response -> {_                _                tookConfigSnapshot.set(true)___                List<JobsAndDatafeeds> batches = splitInBatches(clusterState)__                if (batches.isEmpty()) {_                    unMarkMigrationInProgress.onResponse(Boolean.FALSE)__                    return__                }_                migrateBatches(batches, unMarkMigrationInProgress)__            },_            unMarkMigrationInProgress::onFailure_        ))__    };migrate,ml,job,and,datafeed,configurations,from,the,clusterstate,to,index,documents,configs,to,be,migrated,are,read,from,the,cluster,state,then,bulk,indexed,into,ml,config,those,successfully,indexed,are,then,removed,from,the,clusterstate,migrated,jobs,have,the,job,version,set,to,v6,6,0,and,the,custom,settings,map,has,an,entry,added,recording,the,fact,the,job,was,migrated,and,its,original,version,e,g,migrated,from,version,v6,1,0,param,cluster,state,the,current,clusterstate,param,listener,the,success,listener;public,void,migrate,configs,without,tasks,cluster,state,cluster,state,action,listener,boolean,listener,if,migration,eligibility,check,can,start,migration,cluster,state,false,listener,on,response,false,return,if,migration,in,progress,compare,and,set,false,true,false,listener,on,response,boolean,false,return,logger,debug,migrating,ml,configurations,action,listener,boolean,un,mark,migration,in,progress,action,listener,wrap,response,migration,in,progress,set,false,listener,on,response,response,e,migration,in,progress,set,false,listener,on,failure,e,snapshot,ml,meta,ml,metadata,get,ml,metadata,cluster,state,action,listener,wrap,response,took,config,snapshot,set,true,list,jobs,and,datafeeds,batches,split,in,batches,cluster,state,if,batches,is,empty,un,mark,migration,in,progress,on,response,boolean,false,return,migrate,batches,batches,un,mark,migration,in,progress,un,mark,migration,in,progress,on,failure
MlConfigMigrator -> public void migrateConfigsWithoutTasks(ClusterState clusterState, ActionListener<Boolean> listener);1545227023;Migrate ml job and datafeed configurations from the clusterstate_to index documents.__Configs to be migrated are read from the cluster state then bulk_indexed into .ml-config. Those successfully indexed are then removed_from the clusterstate.__Migrated jobs have the job version set to v6.6.0 and the custom settings_map has an entry added recording the fact the job was migrated and its_original version e.g._"migrated from version" : v6.1.0___@param clusterState The current clusterstate_@param listener     The success listener;public void migrateConfigsWithoutTasks(ClusterState clusterState, ActionListener<Boolean> listener) {_        if (migrationInProgress.compareAndSet(false, true) == false) {_            listener.onResponse(Boolean.FALSE)__            return__        }__        ActionListener<Boolean> unMarkMigrationInProgress = ActionListener.wrap(_                response -> {_                    migrationInProgress.set(false)__                    listener.onResponse(response)__                },_                e -> {_                    migrationInProgress.set(false)__                    listener.onFailure(e)__                }_        )___        List<JobsAndDatafeeds> batches = splitInBatches(clusterState)__        if (batches.isEmpty()) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        if (clusterState.metaData().hasIndex(AnomalyDetectorsIndex.configIndexName()) == false) {_            createConfigIndex(ActionListener.wrap(_                    response -> {_                        unMarkMigrationInProgress.onResponse(Boolean.FALSE)__                    },_                    unMarkMigrationInProgress::onFailure_            ))__            return__        }__        if (migrationEligibilityCheck.canStartMigration(clusterState) == false) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        snapshotMlMeta(MlMetadata.getMlMetadata(clusterState), ActionListener.wrap(_                response -> {_                    _                    tookConfigSnapshot.set(true)__                    migrateBatches(batches, unMarkMigrationInProgress)__                },_                unMarkMigrationInProgress::onFailure_        ))__    };migrate,ml,job,and,datafeed,configurations,from,the,clusterstate,to,index,documents,configs,to,be,migrated,are,read,from,the,cluster,state,then,bulk,indexed,into,ml,config,those,successfully,indexed,are,then,removed,from,the,clusterstate,migrated,jobs,have,the,job,version,set,to,v6,6,0,and,the,custom,settings,map,has,an,entry,added,recording,the,fact,the,job,was,migrated,and,its,original,version,e,g,migrated,from,version,v6,1,0,param,cluster,state,the,current,clusterstate,param,listener,the,success,listener;public,void,migrate,configs,without,tasks,cluster,state,cluster,state,action,listener,boolean,listener,if,migration,in,progress,compare,and,set,false,true,false,listener,on,response,boolean,false,return,action,listener,boolean,un,mark,migration,in,progress,action,listener,wrap,response,migration,in,progress,set,false,listener,on,response,response,e,migration,in,progress,set,false,listener,on,failure,e,list,jobs,and,datafeeds,batches,split,in,batches,cluster,state,if,batches,is,empty,un,mark,migration,in,progress,on,response,boolean,false,return,if,cluster,state,meta,data,has,index,anomaly,detectors,index,config,index,name,false,create,config,index,action,listener,wrap,response,un,mark,migration,in,progress,on,response,boolean,false,un,mark,migration,in,progress,on,failure,return,if,migration,eligibility,check,can,start,migration,cluster,state,false,un,mark,migration,in,progress,on,response,boolean,false,return,snapshot,ml,meta,ml,metadata,get,ml,metadata,cluster,state,action,listener,wrap,response,took,config,snapshot,set,true,migrate,batches,batches,un,mark,migration,in,progress,un,mark,migration,in,progress,on,failure
MlConfigMigrator -> public void migrateConfigsWithoutTasks(ClusterState clusterState, ActionListener<Boolean> listener);1546604488;Migrate ml job and datafeed configurations from the clusterstate_to index documents.__Configs to be migrated are read from the cluster state then bulk_indexed into .ml-config. Those successfully indexed are then removed_from the clusterstate.__Migrated jobs have the job version set to v6.6.0 and the custom settings_map has an entry added recording the fact the job was migrated and its_original version e.g._"migrated from version" : v6.1.0___@param clusterState The current clusterstate_@param listener     The success listener;public void migrateConfigsWithoutTasks(ClusterState clusterState, ActionListener<Boolean> listener) {_        if (migrationInProgress.compareAndSet(false, true) == false) {_            listener.onResponse(Boolean.FALSE)__            return__        }__        ActionListener<Boolean> unMarkMigrationInProgress = ActionListener.wrap(_                response -> {_                    migrationInProgress.set(false)__                    listener.onResponse(response)__                },_                e -> {_                    migrationInProgress.set(false)__                    listener.onFailure(e)__                }_        )___        List<JobsAndDatafeeds> batches = splitInBatches(clusterState)__        if (batches.isEmpty()) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        if (clusterState.metaData().hasIndex(AnomalyDetectorsIndex.configIndexName()) == false) {_            createConfigIndex(ActionListener.wrap(_                    response -> {_                        unMarkMigrationInProgress.onResponse(Boolean.FALSE)__                    },_                    unMarkMigrationInProgress::onFailure_            ))__            return__        }__        if (migrationEligibilityCheck.canStartMigration(clusterState) == false) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        snapshotMlMeta(MlMetadata.getMlMetadata(clusterState), ActionListener.wrap(_                response -> {_                    _                    tookConfigSnapshot.set(true)__                    migrateBatches(batches, unMarkMigrationInProgress)__                },_                unMarkMigrationInProgress::onFailure_        ))__    };migrate,ml,job,and,datafeed,configurations,from,the,clusterstate,to,index,documents,configs,to,be,migrated,are,read,from,the,cluster,state,then,bulk,indexed,into,ml,config,those,successfully,indexed,are,then,removed,from,the,clusterstate,migrated,jobs,have,the,job,version,set,to,v6,6,0,and,the,custom,settings,map,has,an,entry,added,recording,the,fact,the,job,was,migrated,and,its,original,version,e,g,migrated,from,version,v6,1,0,param,cluster,state,the,current,clusterstate,param,listener,the,success,listener;public,void,migrate,configs,without,tasks,cluster,state,cluster,state,action,listener,boolean,listener,if,migration,in,progress,compare,and,set,false,true,false,listener,on,response,boolean,false,return,action,listener,boolean,un,mark,migration,in,progress,action,listener,wrap,response,migration,in,progress,set,false,listener,on,response,response,e,migration,in,progress,set,false,listener,on,failure,e,list,jobs,and,datafeeds,batches,split,in,batches,cluster,state,if,batches,is,empty,un,mark,migration,in,progress,on,response,boolean,false,return,if,cluster,state,meta,data,has,index,anomaly,detectors,index,config,index,name,false,create,config,index,action,listener,wrap,response,un,mark,migration,in,progress,on,response,boolean,false,un,mark,migration,in,progress,on,failure,return,if,migration,eligibility,check,can,start,migration,cluster,state,false,un,mark,migration,in,progress,on,response,boolean,false,return,snapshot,ml,meta,ml,metadata,get,ml,metadata,cluster,state,action,listener,wrap,response,took,config,snapshot,set,true,migrate,batches,batches,un,mark,migration,in,progress,un,mark,migration,in,progress,on,failure
MlConfigMigrator -> public void migrateConfigsWithoutTasks(ClusterState clusterState, ActionListener<Boolean> listener);1547065535;Migrate ml job and datafeed configurations from the clusterstate_to index documents.__Configs to be migrated are read from the cluster state then bulk_indexed into .ml-config. Those successfully indexed are then removed_from the clusterstate.__Migrated jobs have the job version set to v6.6.0 and the custom settings_map has an entry added recording the fact the job was migrated and its_original version e.g._"migrated from version" : v6.1.0___@param clusterState The current clusterstate_@param listener     The success listener;public void migrateConfigsWithoutTasks(ClusterState clusterState, ActionListener<Boolean> listener) {_        if (migrationInProgress.compareAndSet(false, true) == false) {_            listener.onResponse(Boolean.FALSE)__            return__        }__        ActionListener<Boolean> unMarkMigrationInProgress = ActionListener.wrap(_                response -> {_                    migrationInProgress.set(false)__                    listener.onResponse(response)__                },_                e -> {_                    migrationInProgress.set(false)__                    listener.onFailure(e)__                }_        )___        List<JobsAndDatafeeds> batches = splitInBatches(clusterState)__        if (batches.isEmpty()) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        if (clusterState.metaData().hasIndex(AnomalyDetectorsIndex.configIndexName()) == false) {_            createConfigIndex(ActionListener.wrap(_                    response -> {_                        unMarkMigrationInProgress.onResponse(Boolean.FALSE)__                    },_                    unMarkMigrationInProgress::onFailure_            ))__            return__        }__        if (migrationEligibilityCheck.canStartMigration(clusterState) == false) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        snapshotMlMeta(MlMetadata.getMlMetadata(clusterState), ActionListener.wrap(_                response -> {_                    _                    tookConfigSnapshot.set(true)__                    migrateBatches(batches, unMarkMigrationInProgress)__                },_                unMarkMigrationInProgress::onFailure_        ))__    };migrate,ml,job,and,datafeed,configurations,from,the,clusterstate,to,index,documents,configs,to,be,migrated,are,read,from,the,cluster,state,then,bulk,indexed,into,ml,config,those,successfully,indexed,are,then,removed,from,the,clusterstate,migrated,jobs,have,the,job,version,set,to,v6,6,0,and,the,custom,settings,map,has,an,entry,added,recording,the,fact,the,job,was,migrated,and,its,original,version,e,g,migrated,from,version,v6,1,0,param,cluster,state,the,current,clusterstate,param,listener,the,success,listener;public,void,migrate,configs,without,tasks,cluster,state,cluster,state,action,listener,boolean,listener,if,migration,in,progress,compare,and,set,false,true,false,listener,on,response,boolean,false,return,action,listener,boolean,un,mark,migration,in,progress,action,listener,wrap,response,migration,in,progress,set,false,listener,on,response,response,e,migration,in,progress,set,false,listener,on,failure,e,list,jobs,and,datafeeds,batches,split,in,batches,cluster,state,if,batches,is,empty,un,mark,migration,in,progress,on,response,boolean,false,return,if,cluster,state,meta,data,has,index,anomaly,detectors,index,config,index,name,false,create,config,index,action,listener,wrap,response,un,mark,migration,in,progress,on,response,boolean,false,un,mark,migration,in,progress,on,failure,return,if,migration,eligibility,check,can,start,migration,cluster,state,false,un,mark,migration,in,progress,on,response,boolean,false,return,snapshot,ml,meta,ml,metadata,get,ml,metadata,cluster,state,action,listener,wrap,response,took,config,snapshot,set,true,migrate,batches,batches,un,mark,migration,in,progress,un,mark,migration,in,progress,on,failure
MlConfigMigrator -> public void migrateConfigsWithoutTasks(ClusterState clusterState, ActionListener<Boolean> listener);1547483987;Migrate ml job and datafeed configurations from the clusterstate_to index documents.__Configs to be migrated are read from the cluster state then bulk_indexed into .ml-config. Those successfully indexed are then removed_from the clusterstate.__Migrated jobs have the job version set to v6.6.0 and the custom settings_map has an entry added recording the fact the job was migrated and its_original version e.g._"migrated from version" : v6.1.0___@param clusterState The current clusterstate_@param listener     The success listener;public void migrateConfigsWithoutTasks(ClusterState clusterState, ActionListener<Boolean> listener) {_        if (migrationInProgress.compareAndSet(false, true) == false) {_            listener.onResponse(Boolean.FALSE)__            return__        }__        ActionListener<Boolean> unMarkMigrationInProgress = ActionListener.wrap(_                response -> {_                    migrationInProgress.set(false)__                    listener.onResponse(response)__                },_                e -> {_                    migrationInProgress.set(false)__                    listener.onFailure(e)__                }_        )___        List<JobsAndDatafeeds> batches = splitInBatches(clusterState)__        if (batches.isEmpty()) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        if (clusterState.metaData().hasIndex(AnomalyDetectorsIndex.configIndexName()) == false) {_            createConfigIndex(ActionListener.wrap(_                    response -> {_                        unMarkMigrationInProgress.onResponse(Boolean.FALSE)__                    },_                    unMarkMigrationInProgress::onFailure_            ))__            return__        }__        if (migrationEligibilityCheck.canStartMigration(clusterState) == false) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        snapshotMlMeta(MlMetadata.getMlMetadata(clusterState), ActionListener.wrap(_                response -> {_                    _                    tookConfigSnapshot.set(true)__                    migrateBatches(batches, unMarkMigrationInProgress)__                },_                unMarkMigrationInProgress::onFailure_        ))__    };migrate,ml,job,and,datafeed,configurations,from,the,clusterstate,to,index,documents,configs,to,be,migrated,are,read,from,the,cluster,state,then,bulk,indexed,into,ml,config,those,successfully,indexed,are,then,removed,from,the,clusterstate,migrated,jobs,have,the,job,version,set,to,v6,6,0,and,the,custom,settings,map,has,an,entry,added,recording,the,fact,the,job,was,migrated,and,its,original,version,e,g,migrated,from,version,v6,1,0,param,cluster,state,the,current,clusterstate,param,listener,the,success,listener;public,void,migrate,configs,without,tasks,cluster,state,cluster,state,action,listener,boolean,listener,if,migration,in,progress,compare,and,set,false,true,false,listener,on,response,boolean,false,return,action,listener,boolean,un,mark,migration,in,progress,action,listener,wrap,response,migration,in,progress,set,false,listener,on,response,response,e,migration,in,progress,set,false,listener,on,failure,e,list,jobs,and,datafeeds,batches,split,in,batches,cluster,state,if,batches,is,empty,un,mark,migration,in,progress,on,response,boolean,false,return,if,cluster,state,meta,data,has,index,anomaly,detectors,index,config,index,name,false,create,config,index,action,listener,wrap,response,un,mark,migration,in,progress,on,response,boolean,false,un,mark,migration,in,progress,on,failure,return,if,migration,eligibility,check,can,start,migration,cluster,state,false,un,mark,migration,in,progress,on,response,boolean,false,return,snapshot,ml,meta,ml,metadata,get,ml,metadata,cluster,state,action,listener,wrap,response,took,config,snapshot,set,true,migrate,batches,batches,un,mark,migration,in,progress,un,mark,migration,in,progress,on,failure
MlConfigMigrator -> static Set<String> documentsNotWritten(BulkResponse response);1545155131;Check for failures in the bulk response and return the_Ids of any documents not written to the index__If the index operation failed because the document already_exists this is not considered an error.__@param response BulkResponse_@return The set of document Ids not written by the bulk request;static Set<String> documentsNotWritten(BulkResponse response) {_        Set<String> failedDocumentIds = new HashSet<>()___        for (BulkItemResponse itemResponse : response.getItems()) {_            if (itemResponse.isFailed()) {_                BulkItemResponse.Failure failure = itemResponse.getFailure()__                failedDocumentIds.add(itemResponse.getFailure().getId())__                logger.info("failed to index ml configuration [" + itemResponse.getFailure().getId() + "], " +_                        itemResponse.getFailure().getMessage())__            } else {_                logger.info("ml configuration [" + itemResponse.getId() + "] indexed")__            }_        }_        return failedDocumentIds__    };check,for,failures,in,the,bulk,response,and,return,the,ids,of,any,documents,not,written,to,the,index,if,the,index,operation,failed,because,the,document,already,exists,this,is,not,considered,an,error,param,response,bulk,response,return,the,set,of,document,ids,not,written,by,the,bulk,request;static,set,string,documents,not,written,bulk,response,response,set,string,failed,document,ids,new,hash,set,for,bulk,item,response,item,response,response,get,items,if,item,response,is,failed,bulk,item,response,failure,failure,item,response,get,failure,failed,document,ids,add,item,response,get,failure,get,id,logger,info,failed,to,index,ml,configuration,item,response,get,failure,get,id,item,response,get,failure,get,message,else,logger,info,ml,configuration,item,response,get,id,indexed,return,failed,document,ids
MlConfigMigrator -> static Set<String> documentsNotWritten(BulkResponse response);1545227023;Check for failures in the bulk response and return the_Ids of any documents not written to the index__If the index operation failed because the document already_exists this is not considered an error.__@param response BulkResponse_@return The set of document Ids not written by the bulk request;static Set<String> documentsNotWritten(BulkResponse response) {_        Set<String> failedDocumentIds = new HashSet<>()___        for (BulkItemResponse itemResponse : response.getItems()) {_            if (itemResponse.isFailed()) {_                BulkItemResponse.Failure failure = itemResponse.getFailure()__                failedDocumentIds.add(itemResponse.getFailure().getId())__                logger.info("failed to index ml configuration [" + itemResponse.getFailure().getId() + "], " +_                        itemResponse.getFailure().getMessage())__            } else {_                logger.info("ml configuration [" + itemResponse.getId() + "] indexed")__            }_        }_        return failedDocumentIds__    };check,for,failures,in,the,bulk,response,and,return,the,ids,of,any,documents,not,written,to,the,index,if,the,index,operation,failed,because,the,document,already,exists,this,is,not,considered,an,error,param,response,bulk,response,return,the,set,of,document,ids,not,written,by,the,bulk,request;static,set,string,documents,not,written,bulk,response,response,set,string,failed,document,ids,new,hash,set,for,bulk,item,response,item,response,response,get,items,if,item,response,is,failed,bulk,item,response,failure,failure,item,response,get,failure,failed,document,ids,add,item,response,get,failure,get,id,logger,info,failed,to,index,ml,configuration,item,response,get,failure,get,id,item,response,get,failure,get,message,else,logger,info,ml,configuration,item,response,get,id,indexed,return,failed,document,ids
MlConfigMigrator -> static Set<String> documentsNotWritten(BulkResponse response);1546604488;Check for failures in the bulk response and return the_Ids of any documents not written to the index__If the index operation failed because the document already_exists this is not considered an error.__@param response BulkResponse_@return The set of document Ids not written by the bulk request;static Set<String> documentsNotWritten(BulkResponse response) {_        Set<String> failedDocumentIds = new HashSet<>()___        for (BulkItemResponse itemResponse : response.getItems()) {_            if (itemResponse.isFailed()) {_                BulkItemResponse.Failure failure = itemResponse.getFailure()__                failedDocumentIds.add(itemResponse.getFailure().getId())__                logger.info("failed to index ml configuration [" + itemResponse.getFailure().getId() + "], " +_                        itemResponse.getFailure().getMessage())__            } else {_                logger.info("ml configuration [" + itemResponse.getId() + "] indexed")__            }_        }_        return failedDocumentIds__    };check,for,failures,in,the,bulk,response,and,return,the,ids,of,any,documents,not,written,to,the,index,if,the,index,operation,failed,because,the,document,already,exists,this,is,not,considered,an,error,param,response,bulk,response,return,the,set,of,document,ids,not,written,by,the,bulk,request;static,set,string,documents,not,written,bulk,response,response,set,string,failed,document,ids,new,hash,set,for,bulk,item,response,item,response,response,get,items,if,item,response,is,failed,bulk,item,response,failure,failure,item,response,get,failure,failed,document,ids,add,item,response,get,failure,get,id,logger,info,failed,to,index,ml,configuration,item,response,get,failure,get,id,item,response,get,failure,get,message,else,logger,info,ml,configuration,item,response,get,id,indexed,return,failed,document,ids
MlConfigMigrator -> static Set<String> documentsNotWritten(BulkResponse response);1547065535;Check for failures in the bulk response and return the_Ids of any documents not written to the index__If the index operation failed because the document already_exists this is not considered an error.__@param response BulkResponse_@return The set of document Ids not written by the bulk request;static Set<String> documentsNotWritten(BulkResponse response) {_        Set<String> failedDocumentIds = new HashSet<>()___        for (BulkItemResponse itemResponse : response.getItems()) {_            if (itemResponse.isFailed()) {_                BulkItemResponse.Failure failure = itemResponse.getFailure()__                failedDocumentIds.add(itemResponse.getFailure().getId())__                logger.info("failed to index ml configuration [" + itemResponse.getFailure().getId() + "], " +_                        itemResponse.getFailure().getMessage())__            } else {_                logger.info("ml configuration [" + itemResponse.getId() + "] indexed")__            }_        }_        return failedDocumentIds__    };check,for,failures,in,the,bulk,response,and,return,the,ids,of,any,documents,not,written,to,the,index,if,the,index,operation,failed,because,the,document,already,exists,this,is,not,considered,an,error,param,response,bulk,response,return,the,set,of,document,ids,not,written,by,the,bulk,request;static,set,string,documents,not,written,bulk,response,response,set,string,failed,document,ids,new,hash,set,for,bulk,item,response,item,response,response,get,items,if,item,response,is,failed,bulk,item,response,failure,failure,item,response,get,failure,failed,document,ids,add,item,response,get,failure,get,id,logger,info,failed,to,index,ml,configuration,item,response,get,failure,get,id,item,response,get,failure,get,message,else,logger,info,ml,configuration,item,response,get,id,indexed,return,failed,document,ids
MlConfigMigrator -> static Set<String> documentsNotWritten(BulkResponse response);1547483987;Check for failures in the bulk response and return the_Ids of any documents not written to the index__If the index operation failed because the document already_exists this is not considered an error.__@param response BulkResponse_@return The set of document Ids not written by the bulk request;static Set<String> documentsNotWritten(BulkResponse response) {_        Set<String> failedDocumentIds = new HashSet<>()___        for (BulkItemResponse itemResponse : response.getItems()) {_            if (itemResponse.isFailed()) {_                BulkItemResponse.Failure failure = itemResponse.getFailure()__                failedDocumentIds.add(itemResponse.getFailure().getId())__                logger.info("failed to index ml configuration [" + itemResponse.getFailure().getId() + "], " +_                        itemResponse.getFailure().getMessage())__            } else {_                logger.info("ml configuration [" + itemResponse.getId() + "] indexed")__            }_        }_        return failedDocumentIds__    };check,for,failures,in,the,bulk,response,and,return,the,ids,of,any,documents,not,written,to,the,index,if,the,index,operation,failed,because,the,document,already,exists,this,is,not,considered,an,error,param,response,bulk,response,return,the,set,of,document,ids,not,written,by,the,bulk,request;static,set,string,documents,not,written,bulk,response,response,set,string,failed,document,ids,new,hash,set,for,bulk,item,response,item,response,response,get,items,if,item,response,is,failed,bulk,item,response,failure,failure,item,response,get,failure,failed,document,ids,add,item,response,get,failure,get,id,logger,info,failed,to,index,ml,configuration,item,response,get,failure,get,id,item,response,get,failure,get,message,else,logger,info,ml,configuration,item,response,get,id,indexed,return,failed,document,ids
MlConfigMigrator -> static Set<String> documentsNotWritten(BulkResponse response);1547576499;Check for failures in the bulk response and return the_Ids of any documents not written to the index__If the index operation failed because the document already_exists this is not considered an error.__@param response BulkResponse_@return The set of document Ids not written by the bulk request;static Set<String> documentsNotWritten(BulkResponse response) {_        Set<String> failedDocumentIds = new HashSet<>()___        for (BulkItemResponse itemResponse : response.getItems()) {_            if (itemResponse.isFailed()) {_                BulkItemResponse.Failure failure = itemResponse.getFailure()__                failedDocumentIds.add(itemResponse.getFailure().getId())__                logger.info("failed to index ml configuration [" + itemResponse.getFailure().getId() + "], " +_                        itemResponse.getFailure().getMessage())__            } else {_                logger.info("ml configuration [" + itemResponse.getId() + "] indexed")__            }_        }_        return failedDocumentIds__    };check,for,failures,in,the,bulk,response,and,return,the,ids,of,any,documents,not,written,to,the,index,if,the,index,operation,failed,because,the,document,already,exists,this,is,not,considered,an,error,param,response,bulk,response,return,the,set,of,document,ids,not,written,by,the,bulk,request;static,set,string,documents,not,written,bulk,response,response,set,string,failed,document,ids,new,hash,set,for,bulk,item,response,item,response,response,get,items,if,item,response,is,failed,bulk,item,response,failure,failure,item,response,get,failure,failed,document,ids,add,item,response,get,failure,get,id,logger,info,failed,to,index,ml,configuration,item,response,get,failure,get,id,item,response,get,failure,get,message,else,logger,info,ml,configuration,item,response,get,id,indexed,return,failed,document,ids
MlConfigMigrator -> static Set<String> documentsNotWritten(BulkResponse response);1547639475;Check for failures in the bulk response and return the_Ids of any documents not written to the index__If the index operation failed because the document already_exists this is not considered an error.__@param response BulkResponse_@return The set of document Ids not written by the bulk request;static Set<String> documentsNotWritten(BulkResponse response) {_        Set<String> failedDocumentIds = new HashSet<>()___        for (BulkItemResponse itemResponse : response.getItems()) {_            if (itemResponse.isFailed()) {_                BulkItemResponse.Failure failure = itemResponse.getFailure()__                failedDocumentIds.add(itemResponse.getFailure().getId())__                logger.info("failed to index ml configuration [" + itemResponse.getFailure().getId() + "], " +_                        itemResponse.getFailure().getMessage())__            } else {_                logger.info("ml configuration [" + itemResponse.getId() + "] indexed")__            }_        }_        return failedDocumentIds__    };check,for,failures,in,the,bulk,response,and,return,the,ids,of,any,documents,not,written,to,the,index,if,the,index,operation,failed,because,the,document,already,exists,this,is,not,considered,an,error,param,response,bulk,response,return,the,set,of,document,ids,not,written,by,the,bulk,request;static,set,string,documents,not,written,bulk,response,response,set,string,failed,document,ids,new,hash,set,for,bulk,item,response,item,response,response,get,items,if,item,response,is,failed,bulk,item,response,failure,failure,item,response,get,failure,failed,document,ids,add,item,response,get,failure,get,id,logger,info,failed,to,index,ml,configuration,item,response,get,failure,get,id,item,response,get,failure,get,message,else,logger,info,ml,configuration,item,response,get,id,indexed,return,failed,document,ids
MlConfigMigrator -> static Set<String> documentsNotWritten(BulkResponse response);1547843554;Check for failures in the bulk response and return the_Ids of any documents not written to the index__If the index operation failed because the document already_exists this is not considered an error.__@param response BulkResponse_@return The set of document Ids not written by the bulk request;static Set<String> documentsNotWritten(BulkResponse response) {_        Set<String> failedDocumentIds = new HashSet<>()___        for (BulkItemResponse itemResponse : response.getItems()) {_            if (itemResponse.isFailed()) {_                BulkItemResponse.Failure failure = itemResponse.getFailure()__                failedDocumentIds.add(itemResponse.getFailure().getId())__                logger.info("failed to index ml configuration [" + itemResponse.getFailure().getId() + "], " +_                        itemResponse.getFailure().getMessage())__            } else {_                logger.info("ml configuration [" + itemResponse.getId() + "] indexed")__            }_        }_        return failedDocumentIds__    };check,for,failures,in,the,bulk,response,and,return,the,ids,of,any,documents,not,written,to,the,index,if,the,index,operation,failed,because,the,document,already,exists,this,is,not,considered,an,error,param,response,bulk,response,return,the,set,of,document,ids,not,written,by,the,bulk,request;static,set,string,documents,not,written,bulk,response,response,set,string,failed,document,ids,new,hash,set,for,bulk,item,response,item,response,response,get,items,if,item,response,is,failed,bulk,item,response,failure,failure,item,response,get,failure,failed,document,ids,add,item,response,get,failure,get,id,logger,info,failed,to,index,ml,configuration,item,response,get,failure,get,id,item,response,get,failure,get,message,else,logger,info,ml,configuration,item,response,get,id,indexed,return,failed,document,ids
MlConfigMigrator -> public static List<DatafeedConfig> stopppedOrUnallocatedDatafeeds(ClusterState clusterState);1547576499;Find the configurations for stopped datafeeds and datafeeds that do_not have an allocation in the cluster state._Stopped datafeeds are those that do not have an associated persistent task,_unallocated datafeeds have a task but no executing node.__@param clusterState The cluster state_@return The closed job configurations;public static List<DatafeedConfig> stopppedOrUnallocatedDatafeeds(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> startedDatafeedIds = MlTasks.startedDatafeedIds(persistentTasks)__        startedDatafeedIds.removeAll(MlTasks.unallocatedDatafeedIds(persistentTasks, clusterState.nodes()))___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getDatafeeds().values().stream()_                .filter(datafeedConfig-> startedDatafeedIds.contains(datafeedConfig.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,stopped,datafeeds,and,datafeeds,that,do,not,have,an,allocation,in,the,cluster,state,stopped,datafeeds,are,those,that,do,not,have,an,associated,persistent,task,unallocated,datafeeds,have,a,task,but,no,executing,node,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,datafeed,config,stoppped,or,unallocated,datafeeds,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,started,datafeed,ids,ml,tasks,started,datafeed,ids,persistent,tasks,started,datafeed,ids,remove,all,ml,tasks,unallocated,datafeed,ids,persistent,tasks,cluster,state,nodes,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,datafeeds,values,stream,filter,datafeed,config,started,datafeed,ids,contains,datafeed,config,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<DatafeedConfig> stopppedOrUnallocatedDatafeeds(ClusterState clusterState);1547639475;Find the configurations for stopped datafeeds and datafeeds that do_not have an allocation in the cluster state._Stopped datafeeds are those that do not have an associated persistent task,_unallocated datafeeds have a task but no executing node.__@param clusterState The cluster state_@return The closed job configurations;public static List<DatafeedConfig> stopppedOrUnallocatedDatafeeds(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> startedDatafeedIds = MlTasks.startedDatafeedIds(persistentTasks)__        startedDatafeedIds.removeAll(MlTasks.unallocatedDatafeedIds(persistentTasks, clusterState.nodes()))___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getDatafeeds().values().stream()_                .filter(datafeedConfig-> startedDatafeedIds.contains(datafeedConfig.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,stopped,datafeeds,and,datafeeds,that,do,not,have,an,allocation,in,the,cluster,state,stopped,datafeeds,are,those,that,do,not,have,an,associated,persistent,task,unallocated,datafeeds,have,a,task,but,no,executing,node,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,datafeed,config,stoppped,or,unallocated,datafeeds,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,started,datafeed,ids,ml,tasks,started,datafeed,ids,persistent,tasks,started,datafeed,ids,remove,all,ml,tasks,unallocated,datafeed,ids,persistent,tasks,cluster,state,nodes,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,datafeeds,values,stream,filter,datafeed,config,started,datafeed,ids,contains,datafeed,config,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<DatafeedConfig> stopppedOrUnallocatedDatafeeds(ClusterState clusterState);1547843554;Find the configurations for stopped datafeeds and datafeeds that do_not have an allocation in the cluster state._Stopped datafeeds are those that do not have an associated persistent task,_unallocated datafeeds have a task but no executing node.__@param clusterState The cluster state_@return The closed job configurations;public static List<DatafeedConfig> stopppedOrUnallocatedDatafeeds(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> startedDatafeedIds = MlTasks.startedDatafeedIds(persistentTasks)__        startedDatafeedIds.removeAll(MlTasks.unallocatedDatafeedIds(persistentTasks, clusterState.nodes()))___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getDatafeeds().values().stream()_                .filter(datafeedConfig-> startedDatafeedIds.contains(datafeedConfig.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,stopped,datafeeds,and,datafeeds,that,do,not,have,an,allocation,in,the,cluster,state,stopped,datafeeds,are,those,that,do,not,have,an,associated,persistent,task,unallocated,datafeeds,have,a,task,but,no,executing,node,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,datafeed,config,stoppped,or,unallocated,datafeeds,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,started,datafeed,ids,ml,tasks,started,datafeed,ids,persistent,tasks,started,datafeed,ids,remove,all,ml,tasks,unallocated,datafeed,ids,persistent,tasks,cluster,state,nodes,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,datafeeds,values,stream,filter,datafeed,config,started,datafeed,ids,contains,datafeed,config,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> nonDeletingJobs(List<Job> jobs);1545155131;Filter jobs marked as deleting from the list of jobs_are not marked as deleting.__@param jobs The jobs to filter_@return Jobs not marked as deleting;public static List<Job> nonDeletingJobs(List<Job> jobs) {_        return jobs.stream()_                .filter(job -> job.isDeleting() == false)_                .collect(Collectors.toList())__    };filter,jobs,marked,as,deleting,from,the,list,of,jobs,are,not,marked,as,deleting,param,jobs,the,jobs,to,filter,return,jobs,not,marked,as,deleting;public,static,list,job,non,deleting,jobs,list,job,jobs,return,jobs,stream,filter,job,job,is,deleting,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> nonDeletingJobs(List<Job> jobs);1545227023;Filter jobs marked as deleting from the list of jobs_are not marked as deleting.__@param jobs The jobs to filter_@return Jobs not marked as deleting;public static List<Job> nonDeletingJobs(List<Job> jobs) {_        return jobs.stream()_                .filter(job -> job.isDeleting() == false)_                .collect(Collectors.toList())__    };filter,jobs,marked,as,deleting,from,the,list,of,jobs,are,not,marked,as,deleting,param,jobs,the,jobs,to,filter,return,jobs,not,marked,as,deleting;public,static,list,job,non,deleting,jobs,list,job,jobs,return,jobs,stream,filter,job,job,is,deleting,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> nonDeletingJobs(List<Job> jobs);1546604488;Filter jobs marked as deleting from the list of jobs_are not marked as deleting.__@param jobs The jobs to filter_@return Jobs not marked as deleting;public static List<Job> nonDeletingJobs(List<Job> jobs) {_        return jobs.stream()_                .filter(job -> job.isDeleting() == false)_                .collect(Collectors.toList())__    };filter,jobs,marked,as,deleting,from,the,list,of,jobs,are,not,marked,as,deleting,param,jobs,the,jobs,to,filter,return,jobs,not,marked,as,deleting;public,static,list,job,non,deleting,jobs,list,job,jobs,return,jobs,stream,filter,job,job,is,deleting,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> nonDeletingJobs(List<Job> jobs);1547065535;Filter jobs marked as deleting from the list of jobs_are not marked as deleting.__@param jobs The jobs to filter_@return Jobs not marked as deleting;public static List<Job> nonDeletingJobs(List<Job> jobs) {_        return jobs.stream()_                .filter(job -> job.isDeleting() == false)_                .collect(Collectors.toList())__    };filter,jobs,marked,as,deleting,from,the,list,of,jobs,are,not,marked,as,deleting,param,jobs,the,jobs,to,filter,return,jobs,not,marked,as,deleting;public,static,list,job,non,deleting,jobs,list,job,jobs,return,jobs,stream,filter,job,job,is,deleting,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> nonDeletingJobs(List<Job> jobs);1547483987;Filter jobs marked as deleting from the list of jobs_are not marked as deleting.__@param jobs The jobs to filter_@return Jobs not marked as deleting;public static List<Job> nonDeletingJobs(List<Job> jobs) {_        return jobs.stream()_                .filter(job -> job.isDeleting() == false)_                .collect(Collectors.toList())__    };filter,jobs,marked,as,deleting,from,the,list,of,jobs,are,not,marked,as,deleting,param,jobs,the,jobs,to,filter,return,jobs,not,marked,as,deleting;public,static,list,job,non,deleting,jobs,list,job,jobs,return,jobs,stream,filter,job,job,is,deleting,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> nonDeletingJobs(List<Job> jobs);1547576499;Filter jobs marked as deleting from the list of jobs_are not marked as deleting.__@param jobs The jobs to filter_@return Jobs not marked as deleting;public static List<Job> nonDeletingJobs(List<Job> jobs) {_        return jobs.stream()_                .filter(job -> job.isDeleting() == false)_                .collect(Collectors.toList())__    };filter,jobs,marked,as,deleting,from,the,list,of,jobs,are,not,marked,as,deleting,param,jobs,the,jobs,to,filter,return,jobs,not,marked,as,deleting;public,static,list,job,non,deleting,jobs,list,job,jobs,return,jobs,stream,filter,job,job,is,deleting,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> nonDeletingJobs(List<Job> jobs);1547639475;Filter jobs marked as deleting from the list of jobs_are not marked as deleting.__@param jobs The jobs to filter_@return Jobs not marked as deleting;public static List<Job> nonDeletingJobs(List<Job> jobs) {_        return jobs.stream()_                .filter(job -> job.isDeleting() == false)_                .collect(Collectors.toList())__    };filter,jobs,marked,as,deleting,from,the,list,of,jobs,are,not,marked,as,deleting,param,jobs,the,jobs,to,filter,return,jobs,not,marked,as,deleting;public,static,list,job,non,deleting,jobs,list,job,jobs,return,jobs,stream,filter,job,job,is,deleting,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> nonDeletingJobs(List<Job> jobs);1547843554;Filter jobs marked as deleting from the list of jobs_are not marked as deleting.__@param jobs The jobs to filter_@return Jobs not marked as deleting;public static List<Job> nonDeletingJobs(List<Job> jobs) {_        return jobs.stream()_                .filter(job -> job.isDeleting() == false)_                .collect(Collectors.toList())__    };filter,jobs,marked,as,deleting,from,the,list,of,jobs,are,not,marked,as,deleting,param,jobs,the,jobs,to,filter,return,jobs,not,marked,as,deleting;public,static,list,job,non,deleting,jobs,list,job,jobs,return,jobs,stream,filter,job,job,is,deleting,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> closedOrUnallocatedJobs(ClusterState clusterState);1547576499;Find the configurations for all closed jobs and the jobs that_do not have an allocation in the cluster state._Closed jobs are those that do not have an associated persistent task,_unallocated jobs have a task but no executing node__@param clusterState The cluster state_@return The closed job configurations;public static List<Job> closedOrUnallocatedJobs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> openJobIds = MlTasks.openJobIds(persistentTasks)__        openJobIds.removeAll(MlTasks.unallocatedJobIds(persistentTasks, clusterState.nodes()))___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getJobs().values().stream()_                .filter(job -> openJobIds.contains(job.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,all,closed,jobs,and,the,jobs,that,do,not,have,an,allocation,in,the,cluster,state,closed,jobs,are,those,that,do,not,have,an,associated,persistent,task,unallocated,jobs,have,a,task,but,no,executing,node,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,job,closed,or,unallocated,jobs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,open,job,ids,ml,tasks,open,job,ids,persistent,tasks,open,job,ids,remove,all,ml,tasks,unallocated,job,ids,persistent,tasks,cluster,state,nodes,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,jobs,values,stream,filter,job,open,job,ids,contains,job,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> closedOrUnallocatedJobs(ClusterState clusterState);1547639475;Find the configurations for all closed jobs and the jobs that_do not have an allocation in the cluster state._Closed jobs are those that do not have an associated persistent task,_unallocated jobs have a task but no executing node__@param clusterState The cluster state_@return The closed job configurations;public static List<Job> closedOrUnallocatedJobs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> openJobIds = MlTasks.openJobIds(persistentTasks)__        openJobIds.removeAll(MlTasks.unallocatedJobIds(persistentTasks, clusterState.nodes()))___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getJobs().values().stream()_                .filter(job -> openJobIds.contains(job.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,all,closed,jobs,and,the,jobs,that,do,not,have,an,allocation,in,the,cluster,state,closed,jobs,are,those,that,do,not,have,an,associated,persistent,task,unallocated,jobs,have,a,task,but,no,executing,node,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,job,closed,or,unallocated,jobs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,open,job,ids,ml,tasks,open,job,ids,persistent,tasks,open,job,ids,remove,all,ml,tasks,unallocated,job,ids,persistent,tasks,cluster,state,nodes,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,jobs,values,stream,filter,job,open,job,ids,contains,job,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> closedOrUnallocatedJobs(ClusterState clusterState);1547843554;Find the configurations for all closed jobs and the jobs that_do not have an allocation in the cluster state._Closed jobs are those that do not have an associated persistent task,_unallocated jobs have a task but no executing node__@param clusterState The cluster state_@return The closed job configurations;public static List<Job> closedOrUnallocatedJobs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> openJobIds = MlTasks.openJobIds(persistentTasks)__        openJobIds.removeAll(MlTasks.unallocatedJobIds(persistentTasks, clusterState.nodes()))___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getJobs().values().stream()_                .filter(job -> openJobIds.contains(job.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,all,closed,jobs,and,the,jobs,that,do,not,have,an,allocation,in,the,cluster,state,closed,jobs,are,those,that,do,not,have,an,associated,persistent,task,unallocated,jobs,have,a,task,but,no,executing,node,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,job,closed,or,unallocated,jobs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,open,job,ids,ml,tasks,open,job,ids,persistent,tasks,open,job,ids,remove,all,ml,tasks,unallocated,job,ids,persistent,tasks,cluster,state,nodes,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,jobs,values,stream,filter,job,open,job,ids,contains,job,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> closedJobConfigs(ClusterState clusterState);1545155131;Find the configurations for all closed jobs in the cluster state._Closed jobs are those that do not have an associated persistent task.__@param clusterState The cluster state_@return The closed job configurations;public static List<Job> closedJobConfigs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> openJobIds = MlTasks.openJobIds(persistentTasks)___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getJobs().values().stream()_                .filter(job -> openJobIds.contains(job.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,all,closed,jobs,in,the,cluster,state,closed,jobs,are,those,that,do,not,have,an,associated,persistent,task,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,job,closed,job,configs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,open,job,ids,ml,tasks,open,job,ids,persistent,tasks,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,jobs,values,stream,filter,job,open,job,ids,contains,job,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> closedJobConfigs(ClusterState clusterState);1545227023;Find the configurations for all closed jobs in the cluster state._Closed jobs are those that do not have an associated persistent task.__@param clusterState The cluster state_@return The closed job configurations;public static List<Job> closedJobConfigs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> openJobIds = MlTasks.openJobIds(persistentTasks)___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getJobs().values().stream()_                .filter(job -> openJobIds.contains(job.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,all,closed,jobs,in,the,cluster,state,closed,jobs,are,those,that,do,not,have,an,associated,persistent,task,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,job,closed,job,configs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,open,job,ids,ml,tasks,open,job,ids,persistent,tasks,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,jobs,values,stream,filter,job,open,job,ids,contains,job,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> closedJobConfigs(ClusterState clusterState);1546604488;Find the configurations for all closed jobs in the cluster state._Closed jobs are those that do not have an associated persistent task.__@param clusterState The cluster state_@return The closed job configurations;public static List<Job> closedJobConfigs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> openJobIds = MlTasks.openJobIds(persistentTasks)___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getJobs().values().stream()_                .filter(job -> openJobIds.contains(job.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,all,closed,jobs,in,the,cluster,state,closed,jobs,are,those,that,do,not,have,an,associated,persistent,task,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,job,closed,job,configs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,open,job,ids,ml,tasks,open,job,ids,persistent,tasks,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,jobs,values,stream,filter,job,open,job,ids,contains,job,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> closedJobConfigs(ClusterState clusterState);1547065535;Find the configurations for all closed jobs in the cluster state._Closed jobs are those that do not have an associated persistent task.__@param clusterState The cluster state_@return The closed job configurations;public static List<Job> closedJobConfigs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> openJobIds = MlTasks.openJobIds(persistentTasks)___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getJobs().values().stream()_                .filter(job -> openJobIds.contains(job.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,all,closed,jobs,in,the,cluster,state,closed,jobs,are,those,that,do,not,have,an,associated,persistent,task,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,job,closed,job,configs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,open,job,ids,ml,tasks,open,job,ids,persistent,tasks,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,jobs,values,stream,filter,job,open,job,ids,contains,job,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<Job> closedJobConfigs(ClusterState clusterState);1547483987;Find the configurations for all closed jobs in the cluster state._Closed jobs are those that do not have an associated persistent task.__@param clusterState The cluster state_@return The closed job configurations;public static List<Job> closedJobConfigs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> openJobIds = MlTasks.openJobIds(persistentTasks)___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getJobs().values().stream()_                .filter(job -> openJobIds.contains(job.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,all,closed,jobs,in,the,cluster,state,closed,jobs,are,those,that,do,not,have,an,associated,persistent,task,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,job,closed,job,configs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,open,job,ids,ml,tasks,open,job,ids,persistent,tasks,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,jobs,values,stream,filter,job,open,job,ids,contains,job,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<DatafeedConfig> stoppedDatafeedConfigs(ClusterState clusterState);1545155131;Find the configurations for stopped datafeeds in the cluster state._Stopped datafeeds are those that do not have an associated persistent task.__@param clusterState The cluster state_@return The closed job configurations;public static List<DatafeedConfig> stoppedDatafeedConfigs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> startedDatafeedIds = MlTasks.startedDatafeedIds(persistentTasks)___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getDatafeeds().values().stream()_                .filter(datafeedConfig-> startedDatafeedIds.contains(datafeedConfig.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,stopped,datafeeds,in,the,cluster,state,stopped,datafeeds,are,those,that,do,not,have,an,associated,persistent,task,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,datafeed,config,stopped,datafeed,configs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,started,datafeed,ids,ml,tasks,started,datafeed,ids,persistent,tasks,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,datafeeds,values,stream,filter,datafeed,config,started,datafeed,ids,contains,datafeed,config,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<DatafeedConfig> stoppedDatafeedConfigs(ClusterState clusterState);1545227023;Find the configurations for stopped datafeeds in the cluster state._Stopped datafeeds are those that do not have an associated persistent task.__@param clusterState The cluster state_@return The closed job configurations;public static List<DatafeedConfig> stoppedDatafeedConfigs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> startedDatafeedIds = MlTasks.startedDatafeedIds(persistentTasks)___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getDatafeeds().values().stream()_                .filter(datafeedConfig-> startedDatafeedIds.contains(datafeedConfig.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,stopped,datafeeds,in,the,cluster,state,stopped,datafeeds,are,those,that,do,not,have,an,associated,persistent,task,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,datafeed,config,stopped,datafeed,configs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,started,datafeed,ids,ml,tasks,started,datafeed,ids,persistent,tasks,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,datafeeds,values,stream,filter,datafeed,config,started,datafeed,ids,contains,datafeed,config,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<DatafeedConfig> stoppedDatafeedConfigs(ClusterState clusterState);1546604488;Find the configurations for stopped datafeeds in the cluster state._Stopped datafeeds are those that do not have an associated persistent task.__@param clusterState The cluster state_@return The closed job configurations;public static List<DatafeedConfig> stoppedDatafeedConfigs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> startedDatafeedIds = MlTasks.startedDatafeedIds(persistentTasks)___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getDatafeeds().values().stream()_                .filter(datafeedConfig-> startedDatafeedIds.contains(datafeedConfig.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,stopped,datafeeds,in,the,cluster,state,stopped,datafeeds,are,those,that,do,not,have,an,associated,persistent,task,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,datafeed,config,stopped,datafeed,configs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,started,datafeed,ids,ml,tasks,started,datafeed,ids,persistent,tasks,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,datafeeds,values,stream,filter,datafeed,config,started,datafeed,ids,contains,datafeed,config,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<DatafeedConfig> stoppedDatafeedConfigs(ClusterState clusterState);1547065535;Find the configurations for stopped datafeeds in the cluster state._Stopped datafeeds are those that do not have an associated persistent task.__@param clusterState The cluster state_@return The closed job configurations;public static List<DatafeedConfig> stoppedDatafeedConfigs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> startedDatafeedIds = MlTasks.startedDatafeedIds(persistentTasks)___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getDatafeeds().values().stream()_                .filter(datafeedConfig-> startedDatafeedIds.contains(datafeedConfig.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,stopped,datafeeds,in,the,cluster,state,stopped,datafeeds,are,those,that,do,not,have,an,associated,persistent,task,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,datafeed,config,stopped,datafeed,configs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,started,datafeed,ids,ml,tasks,started,datafeed,ids,persistent,tasks,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,datafeeds,values,stream,filter,datafeed,config,started,datafeed,ids,contains,datafeed,config,get,id,false,collect,collectors,to,list
MlConfigMigrator -> public static List<DatafeedConfig> stoppedDatafeedConfigs(ClusterState clusterState);1547483987;Find the configurations for stopped datafeeds in the cluster state._Stopped datafeeds are those that do not have an associated persistent task.__@param clusterState The cluster state_@return The closed job configurations;public static List<DatafeedConfig> stoppedDatafeedConfigs(ClusterState clusterState) {_        PersistentTasksCustomMetaData persistentTasks = clusterState.metaData().custom(PersistentTasksCustomMetaData.TYPE)__        Set<String> startedDatafeedIds = MlTasks.startedDatafeedIds(persistentTasks)___        MlMetadata mlMetadata = MlMetadata.getMlMetadata(clusterState)__        return mlMetadata.getDatafeeds().values().stream()_                .filter(datafeedConfig-> startedDatafeedIds.contains(datafeedConfig.getId()) == false)_                .collect(Collectors.toList())__    };find,the,configurations,for,stopped,datafeeds,in,the,cluster,state,stopped,datafeeds,are,those,that,do,not,have,an,associated,persistent,task,param,cluster,state,the,cluster,state,return,the,closed,job,configurations;public,static,list,datafeed,config,stopped,datafeed,configs,cluster,state,cluster,state,persistent,tasks,custom,meta,data,persistent,tasks,cluster,state,meta,data,custom,persistent,tasks,custom,meta,data,type,set,string,started,datafeed,ids,ml,tasks,started,datafeed,ids,persistent,tasks,ml,metadata,ml,metadata,ml,metadata,get,ml,metadata,cluster,state,return,ml,metadata,get,datafeeds,values,stream,filter,datafeed,config,started,datafeed,ids,contains,datafeed,config,get,id,false,collect,collectors,to,list
MlConfigMigrator -> static RemovalResult removeJobsAndDatafeeds(List<Job> jobsToRemove, List<DatafeedConfig> datafeedsToRemove, MlMetadata mlMetadata);1547576499;Remove the datafeeds and jobs listed in the parameters from_mlMetadata if they exist. An account of removed jobs and datafeeds_is returned in the result structure alongside a new MlMetadata_with the config removed.__@param jobsToRemove       Jobs_@param datafeedsToRemove  Datafeeds_@param mlMetadata         MlMetadata_@return Structure tracking which jobs and datafeeds were actually removed_and the new MlMetadata;static RemovalResult removeJobsAndDatafeeds(List<Job> jobsToRemove, List<DatafeedConfig> datafeedsToRemove, MlMetadata mlMetadata) {_        Map<String, Job> currentJobs = new HashMap<>(mlMetadata.getJobs())__        List<String> removedJobIds = new ArrayList<>()__        for (Job job : jobsToRemove) {_            if (currentJobs.remove(job.getId()) != null) {_                removedJobIds.add(job.getId())__            }_        }__        Map<String, DatafeedConfig> currentDatafeeds = new HashMap<>(mlMetadata.getDatafeeds())__        List<String> removedDatafeedIds = new ArrayList<>()__        for (DatafeedConfig datafeed : datafeedsToRemove) {_            if (currentDatafeeds.remove(datafeed.getId()) != null) {_                removedDatafeedIds.add(datafeed.getId())__            }_        }__        MlMetadata.Builder builder = new MlMetadata.Builder()__        builder.putJobs(currentJobs.values())_                .putDatafeeds(currentDatafeeds.values())___        return new RemovalResult(builder.build(), removedJobIds, removedDatafeedIds)__    };remove,the,datafeeds,and,jobs,listed,in,the,parameters,from,ml,metadata,if,they,exist,an,account,of,removed,jobs,and,datafeeds,is,returned,in,the,result,structure,alongside,a,new,ml,metadata,with,the,config,removed,param,jobs,to,remove,jobs,param,datafeeds,to,remove,datafeeds,param,ml,metadata,ml,metadata,return,structure,tracking,which,jobs,and,datafeeds,were,actually,removed,and,the,new,ml,metadata;static,removal,result,remove,jobs,and,datafeeds,list,job,jobs,to,remove,list,datafeed,config,datafeeds,to,remove,ml,metadata,ml,metadata,map,string,job,current,jobs,new,hash,map,ml,metadata,get,jobs,list,string,removed,job,ids,new,array,list,for,job,job,jobs,to,remove,if,current,jobs,remove,job,get,id,null,removed,job,ids,add,job,get,id,map,string,datafeed,config,current,datafeeds,new,hash,map,ml,metadata,get,datafeeds,list,string,removed,datafeed,ids,new,array,list,for,datafeed,config,datafeed,datafeeds,to,remove,if,current,datafeeds,remove,datafeed,get,id,null,removed,datafeed,ids,add,datafeed,get,id,ml,metadata,builder,builder,new,ml,metadata,builder,builder,put,jobs,current,jobs,values,put,datafeeds,current,datafeeds,values,return,new,removal,result,builder,build,removed,job,ids,removed,datafeed,ids
MlConfigMigrator -> static RemovalResult removeJobsAndDatafeeds(List<Job> jobsToRemove, List<DatafeedConfig> datafeedsToRemove, MlMetadata mlMetadata);1547639475;Remove the datafeeds and jobs listed in the parameters from_mlMetadata if they exist. An account of removed jobs and datafeeds_is returned in the result structure alongside a new MlMetadata_with the config removed.__@param jobsToRemove       Jobs_@param datafeedsToRemove  Datafeeds_@param mlMetadata         MlMetadata_@return Structure tracking which jobs and datafeeds were actually removed_and the new MlMetadata;static RemovalResult removeJobsAndDatafeeds(List<Job> jobsToRemove, List<DatafeedConfig> datafeedsToRemove, MlMetadata mlMetadata) {_        Map<String, Job> currentJobs = new HashMap<>(mlMetadata.getJobs())__        List<String> removedJobIds = new ArrayList<>()__        for (Job job : jobsToRemove) {_            if (currentJobs.remove(job.getId()) != null) {_                removedJobIds.add(job.getId())__            }_        }__        Map<String, DatafeedConfig> currentDatafeeds = new HashMap<>(mlMetadata.getDatafeeds())__        List<String> removedDatafeedIds = new ArrayList<>()__        for (DatafeedConfig datafeed : datafeedsToRemove) {_            if (currentDatafeeds.remove(datafeed.getId()) != null) {_                removedDatafeedIds.add(datafeed.getId())__            }_        }__        MlMetadata.Builder builder = new MlMetadata.Builder()__        builder.putJobs(currentJobs.values())_                .putDatafeeds(currentDatafeeds.values())___        return new RemovalResult(builder.build(), removedJobIds, removedDatafeedIds)__    };remove,the,datafeeds,and,jobs,listed,in,the,parameters,from,ml,metadata,if,they,exist,an,account,of,removed,jobs,and,datafeeds,is,returned,in,the,result,structure,alongside,a,new,ml,metadata,with,the,config,removed,param,jobs,to,remove,jobs,param,datafeeds,to,remove,datafeeds,param,ml,metadata,ml,metadata,return,structure,tracking,which,jobs,and,datafeeds,were,actually,removed,and,the,new,ml,metadata;static,removal,result,remove,jobs,and,datafeeds,list,job,jobs,to,remove,list,datafeed,config,datafeeds,to,remove,ml,metadata,ml,metadata,map,string,job,current,jobs,new,hash,map,ml,metadata,get,jobs,list,string,removed,job,ids,new,array,list,for,job,job,jobs,to,remove,if,current,jobs,remove,job,get,id,null,removed,job,ids,add,job,get,id,map,string,datafeed,config,current,datafeeds,new,hash,map,ml,metadata,get,datafeeds,list,string,removed,datafeed,ids,new,array,list,for,datafeed,config,datafeed,datafeeds,to,remove,if,current,datafeeds,remove,datafeed,get,id,null,removed,datafeed,ids,add,datafeed,get,id,ml,metadata,builder,builder,new,ml,metadata,builder,builder,put,jobs,current,jobs,values,put,datafeeds,current,datafeeds,values,return,new,removal,result,builder,build,removed,job,ids,removed,datafeed,ids
MlConfigMigrator -> static RemovalResult removeJobsAndDatafeeds(List<Job> jobsToRemove, List<DatafeedConfig> datafeedsToRemove, MlMetadata mlMetadata);1547843554;Remove the datafeeds and jobs listed in the parameters from_mlMetadata if they exist. An account of removed jobs and datafeeds_is returned in the result structure alongside a new MlMetadata_with the config removed.__@param jobsToRemove       Jobs_@param datafeedsToRemove  Datafeeds_@param mlMetadata         MlMetadata_@return Structure tracking which jobs and datafeeds were actually removed_and the new MlMetadata;static RemovalResult removeJobsAndDatafeeds(List<Job> jobsToRemove, List<DatafeedConfig> datafeedsToRemove, MlMetadata mlMetadata) {_        Map<String, Job> currentJobs = new HashMap<>(mlMetadata.getJobs())__        List<String> removedJobIds = new ArrayList<>()__        for (Job job : jobsToRemove) {_            if (currentJobs.remove(job.getId()) != null) {_                removedJobIds.add(job.getId())__            }_        }__        Map<String, DatafeedConfig> currentDatafeeds = new HashMap<>(mlMetadata.getDatafeeds())__        List<String> removedDatafeedIds = new ArrayList<>()__        for (DatafeedConfig datafeed : datafeedsToRemove) {_            if (currentDatafeeds.remove(datafeed.getId()) != null) {_                removedDatafeedIds.add(datafeed.getId())__            }_        }__        MlMetadata.Builder builder = new MlMetadata.Builder()__        builder.putJobs(currentJobs.values())_                .putDatafeeds(currentDatafeeds.values())___        return new RemovalResult(builder.build(), removedJobIds, removedDatafeedIds)__    };remove,the,datafeeds,and,jobs,listed,in,the,parameters,from,ml,metadata,if,they,exist,an,account,of,removed,jobs,and,datafeeds,is,returned,in,the,result,structure,alongside,a,new,ml,metadata,with,the,config,removed,param,jobs,to,remove,jobs,param,datafeeds,to,remove,datafeeds,param,ml,metadata,ml,metadata,return,structure,tracking,which,jobs,and,datafeeds,were,actually,removed,and,the,new,ml,metadata;static,removal,result,remove,jobs,and,datafeeds,list,job,jobs,to,remove,list,datafeed,config,datafeeds,to,remove,ml,metadata,ml,metadata,map,string,job,current,jobs,new,hash,map,ml,metadata,get,jobs,list,string,removed,job,ids,new,array,list,for,job,job,jobs,to,remove,if,current,jobs,remove,job,get,id,null,removed,job,ids,add,job,get,id,map,string,datafeed,config,current,datafeeds,new,hash,map,ml,metadata,get,datafeeds,list,string,removed,datafeed,ids,new,array,list,for,datafeed,config,datafeed,datafeeds,to,remove,if,current,datafeeds,remove,datafeed,get,id,null,removed,datafeed,ids,add,datafeed,get,id,ml,metadata,builder,builder,new,ml,metadata,builder,builder,put,jobs,current,jobs,values,put,datafeeds,current,datafeeds,values,return,new,removal,result,builder,build,removed,job,ids,removed,datafeed,ids
MlConfigMigrator -> static RemovalResult removeJobsAndDatafeeds(List<String> jobsToRemove, List<String> datafeedsToRemove, MlMetadata mlMetadata);1545155131;Remove the datafeeds and jobs listed in the parameters from_mlMetadata if they exist. An account of removed jobs and datafeeds_is returned in the result structure alongside a new MlMetadata_with the config removed.__@param jobsToRemove       Jobs_@param datafeedsToRemove  Datafeeds_@param mlMetadata         MlMetadata_@return Structure tracking which jobs and datafeeds were actually removed_and the new MlMetadata;static RemovalResult removeJobsAndDatafeeds(List<String> jobsToRemove, List<String> datafeedsToRemove, MlMetadata mlMetadata) {_        Map<String, Job> currentJobs = new HashMap<>(mlMetadata.getJobs())__        List<String> removedJobIds = new ArrayList<>()__        for (String jobId : jobsToRemove) {_            if (currentJobs.remove(jobId) != null) {_                removedJobIds.add(jobId)__            }_        }__        Map<String, DatafeedConfig> currentDatafeeds = new HashMap<>(mlMetadata.getDatafeeds())__        List<String> removedDatafeedIds = new ArrayList<>()__        for (String datafeedId : datafeedsToRemove) {_            if (currentDatafeeds.remove(datafeedId) != null) {_                removedDatafeedIds.add(datafeedId)__            }_        }__        MlMetadata.Builder builder = new MlMetadata.Builder()__        builder.putJobs(currentJobs.values())_                .putDatafeeds(currentDatafeeds.values())___        return new RemovalResult(builder.build(), removedJobIds, removedDatafeedIds)__    };remove,the,datafeeds,and,jobs,listed,in,the,parameters,from,ml,metadata,if,they,exist,an,account,of,removed,jobs,and,datafeeds,is,returned,in,the,result,structure,alongside,a,new,ml,metadata,with,the,config,removed,param,jobs,to,remove,jobs,param,datafeeds,to,remove,datafeeds,param,ml,metadata,ml,metadata,return,structure,tracking,which,jobs,and,datafeeds,were,actually,removed,and,the,new,ml,metadata;static,removal,result,remove,jobs,and,datafeeds,list,string,jobs,to,remove,list,string,datafeeds,to,remove,ml,metadata,ml,metadata,map,string,job,current,jobs,new,hash,map,ml,metadata,get,jobs,list,string,removed,job,ids,new,array,list,for,string,job,id,jobs,to,remove,if,current,jobs,remove,job,id,null,removed,job,ids,add,job,id,map,string,datafeed,config,current,datafeeds,new,hash,map,ml,metadata,get,datafeeds,list,string,removed,datafeed,ids,new,array,list,for,string,datafeed,id,datafeeds,to,remove,if,current,datafeeds,remove,datafeed,id,null,removed,datafeed,ids,add,datafeed,id,ml,metadata,builder,builder,new,ml,metadata,builder,builder,put,jobs,current,jobs,values,put,datafeeds,current,datafeeds,values,return,new,removal,result,builder,build,removed,job,ids,removed,datafeed,ids
MlConfigMigrator -> static RemovalResult removeJobsAndDatafeeds(List<String> jobsToRemove, List<String> datafeedsToRemove, MlMetadata mlMetadata);1545227023;Remove the datafeeds and jobs listed in the parameters from_mlMetadata if they exist. An account of removed jobs and datafeeds_is returned in the result structure alongside a new MlMetadata_with the config removed.__@param jobsToRemove       Jobs_@param datafeedsToRemove  Datafeeds_@param mlMetadata         MlMetadata_@return Structure tracking which jobs and datafeeds were actually removed_and the new MlMetadata;static RemovalResult removeJobsAndDatafeeds(List<String> jobsToRemove, List<String> datafeedsToRemove, MlMetadata mlMetadata) {_        Map<String, Job> currentJobs = new HashMap<>(mlMetadata.getJobs())__        List<String> removedJobIds = new ArrayList<>()__        for (String jobId : jobsToRemove) {_            if (currentJobs.remove(jobId) != null) {_                removedJobIds.add(jobId)__            }_        }__        Map<String, DatafeedConfig> currentDatafeeds = new HashMap<>(mlMetadata.getDatafeeds())__        List<String> removedDatafeedIds = new ArrayList<>()__        for (String datafeedId : datafeedsToRemove) {_            if (currentDatafeeds.remove(datafeedId) != null) {_                removedDatafeedIds.add(datafeedId)__            }_        }__        MlMetadata.Builder builder = new MlMetadata.Builder()__        builder.putJobs(currentJobs.values())_                .putDatafeeds(currentDatafeeds.values())___        return new RemovalResult(builder.build(), removedJobIds, removedDatafeedIds)__    };remove,the,datafeeds,and,jobs,listed,in,the,parameters,from,ml,metadata,if,they,exist,an,account,of,removed,jobs,and,datafeeds,is,returned,in,the,result,structure,alongside,a,new,ml,metadata,with,the,config,removed,param,jobs,to,remove,jobs,param,datafeeds,to,remove,datafeeds,param,ml,metadata,ml,metadata,return,structure,tracking,which,jobs,and,datafeeds,were,actually,removed,and,the,new,ml,metadata;static,removal,result,remove,jobs,and,datafeeds,list,string,jobs,to,remove,list,string,datafeeds,to,remove,ml,metadata,ml,metadata,map,string,job,current,jobs,new,hash,map,ml,metadata,get,jobs,list,string,removed,job,ids,new,array,list,for,string,job,id,jobs,to,remove,if,current,jobs,remove,job,id,null,removed,job,ids,add,job,id,map,string,datafeed,config,current,datafeeds,new,hash,map,ml,metadata,get,datafeeds,list,string,removed,datafeed,ids,new,array,list,for,string,datafeed,id,datafeeds,to,remove,if,current,datafeeds,remove,datafeed,id,null,removed,datafeed,ids,add,datafeed,id,ml,metadata,builder,builder,new,ml,metadata,builder,builder,put,jobs,current,jobs,values,put,datafeeds,current,datafeeds,values,return,new,removal,result,builder,build,removed,job,ids,removed,datafeed,ids
MlConfigMigrator -> static RemovalResult removeJobsAndDatafeeds(List<String> jobsToRemove, List<String> datafeedsToRemove, MlMetadata mlMetadata);1546604488;Remove the datafeeds and jobs listed in the parameters from_mlMetadata if they exist. An account of removed jobs and datafeeds_is returned in the result structure alongside a new MlMetadata_with the config removed.__@param jobsToRemove       Jobs_@param datafeedsToRemove  Datafeeds_@param mlMetadata         MlMetadata_@return Structure tracking which jobs and datafeeds were actually removed_and the new MlMetadata;static RemovalResult removeJobsAndDatafeeds(List<String> jobsToRemove, List<String> datafeedsToRemove, MlMetadata mlMetadata) {_        Map<String, Job> currentJobs = new HashMap<>(mlMetadata.getJobs())__        List<String> removedJobIds = new ArrayList<>()__        for (String jobId : jobsToRemove) {_            if (currentJobs.remove(jobId) != null) {_                removedJobIds.add(jobId)__            }_        }__        Map<String, DatafeedConfig> currentDatafeeds = new HashMap<>(mlMetadata.getDatafeeds())__        List<String> removedDatafeedIds = new ArrayList<>()__        for (String datafeedId : datafeedsToRemove) {_            if (currentDatafeeds.remove(datafeedId) != null) {_                removedDatafeedIds.add(datafeedId)__            }_        }__        MlMetadata.Builder builder = new MlMetadata.Builder()__        builder.putJobs(currentJobs.values())_                .putDatafeeds(currentDatafeeds.values())___        return new RemovalResult(builder.build(), removedJobIds, removedDatafeedIds)__    };remove,the,datafeeds,and,jobs,listed,in,the,parameters,from,ml,metadata,if,they,exist,an,account,of,removed,jobs,and,datafeeds,is,returned,in,the,result,structure,alongside,a,new,ml,metadata,with,the,config,removed,param,jobs,to,remove,jobs,param,datafeeds,to,remove,datafeeds,param,ml,metadata,ml,metadata,return,structure,tracking,which,jobs,and,datafeeds,were,actually,removed,and,the,new,ml,metadata;static,removal,result,remove,jobs,and,datafeeds,list,string,jobs,to,remove,list,string,datafeeds,to,remove,ml,metadata,ml,metadata,map,string,job,current,jobs,new,hash,map,ml,metadata,get,jobs,list,string,removed,job,ids,new,array,list,for,string,job,id,jobs,to,remove,if,current,jobs,remove,job,id,null,removed,job,ids,add,job,id,map,string,datafeed,config,current,datafeeds,new,hash,map,ml,metadata,get,datafeeds,list,string,removed,datafeed,ids,new,array,list,for,string,datafeed,id,datafeeds,to,remove,if,current,datafeeds,remove,datafeed,id,null,removed,datafeed,ids,add,datafeed,id,ml,metadata,builder,builder,new,ml,metadata,builder,builder,put,jobs,current,jobs,values,put,datafeeds,current,datafeeds,values,return,new,removal,result,builder,build,removed,job,ids,removed,datafeed,ids
MlConfigMigrator -> static RemovalResult removeJobsAndDatafeeds(List<String> jobsToRemove, List<String> datafeedsToRemove, MlMetadata mlMetadata);1547065535;Remove the datafeeds and jobs listed in the parameters from_mlMetadata if they exist. An account of removed jobs and datafeeds_is returned in the result structure alongside a new MlMetadata_with the config removed.__@param jobsToRemove       Jobs_@param datafeedsToRemove  Datafeeds_@param mlMetadata         MlMetadata_@return Structure tracking which jobs and datafeeds were actually removed_and the new MlMetadata;static RemovalResult removeJobsAndDatafeeds(List<String> jobsToRemove, List<String> datafeedsToRemove, MlMetadata mlMetadata) {_        Map<String, Job> currentJobs = new HashMap<>(mlMetadata.getJobs())__        List<String> removedJobIds = new ArrayList<>()__        for (String jobId : jobsToRemove) {_            if (currentJobs.remove(jobId) != null) {_                removedJobIds.add(jobId)__            }_        }__        Map<String, DatafeedConfig> currentDatafeeds = new HashMap<>(mlMetadata.getDatafeeds())__        List<String> removedDatafeedIds = new ArrayList<>()__        for (String datafeedId : datafeedsToRemove) {_            if (currentDatafeeds.remove(datafeedId) != null) {_                removedDatafeedIds.add(datafeedId)__            }_        }__        MlMetadata.Builder builder = new MlMetadata.Builder()__        builder.putJobs(currentJobs.values())_                .putDatafeeds(currentDatafeeds.values())___        return new RemovalResult(builder.build(), removedJobIds, removedDatafeedIds)__    };remove,the,datafeeds,and,jobs,listed,in,the,parameters,from,ml,metadata,if,they,exist,an,account,of,removed,jobs,and,datafeeds,is,returned,in,the,result,structure,alongside,a,new,ml,metadata,with,the,config,removed,param,jobs,to,remove,jobs,param,datafeeds,to,remove,datafeeds,param,ml,metadata,ml,metadata,return,structure,tracking,which,jobs,and,datafeeds,were,actually,removed,and,the,new,ml,metadata;static,removal,result,remove,jobs,and,datafeeds,list,string,jobs,to,remove,list,string,datafeeds,to,remove,ml,metadata,ml,metadata,map,string,job,current,jobs,new,hash,map,ml,metadata,get,jobs,list,string,removed,job,ids,new,array,list,for,string,job,id,jobs,to,remove,if,current,jobs,remove,job,id,null,removed,job,ids,add,job,id,map,string,datafeed,config,current,datafeeds,new,hash,map,ml,metadata,get,datafeeds,list,string,removed,datafeed,ids,new,array,list,for,string,datafeed,id,datafeeds,to,remove,if,current,datafeeds,remove,datafeed,id,null,removed,datafeed,ids,add,datafeed,id,ml,metadata,builder,builder,new,ml,metadata,builder,builder,put,jobs,current,jobs,values,put,datafeeds,current,datafeeds,values,return,new,removal,result,builder,build,removed,job,ids,removed,datafeed,ids
MlConfigMigrator -> static RemovalResult removeJobsAndDatafeeds(List<String> jobsToRemove, List<String> datafeedsToRemove, MlMetadata mlMetadata);1547483987;Remove the datafeeds and jobs listed in the parameters from_mlMetadata if they exist. An account of removed jobs and datafeeds_is returned in the result structure alongside a new MlMetadata_with the config removed.__@param jobsToRemove       Jobs_@param datafeedsToRemove  Datafeeds_@param mlMetadata         MlMetadata_@return Structure tracking which jobs and datafeeds were actually removed_and the new MlMetadata;static RemovalResult removeJobsAndDatafeeds(List<String> jobsToRemove, List<String> datafeedsToRemove, MlMetadata mlMetadata) {_        Map<String, Job> currentJobs = new HashMap<>(mlMetadata.getJobs())__        List<String> removedJobIds = new ArrayList<>()__        for (String jobId : jobsToRemove) {_            if (currentJobs.remove(jobId) != null) {_                removedJobIds.add(jobId)__            }_        }__        Map<String, DatafeedConfig> currentDatafeeds = new HashMap<>(mlMetadata.getDatafeeds())__        List<String> removedDatafeedIds = new ArrayList<>()__        for (String datafeedId : datafeedsToRemove) {_            if (currentDatafeeds.remove(datafeedId) != null) {_                removedDatafeedIds.add(datafeedId)__            }_        }__        MlMetadata.Builder builder = new MlMetadata.Builder()__        builder.putJobs(currentJobs.values())_                .putDatafeeds(currentDatafeeds.values())___        return new RemovalResult(builder.build(), removedJobIds, removedDatafeedIds)__    };remove,the,datafeeds,and,jobs,listed,in,the,parameters,from,ml,metadata,if,they,exist,an,account,of,removed,jobs,and,datafeeds,is,returned,in,the,result,structure,alongside,a,new,ml,metadata,with,the,config,removed,param,jobs,to,remove,jobs,param,datafeeds,to,remove,datafeeds,param,ml,metadata,ml,metadata,return,structure,tracking,which,jobs,and,datafeeds,were,actually,removed,and,the,new,ml,metadata;static,removal,result,remove,jobs,and,datafeeds,list,string,jobs,to,remove,list,string,datafeeds,to,remove,ml,metadata,ml,metadata,map,string,job,current,jobs,new,hash,map,ml,metadata,get,jobs,list,string,removed,job,ids,new,array,list,for,string,job,id,jobs,to,remove,if,current,jobs,remove,job,id,null,removed,job,ids,add,job,id,map,string,datafeed,config,current,datafeeds,new,hash,map,ml,metadata,get,datafeeds,list,string,removed,datafeed,ids,new,array,list,for,string,datafeed,id,datafeeds,to,remove,if,current,datafeeds,remove,datafeed,id,null,removed,datafeed,ids,add,datafeed,id,ml,metadata,builder,builder,new,ml,metadata,builder,builder,put,jobs,current,jobs,values,put,datafeeds,current,datafeeds,values,return,new,removal,result,builder,build,removed,job,ids,removed,datafeed,ids
MlConfigMigrator -> public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate);1545155131;Return at most {@link #MAX_BULK_WRITE_SIZE} configs favouring_datafeed and job pairs so if a datafeed is chosen so is its job.__@param datafeedsToMigrate Datafeed configs_@param jobsToMigrate      Job configs_@return Job and datafeed configs;public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate) {_        JobsAndDatafeeds jobsAndDatafeeds = new JobsAndDatafeeds()___        if (datafeedsToMigrate.size() + jobsToMigrate.size() <= MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.addAll(jobsToMigrate.values())__            jobsAndDatafeeds.datafeedConfigs.addAll(datafeedsToMigrate)__            return jobsAndDatafeeds__        }__        int count = 0___        _        for (DatafeedConfig datafeedConfig : datafeedsToMigrate) {_            if (count < MAX_BULK_WRITE_SIZE) {_                jobsAndDatafeeds.datafeedConfigs.add(datafeedConfig)__                count++__                Job datafeedsJob = jobsToMigrate.remove(datafeedConfig.getJobId())__                if (datafeedsJob != null) {_                    jobsAndDatafeeds.jobs.add(datafeedsJob)__                    count++__                }_            }_        }__        _        Iterator<Job> iter = jobsToMigrate.values().iterator()__        while (iter.hasNext() && count < MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.add(iter.next())__            count++__        }__        return jobsAndDatafeeds__    };return,at,most,link,configs,favouring,datafeed,and,job,pairs,so,if,a,datafeed,is,chosen,so,is,its,job,param,datafeeds,to,migrate,datafeed,configs,param,jobs,to,migrate,job,configs,return,job,and,datafeed,configs;public,static,jobs,and,datafeeds,limit,writes,collection,datafeed,config,datafeeds,to,migrate,map,string,job,jobs,to,migrate,jobs,and,datafeeds,jobs,and,datafeeds,new,jobs,and,datafeeds,if,datafeeds,to,migrate,size,jobs,to,migrate,size,jobs,and,datafeeds,jobs,add,all,jobs,to,migrate,values,jobs,and,datafeeds,datafeed,configs,add,all,datafeeds,to,migrate,return,jobs,and,datafeeds,int,count,0,for,datafeed,config,datafeed,config,datafeeds,to,migrate,if,count,jobs,and,datafeeds,datafeed,configs,add,datafeed,config,count,job,datafeeds,job,jobs,to,migrate,remove,datafeed,config,get,job,id,if,datafeeds,job,null,jobs,and,datafeeds,jobs,add,datafeeds,job,count,iterator,job,iter,jobs,to,migrate,values,iterator,while,iter,has,next,count,jobs,and,datafeeds,jobs,add,iter,next,count,return,jobs,and,datafeeds
MlConfigMigrator -> public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate);1545227023;Return at most {@link #MAX_BULK_WRITE_SIZE} configs favouring_datafeed and job pairs so if a datafeed is chosen so is its job.__@param datafeedsToMigrate Datafeed configs_@param jobsToMigrate      Job configs_@return Job and datafeed configs;public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate) {_        JobsAndDatafeeds jobsAndDatafeeds = new JobsAndDatafeeds()___        if (datafeedsToMigrate.size() + jobsToMigrate.size() <= MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.addAll(jobsToMigrate.values())__            jobsAndDatafeeds.datafeedConfigs.addAll(datafeedsToMigrate)__            return jobsAndDatafeeds__        }__        int count = 0___        _        for (DatafeedConfig datafeedConfig : datafeedsToMigrate) {_            if (count < MAX_BULK_WRITE_SIZE) {_                jobsAndDatafeeds.datafeedConfigs.add(datafeedConfig)__                count++__                Job datafeedsJob = jobsToMigrate.remove(datafeedConfig.getJobId())__                if (datafeedsJob != null) {_                    jobsAndDatafeeds.jobs.add(datafeedsJob)__                    count++__                }_            }_        }__        _        Iterator<Job> iter = jobsToMigrate.values().iterator()__        while (iter.hasNext() && count < MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.add(iter.next())__            count++__        }__        return jobsAndDatafeeds__    };return,at,most,link,configs,favouring,datafeed,and,job,pairs,so,if,a,datafeed,is,chosen,so,is,its,job,param,datafeeds,to,migrate,datafeed,configs,param,jobs,to,migrate,job,configs,return,job,and,datafeed,configs;public,static,jobs,and,datafeeds,limit,writes,collection,datafeed,config,datafeeds,to,migrate,map,string,job,jobs,to,migrate,jobs,and,datafeeds,jobs,and,datafeeds,new,jobs,and,datafeeds,if,datafeeds,to,migrate,size,jobs,to,migrate,size,jobs,and,datafeeds,jobs,add,all,jobs,to,migrate,values,jobs,and,datafeeds,datafeed,configs,add,all,datafeeds,to,migrate,return,jobs,and,datafeeds,int,count,0,for,datafeed,config,datafeed,config,datafeeds,to,migrate,if,count,jobs,and,datafeeds,datafeed,configs,add,datafeed,config,count,job,datafeeds,job,jobs,to,migrate,remove,datafeed,config,get,job,id,if,datafeeds,job,null,jobs,and,datafeeds,jobs,add,datafeeds,job,count,iterator,job,iter,jobs,to,migrate,values,iterator,while,iter,has,next,count,jobs,and,datafeeds,jobs,add,iter,next,count,return,jobs,and,datafeeds
MlConfigMigrator -> public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate);1546604488;Return at most {@link #MAX_BULK_WRITE_SIZE} configs favouring_datafeed and job pairs so if a datafeed is chosen so is its job.__@param datafeedsToMigrate Datafeed configs_@param jobsToMigrate      Job configs_@return Job and datafeed configs;public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate) {_        JobsAndDatafeeds jobsAndDatafeeds = new JobsAndDatafeeds()___        if (datafeedsToMigrate.size() + jobsToMigrate.size() <= MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.addAll(jobsToMigrate.values())__            jobsAndDatafeeds.datafeedConfigs.addAll(datafeedsToMigrate)__            return jobsAndDatafeeds__        }__        int count = 0___        _        for (DatafeedConfig datafeedConfig : datafeedsToMigrate) {_            if (count < MAX_BULK_WRITE_SIZE) {_                jobsAndDatafeeds.datafeedConfigs.add(datafeedConfig)__                count++__                Job datafeedsJob = jobsToMigrate.remove(datafeedConfig.getJobId())__                if (datafeedsJob != null) {_                    jobsAndDatafeeds.jobs.add(datafeedsJob)__                    count++__                }_            }_        }__        _        Iterator<Job> iter = jobsToMigrate.values().iterator()__        while (iter.hasNext() && count < MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.add(iter.next())__            count++__        }__        return jobsAndDatafeeds__    };return,at,most,link,configs,favouring,datafeed,and,job,pairs,so,if,a,datafeed,is,chosen,so,is,its,job,param,datafeeds,to,migrate,datafeed,configs,param,jobs,to,migrate,job,configs,return,job,and,datafeed,configs;public,static,jobs,and,datafeeds,limit,writes,collection,datafeed,config,datafeeds,to,migrate,map,string,job,jobs,to,migrate,jobs,and,datafeeds,jobs,and,datafeeds,new,jobs,and,datafeeds,if,datafeeds,to,migrate,size,jobs,to,migrate,size,jobs,and,datafeeds,jobs,add,all,jobs,to,migrate,values,jobs,and,datafeeds,datafeed,configs,add,all,datafeeds,to,migrate,return,jobs,and,datafeeds,int,count,0,for,datafeed,config,datafeed,config,datafeeds,to,migrate,if,count,jobs,and,datafeeds,datafeed,configs,add,datafeed,config,count,job,datafeeds,job,jobs,to,migrate,remove,datafeed,config,get,job,id,if,datafeeds,job,null,jobs,and,datafeeds,jobs,add,datafeeds,job,count,iterator,job,iter,jobs,to,migrate,values,iterator,while,iter,has,next,count,jobs,and,datafeeds,jobs,add,iter,next,count,return,jobs,and,datafeeds
MlConfigMigrator -> public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate);1547065535;Return at most {@link #MAX_BULK_WRITE_SIZE} configs favouring_datafeed and job pairs so if a datafeed is chosen so is its job.__@param datafeedsToMigrate Datafeed configs_@param jobsToMigrate      Job configs_@return Job and datafeed configs;public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate) {_        JobsAndDatafeeds jobsAndDatafeeds = new JobsAndDatafeeds()___        if (datafeedsToMigrate.size() + jobsToMigrate.size() <= MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.addAll(jobsToMigrate.values())__            jobsAndDatafeeds.datafeedConfigs.addAll(datafeedsToMigrate)__            return jobsAndDatafeeds__        }__        int count = 0___        _        for (DatafeedConfig datafeedConfig : datafeedsToMigrate) {_            if (count < MAX_BULK_WRITE_SIZE) {_                jobsAndDatafeeds.datafeedConfigs.add(datafeedConfig)__                count++__                Job datafeedsJob = jobsToMigrate.remove(datafeedConfig.getJobId())__                if (datafeedsJob != null) {_                    jobsAndDatafeeds.jobs.add(datafeedsJob)__                    count++__                }_            }_        }__        _        Iterator<Job> iter = jobsToMigrate.values().iterator()__        while (iter.hasNext() && count < MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.add(iter.next())__            count++__        }__        return jobsAndDatafeeds__    };return,at,most,link,configs,favouring,datafeed,and,job,pairs,so,if,a,datafeed,is,chosen,so,is,its,job,param,datafeeds,to,migrate,datafeed,configs,param,jobs,to,migrate,job,configs,return,job,and,datafeed,configs;public,static,jobs,and,datafeeds,limit,writes,collection,datafeed,config,datafeeds,to,migrate,map,string,job,jobs,to,migrate,jobs,and,datafeeds,jobs,and,datafeeds,new,jobs,and,datafeeds,if,datafeeds,to,migrate,size,jobs,to,migrate,size,jobs,and,datafeeds,jobs,add,all,jobs,to,migrate,values,jobs,and,datafeeds,datafeed,configs,add,all,datafeeds,to,migrate,return,jobs,and,datafeeds,int,count,0,for,datafeed,config,datafeed,config,datafeeds,to,migrate,if,count,jobs,and,datafeeds,datafeed,configs,add,datafeed,config,count,job,datafeeds,job,jobs,to,migrate,remove,datafeed,config,get,job,id,if,datafeeds,job,null,jobs,and,datafeeds,jobs,add,datafeeds,job,count,iterator,job,iter,jobs,to,migrate,values,iterator,while,iter,has,next,count,jobs,and,datafeeds,jobs,add,iter,next,count,return,jobs,and,datafeeds
MlConfigMigrator -> public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate);1547483987;Return at most {@link #MAX_BULK_WRITE_SIZE} configs favouring_datafeed and job pairs so if a datafeed is chosen so is its job.__@param datafeedsToMigrate Datafeed configs_@param jobsToMigrate      Job configs_@return Job and datafeed configs;public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate) {_        JobsAndDatafeeds jobsAndDatafeeds = new JobsAndDatafeeds()___        if (datafeedsToMigrate.size() + jobsToMigrate.size() <= MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.addAll(jobsToMigrate.values())__            jobsAndDatafeeds.datafeedConfigs.addAll(datafeedsToMigrate)__            return jobsAndDatafeeds__        }__        int count = 0___        _        for (DatafeedConfig datafeedConfig : datafeedsToMigrate) {_            if (count < MAX_BULK_WRITE_SIZE) {_                jobsAndDatafeeds.datafeedConfigs.add(datafeedConfig)__                count++__                Job datafeedsJob = jobsToMigrate.remove(datafeedConfig.getJobId())__                if (datafeedsJob != null) {_                    jobsAndDatafeeds.jobs.add(datafeedsJob)__                    count++__                }_            }_        }__        _        Iterator<Job> iter = jobsToMigrate.values().iterator()__        while (iter.hasNext() && count < MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.add(iter.next())__            count++__        }__        return jobsAndDatafeeds__    };return,at,most,link,configs,favouring,datafeed,and,job,pairs,so,if,a,datafeed,is,chosen,so,is,its,job,param,datafeeds,to,migrate,datafeed,configs,param,jobs,to,migrate,job,configs,return,job,and,datafeed,configs;public,static,jobs,and,datafeeds,limit,writes,collection,datafeed,config,datafeeds,to,migrate,map,string,job,jobs,to,migrate,jobs,and,datafeeds,jobs,and,datafeeds,new,jobs,and,datafeeds,if,datafeeds,to,migrate,size,jobs,to,migrate,size,jobs,and,datafeeds,jobs,add,all,jobs,to,migrate,values,jobs,and,datafeeds,datafeed,configs,add,all,datafeeds,to,migrate,return,jobs,and,datafeeds,int,count,0,for,datafeed,config,datafeed,config,datafeeds,to,migrate,if,count,jobs,and,datafeeds,datafeed,configs,add,datafeed,config,count,job,datafeeds,job,jobs,to,migrate,remove,datafeed,config,get,job,id,if,datafeeds,job,null,jobs,and,datafeeds,jobs,add,datafeeds,job,count,iterator,job,iter,jobs,to,migrate,values,iterator,while,iter,has,next,count,jobs,and,datafeeds,jobs,add,iter,next,count,return,jobs,and,datafeeds
MlConfigMigrator -> public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate);1547576499;Return at most {@link #MAX_BULK_WRITE_SIZE} configs favouring_datafeed and job pairs so if a datafeed is chosen so is its job.__@param datafeedsToMigrate Datafeed configs_@param jobsToMigrate      Job configs_@return Job and datafeed configs;public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate) {_        JobsAndDatafeeds jobsAndDatafeeds = new JobsAndDatafeeds()___        if (datafeedsToMigrate.size() + jobsToMigrate.size() <= MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.addAll(jobsToMigrate.values())__            jobsAndDatafeeds.datafeedConfigs.addAll(datafeedsToMigrate)__            return jobsAndDatafeeds__        }__        int count = 0___        _        for (DatafeedConfig datafeedConfig : datafeedsToMigrate) {_            if (count < MAX_BULK_WRITE_SIZE) {_                jobsAndDatafeeds.datafeedConfigs.add(datafeedConfig)__                count++__                Job datafeedsJob = jobsToMigrate.remove(datafeedConfig.getJobId())__                if (datafeedsJob != null) {_                    jobsAndDatafeeds.jobs.add(datafeedsJob)__                    count++__                }_            }_        }__        _        Iterator<Job> iter = jobsToMigrate.values().iterator()__        while (iter.hasNext() && count < MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.add(iter.next())__            count++__        }__        return jobsAndDatafeeds__    };return,at,most,link,configs,favouring,datafeed,and,job,pairs,so,if,a,datafeed,is,chosen,so,is,its,job,param,datafeeds,to,migrate,datafeed,configs,param,jobs,to,migrate,job,configs,return,job,and,datafeed,configs;public,static,jobs,and,datafeeds,limit,writes,collection,datafeed,config,datafeeds,to,migrate,map,string,job,jobs,to,migrate,jobs,and,datafeeds,jobs,and,datafeeds,new,jobs,and,datafeeds,if,datafeeds,to,migrate,size,jobs,to,migrate,size,jobs,and,datafeeds,jobs,add,all,jobs,to,migrate,values,jobs,and,datafeeds,datafeed,configs,add,all,datafeeds,to,migrate,return,jobs,and,datafeeds,int,count,0,for,datafeed,config,datafeed,config,datafeeds,to,migrate,if,count,jobs,and,datafeeds,datafeed,configs,add,datafeed,config,count,job,datafeeds,job,jobs,to,migrate,remove,datafeed,config,get,job,id,if,datafeeds,job,null,jobs,and,datafeeds,jobs,add,datafeeds,job,count,iterator,job,iter,jobs,to,migrate,values,iterator,while,iter,has,next,count,jobs,and,datafeeds,jobs,add,iter,next,count,return,jobs,and,datafeeds
MlConfigMigrator -> public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate);1547639475;Return at most {@link #MAX_BULK_WRITE_SIZE} configs favouring_datafeed and job pairs so if a datafeed is chosen so is its job.__@param datafeedsToMigrate Datafeed configs_@param jobsToMigrate      Job configs_@return Job and datafeed configs;public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate) {_        JobsAndDatafeeds jobsAndDatafeeds = new JobsAndDatafeeds()___        if (datafeedsToMigrate.size() + jobsToMigrate.size() <= MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.addAll(jobsToMigrate.values())__            jobsAndDatafeeds.datafeedConfigs.addAll(datafeedsToMigrate)__            return jobsAndDatafeeds__        }__        int count = 0___        _        for (DatafeedConfig datafeedConfig : datafeedsToMigrate) {_            if (count < MAX_BULK_WRITE_SIZE) {_                jobsAndDatafeeds.datafeedConfigs.add(datafeedConfig)__                count++__                Job datafeedsJob = jobsToMigrate.remove(datafeedConfig.getJobId())__                if (datafeedsJob != null) {_                    jobsAndDatafeeds.jobs.add(datafeedsJob)__                    count++__                }_            }_        }__        _        Iterator<Job> iter = jobsToMigrate.values().iterator()__        while (iter.hasNext() && count < MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.add(iter.next())__            count++__        }__        return jobsAndDatafeeds__    };return,at,most,link,configs,favouring,datafeed,and,job,pairs,so,if,a,datafeed,is,chosen,so,is,its,job,param,datafeeds,to,migrate,datafeed,configs,param,jobs,to,migrate,job,configs,return,job,and,datafeed,configs;public,static,jobs,and,datafeeds,limit,writes,collection,datafeed,config,datafeeds,to,migrate,map,string,job,jobs,to,migrate,jobs,and,datafeeds,jobs,and,datafeeds,new,jobs,and,datafeeds,if,datafeeds,to,migrate,size,jobs,to,migrate,size,jobs,and,datafeeds,jobs,add,all,jobs,to,migrate,values,jobs,and,datafeeds,datafeed,configs,add,all,datafeeds,to,migrate,return,jobs,and,datafeeds,int,count,0,for,datafeed,config,datafeed,config,datafeeds,to,migrate,if,count,jobs,and,datafeeds,datafeed,configs,add,datafeed,config,count,job,datafeeds,job,jobs,to,migrate,remove,datafeed,config,get,job,id,if,datafeeds,job,null,jobs,and,datafeeds,jobs,add,datafeeds,job,count,iterator,job,iter,jobs,to,migrate,values,iterator,while,iter,has,next,count,jobs,and,datafeeds,jobs,add,iter,next,count,return,jobs,and,datafeeds
MlConfigMigrator -> public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate);1547843554;Return at most {@link #MAX_BULK_WRITE_SIZE} configs favouring_datafeed and job pairs so if a datafeed is chosen so is its job.__@param datafeedsToMigrate Datafeed configs_@param jobsToMigrate      Job configs_@return Job and datafeed configs;public static JobsAndDatafeeds limitWrites(Collection<DatafeedConfig> datafeedsToMigrate, Map<String, Job> jobsToMigrate) {_        JobsAndDatafeeds jobsAndDatafeeds = new JobsAndDatafeeds()___        if (datafeedsToMigrate.size() + jobsToMigrate.size() <= MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.addAll(jobsToMigrate.values())__            jobsAndDatafeeds.datafeedConfigs.addAll(datafeedsToMigrate)__            return jobsAndDatafeeds__        }__        int count = 0___        _        for (DatafeedConfig datafeedConfig : datafeedsToMigrate) {_            if (count < MAX_BULK_WRITE_SIZE) {_                jobsAndDatafeeds.datafeedConfigs.add(datafeedConfig)__                count++__                Job datafeedsJob = jobsToMigrate.remove(datafeedConfig.getJobId())__                if (datafeedsJob != null) {_                    jobsAndDatafeeds.jobs.add(datafeedsJob)__                    count++__                }_            }_        }__        _        Iterator<Job> iter = jobsToMigrate.values().iterator()__        while (iter.hasNext() && count < MAX_BULK_WRITE_SIZE) {_            jobsAndDatafeeds.jobs.add(iter.next())__            count++__        }__        return jobsAndDatafeeds__    };return,at,most,link,configs,favouring,datafeed,and,job,pairs,so,if,a,datafeed,is,chosen,so,is,its,job,param,datafeeds,to,migrate,datafeed,configs,param,jobs,to,migrate,job,configs,return,job,and,datafeed,configs;public,static,jobs,and,datafeeds,limit,writes,collection,datafeed,config,datafeeds,to,migrate,map,string,job,jobs,to,migrate,jobs,and,datafeeds,jobs,and,datafeeds,new,jobs,and,datafeeds,if,datafeeds,to,migrate,size,jobs,to,migrate,size,jobs,and,datafeeds,jobs,add,all,jobs,to,migrate,values,jobs,and,datafeeds,datafeed,configs,add,all,datafeeds,to,migrate,return,jobs,and,datafeeds,int,count,0,for,datafeed,config,datafeed,config,datafeeds,to,migrate,if,count,jobs,and,datafeeds,datafeed,configs,add,datafeed,config,count,job,datafeeds,job,jobs,to,migrate,remove,datafeed,config,get,job,id,if,datafeeds,job,null,jobs,and,datafeeds,jobs,add,datafeeds,job,count,iterator,job,iter,jobs,to,migrate,values,iterator,while,iter,has,next,count,jobs,and,datafeeds,jobs,add,iter,next,count,return,jobs,and,datafeeds
MlConfigMigrator -> public void migrateConfigs(ClusterState clusterState, ActionListener<Boolean> listener);1547576499;Migrate ml job and datafeed configurations from the clusterstate_to index documents.__Configs to be migrated are read from the cluster state then bulk_indexed into .ml-config. Those successfully indexed are then removed_from the clusterstate.__Migrated jobs have the job version set to v6.6.0 and the custom settings_map has an entry added recording the fact the job was migrated and its_original version e.g._"migrated from version" : v6.1.0___@param clusterState The current clusterstate_@param listener     The success listener;public void migrateConfigs(ClusterState clusterState, ActionListener<Boolean> listener) {_        if (migrationInProgress.compareAndSet(false, true) == false) {_            listener.onResponse(Boolean.FALSE)__            return__        }__        ActionListener<Boolean> unMarkMigrationInProgress = ActionListener.wrap(_                response -> {_                    migrationInProgress.set(false)__                    listener.onResponse(response)__                },_                e -> {_                    migrationInProgress.set(false)__                    listener.onFailure(e)__                }_        )___        List<JobsAndDatafeeds> batches = splitInBatches(clusterState)__        if (batches.isEmpty()) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        if (clusterState.metaData().hasIndex(AnomalyDetectorsIndex.configIndexName()) == false) {_            createConfigIndex(ActionListener.wrap(_                    response -> {_                        unMarkMigrationInProgress.onResponse(Boolean.FALSE)__                    },_                    unMarkMigrationInProgress::onFailure_            ))__            return__        }__        if (migrationEligibilityCheck.canStartMigration(clusterState) == false) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        snapshotMlMeta(MlMetadata.getMlMetadata(clusterState), ActionListener.wrap(_                response -> {_                    _                    tookConfigSnapshot.set(true)__                    migrateBatches(batches, unMarkMigrationInProgress)__                },_                unMarkMigrationInProgress::onFailure_        ))__    };migrate,ml,job,and,datafeed,configurations,from,the,clusterstate,to,index,documents,configs,to,be,migrated,are,read,from,the,cluster,state,then,bulk,indexed,into,ml,config,those,successfully,indexed,are,then,removed,from,the,clusterstate,migrated,jobs,have,the,job,version,set,to,v6,6,0,and,the,custom,settings,map,has,an,entry,added,recording,the,fact,the,job,was,migrated,and,its,original,version,e,g,migrated,from,version,v6,1,0,param,cluster,state,the,current,clusterstate,param,listener,the,success,listener;public,void,migrate,configs,cluster,state,cluster,state,action,listener,boolean,listener,if,migration,in,progress,compare,and,set,false,true,false,listener,on,response,boolean,false,return,action,listener,boolean,un,mark,migration,in,progress,action,listener,wrap,response,migration,in,progress,set,false,listener,on,response,response,e,migration,in,progress,set,false,listener,on,failure,e,list,jobs,and,datafeeds,batches,split,in,batches,cluster,state,if,batches,is,empty,un,mark,migration,in,progress,on,response,boolean,false,return,if,cluster,state,meta,data,has,index,anomaly,detectors,index,config,index,name,false,create,config,index,action,listener,wrap,response,un,mark,migration,in,progress,on,response,boolean,false,un,mark,migration,in,progress,on,failure,return,if,migration,eligibility,check,can,start,migration,cluster,state,false,un,mark,migration,in,progress,on,response,boolean,false,return,snapshot,ml,meta,ml,metadata,get,ml,metadata,cluster,state,action,listener,wrap,response,took,config,snapshot,set,true,migrate,batches,batches,un,mark,migration,in,progress,un,mark,migration,in,progress,on,failure
MlConfigMigrator -> public void migrateConfigs(ClusterState clusterState, ActionListener<Boolean> listener);1547639475;Migrate ml job and datafeed configurations from the clusterstate_to index documents.__Configs to be migrated are read from the cluster state then bulk_indexed into .ml-config. Those successfully indexed are then removed_from the clusterstate.__Migrated jobs have the job version set to v6.6.0 and the custom settings_map has an entry added recording the fact the job was migrated and its_original version e.g._"migrated from version" : v6.1.0___@param clusterState The current clusterstate_@param listener     The success listener;public void migrateConfigs(ClusterState clusterState, ActionListener<Boolean> listener) {_        if (migrationInProgress.compareAndSet(false, true) == false) {_            listener.onResponse(Boolean.FALSE)__            return__        }__        ActionListener<Boolean> unMarkMigrationInProgress = ActionListener.wrap(_                response -> {_                    migrationInProgress.set(false)__                    listener.onResponse(response)__                },_                e -> {_                    migrationInProgress.set(false)__                    listener.onFailure(e)__                }_        )___        List<JobsAndDatafeeds> batches = splitInBatches(clusterState)__        if (batches.isEmpty()) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        if (clusterState.metaData().hasIndex(AnomalyDetectorsIndex.configIndexName()) == false) {_            createConfigIndex(ActionListener.wrap(_                    response -> {_                        unMarkMigrationInProgress.onResponse(Boolean.FALSE)__                    },_                    unMarkMigrationInProgress::onFailure_            ))__            return__        }__        if (migrationEligibilityCheck.canStartMigration(clusterState) == false) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        snapshotMlMeta(MlMetadata.getMlMetadata(clusterState), ActionListener.wrap(_                response -> {_                    _                    tookConfigSnapshot.set(true)__                    migrateBatches(batches, unMarkMigrationInProgress)__                },_                unMarkMigrationInProgress::onFailure_        ))__    };migrate,ml,job,and,datafeed,configurations,from,the,clusterstate,to,index,documents,configs,to,be,migrated,are,read,from,the,cluster,state,then,bulk,indexed,into,ml,config,those,successfully,indexed,are,then,removed,from,the,clusterstate,migrated,jobs,have,the,job,version,set,to,v6,6,0,and,the,custom,settings,map,has,an,entry,added,recording,the,fact,the,job,was,migrated,and,its,original,version,e,g,migrated,from,version,v6,1,0,param,cluster,state,the,current,clusterstate,param,listener,the,success,listener;public,void,migrate,configs,cluster,state,cluster,state,action,listener,boolean,listener,if,migration,in,progress,compare,and,set,false,true,false,listener,on,response,boolean,false,return,action,listener,boolean,un,mark,migration,in,progress,action,listener,wrap,response,migration,in,progress,set,false,listener,on,response,response,e,migration,in,progress,set,false,listener,on,failure,e,list,jobs,and,datafeeds,batches,split,in,batches,cluster,state,if,batches,is,empty,un,mark,migration,in,progress,on,response,boolean,false,return,if,cluster,state,meta,data,has,index,anomaly,detectors,index,config,index,name,false,create,config,index,action,listener,wrap,response,un,mark,migration,in,progress,on,response,boolean,false,un,mark,migration,in,progress,on,failure,return,if,migration,eligibility,check,can,start,migration,cluster,state,false,un,mark,migration,in,progress,on,response,boolean,false,return,snapshot,ml,meta,ml,metadata,get,ml,metadata,cluster,state,action,listener,wrap,response,took,config,snapshot,set,true,migrate,batches,batches,un,mark,migration,in,progress,un,mark,migration,in,progress,on,failure
MlConfigMigrator -> public void migrateConfigs(ClusterState clusterState, ActionListener<Boolean> listener);1547843554;Migrate ml job and datafeed configurations from the clusterstate_to index documents.__Configs to be migrated are read from the cluster state then bulk_indexed into .ml-config. Those successfully indexed are then removed_from the clusterstate.__Migrated jobs have the job version set to v6.6.0 and the custom settings_map has an entry added recording the fact the job was migrated and its_original version e.g._"migrated from version" : v6.1.0___@param clusterState The current clusterstate_@param listener     The success listener;public void migrateConfigs(ClusterState clusterState, ActionListener<Boolean> listener) {_        if (migrationInProgress.compareAndSet(false, true) == false) {_            listener.onResponse(Boolean.FALSE)__            return__        }__        ActionListener<Boolean> unMarkMigrationInProgress = ActionListener.wrap(_                response -> {_                    migrationInProgress.set(false)__                    listener.onResponse(response)__                },_                e -> {_                    migrationInProgress.set(false)__                    listener.onFailure(e)__                }_        )___        List<JobsAndDatafeeds> batches = splitInBatches(clusterState)__        if (batches.isEmpty()) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        if (clusterState.metaData().hasIndex(AnomalyDetectorsIndex.configIndexName()) == false) {_            createConfigIndex(ActionListener.wrap(_                    response -> {_                        unMarkMigrationInProgress.onResponse(Boolean.FALSE)__                    },_                    unMarkMigrationInProgress::onFailure_            ))__            return__        }__        if (migrationEligibilityCheck.canStartMigration(clusterState) == false) {_            unMarkMigrationInProgress.onResponse(Boolean.FALSE)__            return__        }__        snapshotMlMeta(MlMetadata.getMlMetadata(clusterState), ActionListener.wrap(_                response -> {_                    _                    tookConfigSnapshot.set(true)__                    migrateBatches(batches, unMarkMigrationInProgress)__                },_                unMarkMigrationInProgress::onFailure_        ))__    };migrate,ml,job,and,datafeed,configurations,from,the,clusterstate,to,index,documents,configs,to,be,migrated,are,read,from,the,cluster,state,then,bulk,indexed,into,ml,config,those,successfully,indexed,are,then,removed,from,the,clusterstate,migrated,jobs,have,the,job,version,set,to,v6,6,0,and,the,custom,settings,map,has,an,entry,added,recording,the,fact,the,job,was,migrated,and,its,original,version,e,g,migrated,from,version,v6,1,0,param,cluster,state,the,current,clusterstate,param,listener,the,success,listener;public,void,migrate,configs,cluster,state,cluster,state,action,listener,boolean,listener,if,migration,in,progress,compare,and,set,false,true,false,listener,on,response,boolean,false,return,action,listener,boolean,un,mark,migration,in,progress,action,listener,wrap,response,migration,in,progress,set,false,listener,on,response,response,e,migration,in,progress,set,false,listener,on,failure,e,list,jobs,and,datafeeds,batches,split,in,batches,cluster,state,if,batches,is,empty,un,mark,migration,in,progress,on,response,boolean,false,return,if,cluster,state,meta,data,has,index,anomaly,detectors,index,config,index,name,false,create,config,index,action,listener,wrap,response,un,mark,migration,in,progress,on,response,boolean,false,un,mark,migration,in,progress,on,failure,return,if,migration,eligibility,check,can,start,migration,cluster,state,false,un,mark,migration,in,progress,on,response,boolean,false,return,snapshot,ml,meta,ml,metadata,get,ml,metadata,cluster,state,action,listener,wrap,response,took,config,snapshot,set,true,migrate,batches,batches,un,mark,migration,in,progress,un,mark,migration,in,progress,on,failure
MlConfigMigrator -> public static PersistentTasksCustomMetaData rewritePersistentTaskParams(Map<String, Job> jobs, Map<String, DatafeedConfig> datafeeds,                                                                             PersistentTasksCustomMetaData currentTasks,                                                                             DiscoveryNodes nodes);1547576499;Find any unallocated datafeed and job tasks and update their persistent_task parameters if they have missing fields that were added in v6.6. If_a task exists with a missing field it must have been created in an earlier_version and survived an elasticsearch upgrade.__If there are no unallocated tasks the {@code currentTasks} argument is returned.__@param jobs          Job configs_@param datafeeds     Datafeed configs_@param currentTasks  The persistent tasks_@param nodes         The nodes in the cluster_@return  The updated tasks;public static PersistentTasksCustomMetaData rewritePersistentTaskParams(Map<String, Job> jobs, Map<String, DatafeedConfig> datafeeds,_                                                                            PersistentTasksCustomMetaData currentTasks,_                                                                            DiscoveryNodes nodes) {__        Collection<PersistentTasksCustomMetaData.PersistentTask> unallocatedJobTasks = MlTasks.unallocatedJobTasks(currentTasks, nodes)__        Collection<PersistentTasksCustomMetaData.PersistentTask> unallocatedDatafeedsTasks =_                MlTasks.unallocatedDatafeedTasks(currentTasks, nodes)___        if (unallocatedJobTasks.isEmpty() && unallocatedDatafeedsTasks.isEmpty()) {_            return currentTasks__        }__        PersistentTasksCustomMetaData.Builder taskBuilder = PersistentTasksCustomMetaData.builder(currentTasks)___        for (PersistentTasksCustomMetaData.PersistentTask jobTask : unallocatedJobTasks) {_            OpenJobAction.JobParams originalParams = (OpenJobAction.JobParams) jobTask.getParams()__            if (originalParams.getJob() == null) {_                Job job = jobs.get(originalParams.getJobId())__                if (job != null) {_                    logger.debug("updating persistent task params for job [{}]", originalParams.getJobId())___                    _                    OpenJobAction.JobParams updatedParams = new OpenJobAction.JobParams(originalParams.getJobId())__                    updatedParams.setTimeout(originalParams.getTimeout())__                    updatedParams.setJob(job)___                    _                    taskBuilder.removeTask(jobTask.getId())__                    taskBuilder.addTask(jobTask.getId(), jobTask.getTaskName(), updatedParams, jobTask.getAssignment())__                } else {_                    logger.error("cannot find job for task [{}]", jobTask.getId())__                }_            }_        }__        for (PersistentTasksCustomMetaData.PersistentTask datafeedTask : unallocatedDatafeedsTasks) {_            StartDatafeedAction.DatafeedParams originalParams = (StartDatafeedAction.DatafeedParams) datafeedTask.getParams()___            if (originalParams.getJobId() == null) {_                DatafeedConfig datafeedConfig = datafeeds.get(originalParams.getDatafeedId())__                if (datafeedConfig != null) {_                    logger.debug("Updating persistent task params for datafeed [{}]", originalParams.getDatafeedId())___                    StartDatafeedAction.DatafeedParams updatedParams =_                            new StartDatafeedAction.DatafeedParams(originalParams.getDatafeedId(), originalParams.getStartTime())__                    updatedParams.setTimeout(originalParams.getTimeout())__                    updatedParams.setEndTime(originalParams.getEndTime())__                    updatedParams.setJobId(datafeedConfig.getJobId())__                    updatedParams.setDatafeedIndices(datafeedConfig.getIndices())___                    _                    taskBuilder.removeTask(datafeedTask.getId())__                    taskBuilder.addTask(datafeedTask.getId(), datafeedTask.getTaskName(), updatedParams, datafeedTask.getAssignment())__                } else {_                    logger.error("cannot find datafeed for task [{}]", datafeedTask.getId())__                }_            }_        }__        return taskBuilder.build()__    };find,any,unallocated,datafeed,and,job,tasks,and,update,their,persistent,task,parameters,if,they,have,missing,fields,that,were,added,in,v6,6,if,a,task,exists,with,a,missing,field,it,must,have,been,created,in,an,earlier,version,and,survived,an,elasticsearch,upgrade,if,there,are,no,unallocated,tasks,the,code,current,tasks,argument,is,returned,param,jobs,job,configs,param,datafeeds,datafeed,configs,param,current,tasks,the,persistent,tasks,param,nodes,the,nodes,in,the,cluster,return,the,updated,tasks;public,static,persistent,tasks,custom,meta,data,rewrite,persistent,task,params,map,string,job,jobs,map,string,datafeed,config,datafeeds,persistent,tasks,custom,meta,data,current,tasks,discovery,nodes,nodes,collection,persistent,tasks,custom,meta,data,persistent,task,unallocated,job,tasks,ml,tasks,unallocated,job,tasks,current,tasks,nodes,collection,persistent,tasks,custom,meta,data,persistent,task,unallocated,datafeeds,tasks,ml,tasks,unallocated,datafeed,tasks,current,tasks,nodes,if,unallocated,job,tasks,is,empty,unallocated,datafeeds,tasks,is,empty,return,current,tasks,persistent,tasks,custom,meta,data,builder,task,builder,persistent,tasks,custom,meta,data,builder,current,tasks,for,persistent,tasks,custom,meta,data,persistent,task,job,task,unallocated,job,tasks,open,job,action,job,params,original,params,open,job,action,job,params,job,task,get,params,if,original,params,get,job,null,job,job,jobs,get,original,params,get,job,id,if,job,null,logger,debug,updating,persistent,task,params,for,job,original,params,get,job,id,open,job,action,job,params,updated,params,new,open,job,action,job,params,original,params,get,job,id,updated,params,set,timeout,original,params,get,timeout,updated,params,set,job,job,task,builder,remove,task,job,task,get,id,task,builder,add,task,job,task,get,id,job,task,get,task,name,updated,params,job,task,get,assignment,else,logger,error,cannot,find,job,for,task,job,task,get,id,for,persistent,tasks,custom,meta,data,persistent,task,datafeed,task,unallocated,datafeeds,tasks,start,datafeed,action,datafeed,params,original,params,start,datafeed,action,datafeed,params,datafeed,task,get,params,if,original,params,get,job,id,null,datafeed,config,datafeed,config,datafeeds,get,original,params,get,datafeed,id,if,datafeed,config,null,logger,debug,updating,persistent,task,params,for,datafeed,original,params,get,datafeed,id,start,datafeed,action,datafeed,params,updated,params,new,start,datafeed,action,datafeed,params,original,params,get,datafeed,id,original,params,get,start,time,updated,params,set,timeout,original,params,get,timeout,updated,params,set,end,time,original,params,get,end,time,updated,params,set,job,id,datafeed,config,get,job,id,updated,params,set,datafeed,indices,datafeed,config,get,indices,task,builder,remove,task,datafeed,task,get,id,task,builder,add,task,datafeed,task,get,id,datafeed,task,get,task,name,updated,params,datafeed,task,get,assignment,else,logger,error,cannot,find,datafeed,for,task,datafeed,task,get,id,return,task,builder,build
MlConfigMigrator -> public static PersistentTasksCustomMetaData rewritePersistentTaskParams(Map<String, Job> jobs, Map<String, DatafeedConfig> datafeeds,                                                                             PersistentTasksCustomMetaData currentTasks,                                                                             DiscoveryNodes nodes);1547639475;Find any unallocated datafeed and job tasks and update their persistent_task parameters if they have missing fields that were added in v6.6. If_a task exists with a missing field it must have been created in an earlier_version and survived an elasticsearch upgrade.__If there are no unallocated tasks the {@code currentTasks} argument is returned.__@param jobs          Job configs_@param datafeeds     Datafeed configs_@param currentTasks  The persistent tasks_@param nodes         The nodes in the cluster_@return  The updated tasks;public static PersistentTasksCustomMetaData rewritePersistentTaskParams(Map<String, Job> jobs, Map<String, DatafeedConfig> datafeeds,_                                                                            PersistentTasksCustomMetaData currentTasks,_                                                                            DiscoveryNodes nodes) {__        Collection<PersistentTasksCustomMetaData.PersistentTask> unallocatedJobTasks = MlTasks.unallocatedJobTasks(currentTasks, nodes)__        Collection<PersistentTasksCustomMetaData.PersistentTask> unallocatedDatafeedsTasks =_                MlTasks.unallocatedDatafeedTasks(currentTasks, nodes)___        if (unallocatedJobTasks.isEmpty() && unallocatedDatafeedsTasks.isEmpty()) {_            return currentTasks__        }__        PersistentTasksCustomMetaData.Builder taskBuilder = PersistentTasksCustomMetaData.builder(currentTasks)___        for (PersistentTasksCustomMetaData.PersistentTask jobTask : unallocatedJobTasks) {_            OpenJobAction.JobParams originalParams = (OpenJobAction.JobParams) jobTask.getParams()__            if (originalParams.getJob() == null) {_                Job job = jobs.get(originalParams.getJobId())__                if (job != null) {_                    logger.debug("updating persistent task params for job [{}]", originalParams.getJobId())___                    _                    OpenJobAction.JobParams updatedParams = new OpenJobAction.JobParams(originalParams.getJobId())__                    updatedParams.setTimeout(originalParams.getTimeout())__                    updatedParams.setJob(job)___                    _                    taskBuilder.removeTask(jobTask.getId())__                    taskBuilder.addTask(jobTask.getId(), jobTask.getTaskName(), updatedParams, jobTask.getAssignment())__                } else {_                    logger.error("cannot find job for task [{}]", jobTask.getId())__                }_            }_        }__        for (PersistentTasksCustomMetaData.PersistentTask datafeedTask : unallocatedDatafeedsTasks) {_            StartDatafeedAction.DatafeedParams originalParams = (StartDatafeedAction.DatafeedParams) datafeedTask.getParams()___            if (originalParams.getJobId() == null) {_                DatafeedConfig datafeedConfig = datafeeds.get(originalParams.getDatafeedId())__                if (datafeedConfig != null) {_                    logger.debug("Updating persistent task params for datafeed [{}]", originalParams.getDatafeedId())___                    StartDatafeedAction.DatafeedParams updatedParams =_                            new StartDatafeedAction.DatafeedParams(originalParams.getDatafeedId(), originalParams.getStartTime())__                    updatedParams.setTimeout(originalParams.getTimeout())__                    updatedParams.setEndTime(originalParams.getEndTime())__                    updatedParams.setJobId(datafeedConfig.getJobId())__                    updatedParams.setDatafeedIndices(datafeedConfig.getIndices())___                    _                    taskBuilder.removeTask(datafeedTask.getId())__                    taskBuilder.addTask(datafeedTask.getId(), datafeedTask.getTaskName(), updatedParams, datafeedTask.getAssignment())__                } else {_                    logger.error("cannot find datafeed for task [{}]", datafeedTask.getId())__                }_            }_        }__        return taskBuilder.build()__    };find,any,unallocated,datafeed,and,job,tasks,and,update,their,persistent,task,parameters,if,they,have,missing,fields,that,were,added,in,v6,6,if,a,task,exists,with,a,missing,field,it,must,have,been,created,in,an,earlier,version,and,survived,an,elasticsearch,upgrade,if,there,are,no,unallocated,tasks,the,code,current,tasks,argument,is,returned,param,jobs,job,configs,param,datafeeds,datafeed,configs,param,current,tasks,the,persistent,tasks,param,nodes,the,nodes,in,the,cluster,return,the,updated,tasks;public,static,persistent,tasks,custom,meta,data,rewrite,persistent,task,params,map,string,job,jobs,map,string,datafeed,config,datafeeds,persistent,tasks,custom,meta,data,current,tasks,discovery,nodes,nodes,collection,persistent,tasks,custom,meta,data,persistent,task,unallocated,job,tasks,ml,tasks,unallocated,job,tasks,current,tasks,nodes,collection,persistent,tasks,custom,meta,data,persistent,task,unallocated,datafeeds,tasks,ml,tasks,unallocated,datafeed,tasks,current,tasks,nodes,if,unallocated,job,tasks,is,empty,unallocated,datafeeds,tasks,is,empty,return,current,tasks,persistent,tasks,custom,meta,data,builder,task,builder,persistent,tasks,custom,meta,data,builder,current,tasks,for,persistent,tasks,custom,meta,data,persistent,task,job,task,unallocated,job,tasks,open,job,action,job,params,original,params,open,job,action,job,params,job,task,get,params,if,original,params,get,job,null,job,job,jobs,get,original,params,get,job,id,if,job,null,logger,debug,updating,persistent,task,params,for,job,original,params,get,job,id,open,job,action,job,params,updated,params,new,open,job,action,job,params,original,params,get,job,id,updated,params,set,timeout,original,params,get,timeout,updated,params,set,job,job,task,builder,remove,task,job,task,get,id,task,builder,add,task,job,task,get,id,job,task,get,task,name,updated,params,job,task,get,assignment,else,logger,error,cannot,find,job,for,task,job,task,get,id,for,persistent,tasks,custom,meta,data,persistent,task,datafeed,task,unallocated,datafeeds,tasks,start,datafeed,action,datafeed,params,original,params,start,datafeed,action,datafeed,params,datafeed,task,get,params,if,original,params,get,job,id,null,datafeed,config,datafeed,config,datafeeds,get,original,params,get,datafeed,id,if,datafeed,config,null,logger,debug,updating,persistent,task,params,for,datafeed,original,params,get,datafeed,id,start,datafeed,action,datafeed,params,updated,params,new,start,datafeed,action,datafeed,params,original,params,get,datafeed,id,original,params,get,start,time,updated,params,set,timeout,original,params,get,timeout,updated,params,set,end,time,original,params,get,end,time,updated,params,set,job,id,datafeed,config,get,job,id,updated,params,set,datafeed,indices,datafeed,config,get,indices,task,builder,remove,task,datafeed,task,get,id,task,builder,add,task,datafeed,task,get,id,datafeed,task,get,task,name,updated,params,datafeed,task,get,assignment,else,logger,error,cannot,find,datafeed,for,task,datafeed,task,get,id,return,task,builder,build
MlConfigMigrator -> public static PersistentTasksCustomMetaData rewritePersistentTaskParams(Map<String, Job> jobs, Map<String, DatafeedConfig> datafeeds,                                                                             PersistentTasksCustomMetaData currentTasks,                                                                             DiscoveryNodes nodes);1547843554;Find any unallocated datafeed and job tasks and update their persistent_task parameters if they have missing fields that were added in v6.6. If_a task exists with a missing field it must have been created in an earlier_version and survived an elasticsearch upgrade.__If there are no unallocated tasks the {@code currentTasks} argument is returned.__@param jobs          Job configs_@param datafeeds     Datafeed configs_@param currentTasks  The persistent tasks_@param nodes         The nodes in the cluster_@return  The updated tasks;public static PersistentTasksCustomMetaData rewritePersistentTaskParams(Map<String, Job> jobs, Map<String, DatafeedConfig> datafeeds,_                                                                            PersistentTasksCustomMetaData currentTasks,_                                                                            DiscoveryNodes nodes) {__        Collection<PersistentTasksCustomMetaData.PersistentTask> unallocatedJobTasks = MlTasks.unallocatedJobTasks(currentTasks, nodes)__        Collection<PersistentTasksCustomMetaData.PersistentTask> unallocatedDatafeedsTasks =_                MlTasks.unallocatedDatafeedTasks(currentTasks, nodes)___        if (unallocatedJobTasks.isEmpty() && unallocatedDatafeedsTasks.isEmpty()) {_            return currentTasks__        }__        PersistentTasksCustomMetaData.Builder taskBuilder = PersistentTasksCustomMetaData.builder(currentTasks)___        for (PersistentTasksCustomMetaData.PersistentTask jobTask : unallocatedJobTasks) {_            OpenJobAction.JobParams originalParams = (OpenJobAction.JobParams) jobTask.getParams()__            if (originalParams.getJob() == null) {_                Job job = jobs.get(originalParams.getJobId())__                if (job != null) {_                    logger.debug("updating persistent task params for job [{}]", originalParams.getJobId())___                    _                    OpenJobAction.JobParams updatedParams = new OpenJobAction.JobParams(originalParams.getJobId())__                    updatedParams.setTimeout(originalParams.getTimeout())__                    updatedParams.setJob(job)___                    _                    taskBuilder.removeTask(jobTask.getId())__                    taskBuilder.addTask(jobTask.getId(), jobTask.getTaskName(), updatedParams, jobTask.getAssignment())__                } else {_                    logger.error("cannot find job for task [{}]", jobTask.getId())__                }_            }_        }__        for (PersistentTasksCustomMetaData.PersistentTask datafeedTask : unallocatedDatafeedsTasks) {_            StartDatafeedAction.DatafeedParams originalParams = (StartDatafeedAction.DatafeedParams) datafeedTask.getParams()___            if (originalParams.getJobId() == null) {_                DatafeedConfig datafeedConfig = datafeeds.get(originalParams.getDatafeedId())__                if (datafeedConfig != null) {_                    logger.debug("Updating persistent task params for datafeed [{}]", originalParams.getDatafeedId())___                    StartDatafeedAction.DatafeedParams updatedParams =_                            new StartDatafeedAction.DatafeedParams(originalParams.getDatafeedId(), originalParams.getStartTime())__                    updatedParams.setTimeout(originalParams.getTimeout())__                    updatedParams.setEndTime(originalParams.getEndTime())__                    updatedParams.setJobId(datafeedConfig.getJobId())__                    updatedParams.setDatafeedIndices(datafeedConfig.getIndices())___                    _                    taskBuilder.removeTask(datafeedTask.getId())__                    taskBuilder.addTask(datafeedTask.getId(), datafeedTask.getTaskName(), updatedParams, datafeedTask.getAssignment())__                } else {_                    logger.error("cannot find datafeed for task [{}]", datafeedTask.getId())__                }_            }_        }__        return taskBuilder.build()__    };find,any,unallocated,datafeed,and,job,tasks,and,update,their,persistent,task,parameters,if,they,have,missing,fields,that,were,added,in,v6,6,if,a,task,exists,with,a,missing,field,it,must,have,been,created,in,an,earlier,version,and,survived,an,elasticsearch,upgrade,if,there,are,no,unallocated,tasks,the,code,current,tasks,argument,is,returned,param,jobs,job,configs,param,datafeeds,datafeed,configs,param,current,tasks,the,persistent,tasks,param,nodes,the,nodes,in,the,cluster,return,the,updated,tasks;public,static,persistent,tasks,custom,meta,data,rewrite,persistent,task,params,map,string,job,jobs,map,string,datafeed,config,datafeeds,persistent,tasks,custom,meta,data,current,tasks,discovery,nodes,nodes,collection,persistent,tasks,custom,meta,data,persistent,task,unallocated,job,tasks,ml,tasks,unallocated,job,tasks,current,tasks,nodes,collection,persistent,tasks,custom,meta,data,persistent,task,unallocated,datafeeds,tasks,ml,tasks,unallocated,datafeed,tasks,current,tasks,nodes,if,unallocated,job,tasks,is,empty,unallocated,datafeeds,tasks,is,empty,return,current,tasks,persistent,tasks,custom,meta,data,builder,task,builder,persistent,tasks,custom,meta,data,builder,current,tasks,for,persistent,tasks,custom,meta,data,persistent,task,job,task,unallocated,job,tasks,open,job,action,job,params,original,params,open,job,action,job,params,job,task,get,params,if,original,params,get,job,null,job,job,jobs,get,original,params,get,job,id,if,job,null,logger,debug,updating,persistent,task,params,for,job,original,params,get,job,id,open,job,action,job,params,updated,params,new,open,job,action,job,params,original,params,get,job,id,updated,params,set,timeout,original,params,get,timeout,updated,params,set,job,job,task,builder,remove,task,job,task,get,id,task,builder,add,task,job,task,get,id,job,task,get,task,name,updated,params,job,task,get,assignment,else,logger,error,cannot,find,job,for,task,job,task,get,id,for,persistent,tasks,custom,meta,data,persistent,task,datafeed,task,unallocated,datafeeds,tasks,start,datafeed,action,datafeed,params,original,params,start,datafeed,action,datafeed,params,datafeed,task,get,params,if,original,params,get,job,id,null,datafeed,config,datafeed,config,datafeeds,get,original,params,get,datafeed,id,if,datafeed,config,null,logger,debug,updating,persistent,task,params,for,datafeed,original,params,get,datafeed,id,start,datafeed,action,datafeed,params,updated,params,new,start,datafeed,action,datafeed,params,original,params,get,datafeed,id,original,params,get,start,time,updated,params,set,timeout,original,params,get,timeout,updated,params,set,end,time,original,params,get,end,time,updated,params,set,job,id,datafeed,config,get,job,id,updated,params,set,datafeed,indices,datafeed,config,get,indices,task,builder,remove,task,datafeed,task,get,id,task,builder,add,task,datafeed,task,get,id,datafeed,task,get,task,name,updated,params,datafeed,task,get,assignment,else,logger,error,cannot,find,datafeed,for,task,datafeed,task,get,id,return,task,builder,build
