commented;modifiers;parameterAmount;loc;comment;code
false;private;1;3;;private void setReassignmentRecheckInterval(TimeValue recheckInterval) {     reassignmentRecheckInterval = Duration.ofNanos(recheckInterval.getNanos()). }
false;public;0;5;;@Override public void onMaster() {     isMaster = true.     logger.trace("ML memory tracker on master"). }
false;public;0;7;;@Override public void offMaster() {     isMaster = false.     logger.trace("ML memory tracker off master").     memoryRequirementByJob.clear().     lastUpdateTime = null. }
true;public;0;12;/**  * Wait for all outstanding searches to complete.  * After returning, no new searches can be started.  */ ;/**  * Wait for all outstanding searches to complete.  * After returning, no new searches can be started.  */ public void stop() {     logger.trace("ML memory tracker stop called").     // We never terminate the phaser     assert stopPhaser.isTerminated() == false.     // in the register/arrive/unregister logic in another method that uses the phaser     assert stopPhaser.getRegisteredParties() > 0.     assert stopPhaser.getUnarrivedParties() > 0.     stopPhaser.arriveAndAwaitAdvance().     assert stopPhaser.getPhase() > 0.     logger.debug("ML memory tracker stopped"). }
false;public;0;4;;@Override public String executorName() {     return MachineLearning.UTILITY_THREAD_POOL_NAME. }
true;public;0;5;/**  * Is the information in this object sufficiently up to date  * for valid task assignment decisions to be made using it?  */ ;/**  * Is the information in this object sufficiently up to date  * for valid task assignment decisions to be made using it?  */ public boolean isRecentlyRefreshed() {     Instant localLastUpdateTime = lastUpdateTime.     return localLastUpdateTime != null && localLastUpdateTime.plus(RECENT_UPDATE_THRESHOLD).plus(reassignmentRecheckInterval).isAfter(Instant.now()). }
true;public;1;13;/**  * Get the memory requirement for a job.  * This method only works on the master node.  * @param jobId The job ID.  * @return The memory requirement of the job specified by {@code jobId},  *         or <code>null</code> if it cannot be calculated.  */ ;/**  * Get the memory requirement for a job.  * This method only works on the master node.  * @param jobId The job ID.  * @return The memory requirement of the job specified by {@code jobId},  *         or <code>null</code> if it cannot be calculated.  */ public Long getJobMemoryRequirement(String jobId) {     if (isMaster == false) {         return null.     }     Long memoryRequirement = memoryRequirementByJob.get(jobId).     if (memoryRequirement != null) {         return memoryRequirement.     }     return null. }
true;public;1;3;/**  * Remove any memory requirement that is stored for the specified job.  * It doesn't matter if this method is called for a job that doesn't have  * a stored memory requirement.  */ ;/**  * Remove any memory requirement that is stored for the specified job.  * It doesn't matter if this method is called for a job that doesn't have  * a stored memory requirement.  */ public void removeJob(String jobId) {     memoryRequirementByJob.remove(jobId). }
true;public;0;18;/**  * Uses a separate thread to refresh the memory requirement for every ML job that has  * a corresponding persistent task.  This method only works on the master node.  * @return <code>true</code> if the async refresh is scheduled, and <code>false</code>  *         if this is not possible for some reason.  */ ;/**  * Uses a separate thread to refresh the memory requirement for every ML job that has  * a corresponding persistent task.  This method only works on the master node.  * @return <code>true</code> if the async refresh is scheduled, and <code>false</code>  *         if this is not possible for some reason.  */ public boolean asyncRefresh() {     if (isMaster) {         try {             ActionListener<Void> listener = ActionListener.wrap(aVoid -> logger.trace("Job memory requirement refresh request completed successfully"), e -> logger.warn("Failed to refresh job memory requirements", e)).             threadPool.executor(executorName()).execute(() -> refresh(clusterService.state().getMetaData().custom(PersistentTasksCustomMetaData.TYPE), listener)).             return true.         } catch (EsRejectedExecutionException e) {             logger.warn("Couldn't schedule ML memory update - node might be shutting down", e).         }     }     return false. }
true;public;2;10;/**  * This refreshes the memory requirement for every ML job that has a corresponding  * persistent task and, in addition, one job that doesn't have a persistent task.  * This method only works on the master node.  * @param jobId The job ID of the job whose memory requirement is to be refreshed  *              despite not having a corresponding persistent task.  * @param listener Receives the memory requirement of the job specified by {@code jobId},  *                 or <code>null</code> if it cannot be calculated.  */ ;/**  * This refreshes the memory requirement for every ML job that has a corresponding  * persistent task and, in addition, one job that doesn't have a persistent task.  * This method only works on the master node.  * @param jobId The job ID of the job whose memory requirement is to be refreshed  *              despite not having a corresponding persistent task.  * @param listener Receives the memory requirement of the job specified by {@code jobId},  *                 or <code>null</code> if it cannot be calculated.  */ public void refreshJobMemoryAndAllOthers(String jobId, ActionListener<Long> listener) {     if (isMaster == false) {         listener.onResponse(null).         return.     }     PersistentTasksCustomMetaData persistentTasks = clusterService.state().getMetaData().custom(PersistentTasksCustomMetaData.TYPE).     refresh(persistentTasks, ActionListener.wrap(aVoid -> refreshJobMemory(jobId, listener), listener::onFailure)). }
true;;2;30;/**  * This refreshes the memory requirement for every ML job that has a corresponding persistent task.  * It does NOT remove entries for jobs that no longer have a persistent task, because that would  * lead to a race where a job was opened part way through the refresh.  (Instead, entries are removed  * when jobs are deleted.)  */ ;/**  * This refreshes the memory requirement for every ML job that has a corresponding persistent task.  * It does NOT remove entries for jobs that no longer have a persistent task, because that would  * lead to a race where a job was opened part way through the refresh.  (Instead, entries are removed  * when jobs are deleted.)  */ void refresh(PersistentTasksCustomMetaData persistentTasks, ActionListener<Void> onCompletion) {     synchronized (fullRefreshCompletionListeners) {         fullRefreshCompletionListeners.add(onCompletion).         if (fullRefreshCompletionListeners.size() > 1) {             // A refresh is already in progress, so don't do another             return.         }     }     ActionListener<Void> refreshComplete = ActionListener.wrap(aVoid -> {         lastUpdateTime = Instant.now().         synchronized (fullRefreshCompletionListeners) {             assert fullRefreshCompletionListeners.isEmpty() == false.             for (ActionListener<Void> listener : fullRefreshCompletionListeners) {                 listener.onResponse(null).             }             fullRefreshCompletionListeners.clear().         }     }, onCompletion::onFailure).     // persistentTasks will be null if there's never been a persistent task created in this cluster     if (persistentTasks == null) {         refreshComplete.onResponse(null).     } else {         List<PersistentTasksCustomMetaData.PersistentTask<?>> mlJobTasks = persistentTasks.tasks().stream().filter(task -> MlTasks.JOB_TASK_NAME.equals(task.getTaskName())).collect(Collectors.toList()).         iterateMlJobTasks(mlJobTasks.iterator(), refreshComplete).     } }
false;private;2;16;;private void iterateMlJobTasks(Iterator<PersistentTasksCustomMetaData.PersistentTask<?>> iterator, ActionListener<Void> refreshComplete) {     if (iterator.hasNext()) {         OpenJobAction.JobParams jobParams = (OpenJobAction.JobParams) iterator.next().getParams().         refreshJobMemory(jobParams.getJobId(), ActionListener.wrap(// is involved         mem -> threadPool.executor(executorName()).execute(() -> iterateMlJobTasks(iterator, refreshComplete)), refreshComplete::onFailure)).     } else {         refreshComplete.onResponse(null).     } }
true;public;2;45;/**  * Refresh the memory requirement for a single job.  * This method only works on the master node.  * @param jobId    The ID of the job to refresh the memory requirement for.  * @param listener Receives the job's memory requirement, or <code>null</code>  *                 if it cannot be calculated.  */ ;/**  * Refresh the memory requirement for a single job.  * This method only works on the master node.  * @param jobId    The ID of the job to refresh the memory requirement for.  * @param listener Receives the job's memory requirement, or <code>null</code>  *                 if it cannot be calculated.  */ public void refreshJobMemory(String jobId, ActionListener<Long> listener) {     if (isMaster == false) {         listener.onResponse(null).         return.     }     // The phaser prevents searches being started after the memory tracker's stop() method has returned     if (stopPhaser.register() != 0) {         // Phases above 0 mean we've been stopped, so don't do any operations that involve external interaction         stopPhaser.arriveAndDeregister().         listener.onFailure(new EsRejectedExecutionException("Couldn't run ML memory update - node is shutting down")).         return.     }     ActionListener<Long> phaserListener = ActionListener.wrap(r -> {         stopPhaser.arriveAndDeregister().         listener.onResponse(r).     }, e -> {         stopPhaser.arriveAndDeregister().         listener.onFailure(e).     }).     try {         jobResultsProvider.getEstablishedMemoryUsage(jobId, null, null, establishedModelMemoryBytes -> {             if (establishedModelMemoryBytes <= 0L) {                 setJobMemoryToLimit(jobId, phaserListener).             } else {                 Long memoryRequirementBytes = establishedModelMemoryBytes + Job.PROCESS_MEMORY_OVERHEAD.getBytes().                 memoryRequirementByJob.put(jobId, memoryRequirementBytes).                 phaserListener.onResponse(memoryRequirementBytes).             }         }, e -> {             logger.error("[" + jobId + "] failed to calculate job established model memory requirement", e).             setJobMemoryToLimit(jobId, phaserListener).         }).     } catch (Exception e) {         logger.error("[" + jobId + "] failed to calculate job established model memory requirement", e).         setJobMemoryToLimit(jobId, phaserListener).     } }
false;private;2;23;;private void setJobMemoryToLimit(String jobId, ActionListener<Long> listener) {     jobManager.getJob(jobId, ActionListener.wrap(job -> {         Long memoryLimitMb = (job.getAnalysisLimits() != null) ? job.getAnalysisLimits().getModelMemoryLimit() : null.         // a mixed version cluster         if (memoryLimitMb == null) {             memoryLimitMb = AnalysisLimits.PRE_6_1_DEFAULT_MODEL_MEMORY_LIMIT_MB.         }         Long memoryRequirementBytes = ByteSizeUnit.MB.toBytes(memoryLimitMb) + Job.PROCESS_MEMORY_OVERHEAD.getBytes().         memoryRequirementByJob.put(jobId, memoryRequirementBytes).         listener.onResponse(memoryRequirementBytes).     }, e -> {         if (e instanceof ResourceNotFoundException) {             // TODO: does this also happen if the .ml-config index exists but is unavailable?             logger.trace("[{}] job deleted during ML memory update", jobId).         } else {             logger.error("[" + jobId + "] failed to get job during ML memory update", e).         }         memoryRequirementByJob.remove(jobId).         listener.onResponse(null).     })). }
