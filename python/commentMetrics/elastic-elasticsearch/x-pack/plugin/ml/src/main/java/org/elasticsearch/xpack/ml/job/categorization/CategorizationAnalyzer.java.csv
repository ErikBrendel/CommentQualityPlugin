# id;timestamp;commentText;codeText;commentWords;codeWords
CategorizationAnalyzer -> private static List<TokenFilterFactory> parseTokenFilterFactories(CategorizationAnalyzerConfig config,                                                                       AnalysisRegistry analysisRegistry, Environment environment,                                                                       Tuple<String, TokenizerFactory> tokenizerFactory,                                                                       List<CharFilterFactory> charFilterFactoryList) throws IOException;1531910483;Get token filter factories for each configured token filter.  Each configuration_element can be the name of an out-of-the-box token filter, or a custom definition.;private static List<TokenFilterFactory> parseTokenFilterFactories(CategorizationAnalyzerConfig config,_                                                                      AnalysisRegistry analysisRegistry, Environment environment,_                                                                      Tuple<String, TokenizerFactory> tokenizerFactory,_                                                                      List<CharFilterFactory> charFilterFactoryList) throws IOException {_        List<CategorizationAnalyzerConfig.NameOrDefinition> tokenFilters = config.getTokenFilters()__        final List<TokenFilterFactory> tokenFilterFactoryList = new ArrayList<>()__        for (CategorizationAnalyzerConfig.NameOrDefinition tokenFilter : tokenFilters) {_            TokenFilterFactory tokenFilterFactory__            if (tokenFilter.name != null) {_                AnalysisModule.AnalysisProvider<TokenFilterFactory> tokenFilterFactoryFactory__                tokenFilterFactoryFactory = analysisRegistry.getTokenFilterProvider(tokenFilter.name)__                if (tokenFilterFactoryFactory == null) {_                    throw new IllegalArgumentException("Failed to find global token filter under [" + tokenFilter.name + "]")__                }_                tokenFilterFactory = tokenFilterFactoryFactory.get(environment, tokenFilter.name)__            } else {_                String filterTypeName = tokenFilter.definition.get("type")__                if (filterTypeName == null) {_                    throw new IllegalArgumentException("Missing [type] setting for token filter: " + tokenFilter.definition)__                }_                AnalysisModule.AnalysisProvider<TokenFilterFactory> tokenFilterFactoryFactory =_                    analysisRegistry.getTokenFilterProvider(filterTypeName)__                if (tokenFilterFactoryFactory == null) {_                    throw new IllegalArgumentException("Failed to find global token filter under [" + filterTypeName + "]")__                }_                Settings settings = augmentSettings(tokenFilter.definition)__                _                tokenFilterFactory = tokenFilterFactoryFactory.get(buildDummyIndexSettings(settings), environment, "_anonymous_tokenfilter",_                    settings)__                tokenFilterFactory = CustomAnalyzerProvider.checkAndApplySynonymFilter(tokenFilterFactory, tokenizerFactory.v1(),_                    tokenizerFactory.v2(), tokenFilterFactoryList, charFilterFactoryList, environment)__            }_            if (tokenFilterFactory == null) {_                throw new IllegalArgumentException("Failed to find or create token filter [" + tokenFilter + "]")__            }_            tokenFilterFactoryList.add(tokenFilterFactory)__        }_        return tokenFilterFactoryList__    };get,token,filter,factories,for,each,configured,token,filter,each,configuration,element,can,be,the,name,of,an,out,of,the,box,token,filter,or,a,custom,definition;private,static,list,token,filter,factory,parse,token,filter,factories,categorization,analyzer,config,config,analysis,registry,analysis,registry,environment,environment,tuple,string,tokenizer,factory,tokenizer,factory,list,char,filter,factory,char,filter,factory,list,throws,ioexception,list,categorization,analyzer,config,name,or,definition,token,filters,config,get,token,filters,final,list,token,filter,factory,token,filter,factory,list,new,array,list,for,categorization,analyzer,config,name,or,definition,token,filter,token,filters,token,filter,factory,token,filter,factory,if,token,filter,name,null,analysis,module,analysis,provider,token,filter,factory,token,filter,factory,factory,token,filter,factory,factory,analysis,registry,get,token,filter,provider,token,filter,name,if,token,filter,factory,factory,null,throw,new,illegal,argument,exception,failed,to,find,global,token,filter,under,token,filter,name,token,filter,factory,token,filter,factory,factory,get,environment,token,filter,name,else,string,filter,type,name,token,filter,definition,get,type,if,filter,type,name,null,throw,new,illegal,argument,exception,missing,type,setting,for,token,filter,token,filter,definition,analysis,module,analysis,provider,token,filter,factory,token,filter,factory,factory,analysis,registry,get,token,filter,provider,filter,type,name,if,token,filter,factory,factory,null,throw,new,illegal,argument,exception,failed,to,find,global,token,filter,under,filter,type,name,settings,settings,augment,settings,token,filter,definition,token,filter,factory,token,filter,factory,factory,get,build,dummy,index,settings,settings,environment,settings,token,filter,factory,custom,analyzer,provider,check,and,apply,synonym,filter,token,filter,factory,tokenizer,factory,v1,tokenizer,factory,v2,token,filter,factory,list,char,filter,factory,list,environment,if,token,filter,factory,null,throw,new,illegal,argument,exception,failed,to,find,or,create,token,filter,token,filter,token,filter,factory,list,add,token,filter,factory,return,token,filter,factory,list
CategorizationAnalyzer -> private static List<TokenFilterFactory> parseTokenFilterFactories(CategorizationAnalyzerConfig config,                                                                       AnalysisRegistry analysisRegistry, Environment environment,                                                                       Tuple<String, TokenizerFactory> tokenizerFactory,                                                                       List<CharFilterFactory> charFilterFactoryList) throws IOException;1537371806;Get token filter factories for each configured token filter.  Each configuration_element can be the name of an out-of-the-box token filter, or a custom definition.;private static List<TokenFilterFactory> parseTokenFilterFactories(CategorizationAnalyzerConfig config,_                                                                      AnalysisRegistry analysisRegistry, Environment environment,_                                                                      Tuple<String, TokenizerFactory> tokenizerFactory,_                                                                      List<CharFilterFactory> charFilterFactoryList) throws IOException {_        List<CategorizationAnalyzerConfig.NameOrDefinition> tokenFilters = config.getTokenFilters()__        TransportAnalyzeAction.DeferredTokenFilterRegistry deferredRegistry_            = new TransportAnalyzeAction.DeferredTokenFilterRegistry(analysisRegistry, null)__        final List<TokenFilterFactory> tokenFilterFactoryList = new ArrayList<>()__        for (CategorizationAnalyzerConfig.NameOrDefinition tokenFilter : tokenFilters) {_            TokenFilterFactory tokenFilterFactory__            if (tokenFilter.name != null) {_                AnalysisModule.AnalysisProvider<TokenFilterFactory> tokenFilterFactoryFactory__                tokenFilterFactoryFactory = analysisRegistry.getTokenFilterProvider(tokenFilter.name)__                if (tokenFilterFactoryFactory == null) {_                    throw new IllegalArgumentException("Failed to find global token filter under [" + tokenFilter.name + "]")__                }_                tokenFilterFactory = tokenFilterFactoryFactory.get(environment, tokenFilter.name)__            } else {_                String filterTypeName = tokenFilter.definition.get("type")__                if (filterTypeName == null) {_                    throw new IllegalArgumentException("Missing [type] setting for token filter: " + tokenFilter.definition)__                }_                AnalysisModule.AnalysisProvider<TokenFilterFactory> tokenFilterFactoryFactory =_                    analysisRegistry.getTokenFilterProvider(filterTypeName)__                if (tokenFilterFactoryFactory == null) {_                    throw new IllegalArgumentException("Failed to find global token filter under [" + filterTypeName + "]")__                }_                Settings settings = augmentSettings(tokenFilter.definition)__                _                tokenFilterFactory = tokenFilterFactoryFactory.get(buildDummyIndexSettings(settings), environment, "_anonymous_tokenfilter",_                    settings)__                tokenFilterFactory = tokenFilterFactory.getChainAwareTokenFilterFactory(tokenizerFactory.v2(),_                    charFilterFactoryList, tokenFilterFactoryList, deferredRegistry)__            }_            if (tokenFilterFactory == null) {_                throw new IllegalArgumentException("Failed to find or create token filter [" + tokenFilter + "]")__            }_            tokenFilterFactoryList.add(tokenFilterFactory)__        }_        return tokenFilterFactoryList__    };get,token,filter,factories,for,each,configured,token,filter,each,configuration,element,can,be,the,name,of,an,out,of,the,box,token,filter,or,a,custom,definition;private,static,list,token,filter,factory,parse,token,filter,factories,categorization,analyzer,config,config,analysis,registry,analysis,registry,environment,environment,tuple,string,tokenizer,factory,tokenizer,factory,list,char,filter,factory,char,filter,factory,list,throws,ioexception,list,categorization,analyzer,config,name,or,definition,token,filters,config,get,token,filters,transport,analyze,action,deferred,token,filter,registry,deferred,registry,new,transport,analyze,action,deferred,token,filter,registry,analysis,registry,null,final,list,token,filter,factory,token,filter,factory,list,new,array,list,for,categorization,analyzer,config,name,or,definition,token,filter,token,filters,token,filter,factory,token,filter,factory,if,token,filter,name,null,analysis,module,analysis,provider,token,filter,factory,token,filter,factory,factory,token,filter,factory,factory,analysis,registry,get,token,filter,provider,token,filter,name,if,token,filter,factory,factory,null,throw,new,illegal,argument,exception,failed,to,find,global,token,filter,under,token,filter,name,token,filter,factory,token,filter,factory,factory,get,environment,token,filter,name,else,string,filter,type,name,token,filter,definition,get,type,if,filter,type,name,null,throw,new,illegal,argument,exception,missing,type,setting,for,token,filter,token,filter,definition,analysis,module,analysis,provider,token,filter,factory,token,filter,factory,factory,analysis,registry,get,token,filter,provider,filter,type,name,if,token,filter,factory,factory,null,throw,new,illegal,argument,exception,failed,to,find,global,token,filter,under,filter,type,name,settings,settings,augment,settings,token,filter,definition,token,filter,factory,token,filter,factory,factory,get,build,dummy,index,settings,settings,environment,settings,token,filter,factory,token,filter,factory,get,chain,aware,token,filter,factory,tokenizer,factory,v2,char,filter,factory,list,token,filter,factory,list,deferred,registry,if,token,filter,factory,null,throw,new,illegal,argument,exception,failed,to,find,or,create,token,filter,token,filter,token,filter,factory,list,add,token,filter,factory,return,token,filter,factory,list
CategorizationAnalyzer -> private static Settings augmentSettings(Settings settings);1531910483;The behaviour of Elasticsearch analyzers can vary between versions._For categorization we'll always use the latest version of the text analysis._The other settings are just to stop classes that expect to be associated with_an index from complaining.;private static Settings augmentSettings(Settings settings) {_        return Settings.builder().put(settings)_            .put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT)_            .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0)_            .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_            .put(IndexMetaData.SETTING_INDEX_UUID, UUIDs.randomBase64UUID())_            .build()__    };the,behaviour,of,elasticsearch,analyzers,can,vary,between,versions,for,categorization,we,ll,always,use,the,latest,version,of,the,text,analysis,the,other,settings,are,just,to,stop,classes,that,expect,to,be,associated,with,an,index,from,complaining;private,static,settings,augment,settings,settings,settings,return,settings,builder,put,settings,put,index,meta,data,version,current,put,index,meta,data,0,put,index,meta,data,1,put,index,meta,data,uuids,random,base64uuid,build
CategorizationAnalyzer -> private static Settings augmentSettings(Settings settings);1537371806;The behaviour of Elasticsearch analyzers can vary between versions._For categorization we'll always use the latest version of the text analysis._The other settings are just to stop classes that expect to be associated with_an index from complaining.;private static Settings augmentSettings(Settings settings) {_        return Settings.builder().put(settings)_            .put(IndexMetaData.SETTING_VERSION_CREATED, Version.CURRENT)_            .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0)_            .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_            .put(IndexMetaData.SETTING_INDEX_UUID, UUIDs.randomBase64UUID())_            .build()__    };the,behaviour,of,elasticsearch,analyzers,can,vary,between,versions,for,categorization,we,ll,always,use,the,latest,version,of,the,text,analysis,the,other,settings,are,just,to,stop,classes,that,expect,to,be,associated,with,an,index,from,complaining;private,static,settings,augment,settings,settings,settings,return,settings,builder,put,settings,put,index,meta,data,version,current,put,index,meta,data,0,put,index,meta,data,1,put,index,meta,data,uuids,random,base64uuid,build
CategorizationAnalyzer -> public List<String> tokenizeField(String fieldName, String fieldValue);1524684173;Given a field value, convert it to a list of tokens using the configured analyzer.;public List<String> tokenizeField(String fieldName, String fieldValue) {_        List<String> tokens = new ArrayList<>()__        try (TokenStream stream = analyzer.tokenStream(fieldName, fieldValue)) {_            stream.reset()__            CharTermAttribute term = stream.addAttribute(CharTermAttribute.class)__            while (stream.incrementToken()) {_                String token = term.toString()__                _                if (token.isEmpty() == false) {_                    tokens.add(term.toString())__                }_            }_            stream.end()__        } catch (IOException e) {_            throw new ElasticsearchException("Failed to analyze value [" + fieldValue + "] of field [" + fieldName + "]", e)__        }_        return tokens__    };given,a,field,value,convert,it,to,a,list,of,tokens,using,the,configured,analyzer;public,list,string,tokenize,field,string,field,name,string,field,value,list,string,tokens,new,array,list,try,token,stream,stream,analyzer,token,stream,field,name,field,value,stream,reset,char,term,attribute,term,stream,add,attribute,char,term,attribute,class,while,stream,increment,token,string,token,term,to,string,if,token,is,empty,false,tokens,add,term,to,string,stream,end,catch,ioexception,e,throw,new,elasticsearch,exception,failed,to,analyze,value,field,value,of,field,field,name,e,return,tokens
CategorizationAnalyzer -> public List<String> tokenizeField(String fieldName, String fieldValue);1531910483;Given a field value, convert it to a list of tokens using the configured analyzer.;public List<String> tokenizeField(String fieldName, String fieldValue) {_        List<String> tokens = new ArrayList<>()__        try (TokenStream stream = analyzer.tokenStream(fieldName, fieldValue)) {_            stream.reset()__            CharTermAttribute term = stream.addAttribute(CharTermAttribute.class)__            while (stream.incrementToken()) {_                String token = term.toString()__                _                if (token.isEmpty() == false) {_                    tokens.add(term.toString())__                }_            }_            stream.end()__        } catch (IOException e) {_            throw new ElasticsearchException("Failed to analyze value [" + fieldValue + "] of field [" + fieldName + "]", e)__        }_        return tokens__    };given,a,field,value,convert,it,to,a,list,of,tokens,using,the,configured,analyzer;public,list,string,tokenize,field,string,field,name,string,field,value,list,string,tokens,new,array,list,try,token,stream,stream,analyzer,token,stream,field,name,field,value,stream,reset,char,term,attribute,term,stream,add,attribute,char,term,attribute,class,while,stream,increment,token,string,token,term,to,string,if,token,is,empty,false,tokens,add,term,to,string,stream,end,catch,ioexception,e,throw,new,elasticsearch,exception,failed,to,analyze,value,field,value,of,field,field,name,e,return,tokens
CategorizationAnalyzer -> public List<String> tokenizeField(String fieldName, String fieldValue);1537371806;Given a field value, convert it to a list of tokens using the configured analyzer.;public List<String> tokenizeField(String fieldName, String fieldValue) {_        List<String> tokens = new ArrayList<>()__        try (TokenStream stream = analyzer.tokenStream(fieldName, fieldValue)) {_            stream.reset()__            CharTermAttribute term = stream.addAttribute(CharTermAttribute.class)__            while (stream.incrementToken()) {_                String token = term.toString()__                _                if (token.isEmpty() == false) {_                    tokens.add(term.toString())__                }_            }_            stream.end()__        } catch (IOException e) {_            throw new ElasticsearchException("Failed to analyze value [" + fieldValue + "] of field [" + fieldName + "]", e)__        }_        return tokens__    };given,a,field,value,convert,it,to,a,list,of,tokens,using,the,configured,analyzer;public,list,string,tokenize,field,string,field,name,string,field,value,list,string,tokens,new,array,list,try,token,stream,stream,analyzer,token,stream,field,name,field,value,stream,reset,char,term,attribute,term,stream,add,attribute,char,term,attribute,class,while,stream,increment,token,string,token,term,to,string,if,token,is,empty,false,tokens,add,term,to,string,stream,end,catch,ioexception,e,throw,new,elasticsearch,exception,failed,to,analyze,value,field,value,of,field,field,name,e,return,tokens
CategorizationAnalyzer -> @Override     public void close();1524684173;Release resources held by the analyzer (unless it's global).;@Override_    public void close() {_        if (closeAnalyzer) {_            analyzer.close()__        }_    };release,resources,held,by,the,analyzer,unless,it,s,global;override,public,void,close,if,close,analyzer,analyzer,close
CategorizationAnalyzer -> @Override     public void close();1531910483;Release resources held by the analyzer (unless it's global).;@Override_    public void close() {_        if (closeAnalyzer) {_            analyzer.close()__        }_    };release,resources,held,by,the,analyzer,unless,it,s,global;override,public,void,close,if,close,analyzer,analyzer,close
CategorizationAnalyzer -> @Override     public void close();1537371806;Release resources held by the analyzer (unless it's global).;@Override_    public void close() {_        if (closeAnalyzer) {_            analyzer.close()__        }_    };release,resources,held,by,the,analyzer,unless,it,s,global;override,public,void,close,if,close,analyzer,analyzer,close
CategorizationAnalyzer -> private static List<CharFilterFactory> parseCharFilterFactories(CategorizationAnalyzerConfig config, AnalysisRegistry analysisRegistry,                                                                     Environment environment) throws IOException;1531910483;Get char filter factories for each configured char filter.  Each configuration_element can be the name of an out-of-the-box char filter, or a custom definition.;private static List<CharFilterFactory> parseCharFilterFactories(CategorizationAnalyzerConfig config, AnalysisRegistry analysisRegistry,_                                                                    Environment environment) throws IOException {_        List<CategorizationAnalyzerConfig.NameOrDefinition> charFilters = config.getCharFilters()__        final List<CharFilterFactory> charFilterFactoryList = new ArrayList<>()__        for (CategorizationAnalyzerConfig.NameOrDefinition charFilter : charFilters) {_            final CharFilterFactory charFilterFactory__            if (charFilter.name != null) {_                AnalysisModule.AnalysisProvider<CharFilterFactory> charFilterFactoryFactory =_                    analysisRegistry.getCharFilterProvider(charFilter.name)__                if (charFilterFactoryFactory == null) {_                    throw new IllegalArgumentException("Failed to find global char filter under [" + charFilter.name + "]")__                }_                charFilterFactory = charFilterFactoryFactory.get(environment, charFilter.name)__            } else {_                String charFilterTypeName = charFilter.definition.get("type")__                if (charFilterTypeName == null) {_                    throw new IllegalArgumentException("Missing [type] setting for char filter: " + charFilter.definition)__                }_                AnalysisModule.AnalysisProvider<CharFilterFactory> charFilterFactoryFactory =_                    analysisRegistry.getCharFilterProvider(charFilterTypeName)__                if (charFilterFactoryFactory == null) {_                    throw new IllegalArgumentException("Failed to find global char filter under [" + charFilterTypeName + "]")__                }_                Settings settings = augmentSettings(charFilter.definition)__                _                charFilterFactory = charFilterFactoryFactory.get(buildDummyIndexSettings(settings), environment, "_anonymous_charfilter",_                    settings)__            }_            if (charFilterFactory == null) {_                throw new IllegalArgumentException("Failed to find char filter [" + charFilter + "]")__            }_            charFilterFactoryList.add(charFilterFactory)__        }_        return charFilterFactoryList__    };get,char,filter,factories,for,each,configured,char,filter,each,configuration,element,can,be,the,name,of,an,out,of,the,box,char,filter,or,a,custom,definition;private,static,list,char,filter,factory,parse,char,filter,factories,categorization,analyzer,config,config,analysis,registry,analysis,registry,environment,environment,throws,ioexception,list,categorization,analyzer,config,name,or,definition,char,filters,config,get,char,filters,final,list,char,filter,factory,char,filter,factory,list,new,array,list,for,categorization,analyzer,config,name,or,definition,char,filter,char,filters,final,char,filter,factory,char,filter,factory,if,char,filter,name,null,analysis,module,analysis,provider,char,filter,factory,char,filter,factory,factory,analysis,registry,get,char,filter,provider,char,filter,name,if,char,filter,factory,factory,null,throw,new,illegal,argument,exception,failed,to,find,global,char,filter,under,char,filter,name,char,filter,factory,char,filter,factory,factory,get,environment,char,filter,name,else,string,char,filter,type,name,char,filter,definition,get,type,if,char,filter,type,name,null,throw,new,illegal,argument,exception,missing,type,setting,for,char,filter,char,filter,definition,analysis,module,analysis,provider,char,filter,factory,char,filter,factory,factory,analysis,registry,get,char,filter,provider,char,filter,type,name,if,char,filter,factory,factory,null,throw,new,illegal,argument,exception,failed,to,find,global,char,filter,under,char,filter,type,name,settings,settings,augment,settings,char,filter,definition,char,filter,factory,char,filter,factory,factory,get,build,dummy,index,settings,settings,environment,settings,if,char,filter,factory,null,throw,new,illegal,argument,exception,failed,to,find,char,filter,char,filter,char,filter,factory,list,add,char,filter,factory,return,char,filter,factory,list
CategorizationAnalyzer -> private static List<CharFilterFactory> parseCharFilterFactories(CategorizationAnalyzerConfig config, AnalysisRegistry analysisRegistry,                                                                     Environment environment) throws IOException;1537371806;Get char filter factories for each configured char filter.  Each configuration_element can be the name of an out-of-the-box char filter, or a custom definition.;private static List<CharFilterFactory> parseCharFilterFactories(CategorizationAnalyzerConfig config, AnalysisRegistry analysisRegistry,_                                                                    Environment environment) throws IOException {_        List<CategorizationAnalyzerConfig.NameOrDefinition> charFilters = config.getCharFilters()__        final List<CharFilterFactory> charFilterFactoryList = new ArrayList<>()__        for (CategorizationAnalyzerConfig.NameOrDefinition charFilter : charFilters) {_            final CharFilterFactory charFilterFactory__            if (charFilter.name != null) {_                AnalysisModule.AnalysisProvider<CharFilterFactory> charFilterFactoryFactory =_                    analysisRegistry.getCharFilterProvider(charFilter.name)__                if (charFilterFactoryFactory == null) {_                    throw new IllegalArgumentException("Failed to find global char filter under [" + charFilter.name + "]")__                }_                charFilterFactory = charFilterFactoryFactory.get(environment, charFilter.name)__            } else {_                String charFilterTypeName = charFilter.definition.get("type")__                if (charFilterTypeName == null) {_                    throw new IllegalArgumentException("Missing [type] setting for char filter: " + charFilter.definition)__                }_                AnalysisModule.AnalysisProvider<CharFilterFactory> charFilterFactoryFactory =_                    analysisRegistry.getCharFilterProvider(charFilterTypeName)__                if (charFilterFactoryFactory == null) {_                    throw new IllegalArgumentException("Failed to find global char filter under [" + charFilterTypeName + "]")__                }_                Settings settings = augmentSettings(charFilter.definition)__                _                charFilterFactory = charFilterFactoryFactory.get(buildDummyIndexSettings(settings), environment, "_anonymous_charfilter",_                    settings)__            }_            if (charFilterFactory == null) {_                throw new IllegalArgumentException("Failed to find char filter [" + charFilter + "]")__            }_            charFilterFactoryList.add(charFilterFactory)__        }_        return charFilterFactoryList__    };get,char,filter,factories,for,each,configured,char,filter,each,configuration,element,can,be,the,name,of,an,out,of,the,box,char,filter,or,a,custom,definition;private,static,list,char,filter,factory,parse,char,filter,factories,categorization,analyzer,config,config,analysis,registry,analysis,registry,environment,environment,throws,ioexception,list,categorization,analyzer,config,name,or,definition,char,filters,config,get,char,filters,final,list,char,filter,factory,char,filter,factory,list,new,array,list,for,categorization,analyzer,config,name,or,definition,char,filter,char,filters,final,char,filter,factory,char,filter,factory,if,char,filter,name,null,analysis,module,analysis,provider,char,filter,factory,char,filter,factory,factory,analysis,registry,get,char,filter,provider,char,filter,name,if,char,filter,factory,factory,null,throw,new,illegal,argument,exception,failed,to,find,global,char,filter,under,char,filter,name,char,filter,factory,char,filter,factory,factory,get,environment,char,filter,name,else,string,char,filter,type,name,char,filter,definition,get,type,if,char,filter,type,name,null,throw,new,illegal,argument,exception,missing,type,setting,for,char,filter,char,filter,definition,analysis,module,analysis,provider,char,filter,factory,char,filter,factory,factory,analysis,registry,get,char,filter,provider,char,filter,type,name,if,char,filter,factory,factory,null,throw,new,illegal,argument,exception,failed,to,find,global,char,filter,under,char,filter,type,name,settings,settings,augment,settings,char,filter,definition,char,filter,factory,char,filter,factory,factory,get,build,dummy,index,settings,settings,environment,settings,if,char,filter,factory,null,throw,new,illegal,argument,exception,failed,to,find,char,filter,char,filter,char,filter,factory,list,add,char,filter,factory,return,char,filter,factory,list
CategorizationAnalyzer -> private static Tuple<String, TokenizerFactory> parseTokenizerFactory(CategorizationAnalyzerConfig config,                                                                          AnalysisRegistry analysisRegistry, Environment environment)         throws IOException;1531910483;Get the tokenizer factory for the configured tokenizer.  The configuration_can be the name of an out-of-the-box tokenizer, or a custom definition.;private static Tuple<String, TokenizerFactory> parseTokenizerFactory(CategorizationAnalyzerConfig config,_                                                                         AnalysisRegistry analysisRegistry, Environment environment)_        throws IOException {_        CategorizationAnalyzerConfig.NameOrDefinition tokenizer = config.getTokenizer()__        final String name__        final TokenizerFactory tokenizerFactory__        if (tokenizer.name != null) {_            name = tokenizer.name__            AnalysisModule.AnalysisProvider<TokenizerFactory> tokenizerFactoryFactory = analysisRegistry.getTokenizerProvider(name)__            if (tokenizerFactoryFactory == null) {_                throw new IllegalArgumentException("Failed to find global tokenizer under [" + name + "]")__            }_            tokenizerFactory = tokenizerFactoryFactory.get(environment, name)__        } else {_            String tokenizerTypeName = tokenizer.definition.get("type")__            if (tokenizerTypeName == null) {_                throw new IllegalArgumentException("Missing [type] setting for tokenizer: " + tokenizer.definition)__            }_            AnalysisModule.AnalysisProvider<TokenizerFactory> tokenizerFactoryFactory =_                analysisRegistry.getTokenizerProvider(tokenizerTypeName)__            if (tokenizerFactoryFactory == null) {_                throw new IllegalArgumentException("Failed to find global tokenizer under [" + tokenizerTypeName + "]")__            }_            Settings settings = augmentSettings(tokenizer.definition)__            _            name = "_anonymous_tokenizer"__            tokenizerFactory = tokenizerFactoryFactory.get(buildDummyIndexSettings(settings), environment, name, settings)__        }_        return new Tuple<>(name, tokenizerFactory)__    };get,the,tokenizer,factory,for,the,configured,tokenizer,the,configuration,can,be,the,name,of,an,out,of,the,box,tokenizer,or,a,custom,definition;private,static,tuple,string,tokenizer,factory,parse,tokenizer,factory,categorization,analyzer,config,config,analysis,registry,analysis,registry,environment,environment,throws,ioexception,categorization,analyzer,config,name,or,definition,tokenizer,config,get,tokenizer,final,string,name,final,tokenizer,factory,tokenizer,factory,if,tokenizer,name,null,name,tokenizer,name,analysis,module,analysis,provider,tokenizer,factory,tokenizer,factory,factory,analysis,registry,get,tokenizer,provider,name,if,tokenizer,factory,factory,null,throw,new,illegal,argument,exception,failed,to,find,global,tokenizer,under,name,tokenizer,factory,tokenizer,factory,factory,get,environment,name,else,string,tokenizer,type,name,tokenizer,definition,get,type,if,tokenizer,type,name,null,throw,new,illegal,argument,exception,missing,type,setting,for,tokenizer,tokenizer,definition,analysis,module,analysis,provider,tokenizer,factory,tokenizer,factory,factory,analysis,registry,get,tokenizer,provider,tokenizer,type,name,if,tokenizer,factory,factory,null,throw,new,illegal,argument,exception,failed,to,find,global,tokenizer,under,tokenizer,type,name,settings,settings,augment,settings,tokenizer,definition,name,tokenizer,factory,tokenizer,factory,factory,get,build,dummy,index,settings,settings,environment,name,settings,return,new,tuple,name,tokenizer,factory
CategorizationAnalyzer -> private static Tuple<String, TokenizerFactory> parseTokenizerFactory(CategorizationAnalyzerConfig config,                                                                          AnalysisRegistry analysisRegistry, Environment environment)         throws IOException;1537371806;Get the tokenizer factory for the configured tokenizer.  The configuration_can be the name of an out-of-the-box tokenizer, or a custom definition.;private static Tuple<String, TokenizerFactory> parseTokenizerFactory(CategorizationAnalyzerConfig config,_                                                                         AnalysisRegistry analysisRegistry, Environment environment)_        throws IOException {_        CategorizationAnalyzerConfig.NameOrDefinition tokenizer = config.getTokenizer()__        final String name__        final TokenizerFactory tokenizerFactory__        if (tokenizer.name != null) {_            name = tokenizer.name__            AnalysisModule.AnalysisProvider<TokenizerFactory> tokenizerFactoryFactory = analysisRegistry.getTokenizerProvider(name)__            if (tokenizerFactoryFactory == null) {_                throw new IllegalArgumentException("Failed to find global tokenizer under [" + name + "]")__            }_            tokenizerFactory = tokenizerFactoryFactory.get(environment, name)__        } else {_            String tokenizerTypeName = tokenizer.definition.get("type")__            if (tokenizerTypeName == null) {_                throw new IllegalArgumentException("Missing [type] setting for tokenizer: " + tokenizer.definition)__            }_            AnalysisModule.AnalysisProvider<TokenizerFactory> tokenizerFactoryFactory =_                analysisRegistry.getTokenizerProvider(tokenizerTypeName)__            if (tokenizerFactoryFactory == null) {_                throw new IllegalArgumentException("Failed to find global tokenizer under [" + tokenizerTypeName + "]")__            }_            Settings settings = augmentSettings(tokenizer.definition)__            _            name = "_anonymous_tokenizer"__            tokenizerFactory = tokenizerFactoryFactory.get(buildDummyIndexSettings(settings), environment, name, settings)__        }_        return new Tuple<>(name, tokenizerFactory)__    };get,the,tokenizer,factory,for,the,configured,tokenizer,the,configuration,can,be,the,name,of,an,out,of,the,box,tokenizer,or,a,custom,definition;private,static,tuple,string,tokenizer,factory,parse,tokenizer,factory,categorization,analyzer,config,config,analysis,registry,analysis,registry,environment,environment,throws,ioexception,categorization,analyzer,config,name,or,definition,tokenizer,config,get,tokenizer,final,string,name,final,tokenizer,factory,tokenizer,factory,if,tokenizer,name,null,name,tokenizer,name,analysis,module,analysis,provider,tokenizer,factory,tokenizer,factory,factory,analysis,registry,get,tokenizer,provider,name,if,tokenizer,factory,factory,null,throw,new,illegal,argument,exception,failed,to,find,global,tokenizer,under,name,tokenizer,factory,tokenizer,factory,factory,get,environment,name,else,string,tokenizer,type,name,tokenizer,definition,get,type,if,tokenizer,type,name,null,throw,new,illegal,argument,exception,missing,type,setting,for,tokenizer,tokenizer,definition,analysis,module,analysis,provider,tokenizer,factory,tokenizer,factory,factory,analysis,registry,get,tokenizer,provider,tokenizer,type,name,if,tokenizer,factory,factory,null,throw,new,illegal,argument,exception,failed,to,find,global,tokenizer,under,tokenizer,type,name,settings,settings,augment,settings,tokenizer,definition,name,tokenizer,factory,tokenizer,factory,factory,get,build,dummy,index,settings,settings,environment,name,settings,return,new,tuple,name,tokenizer,factory
CategorizationAnalyzer -> private static IndexSettings buildDummyIndexSettings(Settings settings);1531910483;The Elasticsearch analysis functionality is designed to work with indices.  For_categorization we have to pretend we've got some index settings.;private static IndexSettings buildDummyIndexSettings(Settings settings) {_        IndexMetaData metaData = IndexMetaData.builder(IndexMetaData.INDEX_UUID_NA_VALUE).settings(settings).build()__        return new IndexSettings(metaData, Settings.EMPTY)__    };the,elasticsearch,analysis,functionality,is,designed,to,work,with,indices,for,categorization,we,have,to,pretend,we,ve,got,some,index,settings;private,static,index,settings,build,dummy,index,settings,settings,settings,index,meta,data,meta,data,index,meta,data,builder,index,meta,data,settings,settings,build,return,new,index,settings,meta,data,settings,empty
CategorizationAnalyzer -> private static IndexSettings buildDummyIndexSettings(Settings settings);1537371806;The Elasticsearch analysis functionality is designed to work with indices.  For_categorization we have to pretend we've got some index settings.;private static IndexSettings buildDummyIndexSettings(Settings settings) {_        IndexMetaData metaData = IndexMetaData.builder(IndexMetaData.INDEX_UUID_NA_VALUE).settings(settings).build()__        return new IndexSettings(metaData, Settings.EMPTY)__    };the,elasticsearch,analysis,functionality,is,designed,to,work,with,indices,for,categorization,we,have,to,pretend,we,ve,got,some,index,settings;private,static,index,settings,build,dummy,index,settings,settings,settings,index,meta,data,meta,data,index,meta,data,builder,index,meta,data,settings,settings,build,return,new,index,settings,meta,data,settings,empty
CategorizationAnalyzer -> public static void verifyConfigBuilder(CategorizationAnalyzerConfig.Builder configBuilder, AnalysisRegistry analysisRegistry,                                            Environment environment) throws IOException;1531910483;Verify that the config builder will build a valid config.  This is not done as part of the basic build_because it verifies that the names of analyzers/tokenizers/filters referenced by the config are_known, and the validity of these names could change over time.  Additionally, it has to be done_server-side rather than client-side, as the client will not have loaded the appropriate analysis_modules/plugins.;public static void verifyConfigBuilder(CategorizationAnalyzerConfig.Builder configBuilder, AnalysisRegistry analysisRegistry,_                                           Environment environment) throws IOException {_        Tuple<Analyzer, Boolean> tuple = makeAnalyzer(configBuilder.build(), analysisRegistry, environment)__        if (tuple.v2()) {_            tuple.v1().close()__        }_    };verify,that,the,config,builder,will,build,a,valid,config,this,is,not,done,as,part,of,the,basic,build,because,it,verifies,that,the,names,of,analyzers,tokenizers,filters,referenced,by,the,config,are,known,and,the,validity,of,these,names,could,change,over,time,additionally,it,has,to,be,done,server,side,rather,than,client,side,as,the,client,will,not,have,loaded,the,appropriate,analysis,modules,plugins;public,static,void,verify,config,builder,categorization,analyzer,config,builder,config,builder,analysis,registry,analysis,registry,environment,environment,throws,ioexception,tuple,analyzer,boolean,tuple,make,analyzer,config,builder,build,analysis,registry,environment,if,tuple,v2,tuple,v1,close
CategorizationAnalyzer -> public static void verifyConfigBuilder(CategorizationAnalyzerConfig.Builder configBuilder, AnalysisRegistry analysisRegistry,                                            Environment environment) throws IOException;1537371806;Verify that the config builder will build a valid config.  This is not done as part of the basic build_because it verifies that the names of analyzers/tokenizers/filters referenced by the config are_known, and the validity of these names could change over time.  Additionally, it has to be done_server-side rather than client-side, as the client will not have loaded the appropriate analysis_modules/plugins.;public static void verifyConfigBuilder(CategorizationAnalyzerConfig.Builder configBuilder, AnalysisRegistry analysisRegistry,_                                           Environment environment) throws IOException {_        Tuple<Analyzer, Boolean> tuple = makeAnalyzer(configBuilder.build(), analysisRegistry, environment)__        if (tuple.v2()) {_            tuple.v1().close()__        }_    };verify,that,the,config,builder,will,build,a,valid,config,this,is,not,done,as,part,of,the,basic,build,because,it,verifies,that,the,names,of,analyzers,tokenizers,filters,referenced,by,the,config,are,known,and,the,validity,of,these,names,could,change,over,time,additionally,it,has,to,be,done,server,side,rather,than,client,side,as,the,client,will,not,have,loaded,the,appropriate,analysis,modules,plugins;public,static,void,verify,config,builder,categorization,analyzer,config,builder,config,builder,analysis,registry,analysis,registry,environment,environment,throws,ioexception,tuple,analyzer,boolean,tuple,make,analyzer,config,builder,build,analysis,registry,environment,if,tuple,v2,tuple,v1,close
CategorizationAnalyzer -> private static Tuple<Analyzer, Boolean> makeAnalyzer(CategorizationAnalyzerConfig config, AnalysisRegistry analysisRegistry,                                                          Environment environment) throws IOException;1531910483;Convert a config to an {@link Analyzer}.  This may be a global analyzer or a newly created custom analyzer._In the case of a global analyzer the caller must NOT close it when they have finished with it.  In the case of_a newly created custom analyzer the caller is responsible for closing it._@return The first tuple member is the {@link Analyzer}_ the second indicates whether the caller is responsible_for closing it.;private static Tuple<Analyzer, Boolean> makeAnalyzer(CategorizationAnalyzerConfig config, AnalysisRegistry analysisRegistry,_                                                         Environment environment) throws IOException {_        String analyzer = config.getAnalyzer()__        if (analyzer != null) {_            Analyzer globalAnalyzer = analysisRegistry.getAnalyzer(analyzer)__            if (globalAnalyzer == null) {_                throw new IllegalArgumentException("Failed to find global analyzer [" + analyzer + "]")__            }_            return new Tuple<>(globalAnalyzer, Boolean.FALSE)__        } else {_            List<CharFilterFactory> charFilterFactoryList = parseCharFilterFactories(config, analysisRegistry, environment)___            Tuple<String, TokenizerFactory> tokenizerFactory = parseTokenizerFactory(config, analysisRegistry, environment)___            List<TokenFilterFactory> tokenFilterFactoryList = parseTokenFilterFactories(config, analysisRegistry, environment,_                tokenizerFactory, charFilterFactoryList)___            return new Tuple<>(new CustomAnalyzer(tokenizerFactory.v1(), tokenizerFactory.v2(),_                charFilterFactoryList.toArray(new CharFilterFactory[charFilterFactoryList.size()]),_                tokenFilterFactoryList.toArray(new TokenFilterFactory[tokenFilterFactoryList.size()])), Boolean.TRUE)__        }_    };convert,a,config,to,an,link,analyzer,this,may,be,a,global,analyzer,or,a,newly,created,custom,analyzer,in,the,case,of,a,global,analyzer,the,caller,must,not,close,it,when,they,have,finished,with,it,in,the,case,of,a,newly,created,custom,analyzer,the,caller,is,responsible,for,closing,it,return,the,first,tuple,member,is,the,link,analyzer,the,second,indicates,whether,the,caller,is,responsible,for,closing,it;private,static,tuple,analyzer,boolean,make,analyzer,categorization,analyzer,config,config,analysis,registry,analysis,registry,environment,environment,throws,ioexception,string,analyzer,config,get,analyzer,if,analyzer,null,analyzer,global,analyzer,analysis,registry,get,analyzer,analyzer,if,global,analyzer,null,throw,new,illegal,argument,exception,failed,to,find,global,analyzer,analyzer,return,new,tuple,global,analyzer,boolean,false,else,list,char,filter,factory,char,filter,factory,list,parse,char,filter,factories,config,analysis,registry,environment,tuple,string,tokenizer,factory,tokenizer,factory,parse,tokenizer,factory,config,analysis,registry,environment,list,token,filter,factory,token,filter,factory,list,parse,token,filter,factories,config,analysis,registry,environment,tokenizer,factory,char,filter,factory,list,return,new,tuple,new,custom,analyzer,tokenizer,factory,v1,tokenizer,factory,v2,char,filter,factory,list,to,array,new,char,filter,factory,char,filter,factory,list,size,token,filter,factory,list,to,array,new,token,filter,factory,token,filter,factory,list,size,boolean,true
CategorizationAnalyzer -> private static Tuple<Analyzer, Boolean> makeAnalyzer(CategorizationAnalyzerConfig config, AnalysisRegistry analysisRegistry,                                                          Environment environment) throws IOException;1537371806;Convert a config to an {@link Analyzer}.  This may be a global analyzer or a newly created custom analyzer._In the case of a global analyzer the caller must NOT close it when they have finished with it.  In the case of_a newly created custom analyzer the caller is responsible for closing it._@return The first tuple member is the {@link Analyzer}_ the second indicates whether the caller is responsible_for closing it.;private static Tuple<Analyzer, Boolean> makeAnalyzer(CategorizationAnalyzerConfig config, AnalysisRegistry analysisRegistry,_                                                         Environment environment) throws IOException {_        String analyzer = config.getAnalyzer()__        if (analyzer != null) {_            Analyzer globalAnalyzer = analysisRegistry.getAnalyzer(analyzer)__            if (globalAnalyzer == null) {_                throw new IllegalArgumentException("Failed to find global analyzer [" + analyzer + "]")__            }_            return new Tuple<>(globalAnalyzer, Boolean.FALSE)__        } else {_            List<CharFilterFactory> charFilterFactoryList = parseCharFilterFactories(config, analysisRegistry, environment)___            Tuple<String, TokenizerFactory> tokenizerFactory = parseTokenizerFactory(config, analysisRegistry, environment)___            List<TokenFilterFactory> tokenFilterFactoryList = parseTokenFilterFactories(config, analysisRegistry, environment,_                tokenizerFactory, charFilterFactoryList)___            return new Tuple<>(new CustomAnalyzer(tokenizerFactory.v1(), tokenizerFactory.v2(),_                charFilterFactoryList.toArray(new CharFilterFactory[charFilterFactoryList.size()]),_                tokenFilterFactoryList.toArray(new TokenFilterFactory[tokenFilterFactoryList.size()])), Boolean.TRUE)__        }_    };convert,a,config,to,an,link,analyzer,this,may,be,a,global,analyzer,or,a,newly,created,custom,analyzer,in,the,case,of,a,global,analyzer,the,caller,must,not,close,it,when,they,have,finished,with,it,in,the,case,of,a,newly,created,custom,analyzer,the,caller,is,responsible,for,closing,it,return,the,first,tuple,member,is,the,link,analyzer,the,second,indicates,whether,the,caller,is,responsible,for,closing,it;private,static,tuple,analyzer,boolean,make,analyzer,categorization,analyzer,config,config,analysis,registry,analysis,registry,environment,environment,throws,ioexception,string,analyzer,config,get,analyzer,if,analyzer,null,analyzer,global,analyzer,analysis,registry,get,analyzer,analyzer,if,global,analyzer,null,throw,new,illegal,argument,exception,failed,to,find,global,analyzer,analyzer,return,new,tuple,global,analyzer,boolean,false,else,list,char,filter,factory,char,filter,factory,list,parse,char,filter,factories,config,analysis,registry,environment,tuple,string,tokenizer,factory,tokenizer,factory,parse,tokenizer,factory,config,analysis,registry,environment,list,token,filter,factory,token,filter,factory,list,parse,token,filter,factories,config,analysis,registry,environment,tokenizer,factory,char,filter,factory,list,return,new,tuple,new,custom,analyzer,tokenizer,factory,v1,tokenizer,factory,v2,char,filter,factory,list,to,array,new,char,filter,factory,char,filter,factory,list,size,token,filter,factory,list,to,array,new,token,filter,factory,token,filter,factory,list,size,boolean,true
