commented;modifiers;parameterAmount;loc;comment;code
true;public;1;18;/**  * This method looks at the {@link DatafeedDelayedDataDetector#datafeedIndices}  * from {@code latestFinalizedBucket - window} to {@code latestFinalizedBucket} and compares the document counts with the  * {@link DatafeedDelayedDataDetector#jobId}'s finalized buckets' event counts.  *  * It is done synchronously, and can block for a considerable amount of time, it should only be executed within the appropriate  * thread pool.  *  * @param latestFinalizedBucketMs The latest finalized bucket timestamp in milliseconds, signifies the end of the time window check  * @return A List of {@link BucketWithMissingData} objects that contain each bucket with the current number of missing docs  */ ;/**  * This method looks at the {@link DatafeedDelayedDataDetector#datafeedIndices}  * from {@code latestFinalizedBucket - window} to {@code latestFinalizedBucket} and compares the document counts with the  * {@link DatafeedDelayedDataDetector#jobId}'s finalized buckets' event counts.  *  * It is done synchronously, and can block for a considerable amount of time, it should only be executed within the appropriate  * thread pool.  *  * @param latestFinalizedBucketMs The latest finalized bucket timestamp in milliseconds, signifies the end of the time window check  * @return A List of {@link BucketWithMissingData} objects that contain each bucket with the current number of missing docs  */ @Override public List<BucketWithMissingData> detectMissingData(long latestFinalizedBucketMs) {     final long end = Intervals.alignToFloor(latestFinalizedBucketMs, bucketSpan).     final long start = Intervals.alignToFloor(latestFinalizedBucketMs - window, bucketSpan).     if (end <= start) {         return Collections.emptyList().     }     List<Bucket> finalizedBuckets = checkBucketEvents(start, end).     Map<Long, Long> indexedData = checkCurrentBucketEventCount(start, end).     return finalizedBuckets.stream().filter(bucket -> calculateMissing(indexedData, bucket) > 0).map(bucket -> BucketWithMissingData.fromMissingAndBucket(calculateMissing(indexedData, bucket), bucket)).collect(Collectors.toList()). }
false;public;0;4;;@Override public long getWindow() {     return window. }
false;private;2;14;;private List<Bucket> checkBucketEvents(long start, long end) {     GetBucketsAction.Request request = new GetBucketsAction.Request(jobId).     request.setStart(Long.toString(start)).     request.setEnd(Long.toString(end)).     request.setSort("timestamp").     request.setDescending(false).     request.setExcludeInterim(true).     request.setPageParams(new PageParams(0, (int) ((end - start) / bucketSpan))).     try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN)) {         GetBucketsAction.Response response = client.execute(GetBucketsAction.INSTANCE, request).actionGet().         return response.getBuckets().results().     } }
false;private;2;21;;private Map<Long, Long> checkCurrentBucketEventCount(long start, long end) {     SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder().size(0).aggregation(new DateHistogramAggregationBuilder(DATE_BUCKETS).interval(bucketSpan).field(timeField)).query(ExtractorUtils.wrapInTimeRangeQuery(datafeedQuery, timeField, start, end)).     SearchRequest searchRequest = new SearchRequest(datafeedIndices).source(searchSourceBuilder).     try (ThreadContext.StoredContext ignore = stashWithOrigin(client.threadPool().getThreadContext(), ML_ORIGIN)) {         SearchResponse response = client.execute(SearchAction.INSTANCE, searchRequest).actionGet().         List<? extends Histogram.Bucket> buckets = ((Histogram) response.getAggregations().get(DATE_BUCKETS)).getBuckets().         Map<Long, Long> hashMap = new HashMap<>(buckets.size()).         for (Histogram.Bucket bucket : buckets) {             long bucketTime = toHistogramKeyToEpoch(bucket.getKey()).             if (bucketTime < 0) {                 throw new IllegalStateException("Histogram key [" + bucket.getKey() + "] cannot be converted to a timestamp").             }             hashMap.put(bucketTime, bucket.getDocCount()).         }         return hashMap.     } }
false;private,static;1;11;;private static long toHistogramKeyToEpoch(Object key) {     if (key instanceof ZonedDateTime) {         return ((ZonedDateTime) key).toInstant().toEpochMilli().     } else if (key instanceof Double) {         return ((Double) key).longValue().     } else if (key instanceof Long) {         return (Long) key.     } else {         return -1L.     } }
false;private,static;2;3;;private static long calculateMissing(Map<Long, Long> indexedData, Bucket bucket) {     return indexedData.getOrDefault(bucket.getEpoch() * 1000, 0L) - bucket.getEventCount(). }
