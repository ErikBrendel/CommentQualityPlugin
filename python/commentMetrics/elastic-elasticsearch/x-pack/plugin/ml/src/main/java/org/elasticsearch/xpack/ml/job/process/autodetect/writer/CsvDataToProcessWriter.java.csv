commented;modifiers;parameterAmount;loc;comment;code
true;public;4;67;/**  * Read the csv inputIndex, transform to length encoded values and pipe to  * the OutputStream. If any of the expected fields in the  * analysis inputIndex or if the expected time field is missing from the CSV  * header a exception is thrown  */ ;/**  * Read the csv inputIndex, transform to length encoded values and pipe to  * the OutputStream. If any of the expected fields in the  * analysis inputIndex or if the expected time field is missing from the CSV  * header a exception is thrown  */ @Override public void write(InputStream inputStream, CategorizationAnalyzer categorizationAnalyzer, XContentType xContentType, BiConsumer<DataCounts, Exception> handler) throws IOException {     CsvPreference csvPref = new CsvPreference.Builder(dataDescription.getQuoteCharacter(), dataDescription.getFieldDelimiter(), new String(new char[] { DataDescription.LINE_ENDING })).maxLinesPerRow(MAX_LINES_PER_RECORD).build().     dataCountsReporter.startNewIncrementalCount().     try (CsvListReader csvReader = new CsvListReader(new InputStreamReader(inputStream, StandardCharsets.UTF_8), csvPref)) {         String[] header = csvReader.getHeader(true).         if (header == null) {             // null if EoF             handler.accept(dataCountsReporter.incrementalStats(), null).             return.         }         // time field doesn't count         long inputFieldCount = Math.max(header.length - 1, 0).         buildFieldIndexMapping(header).         int maxIndex = 0.         for (Integer index : inFieldIndexes.values()) {             maxIndex = Math.max(index, maxIndex).         }         Integer categorizationFieldIndex = inFieldIndexes.get(analysisConfig.getCategorizationFieldName()).         int numFields = outputFieldCount().         String[] record = new String[numFields].         List<String> line.         while ((line = csvReader.read()) != null) {             Arrays.fill(record, "").             if (maxIndex >= line.size()) {                 LOGGER.warn("Not enough fields in csv record, expected at least " + maxIndex + ". " + line).                 for (InputOutputMap inOut : inputOutputMap) {                     if (inOut.inputIndex >= line.size()) {                         dataCountsReporter.reportMissingField().                         continue.                     }                     String field = line.get(inOut.inputIndex).                     record[inOut.outputIndex] = (field == null) ? "" : field.                 }             } else {                 for (InputOutputMap inOut : inputOutputMap) {                     String field = line.get(inOut.inputIndex).                     record[inOut.outputIndex] = (field == null) ? "" : field.                 }             }             if (categorizationAnalyzer != null && categorizationFieldIndex != null && categorizationFieldIndex < line.size()) {                 tokenizeForCategorization(categorizationAnalyzer, line.get(categorizationFieldIndex), record).             }             transformTimeAndWrite(record, inputFieldCount).         }         // This function can throw         dataCountsReporter.finishReporting(ActionListener.wrap(response -> handler.accept(dataCountsReporter.incrementalStats(), null), e -> handler.accept(null, e))).     } }
false;protected;3;18;;@Override protected boolean checkForMissingFields(Collection<String> inputFields, Map<String, Integer> inputFieldIndexes, String[] header) {     for (String field : inputFields) {         if (AnalysisConfig.AUTO_CREATED_FIELDS.contains(field)) {             continue.         }         Integer index = inputFieldIndexes.get(field).         if (index == null) {             String msg = String.format(Locale.ROOT, "Field configured for analysis '%s' is not in the CSV header '%s'", field, Arrays.toString(header)).             LOGGER.error(msg).             throw new IllegalArgumentException(msg).         }     }     return true. }
