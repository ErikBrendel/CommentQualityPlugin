# id;timestamp;commentText;codeText;commentWords;codeWords
RollupJobIdentifierUtils -> public static Set<RollupJobCaps> findBestJobs(AggregationBuilder source, Set<RollupJobCaps> jobCaps);1524684173;Given the aggregation tree and a list of available job capabilities, this method will return a set_of the "best" jobs that should be searched.__It does this by recursively descending through the aggregation tree and independently pruning the_list of valid job caps in each branch.  When a leaf node is reached in the branch, the remaining_jobs are sorted by "best'ness" (see {@link #getComparator()} for the implementation)_and added to a global set of "best jobs".__Once all branches have been evaluated, the final set is returned to the calling code.__Job "best'ness" is, briefly, the job(s) that have_- The larger compatible date interval_- Fewer and larger interval histograms_- Fewer terms groups__Note: the final set of "best" jobs is not guaranteed to be minimal, there may be redundant effort_due to independent branches choosing jobs that are subsets of other branches.__@param source The source aggregation that we are trying to find jobs for_@param jobCaps The total set of available job caps on the index/indices_@return A set of the "best" jobs out of the total job caps;public static Set<RollupJobCaps> findBestJobs(AggregationBuilder source, Set<RollupJobCaps> jobCaps) {_        _        _        _        _        _        Set<RollupJobCaps> bestCaps = new HashSet<>()__        doFindBestJobs(source, new ArrayList<>(jobCaps), bestCaps)__        return bestCaps__    };given,the,aggregation,tree,and,a,list,of,available,job,capabilities,this,method,will,return,a,set,of,the,best,jobs,that,should,be,searched,it,does,this,by,recursively,descending,through,the,aggregation,tree,and,independently,pruning,the,list,of,valid,job,caps,in,each,branch,when,a,leaf,node,is,reached,in,the,branch,the,remaining,jobs,are,sorted,by,best,ness,see,link,get,comparator,for,the,implementation,and,added,to,a,global,set,of,best,jobs,once,all,branches,have,been,evaluated,the,final,set,is,returned,to,the,calling,code,job,best,ness,is,briefly,the,job,s,that,have,the,larger,compatible,date,interval,fewer,and,larger,interval,histograms,fewer,terms,groups,note,the,final,set,of,best,jobs,is,not,guaranteed,to,be,minimal,there,may,be,redundant,effort,due,to,independent,branches,choosing,jobs,that,are,subsets,of,other,branches,param,source,the,source,aggregation,that,we,are,trying,to,find,jobs,for,param,job,caps,the,total,set,of,available,job,caps,on,the,index,indices,return,a,set,of,the,best,jobs,out,of,the,total,job,caps;public,static,set,rollup,job,caps,find,best,jobs,aggregation,builder,source,set,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,new,hash,set,do,find,best,jobs,source,new,array,list,job,caps,best,caps,return,best,caps
RollupJobIdentifierUtils -> public static Set<RollupJobCaps> findBestJobs(AggregationBuilder source, Set<RollupJobCaps> jobCaps);1533319589;Given the aggregation tree and a list of available job capabilities, this method will return a set_of the "best" jobs that should be searched.__It does this by recursively descending through the aggregation tree and independently pruning the_list of valid job caps in each branch.  When a leaf node is reached in the branch, the remaining_jobs are sorted by "best'ness" (see {@link #getComparator()} for the implementation)_and added to a global set of "best jobs".__Once all branches have been evaluated, the final set is returned to the calling code.__Job "best'ness" is, briefly, the job(s) that have_- The larger compatible date interval_- Fewer and larger interval histograms_- Fewer terms groups__Note: the final set of "best" jobs is not guaranteed to be minimal, there may be redundant effort_due to independent branches choosing jobs that are subsets of other branches.__@param source The source aggregation that we are trying to find jobs for_@param jobCaps The total set of available job caps on the index/indices_@return A set of the "best" jobs out of the total job caps;public static Set<RollupJobCaps> findBestJobs(AggregationBuilder source, Set<RollupJobCaps> jobCaps) {_        _        _        _        _        _        Set<RollupJobCaps> bestCaps = new HashSet<>()__        doFindBestJobs(source, new ArrayList<>(jobCaps), bestCaps)__        return bestCaps__    };given,the,aggregation,tree,and,a,list,of,available,job,capabilities,this,method,will,return,a,set,of,the,best,jobs,that,should,be,searched,it,does,this,by,recursively,descending,through,the,aggregation,tree,and,independently,pruning,the,list,of,valid,job,caps,in,each,branch,when,a,leaf,node,is,reached,in,the,branch,the,remaining,jobs,are,sorted,by,best,ness,see,link,get,comparator,for,the,implementation,and,added,to,a,global,set,of,best,jobs,once,all,branches,have,been,evaluated,the,final,set,is,returned,to,the,calling,code,job,best,ness,is,briefly,the,job,s,that,have,the,larger,compatible,date,interval,fewer,and,larger,interval,histograms,fewer,terms,groups,note,the,final,set,of,best,jobs,is,not,guaranteed,to,be,minimal,there,may,be,redundant,effort,due,to,independent,branches,choosing,jobs,that,are,subsets,of,other,branches,param,source,the,source,aggregation,that,we,are,trying,to,find,jobs,for,param,job,caps,the,total,set,of,available,job,caps,on,the,index,indices,return,a,set,of,the,best,jobs,out,of,the,total,job,caps;public,static,set,rollup,job,caps,find,best,jobs,aggregation,builder,source,set,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,new,hash,set,do,find,best,jobs,source,new,array,list,job,caps,best,caps,return,best,caps
RollupJobIdentifierUtils -> public static Set<RollupJobCaps> findBestJobs(AggregationBuilder source, Set<RollupJobCaps> jobCaps);1535666657;Given the aggregation tree and a list of available job capabilities, this method will return a set_of the "best" jobs that should be searched.__It does this by recursively descending through the aggregation tree and independently pruning the_list of valid job caps in each branch.  When a leaf node is reached in the branch, the remaining_jobs are sorted by "best'ness" (see {@link #getComparator()} for the implementation)_and added to a global set of "best jobs".__Once all branches have been evaluated, the final set is returned to the calling code.__Job "best'ness" is, briefly, the job(s) that have_- The larger compatible date interval_- Fewer and larger interval histograms_- Fewer terms groups__Note: the final set of "best" jobs is not guaranteed to be minimal, there may be redundant effort_due to independent branches choosing jobs that are subsets of other branches.__@param source The source aggregation that we are trying to find jobs for_@param jobCaps The total set of available job caps on the index/indices_@return A set of the "best" jobs out of the total job caps;public static Set<RollupJobCaps> findBestJobs(AggregationBuilder source, Set<RollupJobCaps> jobCaps) {_        _        _        _        _        _        Set<RollupJobCaps> bestCaps = new HashSet<>()__        doFindBestJobs(source, new ArrayList<>(jobCaps), bestCaps)__        return bestCaps__    };given,the,aggregation,tree,and,a,list,of,available,job,capabilities,this,method,will,return,a,set,of,the,best,jobs,that,should,be,searched,it,does,this,by,recursively,descending,through,the,aggregation,tree,and,independently,pruning,the,list,of,valid,job,caps,in,each,branch,when,a,leaf,node,is,reached,in,the,branch,the,remaining,jobs,are,sorted,by,best,ness,see,link,get,comparator,for,the,implementation,and,added,to,a,global,set,of,best,jobs,once,all,branches,have,been,evaluated,the,final,set,is,returned,to,the,calling,code,job,best,ness,is,briefly,the,job,s,that,have,the,larger,compatible,date,interval,fewer,and,larger,interval,histograms,fewer,terms,groups,note,the,final,set,of,best,jobs,is,not,guaranteed,to,be,minimal,there,may,be,redundant,effort,due,to,independent,branches,choosing,jobs,that,are,subsets,of,other,branches,param,source,the,source,aggregation,that,we,are,trying,to,find,jobs,for,param,job,caps,the,total,set,of,available,job,caps,on,the,index,indices,return,a,set,of,the,best,jobs,out,of,the,total,job,caps;public,static,set,rollup,job,caps,find,best,jobs,aggregation,builder,source,set,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,new,hash,set,do,find,best,jobs,source,new,array,list,job,caps,best,caps,return,best,caps
RollupJobIdentifierUtils -> public static Set<RollupJobCaps> findBestJobs(AggregationBuilder source, Set<RollupJobCaps> jobCaps);1536053689;Given the aggregation tree and a list of available job capabilities, this method will return a set_of the "best" jobs that should be searched.__It does this by recursively descending through the aggregation tree and independently pruning the_list of valid job caps in each branch.  When a leaf node is reached in the branch, the remaining_jobs are sorted by "best'ness" (see {@link #getComparator()} for the implementation)_and added to a global set of "best jobs".__Once all branches have been evaluated, the final set is returned to the calling code.__Job "best'ness" is, briefly, the job(s) that have_- The larger compatible date interval_- Fewer and larger interval histograms_- Fewer terms groups__Note: the final set of "best" jobs is not guaranteed to be minimal, there may be redundant effort_due to independent branches choosing jobs that are subsets of other branches.__@param source The source aggregation that we are trying to find jobs for_@param jobCaps The total set of available job caps on the index/indices_@return A set of the "best" jobs out of the total job caps;public static Set<RollupJobCaps> findBestJobs(AggregationBuilder source, Set<RollupJobCaps> jobCaps) {_        _        _        _        _        _        Set<RollupJobCaps> bestCaps = new HashSet<>()__        doFindBestJobs(source, new ArrayList<>(jobCaps), bestCaps)__        return bestCaps__    };given,the,aggregation,tree,and,a,list,of,available,job,capabilities,this,method,will,return,a,set,of,the,best,jobs,that,should,be,searched,it,does,this,by,recursively,descending,through,the,aggregation,tree,and,independently,pruning,the,list,of,valid,job,caps,in,each,branch,when,a,leaf,node,is,reached,in,the,branch,the,remaining,jobs,are,sorted,by,best,ness,see,link,get,comparator,for,the,implementation,and,added,to,a,global,set,of,best,jobs,once,all,branches,have,been,evaluated,the,final,set,is,returned,to,the,calling,code,job,best,ness,is,briefly,the,job,s,that,have,the,larger,compatible,date,interval,fewer,and,larger,interval,histograms,fewer,terms,groups,note,the,final,set,of,best,jobs,is,not,guaranteed,to,be,minimal,there,may,be,redundant,effort,due,to,independent,branches,choosing,jobs,that,are,subsets,of,other,branches,param,source,the,source,aggregation,that,we,are,trying,to,find,jobs,for,param,job,caps,the,total,set,of,available,job,caps,on,the,index,indices,return,a,set,of,the,best,jobs,out,of,the,total,job,caps;public,static,set,rollup,job,caps,find,best,jobs,aggregation,builder,source,set,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,new,hash,set,do,find,best,jobs,source,new,array,list,job,caps,best,caps,return,best,caps
RollupJobIdentifierUtils -> public static Set<RollupJobCaps> findBestJobs(AggregationBuilder source, Set<RollupJobCaps> jobCaps);1548236405;Given the aggregation tree and a list of available job capabilities, this method will return a set_of the "best" jobs that should be searched.__It does this by recursively descending through the aggregation tree and independently pruning the_list of valid job caps in each branch.  When a leaf node is reached in the branch, the remaining_jobs are sorted by "best'ness" (see {@link #getComparator()} for the implementation)_and added to a global set of "best jobs".__Once all branches have been evaluated, the final set is returned to the calling code.__Job "best'ness" is, briefly, the job(s) that have_- The larger compatible date interval_- Fewer and larger interval histograms_- Fewer terms groups__Note: the final set of "best" jobs is not guaranteed to be minimal, there may be redundant effort_due to independent branches choosing jobs that are subsets of other branches.__@param source The source aggregation that we are trying to find jobs for_@param jobCaps The total set of available job caps on the index/indices_@return A set of the "best" jobs out of the total job caps;public static Set<RollupJobCaps> findBestJobs(AggregationBuilder source, Set<RollupJobCaps> jobCaps) {_        _        _        _        _        _        Set<RollupJobCaps> bestCaps = new HashSet<>()__        doFindBestJobs(source, new ArrayList<>(jobCaps), bestCaps)__        return bestCaps__    };given,the,aggregation,tree,and,a,list,of,available,job,capabilities,this,method,will,return,a,set,of,the,best,jobs,that,should,be,searched,it,does,this,by,recursively,descending,through,the,aggregation,tree,and,independently,pruning,the,list,of,valid,job,caps,in,each,branch,when,a,leaf,node,is,reached,in,the,branch,the,remaining,jobs,are,sorted,by,best,ness,see,link,get,comparator,for,the,implementation,and,added,to,a,global,set,of,best,jobs,once,all,branches,have,been,evaluated,the,final,set,is,returned,to,the,calling,code,job,best,ness,is,briefly,the,job,s,that,have,the,larger,compatible,date,interval,fewer,and,larger,interval,histograms,fewer,terms,groups,note,the,final,set,of,best,jobs,is,not,guaranteed,to,be,minimal,there,may,be,redundant,effort,due,to,independent,branches,choosing,jobs,that,are,subsets,of,other,branches,param,source,the,source,aggregation,that,we,are,trying,to,find,jobs,for,param,job,caps,the,total,set,of,available,job,caps,on,the,index,indices,return,a,set,of,the,best,jobs,out,of,the,total,job,caps;public,static,set,rollup,job,caps,find,best,jobs,aggregation,builder,source,set,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,new,hash,set,do,find,best,jobs,source,new,array,list,job,caps,best,caps,return,best,caps
RollupJobIdentifierUtils -> private static void checkHisto(HistogramAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps);1524684173;Find the set of histo's with the largest interval;private static void checkHisto(HistogramAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(HistogramAggregationBuilder.NAME)) {_                        Long interval = (long)agg.get(RollupField.INTERVAL)__                        _                        if (interval <= source.interval()) {_                            localCaps.add(cap)__                        }_                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +_                    source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };find,the,set,of,histo,s,with,the,largest,interval;private,static,void,check,histo,histogram,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,histogram,aggregation,builder,name,long,interval,long,agg,get,rollup,field,interval,if,interval,source,interval,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkHisto(HistogramAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps);1533319589;Find the set of histo's with the largest interval;private static void checkHisto(HistogramAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(HistogramAggregationBuilder.NAME)) {_                        Long interval = (long)agg.get(RollupField.INTERVAL)__                        _                        if (interval <= source.interval()) {_                            localCaps.add(cap)__                        }_                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +_                    source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };find,the,set,of,histo,s,with,the,largest,interval;private,static,void,check,histo,histogram,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,histogram,aggregation,builder,name,long,interval,long,agg,get,rollup,field,interval,if,interval,source,interval,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkHisto(HistogramAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps);1535666657;Find the set of histo's with the largest interval;private static void checkHisto(HistogramAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(HistogramAggregationBuilder.NAME)) {_                        Long interval = (long)agg.get(RollupField.INTERVAL)__                        _                        if (interval <= source.interval() && source.interval() % interval == 0) {_                            localCaps.add(cap)__                        }_                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName()_                + "] agg on field [" + source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };find,the,set,of,histo,s,with,the,largest,interval;private,static,void,check,histo,histogram,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,histogram,aggregation,builder,name,long,interval,long,agg,get,rollup,field,interval,if,interval,source,interval,source,interval,interval,0,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkHisto(HistogramAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps);1536053689;Find the set of histo's with the largest interval;private static void checkHisto(HistogramAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(HistogramAggregationBuilder.NAME)) {_                        Long interval = (long)agg.get(RollupField.INTERVAL)__                        _                        if (interval <= source.interval() && source.interval() % interval == 0) {_                            localCaps.add(cap)__                        }_                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName()_                + "] agg on field [" + source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };find,the,set,of,histo,s,with,the,largest,interval;private,static,void,check,histo,histogram,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,histogram,aggregation,builder,name,long,interval,long,agg,get,rollup,field,interval,if,interval,source,interval,source,interval,interval,0,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkHisto(HistogramAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps);1548236405;Find the set of histo's with the largest interval;private static void checkHisto(HistogramAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(HistogramAggregationBuilder.NAME)) {_                        Long interval = (long)agg.get(RollupField.INTERVAL)__                        _                        if (interval <= source.interval() && source.interval() % interval == 0) {_                            localCaps.add(cap)__                        }_                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName()_                + "] agg on field [" + source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };find,the,set,of,histo,s,with,the,largest,interval;private,static,void,check,histo,histogram,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,histogram,aggregation,builder,name,long,interval,long,agg,get,rollup,field,interval,if,interval,source,interval,source,interval,interval,0,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkTerms(TermsAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps);1524684173;Ensure that the terms aggregation is supported by one or more job caps.  There is no notion of "best"_caps for terms, it is either supported or not.;private static void checkTerms(TermsAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(TermsAggregationBuilder.NAME)) {_                        localCaps.add(cap)__                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +_                    source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };ensure,that,the,terms,aggregation,is,supported,by,one,or,more,job,caps,there,is,no,notion,of,best,caps,for,terms,it,is,either,supported,or,not;private,static,void,check,terms,terms,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,terms,aggregation,builder,name,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkTerms(TermsAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps);1533319589;Ensure that the terms aggregation is supported by one or more job caps.  There is no notion of "best"_caps for terms, it is either supported or not.;private static void checkTerms(TermsAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(TermsAggregationBuilder.NAME)) {_                        localCaps.add(cap)__                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +_                    source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };ensure,that,the,terms,aggregation,is,supported,by,one,or,more,job,caps,there,is,no,notion,of,best,caps,for,terms,it,is,either,supported,or,not;private,static,void,check,terms,terms,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,terms,aggregation,builder,name,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkTerms(TermsAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps);1535666657;Ensure that the terms aggregation is supported by one or more job caps.  There is no notion of "best"_caps for terms, it is either supported or not.;private static void checkTerms(TermsAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(TermsAggregationBuilder.NAME)) {_                        localCaps.add(cap)__                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +_                    source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };ensure,that,the,terms,aggregation,is,supported,by,one,or,more,job,caps,there,is,no,notion,of,best,caps,for,terms,it,is,either,supported,or,not;private,static,void,check,terms,terms,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,terms,aggregation,builder,name,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkTerms(TermsAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps);1536053689;Ensure that the terms aggregation is supported by one or more job caps.  There is no notion of "best"_caps for terms, it is either supported or not.;private static void checkTerms(TermsAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(TermsAggregationBuilder.NAME)) {_                        localCaps.add(cap)__                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +_                    source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };ensure,that,the,terms,aggregation,is,supported,by,one,or,more,job,caps,there,is,no,notion,of,best,caps,for,terms,it,is,either,supported,or,not;private,static,void,check,terms,terms,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,terms,aggregation,builder,name,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkTerms(TermsAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps);1548236405;Ensure that the terms aggregation is supported by one or more job caps.  There is no notion of "best"_caps for terms, it is either supported or not.;private static void checkTerms(TermsAggregationBuilder source, List<RollupJobCaps> jobCaps, Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(TermsAggregationBuilder.NAME)) {_                        localCaps.add(cap)__                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +_                    source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };ensure,that,the,terms,aggregation,is,supported,by,one,or,more,job,caps,there,is,no,notion,of,best,caps,for,terms,it,is,either,supported,or,not;private,static,void,check,terms,terms,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,terms,aggregation,builder,name,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkDateHisto(DateHistogramAggregationBuilder source, List<RollupJobCaps> jobCaps,                                        Set<RollupJobCaps> bestCaps);1524684173;Find the set of date_histo's with the largest granularity interval;private static void checkDateHisto(DateHistogramAggregationBuilder source, List<RollupJobCaps> jobCaps,_                                       Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(DateHistogramAggregationBuilder.NAME)) {_                        TimeValue interval = TimeValue.parseTimeValue((String)agg.get(RollupField.INTERVAL), "date_histogram.interval")__                        String thisTimezone  = (String)agg.get(DateHistoGroupConfig.TIME_ZONE.getPreferredName())__                        String sourceTimeZone = source.timeZone() == null ? DateTimeZone.UTC.toString() : source.timeZone().toString()___                        _                        if (thisTimezone.equalsIgnoreCase(sourceTimeZone) == false) {_                            continue__                        }_                        if (source.dateHistogramInterval() != null) {_                            TimeValue sourceInterval = TimeValue.parseTimeValue(source.dateHistogramInterval().toString(),_                                    "source.date_histogram.interval")__                            _                            if (interval.compareTo(sourceInterval) <= 0) {_                                localCaps.add(cap)__                            }_                        } else {_                            if (interval.getMillis() <= source.interval()) {_                                localCaps.add(cap)__                            }_                        }_                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +_                    source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };find,the,set,of,s,with,the,largest,granularity,interval;private,static,void,check,date,histo,date,histogram,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,date,histogram,aggregation,builder,name,time,value,interval,time,value,parse,time,value,string,agg,get,rollup,field,interval,interval,string,this,timezone,string,agg,get,date,histo,group,config,get,preferred,name,string,source,time,zone,source,time,zone,null,date,time,zone,utc,to,string,source,time,zone,to,string,if,this,timezone,equals,ignore,case,source,time,zone,false,continue,if,source,date,histogram,interval,null,time,value,source,interval,time,value,parse,time,value,source,date,histogram,interval,to,string,source,interval,if,interval,compare,to,source,interval,0,local,caps,add,cap,else,if,interval,get,millis,source,interval,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkDateHisto(DateHistogramAggregationBuilder source, List<RollupJobCaps> jobCaps,                                        Set<RollupJobCaps> bestCaps);1533319589;Find the set of date_histo's with the largest granularity interval;private static void checkDateHisto(DateHistogramAggregationBuilder source, List<RollupJobCaps> jobCaps,_                                       Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(DateHistogramAggregationBuilder.NAME)) {_                        TimeValue interval = TimeValue.parseTimeValue((String)agg.get(RollupField.INTERVAL), "date_histogram.interval")__                        String thisTimezone = (String) agg.get(DateHistogramGroupConfig.TIME_ZONE)__                        String sourceTimeZone = source.timeZone() == null ? DateTimeZone.UTC.toString() : source.timeZone().toString()___                        _                        if (thisTimezone.equalsIgnoreCase(sourceTimeZone) == false) {_                            continue__                        }_                        if (source.dateHistogramInterval() != null) {_                            TimeValue sourceInterval = TimeValue.parseTimeValue(source.dateHistogramInterval().toString(),_                                    "source.date_histogram.interval")__                            _                            if (interval.compareTo(sourceInterval) <= 0) {_                                localCaps.add(cap)__                            }_                        } else {_                            if (interval.getMillis() <= source.interval()) {_                                localCaps.add(cap)__                            }_                        }_                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +_                    source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };find,the,set,of,s,with,the,largest,granularity,interval;private,static,void,check,date,histo,date,histogram,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,date,histogram,aggregation,builder,name,time,value,interval,time,value,parse,time,value,string,agg,get,rollup,field,interval,interval,string,this,timezone,string,agg,get,date,histogram,group,config,string,source,time,zone,source,time,zone,null,date,time,zone,utc,to,string,source,time,zone,to,string,if,this,timezone,equals,ignore,case,source,time,zone,false,continue,if,source,date,histogram,interval,null,time,value,source,interval,time,value,parse,time,value,source,date,histogram,interval,to,string,source,interval,if,interval,compare,to,source,interval,0,local,caps,add,cap,else,if,interval,get,millis,source,interval,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkDateHisto(DateHistogramAggregationBuilder source, List<RollupJobCaps> jobCaps,                                        Set<RollupJobCaps> bestCaps);1535666657;Find the set of date_histo's with the largest granularity interval;private static void checkDateHisto(DateHistogramAggregationBuilder source, List<RollupJobCaps> jobCaps,_                                       Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(DateHistogramAggregationBuilder.NAME)) {_                        DateHistogramInterval interval = new DateHistogramInterval((String)agg.get(RollupField.INTERVAL))___                        String thisTimezone  = (String)agg.get(DateHistogramGroupConfig.TIME_ZONE)__                        String sourceTimeZone = source.timeZone() == null ? DateTimeZone.UTC.toString() : source.timeZone().toString()___                        _                        if (thisTimezone.equalsIgnoreCase(sourceTimeZone) == false) {_                            continue__                        }_                        if (source.dateHistogramInterval() != null) {_                            _                            _                            if (validateCalendarInterval(source.dateHistogramInterval(), interval)) {_                                localCaps.add(cap)__                            } else if (validateFixedInterval(source.dateHistogramInterval(), interval)) {_                                localCaps.add(cap)__                            }_                        } else {_                            _                            if (validateFixedInterval(source.interval(), interval)) {_                                localCaps.add(cap)__                            }_                        }_                        _                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +_                    source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };find,the,set,of,s,with,the,largest,granularity,interval;private,static,void,check,date,histo,date,histogram,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,date,histogram,aggregation,builder,name,date,histogram,interval,interval,new,date,histogram,interval,string,agg,get,rollup,field,interval,string,this,timezone,string,agg,get,date,histogram,group,config,string,source,time,zone,source,time,zone,null,date,time,zone,utc,to,string,source,time,zone,to,string,if,this,timezone,equals,ignore,case,source,time,zone,false,continue,if,source,date,histogram,interval,null,if,validate,calendar,interval,source,date,histogram,interval,interval,local,caps,add,cap,else,if,validate,fixed,interval,source,date,histogram,interval,interval,local,caps,add,cap,else,if,validate,fixed,interval,source,interval,interval,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkDateHisto(DateHistogramAggregationBuilder source, List<RollupJobCaps> jobCaps,                                        Set<RollupJobCaps> bestCaps);1536053689;Find the set of date_histo's with the largest granularity interval;private static void checkDateHisto(DateHistogramAggregationBuilder source, List<RollupJobCaps> jobCaps,_                                       Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(DateHistogramAggregationBuilder.NAME)) {_                        DateHistogramInterval interval = new DateHistogramInterval((String)agg.get(RollupField.INTERVAL))___                        String thisTimezone  = (String)agg.get(DateHistogramGroupConfig.TIME_ZONE)__                        String sourceTimeZone = source.timeZone() == null ? DateTimeZone.UTC.toString() : source.timeZone().toString()___                        _                        if (thisTimezone.equalsIgnoreCase(sourceTimeZone) == false) {_                            continue__                        }_                        if (source.dateHistogramInterval() != null) {_                            _                            _                            if (validateCalendarInterval(source.dateHistogramInterval(), interval)) {_                                localCaps.add(cap)__                            } else if (validateFixedInterval(source.dateHistogramInterval(), interval)) {_                                localCaps.add(cap)__                            }_                        } else {_                            _                            if (validateFixedInterval(source.interval(), interval)) {_                                localCaps.add(cap)__                            }_                        }_                        _                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +_                    source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };find,the,set,of,s,with,the,largest,granularity,interval;private,static,void,check,date,histo,date,histogram,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,date,histogram,aggregation,builder,name,date,histogram,interval,interval,new,date,histogram,interval,string,agg,get,rollup,field,interval,string,this,timezone,string,agg,get,date,histogram,group,config,string,source,time,zone,source,time,zone,null,date,time,zone,utc,to,string,source,time,zone,to,string,if,this,timezone,equals,ignore,case,source,time,zone,false,continue,if,source,date,histogram,interval,null,if,validate,calendar,interval,source,date,histogram,interval,interval,local,caps,add,cap,else,if,validate,fixed,interval,source,date,histogram,interval,interval,local,caps,add,cap,else,if,validate,fixed,interval,source,interval,interval,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkDateHisto(DateHistogramAggregationBuilder source, List<RollupJobCaps> jobCaps,                                        Set<RollupJobCaps> bestCaps);1548236405;Find the set of date_histo's with the largest granularity interval;private static void checkDateHisto(DateHistogramAggregationBuilder source, List<RollupJobCaps> jobCaps,_                                       Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(DateHistogramAggregationBuilder.NAME)) {_                        DateHistogramInterval interval = new DateHistogramInterval((String)agg.get(RollupField.INTERVAL))___                        String thisTimezone  = (String)agg.get(DateHistogramGroupConfig.TIME_ZONE)__                        String sourceTimeZone = source.timeZone() == null ? "UTC" : source.timeZone().toString()___                        _                        if (thisTimezone.equalsIgnoreCase(sourceTimeZone) == false) {_                            continue__                        }_                        if (source.dateHistogramInterval() != null) {_                            _                            _                            if (validateCalendarInterval(source.dateHistogramInterval(), interval)) {_                                localCaps.add(cap)__                            } else if (validateFixedInterval(source.dateHistogramInterval(), interval)) {_                                localCaps.add(cap)__                            }_                        } else {_                            _                            if (validateFixedInterval(source.interval(), interval)) {_                                localCaps.add(cap)__                            }_                        }_                        _                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg on field [" +_                    source.field() + "] which also satisfies all requirements of query.")__        }__        _        if (source.getSubAggregations().size() == 0) {_            bestCaps.add(getTopEqualCaps(localCaps))__        } else {_            _            source.getSubAggregations().forEach(sub -> doFindBestJobs(sub, localCaps, bestCaps))__        }_    };find,the,set,of,s,with,the,largest,granularity,interval;private,static,void,check,date,histo,date,histogram,aggregation,builder,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,date,histogram,aggregation,builder,name,date,histogram,interval,interval,new,date,histogram,interval,string,agg,get,rollup,field,interval,string,this,timezone,string,agg,get,date,histogram,group,config,string,source,time,zone,source,time,zone,null,utc,source,time,zone,to,string,if,this,timezone,equals,ignore,case,source,time,zone,false,continue,if,source,date,histogram,interval,null,if,validate,calendar,interval,source,date,histogram,interval,interval,local,caps,add,cap,else,if,validate,fixed,interval,source,date,histogram,interval,interval,local,caps,add,cap,else,if,validate,fixed,interval,source,interval,interval,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,on,field,source,field,which,also,satisfies,all,requirements,of,query,if,source,get,sub,aggregations,size,0,best,caps,add,get,top,equal,caps,local,caps,else,source,get,sub,aggregations,for,each,sub,do,find,best,jobs,sub,local,caps,best,caps
RollupJobIdentifierUtils -> private static void checkVSLeaf(ValuesSourceAggregationBuilder.LeafOnly source, List<RollupJobCaps> jobCaps,                                     Set<RollupJobCaps> bestCaps);1524684173;Ensure that the metrics are supported by one or more job caps.  There is no notion of "best"_caps for metrics, it is either supported or not.;private static void checkVSLeaf(ValuesSourceAggregationBuilder.LeafOnly source, List<RollupJobCaps> jobCaps,_                                    Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(source.getWriteableName())) {_                        localCaps.add(cap)__                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg with name [" +_                    source.getName() + "] which also satisfies all requirements of query.")__        }__        _        bestCaps.add(getTopEqualCaps(localCaps))__    };ensure,that,the,metrics,are,supported,by,one,or,more,job,caps,there,is,no,notion,of,best,caps,for,metrics,it,is,either,supported,or,not;private,static,void,check,vsleaf,values,source,aggregation,builder,leaf,only,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,source,get,writeable,name,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,with,name,source,get,name,which,also,satisfies,all,requirements,of,query,best,caps,add,get,top,equal,caps,local,caps
RollupJobIdentifierUtils -> private static void checkVSLeaf(ValuesSourceAggregationBuilder.LeafOnly source, List<RollupJobCaps> jobCaps,                                     Set<RollupJobCaps> bestCaps);1533319589;Ensure that the metrics are supported by one or more job caps.  There is no notion of "best"_caps for metrics, it is either supported or not.;private static void checkVSLeaf(ValuesSourceAggregationBuilder.LeafOnly source, List<RollupJobCaps> jobCaps,_                                    Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(source.getWriteableName())) {_                        localCaps.add(cap)__                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg with name [" +_                    source.getName() + "] which also satisfies all requirements of query.")__        }__        _        bestCaps.add(getTopEqualCaps(localCaps))__    };ensure,that,the,metrics,are,supported,by,one,or,more,job,caps,there,is,no,notion,of,best,caps,for,metrics,it,is,either,supported,or,not;private,static,void,check,vsleaf,values,source,aggregation,builder,leaf,only,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,source,get,writeable,name,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,with,name,source,get,name,which,also,satisfies,all,requirements,of,query,best,caps,add,get,top,equal,caps,local,caps
RollupJobIdentifierUtils -> private static void checkVSLeaf(ValuesSourceAggregationBuilder.LeafOnly source, List<RollupJobCaps> jobCaps,                                     Set<RollupJobCaps> bestCaps);1535666657;Ensure that the metrics are supported by one or more job caps.  There is no notion of "best"_caps for metrics, it is either supported or not.;private static void checkVSLeaf(ValuesSourceAggregationBuilder.LeafOnly source, List<RollupJobCaps> jobCaps,_                                    Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(source.getWriteableName())) {_                        localCaps.add(cap)__                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg with name [" +_                    source.getName() + "] which also satisfies all requirements of query.")__        }__        _        bestCaps.add(getTopEqualCaps(localCaps))__    };ensure,that,the,metrics,are,supported,by,one,or,more,job,caps,there,is,no,notion,of,best,caps,for,metrics,it,is,either,supported,or,not;private,static,void,check,vsleaf,values,source,aggregation,builder,leaf,only,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,source,get,writeable,name,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,with,name,source,get,name,which,also,satisfies,all,requirements,of,query,best,caps,add,get,top,equal,caps,local,caps
RollupJobIdentifierUtils -> private static void checkVSLeaf(ValuesSourceAggregationBuilder.LeafOnly source, List<RollupJobCaps> jobCaps,                                     Set<RollupJobCaps> bestCaps);1536053689;Ensure that the metrics are supported by one or more job caps.  There is no notion of "best"_caps for metrics, it is either supported or not.;private static void checkVSLeaf(ValuesSourceAggregationBuilder.LeafOnly source, List<RollupJobCaps> jobCaps,_                                    Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(source.getWriteableName())) {_                        localCaps.add(cap)__                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg with name [" +_                    source.getName() + "] which also satisfies all requirements of query.")__        }__        _        bestCaps.add(getTopEqualCaps(localCaps))__    };ensure,that,the,metrics,are,supported,by,one,or,more,job,caps,there,is,no,notion,of,best,caps,for,metrics,it,is,either,supported,or,not;private,static,void,check,vsleaf,values,source,aggregation,builder,leaf,only,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,source,get,writeable,name,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,with,name,source,get,name,which,also,satisfies,all,requirements,of,query,best,caps,add,get,top,equal,caps,local,caps
RollupJobIdentifierUtils -> private static void checkVSLeaf(ValuesSourceAggregationBuilder.LeafOnly source, List<RollupJobCaps> jobCaps,                                     Set<RollupJobCaps> bestCaps);1548236405;Ensure that the metrics are supported by one or more job caps.  There is no notion of "best"_caps for metrics, it is either supported or not.;private static void checkVSLeaf(ValuesSourceAggregationBuilder.LeafOnly source, List<RollupJobCaps> jobCaps,_                                    Set<RollupJobCaps> bestCaps) {_        ArrayList<RollupJobCaps> localCaps = new ArrayList<>()__        for (RollupJobCaps cap : jobCaps) {_            RollupJobCaps.RollupFieldCaps fieldCaps = cap.getFieldCaps().get(source.field())__            if (fieldCaps != null) {_                for (Map<String, Object> agg : fieldCaps.getAggs()) {_                    if (agg.get(RollupField.AGG).equals(source.getWriteableName())) {_                        localCaps.add(cap)__                        break__                    }_                }_            }_        }__        if (localCaps.isEmpty()) {_            throw new IllegalArgumentException("There is not a rollup job that has a [" + source.getWriteableName() + "] agg with name [" +_                    source.getName() + "] which also satisfies all requirements of query.")__        }__        _        bestCaps.add(getTopEqualCaps(localCaps))__    };ensure,that,the,metrics,are,supported,by,one,or,more,job,caps,there,is,no,notion,of,best,caps,for,metrics,it,is,either,supported,or,not;private,static,void,check,vsleaf,values,source,aggregation,builder,leaf,only,source,list,rollup,job,caps,job,caps,set,rollup,job,caps,best,caps,array,list,rollup,job,caps,local,caps,new,array,list,for,rollup,job,caps,cap,job,caps,rollup,job,caps,rollup,field,caps,field,caps,cap,get,field,caps,get,source,field,if,field,caps,null,for,map,string,object,agg,field,caps,get,aggs,if,agg,get,rollup,field,agg,equals,source,get,writeable,name,local,caps,add,cap,break,if,local,caps,is,empty,throw,new,illegal,argument,exception,there,is,not,a,rollup,job,that,has,a,source,get,writeable,name,agg,with,name,source,get,name,which,also,satisfies,all,requirements,of,query,best,caps,add,get,top,equal,caps,local,caps
