commented;modifiers;parameterAmount;loc;comment;code
false;;3;1;;void list(ShardId shardId, DiscoveryNode[] nodes, ActionListener<NodesResponse> listener).
false;public,synchronized;0;4;;@Override public synchronized void close() {     this.closed = true. }
true;public,synchronized;0;9;/**  * Returns the number of async fetches that are currently ongoing.  */ ;/**  * Returns the number of async fetches that are currently ongoing.  */ public synchronized int getNumberOfInFlightFetches() {     int count = 0.     for (NodeEntry<T> nodeEntry : cache.values()) {         if (nodeEntry.isFetching()) {             count++.         }     }     return count. }
true;public,synchronized;2;57;/**  * Fetches the data for the relevant shard. If there any ongoing async fetches going on, or new ones have  * been initiated by this call, the result will have no data.  * <p>  * The ignoreNodes are nodes that are supposed to be ignored for this round, since fetching is async, we need  * to keep them around and make sure we add them back when all the responses are fetched and returned.  */ ;/**  * Fetches the data for the relevant shard. If there any ongoing async fetches going on, or new ones have  * been initiated by this call, the result will have no data.  * <p>  * The ignoreNodes are nodes that are supposed to be ignored for this round, since fetching is async, we need  * to keep them around and make sure we add them back when all the responses are fetched and returned.  */ public synchronized FetchResult<T> fetchData(DiscoveryNodes nodes, Set<String> ignoreNodes) {     if (closed) {         throw new IllegalStateException(shardId + ": can't fetch data on closed async fetch").     }     nodesToIgnore.addAll(ignoreNodes).     fillShardCacheWithDataNodes(cache, nodes).     List<NodeEntry<T>> nodesToFetch = findNodesToFetch(cache).     if (nodesToFetch.isEmpty() == false) {         // mark all node as fetching and go ahead and async fetch them         // use a unique round id to detect stale responses in processAsyncFetch         final long fetchingRound = round.incrementAndGet().         for (NodeEntry<T> nodeEntry : nodesToFetch) {             nodeEntry.markAsFetching(fetchingRound).         }         DiscoveryNode[] discoNodesToFetch = nodesToFetch.stream().map(NodeEntry::getNodeId).map(nodes::get).toArray(DiscoveryNode[]::new).         asyncFetch(discoNodesToFetch, fetchingRound).     }     // if we are still fetching, return null to indicate it     if (hasAnyNodeFetching(cache)) {         return new FetchResult<>(shardId, null, emptySet()).     } else {         // nothing to fetch, yay, build the return value         Map<DiscoveryNode, T> fetchData = new HashMap<>().         Set<String> failedNodes = new HashSet<>().         for (Iterator<Map.Entry<String, NodeEntry<T>>> it = cache.entrySet().iterator(). it.hasNext(). ) {             Map.Entry<String, NodeEntry<T>> entry = it.next().             String nodeId = entry.getKey().             NodeEntry<T> nodeEntry = entry.getValue().             DiscoveryNode node = nodes.get(nodeId).             if (node != null) {                 if (nodeEntry.isFailed()) {                     // if its failed, remove it from the list of nodes, so if this run doesn't work                     // we try again next round to fetch it again                     it.remove().                     failedNodes.add(nodeEntry.getNodeId()).                 } else {                     if (nodeEntry.getValue() != null) {                         fetchData.put(node, nodeEntry.getValue()).                     }                 }             }         }         Set<String> allIgnoreNodes = unmodifiableSet(new HashSet<>(nodesToIgnore)).         // clear the nodes to ignore, we had a successful run in fetching everything we can         // we need to try them if another full run is needed         nodesToIgnore.clear().         // here, just case this round won't find anything, and we need to retry fetching data         if (failedNodes.isEmpty() == false || allIgnoreNodes.isEmpty() == false) {             reroute(shardId, "nodes failed [" + failedNodes.size() + "], ignored [" + allIgnoreNodes.size() + "]").         }         return new FetchResult<>(shardId, fetchData, allIgnoreNodes).     } }
true;protected,synchronized;3;55;/**  * Called by the response handler of the async action to fetch data. Verifies that its still working  * on the same cache generation, otherwise the results are discarded. It then goes and fills the relevant data for  * the shard (response + failures), issuing a reroute at the end of it to make sure there will be another round  * of allocations taking this new data into account.  */ ;/**  * Called by the response handler of the async action to fetch data. Verifies that its still working  * on the same cache generation, otherwise the results are discarded. It then goes and fills the relevant data for  * the shard (response + failures), issuing a reroute at the end of it to make sure there will be another round  * of allocations taking this new data into account.  */ protected synchronized void processAsyncFetch(List<T> responses, List<FailedNodeException> failures, long fetchingRound) {     if (closed) {         // we are closed, no need to process this async fetch at all         logger.trace("{} ignoring fetched [{}] results, already closed", shardId, type).         return.     }     logger.trace("{} processing fetched [{}] results", shardId, type).     if (responses != null) {         for (T response : responses) {             NodeEntry<T> nodeEntry = cache.get(response.getNode().getId()).             if (nodeEntry != null) {                 if (nodeEntry.getFetchingRound() != fetchingRound) {                     assert nodeEntry.getFetchingRound() > fetchingRound : "node entries only replaced by newer rounds".                     logger.trace("{} received response for [{}] from node {} for an older fetching round (expected: {} but was: {})", shardId, nodeEntry.getNodeId(), type, nodeEntry.getFetchingRound(), fetchingRound).                 } else if (nodeEntry.isFailed()) {                     logger.trace("{} node {} has failed for [{}] (failure [{}])", shardId, nodeEntry.getNodeId(), type, nodeEntry.getFailure()).                 } else {                     // if the entry is there, for the right fetching round and not marked as failed already, process it                     logger.trace("{} marking {} as done for [{}], result is [{}]", shardId, nodeEntry.getNodeId(), type, response).                     nodeEntry.doneFetching(response).                 }             }         }     }     if (failures != null) {         for (FailedNodeException failure : failures) {             logger.trace("{} processing failure {} for [{}]", shardId, failure, type).             NodeEntry<T> nodeEntry = cache.get(failure.nodeId()).             if (nodeEntry != null) {                 if (nodeEntry.getFetchingRound() != fetchingRound) {                     assert nodeEntry.getFetchingRound() > fetchingRound : "node entries only replaced by newer rounds".                     logger.trace("{} received failure for [{}] from node {} for an older fetching round (expected: {} but was: {})", shardId, nodeEntry.getNodeId(), type, nodeEntry.getFetchingRound(), fetchingRound).                 } else if (nodeEntry.isFailed() == false) {                     // if the entry is there, for the right fetching round and not marked as failed already, process it                     Throwable unwrappedCause = ExceptionsHelper.unwrapCause(failure.getCause()).                     // if the request got rejected or timed out, we need to try it again next time...                     if (unwrappedCause instanceof EsRejectedExecutionException || unwrappedCause instanceof ReceiveTimeoutTransportException || unwrappedCause instanceof ElasticsearchTimeoutException) {                         nodeEntry.restartFetching().                     } else {                         logger.warn(() -> new ParameterizedMessage("{}: failed to list shard for {} on node [{}]", shardId, type, failure.nodeId()), failure).                         nodeEntry.doneFetching(failure.getCause()).                     }                 }             }         }     }     reroute(shardId, "post_response"). }
true;protected,abstract;2;1;/**  * Implement this in order to scheduled another round that causes a call to fetch data.  */ ;/**  * Implement this in order to scheduled another round that causes a call to fetch data.  */ protected abstract void reroute(ShardId shardId, String reason).
true;private;2;11;/**  * Fills the shard fetched data with new (data) nodes and a fresh NodeEntry, and removes from  * it nodes that are no longer part of the state.  */ ;/**  * Fills the shard fetched data with new (data) nodes and a fresh NodeEntry, and removes from  * it nodes that are no longer part of the state.  */ private void fillShardCacheWithDataNodes(Map<String, NodeEntry<T>> shardCache, DiscoveryNodes nodes) {     // verify that all current data nodes are there     for (ObjectObjectCursor<String, DiscoveryNode> cursor : nodes.getDataNodes()) {         DiscoveryNode node = cursor.value.         if (shardCache.containsKey(node.getId()) == false) {             shardCache.put(node.getId(), new NodeEntry<T>(node.getId())).         }     }     // remove nodes that are not longer part of the data nodes set     shardCache.keySet().removeIf(nodeId -> !nodes.nodeExists(nodeId)). }
true;private;1;9;/**  * Finds all the nodes that need to be fetched. Those are nodes that have no  * data, and are not in fetch mode.  */ ;/**  * Finds all the nodes that need to be fetched. Those are nodes that have no  * data, and are not in fetch mode.  */ private List<NodeEntry<T>> findNodesToFetch(Map<String, NodeEntry<T>> shardCache) {     List<NodeEntry<T>> nodesToFetch = new ArrayList<>().     for (NodeEntry<T> nodeEntry : shardCache.values()) {         if (nodeEntry.hasData() == false && nodeEntry.isFetching() == false) {             nodesToFetch.add(nodeEntry).         }     }     return nodesToFetch. }
true;private;1;8;/**  * Are there any nodes that are fetching data?  */ ;/**  * Are there any nodes that are fetching data?  */ private boolean hasAnyNodeFetching(Map<String, NodeEntry<T>> shardCache) {     for (NodeEntry<T> nodeEntry : shardCache.values()) {         if (nodeEntry.isFetching()) {             return true.         }     }     return false. }
false;public;1;4;;@Override public void onResponse(BaseNodesResponse<T> response) {     processAsyncFetch(response.getNodes(), response.failures(), fetchingRound). }
false;public;1;8;;@Override public void onFailure(Exception e) {     List<FailedNodeException> failures = new ArrayList<>(nodes.length).     for (final DiscoveryNode node : nodes) {         failures.add(new FailedNodeException(node.getId(), "total failure in fetching", e)).     }     processAsyncFetch(null, failures, fetchingRound). }
true;;2;18;// visible for testing ;/**  * Async fetches data for the provided shard with the set of nodes that need to be fetched from.  */ // visible for testing void asyncFetch(final DiscoveryNode[] nodes, long fetchingRound) {     logger.trace("{} fetching [{}] from {}", shardId, type, nodes).     action.list(shardId, nodes, new ActionListener<BaseNodesResponse<T>>() {          @Override         public void onResponse(BaseNodesResponse<T> response) {             processAsyncFetch(response.getNodes(), response.failures(), fetchingRound).         }          @Override         public void onFailure(Exception e) {             List<FailedNodeException> failures = new ArrayList<>(nodes.length).             for (final DiscoveryNode node : nodes) {                 failures.add(new FailedNodeException(node.getId(), "total failure in fetching", e)).             }             processAsyncFetch(null, failures, fetchingRound).         }     }). }
true;public;0;3;/**  * Does the result actually contain data? If not, then there are on going fetch  * operations happening, and it should wait for it.  */ ;/**  * Does the result actually contain data? If not, then there are on going fetch  * operations happening, and it should wait for it.  */ public boolean hasData() {     return data != null. }
true;public;0;4;/**  * Returns the actual data, note, make sure to check {@link #hasData()} first and  * only use this when there is an actual data.  */ ;/**  * Returns the actual data, note, make sure to check {@link #hasData()} first and  * only use this when there is an actual data.  */ public Map<DiscoveryNode, T> getData() {     assert data != null : "getData should only be called if there is data to be fetched, please check hasData first".     return this.data. }
true;public;1;5;/**  * Process any changes needed to the allocation based on this fetch result.  */ ;/**  * Process any changes needed to the allocation based on this fetch result.  */ public void processAllocation(RoutingAllocation allocation) {     for (String ignoreNode : ignoreNodes) {         allocation.addIgnoreShardForNode(shardId, ignoreNode).     } }
false;;0;3;;String getNodeId() {     return this.nodeId. }
false;;0;3;;boolean isFetching() {     return fetching. }
false;;1;5;;void markAsFetching(long fetchingRound) {     assert fetching == false : "double marking a node as fetching".     this.fetching = true.     this.fetchingRound = fetchingRound. }
false;;1;7;;void doneFetching(T value) {     assert fetching : "setting value but not in fetching mode".     assert failure == null : "setting value when failure already set".     this.valueSet = true.     this.value = value.     this.fetching = false. }
false;;1;7;;void doneFetching(Throwable failure) {     assert fetching : "setting value but not in fetching mode".     assert valueSet == false : "setting failure when already set value".     assert failure != null : "setting failure can't be null".     this.failure = failure.     this.fetching = false. }
false;;0;6;;void restartFetching() {     assert fetching : "restarting fetching, but not in fetching mode".     assert valueSet == false : "value can't be set when restarting fetching".     assert failure == null : "failure can't be set when restarting fetching".     this.fetching = false. }
false;;0;3;;boolean isFailed() {     return failure != null. }
false;;0;3;;boolean hasData() {     return valueSet || failure != null. }
false;;0;4;;Throwable getFailure() {     assert hasData() : "getting failure when data has not been fetched".     return failure. }
false;;0;6;;@Nullable T getValue() {     assert failure == null : "trying to fetch value, but its marked as failed, check isFailed".     assert valueSet : "value is not set, hasn't been fetched yet".     return value. }
false;;0;3;;long getFetchingRound() {     return fetchingRound. }
