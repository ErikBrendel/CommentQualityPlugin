commented;modifiers;parameterAmount;loc;comment;code
false;protected;1;4;;@Override protected void printAdditionalHelp(Terminal terminal) {     terminal.println("This tool attempts to detect and remove unrecoverable corrupted data in a shard."). }
true;public;0;3;// Visible for testing ;// Visible for testing public OptionParser getParser() {     return this.parser. }
false;protected;1;4;;@SuppressForbidden(reason = "Necessary to use the path passed in") protected Path getPath(String dirValue) {     return PathUtils.get(dirValue, "", ""). }
false;protected;3;94;;protected void findAndProcessShardPath(OptionSet options, Environment environment, CheckedConsumer<ShardPath, IOException> consumer) throws IOException {     final Settings settings = environment.settings().     final String indexName.     final int shardId.     final int fromNodeId.     final int toNodeId.     if (options.has(folderOption)) {         final Path path = getPath(folderOption.value(options)).getParent().         final Path shardParent = path.getParent().         final Path shardParentParent = shardParent.getParent().         final Path indexPath = path.resolve(ShardPath.INDEX_FOLDER_NAME).         if (Files.exists(indexPath) == false || Files.isDirectory(indexPath) == false) {             throw new ElasticsearchException("index directory [" + indexPath + "], must exist and be a directory").         }         final IndexMetaData indexMetaData = IndexMetaData.FORMAT.loadLatestState(logger, namedXContentRegistry, shardParent).         final String shardIdFileName = path.getFileName().toString().         final String nodeIdFileName = shardParentParent.getParent().getFileName().toString().         if (// SHARD-ID path element check         Files.isDirectory(path) && shardIdFileName.chars().allMatch(Character::isDigit) && // `indices` check         NodeEnvironment.INDICES_FOLDER.equals(shardParentParent.getFileName().toString()) && // NODE-ID check         nodeIdFileName.chars().allMatch(Character::isDigit) && // `nodes` check         NodeEnvironment.NODES_FOLDER.equals(shardParentParent.getParent().getParent().getFileName().toString())) {             shardId = Integer.parseInt(shardIdFileName).             indexName = indexMetaData.getIndex().getName().             fromNodeId = Integer.parseInt(nodeIdFileName).             toNodeId = fromNodeId + 1.         } else {             throw new ElasticsearchException("Unable to resolve shard id. Wrong folder structure at [ " + path.toString() + " ], expected .../nodes/[NODE-ID]/indices/[INDEX-UUID]/[SHARD-ID]").         }     } else {         // otherwise resolve shardPath based on the index name and shard id         indexName = Objects.requireNonNull(indexNameOption.value(options), "Index name is required").         shardId = Objects.requireNonNull(shardIdOption.value(options), "Shard ID is required").         // resolve shard path in case of multi-node layout per environment         fromNodeId = 0.         toNodeId = NodeEnvironment.MAX_LOCAL_STORAGE_NODES_SETTING.get(settings).     }     // have to iterate over possibleLockId as NodeEnvironment. on a contrast to it - we have to fail if node is busy     for (int possibleLockId = fromNodeId. possibleLockId < toNodeId. possibleLockId++) {         try {             try (NodeEnvironment.NodeLock nodeLock = new NodeEnvironment.NodeLock(possibleLockId, logger, environment, Files::exists)) {                 final NodeEnvironment.NodePath[] nodePaths = nodeLock.getNodePaths().                 for (NodeEnvironment.NodePath nodePath : nodePaths) {                     if (Files.exists(nodePath.indicesPath)) {                         // have to scan all index uuid folders to resolve from index name                         try (DirectoryStream<Path> stream = Files.newDirectoryStream(nodePath.indicesPath)) {                             for (Path file : stream) {                                 if (Files.exists(file.resolve(MetaDataStateFormat.STATE_DIR_NAME)) == false) {                                     continue.                                 }                                 final IndexMetaData indexMetaData = IndexMetaData.FORMAT.loadLatestState(logger, namedXContentRegistry, file).                                 if (indexMetaData == null) {                                     continue.                                 }                                 final IndexSettings indexSettings = new IndexSettings(indexMetaData, settings).                                 final Index index = indexMetaData.getIndex().                                 if (indexName.equals(index.getName()) == false) {                                     continue.                                 }                                 final ShardId shId = new ShardId(index, shardId).                                 final Path shardPathLocation = nodePath.resolve(shId).                                 if (Files.exists(shardPathLocation) == false) {                                     continue.                                 }                                 final ShardPath shardPath = ShardPath.loadShardPath(logger, shId, indexSettings, new Path[] { shardPathLocation }, possibleLockId, nodePath.path).                                 if (shardPath != null) {                                     consumer.accept(shardPath).                                     return.                                 }                             }                         }                     }                 }             }         } catch (LockObtainFailedException lofe) {             throw new ElasticsearchException("Failed to lock node's directory [" + lofe.getMessage() + "], is Elasticsearch still running ?").         }     }     throw new ElasticsearchException("Unable to resolve shard path for index [" + indexName + "] and shard id [" + shardId + "]"). }
false;public,static;1;13;;public static boolean isCorruptMarkerFileIsPresent(final Directory directory) throws IOException {     boolean found = false.     final String[] files = directory.listAll().     for (String file : files) {         if (file.startsWith(Store.CORRUPTED)) {             found = true.             break.         }     }     return found. }
false;protected;4;18;;protected void dropCorruptMarkerFiles(Terminal terminal, Path path, Directory directory, boolean clean) throws IOException {     if (clean) {         confirm("This shard has been marked as corrupted but no corruption can now be detected.\n" + "This may indicate an intermittent hardware problem. The corruption marker can be \n" + "removed, but there is a risk that data has been undetectably lost.\n\n" + "Are you taking a risk of losing documents and proceed with removing a corrupted marker ?", terminal).     }     String[] files = directory.listAll().     boolean found = false.     for (String file : files) {         if (file.startsWith(Store.CORRUPTED)) {             directory.deleteFile(file).             terminal.println("Deleted corrupt marker " + file + " from " + path).         }     } }
false;private,static;2;7;;private static void loseDataDetailsBanner(Terminal terminal, Tuple<CleanStatus, String> cleanStatus) {     if (cleanStatus.v2() != null) {         terminal.println("").         terminal.println("  " + cleanStatus.v2()).         terminal.println("").     } }
false;private,static;2;7;;private static void confirm(String msg, Terminal terminal) {     terminal.println(msg).     String text = terminal.readText("Confirm [y/N] ").     if (text.equalsIgnoreCase("y") == false) {         throw new ElasticsearchException("aborted by user").     } }
false;private;1;9;;private void warnAboutESShouldBeStopped(Terminal terminal) {     terminal.println("-----------------------------------------------------------------------").     terminal.println("").     terminal.println("    WARNING: Elasticsearch MUST be stopped before running this tool.").     terminal.println("").     terminal.println("  Please make a complete backup of your index before using this tool.").     terminal.println("").     terminal.println("-----------------------------------------------------------------------"). }
false;public;1;4;;@Override public void write(int b) {     writer.write(b). }
true;public;3;124;// Visible for testing ;// Visible for testing @Override public void execute(Terminal terminal, OptionSet options, Environment environment) throws Exception {     warnAboutESShouldBeStopped(terminal).     findAndProcessShardPath(options, environment, shardPath -> {         final Path indexPath = shardPath.resolveIndex().         final Path translogPath = shardPath.resolveTranslog().         final Path nodePath = getNodePath(shardPath).         if (Files.exists(translogPath) == false || Files.isDirectory(translogPath) == false) {             throw new ElasticsearchException("translog directory [" + translogPath + "], must exist and be a directory").         }         final PrintWriter writer = terminal.getWriter().         final PrintStream printStream = new PrintStream(new OutputStream() {              @Override             public void write(int b) {                 writer.write(b).             }         }, false, "UTF-8").         final boolean verbose = terminal.isPrintable(Terminal.Verbosity.VERBOSE).         final Directory indexDirectory = getDirectory(indexPath).         final Tuple<CleanStatus, String> indexCleanStatus.         final Tuple<CleanStatus, String> translogCleanStatus.         try (Directory indexDir = indexDirectory) {             // keep the index lock to block any runs of older versions of this tool             try (Lock writeIndexLock = indexDir.obtainLock(IndexWriter.WRITE_LOCK_NAME)) {                 // //////// Index                 terminal.println("").                 terminal.println("Opening Lucene index at " + indexPath).                 terminal.println("").                 try {                     indexCleanStatus = removeCorruptedLuceneSegmentsAction.getCleanStatus(shardPath, indexDir, writeIndexLock, printStream, verbose).                 } catch (Exception e) {                     terminal.println(e.getMessage()).                     throw e.                 }                 terminal.println("").                 terminal.println(" >> Lucene index is " + indexCleanStatus.v1().getMessage() + " at " + indexPath).                 terminal.println("").                 // as translog relies on data stored in an index commit - we have to have non unrecoverable index to truncate translog                 if (indexCleanStatus.v1() != CleanStatus.UNRECOVERABLE) {                     terminal.println("").                     terminal.println("Opening translog at " + translogPath).                     terminal.println("").                     try {                         translogCleanStatus = truncateTranslogAction.getCleanStatus(shardPath, indexDir).                     } catch (Exception e) {                         terminal.println(e.getMessage()).                         throw e.                     }                     terminal.println("").                     terminal.println(" >> Translog is " + translogCleanStatus.v1().getMessage() + " at " + translogPath).                     terminal.println("").                 } else {                     translogCleanStatus = Tuple.tuple(CleanStatus.UNRECOVERABLE, null).                 }                 // //////// Drop corrupted data                 final CleanStatus indexStatus = indexCleanStatus.v1().                 final CleanStatus translogStatus = translogCleanStatus.v1().                 if (indexStatus == CleanStatus.CLEAN && translogStatus == CleanStatus.CLEAN) {                     throw new ElasticsearchException("Shard does not seem to be corrupted at " + shardPath.getDataPath()).                 }                 if (indexStatus == CleanStatus.UNRECOVERABLE) {                     if (indexCleanStatus.v2() != null) {                         terminal.println("Details: " + indexCleanStatus.v2()).                     }                     terminal.println("You can allocate a new, empty, primary shard with the following command:").                     printRerouteCommand(shardPath, terminal, false).                     throw new ElasticsearchException("Index is unrecoverable").                 }                 terminal.println("-----------------------------------------------------------------------").                 if (indexStatus != CleanStatus.CLEAN) {                     loseDataDetailsBanner(terminal, indexCleanStatus).                 }                 if (translogStatus != CleanStatus.CLEAN) {                     loseDataDetailsBanner(terminal, translogCleanStatus).                 }                 terminal.println("            WARNING:              YOU MAY LOSE DATA.").                 terminal.println("-----------------------------------------------------------------------").                 confirm("Continue and remove corrupted data from the shard ?", terminal).                 if (indexStatus != CleanStatus.CLEAN) {                     removeCorruptedLuceneSegmentsAction.execute(terminal, shardPath, indexDir, writeIndexLock, printStream, verbose).                 }                 if (translogStatus != CleanStatus.CLEAN) {                     truncateTranslogAction.execute(terminal, shardPath, indexDir).                 }             } catch (LockObtainFailedException lofe) {                 final String msg = "Failed to lock shard's directory at [" + indexPath + "], is Elasticsearch still running?".                 terminal.println(msg).                 throw new ElasticsearchException(msg).             }             final CleanStatus indexStatus = indexCleanStatus.v1().             final CleanStatus translogStatus = translogCleanStatus.v1().             // newHistoryCommit obtains its own lock             addNewHistoryCommit(indexDir, terminal, translogStatus != CleanStatus.CLEAN).             newAllocationId(environment, shardPath, terminal).             if (indexStatus != CleanStatus.CLEAN) {                 dropCorruptMarkerFiles(terminal, indexPath, indexDir, indexStatus == CleanStatus.CLEAN_WITH_CORRUPTED_MARKER).             }         }     }). }
false;private;1;9;;private Directory getDirectory(Path indexPath) {     Directory directory.     try {         directory = FSDirectory.open(indexPath, NativeFSLockFactory.INSTANCE).     } catch (Throwable t) {         throw new ElasticsearchException("ERROR: could not open directory \"" + indexPath + "\". exiting").     }     return directory. }
false;protected;3;33;;protected void addNewHistoryCommit(Directory indexDirectory, Terminal terminal, boolean updateLocalCheckpoint) throws IOException {     final String historyUUID = UUIDs.randomBase64UUID().     terminal.println("Marking index with the new history uuid : " + historyUUID).     // commit the new history id     final IndexWriterConfig iwc = new IndexWriterConfig(null).setCommitOnClose(false).setSoftDeletesField(Lucene.SOFT_DELETES_FIELD).setMergePolicy(NoMergePolicy.INSTANCE).setOpenMode(IndexWriterConfig.OpenMode.APPEND).     // IndexWriter acquires directory lock by its own     try (IndexWriter indexWriter = new IndexWriter(indexDirectory, iwc)) {         final Map<String, String> userData = new HashMap<>().         indexWriter.getLiveCommitData().forEach(e -> userData.put(e.getKey(), e.getValue())).         if (updateLocalCheckpoint) {             // In order to have a safe commit invariant, we have to assign the global checkpoint to the max_seqno of the last commit.             // We can only safely do it because we will generate a new history uuid this shard.             final SequenceNumbers.CommitInfo commitInfo = SequenceNumbers.loadSeqNoInfoFromLuceneCommit(userData.entrySet()).             // Also advances the local checkpoint of the last commit to its max_seqno.             userData.put(SequenceNumbers.LOCAL_CHECKPOINT_KEY, Long.toString(commitInfo.maxSeqNo)).         }         // commit the new history id         userData.put(Engine.HISTORY_UUID_KEY, historyUUID).         indexWriter.setLiveCommitData(userData.entrySet()).         indexWriter.commit().     } }
false;protected;3;24;;protected void newAllocationId(Environment environment, ShardPath shardPath, Terminal terminal) throws IOException {     final Path shardStatePath = shardPath.getShardStatePath().     final ShardStateMetaData shardStateMetaData = ShardStateMetaData.FORMAT.loadLatestState(logger, namedXContentRegistry, shardStatePath).     if (shardStateMetaData == null) {         throw new ElasticsearchException("No shard state meta data at " + shardStatePath).     }     final AllocationId newAllocationId = AllocationId.newInitializing().     terminal.println("Changing allocation id " + shardStateMetaData.allocationId.getId() + " to " + newAllocationId.getId()).     final ShardStateMetaData newShardStateMetaData = new ShardStateMetaData(shardStateMetaData.primary, shardStateMetaData.indexUUID, newAllocationId).     ShardStateMetaData.FORMAT.writeAndCleanup(newShardStateMetaData, shardStatePath).     terminal.println("").     terminal.println("You should run the following command to allocate this shard:").     printRerouteCommand(shardPath, terminal, true). }
false;private;3;28;;private void printRerouteCommand(ShardPath shardPath, Terminal terminal, boolean allocateStale) throws IOException {     final IndexMetaData indexMetaData = IndexMetaData.FORMAT.loadLatestState(logger, namedXContentRegistry, shardPath.getDataPath().getParent()).     final Path nodePath = getNodePath(shardPath).     final NodeMetaData nodeMetaData = NodeMetaData.FORMAT.loadLatestState(logger, namedXContentRegistry, nodePath).     if (nodeMetaData == null) {         throw new ElasticsearchException("No node meta data at " + nodePath).     }     final String nodeId = nodeMetaData.nodeId().     final String index = indexMetaData.getIndex().getName().     final int id = shardPath.getShardId().id().     final AllocationCommands commands = new AllocationCommands(allocateStale ? new AllocateStalePrimaryAllocationCommand(index, id, nodeId, false) : new AllocateEmptyPrimaryAllocationCommand(index, id, nodeId, false)).     terminal.println("").     terminal.println("POST /_cluster/reroute'\n" + Strings.toString(commands, true, true) + "'").     terminal.println("").     terminal.println("You must accept the possibility of data loss by changing parameter `accept_data_loss` to `true`.").     terminal.println(""). }
false;private;1;7;;private Path getNodePath(ShardPath shardPath) {     final Path nodePath = shardPath.getDataPath().getParent().getParent().getParent().     if (Files.exists(nodePath) == false || Files.exists(nodePath.resolve(MetaDataStateFormat.STATE_DIR_NAME)) == false) {         throw new ElasticsearchException("Unable to resolve node path for " + shardPath).     }     return nodePath. }
false;public;0;3;;public String getMessage() {     return msg. }
