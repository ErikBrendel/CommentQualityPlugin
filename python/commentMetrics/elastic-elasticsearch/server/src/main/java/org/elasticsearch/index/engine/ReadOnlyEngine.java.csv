commented;modifiers;parameterAmount;loc;comment;code
false;protected;2;5;;protected void assertMaxSeqNoEqualsToGlobalCheckpoint(final long maxSeqNo, final long globalCheckpoint) {     if (Assertions.ENABLED) {         assert false : "max seq. no. [" + maxSeqNo + "] does not match [" + globalCheckpoint + "]".     } }
false;public;0;9;;@Override public void verifyEngineBeforeIndexClosing() throws IllegalStateException { // the value of the global checkpoint is verified when the read-only engine is opened, // and it is not expected to change during the lifecycle of the engine. We could also // check this value before closing the read-only engine but if something went wrong // and the global checkpoint is not in-sync with the max. sequence number anymore, // checking the value here again would prevent the read-only engine to be closed and // reopened as an internal engine, which would be the path to fix the issue. }
false;protected,final;2;8;;protected final DirectoryReader wrapReader(DirectoryReader reader, Function<DirectoryReader, DirectoryReader> readerWrapperFunction) throws IOException {     reader = ElasticsearchDirectoryReader.wrap(reader, engineConfig.getShardId()).     if (engineConfig.getIndexSettings().isSoftDeleteEnabled()) {         reader = new SoftDeletesDirectoryReaderWrapper(reader, Lucene.SOFT_DELETES_FIELD).     }     return readerWrapperFunction.apply(reader). }
false;protected;1;3;;protected DirectoryReader open(IndexCommit commit) throws IOException {     return DirectoryReader.open(commit). }
false;private;1;17;;private DocsStats docsStats(final SegmentInfos lastCommittedSegmentInfos) {     long numDocs = 0.     long numDeletedDocs = 0.     long sizeInBytes = 0.     if (lastCommittedSegmentInfos != null) {         for (SegmentCommitInfo segmentCommitInfo : lastCommittedSegmentInfos) {             numDocs += segmentCommitInfo.info.maxDoc() - segmentCommitInfo.getDelCount() - segmentCommitInfo.getSoftDelCount().             numDeletedDocs += segmentCommitInfo.getDelCount() + segmentCommitInfo.getSoftDelCount().             try {                 sizeInBytes += segmentCommitInfo.sizeInBytes().             } catch (IOException e) {                 throw new UncheckedIOException("Failed to get size for [" + segmentCommitInfo.info.name + "]", e).             }         }     }     return new DocsStats(numDocs, numDeletedDocs, sizeInBytes). }
false;protected;2;12;;@Override protected void closeNoLock(String reason, CountDownLatch closedLatch) {     if (isClosed.compareAndSet(false, true)) {         try {             IOUtils.close(searcherManager, indexWriterLock, store::decRef).         } catch (Exception ex) {             logger.warn("failed to close searcher", ex).         } finally {             closedLatch.countDown().         }     } }
false;public,static;1;7;;public static SeqNoStats buildSeqNoStats(SegmentInfos infos) {     final SequenceNumbers.CommitInfo seqNoStats = SequenceNumbers.loadSeqNoInfoFromLuceneCommit(infos.userData.entrySet()).     long maxSeqNo = seqNoStats.maxSeqNo.     long localCheckpoint = seqNoStats.localCheckpoint.     return new SeqNoStats(maxSeqNo, localCheckpoint, localCheckpoint). }
false;public;2;4;;@Override public GetResult get(Get get, BiFunction<String, SearcherScope, Searcher> searcherFactory) throws EngineException {     return getFromSearcher(get, searcherFactory, SearcherScope.EXTERNAL). }
false;protected;1;4;;@Override protected ReferenceManager<IndexSearcher> getReferenceManager(SearcherScope scope) {     return searcherManager. }
false;protected;0;4;;@Override protected SegmentInfos getLastCommittedSegmentInfos() {     return lastCommittedSegmentInfos. }
false;public;0;4;;@Override public String getHistoryUUID() {     return lastCommittedSegmentInfos.userData.get(Engine.HISTORY_UUID_KEY). }
false;public;0;4;;@Override public long getWritingBytes() {     return 0. }
false;public;0;4;;@Override public long getIndexThrottleTimeInMillis() {     return 0. }
false;public;0;4;;@Override public boolean isThrottled() {     return false. }
false;public;1;5;;@Override public IndexResult index(Index index) {     assert false : "this should not be called".     throw new UnsupportedOperationException("indexing is not supported on a read-only engine"). }
false;public;1;5;;@Override public DeleteResult delete(Delete delete) {     assert false : "this should not be called".     throw new UnsupportedOperationException("deletes are not supported on a read-only engine"). }
false;public;1;5;;@Override public NoOpResult noOp(NoOp noOp) {     assert false : "this should not be called".     throw new UnsupportedOperationException("no-ops are not supported on a read-only engine"). }
false;public;0;4;;@Override public boolean isTranslogSyncNeeded() {     return false. }
false;public;1;4;;@Override public boolean ensureTranslogSynced(Stream<Translog.Location> locations) {     return false. }
false;public;0;3;;@Override public void syncTranslog() { }
false;public;0;4;;@Override public Closeable acquireRetentionLock() {     return () -> {     }. }
false;public;5;8;;@Override public Translog.Snapshot newChangesSnapshot(String source, MapperService mapperService, long fromSeqNo, long toSeqNo, boolean requiredFullRange) throws IOException {     if (engineConfig.getIndexSettings().isSoftDeleteEnabled() == false) {         throw new IllegalStateException("accessing changes snapshot requires soft-deletes enabled").     }     return readHistoryOperations(source, mapperService, fromSeqNo). }
false;public;3;4;;@Override public Translog.Snapshot readHistoryOperations(String source, MapperService mapperService, long startingSeqNo) throws IOException {     return newEmptySnapshot(). }
false;public;3;4;;@Override public int estimateNumberOfHistoryOperations(String source, MapperService mapperService, long startingSeqNo) throws IOException {     return 0. }
false;public;3;4;;@Override public boolean hasCompleteOperationHistory(String source, MapperService mapperService, long startingSeqNo) throws IOException {     return false. }
false;public;0;4;;@Override public long getMinRetainedSeqNo() {     throw new UnsupportedOperationException(). }
false;public;0;4;;@Override public TranslogStats getTranslogStats() {     return translogStats. }
false;public;0;4;;@Override public Translog.Location getTranslogLastWriteLocation() {     return new Translog.Location(0, 0, 0). }
false;public;0;4;;@Override public long getLocalCheckpoint() {     return seqNoStats.getLocalCheckpoint(). }
false;public;1;4;;@Override public SeqNoStats getSeqNoStats(long globalCheckpoint) {     return new SeqNoStats(seqNoStats.getMaxSeqNo(), seqNoStats.getLocalCheckpoint(), globalCheckpoint). }
false;public;0;4;;@Override public long getLastSyncedGlobalCheckpoint() {     return seqNoStats.getGlobalCheckpoint(). }
false;public;0;4;;@Override public long getIndexBufferRAMBytesUsed() {     return 0. }
false;public;1;4;;@Override public List<Segment> segments(boolean verbose) {     return Arrays.asList(getSegmentInfo(lastCommittedSegmentInfos, verbose)). }
false;public;1;5;;@Override public void refresh(String source) { // we could allow refreshes if we want down the road the searcher manager will then reflect changes to a rw-engine // opened side-by-side }
false;public;1;4;;@Override public boolean maybeRefresh(String source) throws EngineException {     return false. }
false;public;0;3;;@Override public void writeIndexingBuffer() throws EngineException { }
false;public;0;4;;@Override public boolean shouldPeriodicallyFlush() {     return false. }
false;public;2;5;;@Override public SyncedFlushResult syncFlush(String syncId, CommitId expectedCommitId) {     // we can't do synced flushes this would require an indexWriter which we don't have     throw new UnsupportedOperationException("syncedFlush is not supported on a read-only engine"). }
false;public;2;4;;@Override public CommitId flush(boolean force, boolean waitIfOngoing) throws EngineException {     return new CommitId(lastCommittedSegmentInfos.getId()). }
false;public;5;4;;@Override public void forceMerge(boolean flush, int maxNumSegments, boolean onlyExpungeDeletes, boolean upgrade, boolean upgradeOnlyAncientSegments) { }
false;public;1;5;;@Override public IndexCommitRef acquireLastIndexCommit(boolean flushFirst) {     store.incRef().     return new IndexCommitRef(indexCommit, store::decRef). }
false;public;0;4;;@Override public IndexCommitRef acquireSafeIndexCommit() {     return acquireLastIndexCommit(false). }
false;public;0;3;;@Override public void activateThrottling() { }
false;public;0;3;;@Override public void deactivateThrottling() { }
false;public;0;3;;@Override public void trimUnreferencedTranslogFiles() { }
false;public;0;4;;@Override public boolean shouldRollTranslogGeneration() {     return false. }
false;public;0;3;;@Override public void rollTranslogGeneration() { }
false;public;1;4;;@Override public int restoreLocalHistoryFromTranslog(TranslogRecoveryRunner translogRecoveryRunner) {     return 0. }
false;public;1;4;;@Override public int fillSeqNoGaps(long primaryTerm) {     return 0. }
false;public;2;12;;@Override public Engine recoverFromTranslog(final TranslogRecoveryRunner translogRecoveryRunner, final long recoverUpToSeqNo) {     try (ReleasableLock lock = readLock.acquire()) {         ensureOpen().         try (Translog.Snapshot snapshot = newEmptySnapshot()) {             translogRecoveryRunner.run(this, snapshot).         } catch (final Exception e) {             throw new EngineException(shardId, "failed to recover from empty translog snapshot", e).         }     }     return this. }
false;public;0;3;;@Override public void skipTranslogRecovery() { }
false;public;2;3;;@Override public void trimOperationsFromTranslog(long belowTerm, long aboveSeqNo) { }
false;public;0;3;;@Override public void maybePruneDeletes() { }
false;public;0;4;;@Override public DocsStats docStats() {     return docsStats. }
false;public;1;4;;@Override public void updateMaxUnsafeAutoIdTimestamp(long newTimestamp) { }
false;public;0;4;;@Override public void initializeMaxSeqNoOfUpdatesOrDeletes() {     advanceMaxSeqNoOfUpdatesOrDeletes(seqNoStats.getMaxSeqNo()). }
false;protected;2;3;;protected void processReaders(IndexReader reader, IndexReader previousReader) {     searcherFactory.processReaders(reader, previousReader). }
false;public;0;4;;@Override public boolean refreshNeeded() {     return false. }
false;public;0;3;;@Override public void close() { }
false;public;0;4;;@Override public int totalOperations() {     return 0. }
false;public;0;4;;@Override public Translog.Operation next() {     return null. }
false;private;0;17;;private Translog.Snapshot newEmptySnapshot() {     return new Translog.Snapshot() {          @Override         public void close() {         }          @Override         public int totalOperations() {             return 0.         }          @Override         public Translog.Operation next() {             return null.         }     }. }
