commented;modifiers;parameterAmount;loc;comment;code
true;public;0;3;/**  * Returns list of snapshots  *  * @return list of snapshots  */ ;/**  * Returns list of snapshots  *  * @return list of snapshots  */ public List<SnapshotFiles> snapshots() {     return this.shardSnapshots. }
true;public;1;3;/**  * Finds reference to a snapshotted file by its original name  *  * @param physicalName original name  * @return a list of file infos that match specified physical file or null if the file is not present in any of snapshots  */ ;/**  * Finds reference to a snapshotted file by its original name  *  * @param physicalName original name  * @return a list of file infos that match specified physical file or null if the file is not present in any of snapshots  */ public List<FileInfo> findPhysicalIndexFiles(String physicalName) {     return physicalFiles.get(physicalName). }
true;public;1;3;/**  * Finds reference to a snapshotted file by its snapshot name  *  * @param name file name  * @return file info or null if file is not present in any of snapshots  */ ;/**  * Finds reference to a snapshotted file by its snapshot name  *  * @param name file name  * @return file info or null if file is not present in any of snapshots  */ public FileInfo findNameFile(String name) {     return files.get(name). }
false;public;0;4;;@Override public Iterator<SnapshotFiles> iterator() {     return shardSnapshots.iterator(). }
true;public;2;22;/**  * Writes index file for the shard in the following format.  * <pre>  * <code>  * {  *     "files": [{  *         "name": "__3",  *         "physical_name": "_0.si",  *         "length": 310,  *         "checksum": "1tpsg3p",  *         "written_by": "5.1.0",  *         "meta_hash": "P9dsFxNMdWNlb......"  *     }, {  *         "name": "__2",  *         "physical_name": "segments_2",  *         "length": 150,  *         "checksum": "11qjpz6",  *         "written_by": "5.1.0",  *         "meta_hash": "P9dsFwhzZWdtZ......."  *     }, {  *         "name": "__1",  *         "physical_name": "_0.cfe",  *         "length": 363,  *         "checksum": "er9r9g",  *         "written_by": "5.1.0"  *     }, {  *         "name": "__0",  *         "physical_name": "_0.cfs",  *         "length": 3354,  *         "checksum": "491liz",  *         "written_by": "5.1.0"  *     }, {  *         "name": "__4",  *         "physical_name": "segments_3",  *         "length": 150,  *         "checksum": "134567",  *         "written_by": "5.1.0",  *         "meta_hash": "P9dsFwhzZWdtZ......."  *     }],  *     "snapshots": {  *         "snapshot_1": {  *             "files": ["__0", "__1", "__2", "__3"]  *         },  *         "snapshot_2": {  *             "files": ["__0", "__1", "__2", "__4"]  *         }  *     }  * }  * }  * </code>  * </pre>  */ ;/**  * Writes index file for the shard in the following format.  * <pre>  * <code>  * {  *     "files": [{  *         "name": "__3",  *         "physical_name": "_0.si",  *         "length": 310,  *         "checksum": "1tpsg3p",  *         "written_by": "5.1.0",  *         "meta_hash": "P9dsFxNMdWNlb......"  *     }, {  *         "name": "__2",  *         "physical_name": "segments_2",  *         "length": 150,  *         "checksum": "11qjpz6",  *         "written_by": "5.1.0",  *         "meta_hash": "P9dsFwhzZWdtZ......."  *     }, {  *         "name": "__1",  *         "physical_name": "_0.cfe",  *         "length": 363,  *         "checksum": "er9r9g",  *         "written_by": "5.1.0"  *     }, {  *         "name": "__0",  *         "physical_name": "_0.cfs",  *         "length": 3354,  *         "checksum": "491liz",  *         "written_by": "5.1.0"  *     }, {  *         "name": "__4",  *         "physical_name": "segments_3",  *         "length": 150,  *         "checksum": "134567",  *         "written_by": "5.1.0",  *         "meta_hash": "P9dsFwhzZWdtZ......."  *     }],  *     "snapshots": {  *         "snapshot_1": {  *             "files": ["__0", "__1", "__2", "__3"]  *         },  *         "snapshot_2": {  *             "files": ["__0", "__1", "__2", "__4"]  *         }  *     }  * }  * }  * </code>  * </pre>  */ @Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {     // First we list all blobs with their file infos:     builder.startArray(Fields.FILES).     for (Map.Entry<String, FileInfo> entry : files.entrySet()) {         FileInfo.toXContent(entry.getValue(), builder, params).     }     builder.endArray().     // Then we list all snapshots with list of all blobs that are used by the snapshot     builder.startObject(Fields.SNAPSHOTS).     for (SnapshotFiles snapshot : shardSnapshots) {         builder.startObject(snapshot.snapshot()).         builder.startArray(Fields.FILES).         for (FileInfo fileInfo : snapshot.indexFiles()) {             builder.value(fileInfo.name()).         }         builder.endArray().         builder.endObject().     }     builder.endObject().     return builder. }
false;public,static;1;68;;public static BlobStoreIndexShardSnapshots fromXContent(XContentParser parser) throws IOException {     XContentParser.Token token = parser.currentToken().     if (token == null) {         // New parser         token = parser.nextToken().     }     Map<String, List<String>> snapshotsMap = new HashMap<>().     Map<String, FileInfo> files = new HashMap<>().     if (token == XContentParser.Token.START_OBJECT) {         while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {             if (token != XContentParser.Token.FIELD_NAME) {                 throw new ElasticsearchParseException("unexpected token [{}]", token).             }             String currentFieldName = parser.currentName().             token = parser.nextToken().             if (token == XContentParser.Token.START_ARRAY) {                 if (ParseFields.FILES.match(currentFieldName, parser.getDeprecationHandler()) == false) {                     throw new ElasticsearchParseException("unknown array [{}]", currentFieldName).                 }                 while (parser.nextToken() != XContentParser.Token.END_ARRAY) {                     FileInfo fileInfo = FileInfo.fromXContent(parser).                     files.put(fileInfo.name(), fileInfo).                 }             } else if (token == XContentParser.Token.START_OBJECT) {                 if (ParseFields.SNAPSHOTS.match(currentFieldName, parser.getDeprecationHandler()) == false) {                     throw new ElasticsearchParseException("unknown object [{}]", currentFieldName).                 }                 while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {                     if (token != XContentParser.Token.FIELD_NAME) {                         throw new ElasticsearchParseException("unknown object [{}]", currentFieldName).                     }                     String snapshot = parser.currentName().                     if (parser.nextToken() != XContentParser.Token.START_OBJECT) {                         throw new ElasticsearchParseException("unknown object [{}]", currentFieldName).                     }                     while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {                         if (token == XContentParser.Token.FIELD_NAME) {                             currentFieldName = parser.currentName().                             if (parser.nextToken() == XContentParser.Token.START_ARRAY) {                                 if (ParseFields.FILES.match(currentFieldName, parser.getDeprecationHandler()) == false) {                                     throw new ElasticsearchParseException("unknown array [{}]", currentFieldName).                                 }                                 List<String> fileNames = new ArrayList<>().                                 while (parser.nextToken() != XContentParser.Token.END_ARRAY) {                                     fileNames.add(parser.text()).                                 }                                 snapshotsMap.put(snapshot, fileNames).                             }                         }                     }                 }             } else {                 throw new ElasticsearchParseException("unexpected token [{}]", token).             }         }     }     List<SnapshotFiles> snapshots = new ArrayList<>(snapshotsMap.size()).     for (Map.Entry<String, List<String>> entry : snapshotsMap.entrySet()) {         List<FileInfo> fileInfosBuilder = new ArrayList<>().         for (String file : entry.getValue()) {             FileInfo fileInfo = files.get(file).             assert fileInfo != null.             fileInfosBuilder.add(fileInfo).         }         snapshots.add(new SnapshotFiles(entry.getKey(), Collections.unmodifiableList(fileInfosBuilder))).     }     return new BlobStoreIndexShardSnapshots(files, Collections.unmodifiableList(snapshots)). }
