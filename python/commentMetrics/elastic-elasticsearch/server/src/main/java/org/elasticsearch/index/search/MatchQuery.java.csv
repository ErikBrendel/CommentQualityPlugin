commented;modifiers;parameterAmount;loc;comment;code
false;public,static;1;9;;public static Type readFromStream(StreamInput in) throws IOException {     int ord = in.readVInt().     for (Type type : Type.values()) {         if (type.ordinal == ord) {             return type.         }     }     throw new ElasticsearchException("unknown serialized type [" + ord + "]"). }
false;public;1;4;;@Override public void writeTo(StreamOutput out) throws IOException {     out.writeVInt(this.ordinal). }
false;public,static;1;9;;public static ZeroTermsQuery readFromStream(StreamInput in) throws IOException {     int ord = in.readVInt().     for (ZeroTermsQuery zeroTermsQuery : ZeroTermsQuery.values()) {         if (zeroTermsQuery.ordinal == ord) {             return zeroTermsQuery.         }     }     throw new ElasticsearchException("unknown serialized type [" + ord + "]"). }
false;public;1;4;;@Override public void writeTo(StreamOutput out) throws IOException {     out.writeVInt(this.ordinal). }
false;public;1;6;;public void setAnalyzer(String analyzerName) {     this.analyzer = context.getMapperService().getIndexAnalyzers().get(analyzerName).     if (analyzer == null) {         throw new IllegalArgumentException("No analyzer found for [" + analyzerName + "]").     } }
false;public;1;3;;public void setAnalyzer(Analyzer analyzer) {     this.analyzer = analyzer. }
false;public;1;3;;public void setOccur(BooleanClause.Occur occur) {     this.occur = occur. }
false;public;1;3;;public void setCommonTermsCutoff(Float cutoff) {     this.commonTermsCutoff = cutoff. }
false;public;1;3;;public void setEnablePositionIncrements(boolean enablePositionIncrements) {     this.enablePositionIncrements = enablePositionIncrements. }
false;public;1;3;;public void setPhraseSlop(int phraseSlop) {     this.phraseSlop = phraseSlop. }
false;public;1;3;;public void setFuzziness(Fuzziness fuzziness) {     this.fuzziness = fuzziness. }
false;public;1;3;;public void setFuzzyPrefixLength(int fuzzyPrefixLength) {     this.fuzzyPrefixLength = fuzzyPrefixLength. }
false;public;1;4;;public void setMaxExpansions(int maxExpansions) {     this.maxExpansions = maxExpansions.     this.spanRewriteMethod = new SpanBooleanQueryRewriteWithMaxClause(maxExpansions, false). }
false;public;1;3;;public void setTranspositions(boolean transpositions) {     this.transpositions = transpositions. }
false;public;1;3;;public void setFuzzyRewriteMethod(MultiTermQuery.RewriteMethod fuzzyRewriteMethod) {     this.fuzzyRewriteMethod = fuzzyRewriteMethod. }
false;public;1;3;;public void setLenient(boolean lenient) {     this.lenient = lenient. }
false;public;1;3;;public void setZeroTermsQuery(ZeroTermsQuery zeroTermsQuery) {     this.zeroTermsQuery = zeroTermsQuery. }
false;public;1;3;;public void setAutoGenerateSynonymsPhraseQuery(boolean enabled) {     this.autoGenerateSynonymsPhraseQuery = enabled. }
false;public;3;21;;public Query parse(Type type, String fieldName, Object value) throws IOException {     final MappedFieldType fieldType = context.fieldMapper(fieldName).     if (fieldType == null) {         return newUnmappedFieldQuery(fieldName).     }     Analyzer analyzer = getAnalyzer(fieldType, type == Type.PHRASE || type == Type.PHRASE_PREFIX).     assert analyzer != null.     MatchQueryBuilder builder = new MatchQueryBuilder(analyzer, fieldType).     /*          * If a keyword analyzer is used, we know that further analysis isn't          * needed and can immediately return a term query.          */     if (analyzer == Lucene.KEYWORD_ANALYZER && type != Type.PHRASE_PREFIX) {         return builder.newTermQuery(new Term(fieldName, value.toString())).     }     return parseInternal(type, fieldName, builder, value). }
false;protected,final;4;25;;protected final Query parseInternal(Type type, String fieldName, MatchQueryBuilder builder, Object value) throws IOException {     final Query query.     switch(type) {         case BOOLEAN:             if (commonTermsCutoff == null) {                 query = builder.createBooleanQuery(fieldName, value.toString(), occur).             } else {                 query = createCommonTermsQuery(builder, fieldName, value.toString(), occur, occur, commonTermsCutoff).             }             break.         case PHRASE:             query = builder.createPhraseQuery(fieldName, value.toString(), phraseSlop).             break.         case PHRASE_PREFIX:             query = builder.createPhrasePrefixQuery(fieldName, value.toString(), phraseSlop).             break.         default:             throw new IllegalStateException("No type found for [" + type + "]").     }     return query == null ? zeroTermsQuery() : query. }
false;private;6;9;;private Query createCommonTermsQuery(MatchQueryBuilder builder, String field, String queryText, Occur highFreqOccur, Occur lowFreqOccur, float maxTermFrequency) {     Query booleanQuery = builder.createBooleanQuery(field, queryText, lowFreqOccur).     if (booleanQuery != null && booleanQuery instanceof BooleanQuery) {         BooleanQuery bq = (BooleanQuery) booleanQuery.         return boolToExtendedCommonTermsQuery(bq, highFreqOccur, lowFreqOccur, maxTermFrequency).     }     return booleanQuery. }
false;private;4;13;;private Query boolToExtendedCommonTermsQuery(BooleanQuery bq, Occur highFreqOccur, Occur lowFreqOccur, float maxTermFrequency) {     ExtendedCommonTermsQuery query = new ExtendedCommonTermsQuery(highFreqOccur, lowFreqOccur, maxTermFrequency).     for (BooleanClause clause : bq.clauses()) {         if ((clause.getQuery() instanceof TermQuery) == false) {             return bq.         }         query.add(((TermQuery) clause.getQuery()).getTerm()).     }     return query. }
false;protected;2;7;;protected Analyzer getAnalyzer(MappedFieldType fieldType, boolean quoted) {     if (analyzer == null) {         return quoted ? context.getSearchQuoteAnalyzer(fieldType) : context.getSearchAnalyzer(fieldType).     } else {         return analyzer.     } }
false;protected;0;12;;protected Query zeroTermsQuery() {     switch(zeroTermsQuery) {         case NULL:             return null.         case NONE:             return Queries.newMatchNoDocsQuery("Matching no documents because no terms present").         case ALL:             return Queries.newMatchAllQuery().         default:             throw new IllegalStateException("unknown zeroTermsQuery " + zeroTermsQuery).     } }
false;private;1;3;;private boolean hasPositions(MappedFieldType fieldType) {     return fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0. }
false;protected;6;7;;@Override protected Query createFieldQuery(Analyzer analyzer, BooleanClause.Occur operator, String field, String queryText, boolean quoted, int slop) {     assert operator == BooleanClause.Occur.SHOULD || operator == BooleanClause.Occur.MUST.     Type type = quoted ? Type.PHRASE : Type.BOOLEAN.     return createQuery(field, queryText, type, operator, slop). }
false;public;3;3;;public Query createPhrasePrefixQuery(String field, String queryText, int slop) {     return createQuery(field, queryText, Type.PHRASE_PREFIX, occur, slop). }
false;private;5;82;;private Query createFieldQuery(TokenStream source, Type type, BooleanClause.Occur operator, String field, int phraseSlop) {     assert operator == BooleanClause.Occur.SHOULD || operator == BooleanClause.Occur.MUST.     // Build an appropriate query based on the analysis chain.     try (CachingTokenFilter stream = new CachingTokenFilter(source)) {         TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class).         PositionIncrementAttribute posIncAtt = stream.addAttribute(PositionIncrementAttribute.class).         PositionLengthAttribute posLenAtt = stream.addAttribute(PositionLengthAttribute.class).         if (termAtt == null) {             return null.         }         // phase 1: read through the stream and assess the situation:         // counting the number of tokens/positions and marking if we have any synonyms.         int numTokens = 0.         int positionCount = 0.         boolean hasSynonyms = false.         boolean isGraph = false.         stream.reset().         while (stream.incrementToken()) {             numTokens++.             int positionIncrement = posIncAtt.getPositionIncrement().             if (positionIncrement != 0) {                 positionCount += positionIncrement.             } else {                 hasSynonyms = true.             }             int positionLength = posLenAtt.getPositionLength().             if (enableGraphQueries && positionLength > 1) {                 isGraph = true.             }         }         // formulate a single term, boolean, or phrase.         if (numTokens == 0) {             return null.         } else if (numTokens == 1) {             // single term             if (type == Type.PHRASE_PREFIX) {                 return analyzePhrasePrefix(field, stream, phraseSlop, positionCount).             } else {                 return analyzeTerm(field, stream).             }         } else if (isGraph) {             // graph             if (type == Type.PHRASE || type == Type.PHRASE_PREFIX) {                 return analyzeGraphPhrase(stream, field, type, phraseSlop).             } else {                 return analyzeGraphBoolean(field, stream, operator).             }         } else if (type == Type.PHRASE && positionCount > 1) {             // phrase             if (hasSynonyms) {                 // complex phrase with synonyms                 return analyzeMultiPhrase(field, stream, phraseSlop).             } else {                 // simple phrase                 return analyzePhrase(field, stream, phraseSlop).             }         } else if (type == Type.PHRASE_PREFIX) {             // phrase prefix             return analyzePhrasePrefix(field, stream, phraseSlop, positionCount).         } else {             // boolean             if (positionCount == 1) {                 // only one position, with synonyms                 return analyzeBoolean(field, stream).             } else {                 // complex case: multiple positions                 return analyzeMultiBoolean(field, stream, operator).             }         }     } catch (IOException e) {         throw new RuntimeException("Error analyzing query text", e).     } }
false;private;5;20;;private Query createQuery(String field, String queryText, Type type, BooleanClause.Occur operator, int phraseSlop) {     // query based on the analysis chain.     try (TokenStream source = analyzer.tokenStream(field, queryText)) {         if (source.hasAttribute(DisableGraphAttribute.class)) {             /*                      * A {@link TokenFilter} in this {@link TokenStream} disabled the graph analysis to avoid                      * paths explosion. See {@link org.elasticsearch.index.analysis.ShingleTokenFilterFactory} for details.                      */             setEnableGraphQueries(false).         }         try {             return createFieldQuery(source, type, operator, field, phraseSlop).         } finally {             setEnableGraphQueries(true).         }     } catch (IOException e) {         throw new RuntimeException("Error analyzing query text", e).     } }
false;private;2;11;;private SpanQuery newSpanQuery(Term[] terms, boolean prefix) {     if (terms.length == 1) {         return prefix ? fieldType.spanPrefixQuery(terms[0].text(), spanRewriteMethod, context) : new SpanTermQuery(terms[0]).     }     SpanQuery[] spanQueries = new SpanQuery[terms.length].     for (int i = 0. i < terms.length. i++) {         spanQueries[i] = prefix ? new SpanTermQuery(terms[i]) : fieldType.spanPrefixQuery(terms[i].text(), spanRewriteMethod, context).     }     return new SpanOrQuery(spanQueries). }
false;protected;2;4;;@Override protected SpanQuery createSpanQuery(TokenStream in, String field) throws IOException {     return createSpanQuery(in, field, false). }
false;private;3;31;;private SpanQuery createSpanQuery(TokenStream in, String field, boolean prefix) throws IOException {     TermToBytesRefAttribute termAtt = in.getAttribute(TermToBytesRefAttribute.class).     PositionIncrementAttribute posIncAtt = in.getAttribute(PositionIncrementAttribute.class).     if (termAtt == null) {         return null.     }     SpanNearQuery.Builder builder = new SpanNearQuery.Builder(field, true).     Term lastTerm = null.     while (in.incrementToken()) {         if (posIncAtt.getPositionIncrement() > 1) {             builder.addGap(posIncAtt.getPositionIncrement() - 1).         }         if (lastTerm != null) {             builder.addClause(new SpanTermQuery(lastTerm)).         }         lastTerm = new Term(field, termAtt.getBytesRef()).     }     if (lastTerm != null) {         SpanQuery spanQuery = prefix ? fieldType.spanPrefixQuery(lastTerm.text(), spanRewriteMethod, context) : new SpanTermQuery(lastTerm).         builder.addClause(spanQuery).     }     SpanNearQuery query = builder.build().     SpanQuery[] clauses = query.getClauses().     if (clauses.length == 1) {         return clauses[0].     } else {         return query.     } }
false;protected;1;25;;@Override protected Query newTermQuery(Term term) {     Supplier<Query> querySupplier.     if (fuzziness != null) {         querySupplier = () -> {             Query query = fieldType.fuzzyQuery(term.text(), fuzziness, fuzzyPrefixLength, maxExpansions, transpositions).             if (query instanceof FuzzyQuery) {                 QueryParsers.setRewriteMethod((FuzzyQuery) query, fuzzyRewriteMethod).             }             return query.         }.     } else {         querySupplier = () -> fieldType.termQuery(term.bytes(), context).     }     try {         Query query = querySupplier.get().         return query.     } catch (RuntimeException e) {         if (lenient) {             return newLenientFieldQuery(fieldType.name(), e).         } else {             throw e.         }     } }
false;protected;3;12;;@Override protected Query analyzePhrase(String field, TokenStream stream, int slop) throws IOException {     try {         checkForPositions(field).         return fieldType.phraseQuery(stream, slop, enablePositionIncrements).     } catch (IllegalArgumentException | IllegalStateException e) {         if (lenient) {             return newLenientFieldQuery(field, e).         }         throw e.     } }
false;protected;3;12;;@Override protected Query analyzeMultiPhrase(String field, TokenStream stream, int slop) throws IOException {     try {         checkForPositions(field).         return fieldType.multiPhraseQuery(stream, slop, enablePositionIncrements).     } catch (IllegalArgumentException | IllegalStateException e) {         if (lenient) {             return newLenientFieldQuery(field, e).         }         throw e.     } }
false;private;4;13;;private Query analyzePhrasePrefix(String field, TokenStream stream, int slop, int positionCount) throws IOException {     try {         if (positionCount > 1) {             checkForPositions(field).         }         return fieldType.phrasePrefixQuery(stream, slop, maxExpansions).     } catch (IllegalArgumentException | IllegalStateException e) {         if (lenient) {             return newLenientFieldQuery(field, e).         }         throw e.     } }
false;private;4;82;;private Query analyzeGraphPhrase(TokenStream source, String field, Type type, int slop) throws IOException {     assert type == Type.PHRASE_PREFIX || type == Type.PHRASE.     source.reset().     GraphTokenStreamFiniteStrings graph = new GraphTokenStreamFiniteStrings(source).     if (phraseSlop > 0) {         /*                  * Creates a boolean query from the graph token stream by extracting all the finite strings from the graph                  * and using them to create phrase queries with the appropriate slop.                  */         BooleanQuery.Builder builder = new BooleanQuery.Builder().         Iterator<TokenStream> it = graph.getFiniteStrings().         while (it.hasNext()) {             Query query = createFieldQuery(it.next(), type, BooleanClause.Occur.MUST, field, slop).             if (query != null) {                 builder.add(query, BooleanClause.Occur.SHOULD).             }         }         return builder.build().     }     /*              * Creates a span near (phrase) query from a graph token stream.              * The articulation points of the graph are visited in order and the queries              * created at each point are merged in the returned near query.              */     List<SpanQuery> clauses = new ArrayList<>().     int[] articulationPoints = graph.articulationPoints().     int lastState = 0.     int maxClauseCount = BooleanQuery.getMaxClauseCount().     for (int i = 0. i <= articulationPoints.length. i++) {         int start = lastState.         int end = -1.         if (i < articulationPoints.length) {             end = articulationPoints[i].         }         lastState = end.         final SpanQuery queryPos.         boolean endPrefix = end == -1 && type == Type.PHRASE_PREFIX.         if (graph.hasSidePath(start)) {             List<SpanQuery> queries = new ArrayList<>().             Iterator<TokenStream> it = graph.getFiniteStrings(start, end).             while (it.hasNext()) {                 TokenStream ts = it.next().                 SpanQuery q = createSpanQuery(ts, field, endPrefix).                 if (q != null) {                     if (queries.size() >= maxClauseCount) {                         throw new BooleanQuery.TooManyClauses().                     }                     queries.add(q).                 }             }             if (queries.size() > 0) {                 queryPos = new SpanOrQuery(queries.toArray(new SpanQuery[0])).             } else {                 queryPos = null.             }         } else {             Term[] terms = graph.getTerms(field, start).             assert terms.length > 0.             if (terms.length >= maxClauseCount) {                 throw new BooleanQuery.TooManyClauses().             }             queryPos = newSpanQuery(terms, endPrefix).         }         if (queryPos != null) {             if (clauses.size() >= maxClauseCount) {                 throw new BooleanQuery.TooManyClauses().             }             clauses.add(queryPos).         }     }     if (clauses.isEmpty()) {         return null.     } else if (clauses.size() == 1) {         return clauses.get(0).     } else {         return new SpanNearQuery(clauses.toArray(new SpanQuery[0]), 0, true).     } }
false;private;1;5;;private void checkForPositions(String field) {     if (hasPositions(fieldType) == false) {         throw new IllegalStateException("field:[" + field + "] was indexed without position data. cannot run PhraseQuery").     } }
