commented;modifiers;parameterAmount;loc;comment;code
false;private;4;12;;private Map<String, AliasFilter> buildPerIndexAliasFilter(SearchRequest request, ClusterState clusterState, Index[] concreteIndices, Map<String, AliasFilter> remoteAliasMap) {     final Map<String, AliasFilter> aliasFilterMap = new HashMap<>().     for (Index index : concreteIndices) {         clusterState.blocks().indexBlockedRaiseException(ClusterBlockLevel.READ, index.getName()).         AliasFilter aliasFilter = searchService.buildAliasFilter(clusterState, index.getName(), request.indices()).         assert aliasFilter != null.         aliasFilterMap.put(index.getUUID(), aliasFilter).     }     aliasFilterMap.putAll(remoteAliasMap).     return aliasFilterMap. }
false;private;2;21;;private Map<String, Float> resolveIndexBoosts(SearchRequest searchRequest, ClusterState clusterState) {     if (searchRequest.source() == null) {         return Collections.emptyMap().     }     SearchSourceBuilder source = searchRequest.source().     if (source.indexBoosts() == null) {         return Collections.emptyMap().     }     Map<String, Float> concreteIndexBoosts = new HashMap<>().     for (SearchSourceBuilder.IndexBoost ib : source.indexBoosts()) {         Index[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterState, searchRequest.indicesOptions(), ib.getIndex()).         for (Index concreteIndex : concreteIndices) {             concreteIndexBoosts.putIfAbsent(concreteIndex.getUUID(), ib.getBoost()).         }     }     return Collections.unmodifiableMap(concreteIndexBoosts). }
false;;0;3;;long getAbsoluteStartMillis() {     return absoluteStartMillis. }
false;;0;3;;long buildTookInMillis() {     return TimeUnit.NANOSECONDS.toMillis(relativeCurrentNanosProvider.getAsLong() - relativeStartNanos). }
false;protected;3;50;;@Override protected void doExecute(Task task, SearchRequest searchRequest, ActionListener<SearchResponse> listener) {     final long relativeStartNanos = System.nanoTime().     final SearchTimeProvider timeProvider = new SearchTimeProvider(searchRequest.getOrCreateAbsoluteStartMillis(), relativeStartNanos, System::nanoTime).     ActionListener<SearchSourceBuilder> rewriteListener = ActionListener.wrap(source -> {         if (source != searchRequest.source()) {             // only set it if it changed - we don't allow null values to be set but it might be already null. this way we catch             // situations when source is rewritten to null due to a bug             searchRequest.source(source).         }         final ClusterState clusterState = clusterService.state().         final Map<String, OriginalIndices> remoteClusterIndices = remoteClusterService.groupIndices(searchRequest.indicesOptions(), searchRequest.indices(), idx -> indexNameExpressionResolver.hasIndexOrAlias(idx, clusterState)).         OriginalIndices localIndices = remoteClusterIndices.remove(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY).         if (remoteClusterIndices.isEmpty()) {             executeLocalSearch(task, timeProvider, searchRequest, localIndices, clusterState, listener).         } else {             if (shouldMinimizeRoundtrips(searchRequest)) {                 ccsRemoteReduce(searchRequest, localIndices, remoteClusterIndices, timeProvider, searchService::createReduceContext, remoteClusterService, threadPool, listener, (r, l) -> executeLocalSearch(task, timeProvider, r, localIndices, clusterState, l)).             } else {                 AtomicInteger skippedClusters = new AtomicInteger(0).                 collectSearchShards(searchRequest.indicesOptions(), searchRequest.preference(), searchRequest.routing(), skippedClusters, remoteClusterIndices, remoteClusterService, threadPool, ActionListener.wrap(searchShardsResponses -> {                     List<SearchShardIterator> remoteShardIterators = new ArrayList<>().                     Map<String, AliasFilter> remoteAliasFilters = new HashMap<>().                     BiFunction<String, String, DiscoveryNode> clusterNodeLookup = processRemoteShards(searchShardsResponses, remoteClusterIndices, remoteShardIterators, remoteAliasFilters).                     int localClusters = localIndices == null ? 0 : 1.                     int totalClusters = remoteClusterIndices.size() + localClusters.                     int successfulClusters = searchShardsResponses.size() + localClusters.                     executeSearch((SearchTask) task, timeProvider, searchRequest, localIndices, remoteShardIterators, clusterNodeLookup, clusterState, remoteAliasFilters, listener, new SearchResponse.Clusters(totalClusters, successfulClusters, skippedClusters.get())).                 }, listener::onFailure)).             }         }     }, listener::onFailure).     if (searchRequest.source() == null) {         rewriteListener.onResponse(searchRequest.source()).     } else {         Rewriteable.rewriteAndFetch(searchRequest.source(), searchService.getRewriteContext(timeProvider::getAbsoluteStartMillis), rewriteListener).     } }
false;static;1;11;;static boolean shouldMinimizeRoundtrips(SearchRequest searchRequest) {     if (searchRequest.isCcsMinimizeRoundtrips() == false) {         return false.     }     if (searchRequest.scroll() != null) {         return false.     }     SearchSourceBuilder source = searchRequest.source().     return source == null || source.collapse() == null || source.collapse().getInnerHits() == null || source.collapse().getInnerHits().isEmpty(). }
false;public;1;12;;@Override public void onResponse(SearchResponse searchResponse) {     Map<String, ProfileShardResult> profileResults = searchResponse.getProfileResults().     SearchProfileShardResults profile = profileResults == null || profileResults.isEmpty() ? null : new SearchProfileShardResults(profileResults).     InternalSearchResponse internalSearchResponse = new InternalSearchResponse(searchResponse.getHits(), (InternalAggregations) searchResponse.getAggregations(), searchResponse.getSuggest(), profile, searchResponse.isTimedOut(), searchResponse.isTerminatedEarly(), searchResponse.getNumReducePhases()).     listener.onResponse(new SearchResponse(internalSearchResponse, searchResponse.getScrollId(), searchResponse.getTotalShards(), searchResponse.getSuccessfulShards(), searchResponse.getSkippedShards(), timeProvider.buildTookInMillis(), searchResponse.getShardFailures(), new SearchResponse.Clusters(1, 1, 0))). }
false;public;1;8;;@Override public void onFailure(Exception e) {     if (skipUnavailable) {         listener.onResponse(SearchResponse.empty(timeProvider::buildTookInMillis, new SearchResponse.Clusters(1, 0, 1))).     } else {         listener.onFailure(wrapRemoteClusterFailure(clusterAlias, e)).     } }
false;static;9;66;;static void ccsRemoteReduce(SearchRequest searchRequest, OriginalIndices localIndices, Map<String, OriginalIndices> remoteIndices, SearchTimeProvider timeProvider, Function<Boolean, InternalAggregation.ReduceContext> reduceContext, RemoteClusterService remoteClusterService, ThreadPool threadPool, ActionListener<SearchResponse> listener, BiConsumer<SearchRequest, ActionListener<SearchResponse>> localSearchConsumer) {     if (localIndices == null && remoteIndices.size() == 1) {         // if we are searching against a single remote cluster, we simply forward the original search request to such cluster         // and we directly perform final reduction in the remote cluster         Map.Entry<String, OriginalIndices> entry = remoteIndices.entrySet().iterator().next().         String clusterAlias = entry.getKey().         boolean skipUnavailable = remoteClusterService.isSkipUnavailable(clusterAlias).         OriginalIndices indices = entry.getValue().         SearchRequest ccsSearchRequest = SearchRequest.crossClusterSearch(searchRequest, indices.indices(), clusterAlias, timeProvider.getAbsoluteStartMillis(), true).         Client remoteClusterClient = remoteClusterService.getRemoteClusterClient(threadPool, clusterAlias).         remoteClusterClient.search(ccsSearchRequest, new ActionListener<SearchResponse>() {              @Override             public void onResponse(SearchResponse searchResponse) {                 Map<String, ProfileShardResult> profileResults = searchResponse.getProfileResults().                 SearchProfileShardResults profile = profileResults == null || profileResults.isEmpty() ? null : new SearchProfileShardResults(profileResults).                 InternalSearchResponse internalSearchResponse = new InternalSearchResponse(searchResponse.getHits(), (InternalAggregations) searchResponse.getAggregations(), searchResponse.getSuggest(), profile, searchResponse.isTimedOut(), searchResponse.isTerminatedEarly(), searchResponse.getNumReducePhases()).                 listener.onResponse(new SearchResponse(internalSearchResponse, searchResponse.getScrollId(), searchResponse.getTotalShards(), searchResponse.getSuccessfulShards(), searchResponse.getSkippedShards(), timeProvider.buildTookInMillis(), searchResponse.getShardFailures(), new SearchResponse.Clusters(1, 1, 0))).             }              @Override             public void onFailure(Exception e) {                 if (skipUnavailable) {                     listener.onResponse(SearchResponse.empty(timeProvider::buildTookInMillis, new SearchResponse.Clusters(1, 0, 1))).                 } else {                     listener.onFailure(wrapRemoteClusterFailure(clusterAlias, e)).                 }             }         }).     } else {         SearchResponseMerger searchResponseMerger = createSearchResponseMerger(searchRequest.source(), timeProvider, reduceContext).         AtomicInteger skippedClusters = new AtomicInteger(0).         final AtomicReference<Exception> exceptions = new AtomicReference<>().         int totalClusters = remoteIndices.size() + (localIndices == null ? 0 : 1).         final CountDown countDown = new CountDown(totalClusters).         for (Map.Entry<String, OriginalIndices> entry : remoteIndices.entrySet()) {             String clusterAlias = entry.getKey().             boolean skipUnavailable = remoteClusterService.isSkipUnavailable(clusterAlias).             OriginalIndices indices = entry.getValue().             SearchRequest ccsSearchRequest = SearchRequest.crossClusterSearch(searchRequest, indices.indices(), clusterAlias, timeProvider.getAbsoluteStartMillis(), false).             ActionListener<SearchResponse> ccsListener = createCCSListener(clusterAlias, skipUnavailable, countDown, skippedClusters, exceptions, searchResponseMerger, totalClusters, listener).             Client remoteClusterClient = remoteClusterService.getRemoteClusterClient(threadPool, clusterAlias).             remoteClusterClient.search(ccsSearchRequest, ccsListener).         }         if (localIndices != null) {             ActionListener<SearchResponse> ccsListener = createCCSListener(RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY, false, countDown, skippedClusters, exceptions, searchResponseMerger, totalClusters, listener).             // here we provide the empty string a cluster alias, which means no prefix in index name,             // but the coord node will perform non final reduce as it's not null.             SearchRequest ccsLocalSearchRequest = SearchRequest.crossClusterSearch(searchRequest, localIndices.indices(), RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY, timeProvider.getAbsoluteStartMillis(), false).             localSearchConsumer.accept(ccsLocalSearchRequest, ccsListener).         }     } }
false;static;3;20;;static SearchResponseMerger createSearchResponseMerger(SearchSourceBuilder source, SearchTimeProvider timeProvider, Function<Boolean, InternalAggregation.ReduceContext> reduceContextFunction) {     final int from.     final int size.     final int trackTotalHitsUpTo.     if (source == null) {         from = SearchService.DEFAULT_FROM.         size = SearchService.DEFAULT_SIZE.         trackTotalHitsUpTo = SearchContext.DEFAULT_TRACK_TOTAL_HITS_UP_TO.     } else {         from = source.from() == -1 ? SearchService.DEFAULT_FROM : source.from().         size = source.size() == -1 ? SearchService.DEFAULT_SIZE : source.size().         trackTotalHitsUpTo = source.trackTotalHitsUpTo() == null ? SearchContext.DEFAULT_TRACK_TOTAL_HITS_UP_TO : source.trackTotalHitsUpTo().         // here we modify the original source so we can re-use it by setting it to each outgoing search request         source.from(0).         source.size(from + size).     }     return new SearchResponseMerger(from, size, trackTotalHitsUpTo, timeProvider, reduceContextFunction). }
false;;1;4;;@Override void innerOnResponse(ClusterSearchShardsResponse clusterSearchShardsResponse) {     searchShardsResponses.put(clusterAlias, clusterSearchShardsResponse). }
false;;0;4;;@Override Map<String, ClusterSearchShardsResponse> createFinalResponse() {     return searchShardsResponses. }
false;static;8;29;;static void collectSearchShards(IndicesOptions indicesOptions, String preference, String routing, AtomicInteger skippedClusters, Map<String, OriginalIndices> remoteIndicesByCluster, RemoteClusterService remoteClusterService, ThreadPool threadPool, ActionListener<Map<String, ClusterSearchShardsResponse>> listener) {     final CountDown responsesCountDown = new CountDown(remoteIndicesByCluster.size()).     final Map<String, ClusterSearchShardsResponse> searchShardsResponses = new ConcurrentHashMap<>().     final AtomicReference<Exception> exceptions = new AtomicReference<>().     for (Map.Entry<String, OriginalIndices> entry : remoteIndicesByCluster.entrySet()) {         final String clusterAlias = entry.getKey().         boolean skipUnavailable = remoteClusterService.isSkipUnavailable(clusterAlias).         Client clusterClient = remoteClusterService.getRemoteClusterClient(threadPool, clusterAlias).         final String[] indices = entry.getValue().indices().         ClusterSearchShardsRequest searchShardsRequest = new ClusterSearchShardsRequest(indices).indicesOptions(indicesOptions).local(true).preference(preference).routing(routing).         clusterClient.admin().cluster().searchShards(searchShardsRequest, new CCSActionListener<ClusterSearchShardsResponse, Map<String, ClusterSearchShardsResponse>>(clusterAlias, skipUnavailable, responsesCountDown, skippedClusters, exceptions, listener) {              @Override             void innerOnResponse(ClusterSearchShardsResponse clusterSearchShardsResponse) {                 searchShardsResponses.put(clusterAlias, clusterSearchShardsResponse).             }              @Override             Map<String, ClusterSearchShardsResponse> createFinalResponse() {                 return searchShardsResponses.             }         }).     } }
false;;1;4;;@Override void innerOnResponse(SearchResponse searchResponse) {     searchResponseMerger.add(searchResponse). }
false;;0;6;;@Override SearchResponse createFinalResponse() {     SearchResponse.Clusters clusters = new SearchResponse.Clusters(totalClusters, searchResponseMerger.numResponses(), skippedClusters.get()).     return searchResponseMerger.getMergedResponse(clusters). }
false;private,static;8;19;;private static ActionListener<SearchResponse> createCCSListener(String clusterAlias, boolean skipUnavailable, CountDown countDown, AtomicInteger skippedClusters, AtomicReference<Exception> exceptions, SearchResponseMerger searchResponseMerger, int totalClusters, ActionListener<SearchResponse> originalListener) {     return new CCSActionListener<SearchResponse, SearchResponse>(clusterAlias, skipUnavailable, countDown, skippedClusters, exceptions, originalListener) {          @Override         void innerOnResponse(SearchResponse searchResponse) {             searchResponseMerger.add(searchResponse).         }          @Override         SearchResponse createFinalResponse() {             SearchResponse.Clusters clusters = new SearchResponse.Clusters(totalClusters, searchResponseMerger.numResponses(), skippedClusters.get()).             return searchResponseMerger.getMergedResponse(clusters).         }     }. }
false;private;6;5;;private void executeLocalSearch(Task task, SearchTimeProvider timeProvider, SearchRequest searchRequest, OriginalIndices localIndices, ClusterState clusterState, ActionListener<SearchResponse> listener) {     executeSearch((SearchTask) task, timeProvider, searchRequest, localIndices, Collections.emptyList(), (clusterName, nodeId) -> null, clusterState, Collections.emptyMap(), listener, SearchResponse.Clusters.EMPTY). }
false;static;4;45;;static BiFunction<String, String, DiscoveryNode> processRemoteShards(Map<String, ClusterSearchShardsResponse> searchShardsResponses, Map<String, OriginalIndices> remoteIndicesByCluster, List<SearchShardIterator> remoteShardIterators, Map<String, AliasFilter> aliasFilterMap) {     Map<String, Map<String, DiscoveryNode>> clusterToNode = new HashMap<>().     for (Map.Entry<String, ClusterSearchShardsResponse> entry : searchShardsResponses.entrySet()) {         String clusterAlias = entry.getKey().         ClusterSearchShardsResponse searchShardsResponse = entry.getValue().         HashMap<String, DiscoveryNode> idToDiscoveryNode = new HashMap<>().         clusterToNode.put(clusterAlias, idToDiscoveryNode).         for (DiscoveryNode remoteNode : searchShardsResponse.getNodes()) {             idToDiscoveryNode.put(remoteNode.getId(), remoteNode).         }         final Map<String, AliasFilter> indicesAndFilters = searchShardsResponse.getIndicesAndFilters().         for (ClusterSearchShardsGroup clusterSearchShardsGroup : searchShardsResponse.getGroups()) {             // add the cluster name to the remote index names for indices disambiguation             // this ends up in the hits returned with the search response             ShardId shardId = clusterSearchShardsGroup.getShardId().             final AliasFilter aliasFilter.             if (indicesAndFilters == null) {                 aliasFilter = AliasFilter.EMPTY.             } else {                 aliasFilter = indicesAndFilters.get(shardId.getIndexName()).                 assert aliasFilter != null : "alias filter must not be null for index: " + shardId.getIndex().             }             String[] aliases = aliasFilter.getAliases().             String[] finalIndices = aliases.length == 0 ? new String[] { shardId.getIndexName() } : aliases.             // here we have to map the filters to the UUID since from now on we use the uuid for the lookup             aliasFilterMap.put(shardId.getIndex().getUUID(), aliasFilter).             final OriginalIndices originalIndices = remoteIndicesByCluster.get(clusterAlias).             assert originalIndices != null : "original indices are null for clusterAlias: " + clusterAlias.             SearchShardIterator shardIterator = new SearchShardIterator(clusterAlias, shardId, Arrays.asList(clusterSearchShardsGroup.getShards()), new OriginalIndices(finalIndices, originalIndices.indicesOptions())).             remoteShardIterators.add(shardIterator).         }     }     return (clusterAlias, nodeId) -> {         Map<String, DiscoveryNode> clusterNodes = clusterToNode.get(clusterAlias).         if (clusterNodes == null) {             throw new IllegalArgumentException("unknown remote cluster: " + clusterAlias).         }         return clusterNodes.get(nodeId).     }. }
false;private;4;10;;private Index[] resolveLocalIndices(OriginalIndices localIndices, IndicesOptions indicesOptions, ClusterState clusterState, SearchTimeProvider timeProvider) {     if (localIndices == null) {         // don't search on any local index (happens when only remote indices were specified)         return Index.EMPTY_ARRAY.     }     return indexNameExpressionResolver.concreteIndices(clusterState, indicesOptions, timeProvider.getAbsoluteStartMillis(), localIndices.indices()). }
false;private;10;56;;private void executeSearch(SearchTask task, SearchTimeProvider timeProvider, SearchRequest searchRequest, OriginalIndices localIndices, List<SearchShardIterator> remoteShardIterators, BiFunction<String, String, DiscoveryNode> remoteConnections, ClusterState clusterState, Map<String, AliasFilter> remoteAliasMap, ActionListener<SearchResponse> listener, SearchResponse.Clusters clusters) {     clusterState.blocks().globalBlockedRaiseException(ClusterBlockLevel.READ).     // TODO: I think startTime() should become part of ActionRequest and that should be used both for index name     // date math expressions and $now in scripts. This way all apis will deal with now in the same way instead     // of just for the _search api     final Index[] indices = resolveLocalIndices(localIndices, searchRequest.indicesOptions(), clusterState, timeProvider).     Map<String, AliasFilter> aliasFilter = buildPerIndexAliasFilter(searchRequest, clusterState, indices, remoteAliasMap).     Map<String, Set<String>> routingMap = indexNameExpressionResolver.resolveSearchRouting(clusterState, searchRequest.routing(), searchRequest.indices()).     routingMap = routingMap == null ? Collections.emptyMap() : Collections.unmodifiableMap(routingMap).     String[] concreteIndices = new String[indices.length].     for (int i = 0. i < indices.length. i++) {         concreteIndices[i] = indices[i].getName().     }     Map<String, Long> nodeSearchCounts = searchTransportService.getPendingSearchRequests().     GroupShardsIterator<ShardIterator> localShardsIterator = clusterService.operationRouting().searchShards(clusterState, concreteIndices, routingMap, searchRequest.preference(), searchService.getResponseCollectorService(), nodeSearchCounts).     GroupShardsIterator<SearchShardIterator> shardIterators = mergeShardsIterators(localShardsIterator, localIndices, searchRequest.getLocalClusterAlias(), remoteShardIterators).     failIfOverShardCountLimit(clusterService, shardIterators.size()).     Map<String, Float> concreteIndexBoosts = resolveIndexBoosts(searchRequest, clusterState).     // optimize search type for cases where there is only one shard group to search on     if (shardIterators.size() == 1) {         // if we only have one group, then we always want Q_T_F, no need for DFS, and no need to do THEN since we hit one shard         searchRequest.searchType(QUERY_THEN_FETCH).     }     if (searchRequest.allowPartialSearchResults() == null) {         // No user preference defined in search request - apply cluster service default         searchRequest.allowPartialSearchResults(searchService.defaultAllowPartialSearchResults()).     }     if (searchRequest.isSuggestOnly()) {         // disable request cache if we have only suggest         searchRequest.requestCache(false).         switch(searchRequest.searchType()) {             case DFS_QUERY_THEN_FETCH:                 // convert to Q_T_F if we have only suggest                 searchRequest.searchType(QUERY_THEN_FETCH).                 break.         }     }     final DiscoveryNodes nodes = clusterState.nodes().     BiFunction<String, String, Transport.Connection> connectionLookup = buildConnectionLookup(searchRequest.getLocalClusterAlias(), nodes::get, remoteConnections, searchTransportService::getConnection).     boolean preFilterSearchShards = shouldPreFilterSearchShards(searchRequest, shardIterators).     searchAsyncAction(task, searchRequest, shardIterators, timeProvider, connectionLookup, clusterState.version(), Collections.unmodifiableMap(aliasFilter), concreteIndexBoosts, routingMap, listener, preFilterSearchShards, clusters).start(). }
false;static;4;21;;static BiFunction<String, String, Transport.Connection> buildConnectionLookup(String requestClusterAlias, Function<String, DiscoveryNode> localNodes, BiFunction<String, String, DiscoveryNode> remoteNodes, BiFunction<String, DiscoveryNode, Transport.Connection> nodeToConnection) {     return (clusterAlias, nodeId) -> {         final DiscoveryNode discoveryNode.         final boolean remoteCluster.         if (clusterAlias == null || requestClusterAlias != null) {             assert requestClusterAlias == null || requestClusterAlias.equals(clusterAlias).             discoveryNode = localNodes.apply(nodeId).             remoteCluster = false.         } else {             discoveryNode = remoteNodes.apply(clusterAlias, nodeId).             remoteCluster = true.         }         if (discoveryNode == null) {             throw new IllegalStateException("no node found for id: " + nodeId).         }         return nodeToConnection.apply(remoteCluster ? clusterAlias : null, discoveryNode).     }. }
false;private,static;2;7;;private static boolean shouldPreFilterSearchShards(SearchRequest searchRequest, GroupShardsIterator<SearchShardIterator> shardIterators) {     SearchSourceBuilder source = searchRequest.source().     return // we can't do this for DFS it needs to fan out to all shards all the time     searchRequest.searchType() == QUERY_THEN_FETCH && SearchService.canRewriteToMatchNone(source) && searchRequest.getPreFilterShardSize() < shardIterators.size(). }
false;static;4;10;;static GroupShardsIterator<SearchShardIterator> mergeShardsIterators(GroupShardsIterator<ShardIterator> localShardsIterator, OriginalIndices localIndices, @Nullable String localClusterAlias, List<SearchShardIterator> remoteShardIterators) {     List<SearchShardIterator> shards = new ArrayList<>(remoteShardIterators).     for (ShardIterator shardIterator : localShardsIterator) {         shards.add(new SearchShardIterator(localClusterAlias, shardIterator.shardId(), shardIterator.getShardRoutings(), localIndices)).     }     return new GroupShardsIterator<>(shards). }
false;public;0;4;;@Override public void run() {     action.start(). }
false;private;12;44;;private AbstractSearchAsyncAction searchAsyncAction(SearchTask task, SearchRequest searchRequest, GroupShardsIterator<SearchShardIterator> shardIterators, SearchTimeProvider timeProvider, BiFunction<String, String, Transport.Connection> connectionLookup, long clusterStateVersion, Map<String, AliasFilter> aliasFilter, Map<String, Float> concreteIndexBoosts, Map<String, Set<String>> indexRoutings, ActionListener<SearchResponse> listener, boolean preFilter, SearchResponse.Clusters clusters) {     Executor executor = threadPool.executor(ThreadPool.Names.SEARCH).     if (preFilter) {         return new CanMatchPreFilterSearchPhase(logger, searchTransportService, connectionLookup, aliasFilter, concreteIndexBoosts, indexRoutings, executor, searchRequest, listener, shardIterators, timeProvider, clusterStateVersion, task, (iter) -> {             AbstractSearchAsyncAction action = searchAsyncAction(task, searchRequest, iter, timeProvider, connectionLookup, clusterStateVersion, aliasFilter, concreteIndexBoosts, indexRoutings, listener, false, clusters).             return new SearchPhase(action.getName()) {                  @Override                 public void run() {                     action.start().                 }             }.         }, clusters).     } else {         AbstractSearchAsyncAction<? extends SearchPhaseResult> searchAsyncAction.         switch(searchRequest.searchType()) {             case DFS_QUERY_THEN_FETCH:                 searchAsyncAction = new SearchDfsQueryThenFetchAsyncAction(logger, searchTransportService, connectionLookup, aliasFilter, concreteIndexBoosts, indexRoutings, searchPhaseController, executor, searchRequest, listener, shardIterators, timeProvider, clusterStateVersion, task, clusters).                 break.             case QUERY_THEN_FETCH:                 searchAsyncAction = new SearchQueryThenFetchAsyncAction(logger, searchTransportService, connectionLookup, aliasFilter, concreteIndexBoosts, indexRoutings, searchPhaseController, executor, searchRequest, listener, shardIterators, timeProvider, clusterStateVersion, task, clusters).                 break.             default:                 throw new IllegalStateException("Unknown search type: [" + searchRequest.searchType() + "]").         }         return searchAsyncAction.     } }
false;private,static;2;10;;private static void failIfOverShardCountLimit(ClusterService clusterService, int shardCount) {     final long shardCountLimit = clusterService.getClusterSettings().get(SHARD_COUNT_LIMIT_SETTING).     if (shardCount > shardCountLimit) {         throw new IllegalArgumentException("Trying to query " + shardCount + " shards, which is over the limit of " + shardCountLimit + ". This limit exists because querying many shards at the same time can make the " + "job of the coordinating node very CPU and/or memory intensive. It is usually a better idea to " + "have a smaller number of larger shards. Update [" + SHARD_COUNT_LIMIT_SETTING.getKey() + "] to a greater value if you really want to query that many shards at the same time.").     } }
false;public,final;1;5;;@Override public final void onResponse(Response response) {     innerOnResponse(response).     maybeFinish(). }
false;abstract;1;1;;abstract void innerOnResponse(Response response).
false;public,final;1;18;;@Override public final void onFailure(Exception e) {     if (skipUnavailable) {         skippedClusters.incrementAndGet().     } else {         Exception exception = e.         if (RemoteClusterAware.LOCAL_CLUSTER_GROUP_KEY.equals(clusterAlias) == false) {             exception = wrapRemoteClusterFailure(clusterAlias, e).         }         if (exceptions.compareAndSet(null, exception) == false) {             exceptions.accumulateAndGet(exception, (previous, current) -> {                 current.addSuppressed(previous).                 return current.             }).         }     }     maybeFinish(). }
false;private;0;17;;private void maybeFinish() {     if (countDown.countDown()) {         Exception exception = exceptions.get().         if (exception == null) {             FinalResponse response.             try {                 response = createFinalResponse().             } catch (Exception e) {                 originalListener.onFailure(e).                 return.             }             originalListener.onResponse(response).         } else {             originalListener.onFailure(exceptions.get()).         }     } }
false;abstract;0;1;;abstract FinalResponse createFinalResponse().
false;private,static;2;3;;private static RemoteTransportException wrapRemoteClusterFailure(String clusterAlias, Exception e) {     return new RemoteTransportException("error while communicating with remote cluster [" + clusterAlias + "]", e). }
