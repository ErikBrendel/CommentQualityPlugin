commented;modifiers;parameterAmount;loc;comment;code
false;public;0;7;;@Override public ScoreMode scoreMode() {     if (valuesSource != null && valuesSource.needsScores()) {         return ScoreMode.COMPLETE.     }     return super.scoreMode(). }
false;protected;1;4;;@Override protected boolean shouldDefer(Aggregator aggregator) {     return true. }
false;public;0;5;;@Override public DeferringBucketCollector getDeferringCollector() {     deferringCollector = new MergingBucketsDeferringCollector(context).     return deferringCollector. }
false;public;2;29;;@Override public void collect(int doc, long bucket) throws IOException {     assert bucket == 0.     if (values.advanceExact(doc)) {         final int valuesCount = values.docValueCount().         long previousRounded = Long.MIN_VALUE.         for (int i = 0. i < valuesCount. ++i) {             long value = values.nextValue().             long rounded = roundingInfos[roundingIdx].rounding.round(value).             assert rounded >= previousRounded.             if (rounded == previousRounded) {                 continue.             }             long bucketOrd = bucketOrds.add(rounded).             if (bucketOrd < 0) {                 // already seen                 bucketOrd = -1 - bucketOrd.                 collectExistingBucket(sub, doc, bucketOrd).             } else {                 collectBucket(sub, doc, bucketOrd).                 while (roundingIdx < roundingInfos.length - 1 && bucketOrds.size() > (targetBuckets * roundingInfos[roundingIdx].getMaximumInnerInterval())) {                     increaseRounding().                 }             }             previousRounded = rounded.         }     } }
false;private;0;22;;private void increaseRounding() {     try (LongHash oldBucketOrds = bucketOrds) {         LongHash newBucketOrds = new LongHash(1, context.bigArrays()).         long[] mergeMap = new long[(int) oldBucketOrds.size()].         Rounding newRounding = roundingInfos[++roundingIdx].rounding.         for (int i = 0. i < oldBucketOrds.size(). i++) {             long oldKey = oldBucketOrds.get(i).             long newKey = newRounding.round(oldKey).             long newBucketOrd = newBucketOrds.add(newKey).             if (newBucketOrd >= 0) {                 mergeMap[i] = newBucketOrd.             } else {                 mergeMap[i] = -1 - newBucketOrd.             }         }         mergeBuckets(mergeMap, newBucketOrds.size()).         if (deferringCollector != null) {             deferringCollector.mergeBuckets(mergeMap).         }         bucketOrds = newBucketOrds.     } }
false;public;2;62;;@Override public LeafBucketCollector getLeafCollector(LeafReaderContext ctx, final LeafBucketCollector sub) throws IOException {     if (valuesSource == null) {         return LeafBucketCollector.NO_OP_COLLECTOR.     }     final SortedNumericDocValues values = valuesSource.longValues(ctx).     return new LeafBucketCollectorBase(sub, values) {          @Override         public void collect(int doc, long bucket) throws IOException {             assert bucket == 0.             if (values.advanceExact(doc)) {                 final int valuesCount = values.docValueCount().                 long previousRounded = Long.MIN_VALUE.                 for (int i = 0. i < valuesCount. ++i) {                     long value = values.nextValue().                     long rounded = roundingInfos[roundingIdx].rounding.round(value).                     assert rounded >= previousRounded.                     if (rounded == previousRounded) {                         continue.                     }                     long bucketOrd = bucketOrds.add(rounded).                     if (bucketOrd < 0) {                         // already seen                         bucketOrd = -1 - bucketOrd.                         collectExistingBucket(sub, doc, bucketOrd).                     } else {                         collectBucket(sub, doc, bucketOrd).                         while (roundingIdx < roundingInfos.length - 1 && bucketOrds.size() > (targetBuckets * roundingInfos[roundingIdx].getMaximumInnerInterval())) {                             increaseRounding().                         }                     }                     previousRounded = rounded.                 }             }         }          private void increaseRounding() {             try (LongHash oldBucketOrds = bucketOrds) {                 LongHash newBucketOrds = new LongHash(1, context.bigArrays()).                 long[] mergeMap = new long[(int) oldBucketOrds.size()].                 Rounding newRounding = roundingInfos[++roundingIdx].rounding.                 for (int i = 0. i < oldBucketOrds.size(). i++) {                     long oldKey = oldBucketOrds.get(i).                     long newKey = newRounding.round(oldKey).                     long newBucketOrd = newBucketOrds.add(newKey).                     if (newBucketOrd >= 0) {                         mergeMap[i] = newBucketOrd.                     } else {                         mergeMap[i] = -1 - newBucketOrd.                     }                 }                 mergeBuckets(mergeMap, newBucketOrds.size()).                 if (deferringCollector != null) {                     deferringCollector.mergeBuckets(mergeMap).                 }                 bucketOrds = newBucketOrds.             }         }     }. }
false;public;1;28;;@Override public InternalAggregation buildAggregation(long owningBucketOrdinal) throws IOException {     assert owningBucketOrdinal == 0.     consumeBucketsAndMaybeBreak((int) bucketOrds.size()).     long[] bucketOrdArray = new long[(int) bucketOrds.size()].     for (int i = 0. i < bucketOrds.size(). i++) {         bucketOrdArray[i] = i.     }     runDeferredCollections(bucketOrdArray).     List<InternalAutoDateHistogram.Bucket> buckets = new ArrayList<>((int) bucketOrds.size()).     for (long i = 0. i < bucketOrds.size(). i++) {         buckets.add(new InternalAutoDateHistogram.Bucket(bucketOrds.get(i), bucketDocCount(i), formatter, bucketAggregations(i))).     }     // the contract of the histogram aggregation is that shards must return     // buckets ordered by key in ascending order     CollectionUtil.introSort(buckets, BucketOrder.key(true).comparator(this)).     // value source will be null for unmapped fields     InternalAutoDateHistogram.BucketInfo emptyBucketInfo = new InternalAutoDateHistogram.BucketInfo(roundingInfos, roundingIdx, buildEmptySubAggregations()).     return new InternalAutoDateHistogram(name, buckets, targetBuckets, emptyBucketInfo, formatter, pipelineAggregators(), metaData(), 1). }
false;public;0;7;;@Override public InternalAggregation buildEmptyAggregation() {     InternalAutoDateHistogram.BucketInfo emptyBucketInfo = new InternalAutoDateHistogram.BucketInfo(roundingInfos, roundingIdx, buildEmptySubAggregations()).     return new InternalAutoDateHistogram(name, Collections.emptyList(), targetBuckets, emptyBucketInfo, formatter, pipelineAggregators(), metaData(), 1). }
false;public;0;4;;@Override public void doClose() {     Releasables.close(bucketOrds). }
