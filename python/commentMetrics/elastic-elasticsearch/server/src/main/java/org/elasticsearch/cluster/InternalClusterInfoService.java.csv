commented;modifiers;parameterAmount;loc;comment;code
false;private;1;3;;private void setEnabled(boolean enabled) {     this.enabled = enabled. }
false;private;1;3;;private void setFetchTimeout(TimeValue fetchTimeout) {     this.fetchTimeout = fetchTimeout. }
false;;1;3;;void setUpdateFrequency(TimeValue updateFrequency) {     this.updateFrequency = updateFrequency. }
false;public;0;19;;@Override public void onMaster() {     this.isMaster = true.     if (logger.isTraceEnabled()) {         logger.trace("I have been elected master, scheduling a ClusterInfoUpdateJob").     }     // Submit a job that will start after DEFAULT_STARTING_INTERVAL, and reschedule itself after running     threadPool.scheduleUnlessShuttingDown(updateFrequency, executorName(), new SubmitReschedulingClusterInfoUpdatedJob()).     try {         if (clusterService.state().getNodes().getDataNodes().size() > 1) {             // Submit an info update job to be run immediately             threadPool.executor(executorName()).execute(() -> maybeRefresh()).         }     } catch (EsRejectedExecutionException ex) {         logger.debug("Couldn't schedule cluster info update task - node might be shutting down", ex).     } }
false;public;0;4;;@Override public void offMaster() {     this.isMaster = false. }
false;public;0;4;;@Override public String executorName() {     return ThreadPool.Names.MANAGEMENT. }
false;public;1;42;;@Override public void clusterChanged(ClusterChangedEvent event) {     if (!this.enabled) {         return.     }     // Check whether it was a data node that was added     boolean dataNodeAdded = false.     for (DiscoveryNode addedNode : event.nodesDelta().addedNodes()) {         if (addedNode.isDataNode()) {             dataNodeAdded = true.             break.         }     }     if (this.isMaster && dataNodeAdded && event.state().getNodes().getDataNodes().size() > 1) {         if (logger.isDebugEnabled()) {             logger.debug("data node was added, retrieving new cluster info").         }         threadPool.executor(executorName()).execute(() -> maybeRefresh()).     }     if (this.isMaster && event.nodesRemoved()) {         for (DiscoveryNode removedNode : event.nodesDelta().removedNodes()) {             if (removedNode.isDataNode()) {                 if (logger.isTraceEnabled()) {                     logger.trace("Removing node from cluster info: {}", removedNode.getId()).                 }                 if (leastAvailableSpaceUsages.containsKey(removedNode.getId())) {                     ImmutableOpenMap.Builder<String, DiskUsage> newMaxUsages = ImmutableOpenMap.builder(leastAvailableSpaceUsages).                     newMaxUsages.remove(removedNode.getId()).                     leastAvailableSpaceUsages = newMaxUsages.build().                 }                 if (mostAvailableSpaceUsages.containsKey(removedNode.getId())) {                     ImmutableOpenMap.Builder<String, DiskUsage> newMinUsages = ImmutableOpenMap.builder(mostAvailableSpaceUsages).                     newMinUsages.remove(removedNode.getId()).                     mostAvailableSpaceUsages = newMinUsages.build().                 }             }         }     } }
false;public;0;4;;@Override public ClusterInfo getClusterInfo() {     return new ClusterInfo(leastAvailableSpaceUsages, mostAvailableSpaceUsages, shardSizes, shardRoutingToDataPath). }
false;public;0;24;;@Override public void run() {     if (logger.isTraceEnabled()) {         logger.trace("Submitting new rescheduling cluster info update job").     }     try {         threadPool.executor(executorName()).execute(() -> {             try {                 maybeRefresh().             } finally {                 // schedule again after we refreshed                 if (isMaster) {                     if (logger.isTraceEnabled()) {                         logger.trace("Scheduling next run for updating cluster info in: {}", updateFrequency.toString()).                     }                     threadPool.scheduleUnlessShuttingDown(updateFrequency, executorName(), this).                 }             }         }).     } catch (EsRejectedExecutionException ex) {         if (logger.isDebugEnabled()) {             logger.debug("Couldn't re-schedule cluster info update task - node might be shutting down", ex).         }     } }
true;protected;1;9;/**  * Retrieve the latest nodes stats, calling the listener when complete  * @return a latch that can be used to wait for the nodes stats to complete if desired  */ ;/**  * Retrieve the latest nodes stats, calling the listener when complete  * @return a latch that can be used to wait for the nodes stats to complete if desired  */ protected CountDownLatch updateNodeStats(final ActionListener<NodesStatsResponse> listener) {     final CountDownLatch latch = new CountDownLatch(1).     final NodesStatsRequest nodesStatsRequest = new NodesStatsRequest("data:true").     nodesStatsRequest.clear().     nodesStatsRequest.fs(true).     nodesStatsRequest.timeout(fetchTimeout).     client.admin().cluster().nodesStats(nodesStatsRequest, new LatchedActionListener<>(listener, latch)).     return latch. }
true;protected;1;9;/**  * Retrieve the latest indices stats, calling the listener when complete  * @return a latch that can be used to wait for the indices stats to complete if desired  */ ;/**  * Retrieve the latest indices stats, calling the listener when complete  * @return a latch that can be used to wait for the indices stats to complete if desired  */ protected CountDownLatch updateIndicesStats(final ActionListener<IndicesStatsResponse> listener) {     final CountDownLatch latch = new CountDownLatch(1).     final IndicesStatsRequest indicesStatsRequest = new IndicesStatsRequest().     indicesStatsRequest.clear().     indicesStatsRequest.store(true).     client.admin().indices().stats(indicesStatsRequest, new LatchedActionListener<>(listener, latch)).     return latch. }
false;private;0;10;;private void maybeRefresh() {     // Short-circuit if not enabled     if (enabled) {         refresh().     } else {         if (logger.isTraceEnabled()) {             logger.trace("Skipping ClusterInfoUpdatedJob since it is disabled").         }     } }
false;public;1;8;;@Override public void onResponse(NodesStatsResponse nodeStatses) {     ImmutableOpenMap.Builder<String, DiskUsage> newLeastAvaiableUsages = ImmutableOpenMap.builder().     ImmutableOpenMap.Builder<String, DiskUsage> newMostAvaiableUsages = ImmutableOpenMap.builder().     fillDiskUsagePerNode(logger, nodeStatses.getNodes(), newLeastAvaiableUsages, newMostAvaiableUsages).     leastAvailableSpaceUsages = newLeastAvaiableUsages.build().     mostAvailableSpaceUsages = newMostAvaiableUsages.build(). }
false;public;1;17;;@Override public void onFailure(Exception e) {     if (e instanceof ReceiveTimeoutTransportException) {         logger.error("NodeStatsAction timed out for ClusterInfoUpdateJob", e).     } else {         if (e instanceof ClusterBlockException) {             if (logger.isTraceEnabled()) {                 logger.trace("Failed to execute NodeStatsAction for ClusterInfoUpdateJob", e).             }         } else {             logger.warn("Failed to execute NodeStatsAction for ClusterInfoUpdateJob", e).         }         // we empty the usages list, to be safe - we don't know what's going on.         leastAvailableSpaceUsages = ImmutableOpenMap.of().         mostAvailableSpaceUsages = ImmutableOpenMap.of().     } }
false;public;1;9;;@Override public void onResponse(IndicesStatsResponse indicesStatsResponse) {     ShardStats[] stats = indicesStatsResponse.getShards().     ImmutableOpenMap.Builder<String, Long> newShardSizes = ImmutableOpenMap.builder().     ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath = ImmutableOpenMap.builder().     buildShardLevelInfo(logger, stats, newShardSizes, newShardRoutingToDataPath, clusterService.state()).     shardSizes = newShardSizes.build().     shardRoutingToDataPath = newShardRoutingToDataPath.build(). }
false;public;1;17;;@Override public void onFailure(Exception e) {     if (e instanceof ReceiveTimeoutTransportException) {         logger.error("IndicesStatsAction timed out for ClusterInfoUpdateJob", e).     } else {         if (e instanceof ClusterBlockException) {             if (logger.isTraceEnabled()) {                 logger.trace("Failed to execute IndicesStatsAction for ClusterInfoUpdateJob", e).             }         } else {             logger.warn("Failed to execute IndicesStatsAction for ClusterInfoUpdateJob", e).         }         // we empty the usages list, to be safe - we don't know what's going on.         shardSizes = ImmutableOpenMap.of().         shardRoutingToDataPath = ImmutableOpenMap.of().     } }
true;public,final;0;86;/**  * Refreshes the ClusterInfo in a blocking fashion  */ ;/**  * Refreshes the ClusterInfo in a blocking fashion  */ public final ClusterInfo refresh() {     if (logger.isTraceEnabled()) {         logger.trace("Performing ClusterInfoUpdateJob").     }     final CountDownLatch nodeLatch = updateNodeStats(new ActionListener<NodesStatsResponse>() {          @Override         public void onResponse(NodesStatsResponse nodeStatses) {             ImmutableOpenMap.Builder<String, DiskUsage> newLeastAvaiableUsages = ImmutableOpenMap.builder().             ImmutableOpenMap.Builder<String, DiskUsage> newMostAvaiableUsages = ImmutableOpenMap.builder().             fillDiskUsagePerNode(logger, nodeStatses.getNodes(), newLeastAvaiableUsages, newMostAvaiableUsages).             leastAvailableSpaceUsages = newLeastAvaiableUsages.build().             mostAvailableSpaceUsages = newMostAvaiableUsages.build().         }          @Override         public void onFailure(Exception e) {             if (e instanceof ReceiveTimeoutTransportException) {                 logger.error("NodeStatsAction timed out for ClusterInfoUpdateJob", e).             } else {                 if (e instanceof ClusterBlockException) {                     if (logger.isTraceEnabled()) {                         logger.trace("Failed to execute NodeStatsAction for ClusterInfoUpdateJob", e).                     }                 } else {                     logger.warn("Failed to execute NodeStatsAction for ClusterInfoUpdateJob", e).                 }                 // we empty the usages list, to be safe - we don't know what's going on.                 leastAvailableSpaceUsages = ImmutableOpenMap.of().                 mostAvailableSpaceUsages = ImmutableOpenMap.of().             }         }     }).     final CountDownLatch indicesLatch = updateIndicesStats(new ActionListener<IndicesStatsResponse>() {          @Override         public void onResponse(IndicesStatsResponse indicesStatsResponse) {             ShardStats[] stats = indicesStatsResponse.getShards().             ImmutableOpenMap.Builder<String, Long> newShardSizes = ImmutableOpenMap.builder().             ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath = ImmutableOpenMap.builder().             buildShardLevelInfo(logger, stats, newShardSizes, newShardRoutingToDataPath, clusterService.state()).             shardSizes = newShardSizes.build().             shardRoutingToDataPath = newShardRoutingToDataPath.build().         }          @Override         public void onFailure(Exception e) {             if (e instanceof ReceiveTimeoutTransportException) {                 logger.error("IndicesStatsAction timed out for ClusterInfoUpdateJob", e).             } else {                 if (e instanceof ClusterBlockException) {                     if (logger.isTraceEnabled()) {                         logger.trace("Failed to execute IndicesStatsAction for ClusterInfoUpdateJob", e).                     }                 } else {                     logger.warn("Failed to execute IndicesStatsAction for ClusterInfoUpdateJob", e).                 }                 // we empty the usages list, to be safe - we don't know what's going on.                 shardSizes = ImmutableOpenMap.of().                 shardRoutingToDataPath = ImmutableOpenMap.of().             }         }     }).     try {         if (nodeLatch.await(fetchTimeout.getMillis(), TimeUnit.MILLISECONDS) == false) {             logger.warn("Failed to update node information for ClusterInfoUpdateJob within {} timeout", fetchTimeout).         }     } catch (InterruptedException e) {         // restore interrupt status         Thread.currentThread().interrupt().     }     try {         if (indicesLatch.await(fetchTimeout.getMillis(), TimeUnit.MILLISECONDS) == false) {             logger.warn("Failed to update shard information for ClusterInfoUpdateJob within {} timeout", fetchTimeout).         }     } catch (InterruptedException e) {         // restore interrupt status         Thread.currentThread().interrupt().     }     ClusterInfo clusterInfo = getClusterInfo().     try {         listener.accept(clusterInfo).     } catch (Exception e) {         logger.info("Failed executing ClusterInfoService listener", e).     }     return clusterInfo. }
false;static;5;12;;static void buildShardLevelInfo(Logger logger, ShardStats[] stats, ImmutableOpenMap.Builder<String, Long> newShardSizes, ImmutableOpenMap.Builder<ShardRouting, String> newShardRoutingToDataPath, ClusterState state) {     for (ShardStats s : stats) {         newShardRoutingToDataPath.put(s.getShardRouting(), s.getDataPath()).         long size = s.getStats().getStore().sizeInBytes().         String sid = ClusterInfo.shardIdentifierFromRouting(s.getShardRouting()).         if (logger.isTraceEnabled()) {             logger.trace("shard: {} size: {}", sid, size).         }         newShardSizes.put(sid, size).     } }
false;static;4;49;;static void fillDiskUsagePerNode(Logger logger, List<NodeStats> nodeStatsArray, ImmutableOpenMap.Builder<String, DiskUsage> newLeastAvaiableUsages, ImmutableOpenMap.Builder<String, DiskUsage> newMostAvaiableUsages) {     for (NodeStats nodeStats : nodeStatsArray) {         if (nodeStats.getFs() == null) {             logger.warn("Unable to retrieve node FS stats for {}", nodeStats.getNode().getName()).         } else {             FsInfo.Path leastAvailablePath = null.             FsInfo.Path mostAvailablePath = null.             for (FsInfo.Path info : nodeStats.getFs()) {                 if (leastAvailablePath == null) {                     assert mostAvailablePath == null.                     mostAvailablePath = leastAvailablePath = info.                 } else if (leastAvailablePath.getAvailable().getBytes() > info.getAvailable().getBytes()) {                     leastAvailablePath = info.                 } else if (mostAvailablePath.getAvailable().getBytes() < info.getAvailable().getBytes()) {                     mostAvailablePath = info.                 }             }             String nodeId = nodeStats.getNode().getId().             String nodeName = nodeStats.getNode().getName().             if (logger.isTraceEnabled()) {                 logger.trace("node: [{}], most available: total disk: {}," + " available disk: {} / least available: total disk: {}, available disk: {}", nodeId, mostAvailablePath.getTotal(), leastAvailablePath.getAvailable(), leastAvailablePath.getTotal(), leastAvailablePath.getAvailable()).             }             if (leastAvailablePath.getTotal().getBytes() < 0) {                 if (logger.isTraceEnabled()) {                     logger.trace("node: [{}] least available path has less than 0 total bytes of disk [{}], skipping", nodeId, leastAvailablePath.getTotal().getBytes()).                 }             } else {                 newLeastAvaiableUsages.put(nodeId, new DiskUsage(nodeId, nodeName, leastAvailablePath.getPath(), leastAvailablePath.getTotal().getBytes(), leastAvailablePath.getAvailable().getBytes())).             }             if (mostAvailablePath.getTotal().getBytes() < 0) {                 if (logger.isTraceEnabled()) {                     logger.trace("node: [{}] most available path has less than 0 total bytes of disk [{}], skipping", nodeId, mostAvailablePath.getTotal().getBytes()).                 }             } else {                 newMostAvaiableUsages.put(nodeId, new DiskUsage(nodeId, nodeName, mostAvailablePath.getPath(), mostAvailablePath.getTotal().getBytes(), mostAvailablePath.getAvailable().getBytes())).             }         }     } }
