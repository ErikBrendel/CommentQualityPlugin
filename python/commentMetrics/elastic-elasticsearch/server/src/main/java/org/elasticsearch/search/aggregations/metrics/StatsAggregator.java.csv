commented;modifiers;parameterAmount;loc;comment;code
false;public;0;4;;@Override public ScoreMode scoreMode() {     return valuesSource != null && valuesSource.needsScores() ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES. }
false;public;2;43;;@Override public void collect(int doc, long bucket) throws IOException {     if (bucket >= counts.size()) {         final long from = counts.size().         final long overSize = BigArrays.overSize(bucket + 1).         counts = bigArrays.resize(counts, overSize).         sums = bigArrays.resize(sums, overSize).         compensations = bigArrays.resize(compensations, overSize).         mins = bigArrays.resize(mins, overSize).         maxes = bigArrays.resize(maxes, overSize).         mins.fill(from, overSize, Double.POSITIVE_INFINITY).         maxes.fill(from, overSize, Double.NEGATIVE_INFINITY).     }     if (values.advanceExact(doc)) {         final int valuesCount = values.docValueCount().         counts.increment(bucket, valuesCount).         double min = mins.get(bucket).         double max = maxes.get(bucket).         // Compute the sum of double values with Kahan summation algorithm which is more         // accurate than naive summation.         double sum = sums.get(bucket).         double compensation = compensations.get(bucket).         for (int i = 0. i < valuesCount. i++) {             double value = values.nextValue().             if (Double.isFinite(value) == false) {                 sum += value.             } else if (Double.isFinite(sum)) {                 double corrected = value - compensation.                 double newSum = sum + corrected.                 compensation = (newSum - sum) - corrected.                 sum = newSum.             }             min = Math.min(min, value).             max = Math.max(max, value).         }         sums.set(bucket, sum).         compensations.set(bucket, compensation).         mins.set(bucket, min).         maxes.set(bucket, max).     } }
false;public;2;54;;@Override public LeafBucketCollector getLeafCollector(LeafReaderContext ctx, final LeafBucketCollector sub) throws IOException {     if (valuesSource == null) {         return LeafBucketCollector.NO_OP_COLLECTOR.     }     final BigArrays bigArrays = context.bigArrays().     final SortedNumericDoubleValues values = valuesSource.doubleValues(ctx).     return new LeafBucketCollectorBase(sub, values) {          @Override         public void collect(int doc, long bucket) throws IOException {             if (bucket >= counts.size()) {                 final long from = counts.size().                 final long overSize = BigArrays.overSize(bucket + 1).                 counts = bigArrays.resize(counts, overSize).                 sums = bigArrays.resize(sums, overSize).                 compensations = bigArrays.resize(compensations, overSize).                 mins = bigArrays.resize(mins, overSize).                 maxes = bigArrays.resize(maxes, overSize).                 mins.fill(from, overSize, Double.POSITIVE_INFINITY).                 maxes.fill(from, overSize, Double.NEGATIVE_INFINITY).             }             if (values.advanceExact(doc)) {                 final int valuesCount = values.docValueCount().                 counts.increment(bucket, valuesCount).                 double min = mins.get(bucket).                 double max = maxes.get(bucket).                 // Compute the sum of double values with Kahan summation algorithm which is more                 // accurate than naive summation.                 double sum = sums.get(bucket).                 double compensation = compensations.get(bucket).                 for (int i = 0. i < valuesCount. i++) {                     double value = values.nextValue().                     if (Double.isFinite(value) == false) {                         sum += value.                     } else if (Double.isFinite(sum)) {                         double corrected = value - compensation.                         double newSum = sum + corrected.                         compensation = (newSum - sum) - corrected.                         sum = newSum.                     }                     min = Math.min(min, value).                     max = Math.max(max, value).                 }                 sums.set(bucket, sum).                 compensations.set(bucket, compensation).                 mins.set(bucket, min).                 maxes.set(bucket, max).             }         }     }. }
false;public;1;9;;@Override public boolean hasMetric(String name) {     try {         InternalStats.Metrics.resolve(name).         return true.     } catch (IllegalArgumentException iae) {         return false.     } }
false;public;2;23;;@Override public double metric(String name, long owningBucketOrd) {     if (valuesSource == null || owningBucketOrd >= counts.size()) {         switch(InternalStats.Metrics.resolve(name)) {             case count:                 return 0.             case sum:                 return 0.             case min:                 return Double.POSITIVE_INFINITY.             case max:                 return Double.NEGATIVE_INFINITY.             case avg:                 return Double.NaN.             default:                 throw new IllegalArgumentException("Unknown value [" + name + "] in common stats aggregation").         }     }     switch(InternalStats.Metrics.resolve(name)) {         case count:             return counts.get(owningBucketOrd).         case sum:             return sums.get(owningBucketOrd).         case min:             return mins.get(owningBucketOrd).         case max:             return maxes.get(owningBucketOrd).         case avg:             return sums.get(owningBucketOrd) / counts.get(owningBucketOrd).         default:             throw new IllegalArgumentException("Unknown value [" + name + "] in common stats aggregation").     } }
false;public;1;8;;@Override public InternalAggregation buildAggregation(long bucket) {     if (valuesSource == null || bucket >= sums.size()) {         return buildEmptyAggregation().     }     return new InternalStats(name, counts.get(bucket), sums.get(bucket), mins.get(bucket), maxes.get(bucket), format, pipelineAggregators(), metaData()). }
false;public;0;4;;@Override public InternalAggregation buildEmptyAggregation() {     return new InternalStats(name, 0, 0, Double.POSITIVE_INFINITY, Double.NEGATIVE_INFINITY, format, pipelineAggregators(), metaData()). }
false;public;0;4;;@Override public void doClose() {     Releasables.close(counts, maxes, mins, sums, compensations). }
