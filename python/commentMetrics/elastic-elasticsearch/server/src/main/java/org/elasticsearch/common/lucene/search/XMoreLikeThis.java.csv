commented;modifiers;parameterAmount;loc;comment;code
true;public;0;3;/**  * Returns the boost factor used when boosting terms  *  * @return the boost factor used when boosting terms  * @see #setBoostFactor(float)  */ ;/**  * Returns the boost factor used when boosting terms  *  * @return the boost factor used when boosting terms  * @see #setBoostFactor(float)  */ public float getBoostFactor() {     return boostFactor. }
true;public;1;3;/**  * Sets the boost factor to use when boosting terms  *  * @see #getBoostFactor()  */ ;/**  * Sets the boost factor to use when boosting terms  *  * @see #getBoostFactor()  */ public void setBoostFactor(float boostFactor) {     this.boostFactor = boostFactor. }
true;public;1;3;/**  * Sets a list of terms to never select from  */ ;/**  * Sets a list of terms to never select from  */ public void setSkipTerms(Set<Term> skipTerms) {     this.skipTerms = skipTerms. }
false;public;0;3;;public TFIDFSimilarity getSimilarity() {     return similarity. }
false;public;1;3;;public void setSimilarity(TFIDFSimilarity similarity) {     this.similarity = similarity. }
true;public;0;3;/**  * Returns an analyzer that will be used to parse source doc with. The default analyzer  * is not set.  *  * @return the analyzer that will be used to parse source doc with.  */ ;/**  * Returns an analyzer that will be used to parse source doc with. The default analyzer  * is not set.  *  * @return the analyzer that will be used to parse source doc with.  */ public Analyzer getAnalyzer() {     return analyzer. }
true;public;1;3;/**  * Sets the analyzer to use. An analyzer is not required for generating a query with the  * {@link #like(int)} method, all other 'like' methods require an analyzer.  *  * @param analyzer the analyzer to use to tokenize text.  */ ;/**  * Sets the analyzer to use. An analyzer is not required for generating a query with the  * {@link #like(int)} method, all other 'like' methods require an analyzer.  *  * @param analyzer the analyzer to use to tokenize text.  */ public void setAnalyzer(Analyzer analyzer) {     this.analyzer = analyzer. }
true;public;0;3;/**  * Returns the frequency below which terms will be ignored in the source doc. The default  * frequency is the {@link #DEFAULT_MIN_TERM_FREQ}.  *  * @return the frequency below which terms will be ignored in the source doc.  */ ;/**  * Returns the frequency below which terms will be ignored in the source doc. The default  * frequency is the {@link #DEFAULT_MIN_TERM_FREQ}.  *  * @return the frequency below which terms will be ignored in the source doc.  */ public int getMinTermFreq() {     return minTermFreq. }
true;public;1;3;/**  * Sets the frequency below which terms will be ignored in the source doc.  *  * @param minTermFreq the frequency below which terms will be ignored in the source doc.  */ ;/**  * Sets the frequency below which terms will be ignored in the source doc.  *  * @param minTermFreq the frequency below which terms will be ignored in the source doc.  */ public void setMinTermFreq(int minTermFreq) {     this.minTermFreq = minTermFreq. }
true;public;0;3;/**  * Returns the frequency at which words will be ignored which do not occur in at least this  * many docs. The default frequency is {@link #DEFAULT_MIN_DOC_FREQ}.  *  * @return the frequency at which words will be ignored which do not occur in at least this  *         many docs.  */ ;/**  * Returns the frequency at which words will be ignored which do not occur in at least this  * many docs. The default frequency is {@link #DEFAULT_MIN_DOC_FREQ}.  *  * @return the frequency at which words will be ignored which do not occur in at least this  *         many docs.  */ public int getMinDocFreq() {     return minDocFreq. }
true;public;1;3;/**  * Sets the frequency at which words will be ignored which do not occur in at least this  * many docs.  *  * @param minDocFreq the frequency at which words will be ignored which do not occur in at  * least this many docs.  */ ;/**  * Sets the frequency at which words will be ignored which do not occur in at least this  * many docs.  *  * @param minDocFreq the frequency at which words will be ignored which do not occur in at  * least this many docs.  */ public void setMinDocFreq(int minDocFreq) {     this.minDocFreq = minDocFreq. }
true;public;0;3;/**  * Returns the maximum frequency in which words may still appear.  * Words that appear in more than this many docs will be ignored. The default frequency is  * {@link #DEFAULT_MAX_DOC_FREQ}.  *  * @return get the maximum frequency at which words are still allowed,  *         words which occur in more docs than this are ignored.  */ ;/**  * Returns the maximum frequency in which words may still appear.  * Words that appear in more than this many docs will be ignored. The default frequency is  * {@link #DEFAULT_MAX_DOC_FREQ}.  *  * @return get the maximum frequency at which words are still allowed,  *         words which occur in more docs than this are ignored.  */ public int getMaxDocFreq() {     return maxDocFreq. }
true;public;1;3;/**  * Set the maximum frequency in which words may still appear. Words that appear  * in more than this many docs will be ignored.  *  * @param maxFreq the maximum count of documents that a term may appear  * in to be still considered relevant  */ ;/**  * Set the maximum frequency in which words may still appear. Words that appear  * in more than this many docs will be ignored.  *  * @param maxFreq the maximum count of documents that a term may appear  * in to be still considered relevant  */ public void setMaxDocFreq(int maxFreq) {     this.maxDocFreq = maxFreq. }
true;public;1;3;/**  * Set the maximum percentage in which words may still appear. Words that appear  * in more than this many percent of all docs will be ignored.  *  * @param maxPercentage the maximum percentage of documents (0-100) that a term may appear  * in to be still considered relevant  */ ;/**  * Set the maximum percentage in which words may still appear. Words that appear  * in more than this many percent of all docs will be ignored.  *  * @param maxPercentage the maximum percentage of documents (0-100) that a term may appear  * in to be still considered relevant  */ public void setMaxDocFreqPct(int maxPercentage) {     this.maxDocFreq = maxPercentage * ir.numDocs() / 100. }
true;public;0;3;/**  * Returns whether to boost terms in query based on "score" or not. The default is  * {@link #DEFAULT_BOOST}.  *  * @return whether to boost terms in query based on "score" or not.  * @see #setBoost  */ ;/**  * Returns whether to boost terms in query based on "score" or not. The default is  * {@link #DEFAULT_BOOST}.  *  * @return whether to boost terms in query based on "score" or not.  * @see #setBoost  */ public boolean isBoost() {     return boost. }
true;public;1;3;/**  * Sets whether to boost terms in query based on "score" or not.  *  * @param boost true to boost terms in query based on "score", false otherwise.  * @see #isBoost  */ ;/**  * Sets whether to boost terms in query based on "score" or not.  *  * @param boost true to boost terms in query based on "score", false otherwise.  * @see #isBoost  */ public void setBoost(boolean boost) {     this.boost = boost. }
true;public;0;3;/**  * Returns the field names that will be used when generating the 'More Like This' query.  * The default field names that will be used is {@link #DEFAULT_FIELD_NAMES}.  *  * @return the field names that will be used when generating the 'More Like This' query.  */ ;/**  * Returns the field names that will be used when generating the 'More Like This' query.  * The default field names that will be used is {@link #DEFAULT_FIELD_NAMES}.  *  * @return the field names that will be used when generating the 'More Like This' query.  */ public String[] getFieldNames() {     return fieldNames. }
true;public;1;3;/**  * Sets the field names that will be used when generating the 'More Like This' query.  * Set this to null for the field names to be determined at runtime from the IndexReader  * provided in the constructor.  *  * @param fieldNames the field names that will be used when generating the 'More Like This'  * query.  */ ;/**  * Sets the field names that will be used when generating the 'More Like This' query.  * Set this to null for the field names to be determined at runtime from the IndexReader  * provided in the constructor.  *  * @param fieldNames the field names that will be used when generating the 'More Like This'  * query.  */ public void setFieldNames(String[] fieldNames) {     this.fieldNames = fieldNames. }
true;public;0;3;/**  * Returns the minimum word length below which words will be ignored. Set this to 0 for no  * minimum word length. The default is {@link #DEFAULT_MIN_WORD_LENGTH}.  *  * @return the minimum word length below which words will be ignored.  */ ;/**  * Returns the minimum word length below which words will be ignored. Set this to 0 for no  * minimum word length. The default is {@link #DEFAULT_MIN_WORD_LENGTH}.  *  * @return the minimum word length below which words will be ignored.  */ public int getMinWordLen() {     return minWordLen. }
true;public;1;3;/**  * Sets the minimum word length below which words will be ignored.  *  * @param minWordLen the minimum word length below which words will be ignored.  */ ;/**  * Sets the minimum word length below which words will be ignored.  *  * @param minWordLen the minimum word length below which words will be ignored.  */ public void setMinWordLen(int minWordLen) {     this.minWordLen = minWordLen. }
true;public;0;3;/**  * Returns the maximum word length above which words will be ignored. Set this to 0 for no  * maximum word length. The default is {@link #DEFAULT_MAX_WORD_LENGTH}.  *  * @return the maximum word length above which words will be ignored.  */ ;/**  * Returns the maximum word length above which words will be ignored. Set this to 0 for no  * maximum word length. The default is {@link #DEFAULT_MAX_WORD_LENGTH}.  *  * @return the maximum word length above which words will be ignored.  */ public int getMaxWordLen() {     return maxWordLen. }
true;public;1;3;/**  * Sets the maximum word length above which words will be ignored.  *  * @param maxWordLen the maximum word length above which words will be ignored.  */ ;/**  * Sets the maximum word length above which words will be ignored.  *  * @param maxWordLen the maximum word length above which words will be ignored.  */ public void setMaxWordLen(int maxWordLen) {     this.maxWordLen = maxWordLen. }
true;public;1;3;/**  * Set the set of stopwords.  * Any word in this set is considered "uninteresting" and ignored.  * Even if your Analyzer allows stopwords, you might want to tell the MoreLikeThis code to ignore them, as  * for the purposes of document similarity it seems reasonable to assume that "a stop word is never interesting".  *  * @param stopWords set of stopwords, if null it means to allow stop words  * @see #getStopWords  */ ;/**  * Set the set of stopwords.  * Any word in this set is considered "uninteresting" and ignored.  * Even if your Analyzer allows stopwords, you might want to tell the MoreLikeThis code to ignore them, as  * for the purposes of document similarity it seems reasonable to assume that "a stop word is never interesting".  *  * @param stopWords set of stopwords, if null it means to allow stop words  * @see #getStopWords  */ public void setStopWords(Set<?> stopWords) {     this.stopWords = stopWords. }
true;public;0;3;/**  * Get the current stop words being used.  *  * @see #setStopWords  */ ;/**  * Get the current stop words being used.  *  * @see #setStopWords  */ public Set<?> getStopWords() {     return stopWords. }
true;public;0;3;/**  * Returns the maximum number of query terms that will be included in any generated query.  * The default is {@link #DEFAULT_MAX_QUERY_TERMS}.  *  * @return the maximum number of query terms that will be included in any generated query.  */ ;/**  * Returns the maximum number of query terms that will be included in any generated query.  * The default is {@link #DEFAULT_MAX_QUERY_TERMS}.  *  * @return the maximum number of query terms that will be included in any generated query.  */ public int getMaxQueryTerms() {     return maxQueryTerms. }
true;public;1;3;/**  * Sets the maximum number of query terms that will be included in any generated query.  *  * @param maxQueryTerms the maximum number of query terms that will be included in any  * generated query.  */ ;/**  * Sets the maximum number of query terms that will be included in any generated query.  *  * @param maxQueryTerms the maximum number of query terms that will be included in any  * generated query.  */ public void setMaxQueryTerms(int maxQueryTerms) {     this.maxQueryTerms = maxQueryTerms. }
true;public;0;3;/**  * @return The maximum number of tokens to parse in each example doc field that is not stored with TermVector support  * @see #DEFAULT_MAX_NUM_TOKENS_PARSED  */ ;/**  * @return The maximum number of tokens to parse in each example doc field that is not stored with TermVector support  * @see #DEFAULT_MAX_NUM_TOKENS_PARSED  */ public int getMaxNumTokensParsed() {     return maxNumTokensParsed. }
true;public;1;3;/**  * @param i The maximum number of tokens to parse in each example doc field that is not stored with TermVector support  */ ;/**  * @param i The maximum number of tokens to parse in each example doc field that is not stored with TermVector support  */ public void setMaxNumTokensParsed(int i) {     maxNumTokensParsed = i. }
true;public;1;9;/**  * Return a query that will return docs like the passed lucene document ID.  *  * @param docNum the documentID of the lucene doc to generate the 'More Like This" query for.  * @return a query that will return docs like the passed lucene document ID.  */ ;/**  * Return a query that will return docs like the passed lucene document ID.  *  * @param docNum the documentID of the lucene doc to generate the 'More Like This" query for.  * @return a query that will return docs like the passed lucene document ID.  */ public Query like(int docNum) throws IOException {     if (fieldNames == null) {         // gather list of valid fields from lucene         Collection<String> fields = FieldInfos.getIndexedFields(ir).         fieldNames = fields.toArray(new String[fields.size()]).     }     return createQuery(retrieveTerms(docNum)). }
true;public;2;7;/**  * Return a query that will return docs like the passed Readers.  * This was added in order to treat multi-value fields.  *  * @return a query that will return docs like the passed Readers.  */ ;/**  * Return a query that will return docs like the passed Readers.  * This was added in order to treat multi-value fields.  *  * @return a query that will return docs like the passed Readers.  */ public Query like(String fieldName, Reader... readers) throws IOException {     Map<String, Int> words = new HashMap<>().     for (Reader r : readers) {         addTermFrequencies(r, words, fieldName).     }     return createQuery(createQueue(words)). }
true;public;1;7;/**  * Return a query that will return docs like the passed Terms.  *  * @return a query that will return docs like the passed Terms.  */ ;/**  * Return a query that will return docs like the passed Terms.  *  * @return a query that will return docs like the passed Terms.  */ public Query like(Terms... likeTerms) throws IOException {     Map<String, Int> termFreqMap = new HashMap<>().     for (Terms vector : likeTerms) {         addTermFrequencies(termFreqMap, vector).     }     return createQuery(createQueue(termFreqMap)). }
true;public;1;22;/**  * Return a query that will return docs like the passed Fields.  *  * @return a query that will return docs like the passed Fields.  */ ;/**  * Return a query that will return docs like the passed Fields.  *  * @return a query that will return docs like the passed Fields.  */ public Query like(Fields... likeFields) throws IOException {     // get all field names     Set<String> fieldNames = new HashSet<>().     for (Fields fields : likeFields) {         for (String fieldName : fields) {             fieldNames.add(fieldName).         }     }     // term selection is per field, then appended to a single boolean query     BooleanQuery.Builder bq = new BooleanQuery.Builder().     for (String fieldName : fieldNames) {         Map<String, Int> termFreqMap = new HashMap<>().         for (Fields fields : likeFields) {             Terms vector = fields.terms(fieldName).             if (vector != null) {                 addTermFrequencies(termFreqMap, vector, fieldName).             }         }         addToQuery(createQueue(termFreqMap, fieldName), bq).     }     return bq.build(). }
true;private;1;5;/**  * Create the More like query from a PriorityQueue  */ ;/**  * Create the More like query from a PriorityQueue  */ private Query createQuery(PriorityQueue<ScoreTerm> q) {     BooleanQuery.Builder query = new BooleanQuery.Builder().     addToQuery(q, query).     return query.build(). }
true;private;2;23;/**  * Add to an existing boolean query the More Like This query from this PriorityQueue  */ ;/**  * Add to an existing boolean query the More Like This query from this PriorityQueue  */ private void addToQuery(PriorityQueue<ScoreTerm> q, BooleanQuery.Builder query) {     ScoreTerm scoreTerm.     float bestScore = -1.     while ((scoreTerm = q.pop()) != null) {         Query tq = new TermQuery(new Term(scoreTerm.topField, scoreTerm.word)).         if (boost) {             if (bestScore == -1) {                 bestScore = (scoreTerm.score).             }             float myScore = (scoreTerm.score).             tq = new BoostQuery(tq, boostFactor * myScore / bestScore).         }         try {             query.add(tq, BooleanClause.Occur.SHOULD).         } catch (BooleanQuery.TooManyClauses ignore) {             break.         }     } }
true;private;1;3;/**  * Create a PriorityQueue from a word-&gt.tf map.  *  * @param words a map of words keyed on the word(String) with Int objects as the values.  */ ;/**  * Create a PriorityQueue from a word-&gt.tf map.  *  * @param words a map of words keyed on the word(String) with Int objects as the values.  */ private PriorityQueue<ScoreTerm> createQueue(Map<String, Int> words) throws IOException {     return createQueue(words, this.fieldNames). }
true;private;2;49;/**  * Create a PriorityQueue from a word-&gt.tf map.  *  * @param words a map of words keyed on the word(String) with Int objects as the values.  * @param fieldNames an array of field names to override defaults.  */ ;/**  * Create a PriorityQueue from a word-&gt.tf map.  *  * @param words a map of words keyed on the word(String) with Int objects as the values.  * @param fieldNames an array of field names to override defaults.  */ private PriorityQueue<ScoreTerm> createQueue(Map<String, Int> words, String... fieldNames) throws IOException {     // have collected all words in doc and their freqs     int numDocs = ir.numDocs().     final int limit = Math.min(maxQueryTerms, words.size()).     // will order words by score     FreqQ queue = new FreqQ(limit).     for (String word : words.keySet()) {         // for every word         // term freq in the source doc         int tf = words.get(word).x.         if (minTermFreq > 0 && tf < minTermFreq) {             // filter out words that don't occur enough times in the source             continue.         }         // go through all the fields and find the largest document frequency         String topField = fieldNames[0].         int docFreq = 0.         for (String fieldName : fieldNames) {             int freq = ir.docFreq(new Term(fieldName, word)).             topField = (freq > docFreq) ? fieldName : topField.             docFreq = (freq > docFreq) ? freq : docFreq.         }         if (minDocFreq > 0 && docFreq < minDocFreq) {             // filter out words that don't occur in enough docs             continue.         }         if (docFreq > maxDocFreq) {             // filter out words that occur in too many docs             continue.         }         if (docFreq == 0) {             // index update problem?             continue.         }         float idf = similarity.idf(docFreq, numDocs).         float score = tf * idf.         if (queue.size() < limit) {             // there is still space in the queue             queue.add(new ScoreTerm(word, topField, score)).         } else {             ScoreTerm term = queue.top().             if (term.score < score) {                 // update the smallest in the queue in place and update the queue.                 term.update(word, topField, score).                 queue.updateTop().             }         }     }     return queue. }
true;public;0;17;/**  * Describe the parameters that control how the "more like this" query is formed.  */ ;/**  * Describe the parameters that control how the "more like this" query is formed.  */ public String describeParams() {     StringBuilder sb = new StringBuilder().     sb.append("\t").append("maxQueryTerms  : ").append(maxQueryTerms).append("\n").     sb.append("\t").append("minWordLen     : ").append(minWordLen).append("\n").     sb.append("\t").append("maxWordLen     : ").append(maxWordLen).append("\n").     sb.append("\t").append("fieldNames     : ").     String delim = "".     for (String fieldName : fieldNames) {         sb.append(delim).append(fieldName).         delim = ", ".     }     sb.append("\n").     sb.append("\t").append("boost          : ").append(boost).append("\n").     sb.append("\t").append("minTermFreq    : ").append(minTermFreq).append("\n").     sb.append("\t").append("minDocFreq     : ").append(minDocFreq).append("\n").     return sb.toString(). }
true;private;1;28;/**  * Find words for a more-like-this query former.  *  * @param docNum the id of the lucene document from which to find terms  */ ;/**  * Find words for a more-like-this query former.  *  * @param docNum the id of the lucene document from which to find terms  */ private PriorityQueue<ScoreTerm> retrieveTerms(int docNum) throws IOException {     Map<String, Int> termFreqMap = new HashMap<>().     for (String fieldName : fieldNames) {         final Fields vectors = ir.getTermVectors(docNum).         final Terms vector.         if (vectors != null) {             vector = vectors.terms(fieldName).         } else {             vector = null.         }         // field does not store term vector info         if (vector == null) {             Document d = ir.document(docNum).             IndexableField[] fields = d.getFields(fieldName).             for (IndexableField field : fields) {                 final String stringValue = field.stringValue().                 if (stringValue != null) {                     addTermFrequencies(new StringReader(stringValue), termFreqMap, fieldName).                 }             }         } else {             addTermFrequencies(termFreqMap, vector, fieldName).         }     }     return createQueue(termFreqMap). }
true;private;2;3;/**  * Adds terms and frequencies found in vector into the Map termFreqMap  *  * @param termFreqMap a Map of terms and their frequencies  * @param vector List of terms and their frequencies for a doc/field  */ ;/**  * Adds terms and frequencies found in vector into the Map termFreqMap  *  * @param termFreqMap a Map of terms and their frequencies  * @param vector List of terms and their frequencies for a doc/field  */ private void addTermFrequencies(Map<String, Int> termFreqMap, Terms vector) throws IOException {     addTermFrequencies(termFreqMap, vector, null). }
true;private;3;31;/**  * Adds terms and frequencies found in vector into the Map termFreqMap  *  * @param termFreqMap a Map of terms and their frequencies  * @param vector List of terms and their frequencies for a doc/field  * @param fieldName Optional field name of the terms for skip terms  */ ;/**  * Adds terms and frequencies found in vector into the Map termFreqMap  *  * @param termFreqMap a Map of terms and their frequencies  * @param vector List of terms and their frequencies for a doc/field  * @param fieldName Optional field name of the terms for skip terms  */ private void addTermFrequencies(Map<String, Int> termFreqMap, Terms vector, @Nullable String fieldName) throws IOException {     final TermsEnum termsEnum = vector.iterator().     final CharsRefBuilder spare = new CharsRefBuilder().     BytesRef text.     while ((text = termsEnum.next()) != null) {         spare.copyUTF8Bytes(text).         final String term = spare.toString().         if (isNoiseWord(term)) {             continue.         }         if (isSkipTerm(fieldName, term)) {             continue.         }         final PostingsEnum docs = termsEnum.postings(null).         int freq = 0.         while (docs != null && docs.nextDoc() != DocIdSetIterator.NO_MORE_DOCS) {             freq += docs.freq().         }         // increment frequency         Int cnt = termFreqMap.get(term).         if (cnt == null) {             cnt = new Int().             termFreqMap.put(term, cnt).             cnt.x = freq.         } else {             cnt.x += freq.         }     } }
true;private;3;35;/**  * Adds term frequencies found by tokenizing text from reader into the Map words  *  * @param r a source of text to be tokenized  * @param termFreqMap a Map of terms and their frequencies  * @param fieldName Used by analyzer for any special per-field analysis  */ ;/**  * Adds term frequencies found by tokenizing text from reader into the Map words  *  * @param r a source of text to be tokenized  * @param termFreqMap a Map of terms and their frequencies  * @param fieldName Used by analyzer for any special per-field analysis  */ private void addTermFrequencies(Reader r, Map<String, Int> termFreqMap, String fieldName) throws IOException {     if (analyzer == null) {         throw new UnsupportedOperationException("To use MoreLikeThis without " + "term vectors, you must provide an Analyzer").     }     try (TokenStream ts = analyzer.tokenStream(fieldName, r)) {         int tokenCount = 0.         // for every token         CharTermAttribute termAtt = ts.addAttribute(CharTermAttribute.class).         ts.reset().         while (ts.incrementToken()) {             String word = termAtt.toString().             tokenCount++.             if (tokenCount > maxNumTokensParsed) {                 break.             }             if (isNoiseWord(word)) {                 continue.             }             if (isSkipTerm(fieldName, word)) {                 continue.             }             // increment frequency             Int cnt = termFreqMap.get(word).             if (cnt == null) {                 termFreqMap.put(word, new Int()).             } else {                 cnt.x++.             }         }         ts.end().     } }
true;private;1;10;/**  * determines if the passed term is likely to be of interest in "more like" comparisons  *  * @param term The word being considered  * @return true if should be ignored, false if should be used in further analysis  */ ;/**  * determines if the passed term is likely to be of interest in "more like" comparisons  *  * @param term The word being considered  * @return true if should be ignored, false if should be used in further analysis  */ private boolean isNoiseWord(String term) {     int len = term.length().     if (minWordLen > 0 && len < minWordLen) {         return true.     }     if (maxWordLen > 0 && len > maxWordLen) {         return true.     }     return stopWords != null && stopWords.contains(term). }
true;private;2;3;/**  * determines if the passed term is to be skipped all together  */ ;/**  * determines if the passed term is to be skipped all together  */ private boolean isSkipTerm(@Nullable String field, String value) {     return field != null && skipTerms != null && skipTerms.contains(new Term(field, value)). }
true;private;2;5;/**  * Find words for a more-like-this query former.  * The result is a priority queue of arrays with one entry for <b>every word</b> in the document.  * Each array has 6 elements.  * The elements are:  * <ol>  * <li> The word (String)  * <li> The top field that this word comes from (String)  * <li> The score for this word (Float)  * <li> The IDF value (Float)  * <li> The frequency of this word in the index (Integer)  * <li> The frequency of this word in the source document (Integer)  * </ol>  * This is a somewhat "advanced" routine, and in general only the 1st entry in the array is of interest.  * This method is exposed so that you can identify the "interesting words" in a document.  * For an easier method to call see {@link #retrieveInterestingTerms retrieveInterestingTerms()}.  *  * @param r the reader that has the content of the document  * @param fieldName field passed to the analyzer to use when analyzing the content  * @return the most interesting words in the document ordered by score, with the highest scoring, or best entry, first  * @see #retrieveInterestingTerms  */ ;/**  * Find words for a more-like-this query former.  * The result is a priority queue of arrays with one entry for <b>every word</b> in the document.  * Each array has 6 elements.  * The elements are:  * <ol>  * <li> The word (String)  * <li> The top field that this word comes from (String)  * <li> The score for this word (Float)  * <li> The IDF value (Float)  * <li> The frequency of this word in the index (Integer)  * <li> The frequency of this word in the source document (Integer)  * </ol>  * This is a somewhat "advanced" routine, and in general only the 1st entry in the array is of interest.  * This method is exposed so that you can identify the "interesting words" in a document.  * For an easier method to call see {@link #retrieveInterestingTerms retrieveInterestingTerms()}.  *  * @param r the reader that has the content of the document  * @param fieldName field passed to the analyzer to use when analyzing the content  * @return the most interesting words in the document ordered by score, with the highest scoring, or best entry, first  * @see #retrieveInterestingTerms  */ private PriorityQueue<ScoreTerm> retrieveTerms(Reader r, String fieldName) throws IOException {     Map<String, Int> words = new HashMap<>().     addTermFrequencies(r, words, fieldName).     return createQueue(words). }
true;public;1;12;/**  * @see #retrieveInterestingTerms(java.io.Reader, String)  */ ;/**  * @see #retrieveInterestingTerms(java.io.Reader, String)  */ public String[] retrieveInterestingTerms(int docNum) throws IOException {     ArrayList<Object> al = new ArrayList<>(maxQueryTerms).     PriorityQueue<ScoreTerm> pq = retrieveTerms(docNum).     ScoreTerm scoreTerm.     // have to be careful, retrieveTerms returns all words but that's probably not useful to our caller...     int lim = maxQueryTerms.     // we just want to return the top words     while (((scoreTerm = pq.pop()) != null) && lim-- > 0) {         // the 1st entry is the interesting word         al.add(scoreTerm.word).     }     String[] res = new String[al.size()].     return al.toArray(res). }
true;public;2;12;/**  * Convenience routine to make it easy to return the most interesting words in a document.  * More advanced users will call {@link #retrieveTerms(Reader, String) retrieveTerms()} directly.  *  * @param r the source document  * @param fieldName field passed to analyzer to use when analyzing the content  * @return the most interesting words in the document  * @see #retrieveTerms(java.io.Reader, String)  * @see #setMaxQueryTerms  */ ;/**  * Convenience routine to make it easy to return the most interesting words in a document.  * More advanced users will call {@link #retrieveTerms(Reader, String) retrieveTerms()} directly.  *  * @param r the source document  * @param fieldName field passed to analyzer to use when analyzing the content  * @return the most interesting words in the document  * @see #retrieveTerms(java.io.Reader, String)  * @see #setMaxQueryTerms  */ public String[] retrieveInterestingTerms(Reader r, String fieldName) throws IOException {     ArrayList<Object> al = new ArrayList<>(maxQueryTerms).     PriorityQueue<ScoreTerm> pq = retrieveTerms(r, fieldName).     ScoreTerm scoreTerm.     // have to be careful, retrieveTerms returns all words but that's probably not useful to our caller...     int lim = maxQueryTerms.     // we just want to return the top words     while (((scoreTerm = pq.pop()) != null) && lim-- > 0) {         // the 1st entry is the interesting word         al.add(scoreTerm.word).     }     String[] res = new String[al.size()].     return al.toArray(res). }
false;protected;2;4;;@Override protected boolean lessThan(ScoreTerm a, ScoreTerm b) {     return a.score < b.score. }
false;;3;5;;void update(String word, String topField, float score) {     this.word = word.     this.topField = topField.     this.score = score. }
