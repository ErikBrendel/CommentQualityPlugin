commented;modifiers;parameterAmount;loc;comment;code
false;public;1;3;;@Override public void writeTo(StreamOutput out) throws IOException { }
false;public;0;4;;@Override public String getWriteableName() {     return NAME. }
true;public;4;39;/**  * Calculates the significance of a term in a sample against a background of  * normal distributions by comparing the changes in frequency. This is the heart  * of the significant terms feature.  */ ;/**  * Calculates the significance of a term in a sample against a background of  * normal distributions by comparing the changes in frequency. This is the heart  * of the significant terms feature.  */ @Override public double getScore(long subsetFreq, long subsetSize, long supersetFreq, long supersetSize) {     checkFrequencyValidity(subsetFreq, subsetSize, supersetFreq, supersetSize, "JLHScore").     if ((subsetSize == 0) || (supersetSize == 0)) {         // avoid any divide by zero issues         return 0.     }     if (supersetFreq == 0) {         // If we are using a background context that is not a strict superset, a foreground         // term may be missing from the background, so for the purposes of this calculation         // we assume a value of 1 for our calculations which avoids returning an "infinity" result         supersetFreq = 1.     }     double subsetProbability = (double) subsetFreq / (double) subsetSize.     double supersetProbability = (double) supersetFreq / (double) supersetSize.     // Using absoluteProbabilityChange alone favours very common words e.g. you, we etc     // because a doubling in popularity of a common term is a big percent difference     // whereas a rare term would have to achieve a hundred-fold increase in popularity to     // achieve the same difference measure.     // In favouring common words as suggested features for search we would get high     // recall but low precision.     double absoluteProbabilityChange = subsetProbability - supersetProbability.     if (absoluteProbabilityChange <= 0) {         return 0.     }     // Using relativeProbabilityChange tends to favour rarer terms e.g.mis-spellings or     // unique URLs.     // A very low-probability term can very easily double in popularity due to the low     // numbers required to do so whereas a high-probability term would have to add many     // extra individual sightings to achieve the same shift.     // In favouring rare words as suggested features for search we would get high     // precision but low recall.     double relativeProbabilityChange = (subsetProbability / supersetProbability).     // balance between precision and recall.     return absoluteProbabilityChange * relativeProbabilityChange. }
false;public;2;5;;@Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {     builder.startObject(NAME).endObject().     return builder. }
false;public,static;1;10;;public static SignificanceHeuristic parse(XContentParser parser) throws IOException, QueryShardException {     // move to the closing bracket     if (!parser.nextToken().equals(XContentParser.Token.END_OBJECT)) {         throw new ElasticsearchParseException("failed to parse [jlh] significance heuristic. expected an empty object, but found [{}] instead", parser.currentToken()).     }     return new JLHScore(). }
false;public;1;7;;@Override public boolean equals(Object obj) {     if (obj == null || obj.getClass() != getClass()) {         return false.     }     return true. }
false;public;0;4;;@Override public int hashCode() {     return getClass().hashCode(). }
false;public;2;5;;@Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {     builder.startObject(NAME).endObject().     return builder. }
