commented;modifiers;parameterAmount;loc;comment;code
false;public;0;3;;public boolean hasNested() {     return this.hasNested. }
false;public;0;3;;public IndexAnalyzers getIndexAnalyzers() {     return this.indexAnalyzers. }
false;public;1;3;;public NamedAnalyzer getNamedAnalyzer(String analyzerName) {     return this.indexAnalyzers.get(analyzerName). }
false;public;0;3;;public DocumentMapperParser documentMapperParser() {     return this.documentParser. }
true;public,static;2;6;/**  * Parses the mappings (formatted as JSON) into a map  */ ;/**  * Parses the mappings (formatted as JSON) into a map  */ public static Map<String, Object> parseMapping(NamedXContentRegistry xContentRegistry, String mappingSource) throws Exception {     try (XContentParser parser = XContentType.JSON.xContent().createParser(xContentRegistry, LoggingDeprecationHandler.INSTANCE, mappingSource)) {         return parser.map().     } }
true;public;2;58;/**  * Update mapping by only merging the metadata that is different between received and stored entries  */ ;/**  * Update mapping by only merging the metadata that is different between received and stored entries  */ public boolean updateMapping(final IndexMetaData currentIndexMetaData, final IndexMetaData newIndexMetaData) throws IOException {     assert newIndexMetaData.getIndex().equals(index()) : "index mismatch: expected " + index() + " but was " + newIndexMetaData.getIndex().     // go over and add the relevant mappings (or update them)     Set<String> existingMappers = new HashSet<>().     if (mapper != null) {         existingMappers.add(mapper.type()).     }     if (defaultMapper != null) {         existingMappers.add(DEFAULT_MAPPING).     }     final Map<String, DocumentMapper> updatedEntries.     try {         // only update entries if needed         updatedEntries = internalMerge(newIndexMetaData, MergeReason.MAPPING_RECOVERY, true).     } catch (Exception e) {         logger.warn(() -> new ParameterizedMessage("[{}] failed to apply mappings", index()), e).         throw e.     }     boolean requireRefresh = false.     assertMappingVersion(currentIndexMetaData, newIndexMetaData, updatedEntries).     for (DocumentMapper documentMapper : updatedEntries.values()) {         String mappingType = documentMapper.type().         MappingMetaData mappingMetaData.         if (mappingType.equals(MapperService.DEFAULT_MAPPING)) {             mappingMetaData = newIndexMetaData.defaultMapping().         } else {             mappingMetaData = newIndexMetaData.mapping().             assert mappingType.equals(mappingMetaData.type()).         }         CompressedXContent incomingMappingSource = mappingMetaData.source().         String op = existingMappers.contains(mappingType) ? "updated" : "added".         if (logger.isDebugEnabled() && incomingMappingSource.compressed().length < 512) {             logger.debug("[{}] {} mapping [{}], source [{}]", index(), op, mappingType, incomingMappingSource.string()).         } else if (logger.isTraceEnabled()) {             logger.trace("[{}] {} mapping [{}], source [{}]", index(), op, mappingType, incomingMappingSource.string()).         } else {             logger.debug("[{}] {} mapping [{}] (source suppressed due to length, use TRACE level if needed)", index(), op, mappingType).         }         // merge version of it, which it does when refreshing the mappings), and warn log it.         if (documentMapper(mappingType).mappingSource().equals(incomingMappingSource) == false) {             logger.debug("[{}] parsed mapping [{}], and got different sources\noriginal:\n{}\nparsed:\n{}", index(), mappingType, incomingMappingSource, documentMapper(mappingType).mappingSource()).             requireRefresh = true.         }     }     return requireRefresh. }
false;private;3;56;;private void assertMappingVersion(final IndexMetaData currentIndexMetaData, final IndexMetaData newIndexMetaData, final Map<String, DocumentMapper> updatedEntries) {     if (Assertions.ENABLED && currentIndexMetaData != null && currentIndexMetaData.getCreationVersion().onOrAfter(Version.V_6_5_0)) {         if (currentIndexMetaData.getMappingVersion() == newIndexMetaData.getMappingVersion()) {             // if the mapping version is unchanged, then there should not be any updates and all mappings should be the same             assert updatedEntries.isEmpty() : updatedEntries.             MappingMetaData defaultMapping = newIndexMetaData.defaultMapping().             if (defaultMapping != null) {                 final CompressedXContent currentSource = currentIndexMetaData.defaultMapping().source().                 final CompressedXContent newSource = defaultMapping.source().                 assert currentSource.equals(newSource) : "expected current mapping [" + currentSource + "] for type [" + defaultMapping.type() + "] " + "to be the same as new mapping [" + newSource + "]".             }             MappingMetaData mapping = newIndexMetaData.mapping().             if (mapping != null) {                 final CompressedXContent currentSource = currentIndexMetaData.mapping().source().                 final CompressedXContent newSource = mapping.source().                 assert currentSource.equals(newSource) : "expected current mapping [" + currentSource + "] for type [" + mapping.type() + "] " + "to be the same as new mapping [" + newSource + "]".             }         } else {             // if the mapping version is changed, it should increase, there should be updates, and the mapping should be different             final long currentMappingVersion = currentIndexMetaData.getMappingVersion().             final long newMappingVersion = newIndexMetaData.getMappingVersion().             assert currentMappingVersion < newMappingVersion : "expected current mapping version [" + currentMappingVersion + "] " + "to be less than new mapping version [" + newMappingVersion + "]".             assert updatedEntries.isEmpty() == false.             for (final DocumentMapper documentMapper : updatedEntries.values()) {                 final MappingMetaData currentMapping.                 if (documentMapper.type().equals(MapperService.DEFAULT_MAPPING)) {                     currentMapping = currentIndexMetaData.defaultMapping().                 } else {                     currentMapping = currentIndexMetaData.mapping().                     assert currentMapping == null || documentMapper.type().equals(currentMapping.type()).                 }                 if (currentMapping != null) {                     final CompressedXContent currentSource = currentMapping.source().                     final CompressedXContent newSource = documentMapper.mappingSource().                     assert currentSource.equals(newSource) == false : "expected current mapping [" + currentSource + "] for type [" + documentMapper.type() + "] " + "to be different than new mapping".                 }             }         }     } }
false;public;2;13;;public void merge(Map<String, Map<String, Object>> mappings, MergeReason reason) {     Map<String, CompressedXContent> mappingSourcesCompressed = new LinkedHashMap<>(mappings.size()).     for (Map.Entry<String, Map<String, Object>> entry : mappings.entrySet()) {         try {             mappingSourcesCompressed.put(entry.getKey(), new CompressedXContent(Strings.toString(XContentFactory.jsonBuilder().map(entry.getValue())))).         } catch (Exception e) {             throw new MapperParsingException("Failed to parse mapping [{}]: {}", e, entry.getKey(), e.getMessage()).         }     }     internalMerge(mappingSourcesCompressed, reason). }
false;public;2;3;;public void merge(IndexMetaData indexMetaData, MergeReason reason) {     internalMerge(indexMetaData, reason, false). }
false;public;3;3;;public DocumentMapper merge(String type, CompressedXContent mappingSource, MergeReason reason) {     return internalMerge(Collections.singletonMap(type, mappingSource), reason).get(type). }
false;private,synchronized;3;16;;private synchronized Map<String, DocumentMapper> internalMerge(IndexMetaData indexMetaData, MergeReason reason, boolean onlyUpdateIfNeeded) {     Map<String, CompressedXContent> map = new LinkedHashMap<>().     for (ObjectCursor<MappingMetaData> cursor : indexMetaData.getMappings().values()) {         MappingMetaData mappingMetaData = cursor.value.         if (onlyUpdateIfNeeded) {             DocumentMapper existingMapper = documentMapper(mappingMetaData.type()).             if (existingMapper == null || mappingMetaData.source().equals(existingMapper.mappingSource()) == false) {                 map.put(mappingMetaData.type(), mappingMetaData.source()).             }         } else {             map.put(mappingMetaData.type(), mappingMetaData.source()).         }     }     return internalMerge(map, reason). }
false;private,synchronized;2;49;;private synchronized Map<String, DocumentMapper> internalMerge(Map<String, CompressedXContent> mappings, MergeReason reason) {     DocumentMapper defaultMapper = null.     String defaultMappingSource = null.     if (mappings.containsKey(DEFAULT_MAPPING)) {         // NOTE: never apply the default here         try {             defaultMapper = documentParser.parse(DEFAULT_MAPPING, mappings.get(DEFAULT_MAPPING)).         } catch (Exception e) {             throw new MapperParsingException("Failed to parse mapping [{}]: {}", e, DEFAULT_MAPPING, e.getMessage()).         }         defaultMappingSource = mappings.get(DEFAULT_MAPPING).string().     }     final String defaultMappingSourceOrLastStored.     if (defaultMappingSource != null) {         defaultMappingSourceOrLastStored = defaultMappingSource.     } else {         defaultMappingSourceOrLastStored = this.defaultMappingSource.     }     DocumentMapper documentMapper = null.     for (Map.Entry<String, CompressedXContent> entry : mappings.entrySet()) {         String type = entry.getKey().         if (type.equals(DEFAULT_MAPPING)) {             continue.         }         if (documentMapper != null) {             throw new IllegalArgumentException("Cannot put multiple mappings: " + mappings.keySet()).         }         final boolean applyDefault = // the default was already applied if we are recovering         reason != MergeReason.MAPPING_RECOVERY && // only apply the default mapping if we don't have the type yet         this.mapper == null.         try {             documentMapper = documentParser.parse(type, entry.getValue(), applyDefault ? defaultMappingSourceOrLastStored : null).         } catch (Exception e) {             throw new MapperParsingException("Failed to parse mapping [{}]: {}", e, entry.getKey(), e.getMessage()).         }     }     return internalMerge(defaultMapper, defaultMappingSource, documentMapper, reason). }
false;static;1;22;;static void validateTypeName(String type) {     if (type.length() == 0) {         throw new InvalidTypeNameException("mapping type name is empty").     }     if (type.length() > 255) {         throw new InvalidTypeNameException("mapping type name [" + type + "] is too long. limit is length 255 but was [" + type.length() + "]").     }     if (type.charAt(0) == '_' && SINGLE_MAPPING_NAME.equals(type) == false) {         throw new InvalidTypeNameException("mapping type name [" + type + "] can't start with '_' unless it is called [" + SINGLE_MAPPING_NAME + "]").     }     if (type.contains("#")) {         throw new InvalidTypeNameException("mapping type name [" + type + "] should not include '#' in it").     }     if (type.contains(",")) {         throw new InvalidTypeNameException("mapping type name [" + type + "] should not include ',' in it").     }     if (type.charAt(0) == '.') {         throw new IllegalArgumentException("mapping type name [" + type + "] must not start with a '.'").     } }
false;private,synchronized;4;135;;private synchronized Map<String, DocumentMapper> internalMerge(@Nullable DocumentMapper defaultMapper, @Nullable String defaultMappingSource, DocumentMapper mapper, MergeReason reason) {     boolean hasNested = this.hasNested.     Map<String, ObjectMapper> fullPathObjectMappers = this.fullPathObjectMappers.     FieldTypeLookup fieldTypes = this.fieldTypes.     Map<String, DocumentMapper> results = new LinkedHashMap<>(2).     if (defaultMapper != null) {         if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_0_0)) {             throw new IllegalArgumentException("The [default] mapping cannot be updated on index [" + index().getName() + "]: defaults mappings are not useful anymore now that indices can have at most one type.").         } else if (reason == MergeReason.MAPPING_UPDATE) {             // only log in case of explicit mapping updates             deprecationLogger.deprecated("[_default_] mapping is deprecated since it is not useful anymore now that indexes " + "cannot have more than one type").         }         assert defaultMapper.type().equals(DEFAULT_MAPPING).         results.put(DEFAULT_MAPPING, defaultMapper).     }     {         if (mapper != null && this.mapper != null && Objects.equals(this.mapper.type(), mapper.type()) == false) {             throw new IllegalArgumentException("Rejecting mapping update to [" + index().getName() + "] as the final mapping would have more than 1 type: " + Arrays.asList(this.mapper.type(), mapper.type())).         }     }     DocumentMapper newMapper = null.     if (mapper != null) {         // check naming         validateTypeName(mapper.type()).         // compute the merged DocumentMapper         DocumentMapper oldMapper = this.mapper.         if (oldMapper != null) {             newMapper = oldMapper.merge(mapper.mapping()).         } else {             newMapper = mapper.         }         // check basic sanity of the new mapping         List<ObjectMapper> objectMappers = new ArrayList<>().         List<FieldMapper> fieldMappers = new ArrayList<>().         List<FieldAliasMapper> fieldAliasMappers = new ArrayList<>().         MetadataFieldMapper[] metadataMappers = newMapper.mapping().metadataMappers.         Collections.addAll(fieldMappers, metadataMappers).         MapperUtils.collect(newMapper.mapping().root(), objectMappers, fieldMappers, fieldAliasMappers).         MapperMergeValidator.validateMapperStructure(newMapper.type(), objectMappers, fieldMappers, fieldAliasMappers, fullPathObjectMappers, fieldTypes).         checkPartitionedIndexConstraints(newMapper).         // update lookup data-structures         // this will in particular make sure that the merged fields are compatible with other types         fieldTypes = fieldTypes.copyAndAddAll(newMapper.type(), fieldMappers, fieldAliasMappers).         for (ObjectMapper objectMapper : objectMappers) {             if (fullPathObjectMappers == this.fullPathObjectMappers) {                 // first time through the loops                 fullPathObjectMappers = new HashMap<>(this.fullPathObjectMappers).             }             fullPathObjectMappers.put(objectMapper.fullPath(), objectMapper).             if (objectMapper.nested().isNested()) {                 hasNested = true.             }         }         MapperMergeValidator.validateFieldReferences(fieldMappers, fieldAliasMappers, fullPathObjectMappers, fieldTypes).         ContextMapping.validateContextPaths(indexSettings.getIndexVersionCreated(), fieldMappers, fieldTypes::get).         if (reason == MergeReason.MAPPING_UPDATE) {             // this check will only be performed on the master node when there is             // a call to the update mapping API. For all other cases like             // the master node restoring mappings from disk or data nodes             // deserializing cluster state that was sent by the master node,             // this check will be skipped.             // Also, don't take metadata mappers into account for the field limit check             checkTotalFieldsLimit(objectMappers.size() + fieldMappers.size() - metadataMappers.length + fieldAliasMappers.size()).         }         results.put(newMapper.type(), newMapper).     }     if (reason == MergeReason.MAPPING_UPDATE) {         // this check will only be performed on the master node when there is         // a call to the update mapping API. For all other cases like         // the master node restoring mappings from disk or data nodes         // deserializing cluster state that was sent by the master node,         // this check will be skipped.         checkNestedFieldsLimit(fullPathObjectMappers).         checkDepthLimit(fullPathObjectMappers.keySet()).     }     checkIndexSortCompatibility(indexSettings.getIndexSortConfig(), hasNested).     if (newMapper != null) {         DocumentMapper updatedDocumentMapper = newMapper.updateFieldType(fieldTypes.fullNameToFieldType).         if (updatedDocumentMapper != newMapper) {             // update both mappers and result             newMapper = updatedDocumentMapper.             results.put(updatedDocumentMapper.type(), updatedDocumentMapper).         }     }     // make structures immutable     results = Collections.unmodifiableMap(results).     // if not then they are already implicitly immutable.     if (fullPathObjectMappers != this.fullPathObjectMappers) {         fullPathObjectMappers = Collections.unmodifiableMap(fullPathObjectMappers).     }     // commit the change     if (defaultMappingSource != null) {         this.defaultMappingSource = defaultMappingSource.         this.defaultMapper = defaultMapper.     }     if (newMapper != null) {         this.mapper = newMapper.     }     this.fieldTypes = fieldTypes.     this.hasNested = hasNested.     this.fullPathObjectMappers = fullPathObjectMappers.     assert assertMappersShareSameFieldType().     assert results.values().stream().allMatch(this::assertSerialization).     return results. }
false;private;0;11;;private boolean assertMappersShareSameFieldType() {     if (mapper != null) {         List<FieldMapper> fieldMappers = new ArrayList<>().         Collections.addAll(fieldMappers, mapper.mapping().metadataMappers).         MapperUtils.collect(mapper.root(), new ArrayList<>(), fieldMappers, new ArrayList<>()).         for (FieldMapper fieldMapper : fieldMappers) {             assert fieldMapper.fieldType() == fieldTypes.get(fieldMapper.name()) : fieldMapper.name().         }     }     return true. }
false;private;1;12;;private boolean assertSerialization(DocumentMapper mapper) {     // capture the source now, it may change due to concurrent parsing     final CompressedXContent mappingSource = mapper.mappingSource().     DocumentMapper newMapper = parse(mapper.type(), mappingSource, false).     if (newMapper.mappingSource().equals(mappingSource) == false) {         throw new IllegalStateException("DocumentMapper serialization result is different from source. \n--> Source [" + mappingSource + "]\n--> Result [" + newMapper.mappingSource() + "]").     }     return true. }
false;private;1;13;;private void checkNestedFieldsLimit(Map<String, ObjectMapper> fullPathObjectMappers) {     long allowedNestedFields = indexSettings.getValue(INDEX_MAPPING_NESTED_FIELDS_LIMIT_SETTING).     long actualNestedFields = 0.     for (ObjectMapper objectMapper : fullPathObjectMappers.values()) {         if (objectMapper.nested().isNested()) {             actualNestedFields++.         }     }     if (actualNestedFields > allowedNestedFields) {         throw new IllegalArgumentException("Limit of nested fields [" + allowedNestedFields + "] in index [" + index().getName() + "] has been exceeded").     } }
false;private;1;7;;private void checkTotalFieldsLimit(long totalMappers) {     long allowedTotalFields = indexSettings.getValue(INDEX_MAPPING_TOTAL_FIELDS_LIMIT_SETTING).     if (allowedTotalFields < totalMappers) {         throw new IllegalArgumentException("Limit of total fields [" + allowedTotalFields + "] in index [" + index().getName() + "] has been exceeded").     } }
false;private;1;6;;private void checkDepthLimit(Collection<String> objectPaths) {     final long maxDepth = indexSettings.getValue(INDEX_MAPPING_DEPTH_LIMIT_SETTING).     for (String objectPath : objectPaths) {         checkDepthLimit(objectPath, maxDepth).     } }
false;private;2;13;;private void checkDepthLimit(String objectPath, long maxDepth) {     int numDots = 0.     for (int i = 0. i < objectPath.length(). ++i) {         if (objectPath.charAt(i) == '.') {             numDots += 1.         }     }     final int depth = numDots + 2.     if (depth > maxDepth) {         throw new IllegalArgumentException("Limit of mapping depth [" + maxDepth + "] in index [" + index().getName() + "] has been exceeded due to object field [" + objectPath + "]").     } }
false;private;1;8;;private void checkPartitionedIndexConstraints(DocumentMapper newMapper) {     if (indexSettings.getIndexMetaData().isRoutingPartitionedIndex()) {         if (!newMapper.routingFieldMapper().required()) {             throw new IllegalArgumentException("mapping type [" + newMapper.type() + "] must have routing " + "required for partitioned index [" + indexSettings.getIndex().getName() + "]").         }     } }
false;private,static;2;5;;private static void checkIndexSortCompatibility(IndexSortConfig sortConfig, boolean hasNested) {     if (sortConfig.hasIndexSort() && hasNested) {         throw new IllegalArgumentException("cannot have nested fields when index sort is activated").     } }
false;public;3;3;;public DocumentMapper parse(String mappingType, CompressedXContent mappingSource, boolean applyDefault) throws MapperParsingException {     return documentParser.parse(mappingType, mappingSource, applyDefault ? defaultMappingSource : null). }
true;public;0;3;/**  * Return the document mapper, or {@code null} if no mapping has been put yet.  */ ;/**  * Return the document mapper, or {@code null} if no mapping has been put yet.  */ public DocumentMapper documentMapper() {     return mapper. }
true;public;1;9;/**  * Return the {@link DocumentMapper} for the given type. By using the special  * {@value #DEFAULT_MAPPING} type, you can get a {@link DocumentMapper} for  * the default mapping.  */ ;/**  * Return the {@link DocumentMapper} for the given type. By using the special  * {@value #DEFAULT_MAPPING} type, you can get a {@link DocumentMapper} for  * the default mapping.  */ public DocumentMapper documentMapper(String type) {     if (mapper != null && type.equals(mapper.type())) {         return mapper.     }     if (DEFAULT_MAPPING.equals(type)) {         return defaultMapper.     }     return null. }
true;public,static;2;3;/**  * Returns {@code true} if the given {@code mappingSource} includes a type  * as a top-level object.  */ ;/**  * Returns {@code true} if the given {@code mappingSource} includes a type  * as a top-level object.  */ public static boolean isMappingSourceTyped(String type, Map<String, Object> mapping) {     return mapping.size() == 1 && mapping.keySet().iterator().next().equals(type). }
false;public,static;2;4;;public static boolean isMappingSourceTyped(String type, CompressedXContent mappingSource) {     Map<String, Object> root = XContentHelper.convertToMap(mappingSource.compressedReference(), true, XContentType.JSON).v2().     return isMappingSourceTyped(type, root). }
true;public;1;8;/**  * Resolves a type from a mapping-related request into the type that should be used when  * merging and updating mappings.  *  * If the special `_doc` type is provided, then we replace it with the actual type that is  * being used in the mappings. This allows typeless APIs such as 'index' or 'put mappings'  * to work against indices with a custom type name.  */ ;/**  * Resolves a type from a mapping-related request into the type that should be used when  * merging and updating mappings.  *  * If the special `_doc` type is provided, then we replace it with the actual type that is  * being used in the mappings. This allows typeless APIs such as 'index' or 'put mappings'  * to work against indices with a custom type name.  */ public String resolveDocumentType(String type) {     if (MapperService.SINGLE_MAPPING_NAME.equals(type)) {         if (mapper != null) {             return mapper.type().         }     }     return type. }
true;public;1;8;/**  * Returns the document mapper created, including a mapping update if the  * type has been dynamically created.  */ ;/**  * Returns the document mapper created, including a mapping update if the  * type has been dynamically created.  */ public DocumentMapperForType documentMapperWithAutoCreate(String type) {     DocumentMapper mapper = documentMapper(type).     if (mapper != null) {         return new DocumentMapperForType(mapper, null).     }     mapper = parse(type, null, true).     return new DocumentMapperForType(mapper, mapper.mapping()). }
true;public;1;3;/**  * Returns the {@link MappedFieldType} for the give fullName.  *  * If multiple types have fields with the same full name, the first is returned.  */ ;/**  * Returns the {@link MappedFieldType} for the give fullName.  *  * If multiple types have fields with the same full name, the first is returned.  */ public MappedFieldType fullName(String fullName) {     return fieldTypes.get(fullName). }
true;public;1;7;/**  * Returns all the fields that match the given pattern. If the pattern is prefixed with a type  * then the fields will be returned with a type prefix.  */ ;/**  * Returns all the fields that match the given pattern. If the pattern is prefixed with a type  * then the fields will be returned with a type prefix.  */ public Collection<String> simpleMatchToFullName(String pattern) {     if (Regex.isSimpleMatchPattern(pattern) == false) {         // no wildcards         return Collections.singletonList(pattern).     }     return fieldTypes.simpleMatchToFullName(pattern). }
true;public;0;3;/**  * Returns all mapped field types.  */ ;/**  * Returns all mapped field types.  */ public Iterable<MappedFieldType> fieldTypes() {     return fieldTypes. }
false;public;1;3;;public ObjectMapper getObjectMapper(String name) {     return fullPathObjectMappers.get(name). }
true;public;1;24;/**  * Given a type (eg. long, string, ...), return an anonymous field mapper that can be used for search operations.  */ ;/**  * Given a type (eg. long, string, ...), return an anonymous field mapper that can be used for search operations.  */ public MappedFieldType unmappedFieldType(String type) {     if (type.equals("string")) {         deprecationLogger.deprecated("[unmapped_type:string] should be replaced with [unmapped_type:keyword]").         type = "keyword".     }     MappedFieldType fieldType = unmappedFieldTypes.get(type).     if (fieldType == null) {         final Mapper.TypeParser.ParserContext parserContext = documentMapperParser().parserContext(type).         Mapper.TypeParser typeParser = parserContext.typeParser(type).         if (typeParser == null) {             throw new IllegalArgumentException("No mapper found for type [" + type + "]").         }         final Mapper.Builder<?, ?> builder = typeParser.parse("__anonymous_" + type, emptyMap(), parserContext).         final BuilderContext builderContext = new BuilderContext(indexSettings.getSettings(), new ContentPath(1)).         fieldType = ((FieldMapper) builder.build(builderContext)).fieldType().         // There is no need to synchronize writes here. In the case of concurrent access, we could just         // compute some mappers several times, which is not a big deal         Map<String, MappedFieldType> newUnmappedFieldTypes = new HashMap<>(unmappedFieldTypes).         newUnmappedFieldTypes.put(type, fieldType).         unmappedFieldTypes = unmodifiableMap(newUnmappedFieldTypes).     }     return fieldType. }
false;public;0;3;;public Analyzer indexAnalyzer() {     return this.indexAnalyzer. }
false;public;0;3;;public Analyzer searchAnalyzer() {     return this.searchAnalyzer. }
false;public;0;3;;public Analyzer searchQuoteAnalyzer() {     return this.searchQuoteAnalyzer. }
false;public;0;4;;@Override public void close() throws IOException {     indexAnalyzers.close(). }
true;public,static;1;3;/**  * @return Whether a field is a metadata field.  */ ;/**  * @return Whether a field is a metadata field.  */ public static boolean isMetadataField(String fieldName) {     return META_FIELDS.contains(fieldName). }
false;public,static;0;3;;public static String[] getAllMetaFields() {     return Arrays.copyOf(SORTED_META_FIELDS, SORTED_META_FIELDS.length). }
false;protected;1;11;;@Override protected Analyzer getWrappedAnalyzer(String fieldName) {     MappedFieldType fieldType = fullName(fieldName).     if (fieldType != null) {         Analyzer analyzer = extractAnalyzer.apply(fieldType).         if (analyzer != null) {             return analyzer.         }     }     return defaultAnalyzer. }
