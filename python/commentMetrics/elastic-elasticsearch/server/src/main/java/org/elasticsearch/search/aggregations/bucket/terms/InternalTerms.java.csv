commented;modifiers;parameterAmount;loc;comment;code
false;;3;1;;B read(StreamInput in, DocValueFormat format, boolean showDocCountError) throws IOException.
false;public,final;1;9;;@Override public final void writeTo(StreamOutput out) throws IOException {     out.writeVLong(getDocCount()).     if (showDocCountError) {         out.writeLong(docCountError).     }     aggregations.writeTo(out).     writeTermTo(out). }
false;protected,abstract;1;1;;protected abstract void writeTermTo(StreamOutput out) throws IOException.
false;public;0;4;;@Override public long getDocCount() {     return docCount. }
false;public;0;7;;@Override public long getDocCountError() {     if (!showDocCountError) {         throw new IllegalStateException("show_terms_doc_count_error is false").     }     return docCountError. }
false;public;0;4;;@Override public Aggregations getAggregations() {     return aggregations. }
false;abstract;3;1;;abstract B newBucket(long docCount, InternalAggregations aggs, long docCountError).
false;public;2;22;;public B reduce(List<B> buckets, ReduceContext context) {     long docCount = 0.     // For the per term doc count error we add up the errors from the     // shards that did not respond with the term. To do this we add up     // the errors from the shards that did respond with the terms and     // subtract that from the sum of the error from all shards     long docCountError = 0.     List<InternalAggregations> aggregationsList = new ArrayList<>(buckets.size()).     for (B bucket : buckets) {         docCount += bucket.docCount.         if (docCountError != -1) {             if (bucket.docCountError == -1) {                 docCountError = -1.             } else {                 docCountError += bucket.docCountError.             }         }         aggregationsList.add(bucket.aggregations).     }     InternalAggregations aggs = InternalAggregations.reduce(aggregationsList, context).     return newBucket(docCount, aggs, docCountError). }
false;public,final;2;12;;@Override public final XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {     builder.startObject().     keyToXContent(builder).     builder.field(CommonFields.DOC_COUNT.getPreferredName(), getDocCount()).     if (showDocCountError) {         builder.field(InternalTerms.DOC_COUNT_ERROR_UPPER_BOUND_FIELD_NAME.getPreferredName(), getDocCountError()).     }     aggregations.toXContentInternal(builder, params).     builder.endObject().     return builder. }
false;protected,abstract;1;1;;protected abstract XContentBuilder keyToXContent(XContentBuilder builder) throws IOException.
false;public;1;13;;@Override public boolean equals(Object obj) {     if (obj == null || getClass() != obj.getClass()) {         return false.     }     Bucket<?> that = (Bucket<?>) obj.     // for serialization purposes     return Objects.equals(docCount, that.docCount) && Objects.equals(docCountError, that.docCountError) && Objects.equals(aggregations, that.aggregations). }
false;public;0;4;;@Override public int hashCode() {     return Objects.hash(getClass(), docCount, docCountError, aggregations). }
false;protected,final;1;7;;@Override protected final void doWriteTo(StreamOutput out) throws IOException {     order.writeTo(out).     writeSize(requiredSize, out).     out.writeVLong(minDocCount).     writeTermTypeInfoTo(out). }
false;protected,abstract;1;1;;protected abstract void writeTermTypeInfoTo(StreamOutput out) throws IOException.
false;public,abstract;0;2;;@Override public abstract List<B> getBuckets().
false;public,abstract;1;2;;@Override public abstract B getBucketByKey(String term).
false;public;2;97;;@Override public InternalAggregation doReduce(List<InternalAggregation> aggregations, ReduceContext reduceContext) {     Map<Object, List<B>> buckets = new HashMap<>().     long sumDocCountError = 0.     long otherDocCount = 0.     InternalTerms<A, B> referenceTerms = null.     for (InternalAggregation aggregation : aggregations) {         @SuppressWarnings("unchecked")         InternalTerms<A, B> terms = (InternalTerms<A, B>) aggregation.         if (referenceTerms == null && !aggregation.getClass().equals(UnmappedTerms.class)) {             referenceTerms = terms.         }         if (referenceTerms != null && !referenceTerms.getClass().equals(terms.getClass()) && !terms.getClass().equals(UnmappedTerms.class)) {             // is of different types in different indices.             throw new AggregationExecutionException("Merging/Reducing the aggregations failed when computing the aggregation [" + referenceTerms.getName() + "] because the field you gave in the aggregation query existed as two different " + "types in two different indices").         }         otherDocCount += terms.getSumOfOtherDocCounts().         final long thisAggDocCountError.         if (terms.getBuckets().size() < getShardSize() || InternalOrder.isKeyOrder(order)) {             thisAggDocCountError = 0.         } else if (InternalOrder.isCountDesc(order)) {             if (terms.getDocCountError() > 0) {                 // If there is an existing docCountError for this agg then                 // use this as the error for this aggregation                 thisAggDocCountError = terms.getDocCountError().             } else {                 // otherwise use the doc count of the last term in the                 // aggregation                 thisAggDocCountError = terms.getBuckets().get(terms.getBuckets().size() - 1).docCount.             }         } else {             thisAggDocCountError = -1.         }         if (sumDocCountError != -1) {             if (thisAggDocCountError == -1) {                 sumDocCountError = -1.             } else {                 sumDocCountError += thisAggDocCountError.             }         }         setDocCountError(thisAggDocCountError).         for (B bucket : terms.getBuckets()) {             // If there is already a doc count error for this bucket             // subtract this aggs doc count error from it to make the             // new value for the bucket. This then means that when the             // final error for the bucket is calculated below we account             // for the existing error calculated in a previous reduce.             // Note that if the error is unbounded (-1) this will be fixed             // later in this method.             bucket.docCountError -= thisAggDocCountError.             List<B> bucketList = buckets.get(bucket.getKey()).             if (bucketList == null) {                 bucketList = new ArrayList<>().                 buckets.put(bucket.getKey(), bucketList).             }             bucketList.add(bucket).         }     }     final int size = reduceContext.isFinalReduce() == false ? buckets.size() : Math.min(requiredSize, buckets.size()).     final BucketPriorityQueue<B> ordered = new BucketPriorityQueue<>(size, order.comparator(null)).     for (List<B> sameTermBuckets : buckets.values()) {         final B b = sameTermBuckets.get(0).reduce(sameTermBuckets, reduceContext).         if (sumDocCountError == -1) {             b.docCountError = -1.         } else {             b.docCountError += sumDocCountError.         }         if (b.docCount >= minDocCount || reduceContext.isFinalReduce() == false) {             B removed = ordered.insertWithOverflow(b).             if (removed != null) {                 otherDocCount += removed.getDocCount().                 reduceContext.consumeBucketsAndMaybeBreak(-countInnerBucket(removed)).             } else {                 reduceContext.consumeBucketsAndMaybeBreak(1).             }         } else {             reduceContext.consumeBucketsAndMaybeBreak(-countInnerBucket(b)).         }     }     B[] list = createBucketsArray(ordered.size()).     for (int i = ordered.size() - 1. i >= 0. i--) {         list[i] = ordered.pop().     }     long docCountError.     if (sumDocCountError == -1) {         docCountError = -1.     } else {         docCountError = aggregations.size() == 1 ? 0 : sumDocCountError.     }     return create(name, Arrays.asList(list), docCountError, otherDocCount). }
false;protected,abstract;1;1;;protected abstract void setDocCountError(long docCountError).
false;protected,abstract;0;1;;protected abstract int getShardSize().
false;protected,abstract;4;1;;protected abstract A create(String name, List<B> buckets, long docCountError, long otherDocCount).
true;protected,abstract;1;1;/**  * Create an array to hold some buckets. Used in collecting the results.  */ ;/**  * Create an array to hold some buckets. Used in collecting the results.  */ protected abstract B[] createBucketsArray(int size).
false;protected;1;7;;@Override protected boolean doEquals(Object obj) {     InternalTerms<?, ?> that = (InternalTerms<?, ?>) obj.     return Objects.equals(minDocCount, that.minDocCount) && Objects.equals(order, that.order) && Objects.equals(requiredSize, that.requiredSize). }
false;protected;0;4;;@Override protected int doHashCode() {     return Objects.hash(minDocCount, order, requiredSize). }
false;protected,static;5;11;;protected static XContentBuilder doXContentCommon(XContentBuilder builder, Params params, long docCountError, long otherDocCount, List<? extends Bucket> buckets) throws IOException {     builder.field(DOC_COUNT_ERROR_UPPER_BOUND_FIELD_NAME.getPreferredName(), docCountError).     builder.field(SUM_OF_OTHER_DOC_COUNTS.getPreferredName(), otherDocCount).     builder.startArray(CommonFields.BUCKETS.getPreferredName()).     for (Bucket bucket : buckets) {         bucket.toXContent(builder, params).     }     builder.endArray().     return builder. }
