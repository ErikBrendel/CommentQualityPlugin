commented;modifiers;parameterAmount;loc;comment;code
false;public;1;18;;@Override public Query rewrite(IndexReader reader) throws IOException {     Query rewritten = super.rewrite(reader).     if (rewritten != this) {         return rewritten.     }     IndexReaderContext context = reader.getContext().     TermStates[] ctx = new TermStates[terms.length].     int[] docFreqs = new int[ctx.length].     for (int i = 0. i < terms.length. i++) {         ctx[i] = TermStates.build(context, terms[i], true).         docFreqs[i] = ctx[i].docFreq().     }     final int maxDoc = reader.maxDoc().     blend(ctx, maxDoc, reader).     return topLevelQuery(terms, ctx, docFreqs, maxDoc). }
false;protected,abstract;4;1;;protected abstract Query topLevelQuery(Term[] terms, TermStates[] ctx, int[] docFreqs, int maxDoc).
false;protected;2;6;;@Override protected void swap(int i, int j) {     final int tmp = tieBreak[i].     tieBreak[i] = tieBreak[j].     tieBreak[j] = tmp. }
false;protected;2;4;;@Override protected int compare(int i, int j) {     return Integer.compare(contexts[tieBreak[j]].docFreq(), contexts[tieBreak[i]].docFreq()). }
false;protected;3;84;;protected void blend(final TermStates[] contexts, int maxDoc, IndexReader reader) throws IOException {     if (contexts.length <= 1) {         return.     }     int max = 0.     long minSumTTF = Long.MAX_VALUE.     for (int i = 0. i < contexts.length. i++) {         TermStates ctx = contexts[i].         int df = ctx.docFreq().         // we use the max here since it's the only "true" estimation we can make here         // at least max(df) documents have that term. Sum or Averages don't seem         // to have a significant meaning here.         // TODO: Maybe it could also make sense to assume independent distributions of documents and eg. have:         // df = df1 + df2 - (df1 * df2 / maxDoc)?         max = Math.max(df, max).         if (minSumTTF != -1 && ctx.totalTermFreq() != -1) {             // we need to find out the minimum sumTTF to adjust the statistics             // otherwise the statistics don't match             minSumTTF = Math.min(minSumTTF, reader.getSumTotalTermFreq(terms[i].field())).         } else {             minSumTTF = -1.         }     }     if (minSumTTF != -1 && maxDoc > minSumTTF) {         maxDoc = (int) minSumTTF.     }     if (max == 0) {         // we are done that term doesn't exist at all         return.     }     long sumTTF = minSumTTF == -1 ? -1 : 0.     final int[] tieBreak = new int[contexts.length].     for (int i = 0. i < tieBreak.length. ++i) {         tieBreak[i] = i.     }     new InPlaceMergeSorter() {          @Override         protected void swap(int i, int j) {             final int tmp = tieBreak[i].             tieBreak[i] = tieBreak[j].             tieBreak[j] = tmp.         }          @Override         protected int compare(int i, int j) {             return Integer.compare(contexts[tieBreak[j]].docFreq(), contexts[tieBreak[i]].docFreq()).         }     }.sort(0, tieBreak.length).     int prev = contexts[tieBreak[0]].docFreq().     int actualDf = Math.min(maxDoc, max).     assert actualDf >= 0 : "DF must be >= 0".     // that acts as a tie breaker     for (int i : tieBreak) {         TermStates ctx = contexts[i].         if (ctx.docFreq() == 0) {             break.         }         final int current = ctx.docFreq().         if (prev > current) {             actualDf++.         }         contexts[i] = ctx = adjustDF(reader.getContext(), ctx, Math.min(maxDoc, actualDf)).         prev = current.         if (sumTTF >= 0 && ctx.totalTermFreq() >= 0) {             sumTTF += ctx.totalTermFreq().         } else {             // omit once TF is omitted anywhere!             sumTTF = -1.         }     }     sumTTF = Math.min(sumTTF, minSumTTF).     for (int i = 0. i < contexts.length. i++) {         int df = contexts[i].docFreq().         if (df == 0) {             continue.         }         // the blended sumTTF can't be greater than the sumTTTF on the field         final long fixedTTF = sumTTF == -1 ? -1 : sumTTF.         contexts[i] = adjustTTF(reader.getContext(), contexts[i], fixedTTF).     } }
false;private;3;26;;private TermStates adjustTTF(IndexReaderContext readerContext, TermStates termContext, long sumTTF) throws IOException {     assert termContext.wasBuiltFor(readerContext).     if (sumTTF == -1 && termContext.totalTermFreq() == -1) {         return termContext.     }     TermStates newTermContext = new TermStates(readerContext).     List<LeafReaderContext> leaves = readerContext.leaves().     final int len.     if (leaves == null) {         len = 1.     } else {         len = leaves.size().     }     int df = termContext.docFreq().     long ttf = sumTTF.     for (int i = 0. i < len. i++) {         TermState termState = termContext.get(leaves.get(i)).         if (termState == null) {             continue.         }         newTermContext.register(termState, i, df, ttf).         df = 0.         ttf = 0.     }     return newTermContext. }
false;private,static;3;28;;private static TermStates adjustDF(IndexReaderContext readerContext, TermStates ctx, int newDocFreq) throws IOException {     assert ctx.wasBuiltFor(readerContext).     // Use a value of ttf that is consistent with the doc freq (ie. gte)     long newTTF.     if (ctx.totalTermFreq() < 0) {         newTTF = -1.     } else {         newTTF = Math.max(ctx.totalTermFreq(), newDocFreq).     }     List<LeafReaderContext> leaves = readerContext.leaves().     final int len.     if (leaves == null) {         len = 1.     } else {         len = leaves.size().     }     TermStates newCtx = new TermStates(readerContext).     for (int i = 0. i < len. ++i) {         TermState termState = ctx.get(leaves.get(i)).         if (termState == null) {             continue.         }         newCtx.register(termState, i, newDocFreq, newTTF).         newDocFreq = 0.         newTTF = 0.     }     return newCtx. }
false;public;0;3;;public List<Term> getTerms() {     return Arrays.asList(terms). }
false;public;1;20;;@Override public String toString(String field) {     StringBuilder builder = new StringBuilder("blended(terms:[").     for (int i = 0. i < terms.length. ++i) {         builder.append(terms[i]).         float boost = 1f.         if (boosts != null) {             boost = boosts[i].         }         if (boost != 1f) {             builder.append('^').append(boost).         }         builder.append(", ").     }     if (terms.length > 0) {         builder.setLength(builder.length() - 2).     }     builder.append("])").     return builder.toString(). }
false;private;0;15;;private Term[] equalsTerms() {     if (terms.length == 1) {         return terms.     }     if (equalTerms == null) {         // sort the terms to make sure equals and hashCode are consistent         // this should be a very small cost and equivalent to a HashSet but less object creation         final Term[] t = new Term[terms.length].         System.arraycopy(terms, 0, t, 0, terms.length).         ArrayUtil.timSort(t).         equalTerms = t.     }     return equalTerms. }
false;public;1;8;;@Override public boolean equals(Object o) {     if (this == o)         return true.     if (sameClassAs(o) == false)         return false.     BlendedTermQuery that = (BlendedTermQuery) o.     return Arrays.equals(equalsTerms(), that.equalsTerms()). }
false;public;0;4;;@Override public int hashCode() {     return Objects.hash(classHash(), Arrays.hashCode(equalsTerms())). }
false;protected;4;34;;@Override protected Query topLevelQuery(Term[] terms, TermStates[] ctx, int[] docFreqs, int maxDoc) {     BooleanQuery.Builder highBuilder = new BooleanQuery.Builder().     BooleanQuery.Builder lowBuilder = new BooleanQuery.Builder().     for (int i = 0. i < terms.length. i++) {         Query query = new TermQuery(terms[i], ctx[i]).         if (boosts != null && boosts[i] != 1f) {             query = new BoostQuery(query, boosts[i]).         }         if ((maxTermFrequency >= 1f && docFreqs[i] > maxTermFrequency) || (docFreqs[i] > (int) Math.ceil(maxTermFrequency * maxDoc))) {             highBuilder.add(query, BooleanClause.Occur.SHOULD).         } else {             lowBuilder.add(query, BooleanClause.Occur.SHOULD).         }     }     BooleanQuery high = highBuilder.build().     BooleanQuery low = lowBuilder.build().     if (low.clauses().isEmpty()) {         BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder().         for (BooleanClause booleanClause : high) {             queryBuilder.add(booleanClause.getQuery(), Occur.MUST).         }         return queryBuilder.build().     } else if (high.clauses().isEmpty()) {         return low.     } else {         return new BooleanQuery.Builder().add(high, BooleanClause.Occur.SHOULD).add(low, BooleanClause.Occur.MUST).build().     } }
false;public,static;3;38;;public static BlendedTermQuery commonTermsBlendedQuery(Term[] terms, final float[] boosts, final float maxTermFrequency) {     return new BlendedTermQuery(terms, boosts) {          @Override         protected Query topLevelQuery(Term[] terms, TermStates[] ctx, int[] docFreqs, int maxDoc) {             BooleanQuery.Builder highBuilder = new BooleanQuery.Builder().             BooleanQuery.Builder lowBuilder = new BooleanQuery.Builder().             for (int i = 0. i < terms.length. i++) {                 Query query = new TermQuery(terms[i], ctx[i]).                 if (boosts != null && boosts[i] != 1f) {                     query = new BoostQuery(query, boosts[i]).                 }                 if ((maxTermFrequency >= 1f && docFreqs[i] > maxTermFrequency) || (docFreqs[i] > (int) Math.ceil(maxTermFrequency * maxDoc))) {                     highBuilder.add(query, BooleanClause.Occur.SHOULD).                 } else {                     lowBuilder.add(query, BooleanClause.Occur.SHOULD).                 }             }             BooleanQuery high = highBuilder.build().             BooleanQuery low = lowBuilder.build().             if (low.clauses().isEmpty()) {                 BooleanQuery.Builder queryBuilder = new BooleanQuery.Builder().                 for (BooleanClause booleanClause : high) {                     queryBuilder.add(booleanClause.getQuery(), Occur.MUST).                 }                 return queryBuilder.build().             } else if (high.clauses().isEmpty()) {                 return low.             } else {                 return new BooleanQuery.Builder().add(high, BooleanClause.Occur.SHOULD).add(low, BooleanClause.Occur.MUST).build().             }         }     }. }
false;public,static;2;3;;public static BlendedTermQuery dismaxBlendedQuery(Term[] terms, final float tieBreakerMultiplier) {     return dismaxBlendedQuery(terms, null, tieBreakerMultiplier). }
false;protected;4;12;;@Override protected Query topLevelQuery(Term[] terms, TermStates[] ctx, int[] docFreqs, int maxDoc) {     List<Query> queries = new ArrayList<>(ctx.length).     for (int i = 0. i < terms.length. i++) {         Query query = new TermQuery(terms[i], ctx[i]).         if (boosts != null && boosts[i] != 1f) {             query = new BoostQuery(query, boosts[i]).         }         queries.add(query).     }     return new DisjunctionMaxQuery(queries, tieBreakerMultiplier). }
false;public,static;3;16;;public static BlendedTermQuery dismaxBlendedQuery(Term[] terms, final float[] boosts, final float tieBreakerMultiplier) {     return new BlendedTermQuery(terms, boosts) {          @Override         protected Query topLevelQuery(Term[] terms, TermStates[] ctx, int[] docFreqs, int maxDoc) {             List<Query> queries = new ArrayList<>(ctx.length).             for (int i = 0. i < terms.length. i++) {                 Query query = new TermQuery(terms[i], ctx[i]).                 if (boosts != null && boosts[i] != 1f) {                     query = new BoostQuery(query, boosts[i]).                 }                 queries.add(query).             }             return new DisjunctionMaxQuery(queries, tieBreakerMultiplier).         }     }. }
