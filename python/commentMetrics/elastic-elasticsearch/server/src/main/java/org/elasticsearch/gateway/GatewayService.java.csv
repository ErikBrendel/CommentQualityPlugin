commented;modifiers;parameterAmount;loc;comment;code
false;protected;0;5;;@Override protected void doStart() {     // use post applied so that the state will be visible to the background recovery thread we spawn in performStateRecovery     clusterService.addListener(this). }
false;protected;0;4;;@Override protected void doStop() {     clusterService.removeListener(this). }
false;protected;0;3;;@Override protected void doClose() { }
false;public;1;55;;@Override public void clusterChanged(final ClusterChangedEvent event) {     if (lifecycle.stoppedOrClosed()) {         return.     }     final ClusterState state = event.state().     if (state.nodes().isLocalNodeElectedMaster() == false) {         // not our job to recover         return.     }     if (state.blocks().hasGlobalBlock(STATE_NOT_RECOVERED_BLOCK) == false) {         // already recovered         return.     }     final DiscoveryNodes nodes = state.nodes().     if (state.nodes().getMasterNodeId() == null) {         logger.debug("not recovering from gateway, no master elected yet").     } else if (recoverAfterNodes != -1 && (nodes.getMasterAndDataNodes().size()) < recoverAfterNodes) {         logger.debug("not recovering from gateway, nodes_size (data+master) [{}] < recover_after_nodes [{}]", nodes.getMasterAndDataNodes().size(), recoverAfterNodes).     } else if (recoverAfterDataNodes != -1 && nodes.getDataNodes().size() < recoverAfterDataNodes) {         logger.debug("not recovering from gateway, nodes_size (data) [{}] < recover_after_data_nodes [{}]", nodes.getDataNodes().size(), recoverAfterDataNodes).     } else if (recoverAfterMasterNodes != -1 && nodes.getMasterNodes().size() < recoverAfterMasterNodes) {         logger.debug("not recovering from gateway, nodes_size (master) [{}] < recover_after_master_nodes [{}]", nodes.getMasterNodes().size(), recoverAfterMasterNodes).     } else {         boolean enforceRecoverAfterTime.         String reason.         if (expectedNodes == -1 && expectedMasterNodes == -1 && expectedDataNodes == -1) {             // no expected is set, honor the setting if they are there             enforceRecoverAfterTime = true.             reason = "recover_after_time was set to [" + recoverAfterTime + "]".         } else {             // one of the expected is set, see if all of them meet the need, and ignore the timeout in this case             enforceRecoverAfterTime = false.             reason = "".             if (expectedNodes != -1 && (nodes.getMasterAndDataNodes().size() < expectedNodes)) {                 // does not meet the expected...                 enforceRecoverAfterTime = true.                 reason = "expecting [" + expectedNodes + "] nodes, but only have [" + nodes.getMasterAndDataNodes().size() + "]".             } else if (expectedDataNodes != -1 && (nodes.getDataNodes().size() < expectedDataNodes)) {                 // does not meet the expected...                 enforceRecoverAfterTime = true.                 reason = "expecting [" + expectedDataNodes + "] data nodes, but only have [" + nodes.getDataNodes().size() + "]".             } else if (expectedMasterNodes != -1 && (nodes.getMasterNodes().size() < expectedMasterNodes)) {                 // does not meet the expected...                 enforceRecoverAfterTime = true.                 reason = "expecting [" + expectedMasterNodes + "] master nodes, but only have [" + nodes.getMasterNodes().size() + "]".             }         }         performStateRecovery(enforceRecoverAfterTime, reason).     } }
false;public;1;7;;@Override public void onFailure(final Exception e) {     logger.warn("Recovery failed", e).     // we reset `recovered` in the listener don't reset it here otherwise there might be a race     // that resets it to false while a new recover is already running?     GatewayService.this.onFailure("state recovery failed: " + e.getMessage()). }
false;protected;0;4;;@Override protected void doRun() {     recoveryRunnable.run(). }
false;private;2;30;;private void performStateRecovery(final boolean enforceRecoverAfterTime, final String reason) {     if (enforceRecoverAfterTime && recoverAfterTime != null) {         if (scheduledRecovery.compareAndSet(false, true)) {             logger.info("delaying initial state recovery for [{}]. {}", recoverAfterTime, reason).             threadPool.schedule(() -> {                 if (recovered.compareAndSet(false, true)) {                     logger.info("recover_after_time [{}] elapsed. performing state recovery...", recoverAfterTime).                     recoveryRunnable.run().                 }             }, recoverAfterTime, ThreadPool.Names.GENERIC).         }     } else {         if (recovered.compareAndSet(false, true)) {             threadPool.generic().execute(new AbstractRunnable() {                  @Override                 public void onFailure(final Exception e) {                     logger.warn("Recovery failed", e).                     // we reset `recovered` in the listener don't reset it here otherwise there might be a race                     // that resets it to false while a new recover is already running?                     GatewayService.this.onFailure("state recovery failed: " + e.getMessage()).                 }                  @Override                 protected void doRun() {                     recoveryRunnable.run().                 }             }).         }     } }
false;private;1;6;;private void onFailure(final String message) {     recovered.set(false).     scheduledRecovery.set(false).     // don't remove the block here, we don't want to allow anything in such a case     logger.info("metadata state not restored, reason: {}", message). }
false;public;1;9;;@Override public ClusterState execute(final ClusterState currentState) {     final ClusterState newState = Function.<ClusterState>identity().andThen(ClusterStateUpdaters::updateRoutingTable).andThen(ClusterStateUpdaters::removeStateNotRecoveredBlock).apply(currentState).     return allocationService.reroute(newState, "state recovered"). }
false;public;3;4;;@Override public void clusterStateProcessed(final String source, final ClusterState oldState, final ClusterState newState) {     logger.info("recovered [{}] indices into cluster_state", newState.metaData().indices().size()). }
false;public;2;5;;@Override public void onFailure(final String source, final Exception e) {     logger.info(() -> new ParameterizedMessage("unexpected failure during [{}]", source), e).     GatewayService.this.onFailure("failed to update cluster state"). }
false;public;1;5;;@Override public ClusterState execute(final ClusterState currentState) {     final ClusterState updatedState = ClusterStateUpdaters.mixCurrentStateAndRecoveredState(currentState, recoveredState).     return super.execute(ClusterStateUpdaters.recoverClusterBlocks(updatedState)). }
false;public;1;11;;@Override public void onSuccess(final ClusterState recoveredState) {     logger.trace("successful state recovery, importing cluster state...").     clusterService.submitStateUpdateTask("local-gateway-elected-state", new RecoverStateUpdateTask() {          @Override         public ClusterState execute(final ClusterState currentState) {             final ClusterState updatedState = ClusterStateUpdaters.mixCurrentStateAndRecoveredState(currentState, recoveredState).             return super.execute(ClusterStateUpdaters.recoverClusterBlocks(updatedState)).         }     }). }
false;public;1;4;;@Override public void onFailure(final String msg) {     GatewayService.this.onFailure(msg). }
true;;0;3;// used for testing ;// used for testing TimeValue recoverAfterTime() {     return recoverAfterTime. }
