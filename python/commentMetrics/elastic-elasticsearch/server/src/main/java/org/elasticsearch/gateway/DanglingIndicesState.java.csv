commented;modifiers;parameterAmount;loc;comment;code
true;public;1;8;/**  * Process dangling indices based on the provided meta data, handling cleanup, finding  * new dangling indices, and allocating outstanding ones.  */ ;/**  * Process dangling indices based on the provided meta data, handling cleanup, finding  * new dangling indices, and allocating outstanding ones.  */ public void processDanglingIndices(final MetaData metaData) {     if (nodeEnv.hasNodeFile() == false) {         return.     }     cleanupAllocatedDangledIndices(metaData).     findNewAndAddDanglingIndices(metaData).     allocateDanglingIndices(). }
true;;0;4;/**  * The current set of dangling indices.  */ ;/**  * The current set of dangling indices.  */ Map<Index, IndexMetaData> getDanglingIndices() {     // This might be a good use case for CopyOnWriteHashMap     return unmodifiableMap(new HashMap<>(danglingIndices)). }
true;;1;14;/**  * Cleans dangling indices if they are already allocated on the provided meta data.  */ ;/**  * Cleans dangling indices if they are already allocated on the provided meta data.  */ void cleanupAllocatedDangledIndices(MetaData metaData) {     for (Index index : danglingIndices.keySet()) {         final IndexMetaData indexMetaData = metaData.index(index).         if (indexMetaData != null && indexMetaData.getIndex().getName().equals(index.getName())) {             if (indexMetaData.getIndex().getUUID().equals(index.getUUID()) == false) {                 logger.warn("[{}] can not be imported as a dangling index, as there is already another index " + "with the same name but a different uuid. local index will be ignored (but not deleted)", index).             } else {                 logger.debug("[{}] no longer dangling (created), removing from dangling list", index).             }             danglingIndices.remove(index).         }     } }
true;;1;3;/**  * Finds (@{link #findNewAndAddDanglingIndices}) and adds the new dangling indices  * to the currently tracked dangling indices.  */ ;/**  * Finds (@{link #findNewAndAddDanglingIndices}) and adds the new dangling indices  * to the currently tracked dangling indices.  */ void findNewAndAddDanglingIndices(final MetaData metaData) {     danglingIndices.putAll(findNewDanglingIndices(metaData)). }
true;;1;30;/**  * Finds new dangling indices by iterating over the indices and trying to find indices  * that have state on disk, but are not part of the provided meta data, or not detected  * as dangled already.  */ ;/**  * Finds new dangling indices by iterating over the indices and trying to find indices  * that have state on disk, but are not part of the provided meta data, or not detected  * as dangled already.  */ Map<Index, IndexMetaData> findNewDanglingIndices(final MetaData metaData) {     final Set<String> excludeIndexPathIds = new HashSet<>(metaData.indices().size() + danglingIndices.size()).     for (ObjectCursor<IndexMetaData> cursor : metaData.indices().values()) {         excludeIndexPathIds.add(cursor.value.getIndex().getUUID()).     }     excludeIndexPathIds.addAll(danglingIndices.keySet().stream().map(Index::getUUID).collect(Collectors.toList())).     try {         final List<IndexMetaData> indexMetaDataList = metaStateService.loadIndicesStates(excludeIndexPathIds::contains).         Map<Index, IndexMetaData> newIndices = new HashMap<>(indexMetaDataList.size()).         final IndexGraveyard graveyard = metaData.indexGraveyard().         for (IndexMetaData indexMetaData : indexMetaDataList) {             if (metaData.hasIndex(indexMetaData.getIndex().getName())) {                 logger.warn("[{}] can not be imported as a dangling index, as index with same name already exists in cluster metadata", indexMetaData.getIndex()).             } else if (graveyard.containsIndex(indexMetaData.getIndex())) {                 logger.warn("[{}] can not be imported as a dangling index, as an index with the same name and UUID exist in the " + "index tombstones.  This situation is likely caused by copying over the data directory for an index " + "that was previously deleted.", indexMetaData.getIndex()).             } else {                 logger.info("[{}] dangling index exists on local file system, but not in cluster metadata, " + "auto import to cluster state", indexMetaData.getIndex()).                 newIndices.put(indexMetaData.getIndex(), indexMetaData).             }         }         return newIndices.     } catch (IOException e) {         logger.warn("failed to list dangling indices", e).         return emptyMap().     } }
false;public;1;4;;@Override public void onResponse(LocalAllocateDangledIndices.AllocateDangledResponse response) {     logger.trace("allocated dangled"). }
false;public;1;4;;@Override public void onFailure(Throwable e) {     logger.info("failed to send allocated dangled", e). }
true;private;0;22;/**  * Allocates the provided list of the dangled indices by sending them to the master node  * for allocation.  */ ;/**  * Allocates the provided list of the dangled indices by sending them to the master node  * for allocation.  */ private void allocateDanglingIndices() {     if (danglingIndices.isEmpty()) {         return.     }     try {         allocateDangledIndices.allocateDangled(Collections.unmodifiableCollection(new ArrayList<>(danglingIndices.values())), new LocalAllocateDangledIndices.Listener() {              @Override             public void onResponse(LocalAllocateDangledIndices.AllocateDangledResponse response) {                 logger.trace("allocated dangled").             }              @Override             public void onFailure(Throwable e) {                 logger.info("failed to send allocated dangled", e).             }         }).     } catch (Exception e) {         logger.warn("failed to send allocate dangled", e).     } }
false;public;1;6;;@Override public void clusterChanged(ClusterChangedEvent event) {     if (event.state().blocks().disableStatePersistence() == false) {         processDanglingIndices(event.state().metaData()).     } }
