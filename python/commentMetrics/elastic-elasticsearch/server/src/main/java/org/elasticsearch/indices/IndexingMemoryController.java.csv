commented;modifiers;parameterAmount;loc;comment;code
false;protected;1;4;;protected Cancellable scheduleTask(ThreadPool threadPool) {     // it's fine to run it on the scheduler thread, no busy work     return threadPool.scheduleWithFixedDelay(statusChecker, interval, Names.SAME). }
false;public;0;4;;@Override public void close() {     scheduler.cancel(). }
true;;0;3;/**  * returns the current budget for the total amount of indexing buffers of  * active shards on this node  */ ;/**  * returns the current budget for the total amount of indexing buffers of  * active shards on this node  */ ByteSizeValue indexingBufferSize() {     return indexingBuffer. }
false;protected;0;9;;protected List<IndexShard> availableShards() {     List<IndexShard> availableShards = new ArrayList<>().     for (IndexShard shard : indexShards) {         if (CAN_WRITE_INDEX_BUFFER_STATES.contains(shard.state())) {             availableShards.add(shard).         }     }     return availableShards. }
true;protected;1;3;/**  * returns how much heap this shard is using for its indexing buffer  */ ;/**  * returns how much heap this shard is using for its indexing buffer  */ protected long getIndexBufferRAMBytesUsed(IndexShard shard) {     return shard.getIndexBufferRAMBytesUsed(). }
true;protected;1;3;/**  * returns how many bytes this shard is currently writing to disk  */ ;/**  * returns how many bytes this shard is currently writing to disk  */ protected long getShardWritingBytes(IndexShard shard) {     return shard.getWritingBytes(). }
false;public;0;4;;@Override public void doRun() {     shard.writeIndexingBuffer(). }
false;public;1;4;;@Override public void onFailure(Exception e) {     logger.warn(() -> new ParameterizedMessage("failed to write indexing buffer for shard [{}]. ignoring", shard.shardId()), e). }
true;protected;1;13;/**  * ask this shard to refresh, in the background, to free up heap  */ ;/**  * ask this shard to refresh, in the background, to free up heap  */ protected void writeIndexingBufferAsync(IndexShard shard) {     threadPool.executor(ThreadPool.Names.REFRESH).execute(new AbstractRunnable() {          @Override         public void doRun() {             shard.writeIndexingBuffer().         }          @Override         public void onFailure(Exception e) {             logger.warn(() -> new ParameterizedMessage("failed to write indexing buffer for shard [{}]. ignoring", shard.shardId()), e).         }     }). }
true;;0;3;/**  * force checker to run now  */ ;/**  * force checker to run now  */ void forceCheck() {     statusChecker.run(). }
true;protected;1;3;/**  * Asks this shard to throttle indexing to one thread  */ ;/**  * Asks this shard to throttle indexing to one thread  */ protected void activateThrottling(IndexShard shard) {     shard.activateThrottling(). }
true;protected;1;3;/**  * Asks this shard to stop throttling indexing to one thread  */ ;/**  * Asks this shard to stop throttling indexing to one thread  */ protected void deactivateThrottling(IndexShard shard) {     shard.deactivateThrottling(). }
false;public;3;4;;@Override public void postIndex(ShardId shardId, Engine.Index index, Engine.IndexResult result) {     recordOperationBytes(index, result). }
false;public;3;4;;@Override public void postDelete(ShardId shardId, Engine.Delete delete, Engine.DeleteResult result) {     recordOperationBytes(delete, result). }
true;private;2;5;/**  * called by IndexShard to record estimated bytes written to translog for the operation  */ ;/**  * called by IndexShard to record estimated bytes written to translog for the operation  */ private void recordOperationBytes(Engine.Operation operation, Engine.Result result) {     if (result.getResultType() == Engine.Result.Type.SUCCESS) {         statusChecker.bytesWritten(operation.estimatedSizeInBytes()).     } }
false;public;1;5;;@Override public int compareTo(ShardAndBytesUsed other) {     // Sort larger shards first:     return Long.compare(other.bytesUsed, bytesUsed). }
true;public;1;30;/**  * Shard calls this on each indexing/delete op  */ ;/**  * Shard calls this on each indexing/delete op  */ public void bytesWritten(int bytes) {     long totalBytes = bytesWrittenSinceCheck.addAndGet(bytes).     assert totalBytes >= 0.     while (totalBytes > indexingBuffer.getBytes() / 30) {         if (runLock.tryLock()) {             try {                 // Must pull this again because it may have changed since we first checked:                 totalBytes = bytesWrittenSinceCheck.get().                 if (totalBytes > indexingBuffer.getBytes() / 30) {                     bytesWrittenSinceCheck.addAndGet(-totalBytes).                     // NOTE: this is only an approximate check, because bytes written is to the translog,                     // vs indexing memory buffer which is typically smaller but can be larger in extreme                     // cases (many unique terms).  This logic is here only as a safety against thread                     // starvation or too infrequent checking, to ensure we are still checking periodically,                     // in proportion to bytes processed by indexing:                     runUnlocked().                 }             } finally {                 runLock.unlock().             }             // Must get it again since other threads could have increased it while we were in runUnlocked             totalBytes = bytesWrittenSinceCheck.get().         } else {             // Another thread beat us to it: let them do all the work, yay!             break.         }     } }
false;public;0;9;;@Override public void run() {     runLock.lock().     try {         runUnlocked().     } finally {         runLock.unlock().     } }
false;private;0;100;;private void runUnlocked() {     // NOTE: even if we hit an errant exc here, our ThreadPool.scheduledWithFixedDelay will log the exception and re-invoke us     // again, on schedule     // First pass to sum up how much heap all shards' indexing buffers are using now, and how many bytes they are currently moving     // to disk:     long totalBytesUsed = 0.     long totalBytesWriting = 0.     for (IndexShard shard : availableShards()) {         // Give shard a chance to transition to inactive so sync'd flush can happen:         checkIdle(shard, inactiveTime.nanos()).         // How many bytes this shard is currently (async'd) moving from heap to disk:         long shardWritingBytes = getShardWritingBytes(shard).         // How many heap bytes this shard is currently using         long shardBytesUsed = getIndexBufferRAMBytesUsed(shard).         shardBytesUsed -= shardWritingBytes.         totalBytesWriting += shardWritingBytes.         // have a negative value here.  So we just skip this shard since that means it's now using very little heap:         if (shardBytesUsed < 0) {             continue.         }         totalBytesUsed += shardBytesUsed.     }     if (logger.isTraceEnabled()) {         logger.trace("total indexing heap bytes used [{}] vs {} [{}], currently writing bytes [{}]", new ByteSizeValue(totalBytesUsed), INDEX_BUFFER_SIZE_SETTING.getKey(), indexingBuffer, new ByteSizeValue(totalBytesWriting)).     }     // If we are using more than 50% of our budget across both indexing buffer and bytes we are still moving to disk, then we now     // throttle the top shards to send back-pressure to ongoing indexing:     boolean doThrottle = (totalBytesWriting + totalBytesUsed) > 1.5 * indexingBuffer.getBytes().     if (totalBytesUsed > indexingBuffer.getBytes()) {         // OK we are now over-budget. fill the priority queue and ask largest shard(s) to refresh:         PriorityQueue<ShardAndBytesUsed> queue = new PriorityQueue<>().         for (IndexShard shard : availableShards()) {             // How many bytes this shard is currently (async'd) moving from heap to disk:             long shardWritingBytes = getShardWritingBytes(shard).             // How many heap bytes this shard is currently using             long shardBytesUsed = getIndexBufferRAMBytesUsed(shard).             // Only count up bytes not already being refreshed:             shardBytesUsed -= shardWritingBytes.             // have a negative value here.  So we just skip this shard since that means it's now using very little heap:             if (shardBytesUsed < 0) {                 continue.             }             if (shardBytesUsed > 0) {                 if (logger.isTraceEnabled()) {                     if (shardWritingBytes != 0) {                         logger.trace("shard [{}] is using [{}] heap, writing [{}] heap", shard.shardId(), shardBytesUsed, shardWritingBytes).                     } else {                         logger.trace("shard [{}] is using [{}] heap, not writing any bytes", shard.shardId(), shardBytesUsed).                     }                 }                 queue.add(new ShardAndBytesUsed(shardBytesUsed, shard)).             }         }         logger.debug("now write some indexing buffers: total indexing heap bytes used [{}] vs {} [{}], " + "currently writing bytes [{}], [{}] shards with non-zero indexing buffer", new ByteSizeValue(totalBytesUsed), INDEX_BUFFER_SIZE_SETTING.getKey(), indexingBuffer, new ByteSizeValue(totalBytesWriting), queue.size()).         while (totalBytesUsed > indexingBuffer.getBytes() && queue.isEmpty() == false) {             ShardAndBytesUsed largest = queue.poll().             logger.debug("write indexing buffer to disk for shard [{}] to free up its [{}] indexing buffer", largest.shard.shardId(), new ByteSizeValue(largest.bytesUsed)).             writeIndexingBufferAsync(largest.shard).             totalBytesUsed -= largest.bytesUsed.             if (doThrottle && throttled.contains(largest.shard) == false) {                 logger.info("now throttling indexing for shard [{}]: segment writing can't keep up", largest.shard.shardId()).                 throttled.add(largest.shard).                 activateThrottling(largest.shard).             }         }     }     if (doThrottle == false) {         for (IndexShard shard : throttled) {             logger.info("stop throttling indexing for shard [{}]", shard.shardId()).             deactivateThrottling(shard).         }         throttled.clear().     } }
true;protected;2;7;/**  * ask this shard to check now whether it is inactive, and reduces its indexing buffer if so.  */ ;/**  * ask this shard to check now whether it is inactive, and reduces its indexing buffer if so.  */ protected void checkIdle(IndexShard shard, long inactiveTimeNS) {     try {         shard.checkIdle(inactiveTimeNS).     } catch (AlreadyClosedException e) {         logger.trace(() -> new ParameterizedMessage("ignore exception while checking if shard {} is inactive", shard.shardId()), e).     } }
