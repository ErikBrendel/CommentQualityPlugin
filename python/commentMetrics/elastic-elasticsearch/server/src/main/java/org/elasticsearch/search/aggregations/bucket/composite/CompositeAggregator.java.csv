commented;modifiers;parameterAmount;loc;comment;code
false;protected;0;8;;@Override protected void doClose() {     try {         Releasables.close(queue).     } finally {         Releasables.close(sources).     } }
false;protected;0;6;;@Override protected void doPreCollection() throws IOException {     List<BucketCollector> collectors = Arrays.asList(subAggregators).     deferredCollectors = MultiBucketCollector.wrap(collectors).     collectableSubAggregators = BucketCollector.NO_OP_COLLECTOR. }
false;protected;0;4;;@Override protected void doPostCollection() throws IOException {     finishLeaf(). }
false;public;1;23;;@Override public InternalAggregation buildAggregation(long zeroBucket) throws IOException {     assert zeroBucket == 0L.     consumeBucketsAndMaybeBreak(queue.size()).     if (deferredCollectors != NO_OP_COLLECTOR) {         // Replay all documents that contain at least one top bucket (collected during the first pass).         runDeferredCollections().     }     int num = Math.min(size, queue.size()).     final InternalComposite.InternalBucket[] buckets = new InternalComposite.InternalBucket[num].     while (queue.size() > 0) {         int slot = queue.pop().         CompositeKey key = queue.toCompositeKey(slot).         InternalAggregations aggs = bucketAggregations(slot).         int docCount = queue.getDocCount(slot).         buckets[queue.size()] = new InternalComposite.InternalBucket(sourceNames, formats, key, reverseMuls, docCount, aggs).     }     CompositeKey lastBucket = num > 0 ? buckets[num - 1].getRawKey() : null.     return new InternalComposite(name, size, sourceNames, formats, Arrays.asList(buckets), lastBucket, reverseMuls, pipelineAggregators(), metaData()). }
false;public;0;5;;@Override public InternalAggregation buildEmptyAggregation() {     return new InternalComposite(name, size, sourceNames, formats, Collections.emptyList(), null, reverseMuls, pipelineAggregators(), metaData()). }
false;private;0;8;;private void finishLeaf() {     if (currentLeaf != null) {         DocIdSet docIdSet = docIdSetBuilder.build().         entries.add(new Entry(currentLeaf, docIdSet)).         currentLeaf = null.         docIdSetBuilder = null.     } }
false;public;2;5;;@Override public void collect(int doc, long zeroBucket) throws IOException {     assert zeroBucket == 0L.     inner.collect(doc). }
false;protected;2;36;;@Override protected LeafBucketCollector getLeafCollector(LeafReaderContext ctx, LeafBucketCollector sub) throws IOException {     finishLeaf().     boolean fillDocIdSet = deferredCollectors != NO_OP_COLLECTOR.     if (sortedDocsProducer != null) {         /*               The producer will visit documents sorted by the leading source of the composite definition               and terminates when the leading source value is guaranteed to be greater than the lowest               composite bucket in the queue.              */         DocIdSet docIdSet = sortedDocsProducer.processLeaf(context.query(), queue, ctx, fillDocIdSet).         if (fillDocIdSet) {             entries.add(new Entry(ctx, docIdSet)).         }         /*               We can bypass search entirely for this segment, all the processing has been done in the previous call.               Throwing this exception will terminate the execution of the search for this root aggregation,               see {@link org.apache.lucene.search.MultiCollector} for more details on how we handle early termination in aggregations.              */         throw new CollectionTerminatedException().     } else {         if (fillDocIdSet) {             currentLeaf = ctx.             docIdSetBuilder = new RoaringDocIdSet.Builder(ctx.reader().maxDoc()).         }         final LeafBucketCollector inner = queue.getLeafCollector(ctx, getFirstPassCollector(docIdSetBuilder)).         return new LeafBucketCollector() {              @Override             public void collect(int doc, long zeroBucket) throws IOException {                 assert zeroBucket == 0L.                 inner.collect(doc).             }         }.     } }
false;public;2;10;;@Override public void collect(int doc, long bucket) throws IOException {     int slot = queue.addIfCompetitive().     if (slot != -1) {         if (builder != null && lastDoc != doc) {             builder.add(doc).             lastDoc = doc.         }     } }
true;private;1;16;/**  * The first pass selects the top composite buckets from all matching documents.  */ ;/**  * The first pass selects the top composite buckets from all matching documents.  */ private LeafBucketCollector getFirstPassCollector(RoaringDocIdSet.Builder builder) {     return new LeafBucketCollector() {          int lastDoc = -1.          @Override         public void collect(int doc, long bucket) throws IOException {             int slot = queue.addIfCompetitive().             if (slot != -1) {                 if (builder != null && lastDoc != doc) {                     builder.add(doc).                     lastDoc = doc.                 }             }         }     }. }
true;private;0;36;/**  * Replay the documents that might contain a top bucket and pass top buckets to  * the {@link #deferredCollectors}.  */ ;/**  * Replay the documents that might contain a top bucket and pass top buckets to  * the {@link #deferredCollectors}.  */ private void runDeferredCollections() throws IOException {     final boolean needsScores = scoreMode().needsScores().     Weight weight = null.     if (needsScores) {         Query query = context.query().         weight = context.searcher().createWeight(context.searcher().rewrite(query), ScoreMode.COMPLETE, 1f).     }     deferredCollectors.preCollection().     for (Entry entry : entries) {         DocIdSetIterator docIdSetIterator = entry.docIdSet.iterator().         if (docIdSetIterator == null) {             continue.         }         final LeafBucketCollector subCollector = deferredCollectors.getLeafCollector(entry.context).         final LeafBucketCollector collector = queue.getLeafCollector(entry.context, getSecondPassCollector(subCollector)).         DocIdSetIterator scorerIt = null.         if (needsScores) {             Scorer scorer = weight.scorer(entry.context).             if (scorer != null) {                 scorerIt = scorer.iterator().                 subCollector.setScorer(scorer).             }         }         int docID.         while ((docID = docIdSetIterator.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {             if (needsScores) {                 assert scorerIt != null && scorerIt.docID() < docID.                 scorerIt.advance(docID).                 // aggregations should only be replayed on matching documents                 assert scorerIt.docID() == docID.             }             collector.collect(docID).         }     }     deferredCollectors.postCollection(). }
false;public;2;10;;@Override public void collect(int doc, long zeroBucket) throws IOException {     assert zeroBucket == 0.     Integer slot = queue.compareCurrent().     if (slot != null) {         // The candidate key is a top bucket.         // We can defer the collection of this document/bucket to the sub collector         subCollector.collect(doc, slot).     } }
true;private;1;14;/**  * Replay the top buckets from the matching documents.  */ ;/**  * Replay the top buckets from the matching documents.  */ private LeafBucketCollector getSecondPassCollector(LeafBucketCollector subCollector) {     return new LeafBucketCollector() {          @Override         public void collect(int doc, long zeroBucket) throws IOException {             assert zeroBucket == 0.             Integer slot = queue.compareCurrent().             if (slot != null) {                 // The candidate key is a top bucket.                 // We can defer the collection of this document/bucket to the sub collector                 subCollector.collect(doc, slot).             }         }     }. }
false;private;4;64;;private SingleDimensionValuesSource<?> createValuesSource(BigArrays bigArrays, IndexReader reader, CompositeValuesSourceConfig config, int size) {     final int reverseMul = config.reverseMul().     if (config.valuesSource() instanceof ValuesSource.Bytes.WithOrdinals && reader instanceof DirectoryReader) {         ValuesSource.Bytes.WithOrdinals vs = (ValuesSource.Bytes.WithOrdinals) config.valuesSource().         return new GlobalOrdinalValuesSource(bigArrays, config.fieldType(), vs::globalOrdinalsValues, config.format(), config.missingBucket(), size, reverseMul).     } else if (config.valuesSource() instanceof ValuesSource.Bytes) {         ValuesSource.Bytes vs = (ValuesSource.Bytes) config.valuesSource().         return new BinaryValuesSource(bigArrays, this::addRequestCircuitBreakerBytes, config.fieldType(), vs::bytesValues, config.format(), config.missingBucket(), size, reverseMul).     } else if (config.valuesSource() instanceof ValuesSource.Numeric) {         final ValuesSource.Numeric vs = (ValuesSource.Numeric) config.valuesSource().         if (vs.isFloatingPoint()) {             return new DoubleValuesSource(bigArrays, config.fieldType(), vs::doubleValues, config.format(), config.missingBucket(), size, reverseMul).         } else {             final LongUnaryOperator rounding.             if (vs instanceof RoundingValuesSource) {                 rounding = ((RoundingValuesSource) vs)::round.             } else {                 rounding = LongUnaryOperator.identity().             }             return new LongValuesSource(bigArrays, config.fieldType(), vs::longValues, rounding, config.format(), config.missingBucket(), size, reverseMul).         }     } else {         throw new IllegalArgumentException("Unknown values source type: " + config.valuesSource().getClass().getName() + " for source: " + config.name()).     } }
