commented;modifiers;parameterAmount;loc;comment;code
false;public;0;4;;@Override public TextFieldType fieldType() {     return (TextFieldType) super.fieldType(). }
false;public;1;7;;public Builder positionIncrementGap(int positionIncrementGap) {     if (positionIncrementGap < 0) {         throw new MapperParsingException("[positions_increment_gap] must be positive, got " + positionIncrementGap).     }     this.positionIncrementGap = positionIncrementGap.     return this. }
false;public;1;4;;public Builder fielddata(boolean fielddata) {     fieldType().setFielddata(fielddata).     return builder. }
false;public;1;4;;public Builder indexPhrases(boolean indexPhrases) {     fieldType().setIndexPhrases(indexPhrases).     return builder. }
false;public;1;7;;@Override public Builder docValues(boolean docValues) {     if (docValues) {         throw new IllegalArgumentException("[text] fields do not support doc values").     }     return super.docValues(docValues). }
false;public;1;4;;public Builder eagerGlobalOrdinals(boolean eagerGlobalOrdinals) {     fieldType().setEagerGlobalOrdinals(eagerGlobalOrdinals).     return builder. }
false;public;3;6;;public Builder fielddataFrequencyFilter(double minFreq, double maxFreq, int minSegmentSize) {     fieldType().setFielddataMinFrequency(minFreq).     fieldType().setFielddataMaxFrequency(maxFreq).     fieldType().setFielddataMinSegmentSize(minSegmentSize).     return builder. }
false;public;2;14;;public Builder indexPrefixes(int minChars, int maxChars) {     if (minChars > maxChars) {         throw new IllegalArgumentException("min_chars [" + minChars + "] must be less than max_chars [" + maxChars + "]").     }     if (minChars < 1) {         throw new IllegalArgumentException("min_chars [" + minChars + "] must be greater than zero").     }     if (maxChars >= 20) {         throw new IllegalArgumentException("max_chars [" + maxChars + "] must be less than 20").     }     this.prefixFieldType = new PrefixFieldType(name(), name() + "._index_prefix", minChars, maxChars).     fieldType().setPrefixFieldType(this.prefixFieldType).     return this. }
false;public;1;47;;@Override public TextFieldMapper build(BuilderContext context) {     if (positionIncrementGap != POSITION_INCREMENT_GAP_USE_ANALYZER) {         if (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {             throw new IllegalArgumentException("Cannot set position_increment_gap on field [" + name + "] without positions enabled").         }         fieldType.setIndexAnalyzer(new NamedAnalyzer(fieldType.indexAnalyzer(), positionIncrementGap)).         fieldType.setSearchAnalyzer(new NamedAnalyzer(fieldType.searchAnalyzer(), positionIncrementGap)).         fieldType.setSearchQuoteAnalyzer(new NamedAnalyzer(fieldType.searchQuoteAnalyzer(), positionIncrementGap)).     }     setupFieldType(context).     PrefixFieldMapper prefixMapper = null.     if (prefixFieldType != null) {         if (fieldType().isSearchable() == false) {             throw new IllegalArgumentException("Cannot set index_prefixes on unindexed field [" + name() + "]").         }         // the prefix field.         if (context.indexCreatedVersion().onOrAfter(Version.V_6_4_0)) {             if (fieldType.indexOptions() == IndexOptions.DOCS_AND_FREQS) {                 // frequencies are not needed because prefix queries always use a constant score                 prefixFieldType.setIndexOptions(IndexOptions.DOCS).             } else {                 prefixFieldType.setIndexOptions(fieldType.indexOptions()).             }         } else if (fieldType.indexOptions() == IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) {             prefixFieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS).         }         if (fieldType.storeTermVectorOffsets()) {             prefixFieldType.setStoreTermVectorOffsets(true).         }         prefixFieldType.setAnalyzer(fieldType.indexAnalyzer()).         prefixMapper = new PrefixFieldMapper(prefixFieldType, context.indexSettings()).     }     if (fieldType().indexPhrases) {         if (fieldType().isSearchable() == false) {             throw new IllegalArgumentException("Cannot set index_phrases on unindexed field [" + name() + "]").         }         if (fieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {             throw new IllegalArgumentException("Cannot set index_phrases on field [" + name() + "] if positions are not enabled").         }     }     return new TextFieldMapper(name, fieldType(), defaultFieldType, positionIncrementGap, prefixMapper, context.indexSettings(), multiFieldsBuilder.build(this, context), copyTo). }
false;public;3;45;;@Override public Mapper.Builder parse(String fieldName, Map<String, Object> node, ParserContext parserContext) throws MapperParsingException {     TextFieldMapper.Builder builder = new TextFieldMapper.Builder(fieldName).     builder.fieldType().setIndexAnalyzer(parserContext.getIndexAnalyzers().getDefaultIndexAnalyzer()).     builder.fieldType().setSearchAnalyzer(parserContext.getIndexAnalyzers().getDefaultSearchAnalyzer()).     builder.fieldType().setSearchQuoteAnalyzer(parserContext.getIndexAnalyzers().getDefaultSearchQuoteAnalyzer()).     parseTextField(builder, fieldName, node, parserContext).     for (Iterator<Map.Entry<String, Object>> iterator = node.entrySet().iterator(). iterator.hasNext(). ) {         Map.Entry<String, Object> entry = iterator.next().         String propName = entry.getKey().         Object propNode = entry.getValue().         if (propName.equals("position_increment_gap")) {             int newPositionIncrementGap = XContentMapValues.nodeIntegerValue(propNode, -1).             builder.positionIncrementGap(newPositionIncrementGap).             iterator.remove().         } else if (propName.equals("fielddata")) {             builder.fielddata(XContentMapValues.nodeBooleanValue(propNode, "fielddata")).             iterator.remove().         } else if (propName.equals("eager_global_ordinals")) {             builder.eagerGlobalOrdinals(XContentMapValues.nodeBooleanValue(propNode, "eager_global_ordinals")).             iterator.remove().         } else if (propName.equals("fielddata_frequency_filter")) {             Map<?, ?> frequencyFilter = (Map<?, ?>) propNode.             double minFrequency = XContentMapValues.nodeDoubleValue(frequencyFilter.remove("min"), 0).             double maxFrequency = XContentMapValues.nodeDoubleValue(frequencyFilter.remove("max"), Integer.MAX_VALUE).             int minSegmentSize = XContentMapValues.nodeIntegerValue(frequencyFilter.remove("min_segment_size"), 0).             builder.fielddataFrequencyFilter(minFrequency, maxFrequency, minSegmentSize).             DocumentMapperParser.checkNoRemainingFields(propName, frequencyFilter, parserContext.indexVersionCreated()).             iterator.remove().         } else if (propName.equals("index_prefixes")) {             Map<?, ?> indexPrefix = (Map<?, ?>) propNode.             int minChars = XContentMapValues.nodeIntegerValue(indexPrefix.remove("min_chars"), Defaults.INDEX_PREFIX_MIN_CHARS).             int maxChars = XContentMapValues.nodeIntegerValue(indexPrefix.remove("max_chars"), Defaults.INDEX_PREFIX_MAX_CHARS).             builder.indexPrefixes(minChars, maxChars).             DocumentMapperParser.checkNoRemainingFields(propName, indexPrefix, parserContext.indexVersionCreated()).             iterator.remove().         } else if (propName.equals("index_phrases")) {             builder.indexPhrases(XContentMapValues.nodeBooleanValue(propNode, "index_phrases")).             iterator.remove().         }     }     return builder. }
false;protected;1;4;;@Override protected Analyzer getWrappedAnalyzer(String fieldName) {     return delegate. }
false;protected;2;4;;@Override protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {     return new TokenStreamComponents(components.getSource(), new FixedShingleFilter(components.getTokenStream(), 2)). }
false;protected;1;4;;@Override protected Analyzer getWrappedAnalyzer(String fieldName) {     return delegate. }
false;protected;2;5;;@Override protected TokenStreamComponents wrapComponents(String fieldName, TokenStreamComponents components) {     TokenFilter filter = new EdgeNGramTokenFilter(components.getTokenStream(), minChars, maxChars, false).     return new TokenStreamComponents(components.getSource(), filter). }
false;;2;3;;void setAnalyzer(String name, Analyzer delegate) {     setIndexAnalyzer(new NamedAnalyzer(name, AnalyzerScope.INDEX, new PhraseWrappedAnalyzer(delegate))). }
false;public;0;4;;@Override public MappedFieldType clone() {     return new PhraseFieldType(parent). }
false;public;0;4;;@Override public String typeName() {     return "phrase". }
false;public;1;4;;@Override public Query existsQuery(QueryShardContext context) {     throw new UnsupportedOperationException(). }
false;;1;5;;PrefixFieldType setAnalyzer(NamedAnalyzer delegate) {     setIndexAnalyzer(new NamedAnalyzer(delegate.name(), AnalyzerScope.INDEX, new PrefixWrappedAnalyzer(delegate.analyzer(), minChars, maxChars))).     return this. }
false;;1;3;;boolean accept(int length) {     return length >= minChars - 1 && length <= maxChars. }
false;;1;6;;void doXContent(XContentBuilder builder) throws IOException {     builder.startObject("index_prefixes").     builder.field("min_chars", minChars).     builder.field("max_chars", maxChars).     builder.endObject(). }
false;public;3;18;;@Override public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {     if (value.length() >= minChars) {         return super.termQuery(value, context).     }     List<Automaton> automata = new ArrayList<>().     automata.add(Automata.makeString(value)).     for (int i = value.length(). i < minChars. i++) {         automata.add(Automata.makeAnyChar()).     }     Automaton automaton = Operations.concatenate(automata).     AutomatonQuery query = new AutomatonQuery(new Term(name(), value + "*"), automaton).     query.setRewriteMethod(method).     return new BooleanQuery.Builder().add(query, BooleanClause.Occur.SHOULD).add(new TermQuery(new Term(parentField, value)), BooleanClause.Occur.SHOULD).build(). }
false;public;0;4;;@Override public PrefixFieldType clone() {     return new PrefixFieldType(parentField, name(), minChars, maxChars). }
false;public;0;4;;@Override public String typeName() {     return "prefix". }
false;public;0;4;;@Override public String toString() {     return super.toString() + ",prefixChars=" + minChars + ":" + maxChars. }
false;public;1;4;;@Override public Query existsQuery(QueryShardContext context) {     throw new UnsupportedOperationException(). }
false;public;1;9;;@Override public boolean equals(Object o) {     if (this == o)         return true.     if (o == null || getClass() != o.getClass())         return false.     if (!super.equals(o))         return false.     PrefixFieldType that = (PrefixFieldType) o.     return minChars == that.minChars && maxChars == that.maxChars. }
false;public;0;4;;@Override public int hashCode() {     return Objects.hash(super.hashCode(), minChars, maxChars). }
false;protected;2;4;;@Override protected void parseCreateField(ParseContext context, List<IndexableField> fields) throws IOException {     throw new UnsupportedOperationException(). }
false;protected;0;4;;@Override protected String contentType() {     return "phrase". }
false;;2;3;;void addField(String value, List<IndexableField> fields) {     fields.add(new Field(fieldType().name(), value, fieldType())). }
false;protected;2;4;;@Override protected void parseCreateField(ParseContext context, List<IndexableField> fields) {     throw new UnsupportedOperationException(). }
false;protected;0;4;;@Override protected String contentType() {     return "prefix". }
false;public;0;4;;@Override public String toString() {     return fieldType().toString(). }
false;public;0;4;;@Override public TextFieldType clone() {     return new TextFieldType(this). }
false;public;1;13;;@Override public boolean equals(Object o) {     if (super.equals(o) == false) {         return false.     }     TextFieldType that = (TextFieldType) o.     return fielddata == that.fielddata && indexPhrases == that.indexPhrases && Objects.equals(prefixFieldType, that.prefixFieldType) && fielddataMinFrequency == that.fielddataMinFrequency && fielddataMaxFrequency == that.fielddataMaxFrequency && fielddataMinSegmentSize == that.fielddataMinSegmentSize. }
false;public;0;5;;@Override public int hashCode() {     return Objects.hash(super.hashCode(), fielddata, indexPhrases, prefixFieldType, fielddataMinFrequency, fielddataMaxFrequency, fielddataMinSegmentSize). }
false;public;0;3;;public boolean fielddata() {     return fielddata. }
false;public;1;4;;public void setFielddata(boolean fielddata) {     checkIfFrozen().     this.fielddata = fielddata. }
false;public;0;3;;public double fielddataMinFrequency() {     return fielddataMinFrequency. }
false;public;1;4;;public void setFielddataMinFrequency(double fielddataMinFrequency) {     checkIfFrozen().     this.fielddataMinFrequency = fielddataMinFrequency. }
false;public;0;3;;public double fielddataMaxFrequency() {     return fielddataMaxFrequency. }
false;public;1;4;;public void setFielddataMaxFrequency(double fielddataMaxFrequency) {     checkIfFrozen().     this.fielddataMaxFrequency = fielddataMaxFrequency. }
false;public;0;3;;public int fielddataMinSegmentSize() {     return fielddataMinSegmentSize. }
false;public;1;4;;public void setFielddataMinSegmentSize(int fielddataMinSegmentSize) {     checkIfFrozen().     this.fielddataMinSegmentSize = fielddataMinSegmentSize. }
false;;1;4;;void setPrefixFieldType(PrefixFieldType prefixFieldType) {     checkIfFrozen().     this.prefixFieldType = prefixFieldType. }
false;;1;4;;void setIndexPhrases(boolean indexPhrases) {     checkIfFrozen().     this.indexPhrases = indexPhrases. }
false;public;0;3;;public PrefixFieldType getPrefixFieldType() {     return this.prefixFieldType. }
false;public;0;4;;@Override public String typeName() {     return CONTENT_TYPE. }
false;public;3;12;;@Override public Query prefixQuery(String value, MultiTermQuery.RewriteMethod method, QueryShardContext context) {     if (prefixFieldType == null || prefixFieldType.accept(value.length()) == false) {         return super.prefixQuery(value, method, context).     }     Query tq = prefixFieldType.prefixQuery(value, method, context).     if (method == null || method == MultiTermQuery.CONSTANT_SCORE_REWRITE || method == MultiTermQuery.CONSTANT_SCORE_BOOLEAN_REWRITE) {         return new ConstantScoreQuery(tq).     }     return tq. }
false;public;3;16;;@Override public SpanQuery spanPrefixQuery(String value, SpanMultiTermQueryWrapper.SpanRewriteMethod method, QueryShardContext context) {     failIfNotIndexed().     if (prefixFieldType != null && value.length() >= prefixFieldType.minChars && value.length() <= prefixFieldType.maxChars && prefixFieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0) {         return new FieldMaskingSpanQuery(new SpanTermQuery(new Term(prefixFieldType.name(), indexedValueForSearch(value))), name()).     } else {         SpanMultiTermQueryWrapper<?> spanMulti = new SpanMultiTermQueryWrapper<>(new PrefixQuery(new Term(name(), indexedValueForSearch(value)))).         spanMulti.setRewriteMethod(method).         return spanMulti.     } }
false;public;1;8;;@Override public Query existsQuery(QueryShardContext context) {     if (omitNorms()) {         return new TermQuery(new Term(FieldNamesFieldMapper.NAME, name())).     } else {         return new NormsFieldExistsQuery(name()).     } }
false;public;4;8;;@Override public IntervalsSource intervals(String text, int maxGaps, boolean ordered, NamedAnalyzer analyzer) throws IOException {     if (indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {         throw new IllegalArgumentException("Cannot create intervals against field [" + name() + "] with no positions indexed").     }     IntervalBuilder builder = new IntervalBuilder(name(), analyzer == null ? searchAnalyzer() : analyzer).     return builder.analyzeText(text, maxGaps, ordered). }
false;public;3;27;;@Override public Query phraseQuery(TokenStream stream, int slop, boolean enablePosIncrements) throws IOException {     String field = name().     if (indexPhrases && slop == 0 && hasGaps(stream) == false) {         stream = new FixedShingleFilter(stream, 2).         field = field + FAST_PHRASE_SUFFIX.     }     PhraseQuery.Builder builder = new PhraseQuery.Builder().     builder.setSlop(slop).     TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class).     PositionIncrementAttribute posIncrAtt = stream.getAttribute(PositionIncrementAttribute.class).     int position = -1.     stream.reset().     while (stream.incrementToken()) {         if (enablePosIncrements) {             position += posIncrAtt.getPositionIncrement().         } else {             position += 1.         }         builder.add(new Term(field, termAtt.getBytesRef()), position).     }     return builder.build(). }
false;public;3;9;;@Override public Query multiPhraseQuery(TokenStream stream, int slop, boolean enablePositionIncrements) throws IOException {     String field = name().     if (indexPhrases && slop == 0 && hasGaps(stream) == false) {         stream = new FixedShingleFilter(stream, 2).         field = field + FAST_PHRASE_SUFFIX.     }     return createPhraseQuery(stream, field, slop, enablePositionIncrements). }
false;public;3;4;;@Override public Query phrasePrefixQuery(TokenStream stream, int slop, int maxExpansions) throws IOException {     return analyzePhrasePrefix(stream, slop, maxExpansions). }
false;private;3;62;;private Query analyzePhrasePrefix(TokenStream stream, int slop, int maxExpansions) throws IOException {     final MultiPhrasePrefixQuery query = createPhrasePrefixQuery(stream, name(), slop, maxExpansions).     if (slop > 0 || prefixFieldType == null || prefixFieldType.indexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {         return query.     }     int lastPos = query.getTerms().length - 1.     final Term[][] terms = query.getTerms().     final int[] positions = query.getPositions().     for (Term term : terms[lastPos]) {         String value = term.text().         if (value.length() < prefixFieldType.minChars || value.length() > prefixFieldType.maxChars) {             return query.         }     }     if (terms.length == 1) {         Term[] newTerms = Arrays.stream(terms[0]).map(term -> new Term(prefixFieldType.name(), term.bytes())).toArray(Term[]::new).         return new SynonymQuery(newTerms).     }     SpanNearQuery.Builder spanQuery = new SpanNearQuery.Builder(name(), true).     spanQuery.setSlop(slop).     int previousPos = -1.     for (int i = 0. i < terms.length. i++) {         Term[] posTerms = terms[i].         int posInc = positions[i] - previousPos.         previousPos = positions[i].         if (posInc > 1) {             spanQuery.addGap(posInc - 1).         }         if (i == lastPos) {             if (posTerms.length == 1) {                 FieldMaskingSpanQuery fieldMask = new FieldMaskingSpanQuery(new SpanTermQuery(new Term(prefixFieldType.name(), posTerms[0].bytes())), name()).                 spanQuery.addClause(fieldMask).             } else {                 SpanQuery[] queries = Arrays.stream(posTerms).map(term -> new FieldMaskingSpanQuery(new SpanTermQuery(new Term(prefixFieldType.name(), term.bytes())), name())).toArray(SpanQuery[]::new).                 spanQuery.addClause(new SpanOrQuery(queries)).             }         } else {             if (posTerms.length == 1) {                 spanQuery.addClause(new SpanTermQuery(posTerms[0])).             } else {                 SpanTermQuery[] queries = Arrays.stream(posTerms).map(SpanTermQuery::new).toArray(SpanTermQuery[]::new).                 spanQuery.addClause(new SpanOrQuery(queries)).             }         }     }     return spanQuery.build(). }
false;private,static;1;11;;private static boolean hasGaps(TokenStream stream) throws IOException {     assert stream instanceof CachingTokenFilter.     PositionIncrementAttribute posIncAtt = stream.getAttribute(PositionIncrementAttribute.class).     stream.reset().     while (stream.incrementToken()) {         if (posIncAtt.getPositionIncrement() > 1) {             return true.         }     }     return false. }
false;public;1;9;;@Override public IndexFieldData.Builder fielddataBuilder(String fullyQualifiedIndexName) {     if (fielddata == false) {         throw new IllegalArgumentException("Fielddata is disabled on text fields by default. Set fielddata=true on [" + name() + "] in order to load fielddata in memory by uninverting the inverted index. Note that this can however " + "use significant memory. Alternatively use a keyword field instead.").     }     return new PagedBytesIndexFieldData.Builder(fielddataMinFrequency, fielddataMaxFrequency, fielddataMinSegmentSize). }
false;public;2;21;;@Override public void checkCompatibility(MappedFieldType other, List<String> conflicts) {     super.checkCompatibility(other, conflicts).     TextFieldType tft = (TextFieldType) other.     if (tft.indexPhrases != this.indexPhrases) {         conflicts.add("mapper [" + name() + "] has different [index_phrases] values").     }     if (Objects.equals(this.prefixFieldType, tft.prefixFieldType) == false) {         if (this.prefixFieldType == null) {             conflicts.add("mapper [" + name() + "] has different [index_prefixes] settings, cannot change from disabled to enabled").         } else if (tft.prefixFieldType == null) {             conflicts.add("mapper [" + name() + "] has different [index_prefixes] settings, cannot change from enabled to disabled").         } else {             conflicts.add("mapper [" + name() + "] has different [index_prefixes] settings").         }     } }
false;protected;0;4;;@Override protected TextFieldMapper clone() {     return (TextFieldMapper) super.clone(). }
false;public;0;3;;public int getPositionIncrementGap() {     return this.positionIncrementGap. }
false;protected;2;27;;@Override protected void parseCreateField(ParseContext context, List<IndexableField> fields) throws IOException {     final String value.     if (context.externalValueSet()) {         value = context.externalValue().toString().     } else {         value = context.parser().textOrNull().     }     if (value == null) {         return.     }     if (fieldType().indexOptions() != IndexOptions.NONE || fieldType().stored()) {         Field field = new Field(fieldType().name(), value, fieldType()).         fields.add(field).         if (fieldType().omitNorms()) {             createFieldNamesField(context, fields).         }         if (prefixFieldMapper != null) {             prefixFieldMapper.addField(value, fields).         }         if (phraseFieldMapper != null) {             fields.add(new Field(phraseFieldMapper.fieldType.name(), value, phraseFieldMapper.fieldType)).         }     } }
false;public;0;14;;@Override public Iterator<Mapper> iterator() {     List<Mapper> subIterators = new ArrayList<>().     if (prefixFieldMapper != null) {         subIterators.add(prefixFieldMapper).     }     if (phraseFieldMapper != null) {         subIterators.add(phraseFieldMapper).     }     if (subIterators.size() == 0) {         return super.iterator().     }     return Iterators.concat(super.iterator(), subIterators.iterator()). }
false;protected;0;4;;@Override protected String contentType() {     return CONTENT_TYPE. }
false;protected;1;16;;@Override protected void doMerge(Mapper mergeWith) {     super.doMerge(mergeWith).     TextFieldMapper mw = (TextFieldMapper) mergeWith.     if (this.prefixFieldMapper != null && mw.prefixFieldMapper != null) {         this.prefixFieldMapper = (PrefixFieldMapper) this.prefixFieldMapper.merge(mw.prefixFieldMapper).     } else if (this.prefixFieldMapper != null || mw.prefixFieldMapper != null) {         throw new IllegalArgumentException("mapper [" + name() + "] has different index_prefix settings, current [" + this.prefixFieldMapper + "], merged [" + mw.prefixFieldMapper + "]").     } else if (this.fieldType().indexPhrases != mw.fieldType().indexPhrases) {         throw new IllegalArgumentException("mapper [" + name() + "] has different index_phrases settings, current [" + this.fieldType().indexPhrases + "], merged [" + mw.fieldType().indexPhrases + "]").     } }
false;public;0;4;;@Override public TextFieldType fieldType() {     return (TextFieldType) super.fieldType(). }
false;protected;3;37;;@Override protected void doXContentBody(XContentBuilder builder, boolean includeDefaults, Params params) throws IOException {     super.doXContentBody(builder, includeDefaults, params).     doXContentAnalyzers(builder, includeDefaults).     if (includeDefaults || positionIncrementGap != POSITION_INCREMENT_GAP_USE_ANALYZER) {         builder.field("position_increment_gap", positionIncrementGap).     }     if (includeDefaults || fieldType().fielddata() != ((TextFieldType) defaultFieldType).fielddata()) {         builder.field("fielddata", fieldType().fielddata()).     }     if (fieldType().fielddata()) {         if (includeDefaults || fieldType().fielddataMinFrequency() != Defaults.FIELDDATA_MIN_FREQUENCY || fieldType().fielddataMaxFrequency() != Defaults.FIELDDATA_MAX_FREQUENCY || fieldType().fielddataMinSegmentSize() != Defaults.FIELDDATA_MIN_SEGMENT_SIZE) {             builder.startObject("fielddata_frequency_filter").             if (includeDefaults || fieldType().fielddataMinFrequency() != Defaults.FIELDDATA_MIN_FREQUENCY) {                 builder.field("min", fieldType().fielddataMinFrequency()).             }             if (includeDefaults || fieldType().fielddataMaxFrequency() != Defaults.FIELDDATA_MAX_FREQUENCY) {                 builder.field("max", fieldType().fielddataMaxFrequency()).             }             if (includeDefaults || fieldType().fielddataMinSegmentSize() != Defaults.FIELDDATA_MIN_SEGMENT_SIZE) {                 builder.field("min_segment_size", fieldType().fielddataMinSegmentSize()).             }             builder.endObject().         }     }     if (fieldType().prefixFieldType != null) {         fieldType().prefixFieldType.doXContent(builder).     }     if (fieldType().indexPhrases) {         builder.field("index_phrases", fieldType().indexPhrases).     } }
false;public,static;4;33;;public static Query createPhraseQuery(TokenStream stream, String field, int slop, boolean enablePositionIncrements) throws IOException {     MultiPhraseQuery.Builder mpqb = new MultiPhraseQuery.Builder().     mpqb.setSlop(slop).     TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class).     PositionIncrementAttribute posIncrAtt = stream.getAttribute(PositionIncrementAttribute.class).     int position = -1.     List<Term> multiTerms = new ArrayList<>().     stream.reset().     while (stream.incrementToken()) {         int positionIncrement = posIncrAtt.getPositionIncrement().         if (positionIncrement > 0 && multiTerms.size() > 0) {             if (enablePositionIncrements) {                 mpqb.add(multiTerms.toArray(new Term[0]), position).             } else {                 mpqb.add(multiTerms.toArray(new Term[0])).             }             multiTerms.clear().         }         position += positionIncrement.         multiTerms.add(new Term(field, termAtt.getBytesRef())).     }     if (enablePositionIncrements) {         mpqb.add(multiTerms.toArray(new Term[0]), position).     } else {         mpqb.add(multiTerms.toArray(new Term[0])).     }     return mpqb.build(). }
false;public,static;4;26;;public static MultiPhrasePrefixQuery createPhrasePrefixQuery(TokenStream stream, String field, int slop, int maxExpansions) throws IOException {     MultiPhrasePrefixQuery builder = new MultiPhrasePrefixQuery(field).     builder.setSlop(slop).     builder.setMaxExpansions(maxExpansions).     List<Term> currentTerms = new ArrayList<>().     TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class).     PositionIncrementAttribute posIncrAtt = stream.getAttribute(PositionIncrementAttribute.class).     stream.reset().     int position = -1.     while (stream.incrementToken()) {         if (posIncrAtt.getPositionIncrement() != 0) {             if (currentTerms.isEmpty() == false) {                 builder.add(currentTerms.toArray(new Term[0]), position).             }             position += posIncrAtt.getPositionIncrement().             currentTerms.clear().         }         currentTerms.add(new Term(field, termAtt.getBytesRef())).     }     builder.add(currentTerms.toArray(new Term[0]), position).     return builder. }
