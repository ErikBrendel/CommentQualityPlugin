commented;modifiers;parameterAmount;loc;comment;code
false;public,static;2;3;;public static TermVectorsResponse getTermVectors(IndexShard indexShard, TermVectorsRequest request) {     return getTermVectors(indexShard, request, System::nanoTime). }
false;static;3;72;;static TermVectorsResponse getTermVectors(IndexShard indexShard, TermVectorsRequest request, LongSupplier nanoTimeSupplier) {     final long startTime = nanoTimeSupplier.getAsLong().     final TermVectorsResponse termVectorsResponse = new TermVectorsResponse(indexShard.shardId().getIndex().getName(), request.type(), request.id()).     final Term uidTerm = new Term(IdFieldMapper.NAME, Uid.encodeId(request.id())).     Fields termVectorsByField = null.     AggregatedDfs dfs = null.     TermVectorsFilter termVectorsFilter = null.     /* handle potential wildcards in fields */     if (request.selectedFields() != null) {         handleFieldWildcards(indexShard, request).     }     try (Engine.GetResult get = indexShard.get(new Engine.Get(request.realtime(), false, request.type(), request.id(), uidTerm).version(request.version()).versionType(request.versionType())).         Engine.Searcher searcher = indexShard.acquireSearcher("term_vector")) {         Fields topLevelFields = fields(get.searcher() != null ? get.searcher().reader() : searcher.reader()).         DocIdAndVersion docIdAndVersion = get.docIdAndVersion().         /* from an artificial document */         if (request.doc() != null) {             termVectorsByField = generateTermVectorsFromDoc(indexShard, request).             // if no document indexed in shard, take the queried document itself for stats             if (topLevelFields == null) {                 topLevelFields = termVectorsByField.             }             termVectorsResponse.setArtificial(true).             termVectorsResponse.setExists(true).         } else /* or from an existing document */         if (docIdAndVersion != null) {             // fields with stored term vectors             termVectorsByField = docIdAndVersion.reader.getTermVectors(docIdAndVersion.docId).             Set<String> selectedFields = request.selectedFields().             // generate tvs for fields where analyzer is overridden             if (selectedFields == null && request.perFieldAnalyzer() != null) {                 selectedFields = getFieldsToGenerate(request.perFieldAnalyzer(), termVectorsByField).             }             // fields without term vectors             if (selectedFields != null) {                 termVectorsByField = addGeneratedTermVectors(indexShard, get, termVectorsByField, request, selectedFields).             }             termVectorsResponse.setDocVersion(docIdAndVersion.version).             termVectorsResponse.setExists(true).         } else /* no term vectors generated or found */         {             termVectorsResponse.setExists(false).         }         /* if there are term vectors, optional compute dfs and/or terms filtering */         if (termVectorsByField != null) {             if (request.filterSettings() != null) {                 termVectorsFilter = new TermVectorsFilter(termVectorsByField, topLevelFields, request.selectedFields(), dfs).                 termVectorsFilter.setSettings(request.filterSettings()).                 try {                     termVectorsFilter.selectBestTerms().                 } catch (IOException e) {                     throw new ElasticsearchException("failed to select best terms", e).                 }             }             // write term vectors             termVectorsResponse.setFields(termVectorsByField, request.selectedFields(), request.getFlags(), topLevelFields, dfs, termVectorsFilter).         }         termVectorsResponse.setTookInMillis(TimeUnit.NANOSECONDS.toMillis(nanoTimeSupplier.getAsLong() - startTime)).     } catch (Exception ex) {         throw new ElasticsearchException("failed to execute term vector request", ex).     }     return termVectorsResponse. }
false;public;0;4;;@Override public Iterator<String> iterator() {     throw new UnsupportedOperationException(). }
false;public;1;4;;@Override public Terms terms(String field) throws IOException {     return MultiTerms.getTerms(reader, field). }
false;public;0;4;;@Override public int size() {     throw new UnsupportedOperationException(). }
false;public,static;1;18;;public static Fields fields(IndexReader reader) {     return new Fields() {          @Override         public Iterator<String> iterator() {             throw new UnsupportedOperationException().         }          @Override         public Terms terms(String field) throws IOException {             return MultiTerms.getTerms(reader, field).         }          @Override         public int size() {             throw new UnsupportedOperationException().         }     }. }
false;private,static;2;7;;private static void handleFieldWildcards(IndexShard indexShard, TermVectorsRequest request) {     Set<String> fieldNames = new HashSet<>().     for (String pattern : request.selectedFields()) {         fieldNames.addAll(indexShard.mapperService().simpleMatchToFullName(pattern)).     }     request.selectedFields(fieldNames.toArray(Strings.EMPTY_ARRAY)). }
false;private,static;1;11;;private static boolean isValidField(MappedFieldType fieldType) {     // must be a string     if (fieldType instanceof StringFieldType == false) {         return false.     }     // and must be indexed     if (fieldType.indexOptions() == IndexOptions.NONE) {         return false.     }     return true. }
false;private,static;5;36;;private static Fields addGeneratedTermVectors(IndexShard indexShard, Engine.GetResult get, Fields termVectorsByField, TermVectorsRequest request, Set<String> selectedFields) throws IOException {     /* only keep valid fields */     Set<String> validFields = new HashSet<>().     for (String field : selectedFields) {         MappedFieldType fieldType = indexShard.mapperService().fullName(field).         if (!isValidField(fieldType)) {             continue.         }         // already retrieved, only if the analyzer hasn't been overridden at the field         if (fieldType.storeTermVectors() && (request.perFieldAnalyzer() == null || !request.perFieldAnalyzer().containsKey(field))) {             continue.         }         validFields.add(field).     }     if (validFields.isEmpty()) {         return termVectorsByField.     }     /* generate term vectors from fetched document fields */     String[] getFields = validFields.toArray(new String[validFields.size() + 1]).     getFields[getFields.length - 1] = SourceFieldMapper.NAME.     GetResult getResult = indexShard.getService().get(get, request.id(), request.type(), getFields, null).     Fields generatedTermVectors = generateTermVectors(indexShard, getResult.sourceAsMap(), getResult.getFields().values(), request.offsets(), request.perFieldAnalyzer(), validFields).     /* merge with existing Fields */     if (termVectorsByField == null) {         return generatedTermVectors.     } else {         return mergeFields(termVectorsByField, generatedTermVectors).     } }
false;private,static;3;19;;private static Analyzer getAnalyzerAtField(IndexShard indexShard, String field, @Nullable Map<String, String> perFieldAnalyzer) {     MapperService mapperService = indexShard.mapperService().     Analyzer analyzer.     if (perFieldAnalyzer != null && perFieldAnalyzer.containsKey(field)) {         analyzer = mapperService.getIndexAnalyzers().get(perFieldAnalyzer.get(field).toString()).     } else {         MappedFieldType fieldType = mapperService.fullName(field).         if (fieldType instanceof KeywordFieldMapper.KeywordFieldType) {             KeywordFieldMapper.KeywordFieldType keywordFieldType = (KeywordFieldMapper.KeywordFieldType) fieldType.             analyzer = keywordFieldType.normalizer() == null ? keywordFieldType.indexAnalyzer() : keywordFieldType.normalizer().         } else {             analyzer = fieldType.indexAnalyzer().         }     }     if (analyzer == null) {         analyzer = mapperService.getIndexAnalyzers().getDefaultIndexAnalyzer().     }     return analyzer. }
false;private,static;2;9;;private static Set<String> getFieldsToGenerate(Map<String, String> perAnalyzerField, Fields fieldsObject) {     Set<String> selectedFields = new HashSet<>().     for (String fieldName : fieldsObject) {         if (perAnalyzerField.containsKey(fieldName)) {             selectedFields.add(fieldName).         }     }     return selectedFields. }
false;private,static;6;40;;private static Fields generateTermVectors(IndexShard indexShard, Map<String, Object> source, Collection<DocumentField> getFields, boolean withOffsets, @Nullable Map<String, String> perFieldAnalyzer, Set<String> fields) throws IOException {     Map<String, Collection<Object>> values = new HashMap<>().     for (DocumentField getField : getFields) {         String field = getField.getName().         if (fields.contains(field)) {             // some fields are returned even when not asked for, eg. _timestamp             values.put(field, getField.getValues()).         }     }     if (source != null) {         for (String field : fields) {             if (values.containsKey(field) == false) {                 List<Object> v = XContentMapValues.extractRawValues(field, source).                 if (v.isEmpty() == false) {                     values.put(field, v).                 }             }         }     }     /* store document in memory index */     MemoryIndex index = new MemoryIndex(withOffsets).     for (Map.Entry<String, Collection<Object>> entry : values.entrySet()) {         String field = entry.getKey().         Analyzer analyzer = getAnalyzerAtField(indexShard, field, perFieldAnalyzer).         if (entry.getValue() instanceof List) {             for (Object text : entry.getValue()) {                 index.addField(field, text.toString(), analyzer).             }         } else {             index.addField(field, entry.getValue().toString(), analyzer).         }     }     /* and read vectors from it */     return index.createSearcher().getIndexReader().getTermVectors(0). }
false;private,static;2;30;;private static Fields generateTermVectorsFromDoc(IndexShard indexShard, TermVectorsRequest request) throws IOException {     // parse the document, at the moment we do update the mapping, just like percolate     ParsedDocument parsedDocument = parseDocument(indexShard, indexShard.shardId().getIndexName(), request.type(), request.doc(), request.xContentType(), request.routing()).     // select the right fields and generate term vectors     ParseContext.Document doc = parsedDocument.rootDoc().     Set<String> seenFields = new HashSet<>().     Collection<DocumentField> documentFields = new HashSet<>().     for (IndexableField field : doc.getFields()) {         MappedFieldType fieldType = indexShard.mapperService().fullName(field.name()).         if (!isValidField(fieldType)) {             continue.         }         if (request.selectedFields() != null && !request.selectedFields().contains(field.name())) {             continue.         }         if (seenFields.contains(field.name())) {             continue.         } else {             seenFields.add(field.name()).         }         String[] values = doc.getValues(field.name()).         documentFields.add(new DocumentField(field.name(), Arrays.asList((Object[]) values))).     }     return generateTermVectors(indexShard, XContentHelper.convertToMap(parsedDocument.source(), true, request.xContentType()).v2(), documentFields, request.offsets(), request.perFieldAnalyzer(), seenFields). }
false;private,static;6;11;;private static ParsedDocument parseDocument(IndexShard indexShard, String index, String type, BytesReference doc, XContentType xContentType, String routing) {     MapperService mapperService = indexShard.mapperService().     DocumentMapperForType docMapper = mapperService.documentMapperWithAutoCreate(type).     ParsedDocument parsedDocument = docMapper.getDocumentMapper().parse(new SourceToParse(index, type, "_id_for_tv_api", doc, xContentType, routing)).     if (docMapper.getMapping() != null) {         parsedDocument.addDynamicMappingsUpdate(docMapper.getMapping()).     }     return parsedDocument. }
false;private,static;2;19;;private static Fields mergeFields(Fields fields1, Fields fields2) throws IOException {     ParallelFields parallelFields = new ParallelFields().     for (String fieldName : fields2) {         Terms terms = fields2.terms(fieldName).         if (terms != null) {             parallelFields.addField(fieldName, terms).         }     }     for (String fieldName : fields1) {         if (parallelFields.fields.containsKey(fieldName)) {             continue.         }         Terms terms = fields1.terms(fieldName).         if (terms != null) {             parallelFields.addField(fieldName, terms).         }     }     return parallelFields. }
false;;2;3;;void addField(String fieldName, Terms terms) {     fields.put(fieldName, terms). }
false;public;0;4;;@Override public Iterator<String> iterator() {     return Collections.unmodifiableSet(fields.keySet()).iterator(). }
false;public;1;4;;@Override public Terms terms(String field) {     return fields.get(field). }
false;public;0;4;;@Override public int size() {     return fields.size(). }
