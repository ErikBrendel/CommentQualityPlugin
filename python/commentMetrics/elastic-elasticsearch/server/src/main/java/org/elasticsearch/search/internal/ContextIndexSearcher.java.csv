commented;modifiers;parameterAmount;loc;comment;code
false;public;0;3;;@Override public void close() { }
false;public;1;3;;public void setProfiler(QueryProfiler profiler) {     this.profiler = profiler. }
true;public;1;3;/**  * Set a {@link Runnable} that will be run on a regular basis while  * collecting documents.  */ ;/**  * Set a {@link Runnable} that will be run on a regular basis while  * collecting documents.  */ public void setCheckCancelled(Runnable checkCancelled) {     this.checkCancelled = checkCancelled. }
false;public;1;3;;public void setAggregatedDfs(AggregatedDfs aggregatedDfs) {     this.aggregatedDfs = aggregatedDfs. }
false;public;1;14;;@Override public Query rewrite(Query original) throws IOException {     if (profiler != null) {         profiler.startRewriteTime().     }     try {         return in.rewrite(original).     } finally {         if (profiler != null) {             profiler.stopAndAddRewriteTime().         }     } }
false;public;3;22;;@Override public Weight createWeight(Query query, ScoreMode scoreMode, float boost) throws IOException {     if (profiler != null) {         // createWeight() is called for each query in the tree, so we tell the queryProfiler         // each invocation so that it can build an internal representation of the query         // tree         QueryProfileBreakdown profile = profiler.getQueryBreakdown(query).         Timer timer = profile.getTimer(QueryTimingType.CREATE_WEIGHT).         timer.start().         final Weight weight.         try {             weight = super.createWeight(query, scoreMode, boost).         } finally {             timer.stop().             profiler.pollLastElement().         }         return new ProfileWeight(query, weight, profile).     } else {         // needs to be 'super', not 'in' in order to use aggregated DFS         return super.createWeight(query, scoreMode, boost).     } }
false;public;1;4;;@Override public void extractTerms(Set<Term> terms) {     throw new UnsupportedOperationException(). }
false;public;2;4;;@Override public Explanation explain(LeafReaderContext context, int doc) throws IOException {     throw new UnsupportedOperationException(). }
false;public;1;4;;@Override public Scorer scorer(LeafReaderContext context) throws IOException {     throw new UnsupportedOperationException(). }
false;public;1;4;;@Override public boolean isCacheable(LeafReaderContext ctx) {     throw new UnsupportedOperationException(). }
false;public;1;9;;@Override public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {     BulkScorer in = weight.bulkScorer(context).     if (in != null) {         return new CancellableBulkScorer(in, checkCancelled).     } else {         return null.     } }
false;protected;3;41;;@Override protected void search(List<LeafReaderContext> leaves, Weight weight, Collector collector) throws IOException {     final Weight cancellableWeight.     if (checkCancelled != null) {         cancellableWeight = new Weight(weight.getQuery()) {              @Override             public void extractTerms(Set<Term> terms) {                 throw new UnsupportedOperationException().             }              @Override             public Explanation explain(LeafReaderContext context, int doc) throws IOException {                 throw new UnsupportedOperationException().             }              @Override             public Scorer scorer(LeafReaderContext context) throws IOException {                 throw new UnsupportedOperationException().             }              @Override             public boolean isCacheable(LeafReaderContext ctx) {                 throw new UnsupportedOperationException().             }              @Override             public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {                 BulkScorer in = weight.bulkScorer(context).                 if (in != null) {                     return new CancellableBulkScorer(in, checkCancelled).                 } else {                     return null.                 }             }         }.     } else {         cancellableWeight = weight.     }     super.search(leaves, cancellableWeight, collector). }
false;public;2;8;;@Override public Explanation explain(Query query, int doc) throws IOException {     if (aggregatedDfs != null) {         // dfs data is needed to explain the score         return super.explain(createWeight(rewrite(query), ScoreMode.COMPLETE, 1f), doc).     }     return in.explain(query, doc). }
false;public;2;13;;@Override public TermStatistics termStatistics(Term term, TermStates context) throws IOException {     if (aggregatedDfs == null) {         // we are either executing the dfs phase or the search_type doesn't include the dfs phase.         return super.termStatistics(term, context).     }     TermStatistics termStatistics = aggregatedDfs.termStatistics().get(term).     if (termStatistics == null) {         // we don't have stats for this - this might be a must_not clauses etc. that doesn't allow extract terms on the query         return super.termStatistics(term, context).     }     return termStatistics. }
false;public;1;13;;@Override public CollectionStatistics collectionStatistics(String field) throws IOException {     if (aggregatedDfs == null) {         // we are either executing the dfs phase or the search_type doesn't include the dfs phase.         return super.collectionStatistics(field).     }     CollectionStatistics collectionStatistics = aggregatedDfs.fieldStatistics().get(field).     if (collectionStatistics == null) {         // we don't have stats for this - this might be a must_not clauses etc. that doesn't allow extract terms on the query         return super.collectionStatistics(field).     }     return collectionStatistics. }
false;public;0;3;;public DirectoryReader getDirectoryReader() {     return engineSearcher.getDirectoryReader(). }
false;public;0;3;;public Engine.Searcher getEngineSearcher() {     return engineSearcher. }
