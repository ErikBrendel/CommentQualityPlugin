commented;modifiers;parameterAmount;loc;comment;code
false;private;2;7;;private void validateKeepAlives(TimeValue defaultKeepAlive, TimeValue maxKeepAlive) {     if (defaultKeepAlive.millis() > maxKeepAlive.millis()) {         throw new IllegalArgumentException("Default keep alive setting for scroll [" + DEFAULT_KEEPALIVE_SETTING.getKey() + "]" + " should be smaller than max keep alive [" + MAX_KEEPALIVE_SETTING.getKey() + "], " + "was (" + defaultKeepAlive + " > " + maxKeepAlive + ")").     } }
false;private;2;5;;private void setKeepAlives(TimeValue defaultKeepAlive, TimeValue maxKeepAlive) {     validateKeepAlives(defaultKeepAlive, maxKeepAlive).     this.defaultKeepAlive = defaultKeepAlive.millis().     this.maxKeepAlive = maxKeepAlive.millis(). }
false;private;1;3;;private void setDefaultSearchTimeout(TimeValue defaultSearchTimeout) {     this.defaultSearchTimeout = defaultSearchTimeout. }
false;private;1;3;;private void setDefaultAllowPartialSearchResults(boolean defaultAllowPartialSearchResults) {     this.defaultAllowPartialSearchResults = defaultAllowPartialSearchResults. }
false;public;0;3;;public boolean defaultAllowPartialSearchResults() {     return defaultAllowPartialSearchResults. }
false;private;1;3;;private void setMaxOpenScrollContext(int maxOpenScrollContext) {     this.maxOpenScrollContext = maxOpenScrollContext. }
false;private;1;3;;private void setLowLevelCancellation(Boolean lowLevelCancellation) {     this.lowLevelCancellation = lowLevelCancellation. }
false;public;3;12;;@Override public void afterIndexRemoved(Index index, IndexSettings indexSettings, IndexRemovalReason reason) {     // to release memory and let references to the filesystem go etc.     if (reason == IndexRemovalReason.DELETED || reason == IndexRemovalReason.CLOSED || reason == IndexRemovalReason.REOPENED) {         freeAllContextForIndex(index).     } }
false;protected;1;4;;protected void putContext(SearchContext context) {     final SearchContext previous = activeContexts.put(context.id(), context).     assert previous == null. }
false;protected;1;3;;protected SearchContext removeContext(long id) {     return activeContexts.remove(id). }
false;protected;0;3;;@Override protected void doStart() { }
false;protected;0;6;;@Override protected void doStop() {     for (final SearchContext context : activeContexts.values()) {         freeContext(context.id()).     } }
false;protected;0;5;;@Override protected void doClose() {     doStop().     keepAliveReaper.cancel(). }
false;public;1;8;;@Override public void onResponse(ShardSearchRequest request) {     try {         listener.onResponse(executeDfsPhase(request, task)).     } catch (Exception e) {         onFailure(e).     } }
false;public;1;4;;@Override public void onFailure(Exception e) {     listener.onFailure(e). }
false;public;3;17;;public void executeDfsPhase(ShardSearchRequest request, SearchTask task, ActionListener<SearchPhaseResult> listener) {     rewriteShardRequest(request, new ActionListener<ShardSearchRequest>() {          @Override         public void onResponse(ShardSearchRequest request) {             try {                 listener.onResponse(executeDfsPhase(request, task)).             } catch (Exception e) {                 onFailure(e).             }         }          @Override         public void onFailure(Exception e) {             listener.onFailure(e).         }     }). }
false;private;2;17;;private DfsSearchResult executeDfsPhase(ShardSearchRequest request, SearchTask task) throws IOException {     final SearchContext context = createAndPutContext(request).     context.incRef().     try {         context.setTask(task).         contextProcessing(context).         dfsPhase.execute(context).         contextProcessedSuccessfully(context).         return context.dfsResult().     } catch (Exception e) {         logger.trace("Dfs phase failed", e).         processFailure(context, e).         throw e.     } finally {         cleanContext(context).     } }
true;private;2;9;/**  * Try to load the query results from the cache or execute the query phase directly if the cache cannot be used.  */ ;/**  * Try to load the query results from the cache or execute the query phase directly if the cache cannot be used.  */ private void loadOrExecuteQueryPhase(final ShardSearchRequest request, final SearchContext context) throws Exception {     final boolean canCache = indicesService.canCache(request, context).     context.getQueryShardContext().freezeContext().     if (canCache) {         indicesService.loadIntoContext(request, context, queryPhase).     } else {         queryPhase.execute(context).     } }
false;public;1;8;;@Override public void onResponse(ShardSearchRequest request) {     try {         listener.onResponse(executeQueryPhase(request, task)).     } catch (Exception e) {         onFailure(e).     } }
false;public;1;4;;@Override public void onFailure(Exception e) {     listener.onFailure(e). }
false;public;3;17;;public void executeQueryPhase(ShardSearchRequest request, SearchTask task, ActionListener<SearchPhaseResult> listener) {     rewriteShardRequest(request, new ActionListener<ShardSearchRequest>() {          @Override         public void onResponse(ShardSearchRequest request) {             try {                 listener.onResponse(executeQueryPhase(request, task)).             } catch (Exception e) {                 onFailure(e).             }         }          @Override         public void onFailure(Exception e) {             listener.onFailure(e).         }     }). }
false;public;1;4;;@Override public void onFailure(Exception e) {     listener.onFailure(e). }
false;protected;0;4;;@Override protected void doRun() {     listener.onResponse(executable.get()). }
false;private;3;13;;private <T> void runAsync(long id, Supplier<T> executable, ActionListener<T> listener) {     getExecutor(id).execute(new AbstractRunnable() {          @Override         public void onFailure(Exception e) {             listener.onFailure(e).         }          @Override         protected void doRun() {             listener.onResponse(executable.get()).         }     }). }
false;private;2;33;;private SearchPhaseResult executeQueryPhase(ShardSearchRequest request, SearchTask task) throws Exception {     final SearchContext context = createAndPutContext(request).     context.incRef().     try {         context.setTask(task).         final long afterQueryTime.         try (SearchOperationListenerExecutor executor = new SearchOperationListenerExecutor(context)) {             contextProcessing(context).             loadOrExecuteQueryPhase(request, context).             if (context.queryResult().hasSearchContext() == false && context.scrollContext() == null) {                 freeContext(context.id()).             } else {                 contextProcessedSuccessfully(context).             }             afterQueryTime = executor.success().         }         if (request.numberOfShards() == 1) {             return executeFetchPhase(context, afterQueryTime).         }         return context.queryResult().     } catch (Exception e) {         // execution exception can happen while loading the cache, strip it         if (e instanceof ExecutionException) {             e = (e.getCause() == null || e.getCause() instanceof Exception) ? (Exception) e.getCause() : new ElasticsearchException(e.getCause()).         }         logger.trace("Query phase failed", e).         processFailure(context, e).         throw e.     } finally {         cleanContext(context).     } }
false;private;2;13;;private QueryFetchSearchResult executeFetchPhase(SearchContext context, long afterQueryTime) {     try (SearchOperationListenerExecutor executor = new SearchOperationListenerExecutor(context, true, afterQueryTime)) {         shortcutDocIdsToLoad(context).         fetchPhase.execute(context).         if (fetchPhaseShouldFreeContext(context)) {             freeContext(context.id()).         } else {             contextProcessedSuccessfully(context).         }         executor.success().     }     return new QueryFetchSearchResult(context.queryResult(), context.fetchResult()). }
false;public;3;21;;public void executeQueryPhase(InternalScrollSearchRequest request, SearchTask task, ActionListener<ScrollQuerySearchResult> listener) {     runAsync(request.id(), () -> {         final SearchContext context = findContext(request.id(), request).         context.incRef().         try (SearchOperationListenerExecutor executor = new SearchOperationListenerExecutor(context)) {             context.setTask(task).             contextProcessing(context).             processScroll(request, context).             queryPhase.execute(context).             contextProcessedSuccessfully(context).             executor.success().             return new ScrollQuerySearchResult(context.queryResult(), context.shardTarget()).         } catch (Exception e) {             logger.trace("Query phase failed", e).             processFailure(context, e).             throw e.         } finally {             cleanContext(context).         }     }, listener). }
false;public;3;26;;public void executeQueryPhase(QuerySearchRequest request, SearchTask task, ActionListener<QuerySearchResult> listener) {     runAsync(request.id(), () -> {         final SearchContext context = findContext(request.id(), request).         context.setTask(task).         context.incRef().         try (SearchOperationListenerExecutor executor = new SearchOperationListenerExecutor(context)) {             contextProcessing(context).             context.searcher().setAggregatedDfs(request.dfs()).             queryPhase.execute(context).             if (context.queryResult().hasSearchContext() == false && context.scrollContext() == null) {                 // no hits, we can release the context since there will be no fetch phase                 freeContext(context.id()).             } else {                 contextProcessedSuccessfully(context).             }             executor.success().             return context.queryResult().         } catch (Exception e) {             logger.trace("Query phase failed", e).             processFailure(context, e).             throw e.         } finally {             cleanContext(context).         }     }, listener). }
false;private;1;9;;private boolean fetchPhaseShouldFreeContext(SearchContext context) {     if (context.scrollContext() == null) {         // simple search, no scroll         return true.     } else {         // scroll request, but the scroll was not extended         return context.scrollContext().scroll == null.     } }
false;final;1;7;;final Executor getExecutor(long id) {     SearchContext context = activeContexts.get(id).     if (context == null) {         throw new SearchContextMissingException(id).     }     return getExecutor(context.indexShard()). }
false;private;1;4;;private Executor getExecutor(IndexShard indexShard) {     assert indexShard != null.     return threadPool.executor(indexShard.indexSettings().isSearchThrottled() ? Names.SEARCH_THROTTLED : Names.SEARCH). }
false;public;3;22;;public void executeFetchPhase(InternalScrollSearchRequest request, SearchTask task, ActionListener<ScrollQueryFetchSearchResult> listener) {     runAsync(request.id(), () -> {         final SearchContext context = findContext(request.id(), request).         context.setTask(task).         context.incRef().         try (SearchOperationListenerExecutor executor = new SearchOperationListenerExecutor(context)) {             contextProcessing(context).             processScroll(request, context).             queryPhase.execute(context).             final long afterQueryTime = executor.success().             QueryFetchSearchResult fetchSearchResult = executeFetchPhase(context, afterQueryTime).             return new ScrollQueryFetchSearchResult(fetchSearchResult, context.shardTarget()).         } catch (Exception e) {             logger.trace("Fetch phase failed", e).             processFailure(context, e).             throw e.         } finally {             cleanContext(context).         }     }, listener). }
false;public;3;30;;public void executeFetchPhase(ShardFetchRequest request, SearchTask task, ActionListener<FetchSearchResult> listener) {     runAsync(request.id(), () -> {         final SearchContext context = findContext(request.id(), request).         context.incRef().         try {             context.setTask(task).             contextProcessing(context).             if (request.lastEmittedDoc() != null) {                 context.scrollContext().lastEmittedDoc = request.lastEmittedDoc().             }             context.docIdsToLoad(request.docIds(), 0, request.docIdsSize()).             try (SearchOperationListenerExecutor executor = new SearchOperationListenerExecutor(context, true, System.nanoTime())) {                 fetchPhase.execute(context).                 if (fetchPhaseShouldFreeContext(context)) {                     freeContext(request.id()).                 } else {                     contextProcessedSuccessfully(context).                 }                 executor.success().             }             return context.fetchResult().         } catch (Exception e) {             logger.trace("Fetch phase failed", e).             processFailure(context, e).             throw e.         } finally {             cleanContext(context).         }     }, listener). }
false;private;2;15;;private SearchContext findContext(long id, TransportRequest request) throws SearchContextMissingException {     SearchContext context = activeContexts.get(id).     if (context == null) {         throw new SearchContextMissingException(id).     }     SearchOperationListener operationListener = context.indexShard().getSearchOperationListener().     try {         operationListener.validateSearchContext(context, request).         return context.     } catch (Exception e) {         processFailure(context, e).         throw e.     } }
false;final;1;25;;final SearchContext createAndPutContext(ShardSearchRequest request) throws IOException {     if (request.scroll() != null && openScrollContexts.get() >= maxOpenScrollContext) {         throw new ElasticsearchException("Trying to create too many scroll contexts. Must be less than or equal to: [" + maxOpenScrollContext + "]. " + "This limit can be set by changing the [" + MAX_OPEN_SCROLL_CONTEXT.getKey() + "] setting.").     }     SearchContext context = createContext(request).     boolean success = false.     try {         putContext(context).         if (request.scroll() != null) {             openScrollContexts.incrementAndGet().             context.indexShard().getSearchOperationListener().onNewScrollContext(context).         }         context.indexShard().getSearchOperationListener().onNewContext(context).         success = true.         return context.     } finally {         if (!success) {             freeContext(context.id()).         }     } }
false;final;1;36;;final SearchContext createContext(ShardSearchRequest request) throws IOException {     final DefaultSearchContext context = createSearchContext(request, defaultSearchTimeout).     try {         if (request.scroll() != null) {             context.scrollContext(new ScrollContext()).             context.scrollContext().scroll = request.scroll().         }         parseSource(context, request.source()).         // if the from and size are still not set, default them         if (context.from() == -1) {             context.from(DEFAULT_FROM).         }         if (context.size() == -1) {             context.size(DEFAULT_SIZE).         }         // pre process         dfsPhase.preProcess(context).         queryPhase.preProcess(context).         fetchPhase.preProcess(context).         // compute the context keep alive         long keepAlive = defaultKeepAlive.         if (request.scroll() != null && request.scroll().keepAlive() != null) {             keepAlive = request.scroll().keepAlive().millis().         }         contextScrollKeepAlive(context, keepAlive).         context.lowLevelCancellation(lowLevelCancellation).     } catch (Exception e) {         context.close().         throw e.     }     return context. }
false;public;2;3;;public DefaultSearchContext createSearchContext(ShardSearchRequest request, TimeValue timeout) throws IOException {     return createSearchContext(request, timeout, true, "search"). }
false;private;4;28;;private DefaultSearchContext createSearchContext(ShardSearchRequest request, TimeValue timeout, boolean assertAsyncActions, String source) throws IOException {     IndexService indexService = indicesService.indexServiceSafe(request.shardId().getIndex()).     IndexShard indexShard = indexService.getShard(request.shardId().getId()).     SearchShardTarget shardTarget = new SearchShardTarget(clusterService.localNode().getId(), indexShard.shardId(), request.getClusterAlias(), OriginalIndices.NONE).     Engine.Searcher engineSearcher = indexShard.acquireSearcher(source).     final DefaultSearchContext searchContext = new DefaultSearchContext(idGenerator.incrementAndGet(), request, shardTarget, engineSearcher, clusterService, indexService, indexShard, bigArrays, threadPool::relativeTimeInMillis, timeout, fetchPhase, clusterService.state().nodes().getMinNodeVersion()).     boolean success = false.     try {         // we clone the query shard context here just for rewriting otherwise we         // might end up with incorrect state since we are using now() or script services         // during rewrite and normalized / evaluate templates etc.         QueryShardContext context = new QueryShardContext(searchContext.getQueryShardContext()).         Rewriteable.rewrite(request.getRewriteable(), context, assertAsyncActions).         assert searchContext.getQueryShardContext().isCacheable().         success = true.     } finally {         if (success == false) {             IOUtils.closeWhileHandlingException(searchContext).         }     }     return searchContext. }
false;private;1;8;;private void freeAllContextForIndex(Index index) {     assert index != null.     for (SearchContext ctx : activeContexts.values()) {         if (index.equals(ctx.indexShard().shardId().getIndex())) {             freeContext(ctx.id()).         }     } }
false;public;1;14;;public boolean freeContext(long id) {     try (SearchContext context = removeContext(id)) {         if (context != null) {             assert context.refCount() > 0 : " refCount must be > 0: " + context.refCount().             context.indexShard().getSearchOperationListener().onFreeContext(context).             if (context.scrollContext() != null) {                 openScrollContexts.decrementAndGet().                 context.indexShard().getSearchOperationListener().onFreeScrollContext(context).             }             return true.         }         return false.     } }
false;public;0;7;;public void freeAllScrollContexts() {     for (SearchContext searchContext : activeContexts.values()) {         if (searchContext.scrollContext() != null) {             freeContext(searchContext.id()).         }     } }
false;private;2;9;;private void contextScrollKeepAlive(SearchContext context, long keepAlive) {     if (keepAlive > maxKeepAlive) {         throw new IllegalArgumentException("Keep alive for scroll (" + TimeValue.timeValueMillis(keepAlive) + ") is too large. " + "It must be less than (" + TimeValue.timeValueMillis(maxKeepAlive) + "). " + "This limit can be set by changing the [" + MAX_KEEPALIVE_SETTING.getKey() + "] cluster level setting.").     }     context.keepAlive(keepAlive). }
false;private;1;4;;private void contextProcessing(SearchContext context) {     // disable timeout while executing a search     context.accessed(-1). }
false;private;1;3;;private void contextProcessedSuccessfully(SearchContext context) {     context.accessed(threadPool.relativeTimeInMillis()). }
false;private;1;8;;private void cleanContext(SearchContext context) {     try {         context.clearReleasables(Lifetime.PHASE).         context.setTask(null).     } finally {         context.decRef().     } }
false;private;2;11;;private void processFailure(SearchContext context, Exception e) {     freeContext(context.id()).     try {         if (Lucene.isCorruptionException(e)) {             context.indexShard().failShard("search execution corruption failure", e).         }     } catch (Exception inner) {         inner.addSuppressed(e).         logger.warn("failed to process shard failure to (potentially) send back shard failure on corruption", inner).     } }
false;private;2;175;;private void parseSource(DefaultSearchContext context, SearchSourceBuilder source) throws SearchContextException {     // nothing to parse...     if (source == null) {         return.     }     QueryShardContext queryShardContext = context.getQueryShardContext().     context.from(source.from()).     context.size(source.size()).     Map<String, InnerHitContextBuilder> innerHitBuilders = new HashMap<>().     if (source.query() != null) {         InnerHitContextBuilder.extractInnerHits(source.query(), innerHitBuilders).         context.parsedQuery(queryShardContext.toQuery(source.query())).     }     if (source.postFilter() != null) {         InnerHitContextBuilder.extractInnerHits(source.postFilter(), innerHitBuilders).         context.parsedPostFilter(queryShardContext.toQuery(source.postFilter())).     }     if (innerHitBuilders.size() > 0) {         for (Map.Entry<String, InnerHitContextBuilder> entry : innerHitBuilders.entrySet()) {             try {                 entry.getValue().build(context, context.innerHits()).             } catch (IOException e) {                 throw new SearchContextException(context, "failed to build inner_hits", e).             }         }     }     if (source.sorts() != null) {         try {             Optional<SortAndFormats> optionalSort = SortBuilder.buildSort(source.sorts(), context.getQueryShardContext()).             if (optionalSort.isPresent()) {                 context.sort(optionalSort.get()).             }         } catch (IOException e) {             throw new SearchContextException(context, "failed to create sort elements", e).         }     }     context.trackScores(source.trackScores()).     if (source.trackTotalHitsUpTo() != null && source.trackTotalHitsUpTo() != SearchContext.TRACK_TOTAL_HITS_ACCURATE && context.scrollContext() != null) {         throw new SearchContextException(context, "disabling [track_total_hits] is not allowed in a scroll context").     }     if (source.trackTotalHitsUpTo() != null) {         context.trackTotalHitsUpTo(source.trackTotalHitsUpTo()).     }     if (source.minScore() != null) {         context.minimumScore(source.minScore()).     }     if (source.profile()) {         context.setProfilers(new Profilers(context.searcher())).     }     if (source.timeout() != null) {         context.timeout(source.timeout()).     }     context.terminateAfter(source.terminateAfter()).     if (source.aggregations() != null) {         try {             AggregatorFactories factories = source.aggregations().build(context, null).             context.aggregations(new SearchContextAggregations(factories, multiBucketConsumerService.create())).         } catch (IOException e) {             throw new AggregationInitializationException("Failed to create aggregators", e).         }     }     if (source.suggest() != null) {         try {             context.suggest(source.suggest().build(queryShardContext)).         } catch (IOException e) {             throw new SearchContextException(context, "failed to create SuggestionSearchContext", e).         }     }     if (source.rescores() != null) {         try {             for (RescorerBuilder<?> rescore : source.rescores()) {                 context.addRescore(rescore.buildContext(queryShardContext)).             }         } catch (IOException e) {             throw new SearchContextException(context, "failed to create RescoreSearchContext", e).         }     }     if (source.explain() != null) {         context.explain(source.explain()).     }     if (source.fetchSource() != null) {         context.fetchSourceContext(source.fetchSource()).     }     if (source.docValueFields() != null) {         List<DocValueFieldsContext.FieldAndFormat> docValueFields = new ArrayList<>().         for (DocValueFieldsContext.FieldAndFormat format : source.docValueFields()) {             Collection<String> fieldNames = context.mapperService().simpleMatchToFullName(format.field).             for (String fieldName : fieldNames) {                 docValueFields.add(new DocValueFieldsContext.FieldAndFormat(fieldName, format.format)).             }         }         int maxAllowedDocvalueFields = context.mapperService().getIndexSettings().getMaxDocvalueFields().         if (docValueFields.size() > maxAllowedDocvalueFields) {             throw new IllegalArgumentException("Trying to retrieve too many docvalue_fields. Must be less than or equal to: [" + maxAllowedDocvalueFields + "] but was [" + docValueFields.size() + "]. This limit can be set by changing the [" + IndexSettings.MAX_DOCVALUE_FIELDS_SEARCH_SETTING.getKey() + "] index level setting.").         }         context.docValueFieldsContext(new DocValueFieldsContext(docValueFields)).     }     if (source.highlighter() != null) {         HighlightBuilder highlightBuilder = source.highlighter().         try {             context.highlight(highlightBuilder.build(queryShardContext)).         } catch (IOException e) {             throw new SearchContextException(context, "failed to create SearchContextHighlighter", e).         }     }     if (source.scriptFields() != null && source.size() != 0) {         int maxAllowedScriptFields = context.mapperService().getIndexSettings().getMaxScriptFields().         if (source.scriptFields().size() > maxAllowedScriptFields) {             throw new IllegalArgumentException("Trying to retrieve too many script_fields. Must be less than or equal to: [" + maxAllowedScriptFields + "] but was [" + source.scriptFields().size() + "]. This limit can be set by changing the [" + IndexSettings.MAX_SCRIPT_FIELDS_SETTING.getKey() + "] index level setting.").         }         for (org.elasticsearch.search.builder.SearchSourceBuilder.ScriptField field : source.scriptFields()) {             FieldScript.Factory factory = scriptService.compile(field.script(), FieldScript.CONTEXT).             FieldScript.LeafFactory searchScript = factory.newFactory(field.script().getParams(), context.lookup()).             context.scriptFields().add(new ScriptField(field.fieldName(), searchScript, field.ignoreFailure())).         }     }     if (source.ext() != null) {         for (SearchExtBuilder searchExtBuilder : source.ext()) {             context.addSearchExt(searchExtBuilder).         }     }     if (source.version() != null) {         context.version(source.version()).     }     if (source.seqNoAndPrimaryTerm() != null) {         context.seqNoAndPrimaryTerm(source.seqNoAndPrimaryTerm()).     }     if (source.stats() != null) {         context.groupStats(source.stats()).     }     if (source.searchAfter() != null && source.searchAfter().length > 0) {         if (context.scrollContext() != null) {             throw new SearchContextException(context, "`search_after` cannot be used in a scroll context.").         }         if (context.from() > 0) {             throw new SearchContextException(context, "`from` parameter must be set to 0 when `search_after` is used.").         }         FieldDoc fieldDoc = SearchAfterBuilder.buildFieldDoc(context.sort(), source.searchAfter()).         context.searchAfter(fieldDoc).     }     if (source.slice() != null) {         if (context.scrollContext() == null) {             throw new SearchContextException(context, "`slice` cannot be used outside of a scroll context").         }         context.sliceBuilder(source.slice()).     }     if (source.storedFields() != null) {         if (source.storedFields().fetchFields() == false) {             if (context.version()) {                 throw new SearchContextException(context, "`stored_fields` cannot be disabled if version is requested").             }             if (context.sourceRequested()) {                 throw new SearchContextException(context, "`stored_fields` cannot be disabled if _source is requested").             }         }         context.storedFieldsContext(source.storedFields()).     }     if (source.collapse() != null) {         final CollapseContext collapseContext = source.collapse().build(context).         context.collapse(collapseContext).     } }
true;private;1;41;/**  * Shortcut ids to load, we load only "from" and up to "size". The phase controller  * handles this as well since the result is always size * shards for Q_T_F  */ ;/**  * Shortcut ids to load, we load only "from" and up to "size". The phase controller  * handles this as well since the result is always size * shards for Q_T_F  */ private void shortcutDocIdsToLoad(SearchContext context) {     final int[] docIdsToLoad.     int docsOffset = 0.     final Suggest suggest = context.queryResult().suggest().     int numSuggestDocs = 0.     final List<CompletionSuggestion> completionSuggestions.     if (suggest != null && suggest.hasScoreDocs()) {         completionSuggestions = suggest.filter(CompletionSuggestion.class).         for (CompletionSuggestion completionSuggestion : completionSuggestions) {             numSuggestDocs += completionSuggestion.getOptions().size().         }     } else {         completionSuggestions = Collections.emptyList().     }     if (context.request().scroll() != null) {         TopDocs topDocs = context.queryResult().topDocs().topDocs.         docIdsToLoad = new int[topDocs.scoreDocs.length + numSuggestDocs].         for (int i = 0. i < topDocs.scoreDocs.length. i++) {             docIdsToLoad[docsOffset++] = topDocs.scoreDocs[i].doc.         }     } else {         TopDocs topDocs = context.queryResult().topDocs().topDocs.         if (topDocs.scoreDocs.length < context.from()) {             // no more docs...             docIdsToLoad = new int[numSuggestDocs].         } else {             int totalSize = context.from() + context.size().             docIdsToLoad = new int[Math.min(topDocs.scoreDocs.length - context.from(), context.size()) + numSuggestDocs].             for (int i = context.from(). i < Math.min(totalSize, topDocs.scoreDocs.length). i++) {                 docIdsToLoad[docsOffset++] = topDocs.scoreDocs[i].doc.             }         }     }     for (CompletionSuggestion completionSuggestion : completionSuggestions) {         for (CompletionSuggestion.Entry.Option option : completionSuggestion.getOptions()) {             docIdsToLoad[docsOffset++] = option.getDoc().doc.         }     }     context.docIdsToLoad(docIdsToLoad, 0, docIdsToLoad.length). }
false;private;2;9;;private void processScroll(InternalScrollSearchRequest request, SearchContext context) {     // process scroll     context.from(context.from() + context.size()).     context.scrollContext().scroll = request.scroll().     // update the context keep alive based on the new scroll value     if (request.scroll() != null && request.scroll().keepAlive() != null) {         contextScrollKeepAlive(context, request.scroll().keepAlive().millis()).     } }
true;public;0;3;/**  * Returns the number of active contexts in this  * SearchService  */ ;/**  * Returns the number of active contexts in this  * SearchService  */ public int getActiveContexts() {     return this.activeContexts.size(). }
false;public;0;3;;public ResponseCollectorService getResponseCollectorService() {     return this.responseCollectorService. }
false;public;0;17;;@Override public void run() {     final long time = threadPool.relativeTimeInMillis().     for (SearchContext context : activeContexts.values()) {         // Use the same value for both checks since lastAccessTime can         // be modified by another thread between checks!         final long lastAccessTime = context.lastAccessTime().         if (lastAccessTime == -1L) {             // its being processed or timeout is disabled             continue.         }         if ((time - lastAccessTime > context.keepAlive())) {             logger.debug("freeing search context [{}], time [{}], lastAccessTime [{}], keepAlive [{}]", context.id(), time, lastAccessTime, context.keepAlive()).             freeContext(context.id()).         }     } }
false;public;3;3;;public AliasFilter buildAliasFilter(ClusterState state, String index, String... expressions) {     return indicesService.buildAliasFilter(state, index, expressions). }
true;public;1;11;/**  * This method does a very quick rewrite of the query and returns true if the query can potentially match any documents.  * This method can have false positives while if it returns <code>false</code> the query won't match any documents on the current  * shard.  */ ;/**  * This method does a very quick rewrite of the query and returns true if the query can potentially match any documents.  * This method can have false positives while if it returns <code>false</code> the query won't match any documents on the current  * shard.  */ public boolean canMatch(ShardSearchRequest request) throws IOException {     assert request.searchType() == SearchType.QUERY_THEN_FETCH : "unexpected search type: " + request.searchType().     try (DefaultSearchContext context = createSearchContext(request, defaultSearchTimeout, false, "can_match")) {         SearchSourceBuilder source = context.request().source().         if (canRewriteToMatchNone(source)) {             QueryBuilder queryBuilder = source.query().             return queryBuilder instanceof MatchNoneQueryBuilder == false.         }         // null query means match_all         return true.     } }
false;public;2;7;;public void canMatch(ShardSearchRequest request, ActionListener<CanMatchResponse> listener) {     try {         listener.onResponse(new CanMatchResponse(canMatch(request))).     } catch (IOException e) {         listener.onFailure(e).     } }
true;public,static;1;7;/**  * Returns true iff the given search source builder can be early terminated by rewriting to a match none query. Or in other words  * if the execution of the search request can be early terminated without executing it. This is for instance not possible if  * a global aggregation is part of this request or if there is a suggest builder present.  */ ;/**  * Returns true iff the given search source builder can be early terminated by rewriting to a match none query. Or in other words  * if the execution of the search request can be early terminated without executing it. This is for instance not possible if  * a global aggregation is part of this request or if there is a suggest builder present.  */ public static boolean canRewriteToMatchNone(SearchSourceBuilder source) {     if (source == null || source.query() == null || source.query() instanceof MatchAllQueryBuilder || source.suggest() != null) {         return false.     }     AggregatorFactories.Builder aggregations = source.aggregations().     return aggregations == null || aggregations.mustVisitAllDocs() == false. }
false;public;1;4;;@Override public void onFailure(Exception e) {     listener.onFailure(e). }
false;protected;0;4;;@Override protected void doRun() {     listener.onResponse(request). }
true;private;2;23;/*      * Rewrites the search request with a light weight rewrite context in order to fetch resources asynchronously      * The action listener is guaranteed to be executed on the search thread-pool      */ ;/*      * Rewrites the search request with a light weight rewrite context in order to fetch resources asynchronously      * The action listener is guaranteed to be executed on the search thread-pool      */ private void rewriteShardRequest(ShardSearchRequest request, ActionListener<ShardSearchRequest> listener) {     IndexShard shard = indicesService.indexServiceSafe(request.shardId().getIndex()).getShard(request.shardId().id()).     Executor executor = getExecutor(shard).     ActionListener<Rewriteable> actionListener = ActionListener.wrap(r -> shard.awaitShardSearchActive(b -> executor.execute(new AbstractRunnable() {          @Override         public void onFailure(Exception e) {             listener.onFailure(e).         }          @Override         protected void doRun() {             listener.onResponse(request).         }     })), listener::onFailure).     // we also do rewrite on the coordinating node (TransportSearchService) but we also need to do it here for BWC as well as     // AliasFilters that might need to be rewritten. These are edge-cases but we are every efficient doing the rewrite here so it's not     // adding a lot of overhead     Rewriteable.rewriteAndFetch(request.getRewriteable(), indicesService.getRewriteContext(request::nowInMillis), actionListener). }
true;public;1;3;/**  * Returns a new {@link QueryRewriteContext} with the given {@code now} provider  */ ;/**  * Returns a new {@link QueryRewriteContext} with the given {@code now} provider  */ public QueryRewriteContext getRewriteContext(LongSupplier nowInMillis) {     return indicesService.getRewriteContext(nowInMillis). }
false;public;0;3;;public IndicesService getIndicesService() {     return indicesService. }
false;public;1;4;;public InternalAggregation.ReduceContext createReduceContext(boolean finalReduce) {     return new InternalAggregation.ReduceContext(bigArrays, scriptService, finalReduce ? multiBucketConsumerService.create() : bucketCount -> {     }, finalReduce). }
false;public;1;5;;@Override public void readFrom(StreamInput in) throws IOException {     super.readFrom(in).     canMatch = in.readBoolean(). }
false;public;1;5;;@Override public void writeTo(StreamOutput out) throws IOException {     super.writeTo(out).     out.writeBoolean(canMatch). }
false;public;0;3;;public boolean canMatch() {     return canMatch. }
false;;0;3;;long success() {     return afterQueryTime = System.nanoTime(). }
false;public;0;20;;@Override public void close() {     assert closed == false : "already closed - while technically ok double closing is a likely a bug in this case".     if (closed == false) {         closed = true.         if (afterQueryTime != -1) {             if (fetch) {                 listener.onFetchPhase(context, afterQueryTime - time).             } else {                 listener.onQueryPhase(context, afterQueryTime - time).             }         } else {             if (fetch) {                 listener.onFailedFetchPhase(context).             } else {                 listener.onFailedQueryPhase(context).             }         }     } }
