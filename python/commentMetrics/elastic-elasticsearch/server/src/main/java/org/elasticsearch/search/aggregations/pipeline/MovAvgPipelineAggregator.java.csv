commented;modifiers;parameterAmount;loc;comment;code
false;public;1;9;;@Override public void doWriteTo(StreamOutput out) throws IOException {     out.writeNamedWriteable(formatter).     gapPolicy.writeTo(out).     out.writeVInt(window).     out.writeVInt(predict).     out.writeNamedWriteable(model).     out.writeBoolean(minimize). }
false;public;0;4;;@Override public String getWriteableName() {     return MovAvgPipelineAggregationBuilder.NAME. }
false;public;2;90;;@Override public InternalAggregation reduce(InternalAggregation aggregation, ReduceContext reduceContext) {     InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends InternalMultiBucketAggregation.InternalBucket> histo = (InternalMultiBucketAggregation<? extends InternalMultiBucketAggregation, ? extends InternalMultiBucketAggregation.InternalBucket>) aggregation.     List<? extends InternalMultiBucketAggregation.InternalBucket> buckets = histo.getBuckets().     HistogramFactory factory = (HistogramFactory) histo.     List<Bucket> newBuckets = new ArrayList<>().     EvictingQueue<Double> values = new EvictingQueue<>(this.window).     Number lastValidKey = 0.     int lastValidPosition = 0.     int counter = 0.     // Do we need to fit the model parameters to the data?     if (minimize) {         assert (model.canBeMinimized()).         model = minimize(buckets, histo, model).     }     for (InternalMultiBucketAggregation.InternalBucket bucket : buckets) {         Double thisBucketValue = resolveBucketValue(histo, bucket, bucketsPaths()[0], gapPolicy).         // Default is to reuse existing bucket.  Simplifies the rest of the logic,         // since we only change newBucket if we can add to it         Bucket newBucket = bucket.         if ((thisBucketValue == null || thisBucketValue.equals(Double.NaN)) == false) {             // Some models (e.g. HoltWinters) have certain preconditions that must be met             if (model.hasValue(values.size())) {                 double movavg = model.next(values).                 List<InternalAggregation> aggs = StreamSupport.stream(bucket.getAggregations().spliterator(), false).map((p) -> (InternalAggregation) p).collect(Collectors.toList()).                 aggs.add(new InternalSimpleValue(name(), movavg, formatter, new ArrayList<>(), metaData())).                 newBucket = factory.createBucket(factory.getKey(bucket), bucket.getDocCount(), new InternalAggregations(aggs)).             }             if (predict > 0) {                 lastValidKey = factory.getKey(bucket).                 lastValidPosition = counter.             }             values.offer(thisBucketValue).         }         counter += 1.         newBuckets.add(newBucket).     }     if (buckets.size() > 0 && predict > 0) {         double[] predictions = model.predict(values, predict).         for (int i = 0. i < predictions.length. i++) {             List<InternalAggregation> aggs.             Number newKey = factory.nextKey(lastValidKey).             if (lastValidPosition + i + 1 < newBuckets.size()) {                 Bucket bucket = newBuckets.get(lastValidPosition + i + 1).                 // Get the existing aggs in the bucket so we don't clobber data                 aggs = StreamSupport.stream(bucket.getAggregations().spliterator(), false).map((p) -> (InternalAggregation) p).collect(Collectors.toList()).                 aggs.add(new InternalSimpleValue(name(), predictions[i], formatter, new ArrayList<>(), metaData())).                 Bucket newBucket = factory.createBucket(newKey, bucket.getDocCount(), new InternalAggregations(aggs)).                 // Overwrite the existing bucket with the new version                 newBuckets.set(lastValidPosition + i + 1, newBucket).             } else {                 // Not seen before, create fresh                 aggs = new ArrayList<>().                 aggs.add(new InternalSimpleValue(name(), predictions[i], formatter, new ArrayList<>(), metaData())).                 Bucket newBucket = factory.createBucket(newKey, 0, new InternalAggregations(aggs)).                 // Since this is a new bucket, simply append it                 newBuckets.add(newBucket).             }             lastValidKey = newKey.         }     }     return factory.createAggregation(newBuckets). }
false;private;3;54;;private MovAvgModel minimize(List<? extends InternalMultiBucketAggregation.InternalBucket> buckets, MultiBucketsAggregation histo, MovAvgModel model) {     int counter = 0.     EvictingQueue<Double> values = new EvictingQueue<>(this.window).     double[] test = new double[window].     ListIterator<? extends InternalMultiBucketAggregation.InternalBucket> iter = buckets.listIterator(buckets.size()).     // We have to walk the iterator backwards because we don't know if/how many buckets are empty.     while (iter.hasPrevious() && counter < window) {         Double thisBucketValue = resolveBucketValue(histo, iter.previous(), bucketsPaths()[0], gapPolicy).         if (!(thisBucketValue == null || thisBucketValue.equals(Double.NaN))) {             test[window - counter - 1] = thisBucketValue.             counter += 1.         }     }     // Just return the model with the starting coef     if (counter < window) {         return model.     }     // And do it again, for the train set.  Unfortunately we have to fill an array and then     // fill an evicting queue backwards :(     counter = 0.     double[] train = new double[window].     while (iter.hasPrevious() && counter < window) {         Double thisBucketValue = resolveBucketValue(histo, iter.previous(), bucketsPaths()[0], gapPolicy).         if (!(thisBucketValue == null || thisBucketValue.equals(Double.NaN))) {             train[window - counter - 1] = thisBucketValue.             counter += 1.         }     }     // Just return the model with the starting coef     if (counter < window) {         return model.     }     for (double v : train) {         values.add(v).     }     return SimulatedAnealingMinimizer.minimize(model, values, test). }
