commented;modifiers;parameterAmount;loc;comment;code
true;public;4;6;/**  * Starts are new recovery for the given shard, source node and state  *  * @return the id of the new recovery.  */ ;/**  * Starts are new recovery for the given shard, source node and state  *  * @return the id of the new recovery.  */ public long startRecovery(IndexShard indexShard, DiscoveryNode sourceNode, PeerRecoveryTargetService.RecoveryListener listener, TimeValue activityTimeout) {     RecoveryTarget recoveryTarget = new RecoveryTarget(indexShard, sourceNode, listener, ensureClusterStateVersionCallback).     startRecoveryInternal(recoveryTarget, activityTimeout).     return recoveryTarget.recoveryId(). }
false;private;2;8;;private void startRecoveryInternal(RecoveryTarget recoveryTarget, TimeValue activityTimeout) {     RecoveryTarget existingTarget = onGoingRecoveries.putIfAbsent(recoveryTarget.recoveryId(), recoveryTarget).     assert existingTarget == null : "found two RecoveryStatus instances with the same id".     logger.trace("{} started recovery from {}, id [{}]", recoveryTarget.shardId(), recoveryTarget.sourceNode(), recoveryTarget.recoveryId()).     threadPool.schedule(new RecoveryMonitor(recoveryTarget.recoveryId(), recoveryTarget.lastAccessTime(), activityTimeout), activityTimeout, ThreadPool.Names.GENERIC). }
true;public;2;36;/**  * Resets the recovery and performs a recovery restart on the currently recovering index shard  *  * @see IndexShard#performRecoveryRestart()  * @return newly created RecoveryTarget  */ ;/**  * Resets the recovery and performs a recovery restart on the currently recovering index shard  *  * @see IndexShard#performRecoveryRestart()  * @return newly created RecoveryTarget  */ public RecoveryTarget resetRecovery(final long recoveryId, final TimeValue activityTimeout) {     RecoveryTarget oldRecoveryTarget = null.     final RecoveryTarget newRecoveryTarget.     try {         synchronized (onGoingRecoveries) {             // swap recovery targets in a synchronized block to ensure that the newly added recovery target is picked up by             // cancelRecoveriesForShard whenever the old recovery target is picked up             oldRecoveryTarget = onGoingRecoveries.remove(recoveryId).             if (oldRecoveryTarget == null) {                 return null.             }             newRecoveryTarget = oldRecoveryTarget.retryCopy().             startRecoveryInternal(newRecoveryTarget, activityTimeout).         }         // Closes the current recovery target         boolean successfulReset = oldRecoveryTarget.resetRecovery(newRecoveryTarget.cancellableThreads()).         if (successfulReset) {             logger.trace("{} restarted recovery from {}, id [{}], previous id [{}]", newRecoveryTarget.shardId(), newRecoveryTarget.sourceNode(), newRecoveryTarget.recoveryId(), oldRecoveryTarget.recoveryId()).             return newRecoveryTarget.         } else {             logger.trace("{} recovery could not be reset as it is already cancelled, recovery from {}, id [{}], previous id [{}]", newRecoveryTarget.shardId(), newRecoveryTarget.sourceNode(), newRecoveryTarget.recoveryId(), oldRecoveryTarget.recoveryId()).             cancelRecovery(newRecoveryTarget.recoveryId(), "recovery cancelled during reset").             return null.         }     } catch (Exception e) {         // fail shard to be safe         oldRecoveryTarget.notifyListener(new RecoveryFailedException(oldRecoveryTarget.state(), "failed to retry recovery", e), true).         return null.     } }
false;public;1;3;;public RecoveryTarget getRecoveryTarget(long id) {     return onGoingRecoveries.get(id). }
true;public;1;7;/**  * gets the {@link RecoveryTarget } for a given id. The RecoveryStatus returned has it's ref count already incremented  * to make sure it's safe to use. However, you must call {@link RecoveryTarget#decRef()} when you are done with it, typically  * by using this method in a try-with-resources clause.  * <p>  * Returns null if recovery is not found  */ ;/**  * gets the {@link RecoveryTarget } for a given id. The RecoveryStatus returned has it's ref count already incremented  * to make sure it's safe to use. However, you must call {@link RecoveryTarget#decRef()} when you are done with it, typically  * by using this method in a try-with-resources clause.  * <p>  * Returns null if recovery is not found  */ public RecoveryRef getRecovery(long id) {     RecoveryTarget status = onGoingRecoveries.get(id).     if (status != null && status.tryIncRef()) {         return new RecoveryRef(status).     }     return null. }
true;public;2;8;/**  * Similar to {@link #getRecovery(long)} but throws an exception if no recovery is found  */ ;/**  * Similar to {@link #getRecovery(long)} but throws an exception if no recovery is found  */ public RecoveryRef getRecoverySafe(long id, ShardId shardId) {     RecoveryRef recoveryRef = getRecovery(id).     if (recoveryRef == null) {         throw new IndexShardClosedException(shardId).     }     assert recoveryRef.target().shardId().equals(shardId).     return recoveryRef. }
true;public;2;11;/**  * cancel the recovery with the given id (if found) and remove it from the recovery collection  */ ;/**  * cancel the recovery with the given id (if found) and remove it from the recovery collection  */ public boolean cancelRecovery(long id, String reason) {     RecoveryTarget removed = onGoingRecoveries.remove(id).     boolean cancelled = false.     if (removed != null) {         logger.trace("{} canceled recovery from {}, id [{}] (reason [{}])", removed.shardId(), removed.sourceNode(), removed.recoveryId(), reason).         removed.cancel(reason).         cancelled = true.     }     return cancelled. }
true;public;3;8;/**  * fail the recovery with the given id (if found) and remove it from the recovery collection  *  * @param id               id of the recovery to fail  * @param e                exception with reason for the failure  * @param sendShardFailure true a shard failed message should be sent to the master  */ ;/**  * fail the recovery with the given id (if found) and remove it from the recovery collection  *  * @param id               id of the recovery to fail  * @param e                exception with reason for the failure  * @param sendShardFailure true a shard failed message should be sent to the master  */ public void failRecovery(long id, RecoveryFailedException e, boolean sendShardFailure) {     RecoveryTarget removed = onGoingRecoveries.remove(id).     if (removed != null) {         logger.trace("{} failing recovery from {}, id [{}]. Send shard failure: [{}]", removed.shardId(), removed.sourceNode(), removed.recoveryId(), sendShardFailure).         removed.fail(e, sendShardFailure).     } }
true;public;1;7;/**  * mark the recovery with the given id as done (if found)  */ ;/**  * mark the recovery with the given id as done (if found)  */ public void markRecoveryAsDone(long id) {     RecoveryTarget removed = onGoingRecoveries.remove(id).     if (removed != null) {         logger.trace("{} marking recovery from {} as done, id [{}]", removed.shardId(), removed.sourceNode(), removed.recoveryId()).         removed.markAsDone().     } }
true;public;0;3;/**  * the number of ongoing recoveries  */ ;/**  * the number of ongoing recoveries  */ public int size() {     return onGoingRecoveries.size(). }
true;public;2;20;/**  * cancel all ongoing recoveries for the given shard  *  * @param reason       reason for cancellation  * @param shardId      shardId for which to cancel recoveries  * @return true if a recovery was cancelled  */ ;/**  * cancel all ongoing recoveries for the given shard  *  * @param reason       reason for cancellation  * @param shardId      shardId for which to cancel recoveries  * @return true if a recovery was cancelled  */ public boolean cancelRecoveriesForShard(ShardId shardId, String reason) {     boolean cancelled = false.     List<RecoveryTarget> matchedRecoveries = new ArrayList<>().     synchronized (onGoingRecoveries) {         for (Iterator<RecoveryTarget> it = onGoingRecoveries.values().iterator(). it.hasNext(). ) {             RecoveryTarget status = it.next().             if (status.shardId().equals(shardId)) {                 matchedRecoveries.add(status).                 it.remove().             }         }     }     for (RecoveryTarget removed : matchedRecoveries) {         logger.trace("{} canceled recovery from {}, id [{}] (reason [{}])", removed.shardId(), removed.sourceNode(), removed.recoveryId(), reason).         removed.cancel(reason).         cancelled = true.     }     return cancelled. }
false;public;0;6;;@Override public void close() {     if (closed.compareAndSet(false, true)) {         status.decRef().     } }
false;public;0;3;;public RecoveryTarget target() {     return status. }
false;public;1;4;;@Override public void onFailure(Exception e) {     logger.error(() -> new ParameterizedMessage("unexpected error while monitoring recovery [{}]", recoveryId), e). }
false;protected;0;20;;@Override protected void doRun() throws Exception {     RecoveryTarget status = onGoingRecoveries.get(recoveryId).     if (status == null) {         logger.trace("[monitor] no status found for [{}], shutting down", recoveryId).         return.     }     long accessTime = status.lastAccessTime().     if (accessTime == lastSeenAccessTime) {         String message = "no activity after [" + checkInterval + "]".         failRecovery(recoveryId, new RecoveryFailedException(status.state(), message, new ElasticsearchTimeoutException(message)), // to be safe, we don't know what go stuck         true).         return.     }     lastSeenAccessTime = accessTime.     logger.trace("[monitor] rescheduling check for [{}]. last access time is [{}]", recoveryId, lastSeenAccessTime).     threadPool.schedule(this, checkInterval, ThreadPool.Names.GENERIC). }
