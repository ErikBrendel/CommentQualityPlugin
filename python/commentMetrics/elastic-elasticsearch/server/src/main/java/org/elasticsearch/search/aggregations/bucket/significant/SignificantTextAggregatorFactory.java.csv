commented;modifiers;parameterAmount;loc;comment;code
true;public;0;3;/**  * Get the number of docs in the superset.  */ ;/**  * Get the number of docs in the superset.  */ public long getSupersetNumDocs() {     return supersetNumDocs. }
false;private;1;12;;private FilterableTermsEnum getTermsEnum(String field) throws IOException {     if (termsEnum != null) {         return termsEnum.     }     IndexReader reader = context.searcher().getIndexReader().     if (numberOfAggregatorsCreated > 1) {         termsEnum = new FreqTermsEnum(reader, field, true, false, filter, context.bigArrays()).     } else {         termsEnum = new FilterableTermsEnum(reader, indexedFieldName, PostingsEnum.NONE, filter).     }     return termsEnum. }
false;private;1;22;;private long getBackgroundFrequency(String value) throws IOException {     Query query = fieldType.termQuery(value, context.getQueryShardContext()).     if (query instanceof TermQuery) {         // for types that use the inverted index, we prefer using a caching terms         // enum that will do a better job at reusing index inputs         Term term = ((TermQuery) query).getTerm().         FilterableTermsEnum termsEnum = getTermsEnum(term.field()).         if (termsEnum.seekExact(term.bytes())) {             return termsEnum.docFreq().         } else {             return 0.         }     }     // otherwise do it the naive way     if (filter != null) {         query = new BooleanQuery.Builder().add(query, Occur.FILTER).add(filter, Occur.FILTER).build().     }     return context.searcher().count(query). }
false;public;1;4;;public long getBackgroundFrequency(BytesRef termBytes) throws IOException {     String value = format.format(termBytes).toString().     return getBackgroundFrequency(value). }
false;public;0;10;;@Override public void close() {     try {         if (termsEnum instanceof Releasable) {             ((Releasable) termsEnum).close().         }     } finally {         termsEnum = null.     } }
false;protected;4;32;;@Override protected Aggregator createInternal(Aggregator parent, boolean collectsFromSingleBucket, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) throws IOException {     if (collectsFromSingleBucket == false) {         return asMultiBucketAggregator(this, context, parent).     }     numberOfAggregatorsCreated++.     BucketCountThresholds bucketCountThresholds = new BucketCountThresholds(this.bucketCountThresholds).     if (bucketCountThresholds.getShardSize() == SignificantTextAggregationBuilder.DEFAULT_BUCKET_COUNT_THRESHOLDS.getShardSize()) {         // The user has not made a shardSize selection.         // Use default heuristic to avoid any wrong-ranking caused by         // distributed counting but request double the usual amount.         // We typically need more than the number of "top" terms requested         // by other aggregations as the significance algorithm is in less         // of a position to down-select at shard-level - some of the things         // we want to find have only one occurrence on each shard and as         // such are impossible to differentiate from non-significant terms         // at that early stage.         bucketCountThresholds.setShardSize(2 * BucketUtils.suggestShardSideQueueSize(bucketCountThresholds.getRequiredSize())).     }     // TODO - need to check with mapping that this is indeed a text field....     IncludeExclude.StringFilter incExcFilter = includeExclude == null ? null : includeExclude.convertToStringFilter(DocValueFormat.RAW).     return new SignificantTextAggregator(name, factories, context, parent, pipelineAggregators, bucketCountThresholds, incExcFilter, significanceHeuristic, this, indexedFieldName, sourceFieldNames, filterDuplicateText, metaData). }
