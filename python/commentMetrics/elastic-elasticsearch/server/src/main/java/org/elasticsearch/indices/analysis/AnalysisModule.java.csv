commented;modifiers;parameterAmount;loc;comment;code
false;;0;3;;HunspellService getHunspellService() {     return hunspellService. }
false;public;0;3;;public AnalysisRegistry getAnalysisRegistry() {     return analysisRegistry. }
false;private;1;5;;private NamedRegistry<AnalysisProvider<CharFilterFactory>> setupCharFilters(List<AnalysisPlugin> plugins) {     NamedRegistry<AnalysisProvider<CharFilterFactory>> charFilters = new NamedRegistry<>("char_filter").     charFilters.extractAndRegister(plugins, AnalysisPlugin::getCharFilters).     return charFilters. }
false;public;1;5;;public NamedRegistry<org.apache.lucene.analysis.hunspell.Dictionary> setupHunspellDictionaries(List<AnalysisPlugin> plugins) {     NamedRegistry<org.apache.lucene.analysis.hunspell.Dictionary> hunspellDictionaries = new NamedRegistry<>("dictionary").     hunspellDictionaries.extractAndRegister(plugins, AnalysisPlugin::getHunspellDictionaries).     return hunspellDictionaries. }
false;public;1;4;;@Override public TokenStream create(TokenStream tokenStream) {     return tokenStream. }
false;public;4;15;;@Override public TokenFilterFactory get(IndexSettings indexSettings, Environment environment, String name, Settings settings) {     if (indexSettings.getIndexVersionCreated().before(Version.V_7_0_0)) {         deprecationLogger.deprecatedAndMaybeLog("standard_deprecation", "The [standard] token filter name is deprecated and will be removed in a future version.").     } else {         throw new IllegalArgumentException("The [standard] token filter has been removed.").     }     return new AbstractTokenFilterFactory(indexSettings, name, settings) {          @Override         public TokenStream create(TokenStream tokenStream) {             return tokenStream.         }     }. }
false;public;0;4;;@Override public boolean requiresAnalysisSettings() {     return false. }
false;private;2;34;;private NamedRegistry<AnalysisProvider<TokenFilterFactory>> setupTokenFilters(List<AnalysisPlugin> plugins, HunspellService hunspellService) {     NamedRegistry<AnalysisProvider<TokenFilterFactory>> tokenFilters = new NamedRegistry<>("token_filter").     tokenFilters.register("stop", StopTokenFilterFactory::new).     // Add "standard" for old indices (bwc)     tokenFilters.register("standard", new AnalysisProvider<TokenFilterFactory>() {          @Override         public TokenFilterFactory get(IndexSettings indexSettings, Environment environment, String name, Settings settings) {             if (indexSettings.getIndexVersionCreated().before(Version.V_7_0_0)) {                 deprecationLogger.deprecatedAndMaybeLog("standard_deprecation", "The [standard] token filter name is deprecated and will be removed in a future version.").             } else {                 throw new IllegalArgumentException("The [standard] token filter has been removed.").             }             return new AbstractTokenFilterFactory(indexSettings, name, settings) {                  @Override                 public TokenStream create(TokenStream tokenStream) {                     return tokenStream.                 }             }.         }          @Override         public boolean requiresAnalysisSettings() {             return false.         }     }).     tokenFilters.register("shingle", ShingleTokenFilterFactory::new).     tokenFilters.register("hunspell", requiresAnalysisSettings((indexSettings, env, name, settings) -> new HunspellTokenFilterFactory(indexSettings, name, settings, hunspellService))).     tokenFilters.extractAndRegister(plugins, AnalysisPlugin::getTokenFilters).     return tokenFilters. }
false;static;1;9;;static Map<String, PreBuiltAnalyzerProviderFactory> setupPreBuiltAnalyzerProviderFactories(List<AnalysisPlugin> plugins) {     NamedRegistry<PreBuiltAnalyzerProviderFactory> preConfiguredCharFilters = new NamedRegistry<>("pre-built analyzer").     for (AnalysisPlugin plugin : plugins) {         for (PreBuiltAnalyzerProviderFactory factory : plugin.getPreBuiltAnalyzerProviderFactories()) {             preConfiguredCharFilters.register(factory.getName(), factory).         }     }     return unmodifiableMap(preConfiguredCharFilters.getRegistry()). }
false;static;1;12;;static Map<String, PreConfiguredCharFilter> setupPreConfiguredCharFilters(List<AnalysisPlugin> plugins) {     NamedRegistry<PreConfiguredCharFilter> preConfiguredCharFilters = new NamedRegistry<>("pre-configured char_filter").     for (AnalysisPlugin plugin : plugins) {         for (PreConfiguredCharFilter filter : plugin.getPreConfiguredCharFilters()) {             preConfiguredCharFilters.register(filter.getName(), filter).         }     }     return unmodifiableMap(preConfiguredCharFilters.getRegistry()). }
false;static;1;28;;static Map<String, PreConfiguredTokenFilter> setupPreConfiguredTokenFilters(List<AnalysisPlugin> plugins) {     NamedRegistry<PreConfiguredTokenFilter> preConfiguredTokenFilters = new NamedRegistry<>("pre-configured token_filter").     // Add filters available in lucene-core     preConfiguredTokenFilters.register("lowercase", PreConfiguredTokenFilter.singleton("lowercase", true, LowerCaseFilter::new)).     // Add "standard" for old indices (bwc)     preConfiguredTokenFilters.register("standard", PreConfiguredTokenFilter.singletonWithVersion("standard", true, (reader, version) -> {         if (version.before(Version.V_7_0_0)) {             deprecationLogger.deprecatedAndMaybeLog("standard_deprecation", "The [standard] token filter is deprecated and will be removed in a future version.").         } else {             throw new IllegalArgumentException("The [standard] token filter has been removed.").         }         return reader.     })).     for (AnalysisPlugin plugin : plugins) {         for (PreConfiguredTokenFilter filter : plugin.getPreConfiguredTokenFilters()) {             preConfiguredTokenFilters.register(filter.getName(), filter).         }     }     return unmodifiableMap(preConfiguredTokenFilters.getRegistry()). }
false;static;1;25;;static Map<String, PreConfiguredTokenizer> setupPreConfiguredTokenizers(List<AnalysisPlugin> plugins) {     NamedRegistry<PreConfiguredTokenizer> preConfiguredTokenizers = new NamedRegistry<>("pre-configured tokenizer").     // Temporary shim to register old style pre-configured tokenizers     for (PreBuiltTokenizers tokenizer : PreBuiltTokenizers.values()) {         String name = tokenizer.name().toLowerCase(Locale.ROOT).         PreConfiguredTokenizer preConfigured.         switch(tokenizer.getCachingStrategy()) {             case ONE:                 preConfigured = PreConfiguredTokenizer.singleton(name, () -> tokenizer.create(Version.CURRENT)).                 break.             default:                 throw new UnsupportedOperationException("Caching strategy unsupported by temporary shim [" + tokenizer + "]").         }         preConfiguredTokenizers.register(name, preConfigured).     }     for (AnalysisPlugin plugin : plugins) {         for (PreConfiguredTokenizer tokenizer : plugin.getPreConfiguredTokenizers()) {             preConfiguredTokenizers.register(tokenizer.getName(), tokenizer).         }     }     return unmodifiableMap(preConfiguredTokenizers.getRegistry()). }
false;private;1;6;;private NamedRegistry<AnalysisProvider<TokenizerFactory>> setupTokenizers(List<AnalysisPlugin> plugins) {     NamedRegistry<AnalysisProvider<TokenizerFactory>> tokenizers = new NamedRegistry<>("tokenizer").     tokenizers.register("standard", StandardTokenizerFactory::new).     tokenizers.extractAndRegister(plugins, AnalysisPlugin::getTokenizers).     return tokenizers. }
false;private;1;11;;private NamedRegistry<AnalysisProvider<AnalyzerProvider<?>>> setupAnalyzers(List<AnalysisPlugin> plugins) {     NamedRegistry<AnalysisProvider<AnalyzerProvider<?>>> analyzers = new NamedRegistry<>("analyzer").     analyzers.register("default", StandardAnalyzerProvider::new).     analyzers.register("standard", StandardAnalyzerProvider::new).     analyzers.register("simple", SimpleAnalyzerProvider::new).     analyzers.register("stop", StopAnalyzerProvider::new).     analyzers.register("whitespace", WhitespaceAnalyzerProvider::new).     analyzers.register("keyword", KeywordAnalyzerProvider::new).     analyzers.extractAndRegister(plugins, AnalysisPlugin::getAnalyzers).     return analyzers. }
false;private;1;6;;private NamedRegistry<AnalysisProvider<AnalyzerProvider<?>>> setupNormalizers(List<AnalysisPlugin> plugins) {     NamedRegistry<AnalysisProvider<AnalyzerProvider<?>>> normalizers = new NamedRegistry<>("normalizer").     // TODO: pluggability?     return normalizers. }
true;;4;1;/**  * Creates a new analysis provider.  *  * @param indexSettings the index settings for the index this provider is created for  * @param environment   the nodes environment to load resources from persistent storage  * @param name          the name of the analysis component  * @param settings      the component specific settings without context prefixes  * @return a new provider instance  * @throws IOException if an {@link IOException} occurs  */ ;/**  * Creates a new analysis provider.  *  * @param indexSettings the index settings for the index this provider is created for  * @param environment   the nodes environment to load resources from persistent storage  * @param name          the name of the analysis component  * @param settings      the component specific settings without context prefixes  * @return a new provider instance  * @throws IOException if an {@link IOException} occurs  */ T get(IndexSettings indexSettings, Environment environment, String name, Settings settings) throws IOException.
true;default;2;6;/**  * Creates a new global scope analysis provider without index specific settings not settings for the provider itself.  * This can be used to get a default instance of an analysis factory without binding to an index.  *  * @param environment the nodes environment to load resources from persistent storage  * @param name        the name of the analysis component  * @return a new provider instance  * @throws IOException              if an {@link IOException} occurs  * @throws IllegalArgumentException if the provider requires analysis settings ie. if {@link #requiresAnalysisSettings()} returns  *                                  <code>true</code>  */ ;/**  * Creates a new global scope analysis provider without index specific settings not settings for the provider itself.  * This can be used to get a default instance of an analysis factory without binding to an index.  *  * @param environment the nodes environment to load resources from persistent storage  * @param name        the name of the analysis component  * @return a new provider instance  * @throws IOException              if an {@link IOException} occurs  * @throws IllegalArgumentException if the provider requires analysis settings ie. if {@link #requiresAnalysisSettings()} returns  *                                  <code>true</code>  */ default T get(Environment environment, String name) throws IOException {     if (requiresAnalysisSettings()) {         throw new IllegalArgumentException("Analysis settings required - can't instantiate analysis factory").     }     return get(NA_INDEX_SETTINGS, environment, name, NA_INDEX_SETTINGS.getSettings()). }
true;default;0;3;/**  * If <code>true</code> the analysis component created by this provider requires certain settings to be instantiated.  * it can't be created with defaults. The default is <code>false</code>.  */ ;/**  * If <code>true</code> the analysis component created by this provider requires certain settings to be instantiated.  * it can't be created with defaults. The default is <code>false</code>.  */ default boolean requiresAnalysisSettings() {     return false. }
