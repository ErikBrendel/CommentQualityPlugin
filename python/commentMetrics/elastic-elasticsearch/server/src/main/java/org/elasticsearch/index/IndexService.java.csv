commented;modifiers;parameterAmount;loc;comment;code
false;public;0;3;;public int numberOfShards() {     return shards.size(). }
false;public;0;3;;public IndexEventListener getIndexEventListener() {     return this.eventListener. }
false;public;0;4;;@Override public Iterator<IndexShard> iterator() {     return shards.values().iterator(). }
false;public;1;3;;public boolean hasShard(int shardId) {     return shards.containsKey(shardId). }
true;public;1;5;/**  * Return the shard with the provided id, or null if there is no such shard.  */ ;/**  * Return the shard with the provided id, or null if there is no such shard.  */ @Override @Nullable public IndexShard getShardOrNull(int shardId) {     return shards.get(shardId). }
true;public;1;7;/**  * Return the shard with the provided id, or throw an exception if it doesn't exist.  */ ;/**  * Return the shard with the provided id, or throw an exception if it doesn't exist.  */ public IndexShard getShard(int shardId) {     IndexShard indexShard = getShardOrNull(shardId).     if (indexShard == null) {         throw new ShardNotFoundException(new ShardId(index(), shardId)).     }     return indexShard. }
false;public;0;3;;public Set<Integer> shardIds() {     return shards.keySet(). }
false;public;0;3;;public IndexCache cache() {     return indexCache. }
false;public;0;3;;public IndexAnalyzers getIndexAnalyzers() {     return this.mapperService.getIndexAnalyzers(). }
false;public;0;3;;public MapperService mapperService() {     return mapperService. }
false;public;0;3;;public NamedXContentRegistry xContentRegistry() {     return xContentRegistry. }
false;public;0;3;;public SimilarityService similarityService() {     return similarityService. }
false;public;0;3;;public Supplier<Sort> getIndexSortSupplier() {     return indexSortSupplier. }
false;public,synchronized;2;26;;public synchronized void close(final String reason, boolean delete) throws IOException {     if (closed.compareAndSet(false, true)) {         deleted.compareAndSet(false, delete).         try {             final Set<Integer> shardIds = shardIds().             for (final int shardId : shardIds) {                 try {                     removeShard(shardId, reason).                 } catch (Exception e) {                     logger.warn("failed to close shard", e).                 }             }         } finally {             IOUtils.close(bitsetFilterCache, indexCache, indexFieldData, mapperService, refreshTask, fsyncTask, trimTranslogTask, globalCheckpointTask, retentionLeaseSyncTask).         }     } }
false;public;0;3;;public String indexUUID() {     return indexSettings.getUUID(). }
true;private;0;13;// NOTE: O(numShards) cost, but numShards should be smallish? ;// NOTE: O(numShards) cost, but numShards should be smallish? private long getAvgShardSizeInBytes() throws IOException {     long sum = 0.     int count = 0.     for (IndexShard indexShard : this) {         sum += indexShard.store().stats().sizeInBytes().         count++.     }     if (count == 0) {         return -1L.     } else {         return sum / count.     } }
false;public,synchronized;3;111;;public synchronized IndexShard createShard(final ShardRouting routing, final Consumer<ShardId> globalCheckpointSyncer, final RetentionLeaseSyncer retentionLeaseSyncer) throws IOException {     Objects.requireNonNull(retentionLeaseSyncer).     /*          * TODO: we execute this in parallel but it's a synced method. Yet, we might          * be able to serialize the execution via the cluster state in the future. for now we just          * keep it synced.          */     if (closed.get()) {         throw new IllegalStateException("Can't create shard " + routing.shardId() + ", closed").     }     final Settings indexSettings = this.indexSettings.getSettings().     final ShardId shardId = routing.shardId().     boolean success = false.     Store store = null.     IndexShard indexShard = null.     ShardLock lock = null.     try {         lock = nodeEnv.shardLock(shardId, "shard creation", TimeUnit.SECONDS.toMillis(5)).         eventListener.beforeIndexShardCreated(shardId, indexSettings).         ShardPath path.         try {             path = ShardPath.loadShardPath(logger, nodeEnv, shardId, this.indexSettings).         } catch (IllegalStateException ex) {             logger.warn("{} failed to load shard path, trying to remove leftover", shardId).             try {                 ShardPath.deleteLeftoverShardDirectory(logger, nodeEnv, lock, this.indexSettings).                 path = ShardPath.loadShardPath(logger, nodeEnv, shardId, this.indexSettings).             } catch (Exception inner) {                 ex.addSuppressed(inner).                 throw ex.             }         }         if (path == null) {             // TODO: we should, instead, hold a "bytes reserved" of how large we anticipate this shard will be, e.g. for a shard             // that's being relocated/replicated we know how large it will become once it's done copying:             // Count up how many shards are currently on each data path:             Map<Path, Integer> dataPathToShardCount = new HashMap<>().             for (IndexShard shard : this) {                 Path dataPath = shard.shardPath().getRootStatePath().                 Integer curCount = dataPathToShardCount.get(dataPath).                 if (curCount == null) {                     curCount = 0.                 }                 dataPathToShardCount.put(dataPath, curCount + 1).             }             path = ShardPath.selectNewPathForShard(nodeEnv, shardId, this.indexSettings, routing.getExpectedShardSize() == ShardRouting.UNAVAILABLE_EXPECTED_SHARD_SIZE ? getAvgShardSizeInBytes() : routing.getExpectedShardSize(), dataPathToShardCount).             logger.debug("{} creating using a new path [{}]", shardId, path).         } else {             logger.debug("{} creating using an existing path [{}]", shardId, path).         }         if (shards.containsKey(shardId.id())) {             throw new IllegalStateException(shardId + " already exists").         }         logger.debug("creating shard_id {}", shardId).         // if we are on a shared FS we only own the shard (ie. we can safely delete it) if we are the primary.         final Engine.Warmer engineWarmer = (searcher) -> {             IndexShard shard = getShardOrNull(shardId.getId()).             if (shard != null) {                 warmer.warm(searcher, shard, IndexService.this.indexSettings).             }         }.         // TODO we can remove either IndexStore or DirectoryService. All we need is a simple Supplier<Directory>         DirectoryService directoryService = indexStore.newDirectoryService(path).         store = new Store(shardId, this.indexSettings, directoryService.newDirectory(), lock, new StoreCloseListener(shardId, () -> eventListener.onStoreClosed(shardId))).         eventListener.onStoreCreated(shardId).         indexShard = new IndexShard(routing, this.indexSettings, path, store, indexSortSupplier, indexCache, mapperService, similarityService, engineFactory, eventListener, searcherWrapper, threadPool, bigArrays, engineWarmer, searchOperationListeners, indexingOperationListeners, () -> globalCheckpointSyncer.accept(shardId), retentionLeaseSyncer, circuitBreakerService).         eventListener.indexShardStateChanged(indexShard, null, indexShard.state(), "shard created").         eventListener.afterIndexShardCreated(indexShard).         shards = newMapBuilder(shards).put(shardId.id(), indexShard).immutableMap().         success = true.         return indexShard.     } catch (ShardLockObtainFailedException e) {         throw new IOException("failed to obtain in-memory shard lock", e).     } finally {         if (success == false) {             if (lock != null) {                 IOUtils.closeWhileHandlingException(lock).             }             closeShard("initialization failed", shardId, indexShard, store, eventListener).         }     } }
false;public,synchronized;2;14;;@Override public synchronized void removeShard(int shardId, String reason) {     final ShardId sId = new ShardId(index(), shardId).     final IndexShard indexShard.     if (shards.containsKey(shardId) == false) {         return.     }     logger.debug("[{}] closing... (reason: [{}])", shardId, reason).     HashMap<Integer, IndexShard> newShards = new HashMap<>(shards).     indexShard = newShards.remove(shardId).     shards = unmodifiableMap(newShards).     closeShard(reason, sId, indexShard, indexShard.store(), indexShard.getIndexEventListener()).     logger.debug("[{}] closed (reason: [{}])", shardId, reason). }
false;private;5;36;;private void closeShard(String reason, ShardId sId, IndexShard indexShard, Store store, IndexEventListener listener) {     final int shardId = sId.id().     final Settings indexSettings = this.getIndexSettings().getSettings().     try {         try {             listener.beforeIndexShardClosed(sId, indexShard, indexSettings).         } finally {             // and close the shard so no operations are allowed to it             if (indexShard != null) {                 try {                     // only flush we are we closed (closed index or shutdown) and if we are not deleted                     final boolean flushEngine = deleted.get() == false && closed.get().                     indexShard.close(reason, flushEngine).                 } catch (Exception e) {                     logger.debug(() -> new ParameterizedMessage("[{}] failed to close index shard", shardId), e).                 // ignore                 }             }             // call this before we close the store, so we can release resources for it             listener.afterIndexShardClosed(sId, indexShard, indexSettings).         }     } finally {         try {             if (store != null) {                 store.close().             } else {                 logger.trace("[{}] store not initialized prior to closing shard, nothing to close", shardId).             }         } catch (Exception e) {             logger.warn(() -> new ParameterizedMessage("[{}] failed to close store on shard removal (reason: [{}])", shardId, reason), e).         }     } }
false;private;1;17;;private void onShardClose(ShardLock lock) {     if (deleted.get()) {         // we remove that shards content if this index has been deleted         try {             try {                 eventListener.beforeIndexShardDeleted(lock.getShardId(), indexSettings.getSettings()).             } finally {                 shardStoreDeleter.deleteShardStore("delete index", lock, indexSettings).                 eventListener.afterIndexShardDeleted(lock.getShardId(), indexSettings.getSettings()).             }         } catch (IOException e) {             shardStoreDeleter.addPendingDelete(lock.getShardId(), indexSettings).             logger.debug(() -> new ParameterizedMessage("[{}] failed to delete shard content - scheduled a retry", lock.getShardId().id()), e).         }     } }
false;public;0;4;;@Override public IndexSettings getIndexSettings() {     return indexSettings. }
true;public;4;7;/**  * Creates a new QueryShardContext. The context has not types set yet, if types are required set them via  * {@link QueryShardContext#setTypes(String...)}.  *  * Passing a {@code null} {@link IndexReader} will return a valid context, however it won't be able to make  * {@link IndexReader}-specific optimizations, such as rewriting containing range queries.  */ ;/**  * Creates a new QueryShardContext. The context has not types set yet, if types are required set them via  * {@link QueryShardContext#setTypes(String...)}.  *  * Passing a {@code null} {@link IndexReader} will return a valid context, however it won't be able to make  * {@link IndexReader}-specific optimizations, such as rewriting containing range queries.  */ public QueryShardContext newQueryShardContext(int shardId, IndexReader indexReader, LongSupplier nowInMillis, String clusterAlias) {     return new QueryShardContext(shardId, indexSettings, indexCache.bitsetFilterCache(), indexFieldData::getForField, mapperService(), similarityService(), scriptService, xContentRegistry, namedWriteableRegistry, client, indexReader, nowInMillis, clusterAlias). }
true;public;0;3;/**  * The {@link ThreadPool} to use for this index.  */ ;/**  * The {@link ThreadPool} to use for this index.  */ public ThreadPool getThreadPool() {     return threadPool. }
true;public;0;3;/**  * The {@link BigArrays} to use for this index.  */ ;/**  * The {@link BigArrays} to use for this index.  */ public BigArrays getBigArrays() {     return bigArrays. }
true;public;0;3;/**  * The {@link ScriptService} to use for this index.  */ ;/**  * The {@link ScriptService} to use for this index.  */ public ScriptService getScriptService() {     return scriptService. }
false;;0;3;;List<IndexingOperationListener> getIndexOperationListeners() {     // pkg private for testing     return indexingOperationListeners. }
false;;0;3;;List<SearchOperationListener> getSearchOperationListener() {     // pkg private for testing     return searchOperationListeners. }
false;public;2;4;;@Override public boolean updateMapping(final IndexMetaData currentIndexMetaData, final IndexMetaData newIndexMetaData) throws IOException {     return mapperService().updateMapping(currentIndexMetaData, newIndexMetaData). }
false;public;1;14;;@Override public void accept(ShardLock lock) {     try {         assert lock.getShardId().equals(shardId) : "shard id mismatch, expected: " + shardId + " but got: " + lock.getShardId().         onShardClose(lock).     } finally {         try {             IOUtils.close(toClose).         } catch (IOException ex) {             logger.debug("failed to close resource", ex).         }     } }
false;public;2;10;;@Override public void onCache(ShardId shardId, Accountable accountable) {     if (shardId != null) {         final IndexShard shard = indexService.getShardOrNull(shardId.id()).         if (shard != null) {             long ramBytesUsed = accountable != null ? accountable.ramBytesUsed() : 0L.             shard.shardBitsetFilterCache().onCached(ramBytesUsed).         }     } }
false;public;2;10;;@Override public void onRemoval(ShardId shardId, Accountable accountable) {     if (shardId != null) {         final IndexShard shard = indexService.getShardOrNull(shardId.id()).         if (shard != null) {             long ramBytesUsed = accountable != null ? accountable.ramBytesUsed() : 0L.             shard.shardBitsetFilterCache().onRemoval(ramBytesUsed).         }     } }
false;public;3;9;;@Override public void onCache(ShardId shardId, String fieldName, Accountable ramUsage) {     if (shardId != null) {         final IndexShard shard = indexService.getShardOrNull(shardId.id()).         if (shard != null) {             shard.fieldData().onCache(shardId, fieldName, ramUsage).         }     } }
false;public;4;9;;@Override public void onRemoval(ShardId shardId, String fieldName, boolean wasEvicted, long sizeInBytes) {     if (shardId != null) {         final IndexShard shard = indexService.getShardOrNull(shardId.id()).         if (shard != null) {             shard.fieldData().onRemoval(shardId, fieldName, wasEvicted, sizeInBytes).         }     } }
false;public;0;3;;public IndexMetaData getMetaData() {     return indexSettings.getIndexMetaData(). }
false;public;1;4;;@Override public void onFailure(Exception e) {     logger.warn("forced refresh failed after interval change", e). }
false;protected;0;4;;@Override protected void doRun() throws Exception {     maybeRefreshEngine(true). }
false;public;0;4;;@Override public boolean isForceExecution() {     return true. }
false;public,synchronized;2;61;;@Override public synchronized void updateMetaData(final IndexMetaData currentIndexMetaData, final IndexMetaData newIndexMetaData) {     final Translog.Durability oldTranslogDurability = indexSettings.getTranslogDurability().     final boolean updateIndexMetaData = indexSettings.updateIndexMetaData(newIndexMetaData).     if (Assertions.ENABLED && currentIndexMetaData != null && currentIndexMetaData.getCreationVersion().onOrAfter(Version.V_6_5_0)) {         final long currentSettingsVersion = currentIndexMetaData.getSettingsVersion().         final long newSettingsVersion = newIndexMetaData.getSettingsVersion().         if (currentSettingsVersion == newSettingsVersion) {             assert updateIndexMetaData == false.         } else {             assert updateIndexMetaData.             assert currentSettingsVersion < newSettingsVersion : "expected current settings version [" + currentSettingsVersion + "] " + "to be less than new settings version [" + newSettingsVersion + "]".         }     }     if (updateIndexMetaData) {         for (final IndexShard shard : this.shards.values()) {             try {                 shard.onSettingsChanged().             } catch (Exception e) {                 logger.warn(() -> new ParameterizedMessage("[{}] failed to notify shard about setting change", shard.shardId().id()), e).             }         }         if (refreshTask.getInterval().equals(indexSettings.getRefreshInterval()) == false) {             // once we change the refresh interval we schedule yet another refresh             // to ensure we are in a clean and predictable state.             // it doesn't matter if we move from or to <code>-1</code>  in both cases we want             // docs to become visible immediately. This also flushes all pending indexing / search requests             // that are waiting for a refresh.             threadPool.executor(ThreadPool.Names.REFRESH).execute(new AbstractRunnable() {                  @Override                 public void onFailure(Exception e) {                     logger.warn("forced refresh failed after interval change", e).                 }                  @Override                 protected void doRun() throws Exception {                     maybeRefreshEngine(true).                 }                  @Override                 public boolean isForceExecution() {                     return true.                 }             }).             rescheduleRefreshTasks().         }         final Translog.Durability durability = indexSettings.getTranslogDurability().         if (durability != oldTranslogDurability) {             rescheduleFsyncTask(durability).         }     } }
false;private;1;9;;private void rescheduleFsyncTask(Translog.Durability durability) {     try {         if (fsyncTask != null) {             fsyncTask.close().         }     } finally {         fsyncTask = durability == Translog.Durability.REQUEST ? null : new AsyncTranslogFSync(this).     } }
false;private;0;7;;private void rescheduleRefreshTasks() {     try {         refreshTask.close().     } finally {         refreshTask = new AsyncRefreshTask(this).     } }
false;;3;1;;void deleteShardStore(String reason, ShardLock lock, IndexSettings indexSettings) throws IOException.
false;;2;1;;void addPendingDelete(ShardId shardId, IndexSettings indexSettings).
false;public,final;0;3;;public final EngineFactory getEngineFactory() {     return engineFactory. }
false;final;0;3;;final IndexSearcherWrapper getSearcherWrapper() {     return searcherWrapper. }
false;final;0;3;;// pkg private for testing final IndexStore getIndexStore() {     return indexStore. }
false;private;0;15;;// pkg private for testing private void maybeFSyncTranslogs() {     if (indexSettings.getTranslogDurability() == Translog.Durability.ASYNC) {         for (IndexShard shard : this.shards.values()) {             try {                 if (shard.isSyncNeeded()) {                     shard.sync().                 }             } catch (AlreadyClosedException ex) {             // fine - continue.             } catch (IOException e) {                 logger.warn("failed to sync translog", e).             }         }     } }
false;private;1;11;;private void maybeRefreshEngine(boolean force) {     if (indexSettings.getRefreshInterval().millis() > 0 || force) {         for (IndexShard shard : this.shards.values()) {             try {                 shard.scheduledRefresh().             } catch (IndexShardClosedException | AlreadyClosedException ex) {             // fine - continue.             }         }     } }
false;private;0;20;;private void maybeTrimTranslog() {     for (IndexShard shard : this.shards.values()) {         switch(shard.state()) {             case CREATED:             case RECOVERING:             case CLOSED:                 continue.             case POST_RECOVERY:             case STARTED:                 try {                     shard.trimTranslog().                 } catch (IndexShardClosedException | AlreadyClosedException ex) {                 // fine - continue.                 }                 continue.             default:                 throw new IllegalStateException("unknown state: " + shard.state()).         }     } }
false;private;0;3;;private void maybeSyncGlobalCheckpoints() {     sync(is -> is.maybeSyncGlobalCheckpoint("background"), "global checkpoint"). }
false;private;0;3;;private void syncRetentionLeases() {     sync(IndexShard::syncRetentionLeases, "retention lease"). }
false;private;2;35;;private void sync(final Consumer<IndexShard> sync, final String source) {     for (final IndexShard shard : this.shards.values()) {         if (shard.routingEntry().active() && shard.routingEntry().primary()) {             switch(shard.state()) {                 case CLOSED:                 case CREATED:                 case RECOVERING:                     continue.                 case POST_RECOVERY:                     assert false : "shard " + shard.shardId() + " is in post-recovery but marked as active".                     continue.                 case STARTED:                     try {                         shard.runUnderPrimaryPermit(() -> sync.accept(shard), e -> {                             if (e instanceof AlreadyClosedException == false && e instanceof IndexShardClosedException == false) {                                 logger.warn(new ParameterizedMessage("{} failed to execute {} sync", shard.shardId(), source), e).                             }                         }, ThreadPool.Names.SAME, source + " sync").                     } catch (final AlreadyClosedException | IndexShardClosedException e) {                     // the shard was closed concurrently, continue                     }                     continue.                 default:                     throw new IllegalStateException("unknown state [" + shard.state() + "]").             }         }     } }
false;protected;0;6;;@Override protected boolean mustReschedule() {     // don't re-schedule if the IndexService instance is closed or if the index is closed     return indexService.closed.get() == false && indexService.indexSettings.getIndexMetaData().getState() == IndexMetaData.State.OPEN. }
false;protected;0;4;;@Override protected String getThreadPool() {     return ThreadPool.Names.FLUSH. }
false;protected;0;4;;@Override protected void runInternal() {     indexService.maybeFSyncTranslogs(). }
false;public;0;4;;@Override public String toString() {     return "translog_sync". }
false;protected;0;4;;@Override protected void runInternal() {     indexService.maybeRefreshEngine(false). }
false;protected;0;4;;@Override protected String getThreadPool() {     return ThreadPool.Names.REFRESH. }
false;public;0;4;;@Override public String toString() {     return "refresh". }
false;protected;0;4;;@Override protected void runInternal() {     indexService.maybeTrimTranslog(). }
false;protected;0;4;;@Override protected String getThreadPool() {     return ThreadPool.Names.GENERIC. }
false;public;0;4;;@Override public String toString() {     return "trim_translog". }
false;protected;0;4;;@Override protected void runInternal() {     indexService.maybeSyncGlobalCheckpoints(). }
false;protected;0;4;;@Override protected String getThreadPool() {     return ThreadPool.Names.GENERIC. }
false;public;0;4;;@Override public String toString() {     return "global_checkpoint_sync". }
false;protected;0;4;;@Override protected void runInternal() {     indexService.syncRetentionLeases(). }
false;protected;0;4;;@Override protected String getThreadPool() {     return ThreadPool.Names.MANAGEMENT. }
false;public;0;4;;@Override public String toString() {     return "retention_lease_sync". }
false;;0;3;;AsyncRefreshTask getRefreshTask() {     // for tests     return refreshTask. }
false;;0;3;;AsyncTranslogFSync getFsyncTask() {     // for tests     return fsyncTask. }
false;;0;3;;AsyncGlobalCheckpointTask getGlobalCheckpointTask() {     return globalCheckpointTask. }
true;public;3;29;/**  * Clears the caches for the given shard id if the shard is still allocated on this node  */ ;/**  * Clears the caches for the given shard id if the shard is still allocated on this node  */ public boolean clearCaches(boolean queryCache, boolean fieldDataCache, String... fields) {     boolean clearedAtLeastOne = false.     if (queryCache) {         clearedAtLeastOne = true.         indexCache.query().clear("api").     }     if (fieldDataCache) {         clearedAtLeastOne = true.         if (fields.length == 0) {             indexFieldData.clear().         } else {             for (String field : fields) {                 indexFieldData.clearField(field).             }         }     }     if (clearedAtLeastOne == false) {         if (fields.length == 0) {             indexCache.clear("api").             indexFieldData.clear().         } else {             // only clear caches relating to the specified fields             for (String field : fields) {                 indexFieldData.clearField(field).             }         }     }     return clearedAtLeastOne. }
