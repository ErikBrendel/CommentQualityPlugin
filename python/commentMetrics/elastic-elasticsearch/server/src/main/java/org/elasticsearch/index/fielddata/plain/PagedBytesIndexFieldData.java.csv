commented;modifiers;parameterAmount;loc;comment;code
false;public;5;6;;@Override public IndexOrdinalsFieldData build(IndexSettings indexSettings, MappedFieldType fieldType, IndexFieldDataCache cache, CircuitBreakerService breakerService, MapperService mapperService) {     return new PagedBytesIndexFieldData(indexSettings, fieldType.name(), cache, breakerService, minFrequency, maxFrequency, minSegmentSize). }
false;public;4;6;;@Override public SortField sortField(@Nullable Object missingValue, MultiValueMode sortMode, XFieldComparatorSource.Nested nested, boolean reverse) {     XFieldComparatorSource source = new BytesRefFieldComparatorSource(this, missingValue, sortMode, nested).     return new SortField(getFieldName(), source, reverse). }
false;public;1;54;;@Override public AtomicOrdinalsFieldData loadDirect(LeafReaderContext context) throws Exception {     LeafReader reader = context.reader().     AtomicOrdinalsFieldData data = null.     PagedBytesEstimator estimator = new PagedBytesEstimator(context, breakerService.getBreaker(CircuitBreaker.FIELDDATA), getFieldName()).     Terms terms = reader.terms(getFieldName()).     if (terms == null) {         data = AbstractAtomicOrdinalsFieldData.empty().         estimator.afterLoad(null, data.ramBytesUsed()).         return data.     }     final PagedBytes bytes = new PagedBytes(15).     final PackedLongValues.Builder termOrdToBytesOffset = PackedLongValues.monotonicBuilder(PackedInts.COMPACT).     final float acceptableTransientOverheadRatio = OrdinalsBuilder.DEFAULT_ACCEPTABLE_OVERHEAD_RATIO.     // Wrap the context in an estimator and use it to either estimate     // the entire set, or wrap the TermsEnum so it can be calculated     // per-term     TermsEnum termsEnum = estimator.beforeLoad(terms).     boolean success = false.     try (OrdinalsBuilder builder = new OrdinalsBuilder(reader.maxDoc(), acceptableTransientOverheadRatio)) {         PostingsEnum docsEnum = null.         for (BytesRef term = termsEnum.next(). term != null. term = termsEnum.next()) {             final long termOrd = builder.nextOrdinal().             assert termOrd == termOrdToBytesOffset.size().             termOrdToBytesOffset.add(bytes.copyUsingLengthPrefix(term)).             docsEnum = termsEnum.postings(docsEnum, PostingsEnum.NONE).             for (int docId = docsEnum.nextDoc(). docId != DocIdSetIterator.NO_MORE_DOCS. docId = docsEnum.nextDoc()) {                 builder.addDoc(docId).             }         }         PagedBytes.Reader bytesReader = bytes.freeze(true).         final Ordinals ordinals = builder.build().         data = new PagedBytesAtomicFieldData(bytesReader, termOrdToBytesOffset.build(), ordinals).         success = true.         return data.     } finally {         if (!success) {             // If something went wrong, unwind any current estimations we've made             estimator.afterLoad(termsEnum, 0).         } else {             // Call .afterLoad() to adjust the breaker now that we have an exact size             estimator.afterLoad(termsEnum, data.ramBytesUsed()).         }     } }
true;public;1;12;/**  * @return the number of bytes for the term based on the length and ordinal overhead  */ ;/**  * @return the number of bytes for the term based on the length and ordinal overhead  */ @Override public long bytesPerValue(BytesRef term) {     if (term == null) {         return 0.     }     long bytes = term.length.     // 64 bytes for miscellaneous overhead     bytes += 64.     // Seems to be about a 1.5x compression per term/ord, plus 1 for some wiggle room     bytes = (long) ((double) bytes / 1.5) + 1.     return bytes. }
true;public;0;22;/**  * @return the estimate for loading the entire term set into field data, or 0 if unavailable  */ ;/**  * @return the estimate for loading the entire term set into field data, or 0 if unavailable  */ public long estimateStringFieldData() {     try {         LeafReader reader = context.reader().         Terms terms = reader.terms(getFieldName()).         final Terms fieldTerms = reader.terms(getFieldName()).         if (fieldTerms instanceof FieldReader) {             final Stats stats = ((FieldReader) fieldTerms).getStats().             long totalTermBytes = stats.totalTermBytes.             if (logger.isTraceEnabled()) {                 logger.trace("totalTermBytes: {}, terms.size(): {}, terms.getSumDocFreq(): {}", totalTermBytes, terms.size(), terms.getSumDocFreq()).             }             long totalBytes = totalTermBytes + (2 * terms.size()) + (4 * terms.getSumDocFreq()).             return totalBytes.         }     } catch (Exception e) {         logger.warn("Unable to estimate memory overhead", e).     }     return 0. }
true;public;1;26;/**  * Determine whether the BlockTreeTermsReader.FieldReader can be used  * for estimating the field data, adding the estimate to the circuit  * breaker if it can, otherwise wrapping the terms in a  * RamAccountingTermsEnum to be estimated on a per-term basis.  *  * @param terms terms to be estimated  * @return A possibly wrapped TermsEnum for the terms  */ ;/**  * Determine whether the BlockTreeTermsReader.FieldReader can be used  * for estimating the field data, adding the estimate to the circuit  * breaker if it can, otherwise wrapping the terms in a  * RamAccountingTermsEnum to be estimated on a per-term basis.  *  * @param terms terms to be estimated  * @return A possibly wrapped TermsEnum for the terms  */ @Override public TermsEnum beforeLoad(Terms terms) throws IOException {     LeafReader reader = context.reader().     TermsEnum iterator = terms.iterator().     TermsEnum filteredIterator = filter(terms, iterator, reader).     final boolean filtered = iterator != filteredIterator.     iterator = filteredIterator.     if (filtered) {         if (logger.isTraceEnabled()) {             logger.trace("Filter exists, can't circuit break normally, using RamAccountingTermsEnum").         }         return new RamAccountingTermsEnum(iterator, breaker, this, this.fieldName).     } else {         estimatedBytes = this.estimateStringFieldData().         // If we weren't able to estimate, wrap in the RamAccountingTermsEnum         if (estimatedBytes == 0) {             iterator = new RamAccountingTermsEnum(iterator, breaker, this, this.fieldName).         } else {             breaker.addEstimateBytesAndMaybeBreak(estimatedBytes, fieldName).         }         return iterator.     } }
true;public;2;7;/**  * Adjust the circuit breaker now that terms have been loaded, getting  * the actual used either from the parameter (if estimation worked for  * the entire set), or from the TermsEnum if it has been wrapped in a  * RamAccountingTermsEnum.  *  * @param termsEnum  terms that were loaded  * @param actualUsed actual field data memory usage  */ ;/**  * Adjust the circuit breaker now that terms have been loaded, getting  * the actual used either from the parameter (if estimation worked for  * the entire set), or from the TermsEnum if it has been wrapped in a  * RamAccountingTermsEnum.  *  * @param termsEnum  terms that were loaded  * @param actualUsed actual field data memory usage  */ @Override public void afterLoad(TermsEnum termsEnum, long actualUsed) {     if (termsEnum instanceof RamAccountingTermsEnum) {         estimatedBytes = ((RamAccountingTermsEnum) termsEnum).getTotalBytes().     }     breaker.addWithoutBreaking(-(estimatedBytes - actualUsed)). }
