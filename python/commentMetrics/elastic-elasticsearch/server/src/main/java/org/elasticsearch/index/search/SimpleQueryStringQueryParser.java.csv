commented;modifiers;parameterAmount;loc;comment;code
false;private;1;6;;private Analyzer getAnalyzer(MappedFieldType ft) {     if (getAnalyzer() != null) {         return analyzer.     }     return ft.searchAnalyzer(). }
true;private;1;6;/**  * Rethrow the runtime exception, unless the lenient flag has been set, returns {@link MatchNoDocsQuery}  */ ;/**  * Rethrow the runtime exception, unless the lenient flag has been set, returns {@link MatchNoDocsQuery}  */ private Query rethrowUnlessLenient(RuntimeException e) {     if (settings.lenient()) {         return Queries.newMatchNoDocsQuery("failed query, caused by " + e.getMessage()).     }     throw e. }
false;public;1;5;;@Override public void setDefaultOperator(BooleanClause.Occur operator) {     super.setDefaultOperator(operator).     queryBuilder.setOccur(operator). }
false;protected;1;8;;@Override protected Query newTermQuery(Term term) {     MappedFieldType ft = context.fieldMapper(term.field()).     if (ft == null) {         return newUnmappedFieldQuery(term.field()).     }     return ft.termQuery(term.bytes(), context). }
false;public;1;8;;@Override public Query newDefaultQuery(String text) {     try {         return queryBuilder.parse(MultiMatchQueryBuilder.Type.MOST_FIELDS, weights, text, null).     } catch (IOException e) {         return rethrowUnlessLenient(new IllegalStateException(e.getMessage())).     } }
false;public;2;24;;@Override public Query newFuzzyQuery(String text, int fuzziness) {     List<Query> disjuncts = new ArrayList<>().     for (Map.Entry<String, Float> entry : weights.entrySet()) {         final String fieldName = entry.getKey().         final MappedFieldType ft = context.fieldMapper(fieldName).         if (ft == null) {             disjuncts.add(newUnmappedFieldQuery(fieldName)).             continue.         }         try {             final BytesRef term = getAnalyzer(ft).normalize(fieldName, text).             Query query = ft.fuzzyQuery(term, Fuzziness.fromEdits(fuzziness), settings.fuzzyPrefixLength, settings.fuzzyMaxExpansions, settings.fuzzyTranspositions).             disjuncts.add(wrapWithBoost(query, entry.getValue())).         } catch (RuntimeException e) {             disjuncts.add(rethrowUnlessLenient(e)).         }     }     if (disjuncts.size() == 1) {         return disjuncts.get(0).     }     return new DisjunctionMaxQuery(disjuncts, 1.0f). }
false;public;2;17;;@Override public Query newPhraseQuery(String text, int slop) {     try {         queryBuilder.setPhraseSlop(slop).         Map<String, Float> phraseWeights.         if (settings.quoteFieldSuffix() != null) {             phraseWeights = QueryParserHelper.resolveMappingFields(context, weights, settings.quoteFieldSuffix()).         } else {             phraseWeights = weights.         }         return queryBuilder.parse(MultiMatchQueryBuilder.Type.PHRASE, phraseWeights, text, null).     } catch (IOException e) {         return rethrowUnlessLenient(new IllegalStateException(e.getMessage())).     } finally {         queryBuilder.setPhraseSlop(0).     } }
false;public;1;30;;@Override public Query newPrefixQuery(String text) {     List<Query> disjuncts = new ArrayList<>().     for (Map.Entry<String, Float> entry : weights.entrySet()) {         final String fieldName = entry.getKey().         final MappedFieldType ft = context.fieldMapper(fieldName).         if (ft == null) {             disjuncts.add(newUnmappedFieldQuery(fieldName)).             continue.         }         try {             if (settings.analyzeWildcard()) {                 Query analyzedQuery = newPossiblyAnalyzedQuery(fieldName, text, getAnalyzer(ft)).                 if (analyzedQuery != null) {                     disjuncts.add(wrapWithBoost(analyzedQuery, entry.getValue())).                 }             } else {                 BytesRef term = getAnalyzer(ft).normalize(fieldName, text).                 Query query = ft.prefixQuery(term.utf8ToString(), null, context).                 disjuncts.add(wrapWithBoost(query, entry.getValue())).             }         } catch (RuntimeException e) {             disjuncts.add(rethrowUnlessLenient(e)).         }     }     if (disjuncts.size() == 1) {         return disjuncts.get(0).     }     return new DisjunctionMaxQuery(disjuncts, 1.0f). }
false;private,static;2;9;;private static Query wrapWithBoost(Query query, float boost) {     if (query instanceof MatchNoDocsQuery) {         return query.     }     if (boost != AbstractQueryBuilder.DEFAULT_BOOST) {         return new BoostQuery(query, boost).     }     return query. }
true;private;3;70;/**  * Analyze the given string using its analyzer, constructing either a  * {@code PrefixQuery} or a {@code BooleanQuery} made up  * of {@code TermQuery}s and {@code PrefixQuery}s  */ ;/**  * Analyze the given string using its analyzer, constructing either a  * {@code PrefixQuery} or a {@code BooleanQuery} made up  * of {@code TermQuery}s and {@code PrefixQuery}s  */ private Query newPossiblyAnalyzedQuery(String field, String termStr, Analyzer analyzer) {     List<List<BytesRef>> tlist = new ArrayList<>().     try (TokenStream source = analyzer.tokenStream(field, termStr)) {         source.reset().         List<BytesRef> currentPos = new ArrayList<>().         CharTermAttribute termAtt = source.addAttribute(CharTermAttribute.class).         PositionIncrementAttribute posAtt = source.addAttribute(PositionIncrementAttribute.class).         try {             boolean hasMoreTokens = source.incrementToken().             while (hasMoreTokens) {                 if (currentPos.isEmpty() == false && posAtt.getPositionIncrement() > 0) {                     tlist.add(currentPos).                     currentPos = new ArrayList<>().                 }                 final BytesRef term = analyzer.normalize(field, termAtt.toString()).                 currentPos.add(term).                 hasMoreTokens = source.incrementToken().             }             if (currentPos.isEmpty() == false) {                 tlist.add(currentPos).             }         } catch (IOException e) {         // ignore         // TODO: we should not ignore the exception and return a prefix query with the original term ?         }     } catch (IOException e) {         // Bail on any exceptions, going with a regular prefix query         return new PrefixQuery(new Term(field, termStr)).     }     if (tlist.size() == 0) {         return null.     }     if (tlist.size() == 1 && tlist.get(0).size() == 1) {         return new PrefixQuery(new Term(field, tlist.get(0).get(0))).     }     // build a boolean query with prefix on the last position only.     BooleanQuery.Builder builder = new BooleanQuery.Builder().     for (int pos = 0. pos < tlist.size(). pos++) {         List<BytesRef> plist = tlist.get(pos).         boolean isLastPos = (pos == tlist.size() - 1).         Query posQuery.         if (plist.size() == 1) {             if (isLastPos) {                 posQuery = new PrefixQuery(new Term(field, plist.get(0))).             } else {                 posQuery = newTermQuery(new Term(field, plist.get(0))).             }         } else if (isLastPos == false) {             // build a synonym query for terms in the same position.             Term[] terms = new Term[plist.size()].             for (int i = 0. i < plist.size(). i++) {                 terms[i] = new Term(field, plist.get(i)).             }             posQuery = new SynonymQuery(terms).         } else {             BooleanQuery.Builder innerBuilder = new BooleanQuery.Builder().             for (BytesRef token : plist) {                 innerBuilder.add(new BooleanClause(new PrefixQuery(new Term(field, token)), BooleanClause.Occur.SHOULD)).             }             posQuery = innerBuilder.build().         }         builder.add(new BooleanClause(posQuery, getDefaultOperator())).     }     return builder.build(). }
true;public;1;3;/**  * Specifies whether to use lenient parsing, defaults to false.  */ ;/**  * Specifies whether to use lenient parsing, defaults to false.  */ public void lenient(boolean lenient) {     this.lenient = lenient. }
true;public;0;3;/**  * Returns whether to use lenient parsing.  */ ;/**  * Returns whether to use lenient parsing.  */ public boolean lenient() {     return this.lenient. }
true;public;1;3;/**  * Specifies whether to analyze wildcards. Defaults to false if unset.  */ ;/**  * Specifies whether to analyze wildcards. Defaults to false if unset.  */ public void analyzeWildcard(boolean analyzeWildcard) {     this.analyzeWildcard = analyzeWildcard. }
true;public;0;3;/**  * Returns whether to analyze wildcards.  */ ;/**  * Returns whether to analyze wildcards.  */ public boolean analyzeWildcard() {     return analyzeWildcard. }
true;public;1;3;/**  * Set the suffix to append to field names for phrase matching.  */ ;/**  * Set the suffix to append to field names for phrase matching.  */ public void quoteFieldSuffix(String suffix) {     this.quoteFieldSuffix = suffix. }
true;public;0;3;/**  * Return the suffix to append for phrase matching, or {@code null} if  * no suffix should be appended.  */ ;/**  * Return the suffix to append for phrase matching, or {@code null} if  * no suffix should be appended.  */ public String quoteFieldSuffix() {     return quoteFieldSuffix. }
false;public;1;3;;public void autoGenerateSynonymsPhraseQuery(boolean value) {     this.autoGenerateSynonymsPhraseQuery = value. }
true;public;0;3;/**  * Whether phrase queries should be automatically generated for multi terms synonyms.  * Defaults to {@code true}.  */ ;/**  * Whether phrase queries should be automatically generated for multi terms synonyms.  * Defaults to {@code true}.  */ public boolean autoGenerateSynonymsPhraseQuery() {     return autoGenerateSynonymsPhraseQuery. }
false;public;0;3;;public int fuzzyPrefixLength() {     return fuzzyPrefixLength. }
false;public;1;3;;public void fuzzyPrefixLength(int fuzzyPrefixLength) {     this.fuzzyPrefixLength = fuzzyPrefixLength. }
false;public;0;3;;public int fuzzyMaxExpansions() {     return fuzzyMaxExpansions. }
false;public;1;3;;public void fuzzyMaxExpansions(int fuzzyMaxExpansions) {     this.fuzzyMaxExpansions = fuzzyMaxExpansions. }
false;public;0;3;;public boolean fuzzyTranspositions() {     return fuzzyTranspositions. }
false;public;1;3;;public void fuzzyTranspositions(boolean fuzzyTranspositions) {     this.fuzzyTranspositions = fuzzyTranspositions. }
false;public;0;5;;@Override public int hashCode() {     return Objects.hash(lenient, analyzeWildcard, quoteFieldSuffix, autoGenerateSynonymsPhraseQuery, fuzzyPrefixLength, fuzzyMaxExpansions, fuzzyTranspositions). }
false;public;1;17;;@Override public boolean equals(Object obj) {     if (this == obj) {         return true.     }     if (obj == null || getClass() != obj.getClass()) {         return false.     }     Settings other = (Settings) obj.     return Objects.equals(lenient, other.lenient) && Objects.equals(analyzeWildcard, other.analyzeWildcard) && Objects.equals(quoteFieldSuffix, other.quoteFieldSuffix) && Objects.equals(autoGenerateSynonymsPhraseQuery, other.autoGenerateSynonymsPhraseQuery) && Objects.equals(fuzzyPrefixLength, other.fuzzyPrefixLength) && Objects.equals(fuzzyMaxExpansions, other.fuzzyMaxExpansions) && Objects.equals(fuzzyTranspositions, other.fuzzyTranspositions). }
