commented;modifiers;parameterAmount;loc;comment;code
false;protected;0;64;;@Override protected MatchQueryBuilder doCreateTestQueryBuilder() {     String fieldName = randomFrom(STRING_FIELD_NAME, STRING_ALIAS_FIELD_NAME, BOOLEAN_FIELD_NAME, INT_FIELD_NAME, DOUBLE_FIELD_NAME, DATE_FIELD_NAME).     Object value.     if (isTextField(fieldName)) {         int terms = randomIntBetween(0, 3).         StringBuilder builder = new StringBuilder().         for (int i = 0. i < terms. i++) {             builder.append(randomAlphaOfLengthBetween(1, 10)).append(" ").         }         value = builder.toString().trim().     } else {         value = getRandomValueForFieldName(fieldName).     }     MatchQueryBuilder matchQuery = new MatchQueryBuilder(fieldName, value).     matchQuery.operator(randomFrom(Operator.values())).     if (randomBoolean() && isTextField(fieldName)) {         matchQuery.analyzer(randomFrom("simple", "keyword", "whitespace")).     }     if (isTextField(fieldName) && randomBoolean()) {         matchQuery.fuzziness(randomFuzziness(fieldName)).     }     if (randomBoolean()) {         matchQuery.prefixLength(randomIntBetween(0, 10)).     }     if (randomBoolean()) {         matchQuery.maxExpansions(randomIntBetween(1, 1000)).     }     if (randomBoolean()) {         matchQuery.minimumShouldMatch(randomMinimumShouldMatch()).     }     if (randomBoolean()) {         matchQuery.fuzzyRewrite(getRandomRewriteMethod()).     }     if (randomBoolean()) {         matchQuery.fuzzyTranspositions(randomBoolean()).     }     if (randomBoolean()) {         matchQuery.lenient(randomBoolean()).     }     if (randomBoolean()) {         matchQuery.zeroTermsQuery(randomFrom(ZeroTermsQuery.ALL, ZeroTermsQuery.NONE)).     }     if (randomBoolean()) {         matchQuery.cutoffFrequency((float) 10 / randomIntBetween(1, 100)).     }     if (randomBoolean()) {         matchQuery.autoGenerateSynonymsPhraseQuery(randomBoolean()).     }     return matchQuery. }
false;protected;0;12;;@Override protected Map<String, MatchQueryBuilder> getAlternateVersions() {     Map<String, MatchQueryBuilder> alternateVersions = new HashMap<>().     MatchQueryBuilder matchQuery = new MatchQueryBuilder(randomAlphaOfLengthBetween(1, 10), randomAlphaOfLengthBetween(1, 10)).     String contentString = "{\n" + "    \"match\" : {\n" + "        \"" + matchQuery.fieldName() + "\" : \"" + matchQuery.value() + "\"\n" + "    }\n" + "}".     alternateVersions.put(contentString, matchQuery).     return alternateVersions. }
false;protected;3;74;;@Override protected void doAssertLuceneQuery(MatchQueryBuilder queryBuilder, Query query, SearchContext searchContext) throws IOException {     assertThat(query, notNullValue()).     if (query instanceof MatchAllDocsQuery) {         assertThat(queryBuilder.zeroTermsQuery(), equalTo(ZeroTermsQuery.ALL)).         return.     }     QueryShardContext context = searchContext.getQueryShardContext().     MappedFieldType fieldType = context.fieldMapper(queryBuilder.fieldName()).     if (query instanceof TermQuery && fieldType != null) {         String queryValue = queryBuilder.value().toString().         if (queryBuilder.analyzer() == null || queryBuilder.analyzer().equals("simple")) {             queryValue = queryValue.toLowerCase(Locale.ROOT).         }         Query expectedTermQuery = fieldType.termQuery(queryValue, context).         assertEquals(expectedTermQuery, query).     }     if (query instanceof BooleanQuery) {         BooleanQuery bq = (BooleanQuery) query.         if (queryBuilder.minimumShouldMatch() != null) {             // calculate expected minimumShouldMatch value             int optionalClauses = 0.             for (BooleanClause c : bq.clauses()) {                 if (c.getOccur() == BooleanClause.Occur.SHOULD) {                     optionalClauses++.                 }             }             int msm = Queries.calculateMinShouldMatch(optionalClauses, queryBuilder.minimumShouldMatch()).             assertThat(bq.getMinimumNumberShouldMatch(), equalTo(msm)).         }         if (queryBuilder.analyzer() == null && queryBuilder.value().toString().length() > 0) {             assertEquals(bq.clauses().size(), queryBuilder.value().toString().split(" ").length).         }     }     if (query instanceof ExtendedCommonTermsQuery) {         assertTrue(queryBuilder.cutoffFrequency() != null).         ExtendedCommonTermsQuery ectq = (ExtendedCommonTermsQuery) query.         List<Term> terms = ectq.getTerms().         if (!terms.isEmpty()) {             Term term = terms.iterator().next().             String expectedFieldName = expectedFieldName(queryBuilder.fieldName()).             assertThat(term.field(), equalTo(expectedFieldName)).         }         assertEquals(queryBuilder.cutoffFrequency(), ectq.getMaxTermFrequency(), Float.MIN_VALUE).     }     if (query instanceof FuzzyQuery) {         assertTrue(queryBuilder.fuzziness() != null).         FuzzyQuery fuzzyQuery = (FuzzyQuery) query.         // depending on analyzer being set or not we can have term lowercased along the way, so to simplify test we just         // compare lowercased terms here         String originalTermLc = queryBuilder.value().toString().toLowerCase(Locale.ROOT).         String actualTermLc = fuzzyQuery.getTerm().text().toLowerCase(Locale.ROOT).         Matcher<String> termLcMatcher = equalTo(originalTermLc).         if ("false".equals(originalTermLc) || "true".equals(originalTermLc)) {             // Booleans become t/f when querying a boolean field             termLcMatcher = either(termLcMatcher).or(equalTo(originalTermLc.substring(0, 1))).         }         assertThat(actualTermLc, termLcMatcher).         String expectedFieldName = expectedFieldName(queryBuilder.fieldName()).         assertThat(expectedFieldName, equalTo(fuzzyQuery.getTerm().field())).         assertThat(queryBuilder.prefixLength(), equalTo(fuzzyQuery.getPrefixLength())).         assertThat(queryBuilder.fuzzyTranspositions(), equalTo(fuzzyQuery.getTranspositions())).     }     if (query instanceof PointRangeQuery) {     // TODO     } }
false;public;0;39;;public void testIllegalValues() {     {         IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> new MatchQueryBuilder(null, "value")).         assertEquals("[match] requires fieldName", e.getMessage()).     }     {         IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> new MatchQueryBuilder("fieldName", null)).         assertEquals("[match] requires query value", e.getMessage()).     }     MatchQueryBuilder matchQuery = new MatchQueryBuilder("fieldName", "text").     {         IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> matchQuery.prefixLength(-1)).         assertEquals("[match] requires prefix length to be non-negative.", e.getMessage()).     }     {         IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> matchQuery.maxExpansions(randomIntBetween(-10, 0))).         assertEquals("[match] requires maxExpansions to be positive.", e.getMessage()).     }     {         IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> matchQuery.operator(null)).         assertEquals("[match] requires operator to be non-null", e.getMessage()).     }     {         IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> matchQuery.zeroTermsQuery(null)).         assertEquals("[match] requires zeroTermsQuery to be non-null", e.getMessage()).     }     matchQuery.analyzer("bogusAnalyzer").     {         QueryShardException e = expectThrows(QueryShardException.class, () -> matchQuery.toQuery(createShardContext())).         assertThat(e.getMessage(), containsString("analyzer [bogusAnalyzer] not found")).     } }
false;public;0;22;;public void testSimpleMatchQuery() throws IOException {     String json = "{\n" + "  \"match\" : {\n" + "    \"message\" : {\n" + "      \"query\" : \"to be or not to be\",\n" + "      \"operator\" : \"AND\",\n" + "      \"prefix_length\" : 0,\n" + "      \"max_expansions\" : 50,\n" + "      \"fuzzy_transpositions\" : true,\n" + "      \"lenient\" : false,\n" + "      \"zero_terms_query\" : \"ALL\",\n" + "      \"auto_generate_synonyms_phrase_query\" : true,\n" + "      \"boost\" : 1.0\n" + "    }\n" + "  }\n" + "}".     MatchQueryBuilder qb = (MatchQueryBuilder) parseQuery(json).     checkGeneratedJson(json, qb).     assertEquals(json, "to be or not to be", qb.value()).     assertEquals(json, Operator.AND, qb.operator()). }
false;public;0;19;;public void testFuzzinessOnNonStringField() throws Exception {     MatchQueryBuilder query = new MatchQueryBuilder(INT_FIELD_NAME, 42).     query.fuzziness(randomFuzziness(INT_FIELD_NAME)).     QueryShardContext context = createShardContext().     IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> query.toQuery(context)).     assertEquals("Can only use fuzzy queries on keyword and text fields - not on [mapped_int] which is of type [integer]", e.getMessage()).     // triggers a different code path     query.analyzer("keyword").     e = expectThrows(IllegalArgumentException.class, () -> query.toQuery(context)).     assertEquals("Can only use fuzzy queries on keyword and text fields - not on [mapped_int] which is of type [integer]", e.getMessage()).     query.lenient(true).     // no exception     query.toQuery(context).     query.analyzer(null).     // no exception     query.toQuery(context). }
false;public;0;8;;public void testExactOnUnsupportedField() throws Exception {     MatchQueryBuilder query = new MatchQueryBuilder(GEO_POINT_FIELD_NAME, "2,3").     QueryShardContext context = createShardContext().     QueryShardException e = expectThrows(QueryShardException.class, () -> query.toQuery(context)).     assertEquals("Geo fields do not support exact searching, use dedicated geo queries instead: [mapped_geo_point]", e.getMessage()).     query.lenient(true).     // no exception     query.toQuery(context). }
false;public;0;23;;public void testParseFailsWithMultipleFields() throws IOException {     String json = "{\n" + "  \"match\" : {\n" + "    \"message1\" : {\n" + "      \"query\" : \"this is a test\"\n" + "    },\n" + "    \"message2\" : {\n" + "      \"query\" : \"this is a test\"\n" + "    }\n" + "  }\n" + "}".     ParsingException e = expectThrows(ParsingException.class, () -> parseQuery(json)).     assertEquals("[match] query doesn't support multiple fields, found [message1] and [message2]", e.getMessage()).     String shortJson = "{\n" + "  \"match\" : {\n" + "    \"message1\" : \"this is a test\",\n" + "    \"message2\" : \"this is a test\"\n" + "  }\n" + "}".     e = expectThrows(ParsingException.class, () -> parseQuery(shortJson)).     assertEquals("[match] query doesn't support multiple fields, found [message1] and [message2]", e.getMessage()). }
false;public;0;17;;public void testParseFailsWithTermsArray() throws Exception {     String json1 = "{\n" + "  \"match\" : {\n" + "    \"message1\" : {\n" + "      \"query\" : [\"term1\", \"term2\"]\n" + "    }\n" + "  }\n" + "}".     expectThrows(ParsingException.class, () -> parseQuery(json1)).     String json2 = "{\n" + "  \"match\" : {\n" + "    \"message1\" : [\"term1\", \"term2\"]\n" + "  }\n" + "}".     expectThrows(IllegalStateException.class, () -> parseQuery(json2)). }
false;public;0;7;;public void testExceptionUsingAnalyzerOnNumericField() {     QueryShardContext shardContext = createShardContext().     MatchQueryBuilder matchQueryBuilder = new MatchQueryBuilder(DOUBLE_FIELD_NAME, 6.075210893508043E-4).     matchQueryBuilder.analyzer("simple").     NumberFormatException e = expectThrows(NumberFormatException.class, () -> matchQueryBuilder.toQuery(shardContext)).     assertEquals("For input string: \"e\"", e.getMessage()). }
false;protected;1;9;;@Override protected void initializeAdditionalMappings(MapperService mapperService) throws IOException {     mapperService.merge("_doc", new CompressedXContent(Strings.toString(PutMappingRequest.buildFromSimplifiedDef("_doc", "string_boost", "type=text,boost=4", "string_no_pos", "type=text,index_options=docs"))), MapperService.MergeReason.MAPPING_UPDATE). }
false;public;0;16;;public void testMatchPhrasePrefixWithBoost() throws Exception {     QueryShardContext context = createShardContext().     {         // field boost is ignored on a single term query         MatchPhrasePrefixQueryBuilder builder = new MatchPhrasePrefixQueryBuilder("string_boost", "foo").         Query query = builder.toQuery(context).         assertThat(query, instanceOf(MultiPhrasePrefixQuery.class)).     }     {         // field boost is ignored on phrase query         MatchPhrasePrefixQueryBuilder builder = new MatchPhrasePrefixQueryBuilder("string_boost", "foo bar").         Query query = builder.toQuery(context).         assertThat(query, instanceOf(MultiPhrasePrefixQuery.class)).     } }
false;public;0;9;;public void testLenientPhraseQuery() throws Exception {     QueryShardContext context = createShardContext().     MatchQuery b = new MatchQuery(context).     b.setLenient(true).     Query query = b.parse(Type.PHRASE, "string_no_pos", "foo bar").     assertThat(query, instanceOf(MatchNoDocsQuery.class)).     assertThat(query.toString(), containsString("field:[string_no_pos] was indexed without position data. cannot run PhraseQuery")). }
false;public;0;7;;public void testMaxBooleanClause() {     MatchQuery query = new MatchQuery(createShardContext()).     query.setAnalyzer(new MockGraphAnalyzer(createGiantGraph(40))).     expectThrows(BooleanQuery.TooManyClauses.class, () -> query.parse(Type.PHRASE, STRING_FIELD_NAME, "")).     query.setAnalyzer(new MockGraphAnalyzer(createGiantGraphMultiTerms())).     expectThrows(BooleanQuery.TooManyClauses.class, () -> query.parse(Type.PHRASE, STRING_FIELD_NAME, "")). }
false;protected;1;4;;@Override protected TokenStreamComponents createComponents(String fieldName) {     return new TokenStreamComponents(r -> {     }, tokenStream). }
true;private,static;1;16;/**  * Creates a graph token stream with 2 side paths at each position.  */ ;/**  * Creates a graph token stream with 2 side paths at each position.  */ private static CannedBinaryTokenStream.BinaryToken[] createGiantGraph(int numPos) {     List<CannedBinaryTokenStream.BinaryToken> tokens = new ArrayList<>().     BytesRef term1 = new BytesRef("foo").     BytesRef term2 = new BytesRef("bar").     for (int i = 0. i < numPos. ) {         if (i % 2 == 0) {             tokens.add(new CannedBinaryTokenStream.BinaryToken(term2, 1, 1)).             tokens.add(new CannedBinaryTokenStream.BinaryToken(term1, 0, 2)).             i += 2.         } else {             tokens.add(new CannedBinaryTokenStream.BinaryToken(term2, 1, 1)).             i++.         }     }     return tokens.toArray(new CannedBinaryTokenStream.BinaryToken[0]). }
true;private,static;0;13;/**  * Creates a graph token stream with {@link BooleanQuery#getMaxClauseCount()}  * expansions at the last position.  */ ;/**  * Creates a graph token stream with {@link BooleanQuery#getMaxClauseCount()}  * expansions at the last position.  */ private static CannedBinaryTokenStream.BinaryToken[] createGiantGraphMultiTerms() {     List<CannedBinaryTokenStream.BinaryToken> tokens = new ArrayList<>().     BytesRef term1 = new BytesRef("foo").     BytesRef term2 = new BytesRef("bar").     tokens.add(new CannedBinaryTokenStream.BinaryToken(term2, 1, 1)).     tokens.add(new CannedBinaryTokenStream.BinaryToken(term1, 0, 2)).     tokens.add(new CannedBinaryTokenStream.BinaryToken(term2, 1, 1)).     tokens.add(new CannedBinaryTokenStream.BinaryToken(term2, 1, 1)).     for (int i = 0. i < BooleanQuery.getMaxClauseCount(). i++) {         tokens.add(new CannedBinaryTokenStream.BinaryToken(term1, 0, 1)).     }     return tokens.toArray(new CannedBinaryTokenStream.BinaryToken[0]). }
