# id;timestamp;commentText;codeText;commentWords;codeWords
SignificantTermsAggregatorTests -> public void testNumericSignificance() throws IOException;1524684173;Uses the significant terms aggregation to find the keywords in numeric_fields;public void testNumericSignificance() throws IOException {_        NumberFieldType longFieldType = new NumberFieldMapper.NumberFieldType(NumberFieldMapper.NumberType.LONG)__        longFieldType.setName("long_field")___        TextFieldType textFieldType = new TextFieldType()__        textFieldType.setName("text")__        textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer", AnalyzerScope.GLOBAL, new StandardAnalyzer()))___        IndexWriterConfig indexWriterConfig = newIndexWriterConfig()__        indexWriterConfig.setMaxBufferedDocs(100)__        indexWriterConfig.setRAMBufferSizeMB(100)_ _        final long ODD_VALUE = 3__        final long EVEN_VALUE = 6__        final long COMMON_VALUE = 2___        try (Directory dir = newDirectory()_ IndexWriter w = new IndexWriter(dir, indexWriterConfig)) {__            for (int i = 0_ i < 10_ i++) {_                Document doc = new Document()__                if (i % 2 == 0) {_                    addFields(doc, NumberType.LONG.createFields("long_field", ODD_VALUE, true, true, false))__                    doc.add(new Field("text", "odd", textFieldType))__                } else {_                    addFields(doc, NumberType.LONG.createFields("long_field", EVEN_VALUE, true, true, false))__                    doc.add(new Field("text", "even", textFieldType))__                }_                addFields(doc, NumberType.LONG.createFields("long_field", COMMON_VALUE, true, true, false))__                w.addDocument(doc)__            }__            SignificantTermsAggregationBuilder sigNumAgg = new SignificantTermsAggregationBuilder("sig_number", null).field("long_field")__            sigNumAgg.executionHint(randomExecutionHint())___            try (IndexReader reader = DirectoryReader.open(w)) {_                assertEquals("test expects a single segment", 1, reader.leaves().size())__                IndexSearcher searcher = new IndexSearcher(reader)___                _                SignificantLongTerms terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigNumAgg, longFieldType)__                assertEquals(1, terms.getBuckets().size())___                assertNull(terms.getBucketByKey(Long.toString(EVEN_VALUE)))__                assertNull(terms.getBucketByKey(Long.toString(COMMON_VALUE)))__                assertNotNull(terms.getBucketByKey(Long.toString(ODD_VALUE)))___                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "even")), sigNumAgg, longFieldType)__                assertEquals(1, terms.getBuckets().size())___                assertNull(terms.getBucketByKey(Long.toString(ODD_VALUE)))__                assertNull(terms.getBucketByKey(Long.toString(COMMON_VALUE)))__                assertNotNull(terms.getBucketByKey(Long.toString(EVEN_VALUE)))___            }_        }_    };uses,the,significant,terms,aggregation,to,find,the,keywords,in,numeric,fields;public,void,test,numeric,significance,throws,ioexception,number,field,type,long,field,type,new,number,field,mapper,number,field,type,number,field,mapper,number,type,long,long,field,type,set,name,text,field,type,text,field,type,new,text,field,type,text,field,type,set,name,text,text,field,type,set,index,analyzer,new,named,analyzer,analyzer,scope,global,new,standard,analyzer,index,writer,config,index,writer,config,new,index,writer,config,index,writer,config,set,max,buffered,docs,100,index,writer,config,set,rambuffer,size,mb,100,final,long,3,final,long,6,final,long,2,try,directory,dir,new,directory,index,writer,w,new,index,writer,dir,index,writer,config,for,int,i,0,i,10,i,document,doc,new,document,if,i,2,0,add,fields,doc,number,type,long,create,fields,true,true,false,doc,add,new,field,text,odd,text,field,type,else,add,fields,doc,number,type,long,create,fields,true,true,false,doc,add,new,field,text,even,text,field,type,add,fields,doc,number,type,long,create,fields,true,true,false,w,add,document,doc,significant,terms,aggregation,builder,sig,num,agg,new,significant,terms,aggregation,builder,null,field,sig,num,agg,execution,hint,random,execution,hint,try,index,reader,reader,directory,reader,open,w,assert,equals,test,expects,a,single,segment,1,reader,leaves,size,index,searcher,searcher,new,index,searcher,reader,significant,long,terms,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,num,agg,long,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,long,to,string,assert,null,terms,get,bucket,by,key,long,to,string,assert,not,null,terms,get,bucket,by,key,long,to,string,terms,search,and,reduce,searcher,new,term,query,new,term,text,even,sig,num,agg,long,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,long,to,string,assert,null,terms,get,bucket,by,key,long,to,string,assert,not,null,terms,get,bucket,by,key,long,to,string
SignificantTermsAggregatorTests -> public void testNumericSignificance() throws IOException;1531937412;Uses the significant terms aggregation to find the keywords in numeric_fields;public void testNumericSignificance() throws IOException {_        NumberFieldType longFieldType = new NumberFieldMapper.NumberFieldType(NumberFieldMapper.NumberType.LONG)__        longFieldType.setName("long_field")___        TextFieldType textFieldType = new TextFieldType()__        textFieldType.setName("text")__        textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer", AnalyzerScope.GLOBAL, new StandardAnalyzer()))___        IndexWriterConfig indexWriterConfig = newIndexWriterConfig()__        indexWriterConfig.setMaxBufferedDocs(100)__        indexWriterConfig.setRAMBufferSizeMB(100)_ _        final long ODD_VALUE = 3__        final long EVEN_VALUE = 6__        final long COMMON_VALUE = 2___        try (Directory dir = newDirectory()_ IndexWriter w = new IndexWriter(dir, indexWriterConfig)) {__            for (int i = 0_ i < 10_ i++) {_                Document doc = new Document()__                if (i % 2 == 0) {_                    addFields(doc, NumberType.LONG.createFields("long_field", ODD_VALUE, true, true, false))__                    doc.add(new Field("text", "odd", textFieldType))__                } else {_                    addFields(doc, NumberType.LONG.createFields("long_field", EVEN_VALUE, true, true, false))__                    doc.add(new Field("text", "even", textFieldType))__                }_                addFields(doc, NumberType.LONG.createFields("long_field", COMMON_VALUE, true, true, false))__                w.addDocument(doc)__            }__            SignificantTermsAggregationBuilder sigNumAgg = new SignificantTermsAggregationBuilder("sig_number", null).field("long_field")__            sigNumAgg.executionHint(randomExecutionHint())___            try (IndexReader reader = DirectoryReader.open(w)) {_                assertEquals("test expects a single segment", 1, reader.leaves().size())__                IndexSearcher searcher = new IndexSearcher(reader)___                _                SignificantLongTerms terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigNumAgg, longFieldType)__                assertEquals(1, terms.getBuckets().size())___                assertNull(terms.getBucketByKey(Long.toString(EVEN_VALUE)))__                assertNull(terms.getBucketByKey(Long.toString(COMMON_VALUE)))__                assertNotNull(terms.getBucketByKey(Long.toString(ODD_VALUE)))___                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "even")), sigNumAgg, longFieldType)__                assertEquals(1, terms.getBuckets().size())___                assertNull(terms.getBucketByKey(Long.toString(ODD_VALUE)))__                assertNull(terms.getBucketByKey(Long.toString(COMMON_VALUE)))__                assertNotNull(terms.getBucketByKey(Long.toString(EVEN_VALUE)))___            }_        }_    };uses,the,significant,terms,aggregation,to,find,the,keywords,in,numeric,fields;public,void,test,numeric,significance,throws,ioexception,number,field,type,long,field,type,new,number,field,mapper,number,field,type,number,field,mapper,number,type,long,long,field,type,set,name,text,field,type,text,field,type,new,text,field,type,text,field,type,set,name,text,text,field,type,set,index,analyzer,new,named,analyzer,analyzer,scope,global,new,standard,analyzer,index,writer,config,index,writer,config,new,index,writer,config,index,writer,config,set,max,buffered,docs,100,index,writer,config,set,rambuffer,size,mb,100,final,long,3,final,long,6,final,long,2,try,directory,dir,new,directory,index,writer,w,new,index,writer,dir,index,writer,config,for,int,i,0,i,10,i,document,doc,new,document,if,i,2,0,add,fields,doc,number,type,long,create,fields,true,true,false,doc,add,new,field,text,odd,text,field,type,else,add,fields,doc,number,type,long,create,fields,true,true,false,doc,add,new,field,text,even,text,field,type,add,fields,doc,number,type,long,create,fields,true,true,false,w,add,document,doc,significant,terms,aggregation,builder,sig,num,agg,new,significant,terms,aggregation,builder,null,field,sig,num,agg,execution,hint,random,execution,hint,try,index,reader,reader,directory,reader,open,w,assert,equals,test,expects,a,single,segment,1,reader,leaves,size,index,searcher,searcher,new,index,searcher,reader,significant,long,terms,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,num,agg,long,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,long,to,string,assert,null,terms,get,bucket,by,key,long,to,string,assert,not,null,terms,get,bucket,by,key,long,to,string,terms,search,and,reduce,searcher,new,term,query,new,term,text,even,sig,num,agg,long,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,long,to,string,assert,null,terms,get,bucket,by,key,long,to,string,assert,not,null,terms,get,bucket,by,key,long,to,string
SignificantTermsAggregatorTests -> public void testNumericSignificance() throws IOException;1532028790;Uses the significant terms aggregation to find the keywords in numeric_fields;public void testNumericSignificance() throws IOException {_        NumberFieldType longFieldType = new NumberFieldMapper.NumberFieldType(NumberFieldMapper.NumberType.LONG)__        longFieldType.setName("long_field")___        TextFieldType textFieldType = new TextFieldType()__        textFieldType.setName("text")__        textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer", AnalyzerScope.GLOBAL, new StandardAnalyzer()))___        IndexWriterConfig indexWriterConfig = newIndexWriterConfig()__        indexWriterConfig.setMaxBufferedDocs(100)__        indexWriterConfig.setRAMBufferSizeMB(100)_ _        final long ODD_VALUE = 3__        final long EVEN_VALUE = 6__        final long COMMON_VALUE = 2___        try (Directory dir = newDirectory()_ IndexWriter w = new IndexWriter(dir, indexWriterConfig)) {__            for (int i = 0_ i < 10_ i++) {_                Document doc = new Document()__                if (i % 2 == 0) {_                    addFields(doc, NumberType.LONG.createFields("long_field", ODD_VALUE, true, true, false))__                    doc.add(new Field("text", "odd", textFieldType))__                } else {_                    addFields(doc, NumberType.LONG.createFields("long_field", EVEN_VALUE, true, true, false))__                    doc.add(new Field("text", "even", textFieldType))__                }_                addFields(doc, NumberType.LONG.createFields("long_field", COMMON_VALUE, true, true, false))__                w.addDocument(doc)__            }__            SignificantTermsAggregationBuilder sigNumAgg = new SignificantTermsAggregationBuilder("sig_number", null).field("long_field")__            sigNumAgg.executionHint(randomExecutionHint())___            try (IndexReader reader = DirectoryReader.open(w)) {_                assertEquals("test expects a single segment", 1, reader.leaves().size())__                IndexSearcher searcher = new IndexSearcher(reader)___                _                SignificantLongTerms terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigNumAgg, longFieldType)__                assertEquals(1, terms.getBuckets().size())___                assertNull(terms.getBucketByKey(Long.toString(EVEN_VALUE)))__                assertNull(terms.getBucketByKey(Long.toString(COMMON_VALUE)))__                assertNotNull(terms.getBucketByKey(Long.toString(ODD_VALUE)))___                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "even")), sigNumAgg, longFieldType)__                assertEquals(1, terms.getBuckets().size())___                assertNull(terms.getBucketByKey(Long.toString(ODD_VALUE)))__                assertNull(terms.getBucketByKey(Long.toString(COMMON_VALUE)))__                assertNotNull(terms.getBucketByKey(Long.toString(EVEN_VALUE)))___            }_        }_    };uses,the,significant,terms,aggregation,to,find,the,keywords,in,numeric,fields;public,void,test,numeric,significance,throws,ioexception,number,field,type,long,field,type,new,number,field,mapper,number,field,type,number,field,mapper,number,type,long,long,field,type,set,name,text,field,type,text,field,type,new,text,field,type,text,field,type,set,name,text,text,field,type,set,index,analyzer,new,named,analyzer,analyzer,scope,global,new,standard,analyzer,index,writer,config,index,writer,config,new,index,writer,config,index,writer,config,set,max,buffered,docs,100,index,writer,config,set,rambuffer,size,mb,100,final,long,3,final,long,6,final,long,2,try,directory,dir,new,directory,index,writer,w,new,index,writer,dir,index,writer,config,for,int,i,0,i,10,i,document,doc,new,document,if,i,2,0,add,fields,doc,number,type,long,create,fields,true,true,false,doc,add,new,field,text,odd,text,field,type,else,add,fields,doc,number,type,long,create,fields,true,true,false,doc,add,new,field,text,even,text,field,type,add,fields,doc,number,type,long,create,fields,true,true,false,w,add,document,doc,significant,terms,aggregation,builder,sig,num,agg,new,significant,terms,aggregation,builder,null,field,sig,num,agg,execution,hint,random,execution,hint,try,index,reader,reader,directory,reader,open,w,assert,equals,test,expects,a,single,segment,1,reader,leaves,size,index,searcher,searcher,new,index,searcher,reader,significant,long,terms,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,num,agg,long,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,long,to,string,assert,null,terms,get,bucket,by,key,long,to,string,assert,not,null,terms,get,bucket,by,key,long,to,string,terms,search,and,reduce,searcher,new,term,query,new,term,text,even,sig,num,agg,long,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,long,to,string,assert,null,terms,get,bucket,by,key,long,to,string,assert,not,null,terms,get,bucket,by,key,long,to,string
SignificantTermsAggregatorTests -> public void testNumericSignificance() throws IOException;1543834151;Uses the significant terms aggregation to find the keywords in numeric_fields;public void testNumericSignificance() throws IOException {_        NumberFieldType longFieldType = new NumberFieldMapper.NumberFieldType(NumberFieldMapper.NumberType.LONG)__        longFieldType.setName("long_field")___        TextFieldType textFieldType = new TextFieldType()__        textFieldType.setName("text")__        textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer", AnalyzerScope.GLOBAL, new StandardAnalyzer()))___        IndexWriterConfig indexWriterConfig = newIndexWriterConfig()__        indexWriterConfig.setMaxBufferedDocs(100)__        indexWriterConfig.setRAMBufferSizeMB(100)_ _        final long ODD_VALUE = 3__        final long EVEN_VALUE = 6__        final long COMMON_VALUE = 2___        try (Directory dir = newDirectory()_ IndexWriter w = new IndexWriter(dir, indexWriterConfig)) {__            for (int i = 0_ i < 10_ i++) {_                Document doc = new Document()__                if (i % 2 == 0) {_                    addFields(doc, NumberType.LONG.createFields("long_field", ODD_VALUE, true, true, false))__                    doc.add(new Field("text", "odd", textFieldType))__                } else {_                    addFields(doc, NumberType.LONG.createFields("long_field", EVEN_VALUE, true, true, false))__                    doc.add(new Field("text", "even", textFieldType))__                }_                addFields(doc, NumberType.LONG.createFields("long_field", COMMON_VALUE, true, true, false))__                w.addDocument(doc)__            }__            SignificantTermsAggregationBuilder sigNumAgg = new SignificantTermsAggregationBuilder("sig_number", null).field("long_field")__            sigNumAgg.executionHint(randomExecutionHint())___            try (IndexReader reader = DirectoryReader.open(w)) {_                assertEquals("test expects a single segment", 1, reader.leaves().size())__                IndexSearcher searcher = new IndexSearcher(reader)___                _                SignificantLongTerms terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigNumAgg, longFieldType)__                assertEquals(1, terms.getBuckets().size())___                assertNull(terms.getBucketByKey(Long.toString(EVEN_VALUE)))__                assertNull(terms.getBucketByKey(Long.toString(COMMON_VALUE)))__                assertNotNull(terms.getBucketByKey(Long.toString(ODD_VALUE)))___                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "even")), sigNumAgg, longFieldType)__                assertEquals(1, terms.getBuckets().size())___                assertNull(terms.getBucketByKey(Long.toString(ODD_VALUE)))__                assertNull(terms.getBucketByKey(Long.toString(COMMON_VALUE)))__                assertNotNull(terms.getBucketByKey(Long.toString(EVEN_VALUE)))___            }_        }_    };uses,the,significant,terms,aggregation,to,find,the,keywords,in,numeric,fields;public,void,test,numeric,significance,throws,ioexception,number,field,type,long,field,type,new,number,field,mapper,number,field,type,number,field,mapper,number,type,long,long,field,type,set,name,text,field,type,text,field,type,new,text,field,type,text,field,type,set,name,text,text,field,type,set,index,analyzer,new,named,analyzer,analyzer,scope,global,new,standard,analyzer,index,writer,config,index,writer,config,new,index,writer,config,index,writer,config,set,max,buffered,docs,100,index,writer,config,set,rambuffer,size,mb,100,final,long,3,final,long,6,final,long,2,try,directory,dir,new,directory,index,writer,w,new,index,writer,dir,index,writer,config,for,int,i,0,i,10,i,document,doc,new,document,if,i,2,0,add,fields,doc,number,type,long,create,fields,true,true,false,doc,add,new,field,text,odd,text,field,type,else,add,fields,doc,number,type,long,create,fields,true,true,false,doc,add,new,field,text,even,text,field,type,add,fields,doc,number,type,long,create,fields,true,true,false,w,add,document,doc,significant,terms,aggregation,builder,sig,num,agg,new,significant,terms,aggregation,builder,null,field,sig,num,agg,execution,hint,random,execution,hint,try,index,reader,reader,directory,reader,open,w,assert,equals,test,expects,a,single,segment,1,reader,leaves,size,index,searcher,searcher,new,index,searcher,reader,significant,long,terms,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,num,agg,long,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,long,to,string,assert,null,terms,get,bucket,by,key,long,to,string,assert,not,null,terms,get,bucket,by,key,long,to,string,terms,search,and,reduce,searcher,new,term,query,new,term,text,even,sig,num,agg,long,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,long,to,string,assert,null,terms,get,bucket,by,key,long,to,string,assert,not,null,terms,get,bucket,by,key,long,to,string
SignificantTermsAggregatorTests -> @Override     protected Map<String, MappedFieldType> getFieldAliases(MappedFieldType... fieldTypes);1531937412;For each provided field type, we also register an alias with name <field>-alias.;@Override_    protected Map<String, MappedFieldType> getFieldAliases(MappedFieldType... fieldTypes) {_        return Arrays.stream(fieldTypes).collect(Collectors.toMap(_            ft -> ft.name() + "-alias",_            Function.identity()))__    };for,each,provided,field,type,we,also,register,an,alias,with,name,field,alias;override,protected,map,string,mapped,field,type,get,field,aliases,mapped,field,type,field,types,return,arrays,stream,field,types,collect,collectors,to,map,ft,ft,name,alias,function,identity
SignificantTermsAggregatorTests -> @Override     protected Map<String, MappedFieldType> getFieldAliases(MappedFieldType... fieldTypes);1532028790;For each provided field type, we also register an alias with name {@code <field>-alias}.;@Override_    protected Map<String, MappedFieldType> getFieldAliases(MappedFieldType... fieldTypes) {_        return Arrays.stream(fieldTypes).collect(Collectors.toMap(_            ft -> ft.name() + "-alias",_            Function.identity()))__    };for,each,provided,field,type,we,also,register,an,alias,with,name,code,field,alias;override,protected,map,string,mapped,field,type,get,field,aliases,mapped,field,type,field,types,return,arrays,stream,field,types,collect,collectors,to,map,ft,ft,name,alias,function,identity
SignificantTermsAggregatorTests -> @Override     protected Map<String, MappedFieldType> getFieldAliases(MappedFieldType... fieldTypes);1543834151;For each provided field type, we also register an alias with name {@code <field>-alias}.;@Override_    protected Map<String, MappedFieldType> getFieldAliases(MappedFieldType... fieldTypes) {_        return Arrays.stream(fieldTypes).collect(Collectors.toMap(_            ft -> ft.name() + "-alias",_            Function.identity()))__    };for,each,provided,field,type,we,also,register,an,alias,with,name,code,field,alias;override,protected,map,string,mapped,field,type,get,field,aliases,mapped,field,type,field,types,return,arrays,stream,field,types,collect,collectors,to,map,ft,ft,name,alias,function,identity
SignificantTermsAggregatorTests -> public void testSignificance() throws IOException;1524684173;Uses the significant terms aggregation to find the keywords in text fields;public void testSignificance() throws IOException {_        TextFieldType textFieldType = new TextFieldType()__        textFieldType.setName("text")__        textFieldType.setFielddata(true)__        textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer", AnalyzerScope.GLOBAL, new StandardAnalyzer()))___        IndexWriterConfig indexWriterConfig = newIndexWriterConfig()__        indexWriterConfig.setMaxBufferedDocs(100)__        indexWriterConfig.setRAMBufferSizeMB(100)_ _        _        try (Directory dir = newDirectory()_ IndexWriter w = new IndexWriter(dir, indexWriterConfig)) {_            addMixedTextDocs(textFieldType, w)___            SignificantTermsAggregationBuilder sigAgg = new SignificantTermsAggregationBuilder("sig_text", null).field("text")__            sigAgg.executionHint(randomExecutionHint())__            if (randomBoolean()) {_                _                sigAgg.backgroundFilter(QueryBuilders.termsQuery("text",  "common"))__            }__            SignificantTermsAggregationBuilder sigNumAgg = new SignificantTermsAggregationBuilder("sig_number", null).field("long_field")__            sigNumAgg.executionHint(randomExecutionHint())___            try (IndexReader reader = DirectoryReader.open(w)) {_                assertEquals("test expects a single segment", 1, reader.leaves().size())__                IndexSearcher searcher = new IndexSearcher(reader)___                _                SignificantTerms terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)___                assertEquals(1, terms.getBuckets().size())__                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("common"))__                assertNotNull(terms.getBucketByKey("odd"))___                _                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "even")), sigAgg, textFieldType)___                assertEquals(1, terms.getBuckets().size())__                assertNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("common"))__                assertNotNull(terms.getBucketByKey("even"))__                _                _                sigAgg.includeExclude(new IncludeExclude("o.d", null))__                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(1, terms.getBuckets().size())__                assertNotNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("even"))___                _                String oddStrings[] = new String[] {"odd", "weird"}__                String evenStrings[] = new String[] {"even", "regular"}__                _                sigAgg.includeExclude(new IncludeExclude(oddStrings, evenStrings))__                sigAgg.significanceHeuristic(SignificanceHeuristicTests.getRandomSignificanceheuristic())__                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(1, terms.getBuckets().size())__                assertNotNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("weird"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("regular"))__                _                sigAgg.includeExclude(new IncludeExclude(evenStrings, oddStrings))__                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(0, terms.getBuckets().size())__                assertNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("weird"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("regular"))__                _            }_        }_    };uses,the,significant,terms,aggregation,to,find,the,keywords,in,text,fields;public,void,test,significance,throws,ioexception,text,field,type,text,field,type,new,text,field,type,text,field,type,set,name,text,text,field,type,set,fielddata,true,text,field,type,set,index,analyzer,new,named,analyzer,analyzer,scope,global,new,standard,analyzer,index,writer,config,index,writer,config,new,index,writer,config,index,writer,config,set,max,buffered,docs,100,index,writer,config,set,rambuffer,size,mb,100,try,directory,dir,new,directory,index,writer,w,new,index,writer,dir,index,writer,config,add,mixed,text,docs,text,field,type,w,significant,terms,aggregation,builder,sig,agg,new,significant,terms,aggregation,builder,null,field,text,sig,agg,execution,hint,random,execution,hint,if,random,boolean,sig,agg,background,filter,query,builders,terms,query,text,common,significant,terms,aggregation,builder,sig,num,agg,new,significant,terms,aggregation,builder,null,field,sig,num,agg,execution,hint,random,execution,hint,try,index,reader,reader,directory,reader,open,w,assert,equals,test,expects,a,single,segment,1,reader,leaves,size,index,searcher,searcher,new,index,searcher,reader,significant,terms,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,common,assert,not,null,terms,get,bucket,by,key,odd,terms,search,and,reduce,searcher,new,term,query,new,term,text,even,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,common,assert,not,null,terms,get,bucket,by,key,even,sig,agg,include,exclude,new,include,exclude,o,d,null,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,not,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,even,string,odd,strings,new,string,odd,weird,string,even,strings,new,string,even,regular,sig,agg,include,exclude,new,include,exclude,odd,strings,even,strings,sig,agg,significance,heuristic,significance,heuristic,tests,get,random,significanceheuristic,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,not,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,weird,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,regular,sig,agg,include,exclude,new,include,exclude,even,strings,odd,strings,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,0,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,weird,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,regular
SignificantTermsAggregatorTests -> public void testSignificance() throws IOException;1531937412;Uses the significant terms aggregation to find the keywords in text fields;public void testSignificance() throws IOException {_        TextFieldType textFieldType = new TextFieldType()__        textFieldType.setName("text")__        textFieldType.setFielddata(true)__        textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer", AnalyzerScope.GLOBAL, new StandardAnalyzer()))___        IndexWriterConfig indexWriterConfig = newIndexWriterConfig()__        indexWriterConfig.setMaxBufferedDocs(100)__        indexWriterConfig.setRAMBufferSizeMB(100)_ __        try (Directory dir = newDirectory()_ IndexWriter w = new IndexWriter(dir, indexWriterConfig)) {_            addMixedTextDocs(textFieldType, w)___            SignificantTermsAggregationBuilder sigAgg = new SignificantTermsAggregationBuilder("sig_text", null).field("text")__            sigAgg.executionHint(randomExecutionHint())__            if (randomBoolean()) {_                _                sigAgg.backgroundFilter(QueryBuilders.termsQuery("text",  "common"))__            }__            SignificantTermsAggregationBuilder sigNumAgg = new SignificantTermsAggregationBuilder("sig_number", null).field("long_field")__            sigNumAgg.executionHint(randomExecutionHint())___            try (IndexReader reader = DirectoryReader.open(w)) {_                assertEquals("test expects a single segment", 1, reader.leaves().size())__                IndexSearcher searcher = new IndexSearcher(reader)___                _                SignificantTerms terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)___                assertEquals(1, terms.getBuckets().size())__                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("common"))__                assertNotNull(terms.getBucketByKey("odd"))___                _                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "even")), sigAgg, textFieldType)___                assertEquals(1, terms.getBuckets().size())__                assertNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("common"))__                assertNotNull(terms.getBucketByKey("even"))___                _                sigAgg.includeExclude(new IncludeExclude("o.d", null))__                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(1, terms.getBuckets().size())__                assertNotNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("even"))___                _                String oddStrings[] = new String[] {"odd", "weird"}__                String evenStrings[] = new String[] {"even", "regular"}___                sigAgg.includeExclude(new IncludeExclude(oddStrings, evenStrings))__                sigAgg.significanceHeuristic(SignificanceHeuristicTests.getRandomSignificanceheuristic())__                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(1, terms.getBuckets().size())__                assertNotNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("weird"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("regular"))___                sigAgg.includeExclude(new IncludeExclude(evenStrings, oddStrings))__                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(0, terms.getBuckets().size())__                assertNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("weird"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("regular"))___            }_        }_    };uses,the,significant,terms,aggregation,to,find,the,keywords,in,text,fields;public,void,test,significance,throws,ioexception,text,field,type,text,field,type,new,text,field,type,text,field,type,set,name,text,text,field,type,set,fielddata,true,text,field,type,set,index,analyzer,new,named,analyzer,analyzer,scope,global,new,standard,analyzer,index,writer,config,index,writer,config,new,index,writer,config,index,writer,config,set,max,buffered,docs,100,index,writer,config,set,rambuffer,size,mb,100,try,directory,dir,new,directory,index,writer,w,new,index,writer,dir,index,writer,config,add,mixed,text,docs,text,field,type,w,significant,terms,aggregation,builder,sig,agg,new,significant,terms,aggregation,builder,null,field,text,sig,agg,execution,hint,random,execution,hint,if,random,boolean,sig,agg,background,filter,query,builders,terms,query,text,common,significant,terms,aggregation,builder,sig,num,agg,new,significant,terms,aggregation,builder,null,field,sig,num,agg,execution,hint,random,execution,hint,try,index,reader,reader,directory,reader,open,w,assert,equals,test,expects,a,single,segment,1,reader,leaves,size,index,searcher,searcher,new,index,searcher,reader,significant,terms,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,common,assert,not,null,terms,get,bucket,by,key,odd,terms,search,and,reduce,searcher,new,term,query,new,term,text,even,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,common,assert,not,null,terms,get,bucket,by,key,even,sig,agg,include,exclude,new,include,exclude,o,d,null,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,not,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,even,string,odd,strings,new,string,odd,weird,string,even,strings,new,string,even,regular,sig,agg,include,exclude,new,include,exclude,odd,strings,even,strings,sig,agg,significance,heuristic,significance,heuristic,tests,get,random,significanceheuristic,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,not,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,weird,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,regular,sig,agg,include,exclude,new,include,exclude,even,strings,odd,strings,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,0,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,weird,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,regular
SignificantTermsAggregatorTests -> public void testSignificance() throws IOException;1532028790;Uses the significant terms aggregation to find the keywords in text fields;public void testSignificance() throws IOException {_        TextFieldType textFieldType = new TextFieldType()__        textFieldType.setName("text")__        textFieldType.setFielddata(true)__        textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer", AnalyzerScope.GLOBAL, new StandardAnalyzer()))___        IndexWriterConfig indexWriterConfig = newIndexWriterConfig()__        indexWriterConfig.setMaxBufferedDocs(100)__        indexWriterConfig.setRAMBufferSizeMB(100)_ __        try (Directory dir = newDirectory()_ IndexWriter w = new IndexWriter(dir, indexWriterConfig)) {_            addMixedTextDocs(textFieldType, w)___            SignificantTermsAggregationBuilder sigAgg = new SignificantTermsAggregationBuilder("sig_text", null).field("text")__            sigAgg.executionHint(randomExecutionHint())__            if (randomBoolean()) {_                _                sigAgg.backgroundFilter(QueryBuilders.termsQuery("text",  "common"))__            }__            SignificantTermsAggregationBuilder sigNumAgg = new SignificantTermsAggregationBuilder("sig_number", null).field("long_field")__            sigNumAgg.executionHint(randomExecutionHint())___            try (IndexReader reader = DirectoryReader.open(w)) {_                assertEquals("test expects a single segment", 1, reader.leaves().size())__                IndexSearcher searcher = new IndexSearcher(reader)___                _                SignificantTerms terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)___                assertEquals(1, terms.getBuckets().size())__                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("common"))__                assertNotNull(terms.getBucketByKey("odd"))___                _                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "even")), sigAgg, textFieldType)___                assertEquals(1, terms.getBuckets().size())__                assertNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("common"))__                assertNotNull(terms.getBucketByKey("even"))___                _                sigAgg.includeExclude(new IncludeExclude("o.d", null))__                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(1, terms.getBuckets().size())__                assertNotNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("even"))___                _                String oddStrings[] = new String[] {"odd", "weird"}__                String evenStrings[] = new String[] {"even", "regular"}___                sigAgg.includeExclude(new IncludeExclude(oddStrings, evenStrings))__                sigAgg.significanceHeuristic(SignificanceHeuristicTests.getRandomSignificanceheuristic())__                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(1, terms.getBuckets().size())__                assertNotNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("weird"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("regular"))___                sigAgg.includeExclude(new IncludeExclude(evenStrings, oddStrings))__                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(0, terms.getBuckets().size())__                assertNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("weird"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("regular"))___            }_        }_    };uses,the,significant,terms,aggregation,to,find,the,keywords,in,text,fields;public,void,test,significance,throws,ioexception,text,field,type,text,field,type,new,text,field,type,text,field,type,set,name,text,text,field,type,set,fielddata,true,text,field,type,set,index,analyzer,new,named,analyzer,analyzer,scope,global,new,standard,analyzer,index,writer,config,index,writer,config,new,index,writer,config,index,writer,config,set,max,buffered,docs,100,index,writer,config,set,rambuffer,size,mb,100,try,directory,dir,new,directory,index,writer,w,new,index,writer,dir,index,writer,config,add,mixed,text,docs,text,field,type,w,significant,terms,aggregation,builder,sig,agg,new,significant,terms,aggregation,builder,null,field,text,sig,agg,execution,hint,random,execution,hint,if,random,boolean,sig,agg,background,filter,query,builders,terms,query,text,common,significant,terms,aggregation,builder,sig,num,agg,new,significant,terms,aggregation,builder,null,field,sig,num,agg,execution,hint,random,execution,hint,try,index,reader,reader,directory,reader,open,w,assert,equals,test,expects,a,single,segment,1,reader,leaves,size,index,searcher,searcher,new,index,searcher,reader,significant,terms,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,common,assert,not,null,terms,get,bucket,by,key,odd,terms,search,and,reduce,searcher,new,term,query,new,term,text,even,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,common,assert,not,null,terms,get,bucket,by,key,even,sig,agg,include,exclude,new,include,exclude,o,d,null,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,not,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,even,string,odd,strings,new,string,odd,weird,string,even,strings,new,string,even,regular,sig,agg,include,exclude,new,include,exclude,odd,strings,even,strings,sig,agg,significance,heuristic,significance,heuristic,tests,get,random,significanceheuristic,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,not,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,weird,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,regular,sig,agg,include,exclude,new,include,exclude,even,strings,odd,strings,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,0,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,weird,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,regular
SignificantTermsAggregatorTests -> public void testSignificance() throws IOException;1543834151;Uses the significant terms aggregation to find the keywords in text fields;public void testSignificance() throws IOException {_        TextFieldType textFieldType = new TextFieldType()__        textFieldType.setName("text")__        textFieldType.setFielddata(true)__        textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer", AnalyzerScope.GLOBAL, new StandardAnalyzer()))___        IndexWriterConfig indexWriterConfig = newIndexWriterConfig()__        indexWriterConfig.setMaxBufferedDocs(100)__        indexWriterConfig.setRAMBufferSizeMB(100)_ __        try (Directory dir = newDirectory()_ IndexWriter w = new IndexWriter(dir, indexWriterConfig)) {_            addMixedTextDocs(textFieldType, w)___            SignificantTermsAggregationBuilder sigAgg = new SignificantTermsAggregationBuilder("sig_text", null).field("text")__            sigAgg.executionHint(randomExecutionHint())__            if (randomBoolean()) {_                _                sigAgg.backgroundFilter(QueryBuilders.termsQuery("text",  "common"))__            }__            SignificantTermsAggregationBuilder sigNumAgg = new SignificantTermsAggregationBuilder("sig_number", null).field("long_field")__            sigNumAgg.executionHint(randomExecutionHint())___            try (IndexReader reader = DirectoryReader.open(w)) {_                assertEquals("test expects a single segment", 1, reader.leaves().size())__                IndexSearcher searcher = new IndexSearcher(reader)___                _                SignificantTerms terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)___                assertEquals(1, terms.getBuckets().size())__                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("common"))__                assertNotNull(terms.getBucketByKey("odd"))___                _                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "even")), sigAgg, textFieldType)___                assertEquals(1, terms.getBuckets().size())__                assertNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("common"))__                assertNotNull(terms.getBucketByKey("even"))___                _                sigAgg.includeExclude(new IncludeExclude("o.d", null))__                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(1, terms.getBuckets().size())__                assertNotNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("even"))___                _                String oddStrings[] = new String[] {"odd", "weird"}__                String evenStrings[] = new String[] {"even", "regular"}___                sigAgg.includeExclude(new IncludeExclude(oddStrings, evenStrings))__                sigAgg.significanceHeuristic(SignificanceHeuristicTests.getRandomSignificanceheuristic())__                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(1, terms.getBuckets().size())__                assertNotNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("weird"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("regular"))___                sigAgg.includeExclude(new IncludeExclude(evenStrings, oddStrings))__                terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(0, terms.getBuckets().size())__                assertNull(terms.getBucketByKey("odd"))__                assertNull(terms.getBucketByKey("weird"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("regular"))___            }_        }_    };uses,the,significant,terms,aggregation,to,find,the,keywords,in,text,fields;public,void,test,significance,throws,ioexception,text,field,type,text,field,type,new,text,field,type,text,field,type,set,name,text,text,field,type,set,fielddata,true,text,field,type,set,index,analyzer,new,named,analyzer,analyzer,scope,global,new,standard,analyzer,index,writer,config,index,writer,config,new,index,writer,config,index,writer,config,set,max,buffered,docs,100,index,writer,config,set,rambuffer,size,mb,100,try,directory,dir,new,directory,index,writer,w,new,index,writer,dir,index,writer,config,add,mixed,text,docs,text,field,type,w,significant,terms,aggregation,builder,sig,agg,new,significant,terms,aggregation,builder,null,field,text,sig,agg,execution,hint,random,execution,hint,if,random,boolean,sig,agg,background,filter,query,builders,terms,query,text,common,significant,terms,aggregation,builder,sig,num,agg,new,significant,terms,aggregation,builder,null,field,sig,num,agg,execution,hint,random,execution,hint,try,index,reader,reader,directory,reader,open,w,assert,equals,test,expects,a,single,segment,1,reader,leaves,size,index,searcher,searcher,new,index,searcher,reader,significant,terms,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,common,assert,not,null,terms,get,bucket,by,key,odd,terms,search,and,reduce,searcher,new,term,query,new,term,text,even,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,common,assert,not,null,terms,get,bucket,by,key,even,sig,agg,include,exclude,new,include,exclude,o,d,null,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,not,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,even,string,odd,strings,new,string,odd,weird,string,even,strings,new,string,even,regular,sig,agg,include,exclude,new,include,exclude,odd,strings,even,strings,sig,agg,significance,heuristic,significance,heuristic,tests,get,random,significanceheuristic,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,1,terms,get,buckets,size,assert,not,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,weird,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,regular,sig,agg,include,exclude,new,include,exclude,even,strings,odd,strings,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,0,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,odd,assert,null,terms,get,bucket,by,key,weird,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,regular
SignificantTermsAggregatorTests -> public void testUnmapped() throws IOException;1524684173;Uses the significant terms aggregation on an index with unmapped field;public void testUnmapped() throws IOException {_        TextFieldType textFieldType = new TextFieldType()__        textFieldType.setName("text")__        textFieldType.setFielddata(true)__        textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer", AnalyzerScope.GLOBAL, new StandardAnalyzer()))___        IndexWriterConfig indexWriterConfig = newIndexWriterConfig()__        indexWriterConfig.setMaxBufferedDocs(100)__        indexWriterConfig.setRAMBufferSizeMB(100)_ _        try (Directory dir = newDirectory()_ IndexWriter w = new IndexWriter(dir, indexWriterConfig)) {_            addMixedTextDocs(textFieldType, w)___            _            SignificantTermsAggregationBuilder sigAgg = new SignificantTermsAggregationBuilder("sig_text", null).field("unmapped_field")__            sigAgg.executionHint(randomExecutionHint())___            try (IndexReader reader = DirectoryReader.open(w)) {_                assertEquals("test expects a single segment", 1, reader.leaves().size())__                IndexSearcher searcher = new IndexSearcher(reader)___                _                SignificantTerms terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(0, terms.getBuckets().size())___                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("odd"))___            }_        }_    };uses,the,significant,terms,aggregation,on,an,index,with,unmapped,field;public,void,test,unmapped,throws,ioexception,text,field,type,text,field,type,new,text,field,type,text,field,type,set,name,text,text,field,type,set,fielddata,true,text,field,type,set,index,analyzer,new,named,analyzer,analyzer,scope,global,new,standard,analyzer,index,writer,config,index,writer,config,new,index,writer,config,index,writer,config,set,max,buffered,docs,100,index,writer,config,set,rambuffer,size,mb,100,try,directory,dir,new,directory,index,writer,w,new,index,writer,dir,index,writer,config,add,mixed,text,docs,text,field,type,w,significant,terms,aggregation,builder,sig,agg,new,significant,terms,aggregation,builder,null,field,sig,agg,execution,hint,random,execution,hint,try,index,reader,reader,directory,reader,open,w,assert,equals,test,expects,a,single,segment,1,reader,leaves,size,index,searcher,searcher,new,index,searcher,reader,significant,terms,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,0,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,odd
SignificantTermsAggregatorTests -> public void testUnmapped() throws IOException;1531937412;Uses the significant terms aggregation on an index with unmapped field;public void testUnmapped() throws IOException {_        TextFieldType textFieldType = new TextFieldType()__        textFieldType.setName("text")__        textFieldType.setFielddata(true)__        textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer", AnalyzerScope.GLOBAL, new StandardAnalyzer()))___        IndexWriterConfig indexWriterConfig = newIndexWriterConfig()__        indexWriterConfig.setMaxBufferedDocs(100)__        indexWriterConfig.setRAMBufferSizeMB(100)_ _        try (Directory dir = newDirectory()_ IndexWriter w = new IndexWriter(dir, indexWriterConfig)) {_            addMixedTextDocs(textFieldType, w)___            _            SignificantTermsAggregationBuilder sigAgg = new SignificantTermsAggregationBuilder("sig_text", null).field("unmapped_field")__            sigAgg.executionHint(randomExecutionHint())___            try (IndexReader reader = DirectoryReader.open(w)) {_                assertEquals("test expects a single segment", 1, reader.leaves().size())__                IndexSearcher searcher = new IndexSearcher(reader)___                _                SignificantTerms terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(0, terms.getBuckets().size())___                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("odd"))___            }_        }_    };uses,the,significant,terms,aggregation,on,an,index,with,unmapped,field;public,void,test,unmapped,throws,ioexception,text,field,type,text,field,type,new,text,field,type,text,field,type,set,name,text,text,field,type,set,fielddata,true,text,field,type,set,index,analyzer,new,named,analyzer,analyzer,scope,global,new,standard,analyzer,index,writer,config,index,writer,config,new,index,writer,config,index,writer,config,set,max,buffered,docs,100,index,writer,config,set,rambuffer,size,mb,100,try,directory,dir,new,directory,index,writer,w,new,index,writer,dir,index,writer,config,add,mixed,text,docs,text,field,type,w,significant,terms,aggregation,builder,sig,agg,new,significant,terms,aggregation,builder,null,field,sig,agg,execution,hint,random,execution,hint,try,index,reader,reader,directory,reader,open,w,assert,equals,test,expects,a,single,segment,1,reader,leaves,size,index,searcher,searcher,new,index,searcher,reader,significant,terms,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,0,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,odd
SignificantTermsAggregatorTests -> public void testUnmapped() throws IOException;1532028790;Uses the significant terms aggregation on an index with unmapped field;public void testUnmapped() throws IOException {_        TextFieldType textFieldType = new TextFieldType()__        textFieldType.setName("text")__        textFieldType.setFielddata(true)__        textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer", AnalyzerScope.GLOBAL, new StandardAnalyzer()))___        IndexWriterConfig indexWriterConfig = newIndexWriterConfig()__        indexWriterConfig.setMaxBufferedDocs(100)__        indexWriterConfig.setRAMBufferSizeMB(100)_ _        try (Directory dir = newDirectory()_ IndexWriter w = new IndexWriter(dir, indexWriterConfig)) {_            addMixedTextDocs(textFieldType, w)___            _            SignificantTermsAggregationBuilder sigAgg = new SignificantTermsAggregationBuilder("sig_text", null).field("unmapped_field")__            sigAgg.executionHint(randomExecutionHint())___            try (IndexReader reader = DirectoryReader.open(w)) {_                assertEquals("test expects a single segment", 1, reader.leaves().size())__                IndexSearcher searcher = new IndexSearcher(reader)___                _                SignificantTerms terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(0, terms.getBuckets().size())___                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("odd"))___            }_        }_    };uses,the,significant,terms,aggregation,on,an,index,with,unmapped,field;public,void,test,unmapped,throws,ioexception,text,field,type,text,field,type,new,text,field,type,text,field,type,set,name,text,text,field,type,set,fielddata,true,text,field,type,set,index,analyzer,new,named,analyzer,analyzer,scope,global,new,standard,analyzer,index,writer,config,index,writer,config,new,index,writer,config,index,writer,config,set,max,buffered,docs,100,index,writer,config,set,rambuffer,size,mb,100,try,directory,dir,new,directory,index,writer,w,new,index,writer,dir,index,writer,config,add,mixed,text,docs,text,field,type,w,significant,terms,aggregation,builder,sig,agg,new,significant,terms,aggregation,builder,null,field,sig,agg,execution,hint,random,execution,hint,try,index,reader,reader,directory,reader,open,w,assert,equals,test,expects,a,single,segment,1,reader,leaves,size,index,searcher,searcher,new,index,searcher,reader,significant,terms,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,0,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,odd
SignificantTermsAggregatorTests -> public void testUnmapped() throws IOException;1543834151;Uses the significant terms aggregation on an index with unmapped field;public void testUnmapped() throws IOException {_        TextFieldType textFieldType = new TextFieldType()__        textFieldType.setName("text")__        textFieldType.setFielddata(true)__        textFieldType.setIndexAnalyzer(new NamedAnalyzer("my_analyzer", AnalyzerScope.GLOBAL, new StandardAnalyzer()))___        IndexWriterConfig indexWriterConfig = newIndexWriterConfig()__        indexWriterConfig.setMaxBufferedDocs(100)__        indexWriterConfig.setRAMBufferSizeMB(100)_ _        try (Directory dir = newDirectory()_ IndexWriter w = new IndexWriter(dir, indexWriterConfig)) {_            addMixedTextDocs(textFieldType, w)___            _            SignificantTermsAggregationBuilder sigAgg = new SignificantTermsAggregationBuilder("sig_text", null).field("unmapped_field")__            sigAgg.executionHint(randomExecutionHint())___            try (IndexReader reader = DirectoryReader.open(w)) {_                assertEquals("test expects a single segment", 1, reader.leaves().size())__                IndexSearcher searcher = new IndexSearcher(reader)___                _                SignificantTerms terms = searchAndReduce(searcher, new TermQuery(new Term("text", "odd")), sigAgg, textFieldType)__                assertEquals(0, terms.getBuckets().size())___                assertNull(terms.getBucketByKey("even"))__                assertNull(terms.getBucketByKey("common"))__                assertNull(terms.getBucketByKey("odd"))___            }_        }_    };uses,the,significant,terms,aggregation,on,an,index,with,unmapped,field;public,void,test,unmapped,throws,ioexception,text,field,type,text,field,type,new,text,field,type,text,field,type,set,name,text,text,field,type,set,fielddata,true,text,field,type,set,index,analyzer,new,named,analyzer,analyzer,scope,global,new,standard,analyzer,index,writer,config,index,writer,config,new,index,writer,config,index,writer,config,set,max,buffered,docs,100,index,writer,config,set,rambuffer,size,mb,100,try,directory,dir,new,directory,index,writer,w,new,index,writer,dir,index,writer,config,add,mixed,text,docs,text,field,type,w,significant,terms,aggregation,builder,sig,agg,new,significant,terms,aggregation,builder,null,field,sig,agg,execution,hint,random,execution,hint,try,index,reader,reader,directory,reader,open,w,assert,equals,test,expects,a,single,segment,1,reader,leaves,size,index,searcher,searcher,new,index,searcher,reader,significant,terms,terms,search,and,reduce,searcher,new,term,query,new,term,text,odd,sig,agg,text,field,type,assert,equals,0,terms,get,buckets,size,assert,null,terms,get,bucket,by,key,even,assert,null,terms,get,bucket,by,key,common,assert,null,terms,get,bucket,by,key,odd
