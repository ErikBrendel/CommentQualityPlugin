commented;modifiers;parameterAmount;loc;comment;code
false;public;0;22;;public void testMatchAllDocs() throws IOException {     Query query = new MatchAllDocsQuery().     Script script = new Script(Script.DEFAULT_SCRIPT_TYPE, "painless", "test", Collections.emptyMap()).     DateHistogramAggregationBuilder aggBuilder = new DateHistogramAggregationBuilder("histo").     aggBuilder.dateHistogramInterval(DateHistogramInterval.DAY).field(DATE_FIELD).     aggBuilder.subAggregation(new AvgAggregationBuilder("avg").field(VALUE_FIELD)).     aggBuilder.subAggregation(new MovFnPipelineAggregationBuilder("mov_fn", "avg", script, 3)).     executeTestCase(query, aggBuilder, histogram -> {         assertEquals(10, histogram.getBuckets().size()).         List<? extends Histogram.Bucket> buckets = histogram.getBuckets().         for (int i = 0. i < buckets.size(). i++) {             if (i == 0) {                 assertThat(((InternalSimpleValue) (buckets.get(i).getAggregations().get("mov_fn"))).value(), equalTo(Double.NaN)).             } else {                 assertThat(((InternalSimpleValue) (buckets.get(i).getAggregations().get("mov_fn"))).value(), equalTo(((double) i))).             }         }     }, 1000, script). }
false;public;2;5;;@Override public double execute(Map<String, Object> params, double[] values) {     assertNotNull(values).     return MovingFunctions.max(values). }
false;private;5;57;;private void executeTestCase(Query query, DateHistogramAggregationBuilder aggBuilder, Consumer<Histogram> verify, int maxBucket, Script script) throws IOException {     try (Directory directory = newDirectory()) {         try (RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory)) {             Document document = new Document().             int counter = 0.             for (String date : datasetTimes) {                 if (frequently()) {                     indexWriter.commit().                 }                 long instant = asLong(date).                 document.add(new SortedNumericDocValuesField(DATE_FIELD, instant)).                 document.add(new LongPoint(INSTANT_FIELD, instant)).                 document.add(new NumericDocValuesField(VALUE_FIELD, datasetValues.get(counter))).                 indexWriter.addDocument(document).                 document.clear().                 counter += 1.             }         }         ScriptService scriptService = mock(ScriptService.class).         MovingFunctionScript.Factory factory = mock(MovingFunctionScript.Factory.class).         when(scriptService.compile(script, MovingFunctionScript.CONTEXT)).thenReturn(factory).         MovingFunctionScript scriptInstance = new MovingFunctionScript() {              @Override             public double execute(Map<String, Object> params, double[] values) {                 assertNotNull(values).                 return MovingFunctions.max(values).             }         }.         when(factory.newInstance()).thenReturn(scriptInstance).         try (IndexReader indexReader = DirectoryReader.open(directory)) {             IndexSearcher indexSearcher = newSearcher(indexReader, true, true).             DateFieldMapper.Builder builder = new DateFieldMapper.Builder("_name").             DateFieldMapper.DateFieldType fieldType = builder.fieldType().             fieldType.setHasDocValues(true).             fieldType.setName(aggBuilder.field()).             MappedFieldType valueFieldType = new NumberFieldMapper.NumberFieldType(NumberFieldMapper.NumberType.LONG).             valueFieldType.setHasDocValues(true).             valueFieldType.setName("value_field").             InternalDateHistogram histogram.             histogram = searchAndReduce(indexSearcher, query, aggBuilder, maxBucket, scriptService, new MappedFieldType[] { fieldType, valueFieldType }).             verify.accept(histogram).         }     } }
false;private,static;1;3;;private static long asLong(String dateTime) {     return DateFormatters.from(DateFieldMapper.DEFAULT_DATE_TIME_FORMATTER.parse(dateTime)).toInstant().toEpochMilli(). }
true;public;0;8;/**  * The validation should verify the parent aggregation is allowed.  */ ;/**  * The validation should verify the parent aggregation is allowed.  */ public void testValidate() throws IOException {     final Set<PipelineAggregationBuilder> aggBuilders = new HashSet<>().     Script script = new Script(Script.DEFAULT_SCRIPT_TYPE, "painless", "test", Collections.emptyMap()).     aggBuilders.add(new MovFnPipelineAggregationBuilder("mov_fn", "avg", script, 3)).     final MovFnPipelineAggregationBuilder builder = new MovFnPipelineAggregationBuilder("name", "invalid_agg>metric", script, 1).     builder.validate(PipelineAggregationHelperTests.getRandomSequentiallyOrderedParentAgg(), Collections.emptySet(), aggBuilders). }
true;public;0;12;/**  * The validation should throw an IllegalArgumentException, since parent  * aggregation is not a type of HistogramAggregatorFactory,  * DateHistogramAggregatorFactory or AutoDateHistogramAggregatorFactory.  */ ;/**  * The validation should throw an IllegalArgumentException, since parent  * aggregation is not a type of HistogramAggregatorFactory,  * DateHistogramAggregatorFactory or AutoDateHistogramAggregatorFactory.  */ public void testValidateException() throws IOException {     final Set<PipelineAggregationBuilder> aggBuilders = new HashSet<>().     Script script = new Script(Script.DEFAULT_SCRIPT_TYPE, "painless", "test", Collections.emptyMap()).     aggBuilders.add(new MovFnPipelineAggregationBuilder("mov_fn", "avg", script, 3)).     TestAggregatorFactory parentFactory = TestAggregatorFactory.createInstance().     final MovFnPipelineAggregationBuilder builder = new MovFnPipelineAggregationBuilder("name", "invalid_agg>metric", script, 1).     IllegalStateException ex = expectThrows(IllegalStateException.class, () -> builder.validate(parentFactory, Collections.emptySet(), aggBuilders)).     assertEquals("moving_fn aggregation [name] must have a histogram, date_histogram or auto_date_histogram as parent", ex.getMessage()). }
