commented;modifiers;parameterAmount;loc;comment;code
false;public;0;6;;@Before public void createServices() {     tempDir = createTempDir().     deterministicTaskQueue = new DeterministicTaskQueue(Settings.builder().put(NODE_NAME_SETTING.getKey(), "shared").build(), random()). }
false;public;0;4;;@After public void stopServices() {     testClusterNodes.nodes.values().forEach(TestClusterNode::stop). }
false;public;0;38;;public void testSuccessfulSnapshot() {     setupTestCluster(randomFrom(1, 3, 5), randomIntBetween(2, 10)).     String repoName = "repo".     String snapshotName = "snapshot".     final String index = "test".     final int shards = randomIntBetween(1, 10).     TestClusterNode masterNode = testClusterNodes.currentMaster(testClusterNodes.nodes.values().iterator().next().clusterService.state()).     final AtomicBoolean createdSnapshot = new AtomicBoolean().     masterNode.client.admin().cluster().preparePutRepository(repoName).setType(FsRepository.TYPE).setSettings(Settings.builder().put("location", randomAlphaOfLength(10))).execute(assertNoFailureListener(() -> masterNode.client.admin().indices().create(new CreateIndexRequest(index).waitForActiveShards(ActiveShardCount.ALL).settings(defaultIndexSettings(shards)), assertNoFailureListener(() -> masterNode.client.admin().cluster().prepareCreateSnapshot(repoName, snapshotName).execute(assertNoFailureListener(() -> createdSnapshot.set(true))))))).     deterministicTaskQueue.runAllRunnableTasks().     assertTrue(createdSnapshot.get()).     SnapshotsInProgress finalSnapshotsInProgress = masterNode.clusterService.state().custom(SnapshotsInProgress.TYPE).     assertFalse(finalSnapshotsInProgress.entries().stream().anyMatch(entry -> entry.state().completed() == false)).     final Repository repository = masterNode.repositoriesService.repository(repoName).     Collection<SnapshotId> snapshotIds = repository.getRepositoryData().getSnapshotIds().     assertThat(snapshotIds, hasSize(1)).     final SnapshotInfo snapshotInfo = repository.getSnapshotInfo(snapshotIds.iterator().next()).     assertEquals(SnapshotState.SUCCESS, snapshotInfo.state()).     assertThat(snapshotInfo.indices(), containsInAnyOrder(index)).     assertEquals(shards, snapshotInfo.successfulShards()).     assertEquals(0, snapshotInfo.failedShards()). }
false;public;0;69;;public void testSnapshotWithNodeDisconnects() {     final int dataNodes = randomIntBetween(2, 10).     setupTestCluster(randomFrom(1, 3, 5), dataNodes).     String repoName = "repo".     String snapshotName = "snapshot".     final String index = "test".     final int shards = randomIntBetween(1, 10).     TestClusterNode masterNode = testClusterNodes.currentMaster(testClusterNodes.nodes.values().iterator().next().clusterService.state()).     final AtomicBoolean createdSnapshot = new AtomicBoolean().     final AdminClient masterAdminClient = masterNode.client.admin().     masterNode.client.admin().cluster().preparePutRepository(repoName).setType(FsRepository.TYPE).setSettings(Settings.builder().put("location", randomAlphaOfLength(10))).execute(assertNoFailureListener(() -> masterNode.client.admin().indices().create(new CreateIndexRequest(index).waitForActiveShards(ActiveShardCount.ALL).settings(defaultIndexSettings(shards)), assertNoFailureListener(() -> {         for (int i = 0. i < randomIntBetween(0, dataNodes). ++i) {             scheduleNow(this::disconnectRandomDataNode).         }         if (randomBoolean()) {             scheduleNow(() -> testClusterNodes.clearNetworkDisruptions()).         }         masterAdminClient.cluster().prepareCreateSnapshot(repoName, snapshotName).execute(assertNoFailureListener(() -> {             for (int i = 0. i < randomIntBetween(0, dataNodes). ++i) {                 scheduleNow(this::disconnectOrRestartDataNode).             }             final boolean disconnectedMaster = randomBoolean().             if (disconnectedMaster) {                 scheduleNow(this::disconnectOrRestartMasterNode).             }             if (disconnectedMaster || randomBoolean()) {                 scheduleSoon(() -> testClusterNodes.clearNetworkDisruptions()).             } else if (randomBoolean()) {                 scheduleNow(() -> testClusterNodes.clearNetworkDisruptions()).             }             createdSnapshot.set(true).         })).     })))).     runUntil(() -> {         final Optional<TestClusterNode> randomMaster = testClusterNodes.randomMasterNode().         if (randomMaster.isPresent()) {             final SnapshotsInProgress snapshotsInProgress = randomMaster.get().clusterService.state().custom(SnapshotsInProgress.TYPE).             return snapshotsInProgress != null && snapshotsInProgress.entries().isEmpty().         }         return false.     }, TimeUnit.MINUTES.toMillis(1L)).     clearDisruptionsAndAwaitSync().     assertTrue(createdSnapshot.get()).     final TestClusterNode randomMaster = testClusterNodes.randomMasterNode().orElseThrow(() -> new AssertionError("expected to find at least one active master node")).     SnapshotsInProgress finalSnapshotsInProgress = randomMaster.clusterService.state().custom(SnapshotsInProgress.TYPE).     assertThat(finalSnapshotsInProgress.entries(), empty()).     final Repository repository = randomMaster.repositoriesService.repository(repoName).     Collection<SnapshotId> snapshotIds = repository.getRepositoryData().getSnapshotIds().     assertThat(snapshotIds, hasSize(1)). }
false;public;0;44;;public void testConcurrentSnapshotCreateAndDelete() {     setupTestCluster(randomFrom(1, 3, 5), randomIntBetween(2, 10)).     String repoName = "repo".     String snapshotName = "snapshot".     final String index = "test".     final int shards = randomIntBetween(1, 10).     TestClusterNode masterNode = testClusterNodes.currentMaster(testClusterNodes.nodes.values().iterator().next().clusterService.state()).     final AtomicBoolean createdSnapshot = new AtomicBoolean().     masterNode.client.admin().cluster().preparePutRepository(repoName).setType(FsRepository.TYPE).setSettings(Settings.builder().put("location", randomAlphaOfLength(10))).execute(assertNoFailureListener(() -> masterNode.client.admin().indices().create(new CreateIndexRequest(index).waitForActiveShards(ActiveShardCount.ALL).settings(defaultIndexSettings(shards)), assertNoFailureListener(() -> masterNode.client.admin().cluster().prepareCreateSnapshot(repoName, snapshotName).execute(assertNoFailureListener(() -> masterNode.client.admin().cluster().deleteSnapshot(new DeleteSnapshotRequest(repoName, snapshotName), assertNoFailureListener(() -> masterNode.client.admin().cluster().prepareCreateSnapshot(repoName, snapshotName).execute(assertNoFailureListener(() -> createdSnapshot.set(true))))))))))).     deterministicTaskQueue.runAllRunnableTasks().     assertTrue(createdSnapshot.get()).     SnapshotsInProgress finalSnapshotsInProgress = masterNode.clusterService.state().custom(SnapshotsInProgress.TYPE).     assertFalse(finalSnapshotsInProgress.entries().stream().anyMatch(entry -> entry.state().completed() == false)).     final Repository repository = masterNode.repositoriesService.repository(repoName).     Collection<SnapshotId> snapshotIds = repository.getRepositoryData().getSnapshotIds().     assertThat(snapshotIds, hasSize(1)).     final SnapshotInfo snapshotInfo = repository.getSnapshotInfo(snapshotIds.iterator().next()).     assertEquals(SnapshotState.SUCCESS, snapshotInfo.state()).     assertThat(snapshotInfo.indices(), containsInAnyOrder(index)).     assertEquals(shards, snapshotInfo.successfulShards()).     assertEquals(0, snapshotInfo.failedShards()). }
false;public;0;31;;@Override public void run() {     masterAdminClient.cluster().state(new ClusterStateRequest(), assertNoFailureListener(resp -> {         final ShardRouting shardRouting = resp.getState().routingTable().shardRoutingTable(shardToRelocate.shardId()).primaryShard().         if (shardRouting.unassigned() && shardRouting.unassignedInfo().getReason() == UnassignedInfo.Reason.NODE_LEFT) {             if (masterNodeCount > 1) {                 scheduleNow(() -> testClusterNodes.stopNode(masterNode)).             }             testClusterNodes.randomDataNodeSafe().client.admin().cluster().prepareCreateSnapshot(repoName, snapshotName).execute(ActionListener.wrap(() -> {                 testClusterNodes.randomDataNodeSafe().client.admin().cluster().deleteSnapshot(new DeleteSnapshotRequest(repoName, snapshotName), noopListener()).                 createdSnapshot.set(true).             })).             scheduleNow(() -> testClusterNodes.randomMasterNodeSafe().client.admin().cluster().reroute(new ClusterRerouteRequest().add(new AllocateEmptyPrimaryAllocationCommand(index, shardRouting.shardId().id(), otherNode.node.getName(), true)), noopListener())).         } else {             scheduleSoon(this).         }     })). }
true;public;0;88;/**  * Simulates concurrent restarts of data and master nodes as well as relocating a primary shard, while starting and subsequently  * deleting a snapshot.  */ ;/**  * Simulates concurrent restarts of data and master nodes as well as relocating a primary shard, while starting and subsequently  * deleting a snapshot.  */ public void testSnapshotPrimaryRelocations() {     final int masterNodeCount = randomFrom(1, 3, 5).     setupTestCluster(masterNodeCount, randomIntBetween(2, 10)).     String repoName = "repo".     String snapshotName = "snapshot".     final String index = "test".     final int shards = randomIntBetween(1, 10).     final TestClusterNode masterNode = testClusterNodes.currentMaster(testClusterNodes.nodes.values().iterator().next().clusterService.state()).     final AtomicBoolean createdSnapshot = new AtomicBoolean().     final AdminClient masterAdminClient = masterNode.client.admin().     masterAdminClient.cluster().preparePutRepository(repoName).setType(FsRepository.TYPE).setSettings(Settings.builder().put("location", randomAlphaOfLength(10))).execute(assertNoFailureListener(() -> masterAdminClient.indices().create(new CreateIndexRequest(index).waitForActiveShards(ActiveShardCount.ALL).settings(defaultIndexSettings(shards)), assertNoFailureListener(() -> masterAdminClient.cluster().state(new ClusterStateRequest(), assertNoFailureListener(clusterStateResponse -> {         final ShardRouting shardToRelocate = clusterStateResponse.getState().routingTable().allShards(index).get(0).         final TestClusterNode currentPrimaryNode = testClusterNodes.nodeById(shardToRelocate.currentNodeId()).         final TestClusterNode otherNode = testClusterNodes.randomDataNodeSafe(currentPrimaryNode.node.getName()).         final Runnable maybeForceAllocate = new Runnable() {              @Override             public void run() {                 masterAdminClient.cluster().state(new ClusterStateRequest(), assertNoFailureListener(resp -> {                     final ShardRouting shardRouting = resp.getState().routingTable().shardRoutingTable(shardToRelocate.shardId()).primaryShard().                     if (shardRouting.unassigned() && shardRouting.unassignedInfo().getReason() == UnassignedInfo.Reason.NODE_LEFT) {                         if (masterNodeCount > 1) {                             scheduleNow(() -> testClusterNodes.stopNode(masterNode)).                         }                         testClusterNodes.randomDataNodeSafe().client.admin().cluster().prepareCreateSnapshot(repoName, snapshotName).execute(ActionListener.wrap(() -> {                             testClusterNodes.randomDataNodeSafe().client.admin().cluster().deleteSnapshot(new DeleteSnapshotRequest(repoName, snapshotName), noopListener()).                             createdSnapshot.set(true).                         })).                         scheduleNow(() -> testClusterNodes.randomMasterNodeSafe().client.admin().cluster().reroute(new ClusterRerouteRequest().add(new AllocateEmptyPrimaryAllocationCommand(index, shardRouting.shardId().id(), otherNode.node.getName(), true)), noopListener())).                     } else {                         scheduleSoon(this).                     }                 })).             }         }.         scheduleNow(() -> testClusterNodes.stopNode(currentPrimaryNode)).         scheduleNow(maybeForceAllocate).     })))))).     runUntil(() -> {         final Optional<TestClusterNode> randomMaster = testClusterNodes.randomMasterNode().         if (randomMaster.isPresent()) {             final SnapshotsInProgress snapshotsInProgress = randomMaster.get().clusterService.state().custom(SnapshotsInProgress.TYPE).             return (snapshotsInProgress == null || snapshotsInProgress.entries().isEmpty()) && createdSnapshot.get().         }         return false.     }, TimeUnit.MINUTES.toMillis(1L)).     clearDisruptionsAndAwaitSync().     assertTrue(createdSnapshot.get()).     final SnapshotsInProgress finalSnapshotsInProgress = testClusterNodes.randomDataNodeSafe().clusterService.state().custom(SnapshotsInProgress.TYPE).     assertThat(finalSnapshotsInProgress.entries(), empty()).     final Repository repository = masterNode.repositoriesService.repository(repoName).     Collection<SnapshotId> snapshotIds = repository.getRepositoryData().getSnapshotIds().     assertThat(snapshotIds, either(hasSize(1)).or(hasSize(0))). }
false;private;0;8;;private void clearDisruptionsAndAwaitSync() {     testClusterNodes.clearNetworkDisruptions().     runUntil(() -> {         final List<Long> versions = testClusterNodes.nodes.values().stream().map(n -> n.clusterService.state().version()).distinct().collect(Collectors.toList()).         return versions.size() == 1L.     }, TimeUnit.MINUTES.toMillis(1L)). }
false;private;0;7;;private void disconnectOrRestartDataNode() {     if (randomBoolean()) {         disconnectRandomDataNode().     } else {         testClusterNodes.randomDataNode().ifPresent(TestClusterNode::restart).     } }
false;private;0;9;;private void disconnectOrRestartMasterNode() {     testClusterNodes.randomMasterNode().ifPresent(masterNode -> {         if (randomBoolean()) {             testClusterNodes.disconnectNode(masterNode).         } else {             masterNode.restart().         }     }). }
false;private;0;3;;private void disconnectRandomDataNode() {     testClusterNodes.randomDataNode().ifPresent(n -> testClusterNodes.disconnectNode(n)). }
false;private;0;23;;private void startCluster() {     final ClusterState initialClusterState = new ClusterState.Builder(ClusterName.DEFAULT).nodes(testClusterNodes.discoveryNodes()).build().     testClusterNodes.nodes.values().forEach(testClusterNode -> testClusterNode.start(initialClusterState)).     deterministicTaskQueue.advanceTime().     deterministicTaskQueue.runAllRunnableTasks().     final VotingConfiguration votingConfiguration = new VotingConfiguration(testClusterNodes.nodes.values().stream().map(n -> n.node).filter(DiscoveryNode::isMasterNode).map(DiscoveryNode::getId).collect(Collectors.toSet())).     testClusterNodes.nodes.values().stream().filter(n -> n.node.isMasterNode()).forEach(testClusterNode -> testClusterNode.coordinator.setInitialConfiguration(votingConfiguration)).     runUntil(() -> {         List<String> masterNodeIds = testClusterNodes.nodes.values().stream().map(node -> node.clusterService.state().nodes().getMasterNodeId()).distinct().collect(Collectors.toList()).         return masterNodeIds.size() == 1 && masterNodeIds.contains(null) == false.     }, TimeUnit.SECONDS.toMillis(30L)). }
false;private;2;11;;private void runUntil(Supplier<Boolean> fulfilled, long timeout) {     final long start = deterministicTaskQueue.getCurrentTimeMillis().     while (timeout > deterministicTaskQueue.getCurrentTimeMillis() - start) {         if (fulfilled.get()) {             return.         }         deterministicTaskQueue.runAllRunnableTasks().         deterministicTaskQueue.advanceTime().     }     fail("Condition wasn't fulfilled."). }
false;private;2;4;;private void setupTestCluster(int masterNodes, int dataNodes) {     testClusterNodes = new TestClusterNodes(masterNodes, dataNodes).     startCluster(). }
false;private;1;3;;private void scheduleSoon(Runnable runnable) {     deterministicTaskQueue.scheduleAt(deterministicTaskQueue.getCurrentTimeMillis() + randomLongBetween(0, 100L), runnable). }
false;private;1;3;;private void scheduleNow(Runnable runnable) {     deterministicTaskQueue.scheduleNow(runnable). }
false;private,static;1;6;;private static Settings defaultIndexSettings(int shards) {     // TODO: randomize replica count settings once recovery operations aren't blocking anymore     return Settings.builder().put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), shards).put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 0).build(). }
false;public;1;4;;@Override public void onResponse(final T t) {     consumer.accept(t). }
false;public;1;4;;@Override public void onFailure(final Exception e) {     throw new AssertionError(e). }
false;private,static;1;13;;private static <T> ActionListener<T> assertNoFailureListener(Consumer<T> consumer) {     return new ActionListener<T>() {          @Override         public void onResponse(final T t) {             consumer.accept(t).         }          @Override         public void onFailure(final Exception e) {             throw new AssertionError(e).         }     }. }
false;public;1;4;;@Override public void onResponse(final T t) {     r.run(). }
false;public;1;4;;@Override public void onFailure(final Exception e) {     throw new AssertionError(e). }
false;private,static;1;13;;private static <T> ActionListener<T> assertNoFailureListener(Runnable r) {     return new ActionListener<T>() {          @Override         public void onResponse(final T t) {             r.run().         }          @Override         public void onFailure(final Exception e) {             throw new AssertionError(e).         }     }. }
false;public;1;3;;@Override public void onResponse(final T t) { }
false;public;1;3;;@Override public void onFailure(final Exception e) { }
false;private,static;0;11;;private static <T> ActionListener<T> noopListener() {     return new ActionListener<T>() {          @Override         public void onResponse(final T t) {         }          @Override         public void onFailure(final Exception e) {         }     }. }
true;private;1;9;/**  * Create a {@link Environment} with random path.home and path.repo  */ ;/**  * Create a {@link Environment} with random path.home and path.repo  */ private Environment createEnvironment(String nodeName) {     return TestEnvironment.newEnvironment(Settings.builder().put(NODE_NAME_SETTING.getKey(), nodeName).put(PATH_HOME_SETTING.getKey(), tempDir.resolve(nodeName).toAbsolutePath()).put(Environment.PATH_REPO_SETTING.getKey(), tempDir.resolve("repo").toAbsolutePath()).putList(ClusterBootstrapService.INITIAL_MASTER_NODES_SETTING.getKey(), ClusterBootstrapService.INITIAL_MASTER_NODES_SETTING.get(Settings.EMPTY)).build()). }
false;private,static;2;3;;private static ClusterState stateForNode(ClusterState state, DiscoveryNode node) {     return ClusterState.builder(state).nodes(DiscoveryNodes.builder(state.nodes()).localNodeId(node.getId())).build(). }
false;public;1;4;;public TestClusterNode nodeById(final String nodeId) {     return nodes.values().stream().filter(n -> n.node.getId().equals(nodeId)).findFirst().orElseThrow(() -> new AssertionError("Could not find node by id [" + nodeId + ']')). }
false;private;1;3;;private TestClusterNode newMasterNode(String nodeName) throws IOException {     return newNode(nodeName, DiscoveryNode.Role.MASTER). }
false;private;1;3;;private TestClusterNode newDataNode(String nodeName) throws IOException {     return newNode(nodeName, DiscoveryNode.Role.DATA). }
false;private;2;5;;private TestClusterNode newNode(String nodeName, DiscoveryNode.Role role) throws IOException {     return new TestClusterNode(new DiscoveryNode(nodeName, randomAlphaOfLength(10), buildNewFakeTransportAddress(), emptyMap(), Collections.singleton(role), Version.CURRENT), this::getDisruption). }
false;public;0;3;;public TestClusterNode randomMasterNodeSafe() {     return randomMasterNode().orElseThrow(() -> new AssertionError("Expected to find at least one connected master node")). }
false;public;0;6;;public Optional<TestClusterNode> randomMasterNode() {     // Select from sorted list of data-nodes here to not have deterministic behaviour     final List<TestClusterNode> masterNodes = testClusterNodes.nodes.values().stream().filter(n -> n.node.isMasterNode()).sorted(Comparator.comparing(n -> n.node.getName())).collect(Collectors.toList()).     return masterNodes.isEmpty() ? Optional.empty() : Optional.of(randomFrom(masterNodes)). }
false;public;1;4;;public void stopNode(TestClusterNode node) {     node.stop().     nodes.remove(node.node.getName()). }
false;public;1;3;;public TestClusterNode randomDataNodeSafe(String... excludedNames) {     return randomDataNode(excludedNames).orElseThrow(() -> new AssertionError("Could not find another data node.")). }
false;public;1;14;;public Optional<TestClusterNode> randomDataNode(String... excludedNames) {     // Select from sorted list of data-nodes here to not have deterministic behaviour     final List<TestClusterNode> dataNodes = testClusterNodes.nodes.values().stream().filter(n -> n.node.isDataNode()).filter(n -> {         for (final String nodeName : excludedNames) {             if (n.node.getName().equals(nodeName)) {                 return false.             }         }         return true.     }).sorted(Comparator.comparing(n -> n.node.getName())).collect(Collectors.toList()).     return dataNodes.isEmpty() ? Optional.empty() : Optional.ofNullable(randomFrom(dataNodes)). }
false;public;1;7;;public void disconnectNode(TestClusterNode node) {     if (disruptedLinks.disconnected.contains(node.node.getName())) {         return.     }     testClusterNodes.nodes.values().forEach(n -> n.transportService.getConnectionManager().disconnectFromNode(node.node)).     disruptedLinks.disconnect(node.node.getName()). }
false;public;0;9;;public void clearNetworkDisruptions() {     disruptedLinks.disconnected.forEach(nodeName -> {         if (testClusterNodes.nodes.containsKey(nodeName)) {             final DiscoveryNode node = testClusterNodes.nodes.get(nodeName).node.             testClusterNodes.nodes.values().forEach(n -> n.transportService.getConnectionManager().openConnection(node, null)).         }     }).     disruptedLinks.clear(). }
false;private;0;3;;private NetworkDisruption.DisruptedLinks getDisruption() {     return disruptedLinks. }
true;public;0;5;/**  * Builds a {@link DiscoveryNodes} instance that holds the nodes in this test cluster.  * @return DiscoveryNodes  */ ;/**  * Builds a {@link DiscoveryNodes} instance that holds the nodes in this test cluster.  * @return DiscoveryNodes  */ public DiscoveryNodes discoveryNodes() {     DiscoveryNodes.Builder builder = DiscoveryNodes.builder().     nodes.values().forEach(node -> builder.add(node.node)).     return builder.build(). }
true;public;1;6;/**  * Returns the {@link TestClusterNode} for the master node in the given {@link ClusterState}.  * @param state ClusterState  * @return Master Node  */ ;/**  * Returns the {@link TestClusterNode} for the master node in the given {@link ClusterState}.  * @param state ClusterState  * @return Master Node  */ public TestClusterNode currentMaster(ClusterState state) {     TestClusterNode master = nodes.get(state.nodes().getMasterNode().getName()).     assertNotNull(master).     assertTrue(master.node.isMasterNode()).     return master. }
false;protected;0;4;;@Override protected PrioritizedEsThreadPoolExecutor createThreadPoolExecutor() {     return new MockSinglePrioritizingExecutor(node.getName(), deterministicTaskQueue). }
false;protected;1;5;;@Override protected ConnectionStatus getConnectionStatus(DiscoveryNode destination) {     return disruption.get().disrupt(node.getName(), destination.getName()) ? ConnectionStatus.DISCONNECTED : ConnectionStatus.CONNECTED. }
false;protected;1;6;;@Override protected Optional<DisruptableMockTransport> getDisruptableMockTransport(TransportAddress address) {     return testClusterNodes.nodes.values().stream().map(cn -> cn.mockTransport).filter(transport -> transport.getLocalNode().getAddress().equals(address)).findAny(). }
false;protected;1;4;;@Override protected void execute(Runnable runnable) {     scheduleNow(CoordinatorTests.onNodeLog(getLocalNode(), runnable)). }
false;protected;0;4;;@Override protected NamedWriteableRegistry writeableRegistry() {     return namedWriteableRegistry. }
false;protected;0;4;;@Override protected void doRun() throws Exception {     channel.sendResponse(new TransportException(new IOException("failed to recover shard"))). }
false;public;1;4;;@Override public void onFailure(final Exception e) {     throw new AssertionError(e). }
false;public;4;21;;@Override public <T extends TransportRequest> TransportRequestHandler<T> interceptHandler(String action, String executor, boolean forceExecution, TransportRequestHandler<T> actualHandler) {     // TODO: Remove this hack once recoveries are async and can be used in these tests     if (action.startsWith("internal:index/shard/recovery")) {         return (request, channel, task) -> scheduleSoon(new AbstractRunnable() {              @Override             protected void doRun() throws Exception {                 channel.sendResponse(new TransportException(new IOException("failed to recover shard"))).             }              @Override             public void onFailure(final Exception e) {                 throw new AssertionError(e).             }         }).     } else {         return actualHandler.     } }
false;protected;0;4;;@Override protected void assertSnapshotOrGenericThread() { // eliminate thread name check as we create repo in the test thread }
false;public;0;17;;public void restart() {     testClusterNodes.disconnectNode(this).     final ClusterState oldState = this.clusterService.state().     stop().     testClusterNodes.nodes.remove(node.getName()).     scheduleSoon(() -> {         try {             final TestClusterNode restartedNode = new TestClusterNode(new DiscoveryNode(node.getName(), node.getId(), node.getAddress(), emptyMap(), node.getRoles(), Version.CURRENT), disruption).             testClusterNodes.nodes.put(node.getName(), restartedNode).             restartedNode.start(oldState).         } catch (IOException e) {             throw new AssertionError(e).         }     }). }
false;public;0;10;;public void stop() {     testClusterNodes.disconnectNode(this).     indicesService.close().     clusterService.close().     indicesClusterStateService.close().     if (coordinator != null) {         coordinator.close().     }     nodeEnv.close(). }
false;public;1;15;;@Override public void connectToNodes(DiscoveryNodes discoveryNodes) {     // override this method as it does blocking calls     boolean callSuper = true.     for (final DiscoveryNode node : discoveryNodes) {         try {             transportService.connectToNode(node).         } catch (Exception e) {             callSuper = false.         }     }     if (callSuper) {         super.connectToNodes(discoveryNodes).     } }
false;public;1;39;;public void start(ClusterState initialState) {     transportService.start().     transportService.acceptIncomingRequests().     snapshotsService.start().     snapshotShardsService.start().     final CoordinationState.PersistedState persistedState = new InMemoryPersistedState(initialState.term(), stateForNode(initialState, node)).     coordinator = new Coordinator(node.getName(), clusterService.getSettings(), clusterService.getClusterSettings(), transportService, namedWriteableRegistry, allocationService, masterService, () -> persistedState, hostsResolver -> testClusterNodes.nodes.values().stream().filter(n -> n.node.isMasterNode()).map(n -> n.node.getAddress()).collect(Collectors.toList()), clusterService.getClusterApplierService(), Collections.emptyList(), random()).     masterService.setClusterStatePublisher(coordinator).     coordinator.start().     masterService.start().     clusterService.getClusterApplierService().setNodeConnectionsService(new NodeConnectionsService(clusterService.getSettings(), threadPool, transportService) {          @Override         public void connectToNodes(DiscoveryNodes discoveryNodes) {             // override this method as it does blocking calls             boolean callSuper = true.             for (final DiscoveryNode node : discoveryNodes) {                 try {                     transportService.connectToNode(node).                 } catch (Exception e) {                     callSuper = false.                 }             }             if (callSuper) {                 super.connectToNodes(discoveryNodes).             }         }     }).     clusterService.getClusterApplierService().start().     indicesService.start().     indicesClusterStateService.start().     coordinator.startInitialJoin(). }
false;public;2;12;;@Override public boolean disrupt(String node1, String node2) {     if (node1.equals(node2)) {         return false.     }     // Check if both nodes are still part of the cluster     if (testClusterNodes.nodes.containsKey(node1) == false || testClusterNodes.nodes.containsKey(node2) == false) {         return true.     }     return disconnected.contains(node1) || disconnected.contains(node2). }
false;public;1;3;;public void disconnect(String node) {     disconnected.add(node). }
false;public;0;3;;public void clear() {     disconnected.clear(). }
