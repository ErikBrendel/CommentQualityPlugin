commented;modifiers;parameterAmount;loc;comment;code
false;public;0;19;;public void testBasics() throws IOException {     Settings settings = Settings.builder().putList("index.analysis.normalizer.my_normalizer.filter", "lowercase").put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).build().     ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(settings, MOCK_ANALYSIS_PLUGIN).     assertNull(analysis.indexAnalyzers.get("my_normalizer")).     NamedAnalyzer normalizer = analysis.indexAnalyzers.getNormalizer("my_normalizer").     assertNotNull(normalizer).     assertEquals("my_normalizer", normalizer.name()).     assertTokenStreamContents(normalizer.tokenStream("foo", "Cet été-là"), new String[] { "cet été-là" }).     assertEquals(new BytesRef("cet été-là"), normalizer.normalize("foo", "Cet été-là")).     normalizer = analysis.indexAnalyzers.getWhitespaceNormalizer("my_normalizer").     assertNotNull(normalizer).     assertEquals("my_normalizer", normalizer.name()).     assertTokenStreamContents(normalizer.tokenStream("foo", "Cet été-là"), new String[] { "cet", "été-là" }).     assertEquals(new BytesRef("cet été-là"), normalizer.normalize("foo", "Cet été-là")). }
false;public;0;10;;public void testUnknownType() {     Settings settings = Settings.builder().put("index.analysis.normalizer.my_normalizer.type", "foobar").putList("index.analysis.normalizer.my_normalizer.filter", "lowercase", "asciifolding").put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).build().     IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> AnalysisTestsHelper.createTestAnalysisFromSettings(settings)).     assertEquals("Unknown normalizer type [foobar] for [my_normalizer]", e.getMessage()). }
false;public;0;9;;public void testTokenizer() throws IOException {     Settings settings = Settings.builder().put("index.analysis.normalizer.my_normalizer.tokenizer", "keyword").put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).build().     IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> AnalysisTestsHelper.createTestAnalysisFromSettings(settings, MOCK_ANALYSIS_PLUGIN)).     assertEquals("Custom normalizer [my_normalizer] cannot configure a tokenizer", e.getMessage()). }
false;public;0;20;;public void testCharFilters() throws IOException {     Settings settings = Settings.builder().put("index.analysis.char_filter.my_mapping.type", "mock_char_filter").putList("index.analysis.normalizer.my_normalizer.char_filter", "my_mapping").put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).build().     ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(settings, MOCK_ANALYSIS_PLUGIN).     assertNull(analysis.indexAnalyzers.get("my_normalizer")).     NamedAnalyzer normalizer = analysis.indexAnalyzers.getNormalizer("my_normalizer").     assertNotNull(normalizer).     assertEquals("my_normalizer", normalizer.name()).     assertTokenStreamContents(normalizer.tokenStream("foo", "abc acd"), new String[] { "zbc zcd" }).     assertEquals(new BytesRef("zbc"), normalizer.normalize("foo", "abc")).     normalizer = analysis.indexAnalyzers.getWhitespaceNormalizer("my_normalizer").     assertNotNull(normalizer).     assertEquals("my_normalizer", normalizer.name()).     assertTokenStreamContents(normalizer.tokenStream("foo", "abc acd"), new String[] { "zbc", "zcd" }).     assertEquals(new BytesRef("zbc"), normalizer.normalize("foo", "abc")). }
false;public;0;9;;public void testIllegalFilters() throws IOException {     Settings settings = Settings.builder().putList("index.analysis.normalizer.my_normalizer.filter", "mock_forbidden").put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).build().     IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> AnalysisTestsHelper.createTestAnalysisFromSettings(settings, MOCK_ANALYSIS_PLUGIN)).     assertEquals("Custom normalizer [my_normalizer] may not use filter [mock_forbidden]", e.getMessage()). }
false;public;0;9;;public void testIllegalCharFilters() throws IOException {     Settings settings = Settings.builder().putList("index.analysis.normalizer.my_normalizer.char_filter", "mock_forbidden").put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).build().     IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> AnalysisTestsHelper.createTestAnalysisFromSettings(settings, MOCK_ANALYSIS_PLUGIN)).     assertEquals("Custom normalizer [my_normalizer] may not use char filter [mock_forbidden]", e.getMessage()). }
false;public;0;4;;@Override public List<PreConfiguredTokenFilter> getPreConfiguredTokenFilters() {     return singletonList(PreConfiguredTokenFilter.singleton("mock_forbidden", false, MockLowerCaseFilter::new)). }
false;public;0;4;;@Override public List<PreConfiguredCharFilter> getPreConfiguredCharFilters() {     return singletonList(PreConfiguredCharFilter.singleton("mock_forbidden", false, Function.identity())). }
false;public;0;4;;@Override public String name() {     return name. }
false;public;3;10;;@Override public int read(char[] cbuf, int off, int len) throws IOException {     int result = reader.read(cbuf, off, len).     for (int i = off. i < off + len. i++) {         if (cbuf[i] == 'a') {             cbuf[i] = 'z'.         }     }     return result. }
false;public;0;4;;@Override public void close() throws IOException {     reader.close(). }
false;public;1;20;;@Override public Reader create(Reader reader) {     return new Reader() {          @Override         public int read(char[] cbuf, int off, int len) throws IOException {             int result = reader.read(cbuf, off, len).             for (int i = off. i < off + len. i++) {                 if (cbuf[i] == 'a') {                     cbuf[i] = 'z'.                 }             }             return result.         }          @Override         public void close() throws IOException {             reader.close().         }     }. }
false;public;0;32;;@Override public Map<String, AnalysisProvider<CharFilterFactory>> getCharFilters() {     return singletonMap("mock_char_filter", (indexSettings, env, name, settings) -> {         class Factory implements NormalizingCharFilterFactory {              @Override             public String name() {                 return name.             }              @Override             public Reader create(Reader reader) {                 return new Reader() {                      @Override                     public int read(char[] cbuf, int off, int len) throws IOException {                         int result = reader.read(cbuf, off, len).                         for (int i = off. i < off + len. i++) {                             if (cbuf[i] == 'a') {                                 cbuf[i] = 'z'.                             }                         }                         return result.                     }                      @Override                     public void close() throws IOException {                         reader.close().                     }                 }.             }         }         return new Factory().     }). }
false;public;0;5;;@Override public Map<String, AnalysisProvider<TokenizerFactory>> getTokenizers() {     return singletonMap("keyword", (indexSettings, environment, name, settings) -> () -> new MockTokenizer(MockTokenizer.KEYWORD, false)). }
