commented;modifiers;parameterAmount;loc;comment;code
false;public;0;71;;public void testGetStartingSeqNo() throws Exception {     final IndexShard replica = newShard(false).     try {         // Empty store         {             recoveryEmptyReplica(replica, true).             final RecoveryTarget recoveryTarget = new RecoveryTarget(replica, null, null, null).             assertThat(PeerRecoveryTargetService.getStartingSeqNo(logger, recoveryTarget), equalTo(0L)).             recoveryTarget.decRef().         }         // Last commit is good - use it.         final long initDocs = scaledRandomIntBetween(1, 10).         {             for (int i = 0. i < initDocs. i++) {                 indexDoc(replica, "_doc", Integer.toString(i)).                 if (randomBoolean()) {                     flushShard(replica).                 }             }             flushShard(replica).             replica.updateGlobalCheckpointOnReplica(initDocs - 1, "test").             replica.sync().             final RecoveryTarget recoveryTarget = new RecoveryTarget(replica, null, null, null).             assertThat(PeerRecoveryTargetService.getStartingSeqNo(logger, recoveryTarget), equalTo(initDocs)).             recoveryTarget.decRef().         }         // Global checkpoint does not advance, last commit is not good - use the previous commit         final int moreDocs = randomIntBetween(1, 10).         {             for (int i = 0. i < moreDocs. i++) {                 indexDoc(replica, "_doc", Long.toString(i)).                 if (randomBoolean()) {                     flushShard(replica).                 }             }             flushShard(replica).             final RecoveryTarget recoveryTarget = new RecoveryTarget(replica, null, null, null).             assertThat(PeerRecoveryTargetService.getStartingSeqNo(logger, recoveryTarget), equalTo(initDocs)).             recoveryTarget.decRef().         }         // Advances the global checkpoint, a safe commit also advances         {             replica.updateGlobalCheckpointOnReplica(initDocs + moreDocs - 1, "test").             replica.sync().             final RecoveryTarget recoveryTarget = new RecoveryTarget(replica, null, null, null).             assertThat(PeerRecoveryTargetService.getStartingSeqNo(logger, recoveryTarget), equalTo(initDocs + moreDocs)).             recoveryTarget.decRef().         }         // Different translogUUID, fallback to file-based         {             replica.close("test", false).             final List<IndexCommit> commits = DirectoryReader.listCommits(replica.store().directory()).             IndexWriterConfig iwc = new IndexWriterConfig(null).setSoftDeletesField(Lucene.SOFT_DELETES_FIELD).setCommitOnClose(false).setMergePolicy(NoMergePolicy.INSTANCE).setOpenMode(IndexWriterConfig.OpenMode.APPEND).             try (IndexWriter writer = new IndexWriter(replica.store().directory(), iwc)) {                 final Map<String, String> userData = new HashMap<>(commits.get(commits.size() - 1).getUserData()).                 userData.put(Translog.TRANSLOG_UUID_KEY, UUIDs.randomBase64UUID()).                 writer.setLiveCommitData(userData.entrySet()).                 writer.commit().             }             final RecoveryTarget recoveryTarget = new RecoveryTarget(replica, null, null, null).             assertThat(PeerRecoveryTargetService.getStartingSeqNo(logger, recoveryTarget), equalTo(SequenceNumbers.UNASSIGNED_SEQ_NO)).             recoveryTarget.decRef().         }     } finally {         closeShards(replica).     } }
false;public;0;69;;public void testWriteFileChunksConcurrently() throws Exception {     IndexShard sourceShard = newStartedShard(true).     int numDocs = between(20, 100).     for (int i = 0. i < numDocs. i++) {         indexDoc(sourceShard, "_doc", Integer.toString(i)).     }     sourceShard.flush(new FlushRequest()).     Store.MetadataSnapshot sourceSnapshot = sourceShard.store().getMetadata(null).     List<StoreFileMetaData> mdFiles = new ArrayList<>().     for (StoreFileMetaData md : sourceSnapshot) {         mdFiles.add(md).     }     final IndexShard targetShard = newShard(false).     final DiscoveryNode pNode = getFakeDiscoNode(sourceShard.routingEntry().currentNodeId()).     final DiscoveryNode rNode = getFakeDiscoNode(targetShard.routingEntry().currentNodeId()).     targetShard.markAsRecovering("test-peer-recovery", new RecoveryState(targetShard.routingEntry(), rNode, pNode)).     final RecoveryTarget recoveryTarget = new RecoveryTarget(targetShard, null, null, null).     recoveryTarget.receiveFileInfo(mdFiles.stream().map(StoreFileMetaData::name).collect(Collectors.toList()), mdFiles.stream().map(StoreFileMetaData::length).collect(Collectors.toList()), Collections.emptyList(), Collections.emptyList(), 0).     List<RecoveryFileChunkRequest> requests = new ArrayList<>().     for (StoreFileMetaData md : mdFiles) {         try (IndexInput in = sourceShard.store().directory().openInput(md.name(), IOContext.READONCE)) {             int pos = 0.             while (pos < md.length()) {                 int length = between(1, Math.toIntExact(md.length() - pos)).                 byte[] buffer = new byte[length].                 in.readBytes(buffer, 0, length).                 requests.add(new RecoveryFileChunkRequest(0, sourceShard.shardId(), md, pos, new BytesArray(buffer), pos + length == md.length(), 1, 1)).                 pos += length.             }         }     }     Randomness.shuffle(requests).     BlockingQueue<RecoveryFileChunkRequest> queue = new ArrayBlockingQueue<>(requests.size()).     queue.addAll(requests).     Thread[] senders = new Thread[between(1, 4)].     CyclicBarrier barrier = new CyclicBarrier(senders.length).     for (int i = 0. i < senders.length. i++) {         senders[i] = new Thread(() -> {             try {                 barrier.await().                 RecoveryFileChunkRequest r.                 while ((r = queue.poll()) != null) {                     recoveryTarget.writeFileChunk(r.metadata(), r.position(), r.content(), r.lastChunk(), r.totalTranslogOps(), ActionListener.wrap(ignored -> {                     }, e -> {                         throw new AssertionError(e).                     })).                 }             } catch (Exception e) {                 throw new AssertionError(e).             }         }).         senders[i].start().     }     for (Thread sender : senders) {         sender.join().     }     recoveryTarget.cleanFiles(0, sourceSnapshot).     recoveryTarget.decRef().     Store.MetadataSnapshot targetSnapshot = targetShard.snapshotStoreMetadata().     Store.RecoveryDiff diff = sourceSnapshot.recoveryDiff(targetSnapshot).     assertThat(diff.different, empty()).     closeShards(sourceShard, targetShard). }
