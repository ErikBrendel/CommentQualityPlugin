commented;modifiers;parameterAmount;loc;comment;code
false;public;0;4;;@Override public String toString() {     return name. }
false;private;2;15;;private ValuesSourceAggregationBuilder<? extends ValuesSource, ? extends ValuesSourceAggregationBuilder<?, ?>> randomMetric(String name, String field) {     int rand = randomIntBetween(0, 3).     switch(rand) {         case 0:             return min(name).field(field).         case 2:             return max(name).field(field).         case 3:             return avg(name).field(field).         default:             return avg(name).field(field).     } }
false;private;3;11;;private void assertValidIterators(Iterator expectedBucketIter, Iterator expectedCountsIter, Iterator expectedValuesIter) {     if (!expectedBucketIter.hasNext()) {         fail("`expectedBucketIter` iterator ended before `actual` iterator, size mismatch").     }     if (!expectedCountsIter.hasNext()) {         fail("`expectedCountsIter` iterator ended before `actual` iterator, size mismatch").     }     if (!expectedValuesIter.hasNext()) {         fail("`expectedValuesIter` iterator ended before `actual` iterator, size mismatch").     } }
false;private;3;21;;private void assertBucketContents(Histogram.Bucket actual, Double expectedCount, Double expectedValue) {     // This is a gap bucket     SimpleValue countDiff = actual.getAggregations().get("diff_counts").     if (expectedCount == null) {         assertThat("[_count] diff is not null", countDiff, nullValue()).     } else {         assertThat("[_count] diff is null", countDiff, notNullValue()).         assertThat("[_count] diff does not match expected [" + countDiff.value() + " vs " + expectedCount + "]", countDiff.value(), closeTo(expectedCount, 0.1)).     }     // This is a gap bucket     SimpleValue valuesDiff = actual.getAggregations().get("diff_values").     if (expectedValue == null) {         assertThat("[value] diff is not null", valuesDiff, Matchers.nullValue()).     } else {         assertThat("[value] diff is null", valuesDiff, notNullValue()).         assertThat("[value] diff does not match expected [" + valuesDiff.value() + " vs " + expectedValue + "]", valuesDiff.value(), closeTo(expectedValue, 0.1)).     } }
false;public;0;32;;@Override public void setupSuiteScopeCluster() throws Exception {     createIndex("idx").     createIndex("idx_unmapped").     List<IndexRequestBuilder> builders = new ArrayList<>().     interval = 5.     numBuckets = randomIntBetween(10, 80).     lag = randomIntBetween(1, numBuckets / 2).     gapPolicy = randomBoolean() ? BucketHelpers.GapPolicy.SKIP : BucketHelpers.GapPolicy.INSERT_ZEROS.     metric = randomMetric("the_metric", VALUE_FIELD).     mockHisto = PipelineAggregationHelperTests.generateHistogram(interval, numBuckets, randomDouble(), randomDouble()).     testValues = new HashMap<>(8).     for (MetricTarget target : MetricTarget.values()) {         setupExpected(target).     }     for (PipelineAggregationHelperTests.MockBucket mockBucket : mockHisto) {         for (double value : mockBucket.docValues) {             builders.add(client().prepareIndex("idx", "type").setSource(jsonBuilder().startObject().field(INTERVAL_FIELD, mockBucket.key).field(VALUE_FIELD, value).endObject())).         }     }     indexRandom(true, builders).     ensureSearchable(). }
true;private;1;61;/**  * @param target    The document field "target", e.g. _count or a field value  */ ;/**  * @param target    The document field "target", e.g. _count or a field value  */ private void setupExpected(MetricTarget target) {     ArrayList<Double> values = new ArrayList<>(numBuckets).     EvictingQueue<Double> lagWindow = new EvictingQueue<>(lag).     int counter = 0.     for (PipelineAggregationHelperTests.MockBucket mockBucket : mockHisto) {         Double metricValue.         double[] docValues = mockBucket.docValues.         // Gaps only apply to metric values, not doc _counts         if (mockBucket.count == 0 && target.equals(MetricTarget.VALUE)) {             // If there was a gap in doc counts and we are ignoring, just skip this bucket             if (gapPolicy.equals(BucketHelpers.GapPolicy.SKIP)) {                 metricValue = null.             } else if (gapPolicy.equals(BucketHelpers.GapPolicy.INSERT_ZEROS)) {                 // otherwise insert a zero instead of the true value                 metricValue = 0.0.             } else {                 metricValue = PipelineAggregationHelperTests.calculateMetric(docValues, metric).             }         } else {             // If this isn't a gap, or is a _count, just insert the value             metricValue = target.equals(MetricTarget.VALUE) ? PipelineAggregationHelperTests.calculateMetric(docValues, metric) : mockBucket.count.         }         counter += 1.         // Still under the initial lag period, add nothing and move on         Double lagValue.         if (counter <= lag) {             lagValue = Double.NaN.         } else {             // Peek here, because we rely on add'ing to always move the window             lagValue = lagWindow.peek().         }         // Normalize null's to NaN         if (metricValue == null) {             metricValue = Double.NaN.         }         // Both have values, calculate diff and replace the "empty" bucket         if (!Double.isNaN(metricValue) && !Double.isNaN(lagValue)) {             double diff = metricValue - lagValue.             values.add(diff).         } else {             // The tests need null, even though the agg doesn't             values.add(null).         }         lagWindow.add(metricValue).     }     testValues.put(target.toString(), values). }
false;public;0;45;;public void testBasicDiff() {     SearchResponse response = client().prepareSearch("idx").setTypes("type").addAggregation(histogram("histo").field(INTERVAL_FIELD).interval(interval).extendedBounds(0L, (long) (interval * (numBuckets - 1))).subAggregation(metric).subAggregation(diff("diff_counts", "_count").lag(lag).gapPolicy(gapPolicy)).subAggregation(diff("diff_values", "the_metric").lag(lag).gapPolicy(gapPolicy))).get().     assertSearchResponse(response).     Histogram histo = response.getAggregations().get("histo").     assertThat(histo, notNullValue()).     assertThat(histo.getName(), equalTo("histo")).     List<? extends Bucket> buckets = histo.getBuckets().     assertThat("Size of buckets array is not correct.", buckets.size(), equalTo(mockHisto.size())).     List<Double> expectedCounts = testValues.get(MetricTarget.COUNT.toString()).     List<Double> expectedValues = testValues.get(MetricTarget.VALUE.toString()).     Iterator<? extends Histogram.Bucket> actualIter = buckets.iterator().     Iterator<PipelineAggregationHelperTests.MockBucket> expectedBucketIter = mockHisto.iterator().     Iterator<Double> expectedCountsIter = expectedCounts.iterator().     Iterator<Double> expectedValuesIter = expectedValues.iterator().     while (actualIter.hasNext()) {         assertValidIterators(expectedBucketIter, expectedCountsIter, expectedValuesIter).         Histogram.Bucket actual = actualIter.next().         PipelineAggregationHelperTests.MockBucket expected = expectedBucketIter.next().         Double expectedCount = expectedCountsIter.next().         Double expectedValue = expectedValuesIter.next().         assertThat("keys do not match", ((Number) actual.getKey()).longValue(), equalTo(expected.key)).         assertThat("doc counts do not match", actual.getDocCount(), equalTo((long) expected.count)).         assertBucketContents(actual, expectedCount, expectedValue).     } }
false;public;0;16;;public void testInvalidLagSize() {     try {         client().prepareSearch("idx").setTypes("type").addAggregation(histogram("histo").field(INTERVAL_FIELD).interval(interval).extendedBounds(0L, (long) (interval * (numBuckets - 1))).subAggregation(metric).subAggregation(diff("diff_counts", "_count").lag(-1).gapPolicy(gapPolicy))).get().     } catch (IllegalArgumentException e) {         assertThat(e.getMessage(), is("[lag] must be a positive integer: [diff_counts]")).     } }
