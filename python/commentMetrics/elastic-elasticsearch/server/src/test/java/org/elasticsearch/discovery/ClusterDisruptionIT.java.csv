# id;timestamp;commentText;codeText;commentWords;codeWords
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1524684173;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertEquals(DocWriteResponse.Result.CREATED, response.getResult())__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,collections,synchronized,list,new,array,list,exception,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,equals,doc,write,response,result,created,response,get,result,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1525645056;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,collections,synchronized,list,new,array,list,exception,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1536964057;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,collections,synchronized,list,new,array,list,exception,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1537806831;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,collections,synchronized,list,new,array,list,exception,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1538067637;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,collections,synchronized,list,new,array,list,exception,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1539723533;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,collections,synchronized,list,new,array,list,exception,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1541008027;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,collections,synchronized,list,new,array,list,exception,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1544081506;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,collections,synchronized,list,new,array,list,exception,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1544446423;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,collections,synchronized,list,new,array,list,exception,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1544523743;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = Collections.synchronizedList(new ArrayList<Exception>())___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,collections,synchronized,list,new,array,list,exception,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1548405509;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = new CopyOnWriteArrayList<>()___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,new,copy,on,write,array,list,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1548772865;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = new CopyOnWriteArrayList<>()___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,new,copy,on,write,array,list,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1548872469;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = new CopyOnWriteArrayList<>()___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,new,copy,on,write,array,list,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1549029235;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = new CopyOnWriteArrayList<>()___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,new,copy,on,write,array,list,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1549270328;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = new CopyOnWriteArrayList<>()___        logger.info("starting indexers")__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexResponse response =_                                        client.prepareIndex("test", "type", id)_                                                .setSource("{}", XContentType.JSON)_                                                .setTimeout(timeout)_                                                .get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,new,copy,on,write,array,list,logger,info,starting,indexers,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,response,response,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb
ClusterDisruptionIT -> @TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +         "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +         "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +         "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")     public void testAckedIndexing() throws Exception;1550221827;Test that we do not loose document whose indexing request was successful, under a randomly selected disruption scheme_We also collect &amp_ report the type of indexing failures that occur._<p>_This test is a superset of tests run in the Jepsen test suite, with the exception of versioned updates;@TestLogging("_root:DEBUG,org.elasticsearch.action.bulk:TRACE,org.elasticsearch.action.get:TRACE," +_        "org.elasticsearch.discovery:TRACE,org.elasticsearch.action.support.replication:TRACE," +_        "org.elasticsearch.cluster.service:TRACE,org.elasticsearch.indices.recovery:TRACE," +_        "org.elasticsearch.indices.cluster:TRACE,org.elasticsearch.index.shard:TRACE")_    public void testAckedIndexing() throws Exception {__        final int seconds = !(TEST_NIGHTLY && rarely()) ? 1 : 5__        final String timeout = seconds + "s"___        final List<String> nodes = startCluster(rarely() ? 5 : 3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1 + randomInt(2))_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, randomInt(2))_            ))__        ensureGreen()___        ServiceDisruptionScheme disruptionScheme = addRandomDisruptionScheme()__        logger.info("disruption scheme [{}] added", disruptionScheme)___        final ConcurrentHashMap<String, String> ackedDocs = new ConcurrentHashMap<>()_ __        final AtomicBoolean stop = new AtomicBoolean(false)__        List<Thread> indexers = new ArrayList<>(nodes.size())__        List<Semaphore> semaphores = new ArrayList<>(nodes.size())__        final AtomicInteger idGenerator = new AtomicInteger(0)__        final AtomicReference<CountDownLatch> countDownLatchRef = new AtomicReference<>()__        final List<Exception> exceptedExceptions = new CopyOnWriteArrayList<>()___        final ConflictMode conflictMode = ConflictMode.randomMode()___        logger.info("starting indexers using conflict mode " + conflictMode)__        try {_            for (final String node : nodes) {_                final Semaphore semaphore = new Semaphore(0)__                semaphores.add(semaphore)__                final Client client = client(node)__                final String name = "indexer_" + indexers.size()__                final int numPrimaries = getNumShards("test").numPrimaries__                Thread thread = new Thread(() -> {_                    while (!stop.get()) {_                        String id = null__                        try {_                            if (!semaphore.tryAcquire(10, TimeUnit.SECONDS)) {_                                continue__                            }_                            logger.info("[{}] Acquired semaphore and it has {} permits left", name, semaphore.availablePermits())__                            try {_                                id = Integer.toString(idGenerator.incrementAndGet())__                                int shard = Math.floorMod(Murmur3HashFunction.hash(id), numPrimaries)__                                logger.trace("[{}] indexing id [{}] through node [{}] targeting shard [{}]", name, id, node, shard)__                                IndexRequestBuilder indexRequestBuilder = client.prepareIndex("test", "type", id)_                                    .setSource("{}", XContentType.JSON)_                                    .setTimeout(timeout)___                                if (conflictMode == ConflictMode.external) {_                                    indexRequestBuilder.setVersion(randomIntBetween(1,10)).setVersionType(VersionType.EXTERNAL)__                                } else if (conflictMode == ConflictMode.create) {_                                    indexRequestBuilder.setCreate(true)__                                }__                                IndexResponse response = indexRequestBuilder.get(timeout)__                                assertThat(response.getResult(), isOneOf(CREATED, UPDATED))__                                ackedDocs.put(id, node)__                                logger.trace("[{}] indexed id [{}] through node [{}], response [{}]", name, id, node, response)__                            } catch (ElasticsearchException e) {_                                exceptedExceptions.add(e)__                                final String docId = id__                                logger.trace(() -> new ParameterizedMessage("[{}] failed id [{}] through node [{}]", name, docId, node), e)__                            } finally {_                                countDownLatchRef.get().countDown()__                                logger.trace("[{}] decreased counter : {}", name, countDownLatchRef.get().getCount())__                            }_                        } catch (InterruptedException e) {_                            _                        } catch (AssertionError | Exception e) {_                            logger.info(() -> new ParameterizedMessage("unexpected exception in background thread of [{}]", node), e)__                        }_                    }_                })___                thread.setName(name)__                thread.start()__                indexers.add(thread)__            }__            int docsPerIndexer = randomInt(3)__            logger.info("indexing {} docs per indexer before partition", docsPerIndexer)__            countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__            for (Semaphore semaphore : semaphores) {_                semaphore.release(docsPerIndexer)__            }_            assertTrue(countDownLatchRef.get().await(1, TimeUnit.MINUTES))___            for (int iter = 1 + randomInt(2)_ iter > 0_ iter--) {_                logger.info("starting disruptions & indexing (iteration [{}])", iter)__                disruptionScheme.startDisrupting()___                docsPerIndexer = 1 + randomInt(5)__                logger.info("indexing {} docs per indexer during partition", docsPerIndexer)__                countDownLatchRef.set(new CountDownLatch(docsPerIndexer * indexers.size()))__                Collections.shuffle(semaphores, random())__                for (Semaphore semaphore : semaphores) {_                    assertThat(semaphore.availablePermits(), equalTo(0))__                    semaphore.release(docsPerIndexer)__                }_                logger.info("waiting for indexing requests to complete")__                assertTrue(countDownLatchRef.get().await(docsPerIndexer * seconds * 1000 + 2000, TimeUnit.MILLISECONDS))___                logger.info("stopping disruption")__                disruptionScheme.stopDisrupting()__                for (String node : internalCluster().getNodeNames()) {_                    ensureStableCluster(nodes.size(), TimeValue.timeValueMillis(disruptionScheme.expectedTimeToHeal().millis() +_                        DISRUPTION_HEALING_OVERHEAD.millis()), true, node)__                }_                _                _                if (disruptionScheme instanceof NetworkDisruption &&_                    ((NetworkDisruption) disruptionScheme).getDisruptedLinks() instanceof Bridge) {_                    assertAcked(client().admin().cluster().prepareReroute().setRetryFailed(true))__                }_                ensureGreen("test")___                logger.info("validating successful docs")__                assertBusy(() -> {_                    for (String node : nodes) {_                        try {_                            logger.debug("validating through node [{}] ([{}] acked docs)", node, ackedDocs.size())__                            for (String id : ackedDocs.keySet()) {_                                assertTrue("doc [" + id + "] indexed via node [" + ackedDocs.get(id) + "] not found",_                                    client(node).prepareGet("test", "type", id).setPreference("_local").get().isExists())__                            }_                        } catch (AssertionError | NoShardAvailableActionException e) {_                            throw new AssertionError(e.getMessage() + " (checked via node [" + node + "]", e)__                        }_                    }_                }, 30, TimeUnit.SECONDS)___                logger.info("done validating (iteration [{}])", iter)__            }_        } finally {_            logger.info("shutting down indexers")__            stop.set(true)__            for (Thread indexer : indexers) {_                indexer.interrupt()__                indexer.join(60000)__            }_            if (exceptedExceptions.size() > 0) {_                StringBuilder sb = new StringBuilder()__                for (Exception e : exceptedExceptions) {_                    sb.append("\n").append(e.getMessage())__                }_                logger.debug("Indexing exceptions during disruption: {}", sb)__            }_        }_    };test,that,we,do,not,loose,document,whose,indexing,request,was,successful,under,a,randomly,selected,disruption,scheme,we,also,collect,amp,report,the,type,of,indexing,failures,that,occur,p,this,test,is,a,superset,of,tests,run,in,the,jepsen,test,suite,with,the,exception,of,versioned,updates;test,logging,debug,org,elasticsearch,action,bulk,trace,org,elasticsearch,action,get,trace,org,elasticsearch,discovery,trace,org,elasticsearch,action,support,replication,trace,org,elasticsearch,cluster,service,trace,org,elasticsearch,indices,recovery,trace,org,elasticsearch,indices,cluster,trace,org,elasticsearch,index,shard,trace,public,void,test,acked,indexing,throws,exception,final,int,seconds,rarely,1,5,final,string,timeout,seconds,s,final,list,string,nodes,start,cluster,rarely,5,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,random,int,2,put,index,meta,data,random,int,2,ensure,green,service,disruption,scheme,disruption,scheme,add,random,disruption,scheme,logger,info,disruption,scheme,added,disruption,scheme,final,concurrent,hash,map,string,string,acked,docs,new,concurrent,hash,map,final,atomic,boolean,stop,new,atomic,boolean,false,list,thread,indexers,new,array,list,nodes,size,list,semaphore,semaphores,new,array,list,nodes,size,final,atomic,integer,id,generator,new,atomic,integer,0,final,atomic,reference,count,down,latch,count,down,latch,ref,new,atomic,reference,final,list,exception,excepted,exceptions,new,copy,on,write,array,list,final,conflict,mode,conflict,mode,conflict,mode,random,mode,logger,info,starting,indexers,using,conflict,mode,conflict,mode,try,for,final,string,node,nodes,final,semaphore,semaphore,new,semaphore,0,semaphores,add,semaphore,final,client,client,client,node,final,string,name,indexers,size,final,int,num,primaries,get,num,shards,test,num,primaries,thread,thread,new,thread,while,stop,get,string,id,null,try,if,semaphore,try,acquire,10,time,unit,seconds,continue,logger,info,acquired,semaphore,and,it,has,permits,left,name,semaphore,available,permits,try,id,integer,to,string,id,generator,increment,and,get,int,shard,math,floor,mod,murmur3hash,function,hash,id,num,primaries,logger,trace,indexing,id,through,node,targeting,shard,name,id,node,shard,index,request,builder,index,request,builder,client,prepare,index,test,type,id,set,source,xcontent,type,json,set,timeout,timeout,if,conflict,mode,conflict,mode,external,index,request,builder,set,version,random,int,between,1,10,set,version,type,version,type,external,else,if,conflict,mode,conflict,mode,create,index,request,builder,set,create,true,index,response,response,index,request,builder,get,timeout,assert,that,response,get,result,is,one,of,created,updated,acked,docs,put,id,node,logger,trace,indexed,id,through,node,response,name,id,node,response,catch,elasticsearch,exception,e,excepted,exceptions,add,e,final,string,doc,id,id,logger,trace,new,parameterized,message,failed,id,through,node,name,doc,id,node,e,finally,count,down,latch,ref,get,count,down,logger,trace,decreased,counter,name,count,down,latch,ref,get,get,count,catch,interrupted,exception,e,catch,assertion,error,exception,e,logger,info,new,parameterized,message,unexpected,exception,in,background,thread,of,node,e,thread,set,name,name,thread,start,indexers,add,thread,int,docs,per,indexer,random,int,3,logger,info,indexing,docs,per,indexer,before,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,for,semaphore,semaphore,semaphores,semaphore,release,docs,per,indexer,assert,true,count,down,latch,ref,get,await,1,time,unit,minutes,for,int,iter,1,random,int,2,iter,0,iter,logger,info,starting,disruptions,indexing,iteration,iter,disruption,scheme,start,disrupting,docs,per,indexer,1,random,int,5,logger,info,indexing,docs,per,indexer,during,partition,docs,per,indexer,count,down,latch,ref,set,new,count,down,latch,docs,per,indexer,indexers,size,collections,shuffle,semaphores,random,for,semaphore,semaphore,semaphores,assert,that,semaphore,available,permits,equal,to,0,semaphore,release,docs,per,indexer,logger,info,waiting,for,indexing,requests,to,complete,assert,true,count,down,latch,ref,get,await,docs,per,indexer,seconds,1000,2000,time,unit,milliseconds,logger,info,stopping,disruption,disruption,scheme,stop,disrupting,for,string,node,internal,cluster,get,node,names,ensure,stable,cluster,nodes,size,time,value,time,value,millis,disruption,scheme,expected,time,to,heal,millis,millis,true,node,if,disruption,scheme,instanceof,network,disruption,network,disruption,disruption,scheme,get,disrupted,links,instanceof,bridge,assert,acked,client,admin,cluster,prepare,reroute,set,retry,failed,true,ensure,green,test,logger,info,validating,successful,docs,assert,busy,for,string,node,nodes,try,logger,debug,validating,through,node,acked,docs,node,acked,docs,size,for,string,id,acked,docs,key,set,assert,true,doc,id,indexed,via,node,acked,docs,get,id,not,found,client,node,prepare,get,test,type,id,set,preference,get,is,exists,catch,assertion,error,no,shard,available,action,exception,e,throw,new,assertion,error,e,get,message,checked,via,node,node,e,30,time,unit,seconds,logger,info,done,validating,iteration,iter,finally,logger,info,shutting,down,indexers,stop,set,true,for,thread,indexer,indexers,indexer,interrupt,indexer,join,60000,if,excepted,exceptions,size,0,string,builder,sb,new,string,builder,for,exception,e,excepted,exceptions,sb,append,n,append,e,get,message,logger,debug,indexing,exceptions,during,disruption,sb
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1524684173;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DEFAULT_SETTINGS)_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        configureCluster(settings, 3, null, 2)__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2)__        final String dataNode = internalCluster().startDataOnlyNode()__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,configure,cluster,settings,3,null,2,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,final,string,data,node,internal,cluster,start,data,only,node,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1525645056;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DEFAULT_SETTINGS)_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        configureCluster(settings, 3, null, 2)__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2)__        final String dataNode = internalCluster().startDataOnlyNode()__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,configure,cluster,settings,3,null,2,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,final,string,data,node,internal,cluster,start,data,only,node,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1536964057;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DEFAULT_SETTINGS)_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        configureCluster(settings, 3, null, 2)__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2)__        final String dataNode = internalCluster().startDataOnlyNode()__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,configure,cluster,settings,3,null,2,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,final,string,data,node,internal,cluster,start,data,only,node,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1537806831;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DEFAULT_SETTINGS)_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        configureCluster(settings, 3, null, 2)__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2)__        final String dataNode = internalCluster().startDataOnlyNode()__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,configure,cluster,settings,3,null,2,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,final,string,data,node,internal,cluster,start,data,only,node,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1538067637;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DEFAULT_SETTINGS)_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        configureCluster(settings, 3, null, 2)__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2)__        final String dataNode = internalCluster().startDataOnlyNode()__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,configure,cluster,settings,3,null,2,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,final,string,data,node,internal,cluster,start,data,only,node,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1539723533;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DEFAULT_SETTINGS)_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        configureCluster(settings, 3, 2)__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2)__        final String dataNode = internalCluster().startDataOnlyNode()__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,configure,cluster,settings,3,2,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,final,string,data,node,internal,cluster,start,data,only,node,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1541008027;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2, settings)__        final String dataNode = internalCluster().startDataOnlyNode(settings)__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,settings,final,string,data,node,internal,cluster,start,data,only,node,settings,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1544081506;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2, settings)__        final String dataNode = internalCluster().startDataOnlyNode(settings)__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,settings,final,string,data,node,internal,cluster,start,data,only,node,settings,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1544446423;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2, settings)__        final String dataNode = internalCluster().startDataOnlyNode(settings)__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,settings,final,string,data,node,internal,cluster,start,data,only,node,settings,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1544523743;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2, settings)__        final String dataNode = internalCluster().startDataOnlyNode(settings)__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,settings,final,string,data,node,internal,cluster,start,data,only,node,settings,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1548327482;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2, settings)__        final String dataNode = internalCluster().startDataOnlyNode(settings)__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,settings,final,string,data,node,internal,cluster,start,data,only,node,settings,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1548405509;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2, settings)__        final String dataNode = internalCluster().startDataOnlyNode(settings)__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,settings,final,string,data,node,internal,cluster,start,data,only,node,settings,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1548772865;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2, settings)__        final String dataNode = internalCluster().startDataOnlyNode(settings)__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,settings,final,string,data,node,internal,cluster,start,data,only,node,settings,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1548872469;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2, settings)__        final String dataNode = internalCluster().startDataOnlyNode(settings)__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,settings,final,string,data,node,internal,cluster,start,data,only,node,settings,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1549029235;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final Settings settings = Settings.builder()_            .put(DiscoverySettings.PUBLISH_TIMEOUT_SETTING.getKey(), "0s") _            .put(DiscoverySettings.COMMIT_TIMEOUT_SETTING.getKey(), "30s") _            .build()__        final String idxName = "test"__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2, settings)__        final String dataNode = internalCluster().startDataOnlyNode(settings)__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,settings,settings,settings,builder,put,discovery,settings,get,key,0s,put,discovery,settings,get,key,30s,build,final,string,idx,name,test,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,settings,final,string,data,node,internal,cluster,start,data,only,node,settings,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1549270328;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final String idxName = "test"__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2)__        final String dataNode = internalCluster().startDataOnlyNode()__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,string,idx,name,test,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,final,string,data,node,internal,cluster,start,data,only,node,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testIndicesDeleted() throws Exception;1550221827;Tests that indices are properly deleted even if there is a master transition in between._Test for https://github.com/elastic/elasticsearch/issues/11665;public void testIndicesDeleted() throws Exception {_        final String idxName = "test"__        final List<String> allMasterEligibleNodes = internalCluster().startMasterOnlyNodes(2)__        final String dataNode = internalCluster().startDataOnlyNode()__        ensureStableCluster(3)__        assertAcked(prepareCreate("test"))___        final String masterNode1 = internalCluster().getMasterName()__        NetworkDisruption networkDisruption =_                new NetworkDisruption(new TwoPartitions(masterNode1, dataNode), new NetworkDisruption.NetworkUnresponsive())__        internalCluster().setDisruptionScheme(networkDisruption)__        networkDisruption.startDisrupting()__        _        _        internalCluster().client(masterNode1).admin().indices().prepareDelete(idxName).setTimeout("0s").get()__        _        assertBusy(() -> {_            for (String masterNode : allMasterEligibleNodes) {_                final ClusterState masterState = internalCluster().clusterService(masterNode).state()__                assertTrue("index not deleted on " + masterNode, masterState.metaData().hasIndex(idxName) == false)__            }_        })__        internalCluster().restartNode(masterNode1, InternalTestCluster.EMPTY_CALLBACK)__        ensureYellow()__        assertFalse(client().admin().indices().prepareExists(idxName).get().isExists())__    };tests,that,indices,are,properly,deleted,even,if,there,is,a,master,transition,in,between,test,for,https,github,com,elastic,elasticsearch,issues,11665;public,void,test,indices,deleted,throws,exception,final,string,idx,name,test,final,list,string,all,master,eligible,nodes,internal,cluster,start,master,only,nodes,2,final,string,data,node,internal,cluster,start,data,only,node,ensure,stable,cluster,3,assert,acked,prepare,create,test,final,string,master,node1,internal,cluster,get,master,name,network,disruption,network,disruption,new,network,disruption,new,two,partitions,master,node1,data,node,new,network,disruption,network,unresponsive,internal,cluster,set,disruption,scheme,network,disruption,network,disruption,start,disrupting,internal,cluster,client,master,node1,admin,indices,prepare,delete,idx,name,set,timeout,0s,get,assert,busy,for,string,master,node,all,master,eligible,nodes,final,cluster,state,master,state,internal,cluster,cluster,service,master,node,state,assert,true,index,not,deleted,on,master,node,master,state,meta,data,has,index,idx,name,false,internal,cluster,restart,node,master,node1,internal,test,cluster,ensure,yellow,assert,false,client,admin,indices,prepare,exists,idx,name,get,is,exists
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1524684173;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1525645056;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1536964057;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1537806831;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1538067637;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1539723533;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1541008027;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1544081506;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1544446423;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1544523743;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1548327482;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1548405509;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1548772865;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1548872469;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1549029235;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1549270328;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testRejoinDocumentExistsInAllShardCopies() throws Exception;1550221827;Test that a document which is indexed on the majority side of a partition, is available from the minority side,_once the partition is healed;public void testRejoinDocumentExistsInAllShardCopies() throws Exception {_        List<String> nodes = startCluster(3)___        assertAcked(prepareCreate("test")_            .setSettings(Settings.builder()_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 2)_            )_            .get())__        ensureGreen("test")___        nodes = new ArrayList<>(nodes)__        Collections.shuffle(nodes, random())__        String isolatedNode = nodes.get(0)__        String notIsolatedNode = nodes.get(1)___        TwoPartitions partitions = isolateNode(isolatedNode)__        NetworkDisruption scheme = addRandomDisruptionType(partitions)__        scheme.startDisrupting()__        ensureStableCluster(2, notIsolatedNode)__        assertFalse(client(notIsolatedNode).admin().cluster().prepareHealth("test").setWaitForYellowStatus().get().isTimedOut())____        IndexResponse indexResponse = internalCluster().client(notIsolatedNode).prepareIndex("test", "type").setSource("field", "value")_            .get()__        assertThat(indexResponse.getVersion(), equalTo(1L))___        logger.info("Verifying if document exists via node[{}]", notIsolatedNode)__        GetResponse getResponse = internalCluster().client(notIsolatedNode).prepareGet("test", "type", indexResponse.getId())_            .setPreference("_local")_            .get()__        assertThat(getResponse.isExists(), is(true))__        assertThat(getResponse.getVersion(), equalTo(1L))__        assertThat(getResponse.getId(), equalTo(indexResponse.getId()))___        scheme.stopDisrupting()___        ensureStableCluster(3)__        ensureGreen("test")___        for (String node : nodes) {_            logger.info("Verifying if document exists after isolating node[{}] via node[{}]", isolatedNode, node)__            getResponse = internalCluster().client(node).prepareGet("test", "type", indexResponse.getId())_                .setPreference("_local")_                .get()__            assertThat(getResponse.isExists(), is(true))__            assertThat(getResponse.getVersion(), equalTo(1L))__            assertThat(getResponse.getId(), equalTo(indexResponse.getId()))__        }_    };test,that,a,document,which,is,indexed,on,the,majority,side,of,a,partition,is,available,from,the,minority,side,once,the,partition,is,healed;public,void,test,rejoin,document,exists,in,all,shard,copies,throws,exception,list,string,nodes,start,cluster,3,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,meta,data,1,put,index,meta,data,2,get,ensure,green,test,nodes,new,array,list,nodes,collections,shuffle,nodes,random,string,isolated,node,nodes,get,0,string,not,isolated,node,nodes,get,1,two,partitions,partitions,isolate,node,isolated,node,network,disruption,scheme,add,random,disruption,type,partitions,scheme,start,disrupting,ensure,stable,cluster,2,not,isolated,node,assert,false,client,not,isolated,node,admin,cluster,prepare,health,test,set,wait,for,yellow,status,get,is,timed,out,index,response,index,response,internal,cluster,client,not,isolated,node,prepare,index,test,type,set,source,field,value,get,assert,that,index,response,get,version,equal,to,1l,logger,info,verifying,if,document,exists,via,node,not,isolated,node,get,response,get,response,internal,cluster,client,not,isolated,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id,scheme,stop,disrupting,ensure,stable,cluster,3,ensure,green,test,for,string,node,nodes,logger,info,verifying,if,document,exists,after,isolating,node,via,node,isolated,node,node,get,response,internal,cluster,client,node,prepare,get,test,type,index,response,get,id,set,preference,get,assert,that,get,response,is,exists,is,true,assert,that,get,response,get,version,equal,to,1l,assert,that,get,response,get,id,equal,to,index,response,get,id
ClusterDisruptionIT -> public void testSearchWithRelocationAndSlowClusterStateProcessing() throws Exception;1524684173;This test creates a scenario where a primary shard (0 replicas) relocates and is in POST_RECOVERY on the target_node but already deleted on the source node. Search request should still work.;public void testSearchWithRelocationAndSlowClusterStateProcessing() throws Exception {_        _        configureCluster(Settings.EMPTY, 3, null, 1)__        final String masterNode = internalCluster().startMasterOnlyNode()__        final String node_1 = internalCluster().startDataOnlyNode()___        logger.info("--> creating index [test] with one shard and on replica")__        assertAcked(prepareCreate("test").setSettings(_            Settings.builder().put(indexSettings())_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0))_        )__        ensureGreen("test")___        final String node_2 = internalCluster().startDataOnlyNode()__        List<IndexRequestBuilder> indexRequestBuilderList = new ArrayList<>()__        for (int i = 0_ i < 100_ i++) {_            indexRequestBuilderList.add(client().prepareIndex().setIndex("test").setType("_doc")_                .setSource("{\"int_field\":1}", XContentType.JSON))__        }_        indexRandom(true, indexRequestBuilderList)___        IndicesStoreIntegrationIT.relocateAndBlockCompletion(logger, "test", 0, node_1, node_2)__        _        assertThat(client().prepareSearch().setSize(0).get().getHits().getTotalHits(), equalTo(100L))__    };this,test,creates,a,scenario,where,a,primary,shard,0,replicas,relocates,and,is,in,on,the,target,node,but,already,deleted,on,the,source,node,search,request,should,still,work;public,void,test,search,with,relocation,and,slow,cluster,state,processing,throws,exception,configure,cluster,settings,empty,3,null,1,final,string,master,node,internal,cluster,start,master,only,node,final,string,internal,cluster,start,data,only,node,logger,info,creating,index,test,with,one,shard,and,on,replica,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,settings,put,index,meta,data,1,put,index,meta,data,0,ensure,green,test,final,string,internal,cluster,start,data,only,node,list,index,request,builder,index,request,builder,list,new,array,list,for,int,i,0,i,100,i,index,request,builder,list,add,client,prepare,index,set,index,test,set,type,set,source,1,xcontent,type,json,index,random,true,index,request,builder,list,indices,store,integration,it,relocate,and,block,completion,logger,test,0,assert,that,client,prepare,search,set,size,0,get,get,hits,get,total,hits,equal,to,100l
ClusterDisruptionIT -> public void testSearchWithRelocationAndSlowClusterStateProcessing() throws Exception;1525645056;This test creates a scenario where a primary shard (0 replicas) relocates and is in POST_RECOVERY on the target_node but already deleted on the source node. Search request should still work.;public void testSearchWithRelocationAndSlowClusterStateProcessing() throws Exception {_        _        configureCluster(Settings.EMPTY, 3, null, 1)__        final String masterNode = internalCluster().startMasterOnlyNode()__        final String node_1 = internalCluster().startDataOnlyNode()___        logger.info("--> creating index [test] with one shard and on replica")__        assertAcked(prepareCreate("test").setSettings(_            Settings.builder().put(indexSettings())_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0))_        )__        ensureGreen("test")___        final String node_2 = internalCluster().startDataOnlyNode()__        List<IndexRequestBuilder> indexRequestBuilderList = new ArrayList<>()__        for (int i = 0_ i < 100_ i++) {_            indexRequestBuilderList.add(client().prepareIndex().setIndex("test").setType("_doc")_                .setSource("{\"int_field\":1}", XContentType.JSON))__        }_        indexRandom(true, indexRequestBuilderList)___        IndicesStoreIntegrationIT.relocateAndBlockCompletion(logger, "test", 0, node_1, node_2)__        _        assertThat(client().prepareSearch().setSize(0).get().getHits().getTotalHits(), equalTo(100L))__    };this,test,creates,a,scenario,where,a,primary,shard,0,replicas,relocates,and,is,in,on,the,target,node,but,already,deleted,on,the,source,node,search,request,should,still,work;public,void,test,search,with,relocation,and,slow,cluster,state,processing,throws,exception,configure,cluster,settings,empty,3,null,1,final,string,master,node,internal,cluster,start,master,only,node,final,string,internal,cluster,start,data,only,node,logger,info,creating,index,test,with,one,shard,and,on,replica,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,settings,put,index,meta,data,1,put,index,meta,data,0,ensure,green,test,final,string,internal,cluster,start,data,only,node,list,index,request,builder,index,request,builder,list,new,array,list,for,int,i,0,i,100,i,index,request,builder,list,add,client,prepare,index,set,index,test,set,type,set,source,1,xcontent,type,json,index,random,true,index,request,builder,list,indices,store,integration,it,relocate,and,block,completion,logger,test,0,assert,that,client,prepare,search,set,size,0,get,get,hits,get,total,hits,equal,to,100l
ClusterDisruptionIT -> public void testSearchWithRelocationAndSlowClusterStateProcessing() throws Exception;1536964057;This test creates a scenario where a primary shard (0 replicas) relocates and is in POST_RECOVERY on the target_node but already deleted on the source node. Search request should still work.;public void testSearchWithRelocationAndSlowClusterStateProcessing() throws Exception {_        _        configureCluster(Settings.EMPTY, 3, null, 1)__        final String masterNode = internalCluster().startMasterOnlyNode()__        final String node_1 = internalCluster().startDataOnlyNode()___        logger.info("--> creating index [test] with one shard and on replica")__        assertAcked(prepareCreate("test").setSettings(_            Settings.builder().put(indexSettings())_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0))_        )__        ensureGreen("test")___        final String node_2 = internalCluster().startDataOnlyNode()__        List<IndexRequestBuilder> indexRequestBuilderList = new ArrayList<>()__        for (int i = 0_ i < 100_ i++) {_            indexRequestBuilderList.add(client().prepareIndex().setIndex("test").setType("_doc")_                .setSource("{\"int_field\":1}", XContentType.JSON))__        }_        indexRandom(true, indexRequestBuilderList)___        IndicesStoreIntegrationIT.relocateAndBlockCompletion(logger, "test", 0, node_1, node_2)__        _        assertThat(client().prepareSearch().setSize(0).get().getHits().getTotalHits(), equalTo(100L))__    };this,test,creates,a,scenario,where,a,primary,shard,0,replicas,relocates,and,is,in,on,the,target,node,but,already,deleted,on,the,source,node,search,request,should,still,work;public,void,test,search,with,relocation,and,slow,cluster,state,processing,throws,exception,configure,cluster,settings,empty,3,null,1,final,string,master,node,internal,cluster,start,master,only,node,final,string,internal,cluster,start,data,only,node,logger,info,creating,index,test,with,one,shard,and,on,replica,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,settings,put,index,meta,data,1,put,index,meta,data,0,ensure,green,test,final,string,internal,cluster,start,data,only,node,list,index,request,builder,index,request,builder,list,new,array,list,for,int,i,0,i,100,i,index,request,builder,list,add,client,prepare,index,set,index,test,set,type,set,source,1,xcontent,type,json,index,random,true,index,request,builder,list,indices,store,integration,it,relocate,and,block,completion,logger,test,0,assert,that,client,prepare,search,set,size,0,get,get,hits,get,total,hits,equal,to,100l
ClusterDisruptionIT -> public void testSearchWithRelocationAndSlowClusterStateProcessing() throws Exception;1537806831;This test creates a scenario where a primary shard (0 replicas) relocates and is in POST_RECOVERY on the target_node but already deleted on the source node. Search request should still work.;public void testSearchWithRelocationAndSlowClusterStateProcessing() throws Exception {_        _        configureCluster(Settings.EMPTY, 3, null, 1)__        final String masterNode = internalCluster().startMasterOnlyNode()__        final String node_1 = internalCluster().startDataOnlyNode()___        logger.info("--> creating index [test] with one shard and on replica")__        assertAcked(prepareCreate("test").setSettings(_            Settings.builder().put(indexSettings())_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0))_        )__        ensureGreen("test")___        final String node_2 = internalCluster().startDataOnlyNode()__        List<IndexRequestBuilder> indexRequestBuilderList = new ArrayList<>()__        for (int i = 0_ i < 100_ i++) {_            indexRequestBuilderList.add(client().prepareIndex().setIndex("test").setType("_doc")_                .setSource("{\"int_field\":1}", XContentType.JSON))__        }_        indexRandom(true, indexRequestBuilderList)___        IndicesStoreIntegrationIT.relocateAndBlockCompletion(logger, "test", 0, node_1, node_2)__        _        assertThat(client().prepareSearch().setSize(0).get().getHits().getTotalHits(), equalTo(100L))__    };this,test,creates,a,scenario,where,a,primary,shard,0,replicas,relocates,and,is,in,on,the,target,node,but,already,deleted,on,the,source,node,search,request,should,still,work;public,void,test,search,with,relocation,and,slow,cluster,state,processing,throws,exception,configure,cluster,settings,empty,3,null,1,final,string,master,node,internal,cluster,start,master,only,node,final,string,internal,cluster,start,data,only,node,logger,info,creating,index,test,with,one,shard,and,on,replica,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,settings,put,index,meta,data,1,put,index,meta,data,0,ensure,green,test,final,string,internal,cluster,start,data,only,node,list,index,request,builder,index,request,builder,list,new,array,list,for,int,i,0,i,100,i,index,request,builder,list,add,client,prepare,index,set,index,test,set,type,set,source,1,xcontent,type,json,index,random,true,index,request,builder,list,indices,store,integration,it,relocate,and,block,completion,logger,test,0,assert,that,client,prepare,search,set,size,0,get,get,hits,get,total,hits,equal,to,100l
ClusterDisruptionIT -> public void testSearchWithRelocationAndSlowClusterStateProcessing() throws Exception;1538067637;This test creates a scenario where a primary shard (0 replicas) relocates and is in POST_RECOVERY on the target_node but already deleted on the source node. Search request should still work.;public void testSearchWithRelocationAndSlowClusterStateProcessing() throws Exception {_        _        configureCluster(Settings.EMPTY, 3, null, 1)__        internalCluster().startMasterOnlyNode()__        final String node_1 = internalCluster().startDataOnlyNode()___        logger.info("--> creating index [test] with one shard and on replica")__        assertAcked(prepareCreate("test").setSettings(_            Settings.builder().put(indexSettings())_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0))_        )__        ensureGreen("test")___        final String node_2 = internalCluster().startDataOnlyNode()__        List<IndexRequestBuilder> indexRequestBuilderList = new ArrayList<>()__        for (int i = 0_ i < 100_ i++) {_            indexRequestBuilderList.add(client().prepareIndex().setIndex("test").setType("_doc")_                .setSource("{\"int_field\":1}", XContentType.JSON))__        }_        indexRandom(true, indexRequestBuilderList)___        IndicesStoreIntegrationIT.relocateAndBlockCompletion(logger, "test", 0, node_1, node_2)__        _        assertThat(client().prepareSearch().setSize(0).get().getHits().getTotalHits(), equalTo(100L))__    };this,test,creates,a,scenario,where,a,primary,shard,0,replicas,relocates,and,is,in,on,the,target,node,but,already,deleted,on,the,source,node,search,request,should,still,work;public,void,test,search,with,relocation,and,slow,cluster,state,processing,throws,exception,configure,cluster,settings,empty,3,null,1,internal,cluster,start,master,only,node,final,string,internal,cluster,start,data,only,node,logger,info,creating,index,test,with,one,shard,and,on,replica,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,settings,put,index,meta,data,1,put,index,meta,data,0,ensure,green,test,final,string,internal,cluster,start,data,only,node,list,index,request,builder,index,request,builder,list,new,array,list,for,int,i,0,i,100,i,index,request,builder,list,add,client,prepare,index,set,index,test,set,type,set,source,1,xcontent,type,json,index,random,true,index,request,builder,list,indices,store,integration,it,relocate,and,block,completion,logger,test,0,assert,that,client,prepare,search,set,size,0,get,get,hits,get,total,hits,equal,to,100l
ClusterDisruptionIT -> public void testSearchWithRelocationAndSlowClusterStateProcessing() throws Exception;1539723533;This test creates a scenario where a primary shard (0 replicas) relocates and is in POST_RECOVERY on the target_node but already deleted on the source node. Search request should still work.;public void testSearchWithRelocationAndSlowClusterStateProcessing() throws Exception {_        _        configureCluster(Settings.EMPTY, 3, 1)__        internalCluster().startMasterOnlyNode()__        final String node_1 = internalCluster().startDataOnlyNode()___        logger.info("--> creating index [test] with one shard and on replica")__        assertAcked(prepareCreate("test").setSettings(_            Settings.builder().put(indexSettings())_                .put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1)_                .put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 0))_        )__        ensureGreen("test")___        final String node_2 = internalCluster().startDataOnlyNode()__        List<IndexRequestBuilder> indexRequestBuilderList = new ArrayList<>()__        for (int i = 0_ i < 100_ i++) {_            indexRequestBuilderList.add(client().prepareIndex().setIndex("test").setType("_doc")_                .setSource("{\"int_field\":1}", XContentType.JSON))__        }_        indexRandom(true, indexRequestBuilderList)___        IndicesStoreIntegrationIT.relocateAndBlockCompletion(logger, "test", 0, node_1, node_2)__        _        assertThat(client().prepareSearch().setSize(0).get().getHits().getTotalHits(), equalTo(100L))__    };this,test,creates,a,scenario,where,a,primary,shard,0,replicas,relocates,and,is,in,on,the,target,node,but,already,deleted,on,the,source,node,search,request,should,still,work;public,void,test,search,with,relocation,and,slow,cluster,state,processing,throws,exception,configure,cluster,settings,empty,3,1,internal,cluster,start,master,only,node,final,string,internal,cluster,start,data,only,node,logger,info,creating,index,test,with,one,shard,and,on,replica,assert,acked,prepare,create,test,set,settings,settings,builder,put,index,settings,put,index,meta,data,1,put,index,meta,data,0,ensure,green,test,final,string,internal,cluster,start,data,only,node,list,index,request,builder,index,request,builder,list,new,array,list,for,int,i,0,i,100,i,index,request,builder,list,add,client,prepare,index,set,index,test,set,type,set,source,1,xcontent,type,json,index,random,true,index,request,builder,list,indices,store,integration,it,relocate,and,block,completion,logger,test,0,assert,that,client,prepare,search,set,size,0,get,get,hits,get,total,hits,equal,to,100l
