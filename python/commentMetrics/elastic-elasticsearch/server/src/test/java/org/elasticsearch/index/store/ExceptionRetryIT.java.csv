# id;timestamp;commentText;codeText;commentWords;codeWords
ExceptionRetryIT -> public void testRetryDueToExceptionOnNetworkLayer() throws ExecutionException, InterruptedException, IOException;1524684173;Tests retry mechanism when indexing. If an exception occurs when indexing then the indexing request is tried again before finally_failing. If auto generated ids are used this must not lead to duplicate ids_see https://github.com/elastic/elasticsearch/issues/8788;public void testRetryDueToExceptionOnNetworkLayer() throws ExecutionException, InterruptedException, IOException {_        final AtomicBoolean exceptionThrown = new AtomicBoolean(false)__        int numDocs = scaledRandomIntBetween(100, 1000)__        Client client = internalCluster().coordOnlyNodeClient()__        NodesStatsResponse nodeStats = client().admin().cluster().prepareNodesStats().get()__        NodeStats unluckyNode = randomFrom(nodeStats.getNodes().stream().filter((s) -> s.getNode().isDataNode())_            .collect(Collectors.toList()))__        assertAcked(client().admin().indices().prepareCreate("index").setSettings(Settings.builder()_            .put("index.number_of_replicas", 1)_            .put("index.number_of_shards", 5)))__        ensureGreen("index")__        logger.info("unlucky node: {}", unluckyNode.getNode())__        _        for (NodeStats dataNode : nodeStats.getNodes()) {_            MockTransportService mockTransportService = ((MockTransportService) internalCluster().getInstance(TransportService.class,_                dataNode.getNode().getName()))__            mockTransportService.addDelegate(internalCluster().getInstance(TransportService.class, unluckyNode.getNode().getName()),_                new MockTransportService.DelegateTransport(mockTransportService.original()) {_                @Override_                protected void sendRequest(Connection connection, long requestId, String action, TransportRequest request,_                                           TransportRequestOptions options) throws IOException {_                    super.sendRequest(connection, requestId, action, request, options)__                    if (action.equals(TransportShardBulkAction.ACTION_NAME) && exceptionThrown.compareAndSet(false, true)) {_                        logger.debug("Throw ConnectTransportException")__                        throw new ConnectTransportException(connection.getNode(), action)__                    }_                }_            })__        }__        BulkRequestBuilder bulkBuilder = client.prepareBulk()__        for (int i = 0_ i < numDocs_ i++) {_            XContentBuilder doc = null__            doc = jsonBuilder().startObject().field("foo", "bar").endObject()__            bulkBuilder.add(client.prepareIndex("index", "type").setSource(doc))__        }__        BulkResponse response = bulkBuilder.get()__        if (response.hasFailures()) {_            for (BulkItemResponse singleIndexRespons : response.getItems()) {_                if (singleIndexRespons.isFailed()) {_                    fail("None of the bulk items should fail but got " + singleIndexRespons.getFailureMessage())__                }_            }_        }__        refresh()__        SearchResponse searchResponse = client().prepareSearch("index").setSize(numDocs * 2).addStoredField("_id").get()___        Set<String> uniqueIds = new HashSet<>()__        long dupCounter = 0__        boolean found_duplicate_already = false__        for (int i = 0_ i < searchResponse.getHits().getHits().length_ i++) {_            if (!uniqueIds.add(searchResponse.getHits().getHits()[i].getId())) {_                if (!found_duplicate_already) {_                    SearchResponse dupIdResponse = client().prepareSearch("index").setQuery(termQuery("_id",_                        searchResponse.getHits().getHits()[i].getId())).setExplain(true).get()__                    assertThat(dupIdResponse.getHits().getTotalHits(), greaterThan(1L))__                    logger.info("found a duplicate id:")__                    for (SearchHit hit : dupIdResponse.getHits()) {_                        logger.info("Doc {} was found on shard {}", hit.getId(), hit.getShard().getShardId())__                    }_                    logger.info("will not print anymore in case more duplicates are found.")__                    found_duplicate_already = true__                }_                dupCounter++__            }_        }_        assertSearchResponse(searchResponse)__        assertThat(dupCounter, equalTo(0L))__        assertHitCount(searchResponse, numDocs)__        IndicesStatsResponse index = client().admin().indices().prepareStats("index").clear().setSegments(true).get()__        IndexStats indexStats = index.getIndex("index")__        long maxUnsafeAutoIdTimestamp = Long.MIN_VALUE__        for (IndexShardStats indexShardStats : indexStats) {_            for (ShardStats shardStats : indexShardStats) {_                SegmentsStats segments = shardStats.getStats().getSegments()__                maxUnsafeAutoIdTimestamp = Math.max(maxUnsafeAutoIdTimestamp, segments.getMaxUnsafeAutoIdTimestamp())__            }_        }_        assertTrue("exception must have been thrown otherwise setup is broken", exceptionThrown.get())__        assertTrue("maxUnsafeAutoIdTimestamp must be > than 0 we have at least one retry", maxUnsafeAutoIdTimestamp > -1)__    };tests,retry,mechanism,when,indexing,if,an,exception,occurs,when,indexing,then,the,indexing,request,is,tried,again,before,finally,failing,if,auto,generated,ids,are,used,this,must,not,lead,to,duplicate,ids,see,https,github,com,elastic,elasticsearch,issues,8788;public,void,test,retry,due,to,exception,on,network,layer,throws,execution,exception,interrupted,exception,ioexception,final,atomic,boolean,exception,thrown,new,atomic,boolean,false,int,num,docs,scaled,random,int,between,100,1000,client,client,internal,cluster,coord,only,node,client,nodes,stats,response,node,stats,client,admin,cluster,prepare,nodes,stats,get,node,stats,unlucky,node,random,from,node,stats,get,nodes,stream,filter,s,s,get,node,is,data,node,collect,collectors,to,list,assert,acked,client,admin,indices,prepare,create,index,set,settings,settings,builder,put,index,1,put,index,5,ensure,green,index,logger,info,unlucky,node,unlucky,node,get,node,for,node,stats,data,node,node,stats,get,nodes,mock,transport,service,mock,transport,service,mock,transport,service,internal,cluster,get,instance,transport,service,class,data,node,get,node,get,name,mock,transport,service,add,delegate,internal,cluster,get,instance,transport,service,class,unlucky,node,get,node,get,name,new,mock,transport,service,delegate,transport,mock,transport,service,original,override,protected,void,send,request,connection,connection,long,request,id,string,action,transport,request,request,transport,request,options,options,throws,ioexception,super,send,request,connection,request,id,action,request,options,if,action,equals,transport,shard,bulk,action,exception,thrown,compare,and,set,false,true,logger,debug,throw,connect,transport,exception,throw,new,connect,transport,exception,connection,get,node,action,bulk,request,builder,bulk,builder,client,prepare,bulk,for,int,i,0,i,num,docs,i,xcontent,builder,doc,null,doc,json,builder,start,object,field,foo,bar,end,object,bulk,builder,add,client,prepare,index,index,type,set,source,doc,bulk,response,response,bulk,builder,get,if,response,has,failures,for,bulk,item,response,single,index,respons,response,get,items,if,single,index,respons,is,failed,fail,none,of,the,bulk,items,should,fail,but,got,single,index,respons,get,failure,message,refresh,search,response,search,response,client,prepare,search,index,set,size,num,docs,2,add,stored,field,get,set,string,unique,ids,new,hash,set,long,dup,counter,0,boolean,false,for,int,i,0,i,search,response,get,hits,get,hits,length,i,if,unique,ids,add,search,response,get,hits,get,hits,i,get,id,if,search,response,dup,id,response,client,prepare,search,index,set,query,term,query,search,response,get,hits,get,hits,i,get,id,set,explain,true,get,assert,that,dup,id,response,get,hits,get,total,hits,greater,than,1l,logger,info,found,a,duplicate,id,for,search,hit,hit,dup,id,response,get,hits,logger,info,doc,was,found,on,shard,hit,get,id,hit,get,shard,get,shard,id,logger,info,will,not,print,anymore,in,case,more,duplicates,are,found,true,dup,counter,assert,search,response,search,response,assert,that,dup,counter,equal,to,0l,assert,hit,count,search,response,num,docs,indices,stats,response,index,client,admin,indices,prepare,stats,index,clear,set,segments,true,get,index,stats,index,stats,index,get,index,index,long,max,unsafe,auto,id,timestamp,long,for,index,shard,stats,index,shard,stats,index,stats,for,shard,stats,shard,stats,index,shard,stats,segments,stats,segments,shard,stats,get,stats,get,segments,max,unsafe,auto,id,timestamp,math,max,max,unsafe,auto,id,timestamp,segments,get,max,unsafe,auto,id,timestamp,assert,true,exception,must,have,been,thrown,otherwise,setup,is,broken,exception,thrown,get,assert,true,max,unsafe,auto,id,timestamp,must,be,than,0,we,have,at,least,one,retry,max,unsafe,auto,id,timestamp,1
ExceptionRetryIT -> public void testRetryDueToExceptionOnNetworkLayer() throws ExecutionException, InterruptedException, IOException;1534203100;Tests retry mechanism when indexing. If an exception occurs when indexing then the indexing request is tried again before finally_failing. If auto generated ids are used this must not lead to duplicate ids_see https://github.com/elastic/elasticsearch/issues/8788;public void testRetryDueToExceptionOnNetworkLayer() throws ExecutionException, InterruptedException, IOException {_        final AtomicBoolean exceptionThrown = new AtomicBoolean(false)__        int numDocs = scaledRandomIntBetween(100, 1000)__        Client client = internalCluster().coordOnlyNodeClient()__        NodesStatsResponse nodeStats = client().admin().cluster().prepareNodesStats().get()__        NodeStats unluckyNode = randomFrom(nodeStats.getNodes().stream().filter((s) -> s.getNode().isDataNode())_            .collect(Collectors.toList()))__        assertAcked(client().admin().indices().prepareCreate("index").setSettings(Settings.builder()_            .put("index.number_of_replicas", 1)_            .put("index.number_of_shards", 5)))__        ensureGreen("index")__        logger.info("unlucky node: {}", unluckyNode.getNode())__        _        for (NodeStats dataNode : nodeStats.getNodes()) {_            MockTransportService mockTransportService = ((MockTransportService) internalCluster().getInstance(TransportService.class,_                dataNode.getNode().getName()))__            mockTransportService.addSendBehavior(internalCluster().getInstance(TransportService.class, unluckyNode.getNode().getName()),_                (connection, requestId, action, request, options) -> {_                    connection.sendRequest(requestId, action, request, options)__                    if (action.equals(TransportShardBulkAction.ACTION_NAME) && exceptionThrown.compareAndSet(false, true)) {_                        logger.debug("Throw ConnectTransportException")__                        throw new ConnectTransportException(connection.getNode(), action)__                    }_                })__        }__        BulkRequestBuilder bulkBuilder = client.prepareBulk()__        for (int i = 0_ i < numDocs_ i++) {_            XContentBuilder doc = null__            doc = jsonBuilder().startObject().field("foo", "bar").endObject()__            bulkBuilder.add(client.prepareIndex("index", "type").setSource(doc))__        }__        BulkResponse response = bulkBuilder.get()__        if (response.hasFailures()) {_            for (BulkItemResponse singleIndexRespons : response.getItems()) {_                if (singleIndexRespons.isFailed()) {_                    fail("None of the bulk items should fail but got " + singleIndexRespons.getFailureMessage())__                }_            }_        }__        refresh()__        SearchResponse searchResponse = client().prepareSearch("index").setSize(numDocs * 2).addStoredField("_id").get()___        Set<String> uniqueIds = new HashSet<>()__        long dupCounter = 0__        boolean found_duplicate_already = false__        for (int i = 0_ i < searchResponse.getHits().getHits().length_ i++) {_            if (!uniqueIds.add(searchResponse.getHits().getHits()[i].getId())) {_                if (!found_duplicate_already) {_                    SearchResponse dupIdResponse = client().prepareSearch("index").setQuery(termQuery("_id",_                        searchResponse.getHits().getHits()[i].getId())).setExplain(true).get()__                    assertThat(dupIdResponse.getHits().getTotalHits(), greaterThan(1L))__                    logger.info("found a duplicate id:")__                    for (SearchHit hit : dupIdResponse.getHits()) {_                        logger.info("Doc {} was found on shard {}", hit.getId(), hit.getShard().getShardId())__                    }_                    logger.info("will not print anymore in case more duplicates are found.")__                    found_duplicate_already = true__                }_                dupCounter++__            }_        }_        assertSearchResponse(searchResponse)__        assertThat(dupCounter, equalTo(0L))__        assertHitCount(searchResponse, numDocs)__        IndicesStatsResponse index = client().admin().indices().prepareStats("index").clear().setSegments(true).get()__        IndexStats indexStats = index.getIndex("index")__        long maxUnsafeAutoIdTimestamp = Long.MIN_VALUE__        for (IndexShardStats indexShardStats : indexStats) {_            for (ShardStats shardStats : indexShardStats) {_                SegmentsStats segments = shardStats.getStats().getSegments()__                maxUnsafeAutoIdTimestamp = Math.max(maxUnsafeAutoIdTimestamp, segments.getMaxUnsafeAutoIdTimestamp())__            }_        }_        assertTrue("exception must have been thrown otherwise setup is broken", exceptionThrown.get())__        assertTrue("maxUnsafeAutoIdTimestamp must be > than 0 we have at least one retry", maxUnsafeAutoIdTimestamp > -1)__    };tests,retry,mechanism,when,indexing,if,an,exception,occurs,when,indexing,then,the,indexing,request,is,tried,again,before,finally,failing,if,auto,generated,ids,are,used,this,must,not,lead,to,duplicate,ids,see,https,github,com,elastic,elasticsearch,issues,8788;public,void,test,retry,due,to,exception,on,network,layer,throws,execution,exception,interrupted,exception,ioexception,final,atomic,boolean,exception,thrown,new,atomic,boolean,false,int,num,docs,scaled,random,int,between,100,1000,client,client,internal,cluster,coord,only,node,client,nodes,stats,response,node,stats,client,admin,cluster,prepare,nodes,stats,get,node,stats,unlucky,node,random,from,node,stats,get,nodes,stream,filter,s,s,get,node,is,data,node,collect,collectors,to,list,assert,acked,client,admin,indices,prepare,create,index,set,settings,settings,builder,put,index,1,put,index,5,ensure,green,index,logger,info,unlucky,node,unlucky,node,get,node,for,node,stats,data,node,node,stats,get,nodes,mock,transport,service,mock,transport,service,mock,transport,service,internal,cluster,get,instance,transport,service,class,data,node,get,node,get,name,mock,transport,service,add,send,behavior,internal,cluster,get,instance,transport,service,class,unlucky,node,get,node,get,name,connection,request,id,action,request,options,connection,send,request,request,id,action,request,options,if,action,equals,transport,shard,bulk,action,exception,thrown,compare,and,set,false,true,logger,debug,throw,connect,transport,exception,throw,new,connect,transport,exception,connection,get,node,action,bulk,request,builder,bulk,builder,client,prepare,bulk,for,int,i,0,i,num,docs,i,xcontent,builder,doc,null,doc,json,builder,start,object,field,foo,bar,end,object,bulk,builder,add,client,prepare,index,index,type,set,source,doc,bulk,response,response,bulk,builder,get,if,response,has,failures,for,bulk,item,response,single,index,respons,response,get,items,if,single,index,respons,is,failed,fail,none,of,the,bulk,items,should,fail,but,got,single,index,respons,get,failure,message,refresh,search,response,search,response,client,prepare,search,index,set,size,num,docs,2,add,stored,field,get,set,string,unique,ids,new,hash,set,long,dup,counter,0,boolean,false,for,int,i,0,i,search,response,get,hits,get,hits,length,i,if,unique,ids,add,search,response,get,hits,get,hits,i,get,id,if,search,response,dup,id,response,client,prepare,search,index,set,query,term,query,search,response,get,hits,get,hits,i,get,id,set,explain,true,get,assert,that,dup,id,response,get,hits,get,total,hits,greater,than,1l,logger,info,found,a,duplicate,id,for,search,hit,hit,dup,id,response,get,hits,logger,info,doc,was,found,on,shard,hit,get,id,hit,get,shard,get,shard,id,logger,info,will,not,print,anymore,in,case,more,duplicates,are,found,true,dup,counter,assert,search,response,search,response,assert,that,dup,counter,equal,to,0l,assert,hit,count,search,response,num,docs,indices,stats,response,index,client,admin,indices,prepare,stats,index,clear,set,segments,true,get,index,stats,index,stats,index,get,index,index,long,max,unsafe,auto,id,timestamp,long,for,index,shard,stats,index,shard,stats,index,stats,for,shard,stats,shard,stats,index,shard,stats,segments,stats,segments,shard,stats,get,stats,get,segments,max,unsafe,auto,id,timestamp,math,max,max,unsafe,auto,id,timestamp,segments,get,max,unsafe,auto,id,timestamp,assert,true,exception,must,have,been,thrown,otherwise,setup,is,broken,exception,thrown,get,assert,true,max,unsafe,auto,id,timestamp,must,be,than,0,we,have,at,least,one,retry,max,unsafe,auto,id,timestamp,1
ExceptionRetryIT -> public void testRetryDueToExceptionOnNetworkLayer() throws ExecutionException, InterruptedException, IOException;1544035746;Tests retry mechanism when indexing. If an exception occurs when indexing then the indexing request is tried again before finally_failing. If auto generated ids are used this must not lead to duplicate ids_see https://github.com/elastic/elasticsearch/issues/8788;public void testRetryDueToExceptionOnNetworkLayer() throws ExecutionException, InterruptedException, IOException {_        final AtomicBoolean exceptionThrown = new AtomicBoolean(false)__        int numDocs = scaledRandomIntBetween(100, 1000)__        Client client = internalCluster().coordOnlyNodeClient()__        NodesStatsResponse nodeStats = client().admin().cluster().prepareNodesStats().get()__        NodeStats unluckyNode = randomFrom(nodeStats.getNodes().stream().filter((s) -> s.getNode().isDataNode())_            .collect(Collectors.toList()))__        assertAcked(client().admin().indices().prepareCreate("index").setSettings(Settings.builder()_            .put("index.number_of_replicas", 1)_            .put("index.number_of_shards", 5)))__        ensureGreen("index")__        logger.info("unlucky node: {}", unluckyNode.getNode())__        _        for (NodeStats dataNode : nodeStats.getNodes()) {_            MockTransportService mockTransportService = ((MockTransportService) internalCluster().getInstance(TransportService.class,_                dataNode.getNode().getName()))__            mockTransportService.addSendBehavior(internalCluster().getInstance(TransportService.class, unluckyNode.getNode().getName()),_                (connection, requestId, action, request, options) -> {_                    connection.sendRequest(requestId, action, request, options)__                    if (action.equals(TransportShardBulkAction.ACTION_NAME) && exceptionThrown.compareAndSet(false, true)) {_                        logger.debug("Throw ConnectTransportException")__                        throw new ConnectTransportException(connection.getNode(), action)__                    }_                })__        }__        BulkRequestBuilder bulkBuilder = client.prepareBulk()__        for (int i = 0_ i < numDocs_ i++) {_            XContentBuilder doc = null__            doc = jsonBuilder().startObject().field("foo", "bar").endObject()__            bulkBuilder.add(client.prepareIndex("index", "type").setSource(doc))__        }__        BulkResponse response = bulkBuilder.get()__        if (response.hasFailures()) {_            for (BulkItemResponse singleIndexRespons : response.getItems()) {_                if (singleIndexRespons.isFailed()) {_                    fail("None of the bulk items should fail but got " + singleIndexRespons.getFailureMessage())__                }_            }_        }__        refresh()__        SearchResponse searchResponse = client().prepareSearch("index").setSize(numDocs * 2).addStoredField("_id").get()___        Set<String> uniqueIds = new HashSet<>()__        long dupCounter = 0__        boolean found_duplicate_already = false__        for (int i = 0_ i < searchResponse.getHits().getHits().length_ i++) {_            if (!uniqueIds.add(searchResponse.getHits().getHits()[i].getId())) {_                if (!found_duplicate_already) {_                    SearchResponse dupIdResponse = client().prepareSearch("index").setQuery(termQuery("_id",_                        searchResponse.getHits().getHits()[i].getId())).setExplain(true).get()__                    assertThat(dupIdResponse.getHits().getTotalHits().value, greaterThan(1L))__                    logger.info("found a duplicate id:")__                    for (SearchHit hit : dupIdResponse.getHits()) {_                        logger.info("Doc {} was found on shard {}", hit.getId(), hit.getShard().getShardId())__                    }_                    logger.info("will not print anymore in case more duplicates are found.")__                    found_duplicate_already = true__                }_                dupCounter++__            }_        }_        assertSearchResponse(searchResponse)__        assertThat(dupCounter, equalTo(0L))__        assertHitCount(searchResponse, numDocs)__        IndicesStatsResponse index = client().admin().indices().prepareStats("index").clear().setSegments(true).get()__        IndexStats indexStats = index.getIndex("index")__        long maxUnsafeAutoIdTimestamp = Long.MIN_VALUE__        for (IndexShardStats indexShardStats : indexStats) {_            for (ShardStats shardStats : indexShardStats) {_                SegmentsStats segments = shardStats.getStats().getSegments()__                maxUnsafeAutoIdTimestamp = Math.max(maxUnsafeAutoIdTimestamp, segments.getMaxUnsafeAutoIdTimestamp())__            }_        }_        assertTrue("exception must have been thrown otherwise setup is broken", exceptionThrown.get())__        assertTrue("maxUnsafeAutoIdTimestamp must be > than 0 we have at least one retry", maxUnsafeAutoIdTimestamp > -1)__    };tests,retry,mechanism,when,indexing,if,an,exception,occurs,when,indexing,then,the,indexing,request,is,tried,again,before,finally,failing,if,auto,generated,ids,are,used,this,must,not,lead,to,duplicate,ids,see,https,github,com,elastic,elasticsearch,issues,8788;public,void,test,retry,due,to,exception,on,network,layer,throws,execution,exception,interrupted,exception,ioexception,final,atomic,boolean,exception,thrown,new,atomic,boolean,false,int,num,docs,scaled,random,int,between,100,1000,client,client,internal,cluster,coord,only,node,client,nodes,stats,response,node,stats,client,admin,cluster,prepare,nodes,stats,get,node,stats,unlucky,node,random,from,node,stats,get,nodes,stream,filter,s,s,get,node,is,data,node,collect,collectors,to,list,assert,acked,client,admin,indices,prepare,create,index,set,settings,settings,builder,put,index,1,put,index,5,ensure,green,index,logger,info,unlucky,node,unlucky,node,get,node,for,node,stats,data,node,node,stats,get,nodes,mock,transport,service,mock,transport,service,mock,transport,service,internal,cluster,get,instance,transport,service,class,data,node,get,node,get,name,mock,transport,service,add,send,behavior,internal,cluster,get,instance,transport,service,class,unlucky,node,get,node,get,name,connection,request,id,action,request,options,connection,send,request,request,id,action,request,options,if,action,equals,transport,shard,bulk,action,exception,thrown,compare,and,set,false,true,logger,debug,throw,connect,transport,exception,throw,new,connect,transport,exception,connection,get,node,action,bulk,request,builder,bulk,builder,client,prepare,bulk,for,int,i,0,i,num,docs,i,xcontent,builder,doc,null,doc,json,builder,start,object,field,foo,bar,end,object,bulk,builder,add,client,prepare,index,index,type,set,source,doc,bulk,response,response,bulk,builder,get,if,response,has,failures,for,bulk,item,response,single,index,respons,response,get,items,if,single,index,respons,is,failed,fail,none,of,the,bulk,items,should,fail,but,got,single,index,respons,get,failure,message,refresh,search,response,search,response,client,prepare,search,index,set,size,num,docs,2,add,stored,field,get,set,string,unique,ids,new,hash,set,long,dup,counter,0,boolean,false,for,int,i,0,i,search,response,get,hits,get,hits,length,i,if,unique,ids,add,search,response,get,hits,get,hits,i,get,id,if,search,response,dup,id,response,client,prepare,search,index,set,query,term,query,search,response,get,hits,get,hits,i,get,id,set,explain,true,get,assert,that,dup,id,response,get,hits,get,total,hits,value,greater,than,1l,logger,info,found,a,duplicate,id,for,search,hit,hit,dup,id,response,get,hits,logger,info,doc,was,found,on,shard,hit,get,id,hit,get,shard,get,shard,id,logger,info,will,not,print,anymore,in,case,more,duplicates,are,found,true,dup,counter,assert,search,response,search,response,assert,that,dup,counter,equal,to,0l,assert,hit,count,search,response,num,docs,indices,stats,response,index,client,admin,indices,prepare,stats,index,clear,set,segments,true,get,index,stats,index,stats,index,get,index,index,long,max,unsafe,auto,id,timestamp,long,for,index,shard,stats,index,shard,stats,index,stats,for,shard,stats,shard,stats,index,shard,stats,segments,stats,segments,shard,stats,get,stats,get,segments,max,unsafe,auto,id,timestamp,math,max,max,unsafe,auto,id,timestamp,segments,get,max,unsafe,auto,id,timestamp,assert,true,exception,must,have,been,thrown,otherwise,setup,is,broken,exception,thrown,get,assert,true,max,unsafe,auto,id,timestamp,must,be,than,0,we,have,at,least,one,retry,max,unsafe,auto,id,timestamp,1
