# id;timestamp;commentText;codeText;commentWords;codeWords
CombiIT -> public void testSubAggregationForTopAggregationOnUnmappedField() throws Exception;1524684173;Some top aggs (eg. date_/histogram) that are executed on unmapped fields, will generate an estimate count of buckets - zero._when the sub aggregator is then created, it will take this estimation into account. This used to cause_and an ArrayIndexOutOfBoundsException...;public void testSubAggregationForTopAggregationOnUnmappedField() throws Exception {__        prepareCreate("idx").addMapping("type", jsonBuilder()_                .startObject()_                .startObject("type").startObject("properties")_                    .startObject("name").field("type", "keyword").endObject()_                    .startObject("value").field("type", "integer").endObject()_                .endObject().endObject()_                .endObject()).execute().actionGet()___        ensureSearchable("idx")___        SubAggCollectionMode aggCollectionMode = randomFrom(SubAggCollectionMode.values())__        SearchResponse searchResponse = client().prepareSearch("idx")_                .addAggregation(histogram("values").field("value1").interval(1)_                        .subAggregation(terms("names").field("name")_                                .collectMode(aggCollectionMode )))_                .execute().actionGet()___        assertThat(searchResponse.getHits().getTotalHits(), Matchers.equalTo(0L))__        Histogram values = searchResponse.getAggregations().get("values")__        assertThat(values, notNullValue())__        assertThat(values.getBuckets().isEmpty(), is(true))__    };some,top,aggs,eg,histogram,that,are,executed,on,unmapped,fields,will,generate,an,estimate,count,of,buckets,zero,when,the,sub,aggregator,is,then,created,it,will,take,this,estimation,into,account,this,used,to,cause,and,an,array,index,out,of,bounds,exception;public,void,test,sub,aggregation,for,top,aggregation,on,unmapped,field,throws,exception,prepare,create,idx,add,mapping,type,json,builder,start,object,start,object,type,start,object,properties,start,object,name,field,type,keyword,end,object,start,object,value,field,type,integer,end,object,end,object,end,object,end,object,execute,action,get,ensure,searchable,idx,sub,agg,collection,mode,agg,collection,mode,random,from,sub,agg,collection,mode,values,search,response,search,response,client,prepare,search,idx,add,aggregation,histogram,values,field,value1,interval,1,sub,aggregation,terms,names,field,name,collect,mode,agg,collection,mode,execute,action,get,assert,that,search,response,get,hits,get,total,hits,matchers,equal,to,0l,histogram,values,search,response,get,aggregations,get,values,assert,that,values,not,null,value,assert,that,values,get,buckets,is,empty,is,true
CombiIT -> public void testSubAggregationForTopAggregationOnUnmappedField() throws Exception;1544035746;Some top aggs (eg. date_/histogram) that are executed on unmapped fields, will generate an estimate count of buckets - zero._when the sub aggregator is then created, it will take this estimation into account. This used to cause_and an ArrayIndexOutOfBoundsException...;public void testSubAggregationForTopAggregationOnUnmappedField() throws Exception {__        prepareCreate("idx").addMapping("type", jsonBuilder()_                .startObject()_                .startObject("type").startObject("properties")_                    .startObject("name").field("type", "keyword").endObject()_                    .startObject("value").field("type", "integer").endObject()_                .endObject().endObject()_                .endObject()).execute().actionGet()___        ensureSearchable("idx")___        SubAggCollectionMode aggCollectionMode = randomFrom(SubAggCollectionMode.values())__        SearchResponse searchResponse = client().prepareSearch("idx")_                .addAggregation(histogram("values").field("value1").interval(1)_                        .subAggregation(terms("names").field("name")_                                .collectMode(aggCollectionMode )))_                .execute().actionGet()___        assertThat(searchResponse.getHits().getTotalHits().value, Matchers.equalTo(0L))__        Histogram values = searchResponse.getAggregations().get("values")__        assertThat(values, notNullValue())__        assertThat(values.getBuckets().isEmpty(), is(true))__    };some,top,aggs,eg,histogram,that,are,executed,on,unmapped,fields,will,generate,an,estimate,count,of,buckets,zero,when,the,sub,aggregator,is,then,created,it,will,take,this,estimation,into,account,this,used,to,cause,and,an,array,index,out,of,bounds,exception;public,void,test,sub,aggregation,for,top,aggregation,on,unmapped,field,throws,exception,prepare,create,idx,add,mapping,type,json,builder,start,object,start,object,type,start,object,properties,start,object,name,field,type,keyword,end,object,start,object,value,field,type,integer,end,object,end,object,end,object,end,object,execute,action,get,ensure,searchable,idx,sub,agg,collection,mode,agg,collection,mode,random,from,sub,agg,collection,mode,values,search,response,search,response,client,prepare,search,idx,add,aggregation,histogram,values,field,value1,interval,1,sub,aggregation,terms,names,field,name,collect,mode,agg,collection,mode,execute,action,get,assert,that,search,response,get,hits,get,total,hits,value,matchers,equal,to,0l,histogram,values,search,response,get,aggregations,get,values,assert,that,values,not,null,value,assert,that,values,get,buckets,is,empty,is,true
CombiIT -> public void testSubAggregationForTopAggregationOnUnmappedField() throws Exception;1544110272;Some top aggs (eg. date_/histogram) that are executed on unmapped fields, will generate an estimate count of buckets - zero._when the sub aggregator is then created, it will take this estimation into account. This used to cause_and an ArrayIndexOutOfBoundsException...;public void testSubAggregationForTopAggregationOnUnmappedField() throws Exception {__        prepareCreate("idx").addMapping("type", jsonBuilder()_                .startObject()_                .startObject("type").startObject("properties")_                    .startObject("name").field("type", "keyword").endObject()_                    .startObject("value").field("type", "integer").endObject()_                .endObject().endObject()_                .endObject()).get()___        ensureSearchable("idx")___        SubAggCollectionMode aggCollectionMode = randomFrom(SubAggCollectionMode.values())__        SearchResponse searchResponse = client().prepareSearch("idx")_                .addAggregation(histogram("values").field("value1").interval(1)_                        .subAggregation(terms("names").field("name")_                                .collectMode(aggCollectionMode )))_                .get()___        assertThat(searchResponse.getHits().getTotalHits().value, Matchers.equalTo(0L))__        Histogram values = searchResponse.getAggregations().get("values")__        assertThat(values, notNullValue())__        assertThat(values.getBuckets().isEmpty(), is(true))__    };some,top,aggs,eg,histogram,that,are,executed,on,unmapped,fields,will,generate,an,estimate,count,of,buckets,zero,when,the,sub,aggregator,is,then,created,it,will,take,this,estimation,into,account,this,used,to,cause,and,an,array,index,out,of,bounds,exception;public,void,test,sub,aggregation,for,top,aggregation,on,unmapped,field,throws,exception,prepare,create,idx,add,mapping,type,json,builder,start,object,start,object,type,start,object,properties,start,object,name,field,type,keyword,end,object,start,object,value,field,type,integer,end,object,end,object,end,object,end,object,get,ensure,searchable,idx,sub,agg,collection,mode,agg,collection,mode,random,from,sub,agg,collection,mode,values,search,response,search,response,client,prepare,search,idx,add,aggregation,histogram,values,field,value1,interval,1,sub,aggregation,terms,names,field,name,collect,mode,agg,collection,mode,get,assert,that,search,response,get,hits,get,total,hits,value,matchers,equal,to,0l,histogram,values,search,response,get,aggregations,get,values,assert,that,values,not,null,value,assert,that,values,get,buckets,is,empty,is,true
CombiIT -> public void testMultipleAggsOnSameField_WithDifferentRequiredValueSourceType() throws Exception;1524684173;Making sure that if there are multiple aggregations, working on the same field, yet require different_value source type, they can all still work. It used to fail as we used to cache the ValueSource by the_field name. If the cached value source was of type "bytes" and another aggregation on the field required to see_it as "numeric", it didn't work. Now we cache the Value Sources by a custom key (field name + ValueSource type)_so there's no conflict there.;public void testMultipleAggsOnSameField_WithDifferentRequiredValueSourceType() throws Exception {__        createIndex("idx")__        IndexRequestBuilder[] builders = new IndexRequestBuilder[randomInt(30)]__        IntIntMap values = new IntIntHashMap()__        long missingValues = 0__        for (int i = 0_ i < builders.length_ i++) {_            String name = "name_" + randomIntBetween(1, 10)__            if (rarely()) {_                missingValues++__                builders[i] = client().prepareIndex("idx", "type").setSource(jsonBuilder()_                        .startObject()_                        .field("name", name)_                        .endObject())__            } else {_                int value = randomIntBetween(1, 10)__                values.put(value, values.getOrDefault(value, 0) + 1)__                builders[i] = client().prepareIndex("idx", "type").setSource(jsonBuilder()_                        .startObject()_                        .field("name", name)_                        .field("value", value)_                        .endObject())__            }_        }_        indexRandom(true, builders)__        ensureSearchable()____        SubAggCollectionMode aggCollectionMode = randomFrom(SubAggCollectionMode.values())__        SearchResponse response = client().prepareSearch("idx")_                .addAggregation(missing("missing_values").field("value"))_                .addAggregation(terms("values").field("value")_                        .collectMode(aggCollectionMode ))_                .execute().actionGet()___        assertSearchResponse(response)___        Aggregations aggs = response.getAggregations()___        Missing missing = aggs.get("missing_values")__        assertNotNull(missing)__        assertThat(missing.getDocCount(), equalTo(missingValues))___        Terms terms = aggs.get("values")__        assertNotNull(terms)__        List<? extends Terms.Bucket> buckets = terms.getBuckets()__        assertThat(buckets.size(), equalTo(values.size()))__        for (Terms.Bucket bucket : buckets) {_            values.remove(((Number) bucket.getKey()).intValue())__        }_        assertTrue(values.isEmpty())__    };making,sure,that,if,there,are,multiple,aggregations,working,on,the,same,field,yet,require,different,value,source,type,they,can,all,still,work,it,used,to,fail,as,we,used,to,cache,the,value,source,by,the,field,name,if,the,cached,value,source,was,of,type,bytes,and,another,aggregation,on,the,field,required,to,see,it,as,numeric,it,didn,t,work,now,we,cache,the,value,sources,by,a,custom,key,field,name,value,source,type,so,there,s,no,conflict,there;public,void,throws,exception,create,index,idx,index,request,builder,builders,new,index,request,builder,random,int,30,int,int,map,values,new,int,int,hash,map,long,missing,values,0,for,int,i,0,i,builders,length,i,string,name,random,int,between,1,10,if,rarely,missing,values,builders,i,client,prepare,index,idx,type,set,source,json,builder,start,object,field,name,name,end,object,else,int,value,random,int,between,1,10,values,put,value,values,get,or,default,value,0,1,builders,i,client,prepare,index,idx,type,set,source,json,builder,start,object,field,name,name,field,value,value,end,object,index,random,true,builders,ensure,searchable,sub,agg,collection,mode,agg,collection,mode,random,from,sub,agg,collection,mode,values,search,response,response,client,prepare,search,idx,add,aggregation,missing,field,value,add,aggregation,terms,values,field,value,collect,mode,agg,collection,mode,execute,action,get,assert,search,response,response,aggregations,aggs,response,get,aggregations,missing,missing,aggs,get,assert,not,null,missing,assert,that,missing,get,doc,count,equal,to,missing,values,terms,terms,aggs,get,values,assert,not,null,terms,list,extends,terms,bucket,buckets,terms,get,buckets,assert,that,buckets,size,equal,to,values,size,for,terms,bucket,bucket,buckets,values,remove,number,bucket,get,key,int,value,assert,true,values,is,empty
CombiIT -> public void testMultipleAggsOnSameField_WithDifferentRequiredValueSourceType() throws Exception;1544035746;Making sure that if there are multiple aggregations, working on the same field, yet require different_value source type, they can all still work. It used to fail as we used to cache the ValueSource by the_field name. If the cached value source was of type "bytes" and another aggregation on the field required to see_it as "numeric", it didn't work. Now we cache the Value Sources by a custom key (field name + ValueSource type)_so there's no conflict there.;public void testMultipleAggsOnSameField_WithDifferentRequiredValueSourceType() throws Exception {__        createIndex("idx")__        IndexRequestBuilder[] builders = new IndexRequestBuilder[randomInt(30)]__        IntIntMap values = new IntIntHashMap()__        long missingValues = 0__        for (int i = 0_ i < builders.length_ i++) {_            String name = "name_" + randomIntBetween(1, 10)__            if (rarely()) {_                missingValues++__                builders[i] = client().prepareIndex("idx", "type").setSource(jsonBuilder()_                        .startObject()_                        .field("name", name)_                        .endObject())__            } else {_                int value = randomIntBetween(1, 10)__                values.put(value, values.getOrDefault(value, 0) + 1)__                builders[i] = client().prepareIndex("idx", "type").setSource(jsonBuilder()_                        .startObject()_                        .field("name", name)_                        .field("value", value)_                        .endObject())__            }_        }_        indexRandom(true, builders)__        ensureSearchable()____        SubAggCollectionMode aggCollectionMode = randomFrom(SubAggCollectionMode.values())__        SearchResponse response = client().prepareSearch("idx")_                .addAggregation(missing("missing_values").field("value"))_                .addAggregation(terms("values").field("value")_                        .collectMode(aggCollectionMode ))_                .execute().actionGet()___        assertSearchResponse(response)___        Aggregations aggs = response.getAggregations()___        Missing missing = aggs.get("missing_values")__        assertNotNull(missing)__        assertThat(missing.getDocCount(), equalTo(missingValues))___        Terms terms = aggs.get("values")__        assertNotNull(terms)__        List<? extends Terms.Bucket> buckets = terms.getBuckets()__        assertThat(buckets.size(), equalTo(values.size()))__        for (Terms.Bucket bucket : buckets) {_            values.remove(((Number) bucket.getKey()).intValue())__        }_        assertTrue(values.isEmpty())__    };making,sure,that,if,there,are,multiple,aggregations,working,on,the,same,field,yet,require,different,value,source,type,they,can,all,still,work,it,used,to,fail,as,we,used,to,cache,the,value,source,by,the,field,name,if,the,cached,value,source,was,of,type,bytes,and,another,aggregation,on,the,field,required,to,see,it,as,numeric,it,didn,t,work,now,we,cache,the,value,sources,by,a,custom,key,field,name,value,source,type,so,there,s,no,conflict,there;public,void,throws,exception,create,index,idx,index,request,builder,builders,new,index,request,builder,random,int,30,int,int,map,values,new,int,int,hash,map,long,missing,values,0,for,int,i,0,i,builders,length,i,string,name,random,int,between,1,10,if,rarely,missing,values,builders,i,client,prepare,index,idx,type,set,source,json,builder,start,object,field,name,name,end,object,else,int,value,random,int,between,1,10,values,put,value,values,get,or,default,value,0,1,builders,i,client,prepare,index,idx,type,set,source,json,builder,start,object,field,name,name,field,value,value,end,object,index,random,true,builders,ensure,searchable,sub,agg,collection,mode,agg,collection,mode,random,from,sub,agg,collection,mode,values,search,response,response,client,prepare,search,idx,add,aggregation,missing,field,value,add,aggregation,terms,values,field,value,collect,mode,agg,collection,mode,execute,action,get,assert,search,response,response,aggregations,aggs,response,get,aggregations,missing,missing,aggs,get,assert,not,null,missing,assert,that,missing,get,doc,count,equal,to,missing,values,terms,terms,aggs,get,values,assert,not,null,terms,list,extends,terms,bucket,buckets,terms,get,buckets,assert,that,buckets,size,equal,to,values,size,for,terms,bucket,bucket,buckets,values,remove,number,bucket,get,key,int,value,assert,true,values,is,empty
CombiIT -> public void testMultipleAggsOnSameField_WithDifferentRequiredValueSourceType() throws Exception;1544110272;Making sure that if there are multiple aggregations, working on the same field, yet require different_value source type, they can all still work. It used to fail as we used to cache the ValueSource by the_field name. If the cached value source was of type "bytes" and another aggregation on the field required to see_it as "numeric", it didn't work. Now we cache the Value Sources by a custom key (field name + ValueSource type)_so there's no conflict there.;public void testMultipleAggsOnSameField_WithDifferentRequiredValueSourceType() throws Exception {__        createIndex("idx")__        IndexRequestBuilder[] builders = new IndexRequestBuilder[randomInt(30)]__        IntIntMap values = new IntIntHashMap()__        long missingValues = 0__        for (int i = 0_ i < builders.length_ i++) {_            String name = "name_" + randomIntBetween(1, 10)__            if (rarely()) {_                missingValues++__                builders[i] = client().prepareIndex("idx", "type").setSource(jsonBuilder()_                        .startObject()_                        .field("name", name)_                        .endObject())__            } else {_                int value = randomIntBetween(1, 10)__                values.put(value, values.getOrDefault(value, 0) + 1)__                builders[i] = client().prepareIndex("idx", "type").setSource(jsonBuilder()_                        .startObject()_                        .field("name", name)_                        .field("value", value)_                        .endObject())__            }_        }_        indexRandom(true, builders)__        ensureSearchable()____        SubAggCollectionMode aggCollectionMode = randomFrom(SubAggCollectionMode.values())__        SearchResponse response = client().prepareSearch("idx")_                .addAggregation(missing("missing_values").field("value"))_                .addAggregation(terms("values").field("value")_                        .collectMode(aggCollectionMode ))_                .get()___        assertSearchResponse(response)___        Aggregations aggs = response.getAggregations()___        Missing missing = aggs.get("missing_values")__        assertNotNull(missing)__        assertThat(missing.getDocCount(), equalTo(missingValues))___        Terms terms = aggs.get("values")__        assertNotNull(terms)__        List<? extends Terms.Bucket> buckets = terms.getBuckets()__        assertThat(buckets.size(), equalTo(values.size()))__        for (Terms.Bucket bucket : buckets) {_            values.remove(((Number) bucket.getKey()).intValue())__        }_        assertTrue(values.isEmpty())__    };making,sure,that,if,there,are,multiple,aggregations,working,on,the,same,field,yet,require,different,value,source,type,they,can,all,still,work,it,used,to,fail,as,we,used,to,cache,the,value,source,by,the,field,name,if,the,cached,value,source,was,of,type,bytes,and,another,aggregation,on,the,field,required,to,see,it,as,numeric,it,didn,t,work,now,we,cache,the,value,sources,by,a,custom,key,field,name,value,source,type,so,there,s,no,conflict,there;public,void,throws,exception,create,index,idx,index,request,builder,builders,new,index,request,builder,random,int,30,int,int,map,values,new,int,int,hash,map,long,missing,values,0,for,int,i,0,i,builders,length,i,string,name,random,int,between,1,10,if,rarely,missing,values,builders,i,client,prepare,index,idx,type,set,source,json,builder,start,object,field,name,name,end,object,else,int,value,random,int,between,1,10,values,put,value,values,get,or,default,value,0,1,builders,i,client,prepare,index,idx,type,set,source,json,builder,start,object,field,name,name,field,value,value,end,object,index,random,true,builders,ensure,searchable,sub,agg,collection,mode,agg,collection,mode,random,from,sub,agg,collection,mode,values,search,response,response,client,prepare,search,idx,add,aggregation,missing,field,value,add,aggregation,terms,values,field,value,collect,mode,agg,collection,mode,get,assert,search,response,response,aggregations,aggs,response,get,aggregations,missing,missing,aggs,get,assert,not,null,missing,assert,that,missing,get,doc,count,equal,to,missing,values,terms,terms,aggs,get,values,assert,not,null,terms,list,extends,terms,bucket,buckets,terms,get,buckets,assert,that,buckets,size,equal,to,values,size,for,terms,bucket,bucket,buckets,values,remove,number,bucket,get,key,int,value,assert,true,values,is,empty
