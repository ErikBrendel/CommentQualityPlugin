commented;modifiers;parameterAmount;loc;comment;code
false;protected;0;4;;@Override protected Collection<Class<? extends Plugin>> nodePlugins() {     return Arrays.asList(MockTransportService.TestPlugin.class, MockEngineFactoryPlugin.class, InternalSettingsPlugin.class). }
false;public;0;94;;public void testFailedRecoveryOnAllocateStalePrimaryRequiresAnotherAllocateStalePrimary() throws Exception {     /*          * Allocation id is put on start of shard while historyUUID is adjusted after recovery is done.          *          * If during execution of AllocateStalePrimary a proper allocation id is stored in allocation id set and recovery is failed          * shard restart skips the stage where historyUUID is changed.          *          * That leads to situation where allocated stale primary and its replica belongs to the same historyUUID and          * replica will receive operations after local checkpoint while documents before checkpoints could be significant different.          *          * Therefore, on AllocateStalePrimary we put some fake allocation id (no real one could be generated like that)          * and any failure during recovery requires extra AllocateStalePrimary command to be executed.          */     // initial set up     final String indexName = "index42".     final String master = internalCluster().startMasterOnlyNode().     String node1 = internalCluster().startNode().     createIndex(indexName, Settings.builder().put(IndexMetaData.SETTING_NUMBER_OF_SHARDS, 1).put(IndexMetaData.SETTING_NUMBER_OF_REPLICAS, 1).put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), "checksum").build()).     final int numDocs = indexDocs(indexName, "foo", "bar").     final IndexSettings indexSettings = getIndexSettings(indexName, node1).     final Set<String> allocationIds = getAllocationIds(indexName).     final ShardId shardId = new ShardId(resolveIndex(indexName), 0).     final Path indexPath = getIndexPath(node1, shardId).     assertThat(allocationIds, hasSize(1)).     final String historyUUID = historyUUID(node1, indexName).     String node2 = internalCluster().startNode().     ensureGreen(indexName).     internalCluster().assertSameDocIdsOnShards().     // initial set up is done     internalCluster().stopRandomNode(InternalTestCluster.nameFilter(node1)).     // index more docs to node2 that marks node1 as stale     int numExtraDocs = indexDocs(indexName, "foo", "bar2").     assertHitCount(client(node2).prepareSearch(indexName).setQuery(matchAllQuery()).get(), numDocs + numExtraDocs).     internalCluster().stopRandomNode(InternalTestCluster.nameFilter(node2)).     // create fake corrupted marker on node1     putFakeCorruptionMarker(indexSettings, shardId, indexPath).     // thanks to master node1 is out of sync     node1 = internalCluster().startNode().     // there is only _stale_ primary     checkNoValidShardCopy(indexName, shardId).     // allocate stale primary     client(node1).admin().cluster().prepareReroute().add(new AllocateStalePrimaryAllocationCommand(indexName, 0, node1, true)).get().     // allocation fails due to corruption marker     assertBusy(() -> {         final ClusterState state = client().admin().cluster().prepareState().get().getState().         final ShardRouting shardRouting = state.routingTable().index(indexName).shard(shardId.id()).primaryShard().         assertThat(shardRouting.state(), equalTo(ShardRoutingState.UNASSIGNED)).         assertThat(shardRouting.unassignedInfo().getReason(), equalTo(UnassignedInfo.Reason.ALLOCATION_FAILED)).     }).     try (Store store = new Store(shardId, indexSettings, new SimpleFSDirectory(indexPath), new DummyShardLock(shardId))) {         store.removeCorruptionMarker().     }     // index is red: no any shard is allocated (allocation id is a fake id that does not match to anything)     checkHealthStatus(indexName, ClusterHealthStatus.RED).     checkNoValidShardCopy(indexName, shardId).     internalCluster().restartNode(node1, InternalTestCluster.EMPTY_CALLBACK).     // index is still red due to mismatch of allocation id     checkHealthStatus(indexName, ClusterHealthStatus.RED).     checkNoValidShardCopy(indexName, shardId).     // no any valid shard is there. have to invoke AllocateStalePrimary again     client().admin().cluster().prepareReroute().add(new AllocateStalePrimaryAllocationCommand(indexName, 0, node1, true)).get().     ensureYellow(indexName).     // bring node2 back     node2 = internalCluster().startNode().     ensureGreen(indexName).     assertThat(historyUUID(node1, indexName), not(equalTo(historyUUID))).     assertThat(historyUUID(node1, indexName), equalTo(historyUUID(node2, indexName))).     internalCluster().assertSameDocIdsOnShards(). }
false;public;2;5;;public void checkHealthStatus(String indexName, ClusterHealthStatus healthStatus) {     final ClusterHealthStatus indexHealthStatus = client().admin().cluster().health(Requests.clusterHealthRequest(indexName)).actionGet().getStatus().     assertThat(indexHealthStatus, is(healthStatus)). }
false;private;2;16;;private int indexDocs(String indexName, Object... source) throws InterruptedException, ExecutionException {     // index some docs in several segments     int numDocs = 0.     for (int k = 0, attempts = randomIntBetween(5, 10). k < attempts. k++) {         final int numExtraDocs = between(10, 100).         IndexRequestBuilder[] builders = new IndexRequestBuilder[numExtraDocs].         for (int i = 0. i < builders.length. i++) {             builders[i] = client().prepareIndex(indexName, "type").setSource(source).         }         indexRandom(true, false, true, Arrays.asList(builders)).         numDocs += numExtraDocs.     }     return numDocs. }
false;private;2;5;;private Path getIndexPath(String nodeName, ShardId shardId) {     final Set<Path> indexDirs = RemoveCorruptedShardDataCommandIT.getDirs(nodeName, shardId, ShardPath.INDEX_FOLDER_NAME).     assertThat(indexDirs, hasSize(1)).     return indexDirs.iterator().next(). }
false;private;1;5;;private Set<String> getAllocationIds(String indexName) {     final ClusterState state = client().admin().cluster().prepareState().get().getState().     final Set<String> allocationIds = state.metaData().index(indexName).inSyncAllocationIds(0).     return allocationIds. }
false;private;2;5;;private IndexSettings getIndexSettings(String indexName, String nodeName) {     final IndicesService indicesService = internalCluster().getInstance(IndicesService.class, nodeName).     final IndexService indexService = indicesService.indexService(resolveIndex(indexName)).     return indexService.getIndexSettings(). }
false;private;2;9;;private String historyUUID(String node, String indexName) {     final ShardStats[] shards = client(node).admin().indices().prepareStats(indexName).clear().get().getShards().     assertThat(shards.length, greaterThan(0)).     final Set<String> historyUUIDs = Arrays.stream(shards).map(shard -> shard.getCommitStats().getUserData().get(Engine.HISTORY_UUID_KEY)).collect(Collectors.toSet()).     assertThat(historyUUIDs, hasSize(1)).     return historyUUIDs.iterator().next(). }
false;private;3;5;;private void putFakeCorruptionMarker(IndexSettings indexSettings, ShardId shardId, Path indexPath) throws IOException {     try (Store store = new Store(shardId, indexSettings, new SimpleFSDirectory(indexPath), new DummyShardLock(shardId))) {         store.markStoreCorrupted(new IOException("fake ioexception")).     } }
false;private;2;13;;private void checkNoValidShardCopy(String indexName, ShardId shardId) throws Exception {     assertBusy(() -> {         final ClusterAllocationExplanation explanation = client().admin().cluster().prepareAllocationExplain().setIndex(indexName).setShard(shardId.id()).setPrimary(true).get().getExplanation().         final ShardAllocationDecision shardAllocationDecision = explanation.getShardAllocationDecision().         assertThat(shardAllocationDecision.isDecisionTaken(), equalTo(true)).         assertThat(shardAllocationDecision.getAllocateDecision().getAllocationDecision(), equalTo(AllocationDecision.NO_VALID_SHARD_COPY)).     }). }
