commented;modifiers;parameterAmount;loc;comment;code
false;public;0;15;;public void testDefault() throws IOException {     ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(Settings.builder().put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).put("index.analysis.filter.my_word_delimiter.type", type).build(), new CommonAnalysisPlugin()).     TokenFilterFactory tokenFilter = analysis.tokenFilter.get("my_word_delimiter").     String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's".     String[] expected = new String[] { "Power", "Shot", "500", "42", "wi", "fi", "wi", "fi", "4000", "j", "2", "se", "O", "Neil" }.     Tokenizer tokenizer = new WhitespaceTokenizer().     tokenizer.setReader(new StringReader(source)).     assertTokenStreamContents(tokenFilter.create(tokenizer), expected). }
false;public;0;17;;public void testCatenateWords() throws IOException {     ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(Settings.builder().put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).put("index.analysis.filter.my_word_delimiter.type", type).put("index.analysis.filter.my_word_delimiter.catenate_words", "true").put("index.analysis.filter.my_word_delimiter.generate_word_parts", "false").build(), new CommonAnalysisPlugin()).     TokenFilterFactory tokenFilter = analysis.tokenFilter.get("my_word_delimiter").     String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's".     String[] expected = new String[] { "PowerShot", "500", "42", "wifi", "wifi", "4000", "j", "2", "se", "ONeil" }.     Tokenizer tokenizer = new WhitespaceTokenizer().     tokenizer.setReader(new StringReader(source)).     assertTokenStreamContents(tokenFilter.create(tokenizer), expected). }
false;public;0;17;;public void testCatenateNumbers() throws IOException {     ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(Settings.builder().put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).put("index.analysis.filter.my_word_delimiter.type", type).put("index.analysis.filter.my_word_delimiter.generate_number_parts", "false").put("index.analysis.filter.my_word_delimiter.catenate_numbers", "true").build(), new CommonAnalysisPlugin()).     TokenFilterFactory tokenFilter = analysis.tokenFilter.get("my_word_delimiter").     String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's".     String[] expected = new String[] { "Power", "Shot", "50042", "wi", "fi", "wi", "fi", "4000", "j", "2", "se", "O", "Neil" }.     Tokenizer tokenizer = new WhitespaceTokenizer().     tokenizer.setReader(new StringReader(source)).     assertTokenStreamContents(tokenFilter.create(tokenizer), expected). }
false;public;0;17;;public void testCatenateAll() throws IOException {     ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(Settings.builder().put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).put("index.analysis.filter.my_word_delimiter.type", type).put("index.analysis.filter.my_word_delimiter.generate_word_parts", "false").put("index.analysis.filter.my_word_delimiter.generate_number_parts", "false").put("index.analysis.filter.my_word_delimiter.catenate_all", "true").build(), new CommonAnalysisPlugin()).     TokenFilterFactory tokenFilter = analysis.tokenFilter.get("my_word_delimiter").     String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's".     String[] expected = new String[] { "PowerShot", "50042", "wifi", "wifi4000", "j2se", "ONeil" }.     Tokenizer tokenizer = new WhitespaceTokenizer().     tokenizer.setReader(new StringReader(source)).     assertTokenStreamContents(tokenFilter.create(tokenizer), expected). }
false;public;0;15;;public void testSplitOnCaseChange() throws IOException {     ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(Settings.builder().put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).put("index.analysis.filter.my_word_delimiter.type", type).put("index.analysis.filter.my_word_delimiter.split_on_case_change", "false").build(), new CommonAnalysisPlugin()).     TokenFilterFactory tokenFilter = analysis.tokenFilter.get("my_word_delimiter").     String source = "PowerShot".     String[] expected = new String[] { "PowerShot" }.     Tokenizer tokenizer = new WhitespaceTokenizer().     tokenizer.setReader(new StringReader(source)).     assertTokenStreamContents(tokenFilter.create(tokenizer), expected). }
false;public;0;17;;public void testPreserveOriginal() throws IOException {     ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(Settings.builder().put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).put("index.analysis.filter.my_word_delimiter.type", type).put("index.analysis.filter.my_word_delimiter.preserve_original", "true").build(), new CommonAnalysisPlugin()).     TokenFilterFactory tokenFilter = analysis.tokenFilter.get("my_word_delimiter").     String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's".     String[] expected = new String[] { "PowerShot", "Power", "Shot", "500-42", "500", "42", "wi-fi", "wi", "fi", "wi-fi-4000", "wi", "fi", "4000", "j2se", "j", "2", "se", "O'Neil's", "O", "Neil" }.     Tokenizer tokenizer = new WhitespaceTokenizer().     tokenizer.setReader(new StringReader(source)).     assertTokenStreamContents(tokenFilter.create(tokenizer), expected). }
false;public;0;16;;public void testStemEnglishPossessive() throws IOException {     ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(Settings.builder().put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).put("index.analysis.filter.my_word_delimiter.type", type).put("index.analysis.filter.my_word_delimiter.stem_english_possessive", "false").build(), new CommonAnalysisPlugin()).     TokenFilterFactory tokenFilter = analysis.tokenFilter.get("my_word_delimiter").     String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's".     String[] expected = new String[] { "Power", "Shot", "500", "42", "wi", "fi", "wi", "fi", "4000", "j", "2", "se", "O", "Neil", "s" }.     Tokenizer tokenizer = new WhitespaceTokenizer().     tokenizer.setReader(new StringReader(source)).     assertTokenStreamContents(tokenFilter.create(tokenizer), expected). }
