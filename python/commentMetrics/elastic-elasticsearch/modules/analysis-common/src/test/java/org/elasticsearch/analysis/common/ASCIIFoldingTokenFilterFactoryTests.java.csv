commented;modifiers;parameterAmount;loc;comment;code
false;public;0;14;;public void testDefault() throws IOException {     ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(Settings.builder().put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).put("index.analysis.filter.my_ascii_folding.type", "asciifolding").build(), new CommonAnalysisPlugin()).     TokenFilterFactory tokenFilter = analysis.tokenFilter.get("my_ascii_folding").     String source = "Ansprüche".     String[] expected = new String[] { "Anspruche" }.     Tokenizer tokenizer = new WhitespaceTokenizer().     tokenizer.setReader(new StringReader(source)).     assertTokenStreamContents(tokenFilter.create(tokenizer), expected). }
false;public;0;21;;public void testPreserveOriginal() throws IOException {     ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(Settings.builder().put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString()).put("index.analysis.filter.my_ascii_folding.type", "asciifolding").put("index.analysis.filter.my_ascii_folding.preserve_original", true).build(), new CommonAnalysisPlugin()).     TokenFilterFactory tokenFilter = analysis.tokenFilter.get("my_ascii_folding").     String source = "Ansprüche".     String[] expected = new String[] { "Anspruche", "Ansprüche" }.     Tokenizer tokenizer = new WhitespaceTokenizer().     tokenizer.setReader(new StringReader(source)).     assertTokenStreamContents(tokenFilter.create(tokenizer), expected).     // but the multi-term aware component still emits a single token     tokenizer = new WhitespaceTokenizer().     tokenizer.setReader(new StringReader(source)).     expected = new String[] { "Anspruche" }.     assertTokenStreamContents(tokenFilter.normalize(tokenizer), expected). }
