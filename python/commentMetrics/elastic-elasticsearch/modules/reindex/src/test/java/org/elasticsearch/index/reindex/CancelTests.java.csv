commented;modifiers;parameterAmount;loc;comment;code
false;protected;0;7;;@Override protected Collection<Class<? extends Plugin>> nodePlugins() {     Collection<Class<? extends Plugin>> plugins = new ArrayList<>(super.nodePlugins()).     plugins.add(IngestTestPlugin.class).     plugins.add(ReindexCancellationPlugin.class).     return plugins. }
false;public;0;4;;@Before public void clearAllowedOperations() {     ALLOWED_OPERATIONS.drainPermits(). }
true;private;4;109;/**  * Executes the cancellation test  */ ;/**  * Executes the cancellation test  */ private void testCancel(String action, AbstractBulkByScrollRequestBuilder<?, ?> builder, CancelAssertion assertion, Matcher<String> taskDescriptionMatcher) throws Exception {     createIndex(INDEX).     // Total number of documents created for this test (~10 per primary shard per slice)     int numDocs = getNumShards(INDEX).numPrimaries * 10 * builder.request().getSlices().     ALLOWED_OPERATIONS.release(numDocs).     logger.debug("setting up [{}] docs", numDocs).     indexRandom(true, false, true, IntStream.range(0, numDocs).mapToObj(i -> client().prepareIndex(INDEX, TYPE, String.valueOf(i)).setSource("n", i)).collect(Collectors.toList())).     // Checks that the all documents have been indexed and correctly counted     assertHitCount(client().prepareSearch(INDEX).setSize(0).get(), numDocs).     assertThat(ALLOWED_OPERATIONS.drainPermits(), equalTo(0)).     // Scroll by 1 so that cancellation is easier to control     builder.source().setSize(1).     /* Allow a random number of the documents less the number of workers          * to be modified by the reindex action. That way at least one worker          * is blocked. */     int numModifiedDocs = randomIntBetween(builder.request().getSlices() * 2, numDocs).     logger.debug("chose to modify [{}] out of [{}] docs", numModifiedDocs, numDocs).     ALLOWED_OPERATIONS.release(numModifiedDocs - builder.request().getSlices()).     // Now execute the reindex action...     ActionFuture<? extends BulkByScrollResponse> future = builder.execute().     /* ... and wait for the indexing operation listeners to block. It          * is important to realize that some of the workers might have          * exhausted their slice while others might have quite a bit left          * to work on. We can't control that. */     logger.debug("waiting for updates to be blocked").     boolean blocked = awaitBusy(() -> ALLOWED_OPERATIONS.hasQueuedThreads() && ALLOWED_OPERATIONS.availablePermits() == 0, 1, // 10 seconds is usually fine but on heavily loaded machines this can take a while     TimeUnit.MINUTES).     assertTrue("updates blocked", blocked).     // Status should show the task running     TaskInfo mainTask = findTaskToCancel(action, builder.request().getSlices()).     BulkByScrollTask.Status status = (BulkByScrollTask.Status) mainTask.getStatus().     assertNull(status.getReasonCancelled()).     // Description shouldn't be empty     assertThat(mainTask.getDescription(), taskDescriptionMatcher).     // Cancel the request while the action is blocked by the indexing operation listeners.     // This will prevent further requests from being sent.     ListTasksResponse cancelTasksResponse = client().admin().cluster().prepareCancelTasks().setTaskId(mainTask.getTaskId()).get().     cancelTasksResponse.rethrowFailures("Cancel").     assertThat(cancelTasksResponse.getTasks(), hasSize(1)).     /* The status should now show canceled. The request will still be in the          * list because it is (or its children are) still blocked. */     mainTask = client().admin().cluster().prepareGetTask(mainTask.getTaskId()).get().getTask().getTask().     status = (BulkByScrollTask.Status) mainTask.getStatus().     logger.debug("asserting that parent is marked canceled {}", status).     assertEquals(CancelTasksRequest.DEFAULT_REASON, status.getReasonCancelled()).     if (builder.request().getSlices() > 1) {         boolean foundCancelled = false.         ListTasksResponse sliceList = client().admin().cluster().prepareListTasks().setParentTaskId(mainTask.getTaskId()).setDetailed(true).get().         sliceList.rethrowFailures("Fetch slice tasks").         logger.debug("finding at least one canceled child among {}", sliceList.getTasks()).         for (TaskInfo slice : sliceList.getTasks()) {             BulkByScrollTask.Status sliceStatus = (BulkByScrollTask.Status) slice.getStatus().             if (sliceStatus.getReasonCancelled() == null)                 continue.             assertEquals(CancelTasksRequest.DEFAULT_REASON, sliceStatus.getReasonCancelled()).             foundCancelled = true.         }         assertTrue("Didn't find at least one sub task that was cancelled", foundCancelled).     }     logger.debug("unblocking the blocked update").     ALLOWED_OPERATIONS.release(builder.request().getSlices()).     // Checks that no more operations are executed     assertBusy(() -> {         if (builder.request().getSlices() == 1) {             /* We can only be sure that we've drained all the permits if we only use a single worker. Otherwise some worker may have                  * exhausted all of its documents before we blocked. */             assertEquals(0, ALLOWED_OPERATIONS.availablePermits()).         }         assertEquals(0, ALLOWED_OPERATIONS.getQueueLength()).     }).     // And check the status of the response     BulkByScrollResponse response.     try {         response = future.get(30, TimeUnit.SECONDS).     } catch (Exception e) {         String tasks = client().admin().cluster().prepareListTasks().setParentTaskId(mainTask.getTaskId()).setDetailed(true).get().toString().         throw new RuntimeException("Exception while waiting for the response. Running tasks: " + tasks, e).     }     assertThat(response.getReasonCancelled(), equalTo("by user request")).     assertThat(response.getBulkFailures(), emptyIterable()).     assertThat(response.getSearchFailures(), emptyIterable()).     if (builder.request().getSlices() >= 1) {         // If we have more than one worker we might not have made all the modifications         numModifiedDocs -= ALLOWED_OPERATIONS.availablePermits().     }     flushAndRefresh(INDEX).     assertion.assertThat(response, numDocs, numModifiedDocs). }
false;public,static;2;15;;public static TaskInfo findTaskToCancel(String actionName, int workerCount) {     ListTasksResponse tasks.     long start = System.nanoTime().     do {         tasks = client().admin().cluster().prepareListTasks().setActions(actionName).setDetailed(true).get().         tasks.rethrowFailures("Find tasks to cancel").         for (TaskInfo taskInfo : tasks.getTasks()) {             // Skip tasks with a parent because those are children of the task we want to cancel             if (false == taskInfo.getParentTaskId().isSet()) {                 return taskInfo.             }         }     } while (System.nanoTime() - start < TimeUnit.SECONDS.toNanos(10)).     throw new AssertionError("Couldn't find task to rethrottle after waiting tasks=" + tasks.getTasks()). }
false;public;0;8;;public void testReindexCancel() throws Exception {     testCancel(ReindexAction.NAME, reindex().source(INDEX).destination("dest", TYPE), (response, total, modified) -> {         assertThat(response, matcher().created(modified).reasonCancelled(equalTo("by user request"))).         refresh("dest").         assertHitCount(client().prepareSearch("dest").setTypes(TYPE).setSize(0).get(), modified).     }, equalTo("reindex from [" + INDEX + "] to [dest][" + TYPE + "]")). }
false;public;0;16;;public void testUpdateByQueryCancel() throws Exception {     BytesReference pipeline = new BytesArray("{\n" + "  \"description\" : \"sets processed to true\",\n" + "  \"processors\" : [ {\n" + "      \"test\" : {}\n" + "  } ]\n" + "}").     assertAcked(client().admin().cluster().preparePutPipeline("set-processed", pipeline, XContentType.JSON).get()).     testCancel(UpdateByQueryAction.NAME, updateByQuery().setPipeline("set-processed").source(INDEX), (response, total, modified) -> {         assertThat(response, matcher().updated(modified).reasonCancelled(equalTo("by user request"))).         assertHitCount(client().prepareSearch(INDEX).setSize(0).setQuery(termQuery("processed", true)).get(), modified).     }, equalTo("update-by-query [" + INDEX + "]")).     assertAcked(client().admin().cluster().deletePipeline(new DeletePipelineRequest("set-processed")).get()). }
false;public;0;7;;public void testDeleteByQueryCancel() throws Exception {     testCancel(DeleteByQueryAction.NAME, deleteByQuery().source(INDEX).filter(QueryBuilders.matchAllQuery()), (response, total, modified) -> {         assertThat(response, matcher().deleted(modified).reasonCancelled(equalTo("by user request"))).         assertHitCount(client().prepareSearch(INDEX).setSize(0).get(), total - modified).     }, equalTo("delete-by-query [" + INDEX + "]")). }
false;public;0;10;;public void testReindexCancelWithWorkers() throws Exception {     testCancel(ReindexAction.NAME, reindex().source(INDEX).filter(QueryBuilders.matchAllQuery()).destination("dest", TYPE).setSlices(5), (response, total, modified) -> {         assertThat(response, matcher().created(modified).reasonCancelled(equalTo("by user request")).slices(hasSize(5))).         refresh("dest").         assertHitCount(client().prepareSearch("dest").setTypes(TYPE).setSize(0).get(), modified).     }, equalTo("reindex from [" + INDEX + "] to [dest][" + TYPE + "]")). }
false;public;0;17;;public void testUpdateByQueryCancelWithWorkers() throws Exception {     BytesReference pipeline = new BytesArray("{\n" + "  \"description\" : \"sets processed to true\",\n" + "  \"processors\" : [ {\n" + "      \"test\" : {}\n" + "  } ]\n" + "}").     assertAcked(client().admin().cluster().preparePutPipeline("set-processed", pipeline, XContentType.JSON).get()).     testCancel(UpdateByQueryAction.NAME, updateByQuery().setPipeline("set-processed").source(INDEX).setSlices(5), (response, total, modified) -> {         assertThat(response, matcher().updated(modified).reasonCancelled(equalTo("by user request")).slices(hasSize(5))).         assertHitCount(client().prepareSearch(INDEX).setSize(0).setQuery(termQuery("processed", true)).get(), modified).     }, equalTo("update-by-query [" + INDEX + "]")).     assertAcked(client().admin().cluster().deletePipeline(new DeletePipelineRequest("set-processed")).get()). }
false;public;0;7;;public void testDeleteByQueryCancelWithWorkers() throws Exception {     testCancel(DeleteByQueryAction.NAME, deleteByQuery().source(INDEX).filter(QueryBuilders.matchAllQuery()).setSlices(5), (response, total, modified) -> {         assertThat(response, matcher().deleted(modified).reasonCancelled(equalTo("by user request")).slices(hasSize(5))).         assertHitCount(client().prepareSearch(INDEX).setSize(0).get(), total - modified).     }, equalTo("delete-by-query [" + INDEX + "]")). }
false;;3;1;;void assertThat(BulkByScrollResponse response, int total, int modified).
false;public;1;4;;@Override public void onIndexModule(IndexModule indexModule) {     indexModule.addIndexOperationListener(new BlockingOperationListener()). }
false;public;2;4;;@Override public Engine.Index preIndex(ShardId shardId, Engine.Index index) {     return preCheck(index, index.type()). }
false;public;2;4;;@Override public Engine.Delete preDelete(ShardId shardId, Engine.Delete delete) {     return preCheck(delete, delete.type()). }
false;private;2;16;;private <T extends Engine.Operation> T preCheck(T operation, String type) {     if ((TYPE.equals(type) == false) || (operation.origin() != Origin.PRIMARY)) {         return operation.     }     try {         log.debug("checking").         if (ALLOWED_OPERATIONS.tryAcquire(30, TimeUnit.SECONDS)) {             log.debug("passed").             return operation.         }     } catch (InterruptedException e) {         throw new RuntimeException(e).     }     throw new IllegalStateException("Something went wrong"). }
