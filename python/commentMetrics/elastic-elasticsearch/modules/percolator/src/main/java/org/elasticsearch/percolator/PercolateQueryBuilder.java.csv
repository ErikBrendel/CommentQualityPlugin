commented;modifiers;parameterAmount;loc;comment;code
true;public;1;4;/**  * Sets the name used for identification purposes in <code>_percolator_document_slot</code> response field  * when multiple percolate queries have been specified in the main query.  */ ;/**  * Sets the name used for identification purposes in <code>_percolator_document_slot</code> response field  * when multiple percolate queries have been specified in the main query.  */ public PercolateQueryBuilder setName(String name) {     this.name = name.     return this. }
false;protected;1;41;;@Override protected void doWriteTo(StreamOutput out) throws IOException {     if (documentSupplier != null) {         throw new IllegalStateException("supplier must be null, can't serialize suppliers, missing a rewriteAndFetch?").     }     out.writeString(field).     if (out.getVersion().onOrAfter(Version.V_6_1_0)) {         out.writeOptionalString(name).     }     if (out.getVersion().before(Version.V_6_0_0_beta1)) {         out.writeString(documentType).     } else {         out.writeOptionalString(documentType).     }     out.writeOptionalString(indexedDocumentIndex).     out.writeOptionalString(indexedDocumentType).     out.writeOptionalString(indexedDocumentId).     out.writeOptionalString(indexedDocumentRouting).     out.writeOptionalString(indexedDocumentPreference).     if (indexedDocumentVersion != null) {         out.writeBoolean(true).         out.writeVLong(indexedDocumentVersion).     } else {         out.writeBoolean(false).     }     if (out.getVersion().onOrAfter(Version.V_6_1_0)) {         out.writeVInt(documents.size()).         for (BytesReference document : documents) {             out.writeBytesReference(document).         }     } else {         if (documents.size() > 1) {             throw new IllegalArgumentException("Nodes prior to 6.1.0 cannot accept multiple documents").         }         BytesReference doc = documents.isEmpty() ? null : documents.iterator().next().         out.writeOptionalBytesReference(doc).     }     if (documents.isEmpty() == false) {         out.writeEnum(documentXContentType).     } }
false;protected;2;42;;@Override protected void doXContent(XContentBuilder builder, Params params) throws IOException {     builder.startObject(NAME).     builder.field(DOCUMENT_TYPE_FIELD.getPreferredName(), documentType).     builder.field(QUERY_FIELD.getPreferredName(), field).     if (name != null) {         builder.field(NAME_FIELD.getPreferredName(), name).     }     if (documents.isEmpty() == false) {         builder.startArray(DOCUMENTS_FIELD.getPreferredName()).         for (BytesReference document : documents) {             try (XContentParser parser = XContentHelper.createParser(NamedXContentRegistry.EMPTY, LoggingDeprecationHandler.INSTANCE, document)) {                 parser.nextToken().                 builder.generator().copyCurrentStructure(parser).             }         }         builder.endArray().     }     if (indexedDocumentIndex != null || indexedDocumentType != null || indexedDocumentId != null) {         if (indexedDocumentIndex != null) {             builder.field(INDEXED_DOCUMENT_FIELD_INDEX.getPreferredName(), indexedDocumentIndex).         }         if (indexedDocumentType != null) {             builder.field(INDEXED_DOCUMENT_FIELD_TYPE.getPreferredName(), indexedDocumentType).         }         if (indexedDocumentId != null) {             builder.field(INDEXED_DOCUMENT_FIELD_ID.getPreferredName(), indexedDocumentId).         }         if (indexedDocumentRouting != null) {             builder.field(INDEXED_DOCUMENT_FIELD_ROUTING.getPreferredName(), indexedDocumentRouting).         }         if (indexedDocumentPreference != null) {             builder.field(INDEXED_DOCUMENT_FIELD_PREFERENCE.getPreferredName(), indexedDocumentPreference).         }         if (indexedDocumentVersion != null) {             builder.field(INDEXED_DOCUMENT_FIELD_VERSION.getPreferredName(), indexedDocumentVersion).         }     }     printBoostAndQueryName(builder).     builder.endObject(). }
false;public,static;1;114;;public static PercolateQueryBuilder fromXContent(XContentParser parser) throws IOException {     float boost = AbstractQueryBuilder.DEFAULT_BOOST.     String field = null.     String name = null.     String documentType = null.     String indexedDocumentIndex = null.     String indexedDocumentType = null.     String indexedDocumentId = null.     String indexedDocumentRouting = null.     String indexedDocumentPreference = null.     Long indexedDocumentVersion = null.     List<BytesReference> documents = new ArrayList<>().     String queryName = null.     String currentFieldName = null.     boolean documentsSpecified = false.     boolean documentSpecified = false.     XContentParser.Token token.     while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {         if (token == XContentParser.Token.FIELD_NAME) {             currentFieldName = parser.currentName().         } else if (token == XContentParser.Token.START_ARRAY) {             if (DOCUMENTS_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {                 if (documentSpecified) {                     throw new IllegalArgumentException("[" + PercolateQueryBuilder.NAME + "] Either specified [document] or [documents], not both").                 }                 documentsSpecified = true.                 while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {                     if (token == XContentParser.Token.START_OBJECT) {                         try (XContentBuilder builder = XContentFactory.jsonBuilder()) {                             builder.copyCurrentStructure(parser).                             builder.flush().                             documents.add(BytesReference.bytes(builder)).                         }                     } else {                         throw new ParsingException(parser.getTokenLocation(), "[" + PercolateQueryBuilder.NAME + "] query does not support [" + token + "]").                     }                 }             } else {                 throw new ParsingException(parser.getTokenLocation(), "[" + PercolateQueryBuilder.NAME + "] query does not field name [" + currentFieldName + "]").             }         } else if (token == XContentParser.Token.START_OBJECT) {             if (DOCUMENT_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {                 if (documentsSpecified) {                     throw new IllegalArgumentException("[" + PercolateQueryBuilder.NAME + "] Either specified [document] or [documents], not both").                 }                 documentSpecified = true.                 try (XContentBuilder builder = XContentFactory.jsonBuilder()) {                     builder.copyCurrentStructure(parser).                     builder.flush().                     documents.add(BytesReference.bytes(builder)).                 }             } else {                 throw new ParsingException(parser.getTokenLocation(), "[" + PercolateQueryBuilder.NAME + "] query does not support field name [" + currentFieldName + "]").             }         } else if (token.isValue() || token == XContentParser.Token.VALUE_NULL) {             if (QUERY_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {                 field = parser.text().             } else if (NAME_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {                 name = parser.textOrNull().             } else if (DOCUMENT_TYPE_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {                 documentType = parser.textOrNull().             } else if (INDEXED_DOCUMENT_FIELD_INDEX.match(currentFieldName, parser.getDeprecationHandler())) {                 indexedDocumentIndex = parser.text().             } else if (INDEXED_DOCUMENT_FIELD_TYPE.match(currentFieldName, parser.getDeprecationHandler())) {                 indexedDocumentType = parser.text().             } else if (INDEXED_DOCUMENT_FIELD_ID.match(currentFieldName, parser.getDeprecationHandler())) {                 indexedDocumentId = parser.text().             } else if (INDEXED_DOCUMENT_FIELD_ROUTING.match(currentFieldName, parser.getDeprecationHandler())) {                 indexedDocumentRouting = parser.text().             } else if (INDEXED_DOCUMENT_FIELD_PREFERENCE.match(currentFieldName, parser.getDeprecationHandler())) {                 indexedDocumentPreference = parser.text().             } else if (INDEXED_DOCUMENT_FIELD_VERSION.match(currentFieldName, parser.getDeprecationHandler())) {                 indexedDocumentVersion = parser.longValue().             } else if (AbstractQueryBuilder.BOOST_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {                 boost = parser.floatValue().             } else if (AbstractQueryBuilder.NAME_FIELD.match(currentFieldName, parser.getDeprecationHandler())) {                 queryName = parser.text().             } else {                 throw new ParsingException(parser.getTokenLocation(), "[" + PercolateQueryBuilder.NAME + "] query does not support [" + currentFieldName + "]").             }         } else {             throw new ParsingException(parser.getTokenLocation(), "[" + PercolateQueryBuilder.NAME + "] query does not support [" + token + "]").         }     }     PercolateQueryBuilder queryBuilder.     if (documents.isEmpty() == false) {         queryBuilder = new PercolateQueryBuilder(field, documentType, documents, XContentType.JSON).     } else if (indexedDocumentId != null) {         queryBuilder = new PercolateQueryBuilder(field, documentType, indexedDocumentIndex, indexedDocumentType, indexedDocumentId, indexedDocumentRouting, indexedDocumentPreference, indexedDocumentVersion).     } else {         throw new IllegalArgumentException("[" + PercolateQueryBuilder.NAME + "] query, nothing to percolate").     }     if (name != null) {         queryBuilder.setName(name).     }     queryBuilder.queryName(queryName).     queryBuilder.boost(boost).     return queryBuilder. }
false;protected;1;11;;@Override protected boolean doEquals(PercolateQueryBuilder other) {     return Objects.equals(field, other.field) && Objects.equals(documentType, other.documentType) && Objects.equals(documents, other.documents) && Objects.equals(indexedDocumentIndex, other.indexedDocumentIndex) && Objects.equals(indexedDocumentType, other.indexedDocumentType) && Objects.equals(documentSupplier, other.documentSupplier) && Objects.equals(indexedDocumentId, other.indexedDocumentId). }
false;protected;0;4;;@Override protected int doHashCode() {     return Objects.hash(field, documentType, documents, indexedDocumentIndex, indexedDocumentType, indexedDocumentId, documentSupplier). }
false;public;0;4;;@Override public String getWriteableName() {     return NAME. }
false;protected;1;40;;@Override protected QueryBuilder doRewrite(QueryRewriteContext queryShardContext) {     if (documents.isEmpty() == false) {         return this.     } else if (documentSupplier != null) {         final BytesReference source = documentSupplier.get().         if (source == null) {             // not executed yet             return this.         } else {             return new PercolateQueryBuilder(field, documentType, Collections.singletonList(source), XContentHelper.xContentType(source)).         }     }     GetRequest getRequest = new GetRequest(indexedDocumentIndex, indexedDocumentType, indexedDocumentId).     getRequest.preference("_local").     getRequest.routing(indexedDocumentRouting).     getRequest.preference(indexedDocumentPreference).     if (indexedDocumentVersion != null) {         getRequest.version(indexedDocumentVersion).     }     SetOnce<BytesReference> documentSupplier = new SetOnce<>().     queryShardContext.registerAsyncAction((client, listener) -> {         client.get(getRequest, ActionListener.wrap(getResponse -> {             if (getResponse.isExists() == false) {                 throw new ResourceNotFoundException("indexed document [{}/{}/{}] couldn't be found", indexedDocumentIndex, indexedDocumentType, indexedDocumentId).             }             if (getResponse.isSourceEmpty()) {                 throw new IllegalArgumentException("indexed document [" + indexedDocumentIndex + "/" + indexedDocumentType + "/" + indexedDocumentId + "] source disabled").             }             documentSupplier.set(getResponse.getSourceAsBytesRef()).             listener.onResponse(null).         }, listener::onFailure)).     }).     return new PercolateQueryBuilder(field, documentType, documentSupplier::get). }
false;protected;1;9;;@Override protected Analyzer getWrappedAnalyzer(String fieldName) {     Analyzer analyzer = fieldNameAnalyzer.analyzers().get(fieldName).     if (analyzer != null) {         return analyzer.     } else {         return context.getIndexAnalyzers().getDefaultIndexAnalyzer().     } }
false;protected;1;78;;@Override protected Query doToQuery(QueryShardContext context) throws IOException {     // Call nowInMillis() so that this query becomes un-cacheable since we     // can't be sure that it doesn't use now or scripts     context.nowInMillis().     if (indexedDocumentIndex != null || indexedDocumentType != null || indexedDocumentId != null || documentSupplier != null) {         throw new IllegalStateException("query builder must be rewritten first").     }     if (documents.isEmpty()) {         throw new IllegalStateException("no document to percolate").     }     MappedFieldType fieldType = context.fieldMapper(field).     if (fieldType == null) {         throw new QueryShardException(context, "field [" + field + "] does not exist").     }     if (!(fieldType instanceof PercolatorFieldMapper.FieldType)) {         throw new QueryShardException(context, "expected field [" + field + "] to be of type [percolator], but is of type [" + fieldType.typeName() + "]").     }     final List<ParsedDocument> docs = new ArrayList<>().     final DocumentMapper docMapper.     final MapperService mapperService = context.getMapperService().     String type = mapperService.documentMapper().type().     if (documentType != null) {         deprecationLogger.deprecated("[document_type] parameter has been deprecated because types have been deprecated").         if (documentType.equals(type) == false) {             throw new IllegalArgumentException("specified document_type [" + documentType + "] is not equal to the actual type [" + type + "]").         }     }     docMapper = mapperService.documentMapper(type).     for (BytesReference document : documents) {         docs.add(docMapper.parse(new SourceToParse(context.index().getName(), type, "_temp_id", document, documentXContentType))).     }     FieldNameAnalyzer fieldNameAnalyzer = (FieldNameAnalyzer) docMapper.mappers().indexAnalyzer().     // Need to this custom impl because FieldNameAnalyzer is strict and the percolator sometimes isn't when     // 'index.percolator.map_unmapped_fields_as_string' is enabled:     Analyzer analyzer = new DelegatingAnalyzerWrapper(Analyzer.PER_FIELD_REUSE_STRATEGY) {          @Override         protected Analyzer getWrappedAnalyzer(String fieldName) {             Analyzer analyzer = fieldNameAnalyzer.analyzers().get(fieldName).             if (analyzer != null) {                 return analyzer.             } else {                 return context.getIndexAnalyzers().getDefaultIndexAnalyzer().             }         }     }.     final IndexSearcher docSearcher.     final boolean excludeNestedDocuments.     if (docs.size() > 1 || docs.get(0).docs().size() > 1) {         assert docs.size() != 1 || docMapper.hasNestedObjects().         docSearcher = createMultiDocumentSearcher(analyzer, docs).         excludeNestedDocuments = docMapper.hasNestedObjects() && docs.stream().map(ParsedDocument::docs).mapToInt(List::size).anyMatch(size -> size > 1).     } else {         MemoryIndex memoryIndex = MemoryIndex.fromDocument(docs.get(0).rootDoc(), analyzer, true, false).         docSearcher = memoryIndex.createSearcher().         docSearcher.setQueryCache(null).         excludeNestedDocuments = false.     }     PercolatorFieldMapper.FieldType pft = (PercolatorFieldMapper.FieldType) fieldType.     String name = this.name != null ? this.name : pft.name().     QueryShardContext percolateShardContext = wrap(context).     PercolateQuery.QueryStore queryStore = createStore(pft.queryBuilderField, percolateShardContext, pft.mapUnmappedFieldsAsText).     return pft.percolateQuery(name, queryStore, documents, docSearcher, excludeNestedDocuments, context.indexVersionCreated()). }
false;public;0;3;;public String getField() {     return field. }
false;public;0;3;;public String getDocumentType() {     return documentType. }
false;public;0;3;;public List<BytesReference> getDocuments() {     return documents. }
true;;0;3;// pkg-private for testing ;// pkg-private for testing XContentType getXContentType() {     return documentXContentType. }
false;static;2;19;;static IndexSearcher createMultiDocumentSearcher(Analyzer analyzer, Collection<ParsedDocument> docs) {     RAMDirectory ramDirectory = new RAMDirectory().     try (IndexWriter indexWriter = new IndexWriter(ramDirectory, new IndexWriterConfig(analyzer))) {         // Indexing in order here, so that the user provided order matches with the docid sequencing:         Iterable<ParseContext.Document> iterable = () -> docs.stream().map(ParsedDocument::docs).flatMap(Collection::stream).iterator().         indexWriter.addDocuments(iterable).         DirectoryReader directoryReader = DirectoryReader.open(indexWriter).         assert directoryReader.leaves().size() == 1 : "Expected single leaf, but got [" + directoryReader.leaves().size() + "]".         final IndexSearcher slowSearcher = new IndexSearcher(directoryReader).         slowSearcher.setQueryCache(null).         return slowSearcher.     } catch (IOException e) {         throw new ElasticsearchException("Failed to create index for percolator with nested document ", e).     } }
false;static;3;57;;static PercolateQuery.QueryStore createStore(MappedFieldType queryBuilderFieldType, QueryShardContext context, boolean mapUnmappedFieldsAsString) {     Version indexVersion = context.indexVersionCreated().     NamedWriteableRegistry registry = context.getWriteableRegistry().     return ctx -> {         LeafReader leafReader = ctx.reader().         BinaryDocValues binaryDocValues = leafReader.getBinaryDocValues(queryBuilderFieldType.name()).         if (binaryDocValues == null) {             return docId -> null.         }         if (indexVersion.onOrAfter(Version.V_6_0_0_beta2)) {             return docId -> {                 if (binaryDocValues.advanceExact(docId)) {                     BytesRef qbSource = binaryDocValues.binaryValue().                     try (InputStream in = new ByteArrayInputStream(qbSource.bytes, qbSource.offset, qbSource.length)) {                         try (StreamInput input = new NamedWriteableAwareStreamInput(new InputStreamStreamInput(in, qbSource.length), registry)) {                             input.setVersion(indexVersion).                             // Query builder's content is stored via BinaryFieldMapper, which has a custom encoding                             // to encode multiple binary values into a single binary doc values field.                             // This is the reason we need to first need to read the number of values and                             // then the length of the field value in bytes.                             int numValues = input.readVInt().                             assert numValues == 1.                             int valueLength = input.readVInt().                             assert valueLength > 0.                             QueryBuilder queryBuilder = input.readNamedWriteable(QueryBuilder.class).                             assert in.read() == -1.                             return PercolatorFieldMapper.toQuery(context, mapUnmappedFieldsAsString, queryBuilder).                         }                     }                 } else {                     return null.                 }             }.         } else {             return docId -> {                 if (binaryDocValues.advanceExact(docId)) {                     BytesRef qbSource = binaryDocValues.binaryValue().                     if (qbSource.length > 0) {                         XContent xContent = PercolatorFieldMapper.QUERY_BUILDER_CONTENT_TYPE.xContent().                         try (XContentParser sourceParser = xContent.createParser(context.getXContentRegistry(), LoggingDeprecationHandler.INSTANCE, qbSource.bytes, qbSource.offset, qbSource.length)) {                             return parseQuery(context, mapUnmappedFieldsAsString, sourceParser).                         }                     } else {                         return null.                     }                 } else {                     return null.                 }             }.         }     }. }
false;public;1;16;;@Override public BitSetProducer bitsetFilter(Query query) {     return context -> {         final IndexReaderContext topLevelContext = ReaderUtil.getTopLevelContext(context).         final IndexSearcher searcher = new IndexSearcher(topLevelContext).         searcher.setQueryCache(null).         final Weight weight = searcher.createWeight(searcher.rewrite(query), ScoreMode.COMPLETE_NO_SCORES, 1f).         final Scorer s = weight.scorer(context).         if (s != null) {             return new BitDocIdSet(BitSet.of(s.iterator(), context.reader().maxDoc())).bits().         } else {             return null.         }     }. }
false;public;1;9;;@Override @SuppressWarnings("unchecked") public <IFD extends IndexFieldData<?>> IFD getForField(MappedFieldType fieldType) {     IndexFieldData.Builder builder = fieldType.fielddataBuilder(shardContext.getFullyQualifiedIndex().getName()).     IndexFieldDataCache cache = new IndexFieldDataCache.None().     CircuitBreakerService circuitBreaker = new NoneCircuitBreakerService().     return (IFD) builder.build(shardContext.getIndexSettings(), fieldType, cache, circuitBreaker, shardContext.getMapperService()). }
false;static;1;31;;static QueryShardContext wrap(QueryShardContext shardContext) {     return new QueryShardContext(shardContext) {          @Override         public BitSetProducer bitsetFilter(Query query) {             return context -> {                 final IndexReaderContext topLevelContext = ReaderUtil.getTopLevelContext(context).                 final IndexSearcher searcher = new IndexSearcher(topLevelContext).                 searcher.setQueryCache(null).                 final Weight weight = searcher.createWeight(searcher.rewrite(query), ScoreMode.COMPLETE_NO_SCORES, 1f).                 final Scorer s = weight.scorer(context).                 if (s != null) {                     return new BitDocIdSet(BitSet.of(s.iterator(), context.reader().maxDoc())).bits().                 } else {                     return null.                 }             }.         }          @Override         @SuppressWarnings("unchecked")         public <IFD extends IndexFieldData<?>> IFD getForField(MappedFieldType fieldType) {             IndexFieldData.Builder builder = fieldType.fielddataBuilder(shardContext.getFullyQualifiedIndex().getName()).             IndexFieldDataCache cache = new IndexFieldDataCache.None().             CircuitBreakerService circuitBreaker = new NoneCircuitBreakerService().             return (IFD) builder.build(shardContext.getIndexSettings(), fieldType, cache, circuitBreaker, shardContext.getMapperService()).         }     }. }
