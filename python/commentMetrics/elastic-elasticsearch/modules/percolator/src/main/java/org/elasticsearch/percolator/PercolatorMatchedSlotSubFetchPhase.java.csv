commented;modifiers;parameterAmount;loc;comment;code
false;public;2;4;;@Override public void hitsExecute(SearchContext context, SearchHit[] hits) throws IOException {     innerHitsExecute(context.query(), context.searcher(), hits). }
false;static;3;53;;static void innerHitsExecute(Query mainQuery, IndexSearcher indexSearcher, SearchHit[] hits) throws IOException {     List<PercolateQuery> percolateQueries = locatePercolatorQuery(mainQuery).     if (percolateQueries.isEmpty()) {         return.     }     boolean singlePercolateQuery = percolateQueries.size() == 1.     for (PercolateQuery percolateQuery : percolateQueries) {         String fieldName = singlePercolateQuery ? FIELD_NAME_PREFIX : FIELD_NAME_PREFIX + "_" + percolateQuery.getName().         IndexSearcher percolatorIndexSearcher = percolateQuery.getPercolatorIndexSearcher().         // there is a bug in lucene's MemoryIndex that doesn't allow us to use docValues here...         // See https://issues.apache.org/jira/browse/LUCENE-8055         // for now we just use version 6.0 version to find nested parent         // context.mapperService().getIndexSettings().getIndexVersionCreated().         final Version version = Version.V_6_0_0.         Weight weight = percolatorIndexSearcher.createWeight(percolatorIndexSearcher.rewrite(Queries.newNonNestedFilter(version)), ScoreMode.COMPLETE_NO_SCORES, 1f).         Scorer s = weight.scorer(percolatorIndexSearcher.getIndexReader().leaves().get(0)).         int memoryIndexMaxDoc = percolatorIndexSearcher.getIndexReader().maxDoc().         BitSet rootDocs = BitSet.of(s.iterator(), memoryIndexMaxDoc).         int[] rootDocsBySlot = null.         boolean hasNestedDocs = rootDocs.cardinality() != percolatorIndexSearcher.getIndexReader().numDocs().         if (hasNestedDocs) {             rootDocsBySlot = buildRootDocsSlots(rootDocs).         }         PercolateQuery.QueryStore queryStore = percolateQuery.getQueryStore().         List<LeafReaderContext> ctxs = indexSearcher.getIndexReader().leaves().         for (SearchHit hit : hits) {             LeafReaderContext ctx = ctxs.get(ReaderUtil.subIndex(hit.docId(), ctxs)).             int segmentDocId = hit.docId() - ctx.docBase.             Query query = queryStore.getQueries(ctx).apply(segmentDocId).             if (query == null) {                 // This is not a document with a percolator field.                 continue.             }             TopDocs topDocs = percolatorIndexSearcher.search(query, memoryIndexMaxDoc, new Sort(SortField.FIELD_DOC)).             if (topDocs.totalHits.value == 0) {                 // likely to happen when percolating multiple documents                 continue.             }             Map<String, DocumentField> fields = hit.fieldsOrNull().             if (fields == null) {                 fields = new HashMap<>().                 hit.fields(fields).             }             IntStream slots = convertTopDocsToSlots(topDocs, rootDocsBySlot).             fields.put(fieldName, new DocumentField(fieldName, slots.boxed().collect(Collectors.toList()))).         }     } }
false;static;2;8;;static IntStream convertTopDocsToSlots(TopDocs topDocs, int[] rootDocsBySlot) {     IntStream stream = Arrays.stream(topDocs.scoreDocs).mapToInt(scoreDoc -> scoreDoc.doc).     if (rootDocsBySlot != null) {         stream = stream.map(docId -> Arrays.binarySearch(rootDocsBySlot, docId)).     }     return stream. }
false;static;1;9;;static int[] buildRootDocsSlots(BitSet rootDocs) {     int slot = 0.     int[] rootDocsBySlot = new int[rootDocs.cardinality()].     BitSetIterator iterator = new BitSetIterator(rootDocs, 0).     for (int rootDocId = iterator.nextDoc(). rootDocId != NO_MORE_DOCS. rootDocId = iterator.nextDoc()) {         rootDocsBySlot[slot++] = rootDocId.     }     return rootDocsBySlot. }
