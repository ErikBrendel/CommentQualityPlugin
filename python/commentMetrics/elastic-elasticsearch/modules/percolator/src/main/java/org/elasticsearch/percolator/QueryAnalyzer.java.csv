commented;modifiers;parameterAmount;loc;comment;code
true;static;2;14;/**  * Extracts terms and ranges from the provided query. These terms and ranges are stored with the percolator query and  * used by the percolate query's candidate query as fields to be query by. The candidate query  * holds the terms from the document to be percolated and allows to the percolate query to ignore  * percolator queries that we know would otherwise never match.  *  * <p>  * When extracting the terms for the specified query, we can also determine if the percolator query is  * always going to match. For example if a percolator query just contains a term query or a disjunction  * query then when the candidate query matches with that, we know the entire percolator query always  * matches. This allows the percolate query to skip the expensive memory index verification step that  * it would otherwise have to execute (for example when a percolator query contains a phrase query or a  * conjunction query).  *  * <p>  * The query analyzer doesn't always extract all terms from the specified query. For example from a  * boolean query with no should clauses or phrase queries only the longest term are selected,  * since that those terms are likely to be the rarest. Boolean query's must_not clauses are always ignored.  *  * <p>  * Sometimes the query analyzer can't always extract terms or ranges from a sub query, if that happens then  * query analysis is stopped and an UnsupportedQueryException is thrown. So that the caller can mark  * this query in such a way that the PercolatorQuery always verifies if this query with the MemoryIndex.  *  * @param query         The query to analyze.  * @param indexVersion  The create version of the index containing the percolator queries.  */ ;/**  * Extracts terms and ranges from the provided query. These terms and ranges are stored with the percolator query and  * used by the percolate query's candidate query as fields to be query by. The candidate query  * holds the terms from the document to be percolated and allows to the percolate query to ignore  * percolator queries that we know would otherwise never match.  *  * <p>  * When extracting the terms for the specified query, we can also determine if the percolator query is  * always going to match. For example if a percolator query just contains a term query or a disjunction  * query then when the candidate query matches with that, we know the entire percolator query always  * matches. This allows the percolate query to skip the expensive memory index verification step that  * it would otherwise have to execute (for example when a percolator query contains a phrase query or a  * conjunction query).  *  * <p>  * The query analyzer doesn't always extract all terms from the specified query. For example from a  * boolean query with no should clauses or phrase queries only the longest term are selected,  * since that those terms are likely to be the rarest. Boolean query's must_not clauses are always ignored.  *  * <p>  * Sometimes the query analyzer can't always extract terms or ranges from a sub query, if that happens then  * query analysis is stopped and an UnsupportedQueryException is thrown. So that the caller can mark  * this query in such a way that the PercolatorQuery always verifies if this query with the MemoryIndex.  *  * @param query         The query to analyze.  * @param indexVersion  The create version of the index containing the percolator queries.  */ static Result analyze(Query query, Version indexVersion) {     Class<?> queryClass = query.getClass().     if (queryClass.isAnonymousClass()) {         // Sometimes queries have anonymous classes in that case we need the direct super class.         // (for example blended term query)         queryClass = queryClass.getSuperclass().     }     BiFunction<Query, Version, Result> queryProcessor = queryProcessors.get(queryClass).     if (queryProcessor != null) {         return queryProcessor.apply(query, indexVersion).     } else {         throw new UnsupportedQueryException(query).     } }
false;private,static;0;3;;private static BiFunction<Query, Version, Result> matchNoDocsQuery() {     return (query, version) -> new Result(true, Collections.emptySet(), 0). }
false;private,static;0;3;;private static BiFunction<Query, Version, Result> matchAllDocsQuery() {     return (query, version) -> new Result(true, true). }
false;private,static;0;6;;private static BiFunction<Query, Version, Result> constantScoreQuery() {     return (query, boosts) -> {         Query wrappedQuery = ((ConstantScoreQuery) query).getQuery().         return analyze(wrappedQuery, boosts).     }. }
false;private,static;0;6;;private static BiFunction<Query, Version, Result> boostQuery() {     return (query, version) -> {         Query wrappedQuery = ((BoostQuery) query).getQuery().         return analyze(wrappedQuery, version).     }. }
false;private,static;0;6;;private static BiFunction<Query, Version, Result> termQuery() {     return (query, version) -> {         TermQuery termQuery = (TermQuery) query.         return new Result(true, Collections.singleton(new QueryExtraction(termQuery.getTerm())), 1).     }. }
false;private,static;0;11;;private static BiFunction<Query, Version, Result> termInSetQuery() {     return (query, version) -> {         TermInSetQuery termInSetQuery = (TermInSetQuery) query.         Set<QueryExtraction> terms = new HashSet<>().         PrefixCodedTerms.TermIterator iterator = termInSetQuery.getTermData().iterator().         for (BytesRef term = iterator.next(). term != null. term = iterator.next()) {             terms.add(new QueryExtraction(new Term(iterator.field(), term))).         }         return new Result(true, terms, Math.min(1, terms.size())).     }. }
false;private,static;0;6;;private static BiFunction<Query, Version, Result> synonymQuery() {     return (query, version) -> {         Set<QueryExtraction> terms = ((SynonymQuery) query).getTerms().stream().map(QueryExtraction::new).collect(toSet()).         return new Result(true, terms, Math.min(1, terms.size())).     }. }
false;private,static;0;6;;private static BiFunction<Query, Version, Result> commonTermsQuery() {     return (query, version) -> {         Set<QueryExtraction> terms = ((CommonTermsQuery) query).getTerms().stream().map(QueryExtraction::new).collect(toSet()).         return new Result(false, terms, Math.min(1, terms.size())).     }. }
false;private,static;0;6;;private static BiFunction<Query, Version, Result> blendedTermQuery() {     return (query, version) -> {         Set<QueryExtraction> terms = ((BlendedTermQuery) query).getTerms().stream().map(QueryExtraction::new).collect(toSet()).         return new Result(true, terms, Math.min(1, terms.size())).     }. }
false;private,static;0;23;;private static BiFunction<Query, Version, Result> phraseQuery() {     return (query, version) -> {         Term[] terms = ((PhraseQuery) query).getTerms().         if (terms.length == 0) {             return new Result(true, Collections.emptySet(), 0).         }         if (version.onOrAfter(Version.V_6_1_0)) {             Set<QueryExtraction> extractions = Arrays.stream(terms).map(QueryExtraction::new).collect(toSet()).             return new Result(false, extractions, extractions.size()).         } else {             // the longest term is likely to be the rarest,             // so from a performance perspective it makes sense to extract that             Term longestTerm = terms[0].             for (Term term : terms) {                 if (longestTerm.bytes().length < term.bytes().length) {                     longestTerm = term.                 }             }             return new Result(false, Collections.singleton(new QueryExtraction(longestTerm)), 1).         }     }. }
false;private,static;0;21;;private static BiFunction<Query, Version, Result> multiPhraseQuery() {     return (query, version) -> {         Term[][] terms = ((MultiPhraseQuery) query).getTermArrays().         if (terms.length == 0) {             return new Result(true, Collections.emptySet(), 0).         }         // This query has the same problem as boolean queries when it comes to duplicated terms         // So to keep things simple, we just rewrite to a boolean query         BooleanQuery.Builder builder = new BooleanQuery.Builder().         for (Term[] termArr : terms) {             BooleanQuery.Builder subBuilder = new BooleanQuery.Builder().             for (Term term : termArr) {                 subBuilder.add(new TermQuery(term), Occur.SHOULD).             }             builder.add(subBuilder.build(), Occur.FILTER).         }         // Make sure to unverify the result         return booleanQuery().apply(builder.build(), version).unverify().     }. }
false;private,static;0;6;;private static BiFunction<Query, Version, Result> spanTermQuery() {     return (query, version) -> {         Term term = ((SpanTermQuery) query).getTerm().         return new Result(true, Collections.singleton(new QueryExtraction(term)), 1).     }. }
false;private,static;0;22;;private static BiFunction<Query, Version, Result> spanNearQuery() {     return (query, version) -> {         SpanNearQuery spanNearQuery = (SpanNearQuery) query.         if (version.onOrAfter(Version.V_6_1_0)) {             // This has the same problem as boolean queries when it comes to duplicated clauses             // so we rewrite to a boolean query to keep things simple.             BooleanQuery.Builder builder = new BooleanQuery.Builder().             for (SpanQuery clause : spanNearQuery.getClauses()) {                 builder.add(clause, Occur.FILTER).             }             // make sure to unverify the result             return booleanQuery().apply(builder.build(), version).unverify().         } else {             Result bestClause = null.             for (SpanQuery clause : spanNearQuery.getClauses()) {                 Result temp = analyze(clause, version).                 bestClause = selectBestResult(temp, bestClause).             }             return bestClause.         }     }. }
false;private,static;0;12;;private static BiFunction<Query, Version, Result> spanOrQuery() {     return (query, version) -> {         SpanOrQuery spanOrQuery = (SpanOrQuery) query.         // handle it like a boolean query to not dulplicate eg. logic         // about duplicated terms         BooleanQuery.Builder builder = new BooleanQuery.Builder().         for (SpanQuery clause : spanOrQuery.getClauses()) {             builder.add(clause, Occur.SHOULD).         }         return booleanQuery().apply(builder.build(), version).     }. }
false;private,static;0;6;;private static BiFunction<Query, Version, Result> spanNotQuery() {     return (query, version) -> {         Result result = analyze(((SpanNotQuery) query).getInclude(), version).         return new Result(false, result.extractions, result.minimumShouldMatch).     }. }
false;private,static;0;6;;private static BiFunction<Query, Version, Result> spanFirstQuery() {     return (query, version) -> {         Result result = analyze(((SpanFirstQuery) query).getMatch(), version).         return new Result(false, result.extractions, result.minimumShouldMatch).     }. }
false;private,static;0;63;;private static BiFunction<Query, Version, Result> booleanQuery() {     return (query, version) -> {         BooleanQuery bq = (BooleanQuery) query.         int minimumShouldMatch = bq.getMinimumNumberShouldMatch().         List<Query> requiredClauses = new ArrayList<>().         List<Query> optionalClauses = new ArrayList<>().         boolean hasProhibitedClauses = false.         for (BooleanClause clause : bq.clauses()) {             if (clause.isRequired()) {                 requiredClauses.add(clause.getQuery()).             } else if (clause.isProhibited()) {                 hasProhibitedClauses = true.             } else {                 assert clause.getOccur() == Occur.SHOULD.                 optionalClauses.add(clause.getQuery()).             }         }         if (minimumShouldMatch > optionalClauses.size() || (requiredClauses.isEmpty() && optionalClauses.isEmpty())) {             return new Result(false, Collections.emptySet(), 0).         }         if (requiredClauses.size() > 0) {             if (minimumShouldMatch > 0) {                 // mix of required clauses and required optional clauses, we turn it into                 // a pure conjunction by moving the optional clauses to a sub query to                 // simplify logic                 BooleanQuery.Builder minShouldMatchQuery = new BooleanQuery.Builder().                 minShouldMatchQuery.setMinimumNumberShouldMatch(minimumShouldMatch).                 for (Query q : optionalClauses) {                     minShouldMatchQuery.add(q, Occur.SHOULD).                 }                 requiredClauses.add(minShouldMatchQuery.build()).                 optionalClauses.clear().                 minimumShouldMatch = 0.             } else {                 // only matter for scoring, not matching                 optionalClauses.clear().             }         }         // Now we now have either a pure conjunction or a pure disjunction, with at least one clause         Result result.         if (requiredClauses.size() > 0) {             assert optionalClauses.isEmpty().             assert minimumShouldMatch == 0.             result = handleConjunctionQuery(requiredClauses, version).         } else {             assert requiredClauses.isEmpty().             if (minimumShouldMatch == 0) {                 // Lucene always requires one matching clause for disjunctions                 minimumShouldMatch = 1.             }             result = handleDisjunctionQuery(optionalClauses, minimumShouldMatch, version).         }         if (hasProhibitedClauses) {             result = result.unverify().         }         return result.     }. }
false;private,static;0;10;;private static BiFunction<Query, Version, Result> disjunctionMaxQuery() {     return (query, version) -> {         List<Query> disjuncts = ((DisjunctionMaxQuery) query).getDisjuncts().         if (disjuncts.isEmpty()) {             return new Result(false, Collections.emptySet(), 0).         } else {             return handleDisjunctionQuery(disjuncts, 1, version).         }     }. }
false;private,static;0;17;;private static BiFunction<Query, Version, Result> functionScoreQuery() {     return (query, version) -> {         FunctionScoreQuery functionScoreQuery = (FunctionScoreQuery) query.         Result result = analyze(functionScoreQuery.getSubQuery(), version).         // If min_score is specified we can't guarantee upfront that this percolator query matches,         // so in that case we set verified to false.         // (if it matches with the percolator document matches with the extracted terms.         // Min score filters out docs, which is different than the functions, which just influences the score.)         boolean verified = result.verified && functionScoreQuery.getMinScore() == null.         if (result.matchAllDocs) {             return new Result(result.matchAllDocs, verified).         } else {             return new Result(verified, result.extractions, result.minimumShouldMatch).         }     }. }
false;private,static;0;22;;private static BiFunction<Query, Version, Result> pointRangeQuery() {     return (query, version) -> {         PointRangeQuery pointRangeQuery = (PointRangeQuery) query.         if (pointRangeQuery.getNumDims() != 1) {             throw new UnsupportedQueryException(query).         }         byte[] lowerPoint = pointRangeQuery.getLowerPoint().         byte[] upperPoint = pointRangeQuery.getUpperPoint().         // If upper is really smaller than lower then we deal with like MatchNoDocsQuery. (verified and no extractions)         if (new BytesRef(lowerPoint).compareTo(new BytesRef(upperPoint)) > 0) {             return new Result(true, Collections.emptySet(), 0).         }         byte[] interval = new byte[16].         NumericUtils.subtract(16, 0, prepad(upperPoint), prepad(lowerPoint), interval).         return new Result(false, Collections.singleton(new QueryExtraction(new Range(pointRangeQuery.getField(), lowerPoint, upperPoint, interval))), 1).     }. }
false;private,static;1;6;;private static byte[] prepad(byte[] original) {     int offset = BinaryRange.BYTES - original.length.     byte[] result = new byte[BinaryRange.BYTES].     System.arraycopy(original, 0, result, offset, original.length).     return result. }
false;private,static;0;6;;private static BiFunction<Query, Version, Result> indexOrDocValuesQuery() {     return (query, version) -> {         IndexOrDocValuesQuery indexOrDocValuesQuery = (IndexOrDocValuesQuery) query.         return analyze(indexOrDocValuesQuery.getIndexQuery(), version).     }. }
false;private,static;0;7;;private static BiFunction<Query, Version, Result> toParentBlockJoinQuery() {     return (query, version) -> {         ESToParentBlockJoinQuery toParentBlockJoinQuery = (ESToParentBlockJoinQuery) query.         Result result = analyze(toParentBlockJoinQuery.getChildQuery(), version).         return new Result(false, result.extractions, result.minimumShouldMatch).     }. }
false;private,static;2;33;;private static Result handleConjunctionQuery(List<Query> conjunctions, Version version) {     UnsupportedQueryException uqe = null.     List<Result> results = new ArrayList<>(conjunctions.size()).     boolean success = false.     for (Query query : conjunctions) {         try {             Result subResult = analyze(query, version).             if (subResult.isMatchNoDocs()) {                 return subResult.             }             results.add(subResult).             success = true.         } catch (UnsupportedQueryException e) {             uqe = e.         }     }     if (success == false) {         // No clauses could be extracted         if (uqe != null) {             throw uqe.         } else {             // Empty conjunction             return new Result(true, Collections.emptySet(), 0).         }     }     Result result = handleConjunction(results, version).     if (uqe != null) {         result = result.unverify().     }     return result. }
false;private,static;2;77;;private static Result handleConjunction(List<Result> conjunctions, Version version) {     if (conjunctions.isEmpty()) {         throw new IllegalArgumentException("Must have at least on conjunction sub result").     }     if (version.onOrAfter(Version.V_6_1_0)) {         for (Result subResult : conjunctions) {             if (subResult.isMatchNoDocs()) {                 return subResult.             }         }         int msm = 0.         boolean verified = true.         boolean matchAllDocs = true.         boolean hasDuplicateTerms = false.         Set<QueryExtraction> extractions = new HashSet<>().         Set<String> seenRangeFields = new HashSet<>().         for (Result result : conjunctions) {             // In case that there are duplicate query extractions we need to be careful with             // incrementing msm,             // because that could lead to valid matches not becoming candidate matches:             // query: (field:val1 AND field:val2) AND (field:val2 AND field:val3)             // doc: field: val1 val2 val3             // So lets be protective and decrease the msm:             int resultMsm = result.minimumShouldMatch.             for (QueryExtraction queryExtraction : result.extractions) {                 if (queryExtraction.range != null) {                     // the percolator query at index time.                     if (seenRangeFields.add(queryExtraction.range.fieldName)) {                         resultMsm = 1.                     } else {                         resultMsm = 0.                     }                 }                 if (extractions.contains(queryExtraction)) {                     resultMsm = 0.                     verified = false.                     break.                 }             }             msm += resultMsm.             if (result.verified == false || // If some inner extractions are optional, the result can't be verified             result.minimumShouldMatch < result.extractions.size()) {                 verified = false.             }             matchAllDocs &= result.matchAllDocs.             extractions.addAll(result.extractions).         }         if (matchAllDocs) {             return new Result(matchAllDocs, verified).         } else {             return new Result(verified, extractions, hasDuplicateTerms ? 1 : msm).         }     } else {         Result bestClause = null.         for (Result result : conjunctions) {             bestClause = selectBestResult(result, bestClause).         }         return bestClause.     } }
false;private,static;3;9;;private static Result handleDisjunctionQuery(List<Query> disjunctions, int requiredShouldClauses, Version version) {     List<Result> subResults = new ArrayList<>().     for (Query query : disjunctions) {         // if either query fails extraction, we need to propagate as we could miss hits otherwise         Result subResult = analyze(query, version).         subResults.add(subResult).     }     return handleDisjunction(subResults, requiredShouldClauses, version). }
false;private,static;3;85;;private static Result handleDisjunction(List<Result> disjunctions, int requiredShouldClauses, Version version) {     // Keep track of the msm for each clause:     List<Integer> clauses = new ArrayList<>(disjunctions.size()).     boolean verified.     if (version.before(Version.V_6_1_0)) {         verified = requiredShouldClauses <= 1.     } else {         verified = true.     }     int numMatchAllClauses = 0.     boolean hasRangeExtractions = false.     // In case that there are duplicate extracted terms / ranges then the msm should always be equal to the clause     // with lowest msm, because the at percolate time there is no way to know the number of repetitions per     // extracted term and field value from a percolator document may have more 'weight' than others.     // Example percolator query: value1 OR value2 OR value2 OR value3 OR value3 OR value3 OR value4 OR value5 (msm set to 3)     // In the above example query the extracted msm would be 3     // Example document1: value1 value2 value3     // With the msm and extracted terms this would match and is expected behaviour     // Example document2: value3     // This document should match too (value3 appears in 3 clauses), but with msm set to 3 and the fact     // that fact that only distinct values are indexed in extracted terms field this document would     // never match.     boolean hasDuplicateTerms = false.     Set<QueryExtraction> terms = new HashSet<>().     for (int i = 0. i < disjunctions.size(). i++) {         Result subResult = disjunctions.get(i).         if (subResult.verified == false || // verify it with a single top-level min_should_match         subResult.minimumShouldMatch > 1 || // verify it with a single top-level min_should_match         (subResult.extractions.size() > 1 && requiredShouldClauses > 1)) {             verified = false.         }         if (subResult.matchAllDocs) {             numMatchAllClauses++.         }         int resultMsm = subResult.minimumShouldMatch.         for (QueryExtraction extraction : subResult.extractions) {             if (terms.add(extraction) == false) {                 verified = false.                 hasDuplicateTerms = true.             }         }         if (hasRangeExtractions == false) {             hasRangeExtractions = subResult.extractions.stream().anyMatch(qe -> qe.range != null).         }         clauses.add(resultMsm).     }     boolean matchAllDocs = numMatchAllClauses > 0 && numMatchAllClauses >= requiredShouldClauses.     int msm = 0.     if (version.onOrAfter(Version.V_6_1_0) && // so for now lets not do it.     hasRangeExtractions == false) {         // Figure out what the combined msm is for this disjunction:         // (sum the lowest required clauses, otherwise we're too strict and queries may not match)         clauses = clauses.stream().filter(val -> val > 0).sorted().collect(Collectors.toList()).         // When there are duplicated query extractions, percolator can no longer reliably determine msm across this disjunction         if (hasDuplicateTerms) {             // pick lowest msm:             msm = clauses.get(0).         } else {             int limit = Math.min(clauses.size(), Math.max(1, requiredShouldClauses)).             for (int i = 0. i < limit. i++) {                 msm += clauses.get(i).             }         }     } else {         msm = 1.     }     if (matchAllDocs) {         return new Result(matchAllDocs, verified).     } else {         return new Result(verified, terms, msm).     } }
true;static;2;61;/**  * Return an extraction for the conjunction of {@code result1} and {@code result2}  * by picking up clauses that look most restrictive and making it unverified if  * the other clause is not null and doesn't match all documents. This is used by  * 6.0.0 indices which didn't use the terms_set query.  */ ;/**  * Return an extraction for the conjunction of {@code result1} and {@code result2}  * by picking up clauses that look most restrictive and making it unverified if  * the other clause is not null and doesn't match all documents. This is used by  * 6.0.0 indices which didn't use the terms_set query.  */ static Result selectBestResult(Result result1, Result result2) {     assert result1 != null || result2 != null.     if (result1 == null) {         return result2.     } else if (result2 == null) {         return result1.     } else if (result1.matchAllDocs) {         // conjunction with match_all         Result result = result2.         if (result1.verified == false) {             result = result.unverify().         }         return result.     } else if (result2.matchAllDocs) {         // conjunction with match_all         Result result = result1.         if (result2.verified == false) {             result = result.unverify().         }         return result.     } else {         // Prefer term based extractions over range based extractions:         boolean onlyRangeBasedExtractions = true.         for (QueryExtraction clause : result1.extractions) {             if (clause.term != null) {                 onlyRangeBasedExtractions = false.                 break.             }         }         for (QueryExtraction clause : result2.extractions) {             if (clause.term != null) {                 onlyRangeBasedExtractions = false.                 break.             }         }         if (onlyRangeBasedExtractions) {             BytesRef extraction1SmallestRange = smallestRange(result1.extractions).             BytesRef extraction2SmallestRange = smallestRange(result2.extractions).             if (extraction1SmallestRange == null) {                 return result2.unverify().             } else if (extraction2SmallestRange == null) {                 return result1.unverify().             }             // Keep the clause with smallest range, this is likely to be the rarest.             if (extraction1SmallestRange.compareTo(extraction2SmallestRange) <= 0) {                 return result1.unverify().             } else {                 return result2.unverify().             }         } else {             int extraction1ShortestTerm = minTermLength(result1.extractions).             int extraction2ShortestTerm = minTermLength(result2.extractions).             // keep the clause with longest terms, this likely to be rarest.             if (extraction1ShortestTerm >= extraction2ShortestTerm) {                 return result1.unverify().             } else {                 return result2.unverify().             }         }     } }
false;private,static;1;16;;private static int minTermLength(Set<QueryExtraction> extractions) {     // so that selectBestExtraction(...) we are likely to prefer the extractions that contains at least a single extraction     if (extractions.stream().filter(queryExtraction -> queryExtraction.term != null).count() == 0 && extractions.stream().filter(queryExtraction -> queryExtraction.range != null).count() > 0) {         return Integer.MIN_VALUE.     }     int min = Integer.MAX_VALUE.     for (QueryExtraction qt : extractions) {         if (qt.term != null) {             min = Math.min(min, qt.bytes().length).         }     }     return min. }
false;private,static;1;11;;private static BytesRef smallestRange(Set<QueryExtraction> terms) {     BytesRef min = null.     for (QueryExtraction qt : terms) {         if (qt.range != null) {             if (min == null || qt.range.interval.compareTo(min) < 0) {                 min = qt.range.interval.             }         }     }     return min. }
false;;0;7;;Result unverify() {     if (verified) {         return new Result(matchAllDocs, false, extractions, minimumShouldMatch).     } else {         return this.     } }
false;;0;3;;boolean isMatchNoDocs() {     return matchAllDocs == false && extractions.isEmpty(). }
false;;0;3;;String field() {     return term != null ? term.field() : null. }
false;;0;3;;BytesRef bytes() {     return term != null ? term.bytes() : null. }
false;;0;3;;String text() {     return term != null ? term.text() : null. }
false;public;1;8;;@Override public boolean equals(Object o) {     if (this == o)         return true.     if (o == null || getClass() != o.getClass())         return false.     QueryExtraction queryExtraction = (QueryExtraction) o.     return Objects.equals(term, queryExtraction.term) && Objects.equals(range, queryExtraction.range). }
false;public;0;4;;@Override public int hashCode() {     return Objects.hash(term, range). }
false;public;0;7;;@Override public String toString() {     return "QueryExtraction{" + "term=" + term + ",range=" + range + '}'. }
true;;0;3;/**  * The actual Lucene query that was unsupported and caused this exception to be thrown.  */ ;/**  * The actual Lucene query that was unsupported and caused this exception to be thrown.  */ Query getUnsupportedQuery() {     return unsupportedQuery. }
false;public;1;9;;@Override public boolean equals(Object o) {     if (this == o)         return true.     if (o == null || getClass() != o.getClass())         return false.     Range range = (Range) o.     return Objects.equals(fieldName, range.fieldName) && Arrays.equals(lowerPoint, range.lowerPoint) && Arrays.equals(upperPoint, range.upperPoint). }
false;public;0;8;;@Override public int hashCode() {     int result = 1.     result += 31 * fieldName.hashCode().     result += Arrays.hashCode(lowerPoint).     result += Arrays.hashCode(upperPoint).     return result. }
false;public;0;7;;@Override public String toString() {     return "Range{" + ", fieldName='" + fieldName + '\'' + ", interval=" + interval + '}'. }
