commented;modifiers;parameterAmount;loc;comment;code
false;private;1;3;;private org.apache.hadoop.fs.Path box(Path path) {     return new org.apache.hadoop.fs.Path(path.toUri()). }
false;private;1;3;;private Path unbox(org.apache.hadoop.fs.Path path) {     return baseProvider.getPath(path.toUri()). }
false;protected;0;4;;@Override protected org.apache.hadoop.fs.Path getInitialWorkingDirectory() {     return box(base). }
false;public;2;4;;@Override public void setPermission(org.apache.hadoop.fs.Path path, FsPermission permission) { // no execution, thank you very much! }
false;public;0;4;;// pretend we don't support symlinks (which causes hadoop to want to do crazy things), // returning the boolean does not seem to really help, link-related operations are still called. @Override public boolean supportsSymlinks() {     return false. }
false;public;1;4;;@Override public FileStatus getFileLinkStatus(org.apache.hadoop.fs.Path path) throws IOException {     return getFileStatus(path). }
false;public;1;4;;@Override public org.apache.hadoop.fs.Path getLinkTarget(org.apache.hadoop.fs.Path path) throws IOException {     return path. }
false;public;1;20;;@Override public FileStatus getFileStatus(org.apache.hadoop.fs.Path path) throws IOException {     BasicFileAttributes attributes.     try {         attributes = Files.readAttributes(unbox(path), BasicFileAttributes.class).     } catch (NoSuchFileException e) {         // unfortunately, specific exceptions are not guaranteed. don't wrap hadoop over a zip filesystem or something.         FileNotFoundException fnfe = new FileNotFoundException("File " + path + " does not exist").         fnfe.initCause(e).         throw fnfe.     }     // we set similar values to raw local filesystem, except we are never a symlink     long length = attributes.size().     boolean isDir = attributes.isDirectory().     int blockReplication = 1.     long blockSize = getDefaultBlockSize(path).     long modificationTime = attributes.creationTime().toMillis().     return new FileStatus(length, isDir, blockReplication, blockSize, modificationTime, path). }
true;static;1;62;// wrap hadoop rawlocalfilesystem to behave less crazy ;// wrap hadoop rawlocalfilesystem to behave less crazy static RawLocalFileSystem wrap(final Path base) {     final FileSystemProvider baseProvider = base.getFileSystem().provider().     return new RawLocalFileSystem() {          private org.apache.hadoop.fs.Path box(Path path) {             return new org.apache.hadoop.fs.Path(path.toUri()).         }          private Path unbox(org.apache.hadoop.fs.Path path) {             return baseProvider.getPath(path.toUri()).         }          @Override         protected org.apache.hadoop.fs.Path getInitialWorkingDirectory() {             return box(base).         }          @Override         public void setPermission(org.apache.hadoop.fs.Path path, FsPermission permission) {         // no execution, thank you very much!         }          // pretend we don't support symlinks (which causes hadoop to want to do crazy things),         // returning the boolean does not seem to really help, link-related operations are still called.         @Override         public boolean supportsSymlinks() {             return false.         }          @Override         public FileStatus getFileLinkStatus(org.apache.hadoop.fs.Path path) throws IOException {             return getFileStatus(path).         }          @Override         public org.apache.hadoop.fs.Path getLinkTarget(org.apache.hadoop.fs.Path path) throws IOException {             return path.         }          @Override         public FileStatus getFileStatus(org.apache.hadoop.fs.Path path) throws IOException {             BasicFileAttributes attributes.             try {                 attributes = Files.readAttributes(unbox(path), BasicFileAttributes.class).             } catch (NoSuchFileException e) {                 // unfortunately, specific exceptions are not guaranteed. don't wrap hadoop over a zip filesystem or something.                 FileNotFoundException fnfe = new FileNotFoundException("File " + path + " does not exist").                 fnfe.initCause(e).                 throw fnfe.             }             // we set similar values to raw local filesystem, except we are never a symlink             long length = attributes.size().             boolean isDir = attributes.isDirectory().             int blockReplication = 1.             long blockSize = getDefaultBlockSize(path).             long modificationTime = attributes.creationTime().toMillis().             return new FileStatus(length, isDir, blockReplication, blockSize, modificationTime, path).         }     }. }
false;public;1;4;;@Override public void checkPath(org.apache.hadoop.fs.Path path) { // we do evil stuff, we admit it. }
