commented;modifiers;parameterAmount;loc;comment;code
false;protected;0;4;;@Override protected BlobStore newBlobStore() throws IOException {     return new HdfsBlobStore(createTestContext(), "temp", 1024, false). }
false;private;0;10;;private FileContext createTestContext() {     FileContext fileContext.     try {         fileContext = AccessController.doPrivileged((PrivilegedExceptionAction<FileContext>) () -> createContext(new URI("hdfs:///"))).     } catch (PrivilegedActionException e) {         throw new RuntimeException(e.getCause()).     }     return fileContext. }
false;private;1;43;;@SuppressForbidden(reason = "lesser of two evils (the other being a bunch of JNI/classloader nightmares)") private FileContext createContext(URI uri) {     // mirrors HdfsRepository.java behaviour     Configuration cfg = new Configuration(true).     cfg.setClassLoader(HdfsRepository.class.getClassLoader()).     cfg.reloadConfiguration().     Constructor<?> ctor.     Subject subject.     try {         Class<?> clazz = Class.forName("org.apache.hadoop.security.User").         ctor = clazz.getConstructor(String.class).         ctor.setAccessible(true).     } catch (ClassNotFoundException | NoSuchMethodException e) {         throw new RuntimeException(e).     }     try {         Principal principal = (Principal) ctor.newInstance(System.getProperty("user.name")).         subject = new Subject(false, Collections.singleton(principal), Collections.emptySet(), Collections.emptySet()).     } catch (InstantiationException | IllegalAccessException | InvocationTargetException e) {         throw new RuntimeException(e).     }     // disable file system cache     cfg.setBoolean("fs.hdfs.impl.disable.cache", true).     // set file system to TestingFs to avoid a bunch of security     // checks, similar to what is done in HdfsTests.java     cfg.set("fs.AbstractFileSystem." + uri.getScheme() + ".impl", TestingFs.class.getName()).     // create the FileContext with our user     return Subject.doAs(subject, (PrivilegedAction<FileContext>) () -> {         try {             TestingFs fs = (TestingFs) AbstractFileSystem.get(uri, cfg).             return FileContext.getFileContext(fs, cfg).         } catch (UnsupportedFileSystemException e) {             throw new RuntimeException(e).         }     }). }
false;public;0;28;;public void testReadOnly() throws Exception {     FileContext fileContext = createTestContext().     // Constructor will not create dir if read only     HdfsBlobStore hdfsBlobStore = new HdfsBlobStore(fileContext, "dir", 1024, true).     FileContext.Util util = fileContext.util().     Path root = fileContext.makeQualified(new Path("dir")).     assertFalse(util.exists(root)).     BlobPath blobPath = BlobPath.cleanPath().add("path").     // blobContainer() will not create path if read only     hdfsBlobStore.blobContainer(blobPath).     Path hdfsPath = root.     for (String p : blobPath) {         hdfsPath = new Path(hdfsPath, p).     }     assertFalse(util.exists(hdfsPath)).     // if not read only, directory will be created     hdfsBlobStore = new HdfsBlobStore(fileContext, "dir", 1024, false).     assertTrue(util.exists(root)).     BlobContainer container = hdfsBlobStore.blobContainer(blobPath).     assertTrue(util.exists(hdfsPath)).     byte[] data = randomBytes(randomIntBetween(10, scaledRandomIntBetween(1024, 1 << 16))).     writeBlob(container, "foo", new BytesArray(data), randomBoolean()).     assertArrayEquals(readBlobFully(container, "foo", data.length), data).     assertTrue(container.blobExists("foo")). }
