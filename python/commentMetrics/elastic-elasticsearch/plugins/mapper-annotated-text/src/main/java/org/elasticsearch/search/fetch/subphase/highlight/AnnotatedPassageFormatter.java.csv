commented;modifiers;parameterAmount;loc;comment;code
false;public;1;30;;public void addUnlessOverlapping(Markup newMarkup) {     // Fast exit.     if (newMarkup.start > lastMarkupEnd) {         markups.add(newMarkup).         lastMarkupEnd = newMarkup.end.         return.     }     // Check to see if this new markup overlaps with any prior     int index = 0.     for (Markup existingMarkup : markups) {         if (existingMarkup.samePosition(newMarkup)) {             existingMarkup.merge(newMarkup).             return.         }         if (existingMarkup.overlaps(newMarkup)) {             // existing markup wins - we throw away the new markup that would span this position             return.         }         // markup list is in start offset order so we can insert at this position then shift others right         if (existingMarkup.isAfter(newMarkup)) {             markups.add(index, newMarkup).             return.         }         index++.     }     markups.add(newMarkup).     lastMarkupEnd = newMarkup.end. }
false;;1;3;;boolean isAfter(Markup other) {     return start > other.end. }
false;;1;5;;void merge(Markup newMarkup) {     // metadata is key1=value&key2=value&.... syntax used for urls     assert samePosition(newMarkup).     metadata += "&" + newMarkup.metadata. }
false;;1;3;;boolean samePosition(Markup other) {     return this.start == other.start && this.end == other.end. }
false;;1;5;;boolean overlaps(Markup other) {     return (start <= other.start && end >= other.start) || (start <= other.end && end >= other.end) || (start >= other.start && end <= other.end). }
false;public;0;4;;@Override public String toString() {     return "Markup [start=" + start + ", end=" + end + ", metadata=" + metadata + "]". }
true;static;2;30;// Merge original annotations and search hits into a single set of markups for each passage ;// Merge original annotations and search hits into a single set of markups for each passage static MarkupPassage mergeAnnotations(AnnotationToken[] annotations, Passage passage) {     try {         MarkupPassage markupPassage = new MarkupPassage().         // Add search hits first - they take precedence over any other markup         for (int i = 0. i < passage.getNumMatches(). i++) {             int start = passage.getMatchStarts()[i].             int end = passage.getMatchEnds()[i].             String searchTerm = passage.getMatchTerms()[i].utf8ToString().             Markup markup = new Markup(start, end, SEARCH_HIT_TYPE + "=" + URLEncoder.encode(searchTerm, StandardCharsets.UTF_8.name())).             markupPassage.addUnlessOverlapping(markup).         }         // Now add original text's annotations - ignoring any that might conflict with the search hits markup.         for (AnnotationToken token : annotations) {             int start = token.offset.             int end = token.endOffset.             if (start >= passage.getStartOffset() && end <= passage.getEndOffset()) {                 String escapedValue = URLEncoder.encode(token.value, StandardCharsets.UTF_8.name()).                 Markup markup = new Markup(start, end, escapedValue).                 markupPassage.addUnlessOverlapping(markup).             }         }         return markupPassage.     } catch (UnsupportedEncodingException e) {         // We should always have UTF-8 support         throw new IllegalStateException(e).     } }
false;public;2;43;;@Override public Snippet[] format(Passage[] passages, String content) {     Snippet[] snippets = new Snippet[passages.length].     int pos.     int j = 0.     for (Passage passage : passages) {         AnnotationToken[] annotations = annotatedHighlighterAnalyzer.getIntersectingAnnotations(passage.getStartOffset(), passage.getEndOffset()).         MarkupPassage mergedMarkup = mergeAnnotations(annotations, passage).         StringBuilder sb = new StringBuilder().         pos = passage.getStartOffset().         for (Markup markup : mergedMarkup.markups) {             int start = markup.start.             int end = markup.end.             // its possible to have overlapping terms             if (start > pos) {                 append(sb, content, pos, start).             }             if (end > pos) {                 sb.append("[").                 append(sb, content, Math.max(pos, start), end).                 sb.append("](").                 sb.append(markup.metadata).                 sb.append(")").                 pos = end.             }         }         // its possible a "term" from the analyzer could span a sentence boundary.         append(sb, content, pos, Math.max(pos, passage.getEndOffset())).         // we remove the paragraph separator if present at the end of the snippet (we used it as separator between values)         if (sb.charAt(sb.length() - 1) == HighlightUtils.PARAGRAPH_SEPARATOR) {             sb.deleteCharAt(sb.length() - 1).         } else if (sb.charAt(sb.length() - 1) == HighlightUtils.NULL_SEPARATOR) {             sb.deleteCharAt(sb.length() - 1).         }         // and we trim the snippets too         snippets[j++] = new Snippet(sb.toString().trim(), passage.getScore(), passage.getNumMatches() > 0).     }     return snippets. }
false;private;4;3;;private void append(StringBuilder dest, String content, int start, int end) {     dest.append(encoder.encodeText(content.substring(start, end))). }
