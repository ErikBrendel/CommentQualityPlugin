commented;modifiers;parameterAmount;loc;comment;code
false;public,static;0;3;;public static List<NamedXContentRegistry.Entry> getDefaultNamedXContents() {     return namedXContents. }
false;protected;0;3;;protected List<NamedXContentRegistry.Entry> getNamedXContents() {     return namedXContents. }
false;protected,abstract;3;1;;protected abstract T createTestInstance(String name, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData).
true;protected;3;6;/**  * Return an instance on an unmapped field.  */ ;/**  * Return an instance on an unmapped field.  */ protected T createUnmappedInstance(String name, List<PipelineAggregator> pipelineAggregators, Map<String, Object> metaData) {     // For most impls, we use the same instance in the unmapped case and in the mapped case     return createTestInstance(name, pipelineAggregators, metaData). }
false;public;0;43;;public void testReduceRandom() {     String name = randomAlphaOfLength(5).     List<T> inputs = new ArrayList<>().     List<InternalAggregation> toReduce = new ArrayList<>().     int toReduceSize = between(1, 200).     for (int i = 0. i < toReduceSize. i++) {         T t = randomBoolean() ? createUnmappedInstance(name) : createTestInstance(name).         inputs.add(t).         toReduce.add(t).     }     // Sort aggs so that unmapped come last.  This mimicks the behavior of InternalAggregations.reduce()     inputs.sort(INTERNAL_AGG_COMPARATOR).     ScriptService mockScriptService = mockScriptService().     MockBigArrays bigArrays = new MockBigArrays(new MockPageCacheRecycler(Settings.EMPTY), new NoneCircuitBreakerService()).     if (randomBoolean() && toReduce.size() > 1) {         // sometimes do an incremental reduce         Collections.shuffle(toReduce, random()).         int r = randomIntBetween(1, toReduceSize).         List<InternalAggregation> internalAggregations = toReduce.subList(0, r).         MultiBucketConsumer bucketConsumer = new MultiBucketConsumer(DEFAULT_MAX_BUCKETS).         InternalAggregation.ReduceContext context = new InternalAggregation.ReduceContext(bigArrays, mockScriptService, bucketConsumer, false).         @SuppressWarnings("unchecked")         T reduced = (T) inputs.get(0).reduce(internalAggregations, context).         int initialBucketCount = 0.         for (InternalAggregation internalAggregation : internalAggregations) {             initialBucketCount += countInnerBucket(internalAggregation).         }         int reducedBucketCount = countInnerBucket(reduced).         // check that non final reduction never adds buckets         assertThat(reducedBucketCount, lessThanOrEqualTo(initialBucketCount)).         assertMultiBucketConsumer(reducedBucketCount, bucketConsumer).         toReduce = new ArrayList<>(toReduce.subList(r, toReduceSize)).         toReduce.add(reduced).     }     MultiBucketConsumer bucketConsumer = new MultiBucketConsumer(DEFAULT_MAX_BUCKETS).     InternalAggregation.ReduceContext context = new InternalAggregation.ReduceContext(bigArrays, mockScriptService, bucketConsumer, true).     @SuppressWarnings("unchecked")     T reduced = (T) inputs.get(0).reduce(toReduce, context).     assertMultiBucketConsumer(reduced, bucketConsumer).     assertReduced(reduced, inputs). }
true;protected;0;3;/**  * overwrite in tests that need it  */ ;/**  * overwrite in tests that need it  */ protected ScriptService mockScriptService() {     return null. }
false;protected,abstract;2;1;;protected abstract void assertReduced(T reduced, List<T> inputs).
false;public,final;0;4;;@Override public final T createTestInstance() {     return createTestInstance(randomAlphaOfLength(5)). }
false;private;1;13;;private T createTestInstance(String name) {     List<PipelineAggregator> pipelineAggregators = new ArrayList<>().     // TODO populate pipelineAggregators     Map<String, Object> metaData = null.     if (randomBoolean()) {         metaData = new HashMap<>().         int metaDataCount = between(0, 10).         while (metaData.size() < metaDataCount) {             metaData.put(randomAlphaOfLength(5), randomAlphaOfLength(5)).         }     }     return createTestInstance(name, pipelineAggregators, metaData). }
true;protected,final;1;10;/**  * Return an instance on an unmapped field.  */ ;/**  * Return an instance on an unmapped field.  */ protected final T createUnmappedInstance(String name) {     List<PipelineAggregator> pipelineAggregators = new ArrayList<>().     // TODO populate pipelineAggregators     Map<String, Object> metaData = new HashMap<>().     int metaDataCount = randomBoolean() ? 0 : between(1, 10).     while (metaData.size() < metaDataCount) {         metaData.put(randomAlphaOfLength(5), randomAlphaOfLength(5)).     }     return createUnmappedInstance(name, pipelineAggregators, metaData). }
false;protected;0;4;;@Override protected NamedWriteableRegistry getNamedWriteableRegistry() {     return namedWriteableRegistry. }
false;protected;0;4;;@Override protected NamedXContentRegistry xContentRegistry() {     return namedXContentRegistry. }
false;public,final;0;5;;public final void testFromXContent() throws IOException {     final T aggregation = createTestInstance().     final ParsedAggregation parsedAggregation = parseAndAssert(aggregation, randomBoolean(), false).     assertFromXContent(aggregation, parsedAggregation). }
false;public,final;0;5;;public final void testFromXContentWithRandomFields() throws IOException {     final T aggregation = createTestInstance().     final ParsedAggregation parsedAggregation = parseAndAssert(aggregation, randomBoolean(), true).     assertFromXContent(aggregation, parsedAggregation). }
false;protected,abstract;2;1;;protected abstract void assertFromXContent(T aggregation, ParsedAggregation parsedAggregation) throws IOException.
false;protected;3;59;;@SuppressWarnings("unchecked") protected <P extends ParsedAggregation> P parseAndAssert(final InternalAggregation aggregation, final boolean shuffled, final boolean addRandomFields) throws IOException {     final ToXContent.Params params = new ToXContent.MapParams(singletonMap(RestSearchAction.TYPED_KEYS_PARAM, "true")).     final XContentType xContentType = randomFrom(XContentType.values()).     final boolean humanReadable = randomBoolean().     final BytesReference originalBytes.     if (shuffled) {         originalBytes = toShuffledXContent(aggregation, xContentType, params, humanReadable).     } else {         originalBytes = toXContent(aggregation, xContentType, params, humanReadable).     }     BytesReference mutated.     if (addRandomFields) {         /*              * - we don't add to the root object because it should only contain              * the named aggregation to test - we don't want to insert into the              * "meta" object, because we pass on everything we find there              *              * - we don't want to directly insert anything random into "buckets"              * objects, they are used with "keyed" aggregations and contain              * named bucket objects. Any new named object on this level should              * also be a bucket and be parsed as such.              */         Predicate<String> basicExcludes = path -> path.isEmpty() || path.endsWith(Aggregation.CommonFields.META.getPreferredName()) || path.endsWith(Aggregation.CommonFields.BUCKETS.getPreferredName()).         Predicate<String> excludes = basicExcludes.or(excludePathsFromXContentInsertion()).         mutated = insertRandomFields(xContentType, originalBytes, excludes, random()).     } else {         mutated = originalBytes.     }     SetOnce<Aggregation> parsedAggregation = new SetOnce<>().     try (XContentParser parser = createParser(xContentType.xContent(), mutated)) {         assertEquals(XContentParser.Token.START_OBJECT, parser.nextToken()).         assertEquals(XContentParser.Token.FIELD_NAME, parser.nextToken()).         assertEquals(XContentParser.Token.START_OBJECT, parser.nextToken()).         XContentParserUtils.parseTypedKeysObject(parser, Aggregation.TYPED_KEYS_DELIMITER, Aggregation.class, parsedAggregation::set).         assertEquals(XContentParser.Token.END_OBJECT, parser.currentToken()).         assertEquals(XContentParser.Token.END_OBJECT, parser.nextToken()).         assertNull(parser.nextToken()).         Aggregation agg = parsedAggregation.get().         assertEquals(aggregation.getName(), agg.getName()).         assertEquals(aggregation.getMetaData(), agg.getMetaData()).         assertTrue(agg instanceof ParsedAggregation).         assertEquals(aggregation.getType(), agg.getType()).         BytesReference parsedBytes = toXContent(agg, xContentType, params, humanReadable).         assertToXContentEquivalent(originalBytes, parsedBytes, xContentType).         return (P) agg.     } }
true;protected;0;3;/**  * Overwrite this in your test if other than the basic xContent paths should be excluded during insertion of random fields  */ ;/**  * Overwrite this in your test if other than the basic xContent paths should be excluded during insertion of random fields  */ protected Predicate<String> excludePathsFromXContentInsertion() {     return path -> false. }
true;protected,static;0;6;/**  * @return a random {@link DocValueFormat} that can be used in aggregations which  * compute numbers.  */ ;/**  * @return a random {@link DocValueFormat} that can be used in aggregations which  * compute numbers.  */ protected static DocValueFormat randomNumericDocValueFormat() {     final List<Supplier<DocValueFormat>> formats = new ArrayList<>(3).     formats.add(() -> DocValueFormat.RAW).     formats.add(() -> new DocValueFormat.Decimal(randomFrom("###.##", "###,###.##"))).     return randomFrom(formats).get(). }
false;public,static;2;3;;public static void assertMultiBucketConsumer(Aggregation agg, MultiBucketConsumer bucketConsumer) {     assertMultiBucketConsumer(countInnerBucket(agg), bucketConsumer). }
false;private,static;2;3;;private static void assertMultiBucketConsumer(int innerBucketCount, MultiBucketConsumer bucketConsumer) {     assertThat(bucketConsumer.getCount(), equalTo(innerBucketCount)). }
