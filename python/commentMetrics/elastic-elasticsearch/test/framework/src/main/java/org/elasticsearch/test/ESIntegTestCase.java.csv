commented;modifiers;parameterAmount;loc;comment;code
false;public,static;0;5;;@BeforeClass public static void beforeClass() throws Exception {     SUITE_SEED = randomLong().     initializeSuiteScope(). }
false;protected,final;0;6;;@Override protected final boolean enableWarningsCheck() {     // if the cluster is internal the deprecation logger is shared across all nodes     return false. }
false;protected,final;0;21;;protected final void beforeInternal() throws Exception {     final Scope currentClusterScope = getCurrentClusterScope().     Callable<Void> setup = () -> {         cluster().beforeTest(random(), getPerTestTransportClientRatio()).         cluster().wipe(excludeTemplates()).         randomIndexTemplate().         return null.     }.     switch(currentClusterScope) {         case SUITE:             assert SUITE_SEED != null : "Suite seed was not initialized".             currentCluster = buildAndPutCluster(currentClusterScope, SUITE_SEED).             RandomizedContext.current().runWithPrivateRandomness(SUITE_SEED, setup).             break.         case TEST:             currentCluster = buildAndPutCluster(currentClusterScope, randomLong()).             setup.call().             break.     } }
false;private;1;7;;private void printTestMessage(String message) {     if (isSuiteScopedTest(getClass()) && (getTestName().equals("<unknown>"))) {         logger.info("[{}]: {} suite", getTestClass().getSimpleName(), message).     } else {         logger.info("[{}#{}]: {} test", getTestClass().getSimpleName(), getTestName(), message).     } }
true;public;0;39;/**  * Creates a randomized index template. This template is used to pass in randomized settings on a  * per index basis. Allows to enable/disable the randomization for number of shards and replicas  */ ;/**  * Creates a randomized index template. This template is used to pass in randomized settings on a  * per index basis. Allows to enable/disable the randomization for number of shards and replicas  */ public void randomIndexTemplate() {     // TODO move settings for random directory etc here into the index based randomized settings.     if (cluster().size() > 0) {         Settings.Builder randomSettingsBuilder = setRandomIndexSettings(random(), Settings.builder()).         if (isInternalCluster()) {             // this is only used by mock plugins and if the cluster is not internal we just can't set it             randomSettingsBuilder.put(INDEX_TEST_SEED_SETTING.getKey(), random().nextLong()).         }         randomSettingsBuilder.put(SETTING_NUMBER_OF_SHARDS, numberOfShards()).put(SETTING_NUMBER_OF_REPLICAS, numberOfReplicas()).         // if the test class is annotated with SuppressCodecs("*"), it means don't use lucene's codec randomization         // otherwise, use it, it has assertions and so on that can find bugs.         SuppressCodecs annotation = getClass().getAnnotation(SuppressCodecs.class).         if (annotation != null && annotation.value().length == 1 && "*".equals(annotation.value()[0])) {             randomSettingsBuilder.put("index.codec", randomFrom(CodecService.DEFAULT_CODEC, CodecService.BEST_COMPRESSION_CODEC)).         } else {             randomSettingsBuilder.put("index.codec", CodecService.LUCENE_DEFAULT_CODEC).         }         for (String setting : randomSettingsBuilder.keys()) {             assertThat("non index. prefix setting set on index template, its a node setting...", setting, startsWith("index.")).         }         // always default delayed allocation to 0 to make sure we have tests are not delayed         randomSettingsBuilder.put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), 0).         if (randomBoolean()) {             randomSettingsBuilder.put(IndexModule.INDEX_QUERY_CACHE_ENABLED_SETTING.getKey(), randomBoolean()).         }         PutIndexTemplateRequestBuilder putTemplate = client().admin().indices().preparePutTemplate("random_index_template").setPatterns(Collections.singletonList("*")).setOrder(0).setSettings(randomSettingsBuilder).         assertAcked(putTemplate.execute().actionGet()).     } }
false;protected;2;24;;protected Settings.Builder setRandomIndexSettings(Random random, Settings.Builder builder) {     setRandomIndexMergeSettings(random, builder).     setRandomIndexTranslogSettings(random, builder).     if (random.nextBoolean()) {         builder.put(MergeSchedulerConfig.AUTO_THROTTLE_SETTING.getKey(), false).     }     if (random.nextBoolean()) {         builder.put(IndicesRequestCache.INDEX_CACHE_REQUEST_ENABLED_SETTING.getKey(), random.nextBoolean()).     }     if (random.nextBoolean()) {         builder.put(IndexSettings.INDEX_CHECK_ON_STARTUP.getKey(), randomFrom("false", "checksum", "true")).     }     if (randomBoolean()) {         // keep this low so we don't stall tests         builder.put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), RandomNumbers.randomIntBetween(random, 1, 15) + "ms").     }     return builder. }
false;private,static;2;16;;private static Settings.Builder setRandomIndexMergeSettings(Random random, Settings.Builder builder) {     if (random.nextBoolean()) {         builder.put(MergePolicyConfig.INDEX_COMPOUND_FORMAT_SETTING.getKey(), (random.nextBoolean() ? random.nextDouble() : random.nextBoolean()).toString()).     }     switch(random.nextInt(4)) {         case 3:             final int maxThreadCount = RandomNumbers.randomIntBetween(random, 1, 4).             final int maxMergeCount = RandomNumbers.randomIntBetween(random, maxThreadCount, maxThreadCount + 4).             builder.put(MergeSchedulerConfig.MAX_MERGE_COUNT_SETTING.getKey(), maxMergeCount).             builder.put(MergeSchedulerConfig.MAX_THREAD_COUNT_SETTING.getKey(), maxThreadCount).             break.     }     return builder. }
false;private,static;2;21;;private static Settings.Builder setRandomIndexTranslogSettings(Random random, Settings.Builder builder) {     if (random.nextBoolean()) {         builder.put(IndexSettings.INDEX_TRANSLOG_FLUSH_THRESHOLD_SIZE_SETTING.getKey(), new ByteSizeValue(RandomNumbers.randomIntBetween(random, 1, 300), ByteSizeUnit.MB)).     }     if (random.nextBoolean()) {         builder.put(IndexSettings.INDEX_TRANSLOG_FLUSH_THRESHOLD_SIZE_SETTING.getKey(), // just don't flush         new ByteSizeValue(1, ByteSizeUnit.PB)).     }     if (random.nextBoolean()) {         builder.put(IndexSettings.INDEX_TRANSLOG_DURABILITY_SETTING.getKey(), RandomPicks.randomFrom(random, Translog.Durability.values())).     }     if (random.nextBoolean()) {         builder.put(IndexSettings.INDEX_TRANSLOG_SYNC_INTERVAL_SETTING.getKey(), RandomNumbers.randomIntBetween(random, 100, 5000), TimeUnit.MILLISECONDS).     }     return builder. }
false;public;0;4;;@Override public TestCluster call() throws Exception {     return buildTestCluster(scope, seed). }
false;private;2;8;;private TestCluster buildWithPrivateContext(final Scope scope, final long seed) throws Exception {     return RandomizedContext.current().runWithPrivateRandomness(seed, new Callable<TestCluster>() {          @Override         public TestCluster call() throws Exception {             return buildTestCluster(scope, seed).         }     }). }
false;private;2;19;;private TestCluster buildAndPutCluster(Scope currentClusterScope, long seed) throws Exception {     final Class<?> clazz = this.getClass().     // remove this cluster first     TestCluster testCluster = clusters.remove(clazz).     // all leftovers are gone by now... this is really just a double safety if we miss something somewhere     clearClusters().     switch(currentClusterScope) {         case SUITE:             if (testCluster == null) {                 // only build if it's not there yet                 testCluster = buildWithPrivateContext(currentClusterScope, seed).             }             break.         case TEST:             // close the previous one and create a new one             IOUtils.closeWhileHandlingException(testCluster).             testCluster = buildTestCluster(currentClusterScope, seed).             break.     }     clusters.put(clazz, testCluster).     return testCluster. }
false;private,static;0;10;;private static void clearClusters() throws IOException {     if (!clusters.isEmpty()) {         IOUtils.close(clusters.values()).         clusters.clear().     }     if (restClient != null) {         restClient.close().         restClient = null.     } }
false;protected,final;1;58;;protected final void afterInternal(boolean afterClass) throws Exception {     boolean success = false.     try {         final Scope currentClusterScope = getCurrentClusterScope().         clearDisruptionScheme().         try {             if (cluster() != null) {                 if (currentClusterScope != Scope.TEST) {                     MetaData metaData = client().admin().cluster().prepareState().execute().actionGet().getState().getMetaData().                     final Set<String> persistentKeys = new HashSet<>(metaData.persistentSettings().keySet()).                     assertThat("test leaves persistent cluster metadata behind", persistentKeys, empty()).                     final Set<String> transientKeys = new HashSet<>(metaData.transientSettings().keySet()).                     if (isInternalCluster() && internalCluster().getAutoManageMinMasterNode()) {                         // this is set by the test infra                         transientKeys.remove(ElectMasterService.DISCOVERY_ZEN_MINIMUM_MASTER_NODES_SETTING.getKey()).                     }                     assertThat("test leaves transient cluster metadata behind", transientKeys, empty()).                 }                 ensureClusterSizeConsistency().                 ensureClusterStateConsistency().                 if (isInternalCluster()) {                     // check no pending cluster states are leaked                     for (Discovery discovery : internalCluster().getInstances(Discovery.class)) {                         if (discovery instanceof ZenDiscovery) {                             final ZenDiscovery zenDiscovery = (ZenDiscovery) discovery.                             assertBusy(() -> {                                 final ClusterState[] states = zenDiscovery.pendingClusterStates().                                 assertThat(zenDiscovery.clusterState().nodes().getLocalNode().getName() + " still having pending states:\n" + Stream.of(states).map(ClusterState::toString).collect(Collectors.joining("\n")), states, emptyArray()).                             }).                         }                     }                 }                 beforeIndexDeletion().                 // wipe after to make sure we fail in the test that didn't ack the delete                 cluster().wipe(excludeTemplates()).                 if (afterClass || currentClusterScope == Scope.TEST) {                     cluster().close().                 }                 cluster().assertAfterTest().             }         } finally {             if (currentClusterScope == Scope.TEST) {                 // it is ok to leave persistent / transient cluster state behind if scope is TEST                 clearClusters().             }         }         success = true.     } finally {         if (!success) {         // if we failed here that means that something broke horribly so we should clear all clusters         // TODO: just let the exception happen, WTF is all this horseshit         // afterTestRule.forceFailure().         }     } }
true;protected;0;3;/**  * @return An exclude set of index templates that will not be removed in between tests.  */ ;/**  * @return An exclude set of index templates that will not be removed in between tests.  */ protected Set<String> excludeTemplates() {     return Collections.emptySet(). }
false;protected;0;3;;protected void beforeIndexDeletion() throws Exception {     cluster().beforeIndexDeletion(). }
false;public,static;0;3;;public static TestCluster cluster() {     return currentCluster. }
false;public,static;0;3;;public static boolean isInternalCluster() {     return (currentCluster instanceof InternalTestCluster). }
false;public,static;0;6;;public static InternalTestCluster internalCluster() {     if (!isInternalCluster()) {         throw new UnsupportedOperationException("current test cluster is immutable").     }     return (InternalTestCluster) currentCluster. }
false;public;0;3;;public ClusterService clusterService() {     return internalCluster().clusterService(). }
false;public,static;0;3;;public static Client client() {     return client(null). }
false;public,static;1;10;;public static Client client(@Nullable String node) {     if (node != null) {         return internalCluster().client(node).     }     Client client = cluster().client().     if (frequently()) {         client = new RandomizingClient(client, random()).     }     return client. }
false;public,static;0;7;;public static Client dataNodeClient() {     Client client = internalCluster().dataNodeClient().     if (frequently()) {         client = new RandomizingClient(client, random()).     }     return client. }
false;public,static;0;3;;public static Iterable<Client> clients() {     return cluster().getClients(). }
false;protected;0;3;;protected int minimumNumberOfShards() {     return DEFAULT_MIN_NUM_SHARDS. }
false;protected;0;3;;protected int maximumNumberOfShards() {     return DEFAULT_MAX_NUM_SHARDS. }
false;protected;0;3;;protected int numberOfShards() {     return between(minimumNumberOfShards(), maximumNumberOfShards()). }
false;protected;0;3;;protected int minimumNumberOfReplicas() {     return 0. }
false;protected;0;5;;protected int maximumNumberOfReplicas() {     // use either 0 or 1 replica, yet a higher amount when possible, but only rarely     int maxNumReplicas = Math.max(0, cluster().numDataNodes() - 1).     return frequently() ? Math.min(1, maxNumReplicas) : maxNumReplicas. }
false;protected;0;3;;protected int numberOfReplicas() {     return between(minimumNumberOfReplicas(), maximumNumberOfReplicas()). }
false;public;1;3;;public void setDisruptionScheme(ServiceDisruptionScheme scheme) {     internalCluster().setDisruptionScheme(scheme). }
false;public;0;5;;public void clearDisruptionScheme() {     if (isInternalCluster()) {         internalCluster().clearDisruptionScheme().     } }
true;public;0;24;/**  * Returns a settings object used in {@link #createIndex(String...)} and {@link #prepareCreate(String)} and friends.  * This method can be overwritten by subclasses to set defaults for the indices that are created by the test.  * By default it returns a settings object that sets a random number of shards. Number of shards and replicas  * can be controlled through specific methods.  */ ;/**  * Returns a settings object used in {@link #createIndex(String...)} and {@link #prepareCreate(String)} and friends.  * This method can be overwritten by subclasses to set defaults for the indices that are created by the test.  * By default it returns a settings object that sets a random number of shards. Number of shards and replicas  * can be controlled through specific methods.  */ public Settings indexSettings() {     Settings.Builder builder = Settings.builder().     int numberOfShards = numberOfShards().     if (numberOfShards > 0) {         builder.put(SETTING_NUMBER_OF_SHARDS, numberOfShards).build().     }     int numberOfReplicas = numberOfReplicas().     if (numberOfReplicas >= 0) {         builder.put(SETTING_NUMBER_OF_REPLICAS, numberOfReplicas).build().     }     // 30% of the time     if (randomInt(9) < 3) {         final String dataPath = randomAlphaOfLength(10).         logger.info("using custom data_path for index: [{}]", dataPath).         builder.put(IndexMetaData.SETTING_DATA_PATH, dataPath).     }     // always default delayed allocation to 0 to make sure we have tests are not delayed     builder.put(UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), 0).     builder.put(IndexSettings.INDEX_SOFT_DELETES_SETTING.getKey(), randomBoolean()).     if (randomBoolean()) {         builder.put(IndexSettings.INDEX_SOFT_DELETES_RETENTION_OPERATIONS_SETTING.getKey(), between(0, 1000)).     }     return builder.build(). }
true;public,final;1;16;/**  * Creates one or more indices and asserts that the indices are acknowledged. If one of the indices  * already exists this method will fail and wipe all the indices created so far.  */ ;/**  * Creates one or more indices and asserts that the indices are acknowledged. If one of the indices  * already exists this method will fail and wipe all the indices created so far.  */ public final void createIndex(String... names) {     List<String> created = new ArrayList<>().     for (String name : names) {         boolean success = false.         try {             assertAcked(prepareCreate(name)).             created.add(name).             success = true.         } finally {             if (!success && !created.isEmpty()) {                 cluster().wipeIndices(created.toArray(new String[created.size()])).             }         }     } }
true;public,final;2;3;/**  * creates an index with the given setting  */ ;/**  * creates an index with the given setting  */ public final void createIndex(String name, Settings indexSettings) {     assertAcked(prepareCreate(name).setSettings(indexSettings)). }
true;public,final;1;3;/**  * Creates a new {@link CreateIndexRequestBuilder} with the settings obtained from {@link #indexSettings()}.  */ ;/**  * Creates a new {@link CreateIndexRequestBuilder} with the settings obtained from {@link #indexSettings()}.  */ public final CreateIndexRequestBuilder prepareCreate(String index) {     return prepareCreate(index, -1). }
true;public,final;2;3;/**  * Creates a new {@link CreateIndexRequestBuilder} with the settings obtained from {@link #indexSettings()}.  * The index that is created with this builder will only be allowed to allocate on the number of nodes passed to this  * method.  * <p>  * This method uses allocation deciders to filter out certain nodes to allocate the created index on. It defines allocation  * rules based on <code>index.routing.allocation.exclude._name</code>.  * </p>  */ ;/**  * Creates a new {@link CreateIndexRequestBuilder} with the settings obtained from {@link #indexSettings()}.  * The index that is created with this builder will only be allowed to allocate on the number of nodes passed to this  * method.  * <p>  * This method uses allocation deciders to filter out certain nodes to allocate the created index on. It defines allocation  * rules based on <code>index.routing.allocation.exclude._name</code>.  * </p>  */ public final CreateIndexRequestBuilder prepareCreate(String index, int numNodes) {     return prepareCreate(index, numNodes, Settings.builder()). }
true;public;2;3;/**  * Creates a new {@link CreateIndexRequestBuilder} with the settings obtained from {@link #indexSettings()}, augmented  * by the given builder  */ ;/**  * Creates a new {@link CreateIndexRequestBuilder} with the settings obtained from {@link #indexSettings()}, augmented  * by the given builder  */ public CreateIndexRequestBuilder prepareCreate(String index, Settings.Builder settingsBuilder) {     return prepareCreate(index, -1, settingsBuilder). }
true;public;3;9;/**  * Creates a new {@link CreateIndexRequestBuilder} with the settings obtained from {@link #indexSettings()}.  * The index that is created with this builder will only be allowed to allocate on the number of nodes passed to this  * method.  * <p>  * This method uses allocation deciders to filter out certain nodes to allocate the created index on. It defines allocation  * rules based on <code>index.routing.allocation.exclude._name</code>.  * </p>  */ ;/**  * Creates a new {@link CreateIndexRequestBuilder} with the settings obtained from {@link #indexSettings()}.  * The index that is created with this builder will only be allowed to allocate on the number of nodes passed to this  * method.  * <p>  * This method uses allocation deciders to filter out certain nodes to allocate the created index on. It defines allocation  * rules based on <code>index.routing.allocation.exclude._name</code>.  * </p>  */ public CreateIndexRequestBuilder prepareCreate(String index, int numNodes, Settings.Builder settingsBuilder) {     Settings.Builder builder = Settings.builder().put(indexSettings()).put(settingsBuilder.build()).     if (numNodes > 0) {         internalCluster().ensureAtLeastNumDataNodes(numNodes).         getExcludeSettings(numNodes, builder).     }     return client().admin().indices().prepareCreate(index).setSettings(builder.build()). }
false;private;2;5;;private Settings.Builder getExcludeSettings(int num, Settings.Builder builder) {     String exclude = String.join(",", internalCluster().allDataNodesButN(num)).     builder.put("index.routing.allocation.exclude._name", exclude).     return builder. }
true;public;0;14;/**  * Waits until all nodes have no pending tasks.  */ ;/**  * Waits until all nodes have no pending tasks.  */ public void waitNoPendingTasksOnAll() throws Exception {     assertNoTimeout(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).get()).     assertBusy(() -> {         for (Client client : clients()) {             ClusterHealthResponse clusterHealth = client.admin().cluster().prepareHealth().setLocal(true).get().             assertThat("client " + client + " still has in flight fetch", clusterHealth.getNumberOfInFlightFetch(), equalTo(0)).             PendingClusterTasksResponse pendingTasks = client.admin().cluster().preparePendingClusterTasks().setLocal(true).get().             assertThat("client " + client + " still has pending tasks " + pendingTasks, pendingTasks, Matchers.emptyIterable()).             clusterHealth = client.admin().cluster().prepareHealth().setLocal(true).get().             assertThat("client " + client + " still has in flight fetch", clusterHealth.getNumberOfInFlightFetch(), equalTo(0)).         }     }).     assertNoTimeout(client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).get()). }
true;public;3;15;/**  * Waits until mappings for the provided fields exist on all nodes. Note, this waits for the current  * started shards and checks for concrete mappings.  */ ;/**  * Waits until mappings for the provided fields exist on all nodes. Note, this waits for the current  * started shards and checks for concrete mappings.  */ public void assertConcreteMappingsOnAll(final String index, final String type, final String... fieldNames) throws Exception {     Set<String> nodes = internalCluster().nodesInclude(index).     assertThat(nodes, Matchers.not(Matchers.emptyIterable())).     for (String node : nodes) {         IndicesService indicesService = internalCluster().getInstance(IndicesService.class, node).         IndexService indexService = indicesService.indexService(resolveIndex(index)).         assertThat("index service doesn't exists on " + node, indexService, notNullValue()).         MapperService mapperService = indexService.mapperService().         for (String fieldName : fieldNames) {             MappedFieldType fieldType = mapperService.fullName(fieldName).             assertNotNull("field " + fieldName + " doesn't exists on " + node, fieldType).         }     }     assertMappingOnMaster(index, type, fieldNames). }
true;public;3;20;/**  * Waits for the given mapping type to exists on the master node.  */ ;/**  * Waits for the given mapping type to exists on the master node.  */ public void assertMappingOnMaster(final String index, final String type, final String... fieldNames) throws Exception {     GetMappingsResponse response = client().admin().indices().prepareGetMappings(index).setTypes(type).get().     ImmutableOpenMap<String, MappingMetaData> mappings = response.getMappings().get(index).     assertThat(mappings, notNullValue()).     MappingMetaData mappingMetaData = mappings.get(type).     assertThat(mappingMetaData, notNullValue()).     Map<String, Object> mappingSource = mappingMetaData.getSourceAsMap().     assertFalse(mappingSource.isEmpty()).     assertTrue(mappingSource.containsKey("properties")).     for (String fieldName : fieldNames) {         Map<String, Object> mappingProperties = (Map<String, Object>) mappingSource.get("properties").         if (fieldName.indexOf('.') != -1) {             fieldName = fieldName.replace(".", ".properties.").         }         assertThat("field " + fieldName + " doesn't exists in mapping " + mappingMetaData.source().string(), XContentMapValues.extractValue(fieldName, mappingProperties), notNullValue()).     } }
true;public;2;16;/**  * Ensures the result counts are as expected, and logs the results if different  */ ;/**  * Ensures the result counts are as expected, and logs the results if different  */ public void assertResultsAndLogOnFailure(long expectedResults, SearchResponse searchResponse) {     final TotalHits totalHits = searchResponse.getHits().getTotalHits().     if (totalHits.value != expectedResults || totalHits.relation != TotalHits.Relation.EQUAL_TO) {         StringBuilder sb = new StringBuilder("search result contains [").         String value = Long.toString(totalHits.value) + (totalHits.relation == TotalHits.Relation.GREATER_THAN_OR_EQUAL_TO ? "+" : "").         sb.append(value).append("] results. expected [").append(expectedResults).append("]").         String failMsg = sb.toString().         for (SearchHit hit : searchResponse.getHits().getHits()) {             sb.append("\n-> _index: [").append(hit.getIndex()).append("] type [").append(hit.getType()).append("] id [").append(hit.getId()).append("]").         }         logger.warn("{}", sb).         fail(failMsg).     } }
true;public;2;13;/**  * Restricts the given index to be allocated on <code>n</code> nodes using the allocation deciders.  * Yet if the shards can't be allocated on any other node shards for this index will remain allocated on  * more than <code>n</code> nodes.  */ ;/**  * Restricts the given index to be allocated on <code>n</code> nodes using the allocation deciders.  * Yet if the shards can't be allocated on any other node shards for this index will remain allocated on  * more than <code>n</code> nodes.  */ public void allowNodes(String index, int n) {     assert index != null.     internalCluster().ensureAtLeastNumDataNodes(n).     Settings.Builder builder = Settings.builder().     if (n > 0) {         getExcludeSettings(n, builder).     }     Settings build = builder.build().     if (!build.isEmpty()) {         logger.debug("allowNodes: updating [{}]'s setting to [{}]", index, build.toDelimitedString('.')).         client().admin().indices().prepareUpdateSettings(index).setSettings(build).execute().actionGet().     } }
true;public;1;3;/**  * Ensures the cluster has a green state via the cluster health API. This method will also wait for relocations.  * It is useful to ensure that all action on the cluster have finished and all shards that were currently relocating  * are now allocated and started.  */ ;/**  * Ensures the cluster has a green state via the cluster health API. This method will also wait for relocations.  * It is useful to ensure that all action on the cluster have finished and all shards that were currently relocating  * are now allocated and started.  */ public ClusterHealthStatus ensureGreen(String... indices) {     return ensureGreen(TimeValue.timeValueSeconds(30), indices). }
true;public;2;3;/**  * Ensures the cluster has a green state via the cluster health API. This method will also wait for relocations.  * It is useful to ensure that all action on the cluster have finished and all shards that were currently relocating  * are now allocated and started.  *  * @param timeout time out value to set on {@link org.elasticsearch.action.admin.cluster.health.ClusterHealthRequest}  */ ;/**  * Ensures the cluster has a green state via the cluster health API. This method will also wait for relocations.  * It is useful to ensure that all action on the cluster have finished and all shards that were currently relocating  * are now allocated and started.  *  * @param timeout time out value to set on {@link org.elasticsearch.action.admin.cluster.health.ClusterHealthRequest}  */ public ClusterHealthStatus ensureGreen(TimeValue timeout, String... indices) {     return ensureColor(ClusterHealthStatus.GREEN, timeout, false, indices). }
true;public;1;3;/**  * Ensures the cluster has a yellow state via the cluster health API.  */ ;/**  * Ensures the cluster has a yellow state via the cluster health API.  */ public ClusterHealthStatus ensureYellow(String... indices) {     return ensureColor(ClusterHealthStatus.YELLOW, TimeValue.timeValueSeconds(30), false, indices). }
true;public;1;3;/**  * Ensures the cluster has a yellow state via the cluster health API and ensures the that cluster has no initializing shards  * for the given indices  */ ;/**  * Ensures the cluster has a yellow state via the cluster health API and ensures the that cluster has no initializing shards  * for the given indices  */ public ClusterHealthStatus ensureYellowAndNoInitializingShards(String... indices) {     return ensureColor(ClusterHealthStatus.YELLOW, TimeValue.timeValueSeconds(30), true, indices). }
false;private;4;33;;private ClusterHealthStatus ensureColor(ClusterHealthStatus clusterHealthStatus, TimeValue timeout, boolean waitForNoInitializingShards, String... indices) {     String color = clusterHealthStatus.name().toLowerCase(Locale.ROOT).     String method = "ensure" + Strings.capitalize(color).     ClusterHealthRequest healthRequest = Requests.clusterHealthRequest(indices).timeout(timeout).waitForStatus(clusterHealthStatus).waitForEvents(Priority.LANGUID).waitForNoRelocatingShards(true).waitForNoInitializingShards(waitForNoInitializingShards).waitForNodes(Integer.toString(cluster().size())).     ClusterHealthResponse actionGet = client().admin().cluster().health(healthRequest).actionGet().     if (actionGet.isTimedOut()) {         logger.info("{} timed out, cluster state:\n{}\n{}", method, client().admin().cluster().prepareState().get().getState(), client().admin().cluster().preparePendingClusterTasks().get()).         fail("timed out waiting for " + color + " state").     }     assertThat("Expected at least " + clusterHealthStatus + " but got " + actionGet.getStatus(), actionGet.getStatus().value(), lessThanOrEqualTo(clusterHealthStatus.value())).     logger.debug("indices {} are {}", indices.length == 0 ? "[_all]" : indices, color).     return actionGet.getStatus(). }
true;public;0;3;/**  * Waits for all relocating shards to become active using the cluster health API.  */ ;/**  * Waits for all relocating shards to become active using the cluster health API.  */ public ClusterHealthStatus waitForRelocation() {     return waitForRelocation(null). }
true;public;1;17;/**  * Waits for all relocating shards to become active and the cluster has reached the given health status  * using the cluster health API.  */ ;/**  * Waits for all relocating shards to become active and the cluster has reached the given health status  * using the cluster health API.  */ public ClusterHealthStatus waitForRelocation(ClusterHealthStatus status) {     ClusterHealthRequest request = Requests.clusterHealthRequest().waitForNoRelocatingShards(true).     if (status != null) {         request.waitForStatus(status).     }     ClusterHealthResponse actionGet = client().admin().cluster().health(request).actionGet().     if (actionGet.isTimedOut()) {         logger.info("waitForRelocation timed out (status={}), cluster state:\n{}\n{}", status, client().admin().cluster().prepareState().get().getState(), client().admin().cluster().preparePendingClusterTasks().get()).         assertThat("timed out waiting for relocation", actionGet.isTimedOut(), equalTo(false)).     }     if (status != null) {         assertThat(actionGet.getStatus(), equalTo(status)).     }     return actionGet.getStatus(). }
true;public;1;3;/**  * Waits until at least a give number of document is visible for searchers  *  * @param numDocs number of documents to wait for.  * @return the actual number of docs seen.  */ ;/**  * Waits until at least a give number of document is visible for searchers  *  * @param numDocs number of documents to wait for.  * @return the actual number of docs seen.  */ public long waitForDocs(final long numDocs) throws InterruptedException {     return waitForDocs(numDocs, null). }
true;public;2;4;/**  * Waits until at least a give number of document is visible for searchers  *  * @param numDocs number of documents to wait for  * @param indexer a {@link org.elasticsearch.test.BackgroundIndexer}. If supplied it will be first checked for documents indexed.  *                This saves on unneeded searches.  * @return the actual number of docs seen.  */ ;/**  * Waits until at least a give number of document is visible for searchers  *  * @param numDocs number of documents to wait for  * @param indexer a {@link org.elasticsearch.test.BackgroundIndexer}. If supplied it will be first checked for documents indexed.  *                This saves on unneeded searches.  * @return the actual number of docs seen.  */ public long waitForDocs(final long numDocs, @Nullable final BackgroundIndexer indexer) throws InterruptedException {     // indexing threads can wait for up to ~1m before retrying when they first try to index into a shard which is not STARTED.     return waitForDocs(numDocs, 90, TimeUnit.SECONDS, indexer). }
true;public;4;43;/**  * Waits until at least a give number of document is visible for searchers  *  * @param numDocs         number of documents to wait for  * @param maxWaitTime     if not progress have been made during this time, fail the test  * @param maxWaitTimeUnit the unit in which maxWaitTime is specified  * @param indexer         If supplied it will be first checked for documents indexed.  *                        This saves on unneeded searches.  * @return the actual number of docs seen.  */ ;/**  * Waits until at least a give number of document is visible for searchers  *  * @param numDocs         number of documents to wait for  * @param maxWaitTime     if not progress have been made during this time, fail the test  * @param maxWaitTimeUnit the unit in which maxWaitTime is specified  * @param indexer         If supplied it will be first checked for documents indexed.  *                        This saves on unneeded searches.  * @return the actual number of docs seen.  */ public long waitForDocs(final long numDocs, int maxWaitTime, TimeUnit maxWaitTimeUnit, @Nullable final BackgroundIndexer indexer) throws InterruptedException {     final AtomicLong lastKnownCount = new AtomicLong(-1).     long lastStartCount = -1.     BooleanSupplier testDocs = () -> {         if (indexer != null) {             lastKnownCount.set(indexer.totalIndexedDocs()).         }         if (lastKnownCount.get() >= numDocs) {             try {                 long count = client().prepareSearch().setTrackTotalHits(true).setSize(0).setQuery(matchAllQuery()).get().getHits().getTotalHits().value.                 if (count == lastKnownCount.get()) {                     // no progress - try to refresh for the next time                     client().admin().indices().prepareRefresh().get().                 }                 lastKnownCount.set(count).             } catch (Exception e) {                 // count now acts like search and barfs if all shards failed...                 logger.debug("failed to executed count", e).                 return false.             }             logger.debug("[{}] docs visible for search. waiting for [{}]", lastKnownCount.get(), numDocs).         } else {             logger.debug("[{}] docs indexed. waiting for [{}]", lastKnownCount.get(), numDocs).         }         return lastKnownCount.get() >= numDocs.     }.     while (!awaitBusy(testDocs, maxWaitTime, maxWaitTimeUnit)) {         if (lastStartCount == lastKnownCount.get()) {             // we didn't make any progress             fail("failed to reach " + numDocs + "docs").         }         lastStartCount = lastKnownCount.get().     }     return lastKnownCount.get(). }
true;public;0;4;/**  * Prints the current cluster state as debug logging.  */ ;/**  * Prints the current cluster state as debug logging.  */ public void logClusterState() {     logger.debug("cluster state:\n{}\n{}", client().admin().cluster().prepareState().get().getState(), client().admin().cluster().preparePendingClusterTasks().get()). }
true;public;1;5;/**  * Prints the segments info for the given indices as debug logging.  */ ;/**  * Prints the segments info for the given indices as debug logging.  */ public void logSegmentsState(String... indices) throws Exception {     IndicesSegmentResponse segsRsp = client().admin().indices().prepareSegments(indices).get().     logger.debug("segments {} state: \n{}", indices.length == 0 ? "[_all]" : indices, Strings.toString(segsRsp.toXContent(JsonXContent.contentBuilder().prettyPrint(), ToXContent.EMPTY_PARAMS))). }
true;public;0;3;/**  * Prints current memory stats as info logging.  */ ;/**  * Prints current memory stats as info logging.  */ public void logMemoryStats() {     logger.info("memory: {}", Strings.toString(client().admin().cluster().prepareNodesStats().clear().setJvm(true).get(), true, true)). }
false;protected;0;6;;protected void ensureClusterSizeConsistency() {     if (cluster() != null && cluster().size() > 0) {         // if static init fails the cluster can be null         logger.trace("Check consistency for [{}] nodes", cluster().size()).         assertNoTimeout(client().admin().cluster().prepareHealth().setWaitForNodes(Integer.toString(cluster().size())).get()).     } }
true;protected;0;58;/**  * Verifies that all nodes that have the same version of the cluster state as master have same cluster state  */ ;/**  * Verifies that all nodes that have the same version of the cluster state as master have same cluster state  */ protected void ensureClusterStateConsistency() throws IOException {     if (cluster() != null && cluster().size() > 0) {         final NamedWriteableRegistry namedWriteableRegistry = cluster().getNamedWriteableRegistry().         final Client masterClient = client().         ClusterState masterClusterState = masterClient.admin().cluster().prepareState().all().get().getState().         byte[] masterClusterStateBytes = ClusterState.Builder.toBytes(masterClusterState).         // remove local node reference         masterClusterState = ClusterState.Builder.fromBytes(masterClusterStateBytes, null, namedWriteableRegistry).         Map<String, Object> masterStateMap = convertToMap(masterClusterState).         int masterClusterStateSize = ClusterState.Builder.toBytes(masterClusterState).length.         String masterId = masterClusterState.nodes().getMasterNodeId().         for (Client client : cluster().getClients()) {             ClusterState localClusterState = client.admin().cluster().prepareState().all().setLocal(true).get().getState().             byte[] localClusterStateBytes = ClusterState.Builder.toBytes(localClusterState).             // remove local node reference             localClusterState = ClusterState.Builder.fromBytes(localClusterStateBytes, null, namedWriteableRegistry).             final Map<String, Object> localStateMap = convertToMap(localClusterState).             final int localClusterStateSize = ClusterState.Builder.toBytes(localClusterState).length.             // that the master node matches the master (otherwise there is no requirement for the cluster state to match)             if (masterClusterState.version() == localClusterState.version() && masterId.equals(localClusterState.nodes().getMasterNodeId())) {                 try {                     assertEquals("cluster state UUID does not match", masterClusterState.stateUUID(), localClusterState.stateUUID()).                     /*                          * The cluster state received by the transport client can miss customs that the client does not understand. This                          * means that we only expect equality in the cluster state including customs if the master client and the local                          * client are of the same type (both or neither are transport clients). Otherwise, we can only assert equality                          * modulo non-core customs.                          */                     if (isTransportClient(masterClient) == isTransportClient(client)) {                         // We cannot compare serialization bytes since serialization order of maps is not guaranteed                         // but we can compare serialization sizes - they should be the same                         assertEquals("cluster state size does not match", masterClusterStateSize, localClusterStateSize).                         // Compare JSON serialization                         assertNull("cluster state JSON serialization does not match", differenceBetweenMapsIgnoringArrayOrder(masterStateMap, localStateMap)).                     } else {                         // remove non-core customs and compare the cluster states                         assertNull("cluster state JSON serialization does not match (after removing some customs)", differenceBetweenMapsIgnoringArrayOrder(convertToMap(removePluginCustoms(masterClusterState)), convertToMap(removePluginCustoms(localClusterState)))).                     }                 } catch (final AssertionError error) {                     logger.error("Cluster state from master:\n{}\nLocal cluster state:\n{}", masterClusterState.toString(), localClusterState.toString()).                     throw error.                 }             }         }     } }
true;private;1;8;/**  * Tests if the client is a transport client or wraps a transport client.  *  * @param client the client to test  * @return true if the client is a transport client or a wrapped transport client  */ ;/**  * Tests if the client is a transport client or wraps a transport client.  *  * @param client the client to test  * @return true if the client is a transport client or a wrapped transport client  */ private boolean isTransportClient(final Client client) {     if (TransportClient.class.isAssignableFrom(client.getClass())) {         return true.     } else if (client instanceof RandomizingClient) {         return isTransportClient(((RandomizingClient) client).in()).     }     return false. }
true;private;1;16;/**  * Remove any customs except for customs that we know all clients understand.  *  * @param clusterState the cluster state to remove possibly-unknown customs from  * @return the cluster state with possibly-unknown customs removed  */ ;/**  * Remove any customs except for customs that we know all clients understand.  *  * @param clusterState the cluster state to remove possibly-unknown customs from  * @return the cluster state with possibly-unknown customs removed  */ private ClusterState removePluginCustoms(final ClusterState clusterState) {     final ClusterState.Builder builder = ClusterState.builder(clusterState).     clusterState.customs().keysIt().forEachRemaining(key -> {         if (SAFE_CUSTOMS.contains(key) == false) {             builder.removeCustom(key).         }     }).     final MetaData.Builder mdBuilder = MetaData.builder(clusterState.metaData()).     clusterState.metaData().customs().keysIt().forEachRemaining(key -> {         if (SAFE_METADATA_CUSTOMS.contains(key) == false) {             mdBuilder.removeCustom(key).         }     }).     builder.metaData(mdBuilder).     return builder.build(). }
true;protected;1;4;/**  * Ensures the cluster is in a searchable state for the given indices. This means a searchable copy of each  * shard is available on the cluster.  */ ;/**  * Ensures the cluster is in a searchable state for the given indices. This means a searchable copy of each  * shard is available on the cluster.  */ protected ClusterHealthStatus ensureSearchable(String... indices) {     // this is just a temporary thing but it's easier to change if it is encapsulated.     return ensureGreen(indices). }
false;protected;1;3;;protected void ensureStableCluster(int nodeCount) {     ensureStableCluster(nodeCount, TimeValue.timeValueSeconds(30)). }
false;protected;2;3;;protected void ensureStableCluster(int nodeCount, TimeValue timeValue) {     ensureStableCluster(nodeCount, timeValue, false, null). }
false;protected;2;3;;protected void ensureStableCluster(int nodeCount, @Nullable String viaNode) {     ensureStableCluster(nodeCount, TimeValue.timeValueSeconds(30), false, viaNode). }
false;protected;4;20;;protected void ensureStableCluster(int nodeCount, TimeValue timeValue, boolean local, @Nullable String viaNode) {     if (viaNode == null) {         viaNode = randomFrom(internalCluster().getNodeNames()).     }     logger.debug("ensuring cluster is stable with [{}] nodes. access node: [{}]. timeout: [{}]", nodeCount, viaNode, timeValue).     ClusterHealthResponse clusterHealthResponse = client(viaNode).admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForNodes(Integer.toString(nodeCount)).setTimeout(timeValue).setLocal(local).setWaitForNoRelocatingShards(true).get().     if (clusterHealthResponse.isTimedOut()) {         ClusterStateResponse stateResponse = client(viaNode).admin().cluster().prepareState().get().         fail("failed to reach a stable cluster of [" + nodeCount + "] nodes. Tried via [" + viaNode + "]. last cluster state:\n" + stateResponse.getState()).     }     assertThat(clusterHealthResponse.isTimedOut(), is(false)).     ensureFullyConnectedCluster(). }
true;protected;0;3;/**  * Ensures that all nodes in the cluster are connected to each other.  *  * Some network disruptions may leave nodes that are not the master disconnected from each other.  * {@link org.elasticsearch.cluster.NodeConnectionsService} will eventually reconnect but it's  * handy to be able to ensure this happens faster  */ ;/**  * Ensures that all nodes in the cluster are connected to each other.  *  * Some network disruptions may leave nodes that are not the master disconnected from each other.  * {@link org.elasticsearch.cluster.NodeConnectionsService} will eventually reconnect but it's  * handy to be able to ensure this happens faster  */ protected void ensureFullyConnectedCluster() {     NetworkDisruption.ensureFullyConnectedCluster(internalCluster()). }
true;protected,final;3;3;/**  * Syntactic sugar for:  * <pre>  *   client().prepareIndex(index, type).setSource(source).execute().actionGet().  * </pre>  */ ;/**  * Syntactic sugar for:  * <pre>  *   client().prepareIndex(index, type).setSource(source).execute().actionGet().  * </pre>  */ protected final IndexResponse index(String index, String type, XContentBuilder source) {     return client().prepareIndex(index, type).setSource(source).execute().actionGet(). }
true;protected,final;4;3;/**  * Syntactic sugar for:  * <pre>  *   client().prepareIndex(index, type).setSource(source).execute().actionGet().  * </pre>  */ ;/**  * Syntactic sugar for:  * <pre>  *   client().prepareIndex(index, type).setSource(source).execute().actionGet().  * </pre>  */ protected final IndexResponse index(String index, String type, String id, Map<String, Object> source) {     return client().prepareIndex(index, type, id).setSource(source).execute().actionGet(). }
true;protected,final;4;3;/**  * Syntactic sugar for:  * <pre>  *   return client().prepareIndex(index, type, id).setSource(source).execute().actionGet().  * </pre>  */ ;/**  * Syntactic sugar for:  * <pre>  *   return client().prepareIndex(index, type, id).setSource(source).execute().actionGet().  * </pre>  */ protected final IndexResponse index(String index, String type, String id, XContentBuilder source) {     return client().prepareIndex(index, type, id).setSource(source).execute().actionGet(). }
true;protected,final;4;3;/**  * Syntactic sugar for:  * <pre>  *   return client().prepareIndex(index, type, id).setSource(source).execute().actionGet().  * </pre>  */ ;/**  * Syntactic sugar for:  * <pre>  *   return client().prepareIndex(index, type, id).setSource(source).execute().actionGet().  * </pre>  */ protected final IndexResponse index(String index, String type, String id, Object... source) {     return client().prepareIndex(index, type, id).setSource(source).execute().actionGet(). }
true;protected,final;4;3;/**  * Syntactic sugar for:  * <pre>  *   return client().prepareIndex(index, type, id).setSource(source).execute().actionGet().  * </pre>  * <p>  * where source is a JSON String.  */ ;/**  * Syntactic sugar for:  * <pre>  *   return client().prepareIndex(index, type, id).setSource(source).execute().actionGet().  * </pre>  * <p>  * where source is a JSON String.  */ protected final IndexResponse index(String index, String type, String id, String source) {     return client().prepareIndex(index, type, id).setSource(source, XContentType.JSON).execute().actionGet(). }
true;protected,final;1;7;/**  * Waits for relocations and refreshes all indices in the cluster.  *  * @see #waitForRelocation()  */ ;/**  * Waits for relocations and refreshes all indices in the cluster.  *  * @see #waitForRelocation()  */ protected final RefreshResponse refresh(String... indices) {     waitForRelocation().     // TODO RANDOMIZE with flush?     RefreshResponse actionGet = client().admin().indices().prepareRefresh(indices).execute().actionGet().     assertNoFailures(actionGet).     return actionGet. }
true;protected,final;1;4;/**  * Flushes and refreshes all indices in the cluster  */ ;/**  * Flushes and refreshes all indices in the cluster  */ protected final void flushAndRefresh(String... indices) {     flush(indices).     refresh(indices). }
true;protected,final;1;8;/**  * Flush some or all indices in the cluster.  */ ;/**  * Flush some or all indices in the cluster.  */ protected final FlushResponse flush(String... indices) {     waitForRelocation().     FlushResponse actionGet = client().admin().indices().prepareFlush(indices).execute().actionGet().     for (DefaultShardOperationFailedException failure : actionGet.getShardFailures()) {         assertThat("unexpected flush failure " + failure.reason(), failure.status(), equalTo(RestStatus.SERVICE_UNAVAILABLE)).     }     return actionGet. }
true;protected;0;6;/**  * Waits for all relocations and force merge all indices in the cluster to 1 segment.  */ ;/**  * Waits for all relocations and force merge all indices in the cluster to 1 segment.  */ protected ForceMergeResponse forceMerge() {     waitForRelocation().     ForceMergeResponse actionGet = client().admin().indices().prepareForceMerge().setMaxNumSegments(1).execute().actionGet().     assertNoFailures(actionGet).     return actionGet. }
true;protected;1;4;/**  * Returns <code>true</code> iff the given index exists otherwise <code>false</code>  */ ;/**  * Returns <code>true</code> iff the given index exists otherwise <code>false</code>  */ protected boolean indexExists(String index) {     IndicesExistsResponse actionGet = client().admin().indices().prepareExists(index).execute().actionGet().     return actionGet.isExists(). }
true;protected,final;1;5;/**  * Syntactic sugar for enabling allocation for <code>indices</code>  */ ;/**  * Syntactic sugar for enabling allocation for <code>indices</code>  */ protected final void enableAllocation(String... indices) {     client().admin().indices().prepareUpdateSettings(indices).setSettings(Settings.builder().put(EnableAllocationDecider.INDEX_ROUTING_ALLOCATION_ENABLE_SETTING.getKey(), "all")).get(). }
true;protected,final;1;5;/**  * Syntactic sugar for disabling allocation for <code>indices</code>  */ ;/**  * Syntactic sugar for disabling allocation for <code>indices</code>  */ protected final void disableAllocation(String... indices) {     client().admin().indices().prepareUpdateSettings(indices).setSettings(Settings.builder().put(EnableAllocationDecider.INDEX_ROUTING_ALLOCATION_ENABLE_SETTING.getKey(), "none")).get(). }
true;protected;0;3;/**  * Returns a random admin client. This client can either be a node or a transport client pointing to any of  * the nodes in the cluster.  */ ;/**  * Returns a random admin client. This client can either be a node or a transport client pointing to any of  * the nodes in the cluster.  */ protected AdminClient admin() {     return client().admin(). }
true;public;2;3;/**  * Convenience method that forwards to {@link #indexRandom(boolean, List)}.  */ ;/**  * Convenience method that forwards to {@link #indexRandom(boolean, List)}.  */ public void indexRandom(boolean forceRefresh, IndexRequestBuilder... builders) throws InterruptedException {     indexRandom(forceRefresh, Arrays.asList(builders)). }
false;public;3;4;;public void indexRandom(boolean forceRefresh, boolean dummyDocuments, IndexRequestBuilder... builders) throws InterruptedException {     indexRandom(forceRefresh, dummyDocuments, Arrays.asList(builders)). }
true;public;2;3;/**  * Indexes the given {@link IndexRequestBuilder} instances randomly. It shuffles the given builders and either  * indexes them in a blocking or async fashion. This is very useful to catch problems that relate to internal document  * ids or index segment creations. Some features might have bug when a given document is the first or the last in a  * segment or if only one document is in a segment etc. This method prevents issues like this by randomizing the index  * layout.  *  * @param forceRefresh if {@code true} all involved indices are refreshed  *   once the documents are indexed. Additionally if {@code true} some  *   empty dummy documents are may be randomly inserted into the document  *   list and deleted once all documents are indexed. This is useful to  *   produce deleted documents on the server side.  * @param builders     the documents to index.  * @see #indexRandom(boolean, boolean, java.util.List)  */ ;/**  * Indexes the given {@link IndexRequestBuilder} instances randomly. It shuffles the given builders and either  * indexes them in a blocking or async fashion. This is very useful to catch problems that relate to internal document  * ids or index segment creations. Some features might have bug when a given document is the first or the last in a  * segment or if only one document is in a segment etc. This method prevents issues like this by randomizing the index  * layout.  *  * @param forceRefresh if {@code true} all involved indices are refreshed  *   once the documents are indexed. Additionally if {@code true} some  *   empty dummy documents are may be randomly inserted into the document  *   list and deleted once all documents are indexed. This is useful to  *   produce deleted documents on the server side.  * @param builders     the documents to index.  * @see #indexRandom(boolean, boolean, java.util.List)  */ public void indexRandom(boolean forceRefresh, List<IndexRequestBuilder> builders) throws InterruptedException {     indexRandom(forceRefresh, forceRefresh, builders). }
true;public;3;4;/**  * Indexes the given {@link IndexRequestBuilder} instances randomly. It shuffles the given builders and either  * indexes them in a blocking or async fashion. This is very useful to catch problems that relate to internal document  * ids or index segment creations. Some features might have bug when a given document is the first or the last in a  * segment or if only one document is in a segment etc. This method prevents issues like this by randomizing the index  * layout.  *  * @param forceRefresh   if {@code true} all involved indices are refreshed once the documents are indexed.  * @param dummyDocuments if {@code true} some empty dummy documents may be randomly inserted into the document list and deleted once  *                       all documents are indexed. This is useful to produce deleted documents on the server side.  * @param builders       the documents to index.  */ ;/**  * Indexes the given {@link IndexRequestBuilder} instances randomly. It shuffles the given builders and either  * indexes them in a blocking or async fashion. This is very useful to catch problems that relate to internal document  * ids or index segment creations. Some features might have bug when a given document is the first or the last in a  * segment or if only one document is in a segment etc. This method prevents issues like this by randomizing the index  * layout.  *  * @param forceRefresh   if {@code true} all involved indices are refreshed once the documents are indexed.  * @param dummyDocuments if {@code true} some empty dummy documents may be randomly inserted into the document list and deleted once  *                       all documents are indexed. This is useful to produce deleted documents on the server side.  * @param builders       the documents to index.  */ public void indexRandom(boolean forceRefresh, boolean dummyDocuments, List<IndexRequestBuilder> builders) throws InterruptedException {     indexRandom(forceRefresh, dummyDocuments, true, builders). }
true;public;4;85;/**  * Indexes the given {@link IndexRequestBuilder} instances randomly. It shuffles the given builders and either  * indexes them in a blocking or async fashion. This is very useful to catch problems that relate to internal document  * ids or index segment creations. Some features might have bug when a given document is the first or the last in a  * segment or if only one document is in a segment etc. This method prevents issues like this by randomizing the index  * layout.  *  * @param forceRefresh   if {@code true} all involved indices are refreshed once the documents are indexed.  * @param dummyDocuments if {@code true} some empty dummy documents may be randomly inserted into the document list and deleted once  *                       all documents are indexed. This is useful to produce deleted documents on the server side.  * @param maybeFlush     if {@code true} this method may randomly execute full flushes after index operations.  * @param builders       the documents to index.  */ ;/**  * Indexes the given {@link IndexRequestBuilder} instances randomly. It shuffles the given builders and either  * indexes them in a blocking or async fashion. This is very useful to catch problems that relate to internal document  * ids or index segment creations. Some features might have bug when a given document is the first or the last in a  * segment or if only one document is in a segment etc. This method prevents issues like this by randomizing the index  * layout.  *  * @param forceRefresh   if {@code true} all involved indices are refreshed once the documents are indexed.  * @param dummyDocuments if {@code true} some empty dummy documents may be randomly inserted into the document list and deleted once  *                       all documents are indexed. This is useful to produce deleted documents on the server side.  * @param maybeFlush     if {@code true} this method may randomly execute full flushes after index operations.  * @param builders       the documents to index.  */ public void indexRandom(boolean forceRefresh, boolean dummyDocuments, boolean maybeFlush, List<IndexRequestBuilder> builders) throws InterruptedException {     Random random = random().     Map<String, Set<String>> indicesAndTypes = new HashMap<>().     for (IndexRequestBuilder builder : builders) {         final Set<String> types = indicesAndTypes.computeIfAbsent(builder.request().index(), index -> new HashSet<>()).         types.add(builder.request().type()).     }     // (index, type, id)     Set<List<String>> bogusIds = new HashSet<>().     if (random.nextBoolean() && !builders.isEmpty() && dummyDocuments) {         builders = new ArrayList<>(builders).         // inject some bogus docs         final int numBogusDocs = scaledRandomIntBetween(1, builders.size() * 2).         final int unicodeLen = between(1, 10).         for (int i = 0. i < numBogusDocs. i++) {             String id = "bogus_doc_" + randomRealisticUnicodeOfLength(unicodeLen) + Integer.toString(dummmyDocIdGenerator.incrementAndGet()).             Map.Entry<String, Set<String>> indexAndTypes = RandomPicks.randomFrom(random, indicesAndTypes.entrySet()).             String index = indexAndTypes.getKey().             String type = RandomPicks.randomFrom(random, indexAndTypes.getValue()).             bogusIds.add(Arrays.asList(index, type, id)).             // We configure a routing key in case the mapping requires it             builders.add(client().prepareIndex(index, type, id).setSource("{}", XContentType.JSON).setRouting(id)).         }     }     Collections.shuffle(builders, random()).     final CopyOnWriteArrayList<Tuple<IndexRequestBuilder, Exception>> errors = new CopyOnWriteArrayList<>().     List<CountDownLatch> inFlightAsyncOperations = new ArrayList<>().     // If you are indexing just a few documents then frequently do it one at a time.  If many then frequently in bulk.     final String[] indices = indicesAndTypes.keySet().toArray(new String[0]).     if (builders.size() < FREQUENT_BULK_THRESHOLD ? frequently() : builders.size() < ALWAYS_BULK_THRESHOLD ? rarely() : false) {         if (frequently()) {             logger.info("Index [{}] docs async: [{}] bulk: [{}]", builders.size(), true, false).             for (IndexRequestBuilder indexRequestBuilder : builders) {                 indexRequestBuilder.execute(new PayloadLatchedActionListener<>(indexRequestBuilder, newLatch(inFlightAsyncOperations), errors)).                 postIndexAsyncActions(indices, inFlightAsyncOperations, maybeFlush).             }         } else {             logger.info("Index [{}] docs async: [{}] bulk: [{}]", builders.size(), false, false).             for (IndexRequestBuilder indexRequestBuilder : builders) {                 indexRequestBuilder.execute().actionGet().                 postIndexAsyncActions(indices, inFlightAsyncOperations, maybeFlush).             }         }     } else {         List<List<IndexRequestBuilder>> partition = eagerPartition(builders, Math.min(MAX_BULK_INDEX_REQUEST_SIZE, Math.max(1, (int) (builders.size() * randomDouble())))).         logger.info("Index [{}] docs async: [{}] bulk: [{}] partitions [{}]", builders.size(), false, true, partition.size()).         for (List<IndexRequestBuilder> segmented : partition) {             BulkRequestBuilder bulkBuilder = client().prepareBulk().             for (IndexRequestBuilder indexRequestBuilder : segmented) {                 bulkBuilder.add(indexRequestBuilder).             }             BulkResponse actionGet = bulkBuilder.execute().actionGet().             assertThat(actionGet.hasFailures() ? actionGet.buildFailureMessage() : "", actionGet.hasFailures(), equalTo(false)).         }     }     for (CountDownLatch operation : inFlightAsyncOperations) {         operation.await().     }     final List<Exception> actualErrors = new ArrayList<>().     for (Tuple<IndexRequestBuilder, Exception> tuple : errors) {         if (ExceptionsHelper.unwrapCause(tuple.v2()) instanceof EsRejectedExecutionException) {             // re-index if rejected             tuple.v1().execute().actionGet().         } else {             actualErrors.add(tuple.v2()).         }     }     assertThat(actualErrors, emptyIterable()).     if (!bogusIds.isEmpty()) {         // delete the bogus types again - it might trigger merges or at least holes in the segments and enforces deleted docs!         for (List<String> doc : bogusIds) {             assertEquals("failed to delete a dummy doc [" + doc.get(0) + "][" + doc.get(2) + "]", DocWriteResponse.Result.DELETED, client().prepareDelete(doc.get(0), doc.get(1), doc.get(2)).setRouting(doc.get(2)).get().getResult()).         }     }     if (forceRefresh) {         assertNoFailures(client().admin().indices().prepareRefresh(indices).setIndicesOptions(IndicesOptions.lenientExpandOpen()).get()).     } }
true;public,static;2;4;/**  * Disables an index block for the specified index  */ ;/**  * Disables an index block for the specified index  */ public static void disableIndexBlock(String index, String block) {     Settings settings = Settings.builder().put(block, false).build().     client().admin().indices().prepareUpdateSettings(index).setSettings(settings).get(). }
true;public,static;2;4;/**  * Enables an index block for the specified index  */ ;/**  * Enables an index block for the specified index  */ public static void enableIndexBlock(String index, String block) {     Settings settings = Settings.builder().put(block, true).build().     client().admin().indices().prepareUpdateSettings(index).setSettings(settings).get(). }
true;public,static;1;5;/**  * Sets or unsets the cluster read_only mode *  */ ;/**  * Sets or unsets the cluster read_only mode *  */ public static void setClusterReadOnly(boolean value) {     Settings settings = value ? Settings.builder().put(MetaData.SETTING_READ_ONLY_SETTING.getKey(), value).build() : Settings.builder().putNull(MetaData.SETTING_READ_ONLY_SETTING.getKey()).build().     assertAcked(client().admin().cluster().prepareUpdateSettings().setTransientSettings(settings).get()). }
false;private,static;1;5;;private static CountDownLatch newLatch(List<CountDownLatch> latches) {     CountDownLatch l = new CountDownLatch(1).     latches.add(l).     return l. }
true;private;3;27;/**  * Maybe refresh, force merge, or flush then always make sure there aren't too many in flight async operations.  */ ;/**  * Maybe refresh, force merge, or flush then always make sure there aren't too many in flight async operations.  */ private void postIndexAsyncActions(String[] indices, List<CountDownLatch> inFlightAsyncOperations, boolean maybeFlush) throws InterruptedException {     if (rarely()) {         if (rarely()) {             client().admin().indices().prepareRefresh(indices).setIndicesOptions(IndicesOptions.lenientExpandOpen()).execute(new LatchedActionListener<>(newLatch(inFlightAsyncOperations))).         } else if (maybeFlush && rarely()) {             if (randomBoolean()) {                 client().admin().indices().prepareFlush(indices).setIndicesOptions(IndicesOptions.lenientExpandOpen()).execute(new LatchedActionListener<>(newLatch(inFlightAsyncOperations))).             } else {                 client().admin().indices().syncedFlush(syncedFlushRequest(indices).indicesOptions(IndicesOptions.lenientExpandOpen()), new LatchedActionListener<>(newLatch(inFlightAsyncOperations))).             }         } else if (rarely()) {             client().admin().indices().prepareForceMerge(indices).setIndicesOptions(IndicesOptions.lenientExpandOpen()).setMaxNumSegments(between(1, 10)).setFlush(maybeFlush && randomBoolean()).execute(new LatchedActionListener<>(newLatch(inFlightAsyncOperations))).         }     }     while (inFlightAsyncOperations.size() > MAX_IN_FLIGHT_ASYNC_INDEXES) {         int waitFor = between(0, inFlightAsyncOperations.size() - 1).         inFlightAsyncOperations.remove(waitFor).await().     } }
false;public,final;1;4;;@Override public final void onResponse(Response response) {     latch.countDown(). }
false;public,final;1;9;;@Override public final void onFailure(Exception t) {     try {         logger.info("Action Failed", t).         addError(t).     } finally {         latch.countDown().     } }
false;protected;1;2;;protected void addError(Exception e) { }
false;protected;1;4;;@Override protected void addError(Exception e) {     errors.add(new Tuple<>(builder, e)). }
true;public;1;5;/**  * Clears the given scroll Ids  */ ;/**  * Clears the given scroll Ids  */ public void clearScroll(String... scrollIds) {     ClearScrollResponse clearResponse = client().prepareClearScroll().setScrollIds(Arrays.asList(scrollIds)).get().     assertThat(clearResponse.isSucceeded(), equalTo(true)). }
false;private,static;2;10;;private static <A extends Annotation> A getAnnotation(Class<?> clazz, Class<A> annotationClass) {     if (clazz == Object.class || clazz == ESIntegTestCase.class) {         return null.     }     A annotation = clazz.getAnnotation(annotationClass).     if (annotation != null) {         return annotation.     }     return getAnnotation(clazz.getSuperclass(), annotationClass). }
false;private;0;3;;private Scope getCurrentClusterScope() {     return getCurrentClusterScope(this.getClass()). }
false;private,static;1;5;;private static Scope getCurrentClusterScope(Class<?> clazz) {     ClusterScope annotation = getAnnotation(clazz, ClusterScope.class).     // if we are not annotated assume suite!     return annotation == null ? Scope.SUITE : annotation.scope(). }
false;private;0;4;;private boolean getSupportsDedicatedMasters() {     ClusterScope annotation = getAnnotation(this.getClass(), ClusterScope.class).     return annotation == null ? true : annotation.supportsDedicatedMasters(). }
false;private;0;4;;private boolean getAutoMinMasterNodes() {     ClusterScope annotation = getAnnotation(this.getClass(), ClusterScope.class).     return annotation == null ? true : annotation.autoMinMasterNodes(). }
false;private;0;4;;private int getNumDataNodes() {     ClusterScope annotation = getAnnotation(this.getClass(), ClusterScope.class).     return annotation == null ? -1 : annotation.numDataNodes(). }
false;private;0;5;;private int getMinNumDataNodes() {     ClusterScope annotation = getAnnotation(this.getClass(), ClusterScope.class).     return annotation == null || annotation.minNumDataNodes() == -1 ? InternalTestCluster.DEFAULT_MIN_NUM_DATA_NODES : annotation.minNumDataNodes(). }
false;private;0;5;;private int getMaxNumDataNodes() {     ClusterScope annotation = getAnnotation(this.getClass(), ClusterScope.class).     return annotation == null || annotation.maxNumDataNodes() == -1 ? InternalTestCluster.DEFAULT_MAX_NUM_DATA_NODES : annotation.maxNumDataNodes(). }
false;private;0;4;;private int getNumClientNodes() {     ClusterScope annotation = getAnnotation(this.getClass(), ClusterScope.class).     return annotation == null ? InternalTestCluster.DEFAULT_NUM_CLIENT_NODES : annotation.numClientNodes(). }
true;protected;1;27;/**  * This method is used to obtain settings for the {@code N}th node in the cluster.  * Nodes in this cluster are associated with an ordinal number such that nodes can  * be started with specific configurations. This method might be called multiple  * times with the same ordinal and is expected to return the same value for each invocation.  * In other words subclasses must ensure this method is idempotent.  */ ;/**  * This method is used to obtain settings for the {@code N}th node in the cluster.  * Nodes in this cluster are associated with an ordinal number such that nodes can  * be started with specific configurations. This method might be called multiple  * times with the same ordinal and is expected to return the same value for each invocation.  * In other words subclasses must ensure this method is idempotent.  */ protected Settings nodeSettings(int nodeOrdinal) {     Settings.Builder builder = Settings.builder().put(NodeEnvironment.MAX_LOCAL_STORAGE_NODES_SETTING.getKey(), Integer.MAX_VALUE).put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_LOW_DISK_WATERMARK_SETTING.getKey(), "1b").put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_HIGH_DISK_WATERMARK_SETTING.getKey(), "1b").put(DiskThresholdSettings.CLUSTER_ROUTING_ALLOCATION_DISK_FLOOD_STAGE_WATERMARK_SETTING.getKey(), "1b").put(ScriptService.SCRIPT_MAX_COMPILATIONS_RATE.getKey(), "2048/1m").put(IndicesQueryCache.INDICES_QUERIES_CACHE_ALL_SEGMENTS_SETTING.getKey(), nodeOrdinal % 2 == 0).put(IndicesStore.INDICES_STORE_DELETE_SHARD_TIMEOUT.getKey(), new TimeValue(1, TimeUnit.SECONDS)).put(SearchService.LOW_LEVEL_CANCELLATION_SETTING.getKey(), randomBoolean()).putList(// empty list disables a port scan for other nodes     DISCOVERY_SEED_HOSTS_SETTING.getKey()).putList(DISCOVERY_SEED_PROVIDERS_SETTING.getKey(), "file").     if (rarely()) {         // Sometimes adjust the minimum search thread pool size, causing         // QueueResizingEsThreadPoolExecutor to be used instead of a regular         // fixed thread pool         builder.put("thread_pool.search.min_queue_size", 100).     }     return builder.build(). }
false;protected;1;3;;protected Path nodeConfigPath(int nodeOrdinal) {     return null. }
true;protected;0;3;/**  * Returns a collection of plugins that should be loaded on each node.  */ ;/**  * Returns a collection of plugins that should be loaded on each node.  */ protected Collection<Class<? extends Plugin>> nodePlugins() {     return Collections.emptyList(). }
true;protected;0;3;/**  * Returns a collection of plugins that should be loaded when creating a transport client.  */ ;/**  * Returns a collection of plugins that should be loaded when creating a transport client.  */ protected Collection<Class<? extends Plugin>> transportClientPlugins() {     return Collections.emptyList(). }
true;protected;0;3;/**  * This method is used to obtain additional settings for clients created by the internal cluster.  * These settings will be applied on the client in addition to some randomized settings defined in  * the cluster. These settings will also override any other settings the internal cluster might  * add by default.  */ ;/**  * This method is used to obtain additional settings for clients created by the internal cluster.  * These settings will be applied on the client in addition to some randomized settings defined in  * the cluster. These settings will also override any other settings the internal cluster might  * add by default.  */ protected Settings transportClientSettings() {     return Settings.EMPTY. }
false;private;1;11;;private ExternalTestCluster buildExternalCluster(String clusterAddresses) throws IOException {     String[] stringAddresses = clusterAddresses.split(",").     TransportAddress[] transportAddresses = new TransportAddress[stringAddresses.length].     int i = 0.     for (String stringAddress : stringAddresses) {         URL url = new URL("http://" + stringAddress).         InetAddress inetAddress = InetAddress.getByName(url.getHost()).         transportAddresses[i++] = new TransportAddress(new InetSocketAddress(inetAddress, url.getPort())).     }     return new ExternalTestCluster(createTempDir(), externalClusterClientSettings(), transportClientPlugins(), transportAddresses). }
false;protected;0;3;;protected Settings externalClusterClientSettings() {     return Settings.EMPTY. }
false;protected;0;3;;protected boolean ignoreExternalCluster() {     return false. }
false;protected;2;48;;protected TestCluster buildTestCluster(Scope scope, long seed) throws IOException {     String clusterAddresses = System.getProperty(TESTS_CLUSTER).     if (Strings.hasLength(clusterAddresses) && ignoreExternalCluster() == false) {         if (scope == Scope.TEST) {             throw new IllegalArgumentException("Cannot run TEST scope test with " + TESTS_CLUSTER).         }         return buildExternalCluster(clusterAddresses).     }     final String nodePrefix.     switch(scope) {         case TEST:             nodePrefix = TEST_CLUSTER_NODE_PREFIX.             break.         case SUITE:             nodePrefix = SUITE_CLUSTER_NODE_PREFIX.             break.         default:             throw new ElasticsearchException("Scope not supported: " + scope).     }     boolean supportsDedicatedMasters = getSupportsDedicatedMasters().     int numDataNodes = getNumDataNodes().     int minNumDataNodes.     int maxNumDataNodes.     if (numDataNodes >= 0) {         minNumDataNodes = maxNumDataNodes = numDataNodes.     } else {         minNumDataNodes = getMinNumDataNodes().         maxNumDataNodes = getMaxNumDataNodes().     }     Collection<Class<? extends Plugin>> mockPlugins = getMockPlugins().     final NodeConfigurationSource nodeConfigurationSource = getNodeConfigSource().     if (addMockTransportService()) {         ArrayList<Class<? extends Plugin>> mocks = new ArrayList<>(mockPlugins).         // we do this in case somebody overrides getMockPlugins and misses to call super         if (mockPlugins.contains(getTestTransportPlugin()) == false) {             mocks.add(getTestTransportPlugin()).         }         mockPlugins = mocks.     }     return new InternalTestCluster(seed, createTempDir(), supportsDedicatedMasters, getAutoMinMasterNodes(), minNumDataNodes, maxNumDataNodes, InternalTestCluster.clusterName(scope.name(), seed) + "-cluster", nodeConfigurationSource, getNumClientNodes(), nodePrefix, mockPlugins, getClientWrapper(), forbidPrivateIndexSettings()). }
false;public;1;6;;@Override public Settings nodeSettings(int nodeOrdinal) {     return Settings.builder().put(initialNodeSettings.build()).put(ESIntegTestCase.this.nodeSettings(nodeOrdinal)).build(). }
false;public;1;4;;@Override public Path nodeConfigPath(int nodeOrdinal) {     return ESIntegTestCase.this.nodeConfigPath(nodeOrdinal). }
false;public;0;4;;@Override public Collection<Class<? extends Plugin>> nodePlugins() {     return ESIntegTestCase.this.nodePlugins(). }
false;public;0;5;;@Override public Settings transportClientSettings() {     return Settings.builder().put(initialTransportClientSettings.build()).put(ESIntegTestCase.this.transportClientSettings()).build(). }
false;public;0;9;;@Override public Collection<Class<? extends Plugin>> transportClientPlugins() {     Collection<Class<? extends Plugin>> plugins = ESIntegTestCase.this.transportClientPlugins().     if (plugins.contains(getTestTransportPlugin()) == false) {         plugins = new ArrayList<>(plugins).         plugins.add(getTestTransportPlugin()).     }     return Collections.unmodifiableCollection(plugins). }
false;protected;0;42;;protected NodeConfigurationSource getNodeConfigSource() {     Settings.Builder initialNodeSettings = Settings.builder().     Settings.Builder initialTransportClientSettings = Settings.builder().     if (addMockTransportService()) {         initialNodeSettings.put(NetworkModule.TRANSPORT_TYPE_KEY, getTestTransportType()).         initialTransportClientSettings.put(NetworkModule.TRANSPORT_TYPE_KEY, getTestTransportType()).     }     return new NodeConfigurationSource() {          @Override         public Settings nodeSettings(int nodeOrdinal) {             return Settings.builder().put(initialNodeSettings.build()).put(ESIntegTestCase.this.nodeSettings(nodeOrdinal)).build().         }          @Override         public Path nodeConfigPath(int nodeOrdinal) {             return ESIntegTestCase.this.nodeConfigPath(nodeOrdinal).         }          @Override         public Collection<Class<? extends Plugin>> nodePlugins() {             return ESIntegTestCase.this.nodePlugins().         }          @Override         public Settings transportClientSettings() {             return Settings.builder().put(initialTransportClientSettings.build()).put(ESIntegTestCase.this.transportClientSettings()).build().         }          @Override         public Collection<Class<? extends Plugin>> transportClientPlugins() {             Collection<Class<? extends Plugin>> plugins = ESIntegTestCase.this.transportClientPlugins().             if (plugins.contains(getTestTransportPlugin()) == false) {                 plugins = new ArrayList<>(plugins).                 plugins.add(getTestTransportPlugin()).             }             return Collections.unmodifiableCollection(plugins).         }     }. }
true;protected;0;3;/**  * Iff this returns true mock transport implementations are used for the test runs. Otherwise not mock transport impls are used.  * The default is {@code true}.  */ ;/**  * Iff this returns true mock transport implementations are used for the test runs. Otherwise not mock transport impls are used.  * The default is {@code true}.  */ protected boolean addMockTransportService() {     return true. }
true;protected;0;3;/**  * Returns {@code true} iff this test cluster should use a dummy http transport  */ ;/**  * Returns {@code true} iff this test cluster should use a dummy http transport  */ protected boolean addMockHttpTransport() {     return true. }
true;protected;0;3;/**  * Returns a function that allows to wrap / filter all clients that are exposed by the test cluster. This is useful  * for debugging or request / response pre and post processing. It also allows to intercept all calls done by the test  * framework. By default this method returns an identity function {@link Function#identity()}.  */ ;/**  * Returns a function that allows to wrap / filter all clients that are exposed by the test cluster. This is useful  * for debugging or request / response pre and post processing. It also allows to intercept all calls done by the test  * framework. By default this method returns an identity function {@link Function#identity()}.  */ protected Function<Client, Client> getClientWrapper() {     return Function.identity(). }
true;protected;0;33;/**  * Return the mock plugins the cluster should use  */ ;/**  * Return the mock plugins the cluster should use  */ protected Collection<Class<? extends Plugin>> getMockPlugins() {     final ArrayList<Class<? extends Plugin>> mocks = new ArrayList<>().     if (MOCK_MODULES_ENABLED && randomBoolean()) {         // sometimes run without those completely         if (randomBoolean() && addMockTransportService()) {             mocks.add(MockTransportService.TestPlugin.class).         }         if (randomBoolean()) {             mocks.add(MockFSIndexStore.TestPlugin.class).         }         if (randomBoolean()) {             mocks.add(NodeMocksPlugin.class).         }         if (randomBoolean()) {             mocks.add(MockEngineFactoryPlugin.class).         }         if (randomBoolean()) {             mocks.add(MockSearchService.TestPlugin.class).         }         if (randomBoolean()) {             mocks.add(MockFieldFilterPlugin.class).         }     }     if (addMockTransportService()) {         mocks.add(getTestTransportPlugin()).     }     if (addMockHttpTransport()) {         mocks.add(MockHttpTransport.TestPlugin.class).     }     mocks.add(TestSeedPlugin.class).     mocks.add(AssertActionNamePlugin.class).     return Collections.unmodifiableList(mocks). }
false;public;0;4;;@Override public List<Setting<?>> getSettings() {     return Collections.singletonList(INDEX_TEST_SEED_SETTING). }
false;public;4;10;;@Override public <T extends TransportRequest> TransportRequestHandler<T> interceptHandler(String action, String executor, boolean forceExecution, TransportRequestHandler<T> actualHandler) {     if (TransportService.isValidActionName(action) == false) {         throw new IllegalArgumentException("invalid action name [" + action + "] must start with one of: " + TransportService.VALID_ACTION_PREFIXES).     }     return actualHandler. }
false;public;2;16;;@Override public List<TransportInterceptor> getTransportInterceptors(NamedWriteableRegistry namedWriteableRegistry, ThreadContext threadContext) {     return Arrays.asList(new TransportInterceptor() {          @Override         public <T extends TransportRequest> TransportRequestHandler<T> interceptHandler(String action, String executor, boolean forceExecution, TransportRequestHandler<T> actualHandler) {             if (TransportService.isValidActionName(action) == false) {                 throw new IllegalArgumentException("invalid action name [" + action + "] must start with one of: " + TransportService.VALID_ACTION_PREFIXES).             }             return actualHandler.         }     }). }
true;private,static;0;7;/**  * Returns the client ratio configured via  */ ;/**  * Returns the client ratio configured via  */ private static double transportClientRatio() {     String property = System.getProperty(TESTS_CLIENT_RATIO).     if (property == null || property.isEmpty()) {         return Double.NaN.     }     return Double.parseDouble(property). }
true;protected;0;12;/**  * Returns the transport client ratio from the class level annotation or via  * {@link System#getProperty(String)} if available. If both are not available this will  * return a random ratio in the interval {@code [0..1]}.  */ ;/**  * Returns the transport client ratio from the class level annotation or via  * {@link System#getProperty(String)} if available. If both are not available this will  * return a random ratio in the interval {@code [0..1]}.  */ protected double getPerTestTransportClientRatio() {     final ClusterScope annotation = getAnnotation(this.getClass(), ClusterScope.class).     double perTestRatio = -1.     if (annotation != null) {         perTestRatio = annotation.transportClientRatio().     }     if (perTestRatio == -1) {         return Double.isNaN(TRANSPORT_CLIENT_RATIO) ? randomDouble() : TRANSPORT_CLIENT_RATIO.     }     assert perTestRatio >= 0.0 && perTestRatio <= 1.0.     return perTestRatio. }
true;public;0;6;/**  * Returns path to a random directory that can be used to create a temporary file system repo  */ ;/**  * Returns path to a random directory that can be used to create a temporary file system repo  */ public Path randomRepoPath() {     if (currentCluster instanceof InternalTestCluster) {         return randomRepoPath(((InternalTestCluster) currentCluster).getDefaultSettings()).     }     throw new UnsupportedOperationException("unsupported cluster type"). }
true;public,static;1;10;/**  * Returns path to a random directory that can be used to create a temporary file system repo  */ ;/**  * Returns path to a random directory that can be used to create a temporary file system repo  */ public static Path randomRepoPath(Settings settings) {     Environment environment = TestEnvironment.newEnvironment(settings).     Path[] repoFiles = environment.repoFiles().     assert repoFiles.length > 0.     Path path.     do {         path = repoFiles[0].resolve(randomAlphaOfLength(10)).     } while (Files.exists(path)).     return path. }
false;protected;1;7;;protected NumShards getNumShards(String index) {     MetaData metaData = client().admin().cluster().prepareState().get().getState().metaData().     assertThat(metaData.hasIndex(index), equalTo(true)).     int numShards = Integer.valueOf(metaData.index(index).getSettings().get(SETTING_NUMBER_OF_SHARDS)).     int numReplicas = Integer.valueOf(metaData.index(index).getSettings().get(SETTING_NUMBER_OF_REPLICAS)).     return new NumShards(numShards, numReplicas). }
true;public;2;16;/**  * Asserts that all shards are allocated on nodes matching the given node pattern.  */ ;/**  * Asserts that all shards are allocated on nodes matching the given node pattern.  */ public Set<String> assertAllShardsOnNodes(String index, String... pattern) {     Set<String> nodes = new HashSet<>().     ClusterState clusterState = client().admin().cluster().prepareState().execute().actionGet().getState().     for (IndexRoutingTable indexRoutingTable : clusterState.routingTable()) {         for (IndexShardRoutingTable indexShardRoutingTable : indexRoutingTable) {             for (ShardRouting shardRouting : indexShardRoutingTable) {                 if (shardRouting.currentNodeId() != null && index.equals(shardRouting.getIndexName())) {                     String name = clusterState.nodes().get(shardRouting.currentNodeId()).getName().                     nodes.add(name).                     assertThat("Allocated on new node: " + name, Regex.simpleMatch(pattern, name), is(true)).                 }             }         }     }     return nodes. }
true;public;2;12;/**  * Asserts that all segments are sorted with the provided {@link Sort}.  */ ;/**  * Asserts that all segments are sorted with the provided {@link Sort}.  */ public void assertSortedSegments(String indexName, Sort expectedIndexSort) {     IndicesSegmentResponse segmentResponse = client().admin().indices().prepareSegments(indexName).execute().actionGet().     IndexSegments indexSegments = segmentResponse.getIndices().get(indexName).     for (IndexShardSegments indexShardSegments : indexSegments.getShards().values()) {         for (ShardSegments shardSegments : indexShardSegments.getShards()) {             for (Segment segment : shardSegments) {                 assertThat(expectedIndexSort, equalTo(segment.getSegmentSort())).             }         }     } }
false;private,static;0;3;;private static boolean runTestScopeLifecycle() {     return INSTANCE == null. }
false;public,final;0;8;;@Before public final void setupTestCluster() throws Exception {     if (runTestScopeLifecycle()) {         printTestMessage("setting up").         beforeInternal().         printTestMessage("all set up").     } }
false;public,final;0;15;;@After public final void cleanUpCluster() throws Exception {     // we remove indices     if (isInternalCluster()) {         internalCluster().setBootstrapMasterNodeIndex(-1).     }     super.ensureAllSearchContextsReleased().     if (runTestScopeLifecycle()) {         printTestMessage("cleaning up after").         afterInternal(false).         printTestMessage("cleaned up after").     } }
false;public,static;0;16;;@AfterClass public static void afterClass() throws Exception {     if (!runTestScopeLifecycle()) {         try {             INSTANCE.printTestMessage("cleaning up after").             INSTANCE.afterInternal(true).             checkStaticState(true).         } finally {             INSTANCE = null.         }     } else {         clearClusters().     }     SUITE_SEED = null.     currentCluster = null. }
false;private,static;0;27;;private static void initializeSuiteScope() throws Exception {     Class<?> targetClass = getTestClass().     /**      * Note we create these test class instance via reflection      * since JUnit creates a new instance per test and that is also      * the reason why INSTANCE is static since this entire method      * must be executed in a static context.      */     assert INSTANCE == null.     if (isSuiteScopedTest(targetClass)) {         // note we need to do this this way to make sure this is reproducible         INSTANCE = (ESIntegTestCase) targetClass.getConstructor().newInstance().         boolean success = false.         try {             INSTANCE.printTestMessage("setup").             INSTANCE.beforeInternal().             INSTANCE.setupSuiteScopeCluster().             success = true.         } finally {             if (!success) {                 afterClass().             }         }     } else {         INSTANCE = null.     } }
true;protected;2;3;/**  * Compute a routing key that will route documents to the <code>shard</code>-th shard  * of the provided index.  */ ;/**  * Compute a routing key that will route documents to the <code>shard</code>-th shard  * of the provided index.  */ protected String routingKeyForShard(String index, int shard) {     return internalCluster().routingKeyForShard(resolveIndex(index), shard, random()). }
false;protected;0;10;;@Override protected NamedXContentRegistry xContentRegistry() {     if (isInternalCluster() && cluster().size() > 0) {         // If it's internal cluster - using existing registry in case plugin registered custom data         return internalCluster().getInstance(NamedXContentRegistry.class).     } else {         // If it's external cluster - fall back to the standard set         return new NamedXContentRegistry(ClusterModule.getNamedXWriteables()).     } }
false;protected;0;3;;protected boolean forbidPrivateIndexSettings() {     return true. }
true;protected,static,synchronized;0;6;/**  * Returns an instance of {@link RestClient} pointing to the current test cluster.  * Creates a new client if the method is invoked for the first time in the context of the current test scope.  * The returned client gets automatically closed when needed, it shouldn't be closed as part of tests otherwise  * it cannot be reused by other tests anymore.  */ ;/**  * Returns an instance of {@link RestClient} pointing to the current test cluster.  * Creates a new client if the method is invoked for the first time in the context of the current test scope.  * The returned client gets automatically closed when needed, it shouldn't be closed as part of tests otherwise  * it cannot be reused by other tests anymore.  */ protected static synchronized RestClient getRestClient() {     if (restClient == null) {         restClient = createRestClient(null).     }     return restClient. }
false;protected,static;1;3;;protected static RestClient createRestClient(RestClientBuilder.HttpClientConfigCallback httpClientConfigCallback) {     return createRestClient(httpClientConfigCallback, "http"). }
false;protected,static;2;5;;protected static RestClient createRestClient(RestClientBuilder.HttpClientConfigCallback httpClientConfigCallback, String protocol) {     NodesInfoResponse nodesInfoResponse = client().admin().cluster().prepareNodesInfo().get().     assertFalse(nodesInfoResponse.hasFailures()).     return createRestClient(nodesInfoResponse.getNodes(), httpClientConfigCallback, protocol). }
false;protected,static;3;16;;protected static RestClient createRestClient(final List<NodeInfo> nodes, RestClientBuilder.HttpClientConfigCallback httpClientConfigCallback, String protocol) {     List<HttpHost> hosts = new ArrayList<>().     for (NodeInfo node : nodes) {         if (node.getHttp() != null) {             TransportAddress publishAddress = node.getHttp().address().publishAddress().             InetSocketAddress address = publishAddress.address().             hosts.add(new HttpHost(NetworkAddress.format(address.getAddress()), address.getPort(), protocol)).         }     }     RestClientBuilder builder = RestClient.builder(hosts.toArray(new HttpHost[hosts.size()])).     if (httpClientConfigCallback != null) {         builder.setHttpClientConfigCallback(httpClientConfigCallback).     }     return builder.build(). }
true;protected;0;2;/**  * This method is executed iff the test is annotated with {@link SuiteScopeTestCase}  * before the first test of this class is executed.  *  * @see SuiteScopeTestCase  */ ;/**  * This method is executed iff the test is annotated with {@link SuiteScopeTestCase}  * before the first test of this class is executed.  *  * @see SuiteScopeTestCase  */ protected void setupSuiteScopeCluster() throws Exception { }
false;private,static;1;3;;private static boolean isSuiteScopedTest(Class<?> clazz) {     return clazz.getAnnotation(SuiteScopeTestCase.class) != null. }
false;public,static;1;6;;public static Index resolveIndex(String index) {     GetIndexResponse getIndexResponse = client().admin().indices().prepareGetIndex().setIndices(index).get().     assertTrue("index " + index + " not found", getIndexResponse.getSettings().containsKey(index)).     String uuid = getIndexResponse.getSettings().get(index).get(IndexMetaData.SETTING_INDEX_UUID).     return new Index(index, uuid). }
false;public,static;0;3;;public static boolean inFipsJvm() {     return Security.getProviders()[0].getName().toLowerCase(Locale.ROOT).contains("fips"). }
