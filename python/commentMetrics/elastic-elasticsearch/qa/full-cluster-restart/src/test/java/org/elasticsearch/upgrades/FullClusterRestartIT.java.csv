# id;timestamp;commentText;codeText;commentWords;codeWords
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1524684173;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (runningAgainstOldCluster) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1529916083;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (runningAgainstOldCluster) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1532353780;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (runningAgainstOldCluster) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1535139672;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (runningAgainstOldCluster) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1536314350;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (runningAgainstOldCluster) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1536828374;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1539615817;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1540486836;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1540583181;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1544035746;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1544169664;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1544491368;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1544499913;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1544572729;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1544648252;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1544667713;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1544813247;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1545253165;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1547156119;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1547500081;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1548680839;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1548684170;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1548795161;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1549016214;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1549127354;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1549310947;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1549394143;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1549608646;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1550083218;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1550227375;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> public void testEmptyShard() throws IOException;1550504256;Tests that a single empty shard index is correctly recovered. Empty shards are often an edge case.;public void testEmptyShard() throws IOException {_        final String index = "test_empty_shard"___        if (isRunningAgainstOldCluster()) {_            Settings.Builder settings = Settings.builder()_                .put(IndexMetaData.INDEX_NUMBER_OF_SHARDS_SETTING.getKey(), 1)_                .put(IndexMetaData.INDEX_NUMBER_OF_REPLICAS_SETTING.getKey(), 1)_                _                _                _                _                .put(INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey(), "100ms")_                .put(SETTING_ALLOCATION_MAX_RETRY.getKey(), "0")_ _            createIndex(index, settings.build())__        }_        ensureGreen(index)__    };tests,that,a,single,empty,shard,index,is,correctly,recovered,empty,shards,are,often,an,edge,case;public,void,test,empty,shard,throws,ioexception,final,string,index,if,is,running,against,old,cluster,settings,builder,settings,settings,builder,put,index,meta,data,get,key,1,put,index,meta,data,get,key,1,put,get,key,100ms,put,get,key,0,create,index,index,settings,build,ensure,green,index
FullClusterRestartIT -> private Map<String, String> listSnapshotVerboseParams();1524684173;Parameters required to get the version of Elasticsearch that took the snapshot._On versions after 5.5 we need a {@code verbose} parameter.;private Map<String, String> listSnapshotVerboseParams() {_        if (runningAgainstOldCluster && oldClusterVersion.before(Version.V_5_5_0)) {_            return emptyMap()__        }_        return singletonMap("verbose", "true")__    };parameters,required,to,get,the,version,of,elasticsearch,that,took,the,snapshot,on,versions,after,5,5,we,need,a,code,verbose,parameter;private,map,string,string,list,snapshot,verbose,params,if,running,against,old,cluster,old,cluster,version,before,version,return,empty,map,return,singleton,map,verbose,true
FullClusterRestartIT -> private Map<String, String> listSnapshotVerboseParams();1529916083;Parameters required to get the version of Elasticsearch that took the snapshot._On versions after 5.5 we need a {@code verbose} parameter.;private Map<String, String> listSnapshotVerboseParams() {_        if (runningAgainstOldCluster && oldClusterVersion.before(Version.V_5_5_0)) {_            return emptyMap()__        }_        return singletonMap("verbose", "true")__    };parameters,required,to,get,the,version,of,elasticsearch,that,took,the,snapshot,on,versions,after,5,5,we,need,a,code,verbose,parameter;private,map,string,string,list,snapshot,verbose,params,if,running,against,old,cluster,old,cluster,version,before,version,return,empty,map,return,singleton,map,verbose,true
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1524684173;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            oldClusterVersion.before(VERSION_5_1_0_UNRELEASED))___        int count__        if (runningAgainstOldCluster) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            client().performRequest("PUT", "/" + index, Collections.emptyMap(),_                new StringEntity(Strings.toString(mappingsAndSettings), ContentType.APPLICATION_JSON))___            String aliasName = "%23" + index_ _            client().performRequest("PUT", "/" + index + "/_alias/" + aliasName)__            Response response = client().performRequest("HEAD", "/" + index + "/_alias/" + aliasName)__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        logger.error("clusterState=" + toMap(client().performRequest("GET", "/_cluster/state",_            Collections.singletonMap("metric", "metadata"))))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = toMap(client().performRequest("GET", "/" + aliasName + "/_search"))__        int totalHits = (int) XContentMapValues.extractValue("hits.total", searchRsp)__        assertEquals(count, totalHits)__        if (runningAgainstOldCluster == false) {_            _            Response response = client().performRequest("DELETE", "/" + index + "/_alias/" + aliasName)__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest("HEAD", "/" + index + "/_alias/" + aliasName)__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,old,cluster,version,before,int,count,if,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,client,perform,request,put,index,collections,empty,map,new,string,entity,strings,to,string,mappings,and,settings,content,type,string,alias,name,23,index,client,perform,request,put,index,alias,name,response,response,client,perform,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,logger,error,cluster,state,to,map,client,perform,request,get,state,collections,singleton,map,metric,metadata,string,alias,name,23,index,map,string,object,search,rsp,to,map,client,perform,request,get,alias,name,int,total,hits,int,xcontent,map,values,extract,value,hits,total,search,rsp,assert,equals,count,total,hits,if,running,against,old,cluster,false,response,response,client,perform,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1529916083;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            oldClusterVersion.before(VERSION_5_1_0_UNRELEASED))___        int count__        if (runningAgainstOldCluster) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            client().performRequest("PUT", "/" + index, Collections.emptyMap(),_                new StringEntity(Strings.toString(mappingsAndSettings), ContentType.APPLICATION_JSON))___            String aliasName = "%23" + index_ _            client().performRequest("PUT", "/" + index + "/_alias/" + aliasName)__            Response response = client().performRequest("HEAD", "/" + index + "/_alias/" + aliasName)__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        logger.error("clusterState=" + toMap(client().performRequest("GET", "/_cluster/state",_            Collections.singletonMap("metric", "metadata"))))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = toMap(client().performRequest("GET", "/" + aliasName + "/_search"))__        int totalHits = (int) XContentMapValues.extractValue("hits.total", searchRsp)__        assertEquals(count, totalHits)__        if (runningAgainstOldCluster == false) {_            _            Response response = client().performRequest("DELETE", "/" + index + "/_alias/" + aliasName)__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest("HEAD", "/" + index + "/_alias/" + aliasName)__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,old,cluster,version,before,int,count,if,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,client,perform,request,put,index,collections,empty,map,new,string,entity,strings,to,string,mappings,and,settings,content,type,string,alias,name,23,index,client,perform,request,put,index,alias,name,response,response,client,perform,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,logger,error,cluster,state,to,map,client,perform,request,get,state,collections,singleton,map,metric,metadata,string,alias,name,23,index,map,string,object,search,rsp,to,map,client,perform,request,get,alias,name,int,total,hits,int,xcontent,map,values,extract,value,hits,total,search,rsp,assert,equals,count,total,hits,if,running,against,old,cluster,false,response,response,client,perform,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1532353780;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            oldClusterVersion.before(VERSION_5_1_0_UNRELEASED))___        int count__        if (runningAgainstOldCluster) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = (int) XContentMapValues.extractValue("hits.total", searchRsp)__        assertEquals(count, totalHits)__        if (runningAgainstOldCluster == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,old,cluster,version,before,int,count,if,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,int,xcontent,map,values,extract,value,hits,total,search,rsp,assert,equals,count,total,hits,if,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1535139672;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            oldClusterVersion.before(VERSION_5_1_0_UNRELEASED))___        int count__        if (runningAgainstOldCluster) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = (int) XContentMapValues.extractValue("hits.total", searchRsp)__        assertEquals(count, totalHits)__        if (runningAgainstOldCluster == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,old,cluster,version,before,int,count,if,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,int,xcontent,map,values,extract,value,hits,total,search,rsp,assert,equals,count,total,hits,if,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1536314350;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            oldClusterVersion.before(VERSION_5_1_0_UNRELEASED))___        int count__        if (runningAgainstOldCluster) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = (int) XContentMapValues.extractValue("hits.total", searchRsp)__        assertEquals(count, totalHits)__        if (runningAgainstOldCluster == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,old,cluster,version,before,int,count,if,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,int,xcontent,map,values,extract,value,hits,total,search,rsp,assert,equals,count,total,hits,if,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1536828374;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = (int) XContentMapValues.extractValue("hits.total", searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,int,xcontent,map,values,extract,value,hits,total,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1539615817;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = (int) XContentMapValues.extractValue("hits.total", searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,int,xcontent,map,values,extract,value,hits,total,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1540486836;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = (int) XContentMapValues.extractValue("hits.total", searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,int,xcontent,map,values,extract,value,hits,total,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1540583181;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = (int) XContentMapValues.extractValue("hits.total", searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,int,xcontent,map,values,extract,value,hits,total,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1544035746;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1544169664;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1544491368;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("_doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1544499913;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("_doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1544572729;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("_doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1544648252;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1544667713;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1544813247;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1545253165;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1547156119;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1547500081;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1548680839;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1548684170;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1548795161;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1549016214;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1549127354;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1549310947;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> public void testAliasWithBadName() throws Exception;1549394143;Search on an alias that contains illegal characters that would prevent it from being created after 5.1.0. It should still be_search-able though.;public void testAliasWithBadName() throws Exception {_        assumeTrue("Can only test bad alias name if old cluster is on 5.1.0 or before",_            getOldClusterVersion().before(VERSION_5_1_0_UNRELEASED))___        int count__        if (isRunningAgainstOldCluster()) {_            XContentBuilder mappingsAndSettings = jsonBuilder()__            mappingsAndSettings.startObject()__            {_                mappingsAndSettings.startObject("settings")__                mappingsAndSettings.field("number_of_shards", 1)__                mappingsAndSettings.field("number_of_replicas", 0)__                mappingsAndSettings.endObject()__            }_            {_                mappingsAndSettings.startObject("mappings")__                mappingsAndSettings.startObject("doc")__                mappingsAndSettings.startObject("properties")__                {_                    mappingsAndSettings.startObject("key")__                    mappingsAndSettings.field("type", "keyword")__                    mappingsAndSettings.endObject()__                }_                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__                mappingsAndSettings.endObject()__            }_            mappingsAndSettings.endObject()__            Request createIndex = new Request("PUT", "/" + index)__            createIndex.setJsonEntity(Strings.toString(mappingsAndSettings))__            client().performRequest(createIndex)___            String aliasName = "%23" + index_ _            client().performRequest(new Request("PUT", "/" + index + "/_alias/" + aliasName))__            Response response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())___            count = randomIntBetween(32, 128)__            indexRandomDocuments(count, true, true, i -> {_                return JsonXContent.contentBuilder().startObject()_                    .field("key", "value")_                    .endObject()__            })__            refresh()__        } else {_            count = countOfIndexedRandomDocuments()__        }__        Request request = new Request("GET", "/_cluster/state")__        request.addParameter("metric", "metadata")__        logger.error("clusterState=" + entityAsMap(client().performRequest(request)))__        _        String aliasName = "%23" + index_ _        Map<String, Object> searchRsp = entityAsMap(client().performRequest(new Request("GET", "/" + aliasName + "/_search")))__        int totalHits = extractTotalHits(searchRsp)__        assertEquals(count, totalHits)__        if (isRunningAgainstOldCluster() == false) {_            _            Response response = client().performRequest(new Request("DELETE", "/" + index + "/_alias/" + aliasName))__            assertEquals(200, response.getStatusLine().getStatusCode())__            _            response = client().performRequest(new Request("HEAD", "/" + index + "/_alias/" + aliasName))__            assertEquals(404, response.getStatusLine().getStatusCode())__        }_    };search,on,an,alias,that,contains,illegal,characters,that,would,prevent,it,from,being,created,after,5,1,0,it,should,still,be,search,able,though;public,void,test,alias,with,bad,name,throws,exception,assume,true,can,only,test,bad,alias,name,if,old,cluster,is,on,5,1,0,or,before,get,old,cluster,version,before,int,count,if,is,running,against,old,cluster,xcontent,builder,mappings,and,settings,json,builder,mappings,and,settings,start,object,mappings,and,settings,start,object,settings,mappings,and,settings,field,1,mappings,and,settings,field,0,mappings,and,settings,end,object,mappings,and,settings,start,object,mappings,mappings,and,settings,start,object,doc,mappings,and,settings,start,object,properties,mappings,and,settings,start,object,key,mappings,and,settings,field,type,keyword,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,mappings,and,settings,end,object,request,create,index,new,request,put,index,create,index,set,json,entity,strings,to,string,mappings,and,settings,client,perform,request,create,index,string,alias,name,23,index,client,perform,request,new,request,put,index,alias,name,response,response,client,perform,request,new,request,head,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,count,random,int,between,32,128,index,random,documents,count,true,true,i,return,json,xcontent,content,builder,start,object,field,key,value,end,object,refresh,else,count,count,of,indexed,random,documents,request,request,new,request,get,state,request,add,parameter,metric,metadata,logger,error,cluster,state,entity,as,map,client,perform,request,request,string,alias,name,23,index,map,string,object,search,rsp,entity,as,map,client,perform,request,new,request,get,alias,name,int,total,hits,extract,total,hits,search,rsp,assert,equals,count,total,hits,if,is,running,against,old,cluster,false,response,response,client,perform,request,new,request,delete,index,alias,name,assert,equals,200,response,get,status,line,get,status,code,response,client,perform,request,new,request,head,index,alias,name,assert,equals,404,response,get,status,line,get,status,code
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1532353780;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1535139672;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1536314350;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1536828374;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1539615817;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1540486836;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1540583181;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1544035746;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1544169664;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1544491368;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1544499913;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1544572729;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1544648252;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1544667713;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1544813247;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1545253165;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1547156119;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1547500081;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1548680839;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1548684170;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1548795161;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1549016214;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1549127354;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1549310947;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1549394143;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1549608646;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1550083218;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1550227375;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> protected void ensureGreenLongWait(String index) throws IOException;1550504256;Wait for an index to have green health, waiting longer than_{@link ESRestTestCase#ensureGreen}.;protected void ensureGreenLongWait(String index) throws IOException {_        Request request = new Request("GET", "/_cluster/health/" + index)__        request.addParameter("timeout", "2m")__        request.addParameter("wait_for_status", "green")__        request.addParameter("wait_for_no_relocating_shards", "true")__        request.addParameter("wait_for_events", "languid")__        request.addParameter("level", "shards")__        Map<String, Object> healthRsp = entityAsMap(client().performRequest(request))__        logger.info("health api response: {}", healthRsp)__        assertEquals("green", healthRsp.get("status"))__        assertFalse((Boolean) healthRsp.get("timed_out"))__    };wait,for,an,index,to,have,green,health,waiting,longer,than,link,esrest,test,case,ensure,green;protected,void,ensure,green,long,wait,string,index,throws,ioexception,request,request,new,request,get,health,index,request,add,parameter,timeout,2m,request,add,parameter,green,request,add,parameter,true,request,add,parameter,languid,request,add,parameter,level,shards,map,string,object,health,rsp,entity,as,map,client,perform,request,request,logger,info,health,api,response,health,rsp,assert,equals,green,health,rsp,get,status,assert,false,boolean,health,rsp,get
FullClusterRestartIT -> public void testRollover() throws IOException;1536314350;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (runningAgainstOldCluster) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (runningAgainstOldCluster) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (runningAgainstOldCluster ? 0 : bulkCount)__        assertEquals(expectedCount, (int) XContentMapValues.extractValue("hits.total", count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,int,xcontent,map,values,extract,value,hits,total,count
FullClusterRestartIT -> public void testRollover() throws IOException;1536828374;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, (int) XContentMapValues.extractValue("hits.total", count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,int,xcontent,map,values,extract,value,hits,total,count
FullClusterRestartIT -> public void testRollover() throws IOException;1539615817;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, (int) XContentMapValues.extractValue("hits.total", count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,int,xcontent,map,values,extract,value,hits,total,count
FullClusterRestartIT -> public void testRollover() throws IOException;1540486836;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, (int) XContentMapValues.extractValue("hits.total", count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,int,xcontent,map,values,extract,value,hits,total,count
FullClusterRestartIT -> public void testRollover() throws IOException;1540583181;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, (int) XContentMapValues.extractValue("hits.total", count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,int,xcontent,map,values,extract,value,hits,total,count
FullClusterRestartIT -> public void testRollover() throws IOException;1544035746;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1544169664;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1544491368;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/_doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1544499913;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/_doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1544572729;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/_doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1544648252;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1544667713;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1544813247;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1545253165;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1547156119;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        bulkRequest.setOptions(expectWarnings(RestBulkAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,bulk,request,set,options,expect,warnings,rest,bulk,action,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1547500081;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        bulkRequest.setOptions(expectWarnings(RestBulkAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,bulk,request,set,options,expect,warnings,rest,bulk,action,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1548680839;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        bulkRequest.setOptions(expectWarnings(RestBulkAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,bulk,request,set,options,expect,warnings,rest,bulk,action,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1548684170;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        bulkRequest.setOptions(expectWarnings(RestBulkAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,bulk,request,set,options,expect,warnings,rest,bulk,action,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1548795161;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        bulkRequest.setOptions(expectWarnings(RestBulkAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,bulk,request,set,options,expect,warnings,rest,bulk,action,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1549016214;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        bulkRequest.setOptions(expectWarnings(RestBulkAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,bulk,request,set,options,expect,warnings,rest,bulk,action,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1549127354;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        bulkRequest.setOptions(expectWarnings(RestBulkAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,bulk,request,set,options,expect,warnings,rest,bulk,action,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1549310947;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        bulkRequest.setOptions(expectWarnings(RestBulkAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,bulk,request,set,options,expect,warnings,rest,bulk,action,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1549394143;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/doc/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        bulkRequest.setOptions(expectWarnings(RestBulkAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setOptions(allowTypeRemovalWarnings())__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,doc,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,bulk,request,set,options,expect,warnings,rest,bulk,action,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,options,allow,type,removal,warnings,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1549608646;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/" + type + "/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        bulkRequest.setOptions(expectWarnings(RestBulkAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setOptions(allowTypeRemovalWarnings())__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,type,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,bulk,request,set,options,expect,warnings,rest,bulk,action,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,options,allow,type,removal,warnings,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1550083218;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/" + type + "/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        bulkRequest.setOptions(expectWarnings(RestBulkAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setOptions(allowTypesRemovalWarnings())__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,type,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,bulk,request,set,options,expect,warnings,rest,bulk,action,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,options,allow,types,removal,warnings,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1550227375;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }_        Request bulkRequest = new Request("POST", "/" + index + "_write/_bulk")__        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testRollover() throws IOException;1550504256;Test upgrading after a rollover. Specifically:_<ol>_<li>Create an index with a write alias_<li>Write some documents to the write alias_<li>Roll over the index_<li>Make sure the document count is correct_<li>Upgrade_<li>Write some more documents to the write alias_<li>Make sure the document count is correct_</ol>;public void testRollover() throws IOException {_        if (isRunningAgainstOldCluster()) {_            Request createIndex = new Request("PUT", "/" + index + "-000001")__            createIndex.setJsonEntity("{"_                    + "  \"aliases\": {"_                    + "    \"" + index + "_write\": {}"_                    + "  }"_                    + "}")__            client().performRequest(createIndex)__        }__        int bulkCount = 10__        StringBuilder bulk = new StringBuilder()__        for (int i = 0_ i < bulkCount_ i++) {_            bulk.append("{\"index\":{}}\n")__            bulk.append("{\"test\":\"test\"}\n")__        }__        Request bulkRequest = new Request("POST", "/" + index + "_write/_bulk")___        bulkRequest.setJsonEntity(bulk.toString())__        bulkRequest.addParameter("refresh", "")__        assertThat(EntityUtils.toString(client().performRequest(bulkRequest).getEntity()), containsString("\"errors\":false"))___        if (isRunningAgainstOldCluster()) {_            Request rolloverRequest = new Request("POST", "/" + index + "_write/_rollover")__            rolloverRequest.setJsonEntity("{"_                    + "  \"conditions\": {"_                    + "    \"max_docs\": 5"_                    + "  }"_                    + "}")__            client().performRequest(rolloverRequest)___            assertThat(EntityUtils.toString(client().performRequest(new Request("GET", "/_cat/indices?v")).getEntity()),_                    containsString("testrollover-000002"))__        }__        Request countRequest = new Request("POST", "/" + index + "-*/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> count = entityAsMap(client().performRequest(countRequest))__        assertNoFailures(count)___        int expectedCount = bulkCount + (isRunningAgainstOldCluster() ? 0 : bulkCount)__        assertEquals(expectedCount, extractTotalHits(count))__    };test,upgrading,after,a,rollover,specifically,ol,li,create,an,index,with,a,write,alias,li,write,some,documents,to,the,write,alias,li,roll,over,the,index,li,make,sure,the,document,count,is,correct,li,upgrade,li,write,some,more,documents,to,the,write,alias,li,make,sure,the,document,count,is,correct,ol;public,void,test,rollover,throws,ioexception,if,is,running,against,old,cluster,request,create,index,new,request,put,index,000001,create,index,set,json,entity,aliases,index,client,perform,request,create,index,int,bulk,count,10,string,builder,bulk,new,string,builder,for,int,i,0,i,bulk,count,i,bulk,append,index,n,bulk,append,test,test,n,request,bulk,request,new,request,post,index,bulk,request,set,json,entity,bulk,to,string,bulk,request,add,parameter,refresh,assert,that,entity,utils,to,string,client,perform,request,bulk,request,get,entity,contains,string,errors,false,if,is,running,against,old,cluster,request,rollover,request,new,request,post,index,rollover,request,set,json,entity,conditions,5,client,perform,request,rollover,request,assert,that,entity,utils,to,string,client,perform,request,new,request,get,indices,v,get,entity,contains,string,testrollover,000002,request,count,request,new,request,post,index,count,request,add,parameter,size,0,map,string,object,count,entity,as,map,client,perform,request,count,request,assert,no,failures,count,int,expected,count,bulk,count,is,running,against,old,cluster,0,bulk,count,assert,equals,expected,count,extract,total,hits,count
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1524684173;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (runningAgainstOldCluster) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        String countResponse = toStr(client().performRequest("GET", "/" + index + "/_search", singletonMap("size", "0")))__        assertThat(countResponse, containsString("\"total\":" + count))___        _        HttpEntity routingSetting = new StringEntity(_                "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + oldClusterVersion + "\"}}",_                ContentType.APPLICATION_JSON)__        client().performRequest("PUT", "/_cluster/settings", emptyMap(), routingSetting)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("template", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", runningAgainstOldCluster ? oldClusterVersion : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        client().performRequest("PUT", "/_template/test_template", emptyMap(),_                new StringEntity(Strings.toString(templateBuilder), ContentType.APPLICATION_JSON))___        if (runningAgainstOldCluster) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            client().performRequest("PUT", "/_snapshot/repo", emptyMap(),_                    new StringEntity(Strings.toString(repoConfig), ContentType.APPLICATION_JSON))__        }__        client().performRequest("PUT", "/_snapshot/repo/" + (runningAgainstOldCluster ? "old_snap" : "new_snap"),_                singletonMap("wait_for_completion", "true"),_                new StringEntity("{\"indices\": \"" + index + "\"}", ContentType.APPLICATION_JSON))___        checkSnapshot("old_snap", count, oldClusterVersion)__        if (false == runningAgainstOldCluster) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,string,count,response,to,str,client,perform,request,get,index,singleton,map,size,0,assert,that,count,response,contains,string,total,count,http,entity,routing,setting,new,string,entity,persistent,cluster,routing,allocation,exclude,old,cluster,version,content,type,client,perform,request,put,settings,empty,map,routing,setting,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,running,against,old,cluster,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,client,perform,request,put,empty,map,new,string,entity,strings,to,string,template,builder,content,type,if,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,client,perform,request,put,repo,empty,map,new,string,entity,strings,to,string,repo,config,content,type,client,perform,request,put,repo,running,against,old,cluster,singleton,map,true,new,string,entity,indices,index,content,type,check,snapshot,count,old,cluster,version,if,false,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1529916083;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (runningAgainstOldCluster) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        String countResponse = toStr(client().performRequest("GET", "/" + index + "/_search", singletonMap("size", "0")))__        assertThat(countResponse, containsString("\"total\":" + count))___        _        HttpEntity routingSetting = new StringEntity(_                "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + oldClusterVersion + "\"}}",_                ContentType.APPLICATION_JSON)__        client().performRequest("PUT", "/_cluster/settings", emptyMap(), routingSetting)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("template", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", runningAgainstOldCluster ? oldClusterVersion : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        client().performRequest("PUT", "/_template/test_template", emptyMap(),_                new StringEntity(Strings.toString(templateBuilder), ContentType.APPLICATION_JSON))___        if (runningAgainstOldCluster) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            client().performRequest("PUT", "/_snapshot/repo", emptyMap(),_                    new StringEntity(Strings.toString(repoConfig), ContentType.APPLICATION_JSON))__        }__        client().performRequest("PUT", "/_snapshot/repo/" + (runningAgainstOldCluster ? "old_snap" : "new_snap"),_                singletonMap("wait_for_completion", "true"),_                new StringEntity("{\"indices\": \"" + index + "\"}", ContentType.APPLICATION_JSON))___        checkSnapshot("old_snap", count, oldClusterVersion)__        if (false == runningAgainstOldCluster) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,string,count,response,to,str,client,perform,request,get,index,singleton,map,size,0,assert,that,count,response,contains,string,total,count,http,entity,routing,setting,new,string,entity,persistent,cluster,routing,allocation,exclude,old,cluster,version,content,type,client,perform,request,put,settings,empty,map,routing,setting,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,running,against,old,cluster,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,client,perform,request,put,empty,map,new,string,entity,strings,to,string,template,builder,content,type,if,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,client,perform,request,put,repo,empty,map,new,string,entity,strings,to,string,repo,config,content,type,client,perform,request,put,repo,running,against,old,cluster,singleton,map,true,new,string,entity,indices,index,content,type,check,snapshot,count,old,cluster,version,if,false,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1532353780;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (runningAgainstOldCluster) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + oldClusterVersion + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("template", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", runningAgainstOldCluster ? oldClusterVersion : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (runningAgainstOldCluster) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (runningAgainstOldCluster ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, oldClusterVersion)__        if (false == runningAgainstOldCluster) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,running,against,old,cluster,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,old,cluster,version,if,false,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1535139672;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (runningAgainstOldCluster) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + oldClusterVersion + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("template", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", runningAgainstOldCluster ? oldClusterVersion : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (runningAgainstOldCluster) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (runningAgainstOldCluster ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, oldClusterVersion)__        if (false == runningAgainstOldCluster) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,running,against,old,cluster,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,old,cluster,version,if,false,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1536314350;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (runningAgainstOldCluster) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + oldClusterVersion + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("template", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", runningAgainstOldCluster ? oldClusterVersion : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (runningAgainstOldCluster) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (runningAgainstOldCluster ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, oldClusterVersion)__        if (false == runningAgainstOldCluster) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,running,against,old,cluster,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,old,cluster,version,if,false,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1536828374;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("template", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1539615817;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("template", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1540486836;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1540583181;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1544035746;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1544169664;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1544491368;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("_doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1544499913;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("_doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1544572729;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("_doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1544648252;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1544667713;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1544813247;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1545253165;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1547156119;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1547500081;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))___        _        _        if (isRunningAgainstOldCluster() == false) {_            createTemplateRequest.addParameter(INCLUDE_TYPE_NAME_PARAMETER, "true")__        }__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,if,is,running,against,old,cluster,false,create,template,request,add,parameter,true,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1548680839;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))___        _        _        if (isRunningAgainstOldCluster() == false) {_            createTemplateRequest.addParameter(INCLUDE_TYPE_NAME_PARAMETER, "true")__        }__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,if,is,running,against,old,cluster,false,create,template,request,add,parameter,true,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1548684170;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))___        _        _        if (isRunningAgainstOldCluster() == false) {_            createTemplateRequest.addParameter(INCLUDE_TYPE_NAME_PARAMETER, "true")__        }__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,if,is,running,against,old,cluster,false,create,template,request,add,parameter,true,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1548795161;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))___        _        _        if (isRunningAgainstOldCluster() == false) {_            createTemplateRequest.addParameter(INCLUDE_TYPE_NAME_PARAMETER, "true")__            createTemplateRequest.setOptions(expectWarnings(RestPutIndexTemplateAction.TYPES_DEPRECATION_MESSAGE))__        }__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,if,is,running,against,old,cluster,false,create,template,request,add,parameter,true,create,template,request,set,options,expect,warnings,rest,put,index,template,action,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1549016214;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))___        _        _        if (isRunningAgainstOldCluster() == false) {_            createTemplateRequest.addParameter(INCLUDE_TYPE_NAME_PARAMETER, "true")__            createTemplateRequest.setOptions(expectWarnings(RestPutIndexTemplateAction.TYPES_DEPRECATION_MESSAGE))__        }__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,if,is,running,against,old,cluster,false,create,template,request,add,parameter,true,create,template,request,set,options,expect,warnings,rest,put,index,template,action,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1549127354;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))___        _        _        if (isRunningAgainstOldCluster() == false) {_            createTemplateRequest.addParameter(INCLUDE_TYPE_NAME_PARAMETER, "true")__            createTemplateRequest.setOptions(expectWarnings(RestPutIndexTemplateAction.TYPES_DEPRECATION_MESSAGE))__        }__        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,if,is,running,against,old,cluster,false,create,template,request,add,parameter,true,create,template,request,set,options,expect,warnings,rest,put,index,template,action,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1549310947;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))___        _        _        if (isRunningAgainstOldCluster() == false) {_            createTemplateRequest.addParameter(INCLUDE_TYPE_NAME_PARAMETER, "true")__        }_        createTemplateRequest.setOptions(allowTypeRemovalWarnings())___        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,if,is,running,against,old,cluster,false,create,template,request,add,parameter,true,create,template,request,set,options,allow,type,removal,warnings,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1549394143;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster()) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            templateBuilder.startObject("doc")_ {_                templateBuilder.startObject("_source")_ {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))___        _        _        if (isRunningAgainstOldCluster() == false) {_            createTemplateRequest.addParameter(INCLUDE_TYPE_NAME_PARAMETER, "true")__        }_        createTemplateRequest.setOptions(allowTypeRemovalWarnings())___        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,doc,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,if,is,running,against,old,cluster,false,create,template,request,add,parameter,true,create,template,request,set,options,allow,type,removal,warnings,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1549608646;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster() && getOldClusterVersion().major < 8) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            if (isRunningAgainstAncientCluster()) {_                templateBuilder.startObject(type)__            }_            {_                templateBuilder.startObject("_source")__                {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            if (isRunningAgainstAncientCluster()) {_                templateBuilder.endObject()__            }_        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))___        _        _        if (isRunningAgainstOldCluster() == false && getOldClusterVersion().major < 7) {_            createTemplateRequest.addParameter(INCLUDE_TYPE_NAME_PARAMETER, "true")__        }_        createTemplateRequest.setOptions(allowTypeRemovalWarnings())___        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,get,old,cluster,version,major,8,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,if,is,running,against,ancient,cluster,template,builder,start,object,type,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,if,is,running,against,ancient,cluster,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,if,is,running,against,old,cluster,false,get,old,cluster,version,major,7,create,template,request,add,parameter,true,create,template,request,set,options,allow,type,removal,warnings,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1550083218;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster() && getOldClusterVersion().major < 8) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            if (isRunningAgainstAncientCluster()) {_                templateBuilder.startObject(type)__            }_            {_                templateBuilder.startObject("_source")__                {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_            if (isRunningAgainstAncientCluster()) {_                templateBuilder.endObject()__            }_        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))___        _        _        if (isRunningAgainstOldCluster() == false && getOldClusterVersion().major < 7) {_            createTemplateRequest.addParameter(INCLUDE_TYPE_NAME_PARAMETER, "true")__        }_        createTemplateRequest.setOptions(allowTypesRemovalWarnings())___        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,get,old,cluster,version,major,8,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,if,is,running,against,ancient,cluster,template,builder,start,object,type,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,if,is,running,against,ancient,cluster,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,if,is,running,against,old,cluster,false,get,old,cluster,version,major,7,create,template,request,add,parameter,true,create,template,request,set,options,allow,types,removal,warnings,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1550227375;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster() && getOldClusterVersion().major < 8) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            {_                templateBuilder.startObject("_source")__                {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))___        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,get,old,cluster,version,major,8,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSnapshotRestore() throws IOException;1550504256;Tests snapshot/restore by creating a snapshot and restoring it. It takes_a snapshot on the old cluster and restores it on the old cluster as a_sanity check and on the new cluster as an upgrade test. It also takes a_snapshot on the new cluster and restores that on the new cluster as a_test that the repository is ok with containing snapshot from both the_old and new versions. All of the snapshots include an index, a template,_and some routing configuration.;public void testSnapshotRestore() throws IOException {_        int count__        if (isRunningAgainstOldCluster() && getOldClusterVersion().major < 8) {_            _            count = between(200, 300)__            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())__        } else {_            count = countOfIndexedRandomDocuments()__        }__        _        refresh()___        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        _        Request addRoutingSettings = new Request("PUT", "/_cluster/settings")__        addRoutingSettings.setJsonEntity(_                    "{\"persistent\": {\"cluster.routing.allocation.exclude.test_attr\": \"" + getOldClusterVersion() + "\"}}")__        client().performRequest(addRoutingSettings)___        _        XContentBuilder templateBuilder = JsonXContent.contentBuilder().startObject()__        templateBuilder.field("index_patterns", "evil_*")_ _        templateBuilder.startObject("settings")_ {_            templateBuilder.field("number_of_shards", 1)__        }_        templateBuilder.endObject()__        templateBuilder.startObject("mappings")_ {_            {_                templateBuilder.startObject("_source")__                {_                    templateBuilder.field("enabled", true)__                }_                templateBuilder.endObject()__            }_        }_        templateBuilder.endObject()__        templateBuilder.startObject("aliases")_ {_            templateBuilder.startObject("alias1").endObject()__            templateBuilder.startObject("alias2")_ {_                templateBuilder.startObject("filter")_ {_                    templateBuilder.startObject("term")_ {_                        templateBuilder.field("version", isRunningAgainstOldCluster() ? getOldClusterVersion() : Version.CURRENT)__                    }_                    templateBuilder.endObject()__                }_                templateBuilder.endObject()__            }_            templateBuilder.endObject()__        }_        templateBuilder.endObject().endObject()__        Request createTemplateRequest = new Request("PUT", "/_template/test_template")__        createTemplateRequest.setJsonEntity(Strings.toString(templateBuilder))___        client().performRequest(createTemplateRequest)___        if (isRunningAgainstOldCluster()) {_            _            XContentBuilder repoConfig = JsonXContent.contentBuilder().startObject()_ {_                repoConfig.field("type", "fs")__                repoConfig.startObject("settings")_ {_                    repoConfig.field("compress", randomBoolean())__                    repoConfig.field("location", System.getProperty("tests.path.repo"))__                }_                repoConfig.endObject()__            }_            repoConfig.endObject()__            Request createRepoRequest = new Request("PUT", "/_snapshot/repo")__            createRepoRequest.setJsonEntity(Strings.toString(repoConfig))__            client().performRequest(createRepoRequest)__        }__        Request createSnapshot = new Request("PUT", "/_snapshot/repo/" + (isRunningAgainstOldCluster() ? "old_snap" : "new_snap"))__        createSnapshot.addParameter("wait_for_completion", "true")__        createSnapshot.setJsonEntity("{\"indices\": \"" + index + "\"}")__        client().performRequest(createSnapshot)___        checkSnapshot("old_snap", count, getOldClusterVersion())__        if (false == isRunningAgainstOldCluster()) {_            checkSnapshot("new_snap", count, Version.CURRENT)__        }_    };tests,snapshot,restore,by,creating,a,snapshot,and,restoring,it,it,takes,a,snapshot,on,the,old,cluster,and,restores,it,on,the,old,cluster,as,a,sanity,check,and,on,the,new,cluster,as,an,upgrade,test,it,also,takes,a,snapshot,on,the,new,cluster,and,restores,that,on,the,new,cluster,as,a,test,that,the,repository,is,ok,with,containing,snapshot,from,both,the,old,and,new,versions,all,of,the,snapshots,include,an,index,a,template,and,some,routing,configuration;public,void,test,snapshot,restore,throws,ioexception,int,count,if,is,running,against,old,cluster,get,old,cluster,version,major,8,count,between,200,300,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,else,count,count,of,indexed,random,documents,refresh,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,request,add,routing,settings,new,request,put,settings,add,routing,settings,set,json,entity,persistent,cluster,routing,allocation,exclude,get,old,cluster,version,client,perform,request,add,routing,settings,xcontent,builder,template,builder,json,xcontent,content,builder,start,object,template,builder,field,template,builder,start,object,settings,template,builder,field,1,template,builder,end,object,template,builder,start,object,mappings,template,builder,start,object,template,builder,field,enabled,true,template,builder,end,object,template,builder,end,object,template,builder,start,object,aliases,template,builder,start,object,alias1,end,object,template,builder,start,object,alias2,template,builder,start,object,filter,template,builder,start,object,term,template,builder,field,version,is,running,against,old,cluster,get,old,cluster,version,version,current,template,builder,end,object,template,builder,end,object,template,builder,end,object,template,builder,end,object,end,object,request,create,template,request,new,request,put,create,template,request,set,json,entity,strings,to,string,template,builder,client,perform,request,create,template,request,if,is,running,against,old,cluster,xcontent,builder,repo,config,json,xcontent,content,builder,start,object,repo,config,field,type,fs,repo,config,start,object,settings,repo,config,field,compress,random,boolean,repo,config,field,location,system,get,property,tests,path,repo,repo,config,end,object,repo,config,end,object,request,create,repo,request,new,request,put,repo,create,repo,request,set,json,entity,strings,to,string,repo,config,client,perform,request,create,repo,request,request,create,snapshot,new,request,put,repo,is,running,against,old,cluster,create,snapshot,add,parameter,true,create,snapshot,set,json,entity,indices,index,client,perform,request,create,snapshot,check,snapshot,count,get,old,cluster,version,if,false,is,running,against,old,cluster,check,snapshot,count,version,current
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1524684173;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (runningAgainstOldCluster) {_            client().performRequest("PUT", docLocation, singletonMap("refresh", "true"),_                    new StringEntity(doc, ContentType.APPLICATION_JSON))__        }__        assertThat(toStr(client().performRequest("GET", docLocation)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,running,against,old,cluster,client,perform,request,put,doc,location,singleton,map,refresh,true,new,string,entity,doc,content,type,assert,that,to,str,client,perform,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1529916083;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (runningAgainstOldCluster) {_            client().performRequest("PUT", docLocation, singletonMap("refresh", "true"),_                    new StringEntity(doc, ContentType.APPLICATION_JSON))__        }__        assertThat(toStr(client().performRequest("GET", docLocation)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,running,against,old,cluster,client,perform,request,put,doc,location,singleton,map,refresh,true,new,string,entity,doc,content,type,assert,that,to,str,client,perform,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1532353780;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (runningAgainstOldCluster) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }__        assertThat(toStr(client().performRequest(new Request("GET", docLocation))), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,assert,that,to,str,client,perform,request,new,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1535139672;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (runningAgainstOldCluster) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }__        assertThat(toStr(client().performRequest(new Request("GET", docLocation))), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,assert,that,to,str,client,perform,request,new,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1536314350;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (runningAgainstOldCluster) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }__        assertThat(toStr(client().performRequest(new Request("GET", docLocation))), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,assert,that,to,str,client,perform,request,new,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1536828374;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }__        assertThat(toStr(client().performRequest(new Request("GET", docLocation))), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,assert,that,to,str,client,perform,request,new,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1539615817;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }__        assertThat(toStr(client().performRequest(new Request("GET", docLocation))), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,assert,that,to,str,client,perform,request,new,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1540486836;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }__        assertThat(toStr(client().performRequest(new Request("GET", docLocation))), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,assert,that,to,str,client,perform,request,new,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1540583181;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }__        assertThat(toStr(client().performRequest(new Request("GET", docLocation))), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,assert,that,to,str,client,perform,request,new,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1544035746;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }__        assertThat(toStr(client().performRequest(new Request("GET", docLocation))), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,assert,that,to,str,client,perform,request,new,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1544169664;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }__        assertThat(toStr(client().performRequest(new Request("GET", docLocation))), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,assert,that,to,str,client,perform,request,new,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1544491368;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/_doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }__        assertThat(toStr(client().performRequest(new Request("GET", docLocation))), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,assert,that,to,str,client,perform,request,new,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1544499913;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/_doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }__        assertThat(toStr(client().performRequest(new Request("GET", docLocation))), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,assert,that,to,str,client,perform,request,new,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1544572729;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/_doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }__        assertThat(toStr(client().performRequest(new Request("GET", docLocation))), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,assert,that,to,str,client,perform,request,new,request,get,doc,location,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1544648252;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1544667713;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1544813247;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1545253165;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1547156119;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1547500081;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1548680839;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1548684170;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1548795161;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1549016214;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1549127354;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1549310947;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1549394143;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,doc,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1549608646;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/" + type + "/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        if (getOldClusterVersion().before(Version.V_6_7_0)) {_            request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        }_        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,type,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,if,get,old,cluster,version,before,version,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1550083218;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/" + type + "/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        if (getOldClusterVersion().before(Version.V_6_7_0)) {_            request.setOptions(expectWarnings(RestGetAction.TYPES_DEPRECATION_MESSAGE))__        }_        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,type,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,if,get,old,cluster,version,before,version,request,set,options,expect,warnings,rest,get,action,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1550227375;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/_doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testSingleDoc() throws IOException;1550504256;Tests that a single document survives. Super basic smoke test.;public void testSingleDoc() throws IOException {_        String docLocation = "/" + index + "/_doc/1"__        String doc = "{\"test\": \"test\"}"___        if (isRunningAgainstOldCluster()) {_            Request createDoc = new Request("PUT", docLocation)__            createDoc.setJsonEntity(doc)__            client().performRequest(createDoc)__        }___        Request request = new Request("GET", docLocation)__        assertThat(toStr(client().performRequest(request)), containsString(doc))__    };tests,that,a,single,document,survives,super,basic,smoke,test;public,void,test,single,doc,throws,ioexception,string,doc,location,index,1,string,doc,test,test,if,is,running,against,old,cluster,request,create,doc,new,request,put,doc,location,create,doc,set,json,entity,doc,client,perform,request,create,doc,request,request,new,request,get,doc,location,assert,that,to,str,client,perform,request,request,contains,string,doc
FullClusterRestartIT -> public void testRecovery() throws Exception;1524684173;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (runningAgainstOldCluster) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            client().performRequest("POST", "/_flush")__            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        String countResponse = toStr(client().performRequest("GET", "/" + index + "/_search", singletonMap("size", "0")))__        assertThat(countResponse, containsString("\"total\":" + count))___        if (false == runningAgainstOldCluster) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Map<String, String> params = new HashMap<>()__            params.put("h", "index,shard,type,stage,translog_ops_recovered")__            params.put("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest("GET", "/_cat/recovery/" + index, params))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___        String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__        String bwcLuceneVersion = oldClusterVersion.luceneVersion.toString()__        if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_            int numCurrentVersion = 0__            int numBwcVersion = 0__            params.clear()__            params.put("h", "prirep,shard,index,version")__            params.put("s", "prirep,shard,index")__            String segmentsResponse = toStr(_                    client().performRequest("GET", "/_cat/segments/" + index, params))__            for (String line : segmentsResponse.split("\n")) {_                if (false == line.startsWith("p")) {_                    continue__                }_                Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                assertTrue(line, m.find())__                String version = m.group(1)__                if (currentLuceneVersion.equals(version)) {_                    numCurrentVersion++__                } else if (bwcLuceneVersion.equals(version)) {_                    numBwcVersion++__                } else {_                    fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                }_            }_            assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                0, numCurrentVersion)__            assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)_}_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,client,perform,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,string,count,response,to,str,client,perform,request,get,index,singleton,map,size,0,assert,that,count,response,contains,string,total,count,if,false,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,map,string,string,params,new,hash,map,params,put,h,index,shard,type,stage,params,put,s,index,shard,type,string,recovery,response,to,str,client,perform,request,get,recovery,index,params,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,params,clear,params,put,h,prirep,shard,index,version,params,put,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,get,segments,index,params,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1529916083;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (runningAgainstOldCluster) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        String countResponse = toStr(client().performRequest("GET", "/" + index + "/_search", singletonMap("size", "0")))__        assertThat(countResponse, containsString("\"total\":" + count))___        if (false == runningAgainstOldCluster) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Map<String, String> params = new HashMap<>()__            params.put("h", "index,shard,type,stage,translog_ops_recovered")__            params.put("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest("GET", "/_cat/recovery/" + index, params))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___        String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__        String bwcLuceneVersion = oldClusterVersion.luceneVersion.toString()__        if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_            int numCurrentVersion = 0__            int numBwcVersion = 0__            params.clear()__            params.put("h", "prirep,shard,index,version")__            params.put("s", "prirep,shard,index")__            String segmentsResponse = toStr(_                    client().performRequest("GET", "/_cat/segments/" + index, params))__            for (String line : segmentsResponse.split("\n")) {_                if (false == line.startsWith("p")) {_                    continue__                }_                Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                assertTrue(line, m.find())__                String version = m.group(1)__                if (currentLuceneVersion.equals(version)) {_                    numCurrentVersion++__                } else if (bwcLuceneVersion.equals(version)) {_                    numBwcVersion++__                } else {_                    fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                }_            }_            assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                0, numCurrentVersion)__            assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)_}_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,string,count,response,to,str,client,perform,request,get,index,singleton,map,size,0,assert,that,count,response,contains,string,total,count,if,false,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,map,string,string,params,new,hash,map,params,put,h,index,shard,type,stage,params,put,s,index,shard,type,string,recovery,response,to,str,client,perform,request,get,recovery,index,params,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,params,clear,params,put,h,prirep,shard,index,version,params,put,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,get,segments,index,params,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1532353780;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (runningAgainstOldCluster) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        if (false == runningAgainstOldCluster) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___        String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__        String bwcLuceneVersion = oldClusterVersion.luceneVersion.toString()__        if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_            int numCurrentVersion = 0__            int numBwcVersion = 0__            Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__            segmentsRequest.addParameter("h", "prirep,shard,index,version")__            segmentsRequest.addParameter("s", "prirep,shard,index")__            String segmentsResponse = toStr(client().performRequest(segmentsRequest))__            for (String line : segmentsResponse.split("\n")) {_                if (false == line.startsWith("p")) {_                    continue__                }_                Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                assertTrue(line, m.find())__                String version = m.group(1)__                if (currentLuceneVersion.equals(version)) {_                    numCurrentVersion++__                } else if (bwcLuceneVersion.equals(version)) {_                    numBwcVersion++__                } else {_                    fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                }_            }_            assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                0, numCurrentVersion)__            assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)_}_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,if,false,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1535139672;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (runningAgainstOldCluster) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        if (false == runningAgainstOldCluster) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___        String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__        String bwcLuceneVersion = oldClusterVersion.luceneVersion.toString()__        if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_            int numCurrentVersion = 0__            int numBwcVersion = 0__            Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__            segmentsRequest.addParameter("h", "prirep,shard,index,version")__            segmentsRequest.addParameter("s", "prirep,shard,index")__            String segmentsResponse = toStr(client().performRequest(segmentsRequest))__            for (String line : segmentsResponse.split("\n")) {_                if (false == line.startsWith("p")) {_                    continue__                }_                Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                assertTrue(line, m.find())__                String version = m.group(1)__                if (currentLuceneVersion.equals(version)) {_                    numCurrentVersion++__                } else if (bwcLuceneVersion.equals(version)) {_                    numBwcVersion++__                } else {_                    fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                }_            }_            assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                0, numCurrentVersion)__            assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)_}_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,if,false,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1536314350;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (runningAgainstOldCluster) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        if (false == runningAgainstOldCluster) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___        String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__        String bwcLuceneVersion = oldClusterVersion.luceneVersion.toString()__        if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_            int numCurrentVersion = 0__            int numBwcVersion = 0__            Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__            segmentsRequest.addParameter("h", "prirep,shard,index,version")__            segmentsRequest.addParameter("s", "prirep,shard,index")__            String segmentsResponse = toStr(client().performRequest(segmentsRequest))__            for (String line : segmentsResponse.split("\n")) {_                if (false == line.startsWith("p")) {_                    continue__                }_                Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                assertTrue(line, m.find())__                String version = m.group(1)__                if (currentLuceneVersion.equals(version)) {_                    numCurrentVersion++__                } else if (bwcLuceneVersion.equals(version)) {_                    numBwcVersion++__                } else {_                    fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                }_            }_            assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                0, numCurrentVersion)__            assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)_}_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,if,false,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1536828374;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___        String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__        String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__        if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_            int numCurrentVersion = 0__            int numBwcVersion = 0__            Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__            segmentsRequest.addParameter("h", "prirep,shard,index,version")__            segmentsRequest.addParameter("s", "prirep,shard,index")__            String segmentsResponse = toStr(client().performRequest(segmentsRequest))__            for (String line : segmentsResponse.split("\n")) {_                if (false == line.startsWith("p")) {_                    continue__                }_                Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                assertTrue(line, m.find())__                String version = m.group(1)__                if (currentLuceneVersion.equals(version)) {_                    numCurrentVersion++__                } else if (bwcLuceneVersion.equals(version)) {_                    numBwcVersion++__                } else {_                    fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                }_            }_            assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                0, numCurrentVersion)__            assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)_}_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1539615817;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1540486836;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1540583181;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        String countResponse = toStr(client().performRequest(countRequest))__        assertThat(countResponse, containsString("\"total\":" + count))___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,string,count,response,to,str,client,perform,request,count,request,assert,that,count,response,contains,string,total,count,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1544035746;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1544169664;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1544491368;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1544499913;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1544572729;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1544648252;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1544667713;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1544813247;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1545253165;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1547156119;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1547500081;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1548680839;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1548684170;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1548795161;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1549016214;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1549127354;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1549310947;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1549394143;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(count / 10, false , false,_                    i -> jsonBuilder().startObject().field("field", "value").endObject())__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1549608646;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(_                        count / 10,_                        false, _                        false,_                        i -> jsonBuilder().startObject().field("field", "value").endObject()_                )__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        refresh()__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,refresh,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1550083218;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(_                        count / 10,_                        false, _                        false,_                        i -> jsonBuilder().startObject().field("field", "value").endObject()_                )__            }_            saveInfoDocument("should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument("should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        refresh()__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,request,count,request,new,request,get,index,count,request,add,parameter,size,0,refresh,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1550227375;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(_                        count / 10,_                        false, _                        false,_                        i -> jsonBuilder().startObject().field("field", "value").endObject()_                )__            }_            saveInfoDocument(index + "_should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument(index + "_should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        refresh()__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,index,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,index,request,count,request,new,request,get,index,count,request,add,parameter,size,0,refresh,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
FullClusterRestartIT -> public void testRecovery() throws Exception;1550504256;Tests recovery of an index with or without a translog and the_statistics we gather about that.;public void testRecovery() throws Exception {_        int count__        boolean shouldHaveTranslog__        if (isRunningAgainstOldCluster()) {_            count = between(200, 300)__            _            shouldHaveTranslog = randomBoolean()___            indexRandomDocuments(count, true, true, i -> jsonBuilder().startObject().field("field", "value").endObject())___            _            ensureGreen(index)__            _            if (randomBoolean()) {_                _                _                assertBusy(() -> {_                    try {_                        Response resp = client().performRequest(new Request("POST", index + "/_flush/synced"))__                        Map<String, Object> result = ObjectPath.createFromResponse(resp).evaluate("_shards")__                        assertThat(result.get("successful"), equalTo(result.get("total")))__                        assertThat(result.get("failed"), equalTo(0))__                    } catch (ResponseException ex) {_                        throw new AssertionError(ex)_ _                    }_                })__            } else {_                _                assertOK(client().performRequest(new Request("POST", "/_flush")))__            }_            if (shouldHaveTranslog) {_                _                indexRandomDocuments(_                        count / 10,_                        false, _                        false,_                        i -> jsonBuilder().startObject().field("field", "value").endObject()_                )__            }_            saveInfoDocument(index + "_should_have_translog", Boolean.toString(shouldHaveTranslog))__        } else {_            count = countOfIndexedRandomDocuments()__            shouldHaveTranslog = Booleans.parseBoolean(loadInfoDocument(index + "_should_have_translog"))__        }__        _        Request countRequest = new Request("GET", "/" + index + "/_search")__        countRequest.addParameter("size", "0")__        refresh()__        Map<String, Object> countResponse = entityAsMap(client().performRequest(countRequest))__        assertTotalHits(count, countResponse)___        if (false == isRunningAgainstOldCluster()) {_            boolean restoredFromTranslog = false__            boolean foundPrimary = false__            Request recoveryRequest = new Request("GET", "/_cat/recovery/" + index)__            recoveryRequest.addParameter("h", "index,shard,type,stage,translog_ops_recovered")__            recoveryRequest.addParameter("s", "index,shard,type")__            String recoveryResponse = toStr(client().performRequest(recoveryRequest))__            for (String line : recoveryResponse.split("\n")) {_                _                foundPrimary = true__                if (false == line.contains("done") && line.contains("existing_store")) {_                    continue__                }_                _                Matcher m = Pattern.compile("(\\d+)$").matcher(line)__                assertTrue(line, m.find())__                int translogOps = Integer.parseInt(m.group(1))__                if (translogOps > 0) {_                    restoredFromTranslog = true__                }_            }_            assertTrue("expected to find a primary but didn't\n" + recoveryResponse, foundPrimary)__            assertEquals("mismatch while checking for translog recovery\n" + recoveryResponse, shouldHaveTranslog, restoredFromTranslog)___            String currentLuceneVersion = Version.CURRENT.luceneVersion.toString()__            String bwcLuceneVersion = getOldClusterVersion().luceneVersion.toString()__            if (shouldHaveTranslog && false == currentLuceneVersion.equals(bwcLuceneVersion)) {_                int numCurrentVersion = 0__                int numBwcVersion = 0__                Request segmentsRequest = new Request("GET", "/_cat/segments/" + index)__                segmentsRequest.addParameter("h", "prirep,shard,index,version")__                segmentsRequest.addParameter("s", "prirep,shard,index")__                String segmentsResponse = toStr(client().performRequest(segmentsRequest))__                for (String line : segmentsResponse.split("\n")) {_                    if (false == line.startsWith("p")) {_                        continue__                    }_                    Matcher m = Pattern.compile("(\\d+\\.\\d+\\.\\d+)$").matcher(line)__                    assertTrue(line, m.find())__                    String version = m.group(1)__                    if (currentLuceneVersion.equals(version)) {_                        numCurrentVersion++__                    } else if (bwcLuceneVersion.equals(version)) {_                        numBwcVersion++__                    } else {_                        fail("expected version to be one of [" + currentLuceneVersion + "," + bwcLuceneVersion + "] but was " + line)__                    }_                }_                assertNotEquals("expected at least 1 current segment after translog recovery. segments:\n" + segmentsResponse,_                    0, numCurrentVersion)__                assertNotEquals("expected at least 1 old segment. segments:\n" + segmentsResponse, 0, numBwcVersion)__            }_        }_    };tests,recovery,of,an,index,with,or,without,a,translog,and,the,statistics,we,gather,about,that;public,void,test,recovery,throws,exception,int,count,boolean,should,have,translog,if,is,running,against,old,cluster,count,between,200,300,should,have,translog,random,boolean,index,random,documents,count,true,true,i,json,builder,start,object,field,field,value,end,object,ensure,green,index,if,random,boolean,assert,busy,try,response,resp,client,perform,request,new,request,post,index,synced,map,string,object,result,object,path,create,from,response,resp,evaluate,assert,that,result,get,successful,equal,to,result,get,total,assert,that,result,get,failed,equal,to,0,catch,response,exception,ex,throw,new,assertion,error,ex,else,assert,ok,client,perform,request,new,request,post,if,should,have,translog,index,random,documents,count,10,false,false,i,json,builder,start,object,field,field,value,end,object,save,info,document,index,boolean,to,string,should,have,translog,else,count,count,of,indexed,random,documents,should,have,translog,booleans,parse,boolean,load,info,document,index,request,count,request,new,request,get,index,count,request,add,parameter,size,0,refresh,map,string,object,count,response,entity,as,map,client,perform,request,count,request,assert,total,hits,count,count,response,if,false,is,running,against,old,cluster,boolean,restored,from,translog,false,boolean,found,primary,false,request,recovery,request,new,request,get,recovery,index,recovery,request,add,parameter,h,index,shard,type,stage,recovery,request,add,parameter,s,index,shard,type,string,recovery,response,to,str,client,perform,request,recovery,request,for,string,line,recovery,response,split,n,found,primary,true,if,false,line,contains,done,line,contains,continue,matcher,m,pattern,compile,d,matcher,line,assert,true,line,m,find,int,translog,ops,integer,parse,int,m,group,1,if,translog,ops,0,restored,from,translog,true,assert,true,expected,to,find,a,primary,but,didn,t,n,recovery,response,found,primary,assert,equals,mismatch,while,checking,for,translog,recovery,n,recovery,response,should,have,translog,restored,from,translog,string,current,lucene,version,version,current,lucene,version,to,string,string,bwc,lucene,version,get,old,cluster,version,lucene,version,to,string,if,should,have,translog,false,current,lucene,version,equals,bwc,lucene,version,int,num,current,version,0,int,num,bwc,version,0,request,segments,request,new,request,get,segments,index,segments,request,add,parameter,h,prirep,shard,index,version,segments,request,add,parameter,s,prirep,shard,index,string,segments,response,to,str,client,perform,request,segments,request,for,string,line,segments,response,split,n,if,false,line,starts,with,p,continue,matcher,m,pattern,compile,d,d,d,matcher,line,assert,true,line,m,find,string,version,m,group,1,if,current,lucene,version,equals,version,num,current,version,else,if,bwc,lucene,version,equals,version,num,bwc,version,else,fail,expected,version,to,be,one,of,current,lucene,version,bwc,lucene,version,but,was,line,assert,not,equals,expected,at,least,1,current,segment,after,translog,recovery,segments,n,segments,response,0,num,current,version,assert,not,equals,expected,at,least,1,old,segment,segments,n,segments,response,0,num,bwc,version
