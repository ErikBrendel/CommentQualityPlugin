commented;modifiers;parameterAmount;loc;comment;code
false;public;1;12;;@Override @SuppressForbidden(reason = "PathUtils#get is fine - we don't have environment here") public void setUp(SampleRecorder sampleRecorder) {     BlockingQueue<List<String>> bulkQueue = new ArrayBlockingQueue<>(256).     BulkIndexer runner = new BulkIndexer(bulkQueue, warmupIterations, measurementIterations, sampleRecorder, requestExecutor).     executorService = Executors.newSingleThreadExecutor((r) -> new Thread(r, "bulk-index-runner")).     executorService.submit(runner).     generator = new LoadGenerator(PathUtils.get(indexFilePath), bulkQueue, bulkSize). }
false;public;0;13;;@Override @SuppressForbidden(reason = "system out is ok for a command line tool") public void run() throws Exception {     generator.execute().     // when the generator is done, there are no more data -> shutdown client     executorService.shutdown().     // We need to wait until the queue is drained     final boolean finishedNormally = executorService.awaitTermination(20, TimeUnit.MINUTES).     if (finishedNormally == false) {         System.err.println("Background tasks are still running after timeout on enclosing pool. Forcing pool shutdown.").         executorService.shutdownNow().     } }
false;public;0;4;;@Override public void tearDown() { // no op }
false;public;0;26;;@SuppressForbidden(reason = "Classic I/O is fine in non-production code") public void execute() {     try (BufferedReader reader = Files.newBufferedReader(bulkDataFile, StandardCharsets.UTF_8)) {         String line.         int bulkIndex = 0.         List<String> bulkData = new ArrayList<>(bulkSize).         while ((line = reader.readLine()) != null) {             if (bulkIndex == bulkSize) {                 sendBulk(bulkData).                 // reset data structures                 bulkData = new ArrayList<>(bulkSize).                 bulkIndex = 0.             }             bulkData.add(line).             bulkIndex++.         }         // also send the last bulk:         if (bulkIndex > 0) {             sendBulk(bulkData).         }     } catch (IOException e) {         throw new ElasticsearchException(e).     } catch (InterruptedException e) {         Thread.currentThread().interrupt().     } }
false;private;1;3;;private void sendBulk(List<String> bulkData) throws InterruptedException {     bulkQueue.put(bulkData). }
false;public;0;24;;@Override public void run() {     for (int iteration = 0. iteration < warmupIterations + measurementIterations. iteration++) {         boolean success = false.         List<String> currentBulk.         try {             currentBulk = bulkData.take().         } catch (InterruptedException e) {             Thread.currentThread().interrupt().             return.         }         // measure only service time, latency is not that interesting for a throughput benchmark         long start = System.nanoTime().         try {             success = bulkRequestExecutor.bulkIndex(currentBulk).         } catch (Exception ex) {             logger.warn("Error while executing bulk request", ex).         }         long stop = System.nanoTime().         if (iteration < warmupIterations) {             sampleRecorder.addSample(new Sample("bulk", start, start, stop, success)).         }     } }
