commented;modifiers;parameterAmount;loc;comment;code
false;public;0;3;;public String getJobId() {     return jobId. }
true;public;0;3;/**  * Number of records processed by this job.  * This value is the number of records sent passed on to  * the engine i.e. {@linkplain #getInputRecordCount()} minus  * records with bad dates or out of order  *  * @return Number of records processed by this job {@code long}  */ ;/**  * Number of records processed by this job.  * This value is the number of records sent passed on to  * the engine i.e. {@linkplain #getInputRecordCount()} minus  * records with bad dates or out of order  *  * @return Number of records processed by this job {@code long}  */ public long getProcessedRecordCount() {     return processedRecordCount. }
true;public;0;3;/**  * Number of data points (processed record count * the number  * of analysed fields) processed by this job. This count does  * not include the time field.  *  * @return Number of data points processed by this job {@code long}  */ ;/**  * Number of data points (processed record count * the number  * of analysed fields) processed by this job. This count does  * not include the time field.  *  * @return Number of data points processed by this job {@code long}  */ public long getProcessedFieldCount() {     return processedFieldCount. }
true;public;0;4;/**  * Total number of input records read.  * This = processed record count + date parse error records count  * + out of order record count.  * <p>  * Records with missing fields are counted as they are still written.  *  * @return Total number of input records read {@code long}  */ ;/**  * Total number of input records read.  * This = processed record count + date parse error records count  * + out of order record count.  * <p>  * Records with missing fields are counted as they are still written.  *  * @return Total number of input records read {@code long}  */ public long getInputRecordCount() {     return processedRecordCount + outOfOrderTimeStampCount + invalidDateCount. }
true;public;0;3;/**  * The total number of bytes sent to this job.  * This value includes the bytes from any  records  * that have been discarded for any  reason  * e.g. because the date cannot be read  *  * @return Volume in bytes  */ ;/**  * The total number of bytes sent to this job.  * This value includes the bytes from any  records  * that have been discarded for any  reason  * e.g. because the date cannot be read  *  * @return Volume in bytes  */ public long getInputBytes() {     return inputBytes. }
true;public;0;3;/**  * The total number of fields sent to the job  * including fields that aren't analysed.  *  * @return The total number of fields sent to the job  */ ;/**  * The total number of fields sent to the job  * including fields that aren't analysed.  *  * @return The total number of fields sent to the job  */ public long getInputFieldCount() {     return inputFieldCount. }
true;public;0;3;/**  * The number of records with an invalid date field that could  * not be parsed or converted to epoch time.  *  * @return The number of records with an invalid date field  */ ;/**  * The number of records with an invalid date field that could  * not be parsed or converted to epoch time.  *  * @return The number of records with an invalid date field  */ public long getInvalidDateCount() {     return invalidDateCount. }
true;public;0;3;/**  * The number of missing fields that had been  * configured for analysis.  *  * @return The number of missing fields  */ ;/**  * The number of missing fields that had been  * configured for analysis.  *  * @return The number of missing fields  */ public long getMissingFieldCount() {     return missingFieldCount. }
true;public;0;3;/**  * The number of records with a timestamp that is  * before the time of the latest record. Records should  * be in ascending chronological order  *  * @return The number of records with a timestamp that is before the time of the latest record  */ ;/**  * The number of records with a timestamp that is  * before the time of the latest record. Records should  * be in ascending chronological order  *  * @return The number of records with a timestamp that is before the time of the latest record  */ public long getOutOfOrderTimeStampCount() {     return outOfOrderTimeStampCount. }
true;public;0;3;/**  * The number of buckets with no records in it. Used to measure general data fitness and/or  * configuration problems (bucket span).  *  * @return Number of empty buckets processed by this job {@code long}  */ ;/**  * The number of buckets with no records in it. Used to measure general data fitness and/or  * configuration problems (bucket span).  *  * @return Number of empty buckets processed by this job {@code long}  */ public long getEmptyBucketCount() {     return emptyBucketCount. }
true;public;0;3;/**  * The number of buckets with few records compared to the overall counts.  * Used to measure general data fitness and/or configuration problems (bucket span).  *  * @return Number of sparse buckets processed by this job {@code long}  */ ;/**  * The number of buckets with few records compared to the overall counts.  * Used to measure general data fitness and/or configuration problems (bucket span).  *  * @return Number of sparse buckets processed by this job {@code long}  */ public long getSparseBucketCount() {     return sparseBucketCount. }
true;public;0;3;/**  * The number of buckets overall.  *  * @return Number of buckets processed by this job {@code long}  */ ;/**  * The number of buckets overall.  *  * @return Number of buckets processed by this job {@code long}  */ public long getBucketCount() {     return bucketCount. }
true;public;0;3;/**  * The time of the first record seen.  *  * @return The first record time  */ ;/**  * The time of the first record seen.  *  * @return The first record time  */ public Date getEarliestRecordTimeStamp() {     return earliestRecordTimeStamp. }
true;public;0;3;/**  * The time of the latest record seen.  *  * @return Latest record time  */ ;/**  * The time of the latest record seen.  *  * @return Latest record time  */ public Date getLatestRecordTimeStamp() {     return latestRecordTimeStamp. }
true;public;0;3;/**  * The wall clock time the latest record was seen.  *  * @return Wall clock time of the lastest record  */ ;/**  * The wall clock time the latest record was seen.  *  * @return Wall clock time of the lastest record  */ public Date getLastDataTimeStamp() {     return lastDataTimeStamp. }
true;public;0;3;/**  * The time of the latest empty bucket seen.  *  * @return Latest empty bucket time  */ ;/**  * The time of the latest empty bucket seen.  *  * @return Latest empty bucket time  */ public Date getLatestEmptyBucketTimeStamp() {     return latestEmptyBucketTimeStamp. }
true;public;0;3;/**  * The time of the latest sparse bucket seen.  *  * @return Latest sparse bucket time  */ ;/**  * The time of the latest sparse bucket seen.  *  * @return Latest sparse bucket time  */ public Date getLatestSparseBucketTimeStamp() {     return latestSparseBucketTimeStamp. }
false;public;2;40;;@Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException {     builder.startObject().     builder.field(Job.ID.getPreferredName(), jobId).     builder.field(PROCESSED_RECORD_COUNT.getPreferredName(), processedRecordCount).     builder.field(PROCESSED_FIELD_COUNT.getPreferredName(), processedFieldCount).     builder.field(INPUT_BYTES.getPreferredName(), inputBytes).     builder.field(INPUT_FIELD_COUNT.getPreferredName(), inputFieldCount).     builder.field(INVALID_DATE_COUNT.getPreferredName(), invalidDateCount).     builder.field(MISSING_FIELD_COUNT.getPreferredName(), missingFieldCount).     builder.field(OUT_OF_ORDER_TIME_COUNT.getPreferredName(), outOfOrderTimeStampCount).     builder.field(EMPTY_BUCKET_COUNT.getPreferredName(), emptyBucketCount).     builder.field(SPARSE_BUCKET_COUNT.getPreferredName(), sparseBucketCount).     builder.field(BUCKET_COUNT.getPreferredName(), bucketCount).     if (earliestRecordTimeStamp != null) {         builder.timeField(EARLIEST_RECORD_TIME.getPreferredName(), EARLIEST_RECORD_TIME.getPreferredName() + "_string", earliestRecordTimeStamp.getTime()).     }     if (latestRecordTimeStamp != null) {         builder.timeField(LATEST_RECORD_TIME.getPreferredName(), LATEST_RECORD_TIME.getPreferredName() + "_string", latestRecordTimeStamp.getTime()).     }     if (lastDataTimeStamp != null) {         builder.timeField(LAST_DATA_TIME.getPreferredName(), LAST_DATA_TIME.getPreferredName() + "_string", lastDataTimeStamp.getTime()).     }     if (latestEmptyBucketTimeStamp != null) {         builder.timeField(LATEST_EMPTY_BUCKET_TIME.getPreferredName(), LATEST_EMPTY_BUCKET_TIME.getPreferredName() + "_string", latestEmptyBucketTimeStamp.getTime()).     }     if (latestSparseBucketTimeStamp != null) {         builder.timeField(LATEST_SPARSE_BUCKET_TIME.getPreferredName(), LATEST_SPARSE_BUCKET_TIME.getPreferredName() + "_string", latestSparseBucketTimeStamp.getTime()).     }     builder.field(INPUT_RECORD_COUNT.getPreferredName(), getInputRecordCount()).     builder.endObject().     return builder. }
true;public;1;29;/**  * Equality test  */ ;/**  * Equality test  */ @Override public boolean equals(Object other) {     if (this == other) {         return true.     }     if (other == null || getClass() != other.getClass()) {         return false.     }     DataCounts that = (DataCounts) other.     return Objects.equals(this.jobId, that.jobId) && this.processedRecordCount == that.processedRecordCount && this.processedFieldCount == that.processedFieldCount && this.inputBytes == that.inputBytes && this.inputFieldCount == that.inputFieldCount && this.invalidDateCount == that.invalidDateCount && this.missingFieldCount == that.missingFieldCount && this.outOfOrderTimeStampCount == that.outOfOrderTimeStampCount && this.emptyBucketCount == that.emptyBucketCount && this.sparseBucketCount == that.sparseBucketCount && this.bucketCount == that.bucketCount && Objects.equals(this.latestRecordTimeStamp, that.latestRecordTimeStamp) && Objects.equals(this.earliestRecordTimeStamp, that.earliestRecordTimeStamp) && Objects.equals(this.lastDataTimeStamp, that.lastDataTimeStamp) && Objects.equals(this.latestEmptyBucketTimeStamp, that.latestEmptyBucketTimeStamp) && Objects.equals(this.latestSparseBucketTimeStamp, that.latestSparseBucketTimeStamp). }
false;public;0;7;;@Override public int hashCode() {     return Objects.hash(jobId, processedRecordCount, processedFieldCount, inputBytes, inputFieldCount, invalidDateCount, missingFieldCount, outOfOrderTimeStampCount, lastDataTimeStamp, emptyBucketCount, sparseBucketCount, bucketCount, latestRecordTimeStamp, earliestRecordTimeStamp, latestEmptyBucketTimeStamp, latestSparseBucketTimeStamp). }
