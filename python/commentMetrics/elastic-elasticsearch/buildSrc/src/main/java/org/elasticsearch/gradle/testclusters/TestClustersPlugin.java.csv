commented;modifiers;parameterAmount;loc;comment;code
false;public;1;79;;@Override public void apply(Project project) {     Project rootProject = project.getRootProject().     // enable the DSL to describe clusters     NamedDomainObjectContainer<ElasticsearchNode> container = createTestClustersContainerExtension(project).     // provide a task to be able to list defined clusters.     createListClustersTask(project, container).     // create DSL for tasks to mark clusters these use     createUseClusterTaskExtension(project).     // done only once even if the plugin is applied multiple times as a part of multi project build     if (rootProject.getConfigurations().findByName(HELPER_CONFIGURATION_NAME) == null) {         // We use a single configuration on the root project to resolve all testcluster dependencies ( like distros )         // at once, only once without the need to repeat it for each project. This pays off assuming that most         // projects use the same dependencies.         Configuration helperConfiguration = project.getRootProject().getConfigurations().create(HELPER_CONFIGURATION_NAME).         helperConfiguration.setDescription("Internal helper configuration used by cluster configuration to download " + "ES distributions and plugins.").         helperConfiguration.getIncoming().afterResolve(resolvableDependencies -> {             Set<ComponentArtifactIdentifier> nonZipComponents = resolvableDependencies.getArtifacts().getArtifacts().stream().filter(artifact -> artifact.getFile().getName().endsWith(".zip") == false).map(artifact -> artifact.getId()).collect(Collectors.toSet()).             if (nonZipComponents.isEmpty() == false) {                 throw new IllegalStateException("Dependencies with non-zip artifacts found in configuration '" + TestClustersPlugin.HELPER_CONFIGURATION_NAME + "': " + nonZipComponents).             }         }).         // When running in the Daemon it's possible for this to hold references to past         usedClusters.clear().         claimsInventory.clear().         runningClusters.clear().         // We have a single task to sync the helper configuration to "artifacts dir"         // the clusters will look for artifacts there based on the naming conventions.         // Tasks that use a cluster will add this as a dependency automatically so it's guaranteed to run early in         // the build.         rootProject.getTasks().create(SYNC_ARTIFACTS_TASK_NAME, Sync.class, sync -> {             sync.from((Callable<List<FileTree>>) () -> helperConfiguration.getFiles().stream().map(project::zipTree).collect(Collectors.toList())).             sync.into(new File(getTestClustersConfigurationExtractDir(project), "zip")).         }).         // When we know what tasks will run, we claim the clusters of those task to differentiate between clusters         // that are defined in the build script and the ones that will actually be used in this invocation of gradle         // we use this information to determine when the last task that required the cluster executed so that we can         // terminate the cluster right away and free up resources.         configureClaimClustersHook(project).         // Before each task, we determine if a cluster needs to be started for that task.         configureStartClustersHook(project).         // After each task we determine if there are clusters that are no longer needed.         configureStopClustersHook(project).         // configure hooks to make sure no test cluster processes survive the build         configureCleanupHooks(project).         // Since we have everything modeled in the DSL, add all the required dependencies e.x. the distribution to the         // configuration so the user doesn't have to repeat this.         autoConfigureClusterDependencies(project, rootProject, container).     } }
false;private;1;15;;private NamedDomainObjectContainer<ElasticsearchNode> createTestClustersContainerExtension(Project project) {     // Create an extensions that allows describing clusters     NamedDomainObjectContainer<ElasticsearchNode> container = project.container(ElasticsearchNode.class, name -> new ElasticsearchNode(project.getPath(), name, GradleServicesAdapter.getInstance(project), getTestClustersConfigurationExtractDir(project), new File(project.getBuildDir(), "testclusters"))).     project.getExtensions().add(NODE_EXTENSION_NAME, container).     return container. }
false;private;2;10;;private void createListClustersTask(Project project, NamedDomainObjectContainer<ElasticsearchNode> container) {     Task listTask = project.getTasks().create(LIST_TASK_NAME).     listTask.setGroup("ES cluster formation").     listTask.setDescription("Lists all ES clusters configured for this project").     listTask.doLast((Task task) -> container.forEach(cluster -> logger.lifecycle("   * {}: {}", cluster.getName(), cluster.getDistribution()))). }
false;public;1;11;;public void doCall(ElasticsearchNode node) {     Object thisObject = this.getThisObject().     if (thisObject instanceof Task == false) {         throw new AssertionError("Expected " + thisObject + " to be an instance of " + "Task, but got: " + thisObject.getClass()).     }     usedClusters.computeIfAbsent(task, k -> new ArrayList<>()).add(node).     ((Task) thisObject).dependsOn(project.getRootProject().getTasks().getByName(SYNC_ARTIFACTS_TASK_NAME)). }
false;private,static;1;22;;private static void createUseClusterTaskExtension(Project project) {     // register an extension for all current and future tasks, so that any task can declare that it wants to use a     // specific cluster.     project.getTasks().all((Task task) -> task.getExtensions().findByType(ExtraPropertiesExtension.class).set("useCluster", new Closure<Void>(project, task) {          public void doCall(ElasticsearchNode node) {             Object thisObject = this.getThisObject().             if (thisObject instanceof Task == false) {                 throw new AssertionError("Expected " + thisObject + " to be an instance of " + "Task, but got: " + thisObject.getClass()).             }             usedClusters.computeIfAbsent(task, k -> new ArrayList<>()).add(node).             ((Task) thisObject).dependsOn(project.getRootProject().getTasks().getByName(SYNC_ARTIFACTS_TASK_NAME)).         }     })). }
false;private,static;1;13;;private static void configureClaimClustersHook(Project project) {     project.getGradle().getTaskGraph().whenReady(taskExecutionGraph -> taskExecutionGraph.getAllTasks().forEach(task -> usedClusters.getOrDefault(task, Collections.emptyList()).forEach(each -> {         synchronized (claimsInventory) {             claimsInventory.put(each, claimsInventory.getOrDefault(each, 0) + 1).         }         each.freeze().     }))). }
false;public;1;13;;@Override public void beforeActions(Task task) {     // we only start the cluster before the actions, so we'll not start it if the task is up-to-date     final List<ElasticsearchNode> clustersToStart.     synchronized (runningClusters) {         clustersToStart = usedClusters.getOrDefault(task, Collections.emptyList()).stream().filter(each -> runningClusters.contains(each) == false).collect(Collectors.toList()).         runningClusters.addAll(clustersToStart).     }     clustersToStart.forEach(ElasticsearchNode::start). }
false;public;1;2;;@Override public void afterActions(Task task) { }
false;private,static;1;21;;private static void configureStartClustersHook(Project project) {     project.getGradle().addListener(new TaskActionListener() {          @Override         public void beforeActions(Task task) {             // we only start the cluster before the actions, so we'll not start it if the task is up-to-date             final List<ElasticsearchNode> clustersToStart.             synchronized (runningClusters) {                 clustersToStart = usedClusters.getOrDefault(task, Collections.emptyList()).stream().filter(each -> runningClusters.contains(each) == false).collect(Collectors.toList()).                 runningClusters.addAll(clustersToStart).             }             clustersToStart.forEach(ElasticsearchNode::start).         }          @Override         public void afterActions(Task task) {         }     }). }
false;public;2;32;;@Override public void afterExecute(Task task, TaskState state) {     // always unclaim the cluster, even if _this_ task is up-to-date, as others might not have been     // and caused the cluster to start.     List<ElasticsearchNode> clustersUsedByTask = usedClusters.getOrDefault(task, Collections.emptyList()).     if (state.getFailure() != null) {         // If the task fails, and other tasks use this cluster, the other task will likely never be         // executed at all, so we will never get to un-claim and terminate it.         // The downside is that with multi project builds if that other  task is in a different         // project and executing right now, we may terminate the cluster while it's running it.         clustersUsedByTask.forEach(each -> each.stop(true)).     } else {         clustersUsedByTask.forEach(each -> {             synchronized (claimsInventory) {                 claimsInventory.put(each, claimsInventory.get(each) - 1).             }         }).         final List<ElasticsearchNode> stoppable.         synchronized (runningClusters) {             stoppable = claimsInventory.entrySet().stream().filter(entry -> entry.getValue() == 0).filter(entry -> runningClusters.contains(entry.getKey())).map(Map.Entry::getKey).collect(Collectors.toList()).             runningClusters.removeAll(stoppable).         }         stoppable.forEach(each -> each.stop(false)).     } }
false;public;1;2;;@Override public void beforeExecute(Task task) { }
false;private,static;1;40;;private static void configureStopClustersHook(Project project) {     project.getGradle().addListener(new TaskExecutionListener() {          @Override         public void afterExecute(Task task, TaskState state) {             // always unclaim the cluster, even if _this_ task is up-to-date, as others might not have been             // and caused the cluster to start.             List<ElasticsearchNode> clustersUsedByTask = usedClusters.getOrDefault(task, Collections.emptyList()).             if (state.getFailure() != null) {                 // If the task fails, and other tasks use this cluster, the other task will likely never be                 // executed at all, so we will never get to un-claim and terminate it.                 // The downside is that with multi project builds if that other  task is in a different                 // project and executing right now, we may terminate the cluster while it's running it.                 clustersUsedByTask.forEach(each -> each.stop(true)).             } else {                 clustersUsedByTask.forEach(each -> {                     synchronized (claimsInventory) {                         claimsInventory.put(each, claimsInventory.get(each) - 1).                     }                 }).                 final List<ElasticsearchNode> stoppable.                 synchronized (runningClusters) {                     stoppable = claimsInventory.entrySet().stream().filter(entry -> entry.getValue() == 0).filter(entry -> runningClusters.contains(entry.getKey())).map(Map.Entry::getKey).collect(Collectors.toList()).                     runningClusters.removeAll(stoppable).                 }                 stoppable.forEach(each -> each.stop(false)).             }         }          @Override         public void beforeExecute(Task task) {         }     }). }
false;static;1;3;;static File getTestClustersConfigurationExtractDir(Project project) {     return new File(project.getRootProject().getBuildDir(), "testclusters/extract"). }
true;public,static;1;5;/**  * Boilerplate to get testClusters container extension  *  * Equivalent to project.testClusters in the DSL  */ ;/**  * Boilerplate to get testClusters container extension  *  * Equivalent to project.testClusters in the DSL  */ @SuppressWarnings("unchecked") public static NamedDomainObjectContainer<ElasticsearchNode> getNodeExtension(Project project) {     return (NamedDomainObjectContainer<ElasticsearchNode>) project.getExtensions().getByName(NODE_EXTENSION_NAME). }
false;private,static;3;20;;private static void autoConfigureClusterDependencies(Project project, Project rootProject, NamedDomainObjectContainer<ElasticsearchNode> container) {     // When the project evaluated we know of all tasks that use clusters.     // Each of these have to depend on the artifacts being synced.     // We need afterEvaluate here despite the fact that container is a domain object, we can't implement this with     // all because fields can change after the fact.     project.afterEvaluate(ip -> container.forEach(esNode -> {         // declare dependencies against artifacts needed by cluster formation.         String dependency = String.format("org.elasticsearch.distribution.zip:%s:%s@zip", esNode.getDistribution().getFileName(), esNode.getVersion()).         logger.info("Cluster {} depends on {}", esNode.getName(), dependency).         rootProject.getDependencies().add(HELPER_CONFIGURATION_NAME, dependency).     })). }
false;private,static;1;30;;private static void configureCleanupHooks(Project project) {     synchronized (runningClusters) {         if (executorService == null || executorService.isTerminated()) {             executorService = Executors.newSingleThreadExecutor().         } else {             throw new IllegalStateException("Trying to configure executor service twice").         }     }     // When the Gradle daemon is used, it will interrupt all threads when the build concludes.     executorService.submit(() -> {         while (true) {             try {                 Thread.sleep(Long.MAX_VALUE).             } catch (InterruptedException interrupted) {                 shutDownAllClusters().                 Thread.currentThread().interrupt().                 return.             }         }     }).     project.getGradle().buildFinished(buildResult -> {         logger.info("Build finished").         shutdownExecutorService().     }).     // When the Daemon is not used, or runs into issues, rely on a shutdown hook     // When the daemon is used, but does not work correctly and eventually dies off (e.x. due to non interruptible     // thread in the build) process will be stopped eventually when the daemon dies.     Runtime.getRuntime().addShutdownHook(new Thread(TestClustersPlugin::shutDownAllClusters)). }
false;private,static;0;14;;private static void shutdownExecutorService() {     executorService.shutdownNow().     try {         if (executorService.awaitTermination(EXECUTOR_SHUTDOWN_TIMEOUT, EXECUTOR_SHUTDOWN_TIMEOUT_UNIT) == false) {             throw new IllegalStateException("Failed to shut down executor service after " + EXECUTOR_SHUTDOWN_TIMEOUT + " " + EXECUTOR_SHUTDOWN_TIMEOUT_UNIT).         }     } catch (InterruptedException e) {         logger.info("Wait for testclusters shutdown interrupted", e).         Thread.currentThread().interrupt().     } }
false;private,static;0;9;;private static void shutDownAllClusters() {     if (logger.isDebugEnabled()) {         logger.debug("Shutting down all test clusters", new RuntimeException()).     }     synchronized (runningClusters) {         runningClusters.forEach(each -> each.stop(true)).         runningClusters.clear().     } }
