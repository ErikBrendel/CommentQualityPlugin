commented;modifiers;parameterAmount;loc;comment;code
false;public;0;23;;public void run() {     synchronized (DiskLruCache.this) {         if (!initialized | closed) {             // Nothing to do             return.         }         try {             trimToSize().         } catch (IOException ignored) {             mostRecentTrimFailed = true.         }         try {             if (journalRebuildRequired()) {                 rebuildJournal().                 redundantOpCount = 0.             }         } catch (IOException e) {             mostRecentRebuildFailed = true.             journalWriter = Okio.buffer(Okio.blackhole()).         }     } }
false;public,synchronized;0;42;;public synchronized void initialize() throws IOException {     assert Thread.holdsLock(this).     if (initialized) {         // Already initialized.         return.     }     // If a bkp file exists, use it instead.     if (fileSystem.exists(journalFileBackup)) {         // If journal file also exists just delete backup file.         if (fileSystem.exists(journalFile)) {             fileSystem.delete(journalFileBackup).         } else {             fileSystem.rename(journalFileBackup, journalFile).         }     }     // Prefer to pick up where we left off.     if (fileSystem.exists(journalFile)) {         try {             readJournal().             processJournal().             initialized = true.             return.         } catch (IOException journalIsCorrupt) {             Platform.get().log(WARN, "DiskLruCache " + directory + " is corrupt: " + journalIsCorrupt.getMessage() + ", removing", journalIsCorrupt).         }         // we'll let that propagate out as it likely means there is a severe filesystem problem.         try {             delete().         } finally {             closed = false.         }     }     rebuildJournal().     initialized = true. }
true;public,static;5;15;/**  * Create a cache which will reside in {@code directory}. This cache is lazily initialized on  * first access and will be created if it does not exist.  *  * @param directory a writable directory  * @param valueCount the number of values per cache entry. Must be positive.  * @param maxSize the maximum number of bytes this cache should use to store  */ ;/**  * Create a cache which will reside in {@code directory}. This cache is lazily initialized on  * first access and will be created if it does not exist.  *  * @param directory a writable directory  * @param valueCount the number of values per cache entry. Must be positive.  * @param maxSize the maximum number of bytes this cache should use to store  */ public static DiskLruCache create(FileSystem fileSystem, File directory, int appVersion, int valueCount, long maxSize) {     if (maxSize <= 0) {         throw new IllegalArgumentException("maxSize <= 0").     }     if (valueCount <= 0) {         throw new IllegalArgumentException("valueCount <= 0").     }     // Use a single background thread to evict entries.     Executor executor = new ThreadPoolExecutor(0, 1, 60L, TimeUnit.SECONDS, new LinkedBlockingQueue<>(), Util.threadFactory("OkHttp DiskLruCache", true)).     return new DiskLruCache(fileSystem, directory, appVersion, valueCount, maxSize, executor). }
false;private;0;35;;private void readJournal() throws IOException {     try (BufferedSource source = Okio.buffer(fileSystem.source(journalFile))) {         String magic = source.readUtf8LineStrict().         String version = source.readUtf8LineStrict().         String appVersionString = source.readUtf8LineStrict().         String valueCountString = source.readUtf8LineStrict().         String blank = source.readUtf8LineStrict().         if (!MAGIC.equals(magic) || !VERSION_1.equals(version) || !Integer.toString(appVersion).equals(appVersionString) || !Integer.toString(valueCount).equals(valueCountString) || !"".equals(blank)) {             throw new IOException("unexpected journal header: [" + magic + ", " + version + ", " + valueCountString + ", " + blank + "]").         }         int lineCount = 0.         while (true) {             try {                 readJournalLine(source.readUtf8LineStrict()).                 lineCount++.             } catch (EOFException endOfJournal) {                 break.             }         }         redundantOpCount = lineCount - lruEntries.size().         // If we ended on a truncated line, rebuild the journal before appending to it.         if (!source.exhausted()) {             rebuildJournal().         } else {             journalWriter = newJournalWriter().         }     } }
false;protected;1;4;;@Override protected void onException(IOException e) {     assert (Thread.holdsLock(DiskLruCache.this)).     hasJournalErrors = true. }
false;private;0;10;;private BufferedSink newJournalWriter() throws FileNotFoundException {     Sink fileSink = fileSystem.appendingSink(journalFile).     Sink faultHidingSink = new FaultHidingSink(fileSink) {          @Override         protected void onException(IOException e) {             assert (Thread.holdsLock(DiskLruCache.this)).             hasJournalErrors = true.         }     }.     return Okio.buffer(faultHidingSink). }
false;private;1;38;;private void readJournalLine(String line) throws IOException {     int firstSpace = line.indexOf(' ').     if (firstSpace == -1) {         throw new IOException("unexpected journal line: " + line).     }     int keyBegin = firstSpace + 1.     int secondSpace = line.indexOf(' ', keyBegin).     final String key.     if (secondSpace == -1) {         key = line.substring(keyBegin).         if (firstSpace == REMOVE.length() && line.startsWith(REMOVE)) {             lruEntries.remove(key).             return.         }     } else {         key = line.substring(keyBegin, secondSpace).     }     Entry entry = lruEntries.get(key).     if (entry == null) {         entry = new Entry(key).         lruEntries.put(key, entry).     }     if (secondSpace != -1 && firstSpace == CLEAN.length() && line.startsWith(CLEAN)) {         String[] parts = line.substring(secondSpace + 1).split(" ").         entry.readable = true.         entry.currentEditor = null.         entry.setLengths(parts).     } else if (secondSpace == -1 && firstSpace == DIRTY.length() && line.startsWith(DIRTY)) {         entry.currentEditor = new Editor(entry).     } else if (secondSpace == -1 && firstSpace == READ.length() && line.startsWith(READ)) {     // This work was already done by calling lruEntries.get().     } else {         throw new IOException("unexpected journal line: " + line).     } }
true;private;0;18;/**  * Computes the initial size and collects garbage as a part of opening the cache. Dirty entries  * are assumed to be inconsistent and will be deleted.  */ ;/**  * Computes the initial size and collects garbage as a part of opening the cache. Dirty entries  * are assumed to be inconsistent and will be deleted.  */ private void processJournal() throws IOException {     fileSystem.delete(journalFileTmp).     for (Iterator<Entry> i = lruEntries.values().iterator(). i.hasNext(). ) {         Entry entry = i.next().         if (entry.currentEditor == null) {             for (int t = 0. t < valueCount. t++) {                 size += entry.lengths[t].             }         } else {             entry.currentEditor = null.             for (int t = 0. t < valueCount. t++) {                 fileSystem.delete(entry.cleanFiles[t]).                 fileSystem.delete(entry.dirtyFiles[t]).             }             i.remove().         }     } }
true;synchronized;0;36;/**  * Creates a new journal that omits redundant information. This replaces the current journal if it  * exists.  */ ;/**  * Creates a new journal that omits redundant information. This replaces the current journal if it  * exists.  */ synchronized void rebuildJournal() throws IOException {     if (journalWriter != null) {         journalWriter.close().     }     try (BufferedSink writer = Okio.buffer(fileSystem.sink(journalFileTmp))) {         writer.writeUtf8(MAGIC).writeByte('\n').         writer.writeUtf8(VERSION_1).writeByte('\n').         writer.writeDecimalLong(appVersion).writeByte('\n').         writer.writeDecimalLong(valueCount).writeByte('\n').         writer.writeByte('\n').         for (Entry entry : lruEntries.values()) {             if (entry.currentEditor != null) {                 writer.writeUtf8(DIRTY).writeByte(' ').                 writer.writeUtf8(entry.key).                 writer.writeByte('\n').             } else {                 writer.writeUtf8(CLEAN).writeByte(' ').                 writer.writeUtf8(entry.key).                 entry.writeLengths(writer).                 writer.writeByte('\n').             }         }     }     if (fileSystem.exists(journalFile)) {         fileSystem.rename(journalFile, journalFileBackup).     }     fileSystem.rename(journalFileTmp, journalFile).     fileSystem.delete(journalFileBackup).     journalWriter = newJournalWriter().     hasJournalErrors = false.     mostRecentRebuildFailed = false. }
true;public,synchronized;1;19;/**  * Returns a snapshot of the entry named {@code key}, or null if it doesn't exist is not currently  * readable. If a value is returned, it is moved to the head of the LRU queue.  */ ;/**  * Returns a snapshot of the entry named {@code key}, or null if it doesn't exist is not currently  * readable. If a value is returned, it is moved to the head of the LRU queue.  */ public synchronized Snapshot get(String key) throws IOException {     initialize().     checkNotClosed().     validateKey(key).     Entry entry = lruEntries.get(key).     if (entry == null || !entry.readable)         return null.     Snapshot snapshot = entry.snapshot().     if (snapshot == null)         return null.     redundantOpCount++.     journalWriter.writeUtf8(READ).writeByte(' ').writeUtf8(key).writeByte('\n').     if (journalRebuildRequired()) {         executor.execute(cleanupRunnable).     }     return snapshot. }
true;public;1;3;/**  * Returns an editor for the entry named {@code key}, or null if another edit is in progress.  */ ;/**  * Returns an editor for the entry named {@code key}, or null if another edit is in progress.  */ @Nullable public Editor edit(String key) throws IOException {     return edit(key, ANY_SEQUENCE_NUMBER). }
false;synchronized;2;39;;synchronized Editor edit(String key, long expectedSequenceNumber) throws IOException {     initialize().     checkNotClosed().     validateKey(key).     Entry entry = lruEntries.get(key).     if (expectedSequenceNumber != ANY_SEQUENCE_NUMBER && (entry == null || entry.sequenceNumber != expectedSequenceNumber)) {         // Snapshot is stale.         return null.     }     if (entry != null && entry.currentEditor != null) {         // Another edit is in progress.         return null.     }     if (mostRecentTrimFailed || mostRecentRebuildFailed) {         // The OS has become our enemy! If the trim job failed, it means we are storing more data than         // requested by the user. Do not allow edits so we do not go over that limit any further. If         // the journal rebuild failed, the journal writer will not be active, meaning we will not be         // able to record the edit, causing file leaks. In both cases, we want to retry the clean up         // so we can get out of this state!         executor.execute(cleanupRunnable).         return null.     }     // Flush the journal before creating files to prevent file leaks.     journalWriter.writeUtf8(DIRTY).writeByte(' ').writeUtf8(key).writeByte('\n').     journalWriter.flush().     if (hasJournalErrors) {         // Don't edit. the journal can't be written.         return null.     }     if (entry == null) {         entry = new Entry(key).         lruEntries.put(key, entry).     }     Editor editor = new Editor(entry).     entry.currentEditor = editor.     return editor. }
true;public;0;3;/**  * Returns the directory where this cache stores its data.  */ ;/**  * Returns the directory where this cache stores its data.  */ public File getDirectory() {     return directory. }
true;public,synchronized;0;3;/**  * Returns the maximum number of bytes that this cache should use to store its data.  */ ;/**  * Returns the maximum number of bytes that this cache should use to store its data.  */ public synchronized long getMaxSize() {     return maxSize. }
true;public,synchronized;1;6;/**  * Changes the maximum number of bytes the cache can store and queues a job to trim the existing  * store, if necessary.  */ ;/**  * Changes the maximum number of bytes the cache can store and queues a job to trim the existing  * store, if necessary.  */ public synchronized void setMaxSize(long maxSize) {     this.maxSize = maxSize.     if (initialized) {         executor.execute(cleanupRunnable).     } }
true;public,synchronized;0;4;/**  * Returns the number of bytes currently being used to store the values in this cache. This may be  * greater than the max size if a background deletion is pending.  */ ;/**  * Returns the number of bytes currently being used to store the values in this cache. This may be  * greater than the max size if a background deletion is pending.  */ public synchronized long size() throws IOException {     initialize().     return size. }
false;synchronized;2;59;;synchronized void completeEdit(Editor editor, boolean success) throws IOException {     Entry entry = editor.entry.     if (entry.currentEditor != editor) {         throw new IllegalStateException().     }     // If this edit is creating the entry for the first time, every index must have a value.     if (success && !entry.readable) {         for (int i = 0. i < valueCount. i++) {             if (!editor.written[i]) {                 editor.abort().                 throw new IllegalStateException("Newly created entry didn't create value for index " + i).             }             if (!fileSystem.exists(entry.dirtyFiles[i])) {                 editor.abort().                 return.             }         }     }     for (int i = 0. i < valueCount. i++) {         File dirty = entry.dirtyFiles[i].         if (success) {             if (fileSystem.exists(dirty)) {                 File clean = entry.cleanFiles[i].                 fileSystem.rename(dirty, clean).                 long oldLength = entry.lengths[i].                 long newLength = fileSystem.size(clean).                 entry.lengths[i] = newLength.                 size = size - oldLength + newLength.             }         } else {             fileSystem.delete(dirty).         }     }     redundantOpCount++.     entry.currentEditor = null.     if (entry.readable | success) {         entry.readable = true.         journalWriter.writeUtf8(CLEAN).writeByte(' ').         journalWriter.writeUtf8(entry.key).         entry.writeLengths(journalWriter).         journalWriter.writeByte('\n').         if (success) {             entry.sequenceNumber = nextSequenceNumber++.         }     } else {         lruEntries.remove(entry.key).         journalWriter.writeUtf8(REMOVE).writeByte(' ').         journalWriter.writeUtf8(entry.key).         journalWriter.writeByte('\n').     }     journalWriter.flush().     if (size > maxSize || journalRebuildRequired()) {         executor.execute(cleanupRunnable).     } }
true;;0;5;/**  * We only rebuild the journal when it will halve the size of the journal and eliminate at least  * 2000 ops.  */ ;/**  * We only rebuild the journal when it will halve the size of the journal and eliminate at least  * 2000 ops.  */ boolean journalRebuildRequired() {     final int redundantOpCompactThreshold = 2000.     return redundantOpCount >= redundantOpCompactThreshold && redundantOpCount >= lruEntries.size(). }
true;public,synchronized;1;11;/**  * Drops the entry for {@code key} if it exists and can be removed. If the entry for {@code key}  * is currently being edited, that edit will complete normally but its value will not be stored.  *  * @return true if an entry was removed.  */ ;/**  * Drops the entry for {@code key} if it exists and can be removed. If the entry for {@code key}  * is currently being edited, that edit will complete normally but its value will not be stored.  *  * @return true if an entry was removed.  */ public synchronized boolean remove(String key) throws IOException {     initialize().     checkNotClosed().     validateKey(key).     Entry entry = lruEntries.get(key).     if (entry == null)         return false.     boolean removed = removeEntry(entry).     if (removed && size <= maxSize)         mostRecentTrimFailed = false.     return removed. }
false;;1;21;;boolean removeEntry(Entry entry) throws IOException {     if (entry.currentEditor != null) {         // Prevent the edit from completing normally.         entry.currentEditor.detach().     }     for (int i = 0. i < valueCount. i++) {         fileSystem.delete(entry.cleanFiles[i]).         size -= entry.lengths[i].         entry.lengths[i] = 0.     }     redundantOpCount++.     journalWriter.writeUtf8(REMOVE).writeByte(' ').writeUtf8(entry.key).writeByte('\n').     lruEntries.remove(entry.key).     if (journalRebuildRequired()) {         executor.execute(cleanupRunnable).     }     return true. }
true;public,synchronized;0;3;/**  * Returns true if this cache has been closed.  */ ;/**  * Returns true if this cache has been closed.  */ public synchronized boolean isClosed() {     return closed. }
false;private,synchronized;0;5;;private synchronized void checkNotClosed() {     if (isClosed()) {         throw new IllegalStateException("cache is closed").     } }
true;public,synchronized;0;7;/**  * Force buffered operations to the filesystem.  */ ;/**  * Force buffered operations to the filesystem.  */ @Override public synchronized void flush() throws IOException {     if (!initialized)         return.     checkNotClosed().     trimToSize().     journalWriter.flush(). }
true;public,synchronized;0;16;/**  * Closes this cache. Stored values will remain on the filesystem.  */ ;/**  * Closes this cache. Stored values will remain on the filesystem.  */ @Override public synchronized void close() throws IOException {     if (!initialized || closed) {         closed = true.         return.     }     // Copying for safe iteration.     for (Entry entry : lruEntries.values().toArray(new Entry[lruEntries.size()])) {         if (entry.currentEditor != null) {             entry.currentEditor.abort().         }     }     trimToSize().     journalWriter.close().     journalWriter = null.     closed = true. }
false;;0;7;;void trimToSize() throws IOException {     while (size > maxSize) {         Entry toEvict = lruEntries.values().iterator().next().         removeEntry(toEvict).     }     mostRecentTrimFailed = false. }
true;public;0;4;/**  * Closes the cache and deletes all of its stored values. This will delete all files in the cache  * directory including files that weren't created by the cache.  */ ;/**  * Closes the cache and deletes all of its stored values. This will delete all files in the cache  * directory including files that weren't created by the cache.  */ public void delete() throws IOException {     close().     fileSystem.deleteContents(directory). }
true;public,synchronized;0;8;/**  * Deletes all stored values from the cache. In-flight edits will complete normally but their  * values will not be stored.  */ ;/**  * Deletes all stored values from the cache. In-flight edits will complete normally but their  * values will not be stored.  */ public synchronized void evictAll() throws IOException {     initialize().     // Copying for safe iteration.     for (Entry entry : lruEntries.values().toArray(new Entry[lruEntries.size()])) {         removeEntry(entry).     }     mostRecentTrimFailed = false. }
false;private;1;7;;private void validateKey(String key) {     Matcher matcher = LEGAL_KEY_PATTERN.matcher(key).     if (!matcher.matches()) {         throw new IllegalArgumentException("keys must match regex [a-z0-9_-]{1,120}: \"" + key + "\"").     } }
false;public;0;18;;@Override public boolean hasNext() {     if (nextSnapshot != null)         return true.     synchronized (DiskLruCache.this) {         // If the cache is closed, truncate the iterator.         if (closed)             return false.         while (delegate.hasNext()) {             Entry entry = delegate.next().             Snapshot snapshot = entry.snapshot().             // Evicted since we copied the entries.             if (snapshot == null)                 continue.             nextSnapshot = snapshot.             return true.         }     }     return false. }
false;public;0;6;;@Override public Snapshot next() {     if (!hasNext())         throw new NoSuchElementException().     removeSnapshot = nextSnapshot.     nextSnapshot = null.     return removeSnapshot. }
false;public;0;11;;@Override public void remove() {     if (removeSnapshot == null)         throw new IllegalStateException("remove() before next()").     try {         DiskLruCache.this.remove(removeSnapshot.key).     } catch (IOException ignored) {     // Nothing useful to do here. We failed to remove from the cache. Most likely that's     // because we couldn't update the journal, but the cached entry will still be gone.     } finally {         removeSnapshot = null.     } }
true;public,synchronized;0;51;/**  * Returns an iterator over the cache's current entries. This iterator doesn't throw {@code  * ConcurrentModificationException}, but if new entries are added while iterating, those new  * entries will not be returned by the iterator. If existing entries are removed during iteration,  * they will be absent (unless they were already returned).  *  * <p>If there are I/O problems during iteration, this iterator fails silently. For example, if  * the hosting filesystem becomes unreachable, the iterator will omit elements rather than  * throwing exceptions.  *  * <p><strong>The caller must {@link Snapshot#close close}</strong> each snapshot returned by  * {@link Iterator#next}. Failing to do so leaks open files!  *  * <p>The returned iterator supports {@link Iterator#remove}.  */ ;/**  * Returns an iterator over the cache's current entries. This iterator doesn't throw {@code  * ConcurrentModificationException}, but if new entries are added while iterating, those new  * entries will not be returned by the iterator. If existing entries are removed during iteration,  * they will be absent (unless they were already returned).  *  * <p>If there are I/O problems during iteration, this iterator fails silently. For example, if  * the hosting filesystem becomes unreachable, the iterator will omit elements rather than  * throwing exceptions.  *  * <p><strong>The caller must {@link Snapshot#close close}</strong> each snapshot returned by  * {@link Iterator#next}. Failing to do so leaks open files!  *  * <p>The returned iterator supports {@link Iterator#remove}.  */ public synchronized Iterator<Snapshot> snapshots() throws IOException {     initialize().     return new Iterator<Snapshot>() {          /**          * Iterate a copy of the entries to defend against concurrent modification errors.          */         final Iterator<Entry> delegate = new ArrayList<>(lruEntries.values()).iterator().          /**          * The snapshot to return from {@link #next}. Null if we haven't computed that yet.          */         Snapshot nextSnapshot.          /**          * The snapshot to remove with {@link #remove}. Null if removal is illegal.          */         Snapshot removeSnapshot.          @Override         public boolean hasNext() {             if (nextSnapshot != null)                 return true.             synchronized (DiskLruCache.this) {                 // If the cache is closed, truncate the iterator.                 if (closed)                     return false.                 while (delegate.hasNext()) {                     Entry entry = delegate.next().                     Snapshot snapshot = entry.snapshot().                     // Evicted since we copied the entries.                     if (snapshot == null)                         continue.                     nextSnapshot = snapshot.                     return true.                 }             }             return false.         }          @Override         public Snapshot next() {             if (!hasNext())                 throw new NoSuchElementException().             removeSnapshot = nextSnapshot.             nextSnapshot = null.             return removeSnapshot.         }          @Override         public void remove() {             if (removeSnapshot == null)                 throw new IllegalStateException("remove() before next()").             try {                 DiskLruCache.this.remove(removeSnapshot.key).             } catch (IOException ignored) {             // Nothing useful to do here. We failed to remove from the cache. Most likely that's             // because we couldn't update the journal, but the cached entry will still be gone.             } finally {                 removeSnapshot = null.             }         }     }. }
false;public;0;3;;public String key() {     return key. }
true;public;0;3;/**  * Returns an editor for this snapshot's entry, or null if either the entry has changed since  * this snapshot was created or if another edit is in progress.  */ ;/**  * Returns an editor for this snapshot's entry, or null if either the entry has changed since  * this snapshot was created or if another edit is in progress.  */ @Nullable public Editor edit() throws IOException {     return DiskLruCache.this.edit(key, sequenceNumber). }
true;public;1;3;/**  * Returns the unbuffered stream with the value for {@code index}.  */ ;/**  * Returns the unbuffered stream with the value for {@code index}.  */ public Source getSource(int index) {     return sources[index]. }
true;public;1;3;/**  * Returns the byte length of the value for {@code index}.  */ ;/**  * Returns the byte length of the value for {@code index}.  */ public long getLength(int index) {     return lengths[index]. }
false;public;0;5;;public void close() {     for (Source in : sources) {         Util.closeQuietly(in).     } }
true;;0;12;/**  * Prevents this editor from completing normally. This is necessary either when the edit causes  * an I/O error, or if the target entry is evicted while this editor is active. In either case  * we delete the editor's created files and prevent new files from being created. Note that once  * an editor has been detached it is possible for another editor to edit the entry.  */ ;/**  * Prevents this editor from completing normally. This is necessary either when the edit causes  * an I/O error, or if the target entry is evicted while this editor is active. In either case  * we delete the editor's created files and prevent new files from being created. Note that once  * an editor has been detached it is possible for another editor to edit the entry.  */ void detach() {     if (entry.currentEditor == this) {         for (int i = 0. i < valueCount. i++) {             try {                 fileSystem.delete(entry.dirtyFiles[i]).             } catch (IOException e) {             // This file is potentially leaked. Not much we can do about that.             }         }         entry.currentEditor = null.     } }
true;public;1;15;/**  * Returns an unbuffered input stream to read the last committed value, or null if no value has  * been committed.  */ ;/**  * Returns an unbuffered input stream to read the last committed value, or null if no value has  * been committed.  */ public Source newSource(int index) {     synchronized (DiskLruCache.this) {         if (done) {             throw new IllegalStateException().         }         if (!entry.readable || entry.currentEditor != this) {             return null.         }         try {             return fileSystem.source(entry.cleanFiles[index]).         } catch (FileNotFoundException e) {             return null.         }     } }
false;protected;1;5;;@Override protected void onException(IOException e) {     synchronized (DiskLruCache.this) {         detach().     } }
true;public;1;27;/**  * Returns a new unbuffered output stream to write the value at {@code index}. If the underlying  * output stream encounters errors when writing to the filesystem, this edit will be aborted  * when {@link #commit} is called. The returned output stream does not throw IOExceptions.  */ ;/**  * Returns a new unbuffered output stream to write the value at {@code index}. If the underlying  * output stream encounters errors when writing to the filesystem, this edit will be aborted  * when {@link #commit} is called. The returned output stream does not throw IOExceptions.  */ public Sink newSink(int index) {     synchronized (DiskLruCache.this) {         if (done) {             throw new IllegalStateException().         }         if (entry.currentEditor != this) {             return Okio.blackhole().         }         if (!entry.readable) {             written[index] = true.         }         File dirtyFile = entry.dirtyFiles[index].         Sink sink.         try {             sink = fileSystem.sink(dirtyFile).         } catch (FileNotFoundException e) {             return Okio.blackhole().         }         return new FaultHidingSink(sink) {              @Override             protected void onException(IOException e) {                 synchronized (DiskLruCache.this) {                     detach().                 }             }         }.     } }
true;public;0;11;/**  * Commits this edit so it is visible to readers.  This releases the edit lock so another edit  * may be started on the same key.  */ ;/**  * Commits this edit so it is visible to readers.  This releases the edit lock so another edit  * may be started on the same key.  */ public void commit() throws IOException {     synchronized (DiskLruCache.this) {         if (done) {             throw new IllegalStateException().         }         if (entry.currentEditor == this) {             completeEdit(this, true).         }         done = true.     } }
true;public;0;11;/**  * Aborts this edit. This releases the edit lock so another edit may be started on the same  * key.  */ ;/**  * Aborts this edit. This releases the edit lock so another edit may be started on the same  * key.  */ public void abort() throws IOException {     synchronized (DiskLruCache.this) {         if (done) {             throw new IllegalStateException().         }         if (entry.currentEditor == this) {             completeEdit(this, false).         }         done = true.     } }
false;public;0;10;;public void abortUnlessCommitted() {     synchronized (DiskLruCache.this) {         if (!done && entry.currentEditor == this) {             try {                 completeEdit(this, false).             } catch (IOException ignored) {             }         }     } }
true;;1;13;/**  * Set lengths using decimal numbers like "10123".  */ ;/**  * Set lengths using decimal numbers like "10123".  */ void setLengths(String[] strings) throws IOException {     if (strings.length != valueCount) {         throw invalidLengths(strings).     }     try {         for (int i = 0. i < strings.length. i++) {             lengths[i] = Long.parseLong(strings[i]).         }     } catch (NumberFormatException e) {         throw invalidLengths(strings).     } }
true;;1;5;/**  * Append space-prefixed lengths to {@code writer}.  */ ;/**  * Append space-prefixed lengths to {@code writer}.  */ void writeLengths(BufferedSink writer) throws IOException {     for (long length : lengths) {         writer.writeByte(' ').writeDecimalLong(length).     } }
false;private;1;3;;private IOException invalidLengths(String[] strings) throws IOException {     throw new IOException("unexpected journal line: " + Arrays.toString(strings)). }
true;;0;28;/**  * Returns a snapshot of this entry. This opens all streams eagerly to guarantee that we see a  * single published snapshot. If we opened streams lazily then the streams could come from  * different edits.  */ ;/**  * Returns a snapshot of this entry. This opens all streams eagerly to guarantee that we see a  * single published snapshot. If we opened streams lazily then the streams could come from  * different edits.  */ Snapshot snapshot() {     if (!Thread.holdsLock(DiskLruCache.this))         throw new AssertionError().     Source[] sources = new Source[valueCount].     // Defensive copy since these can be zeroed out.     long[] lengths = this.lengths.clone().     try {         for (int i = 0. i < valueCount. i++) {             sources[i] = fileSystem.source(cleanFiles[i]).         }         return new Snapshot(key, sequenceNumber, sources, lengths).     } catch (FileNotFoundException e) {         // A file must have been deleted manually!         for (int i = 0. i < valueCount. i++) {             if (sources[i] != null) {                 Util.closeQuietly(sources[i]).             } else {                 break.             }         }         // size.)         try {             removeEntry(this).         } catch (IOException ignored) {         }         return null.     } }
