# id;timestamp;commentText;codeText;commentWords;codeWords
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1493403095;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1493895399;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1494504667;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1495484544;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1499314317;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1502801814;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1503598628;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1506618381;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1511180335;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1516295283;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1516971863;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1524407315;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1525420604;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1529583969;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1531381123;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1531499577;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1537337120;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1538386941;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1547644408;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes);1547905886;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes, Map<Integer, List<Tuple2<byte[], byte[]>>> chainedOperatorHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0, chainedOperatorHashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,map,integer,list,tuple2,byte,byte,chained,operator,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0,chained,operator,hashes
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1452526242;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1452854660;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1453730836;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1453987828;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1454527671;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1454933011;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1454959165;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1454960195;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1455486690;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1455548285;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1456247173;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1456347641;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1456427030;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1457737669;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1459526979;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1463155298;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1463939897;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1470419821;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1470677230;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1472663071;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1472663401;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1476432306;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1476877808;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1477127608;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1477517188;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1477923122;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1478288497;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private byte[] generateDeterministicHash( 			StreamNode node, 			Hasher hasher, 			Map<Integer, byte[]> hashes);1478815184;Generates a deterministic hash from node-local properties and input and_output edges.;private byte[] generateDeterministicHash(_			StreamNode node,_			Hasher hasher,_			Map<Integer, byte[]> hashes) {__		_		_		_		_		generateNodeLocalHash(node, hasher, hashes.size())___		_		for (StreamEdge outEdge : node.getOutEdges()) {_			if (isChainable(outEdge)) {_				StreamNode chainedNode = outEdge.getTargetVertex()___				_				_				generateNodeLocalHash(chainedNode, hasher, hashes.size())__			}_		}__		byte[] hash = hasher.hash().asBytes()___		_		_		for (StreamEdge inEdge : node.getInEdges()) {_			byte[] otherHash = hashes.get(inEdge.getSourceId())___			_			if (otherHash == null) {_				throw new IllegalStateException("Missing hash for input node "_						+ inEdge.getSourceVertex() + ". Cannot generate hash for "_						+ node + ".")__			}__			for (int j = 0_ j < hash.length_ j++) {_				hash[j] = (byte) (hash[j] * 37 ^ otherHash[j])__			}_		}__		if (LOG.isDebugEnabled()) {_			String udfClassName = ""__			if (node.getOperator() instanceof AbstractUdfStreamOperator) {_				udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_						.getUserFunction().getClass().getName()__			}__			LOG.debug("Generated hash '" + byteToHexString(hash) + "' for node " +_					"'" + node.toString() + "' {id: " + node.getId() + ", " +_					"parallelism: " + node.getParallelism() + ", " +_					"user function: " + udfClassName + "}")__		}__		return hash__	};generates,a,deterministic,hash,from,node,local,properties,and,input,and,output,edges;private,byte,generate,deterministic,hash,stream,node,node,hasher,hasher,map,integer,byte,hashes,generate,node,local,hash,node,hasher,hashes,size,for,stream,edge,out,edge,node,get,out,edges,if,is,chainable,out,edge,stream,node,chained,node,out,edge,get,target,vertex,generate,node,local,hash,chained,node,hasher,hashes,size,byte,hash,hasher,hash,as,bytes,for,stream,edge,in,edge,node,get,in,edges,byte,other,hash,hashes,get,in,edge,get,source,id,if,other,hash,null,throw,new,illegal,state,exception,missing,hash,for,input,node,in,edge,get,source,vertex,cannot,generate,hash,for,node,for,int,j,0,j,hash,length,j,hash,j,byte,hash,j,37,other,hash,j,if,log,is,debug,enabled,string,udf,class,name,if,node,get,operator,instanceof,abstract,udf,stream,operator,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,log,debug,generated,hash,byte,to,hex,string,hash,for,node,node,to,string,id,node,get,id,parallelism,node,get,parallelism,user,function,udf,class,name,return,hash
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1481709237;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1484038132;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1484594327;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1484866640;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1485181339;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1485269495;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1487616195;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1488304933;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1489149058;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1489671807;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1489782894;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1489819457;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1489819457;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1492530130;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1492678790;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1492680901;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1493195810;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1493195810;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes);1493236605;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes, List<Map<Integer, byte[]>> legacyHashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, legacyHashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,list,map,integer,byte,legacy,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,legacy,hashes,0
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1452526242;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1452854660;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1453730836;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1453987828;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1454527671;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1454933011;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1454959165;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1454960195;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1455486690;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1455548285;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1456247173;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1456347641;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1456427030;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1457737669;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1459526979;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1463155298;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1463939897;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1470419821;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1470677230;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1472663071;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1472663401;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1476432306;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1476877808;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1477127608;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1477517188;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1477923122;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1478288497;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher);1478815184;Generates a hash from a user-specified ID.;private byte[] generateUserSpecifiedHash(StreamNode node, Hasher hasher) {_		hasher.putString(node.getTransformationId(), Charset.forName("UTF-8"))___		return hasher.hash().asBytes()__	};generates,a,hash,from,a,user,specified,id;private,byte,generate,user,specified,hash,stream,node,node,hasher,hasher,hasher,put,string,node,get,transformation,id,charset,for,name,utf,8,return,hasher,hash,as,bytes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1452526242;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1452854660;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1453730836;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1453987828;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1454527671;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1454933011;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1454959165;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1454960195;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1455486690;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1455548285;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1456247173;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1456347641;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1456427030;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1457737669;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1459526979;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1463155298;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1463939897;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1470419821;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1470677230;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1472663071;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1472663401;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1476432306;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1476877808;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1477127608;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1477517188;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1477923122;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1478288497;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes();1478815184;Returns a map with a hash for each {@link StreamNode} of the {@link_StreamGraph}. The hash is used as the {@link JobVertexID} in order to_identify nodes across job submissions if they didn't change.__<p>The complete {@link StreamGraph} is traversed. The hash is either_computed from the transformation's user-specified id (see_{@link StreamTransformation#getUid()}) or generated in a deterministic way.__<p>The generated hash is deterministic with respect to:_<ul>_<li>node-local properties (like parallelism, UDF, node ID),_<li>chained output nodes, and_<li>input nodes hashes_</ul>__@return A map from {@link StreamNode#id} to hash as 16-byte array.;private Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes() {_		_		final HashFunction hashFunction = Hashing.murmur3_128(0)__		final Map<Integer, byte[]> hashes = new HashMap<>()___		Set<Integer> visited = new HashSet<>()__		Queue<StreamNode> remaining = new ArrayDeque<>()___		_		_		_		_		List<Integer> sources = new ArrayList<>()__		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			sources.add(sourceNodeId)__		}_		Collections.sort(sources)___		_		_		_		__		_		for (Integer sourceNodeId : sources) {_			remaining.add(streamGraph.getStreamNode(sourceNodeId))__			visited.add(sourceNodeId)__		}__		StreamNode currentNode__		while ((currentNode = remaining.poll()) != null) {_			_			_			_			if (generateNodeHash(currentNode, hashFunction, hashes)) {_				_				for (StreamEdge outEdge : currentNode.getOutEdges()) {_					StreamNode child = outEdge.getTargetVertex()___					if (!visited.contains(child.getId())) {_						remaining.add(child)__						visited.add(child.getId())__					}_				}_			}_			else {_				_				visited.remove(currentNode.getId())__			}_		}__		return hashes__	};returns,a,map,with,a,hash,for,each,link,stream,node,of,the,link,stream,graph,the,hash,is,used,as,the,link,job,vertex,id,in,order,to,identify,nodes,across,job,submissions,if,they,didn,t,change,p,the,complete,link,stream,graph,is,traversed,the,hash,is,either,computed,from,the,transformation,s,user,specified,id,see,link,stream,transformation,get,uid,or,generated,in,a,deterministic,way,p,the,generated,hash,is,deterministic,with,respect,to,ul,li,node,local,properties,like,parallelism,udf,node,id,li,chained,output,nodes,and,li,input,nodes,hashes,ul,return,a,map,from,link,stream,node,id,to,hash,as,16,byte,array;private,map,integer,byte,traverse,stream,graph,and,generate,hashes,final,hash,function,hash,function,hashing,0,final,map,integer,byte,hashes,new,hash,map,set,integer,visited,new,hash,set,queue,stream,node,remaining,new,array,deque,list,integer,sources,new,array,list,for,integer,source,node,id,stream,graph,get,source,ids,sources,add,source,node,id,collections,sort,sources,for,integer,source,node,id,sources,remaining,add,stream,graph,get,stream,node,source,node,id,visited,add,source,node,id,stream,node,current,node,while,current,node,remaining,poll,null,if,generate,node,hash,current,node,hash,function,hashes,for,stream,edge,out,edge,current,node,get,out,edges,stream,node,child,out,edge,get,target,vertex,if,visited,contains,child,get,id,remaining,add,child,visited,add,child,get,id,else,visited,remove,current,node,get,id,return,hashes
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1452526242;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		hasher.putString(node.getOperatorName(), Charset.forName("UTF-8"))___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,hasher,put,string,node,get,operator,name,charset,for,name,utf,8,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1452854660;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		hasher.putString(node.getOperatorName(), Charset.forName("UTF-8"))___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,hasher,put,string,node,get,operator,name,charset,for,name,utf,8,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1453730836;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		hasher.putString(node.getOperatorName(), Charset.forName("UTF-8"))___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,hasher,put,string,node,get,operator,name,charset,for,name,utf,8,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1453987828;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		hasher.putString(node.getOperatorName(), Charset.forName("UTF-8"))___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,hasher,put,string,node,get,operator,name,charset,for,name,utf,8,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1454527671;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		hasher.putString(node.getOperatorName(), Charset.forName("UTF-8"))___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,hasher,put,string,node,get,operator,name,charset,for,name,utf,8,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1454933011;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		hasher.putString(node.getOperatorName(), Charset.forName("UTF-8"))___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,hasher,put,string,node,get,operator,name,charset,for,name,utf,8,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1454959165;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		hasher.putString(node.getOperatorName(), Charset.forName("UTF-8"))___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,hasher,put,string,node,get,operator,name,charset,for,name,utf,8,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1454960195;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		hasher.putString(node.getOperatorName(), Charset.forName("UTF-8"))___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,hasher,put,string,node,get,operator,name,charset,for,name,utf,8,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1455486690;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		hasher.putString(node.getOperatorName(), Charset.forName("UTF-8"))___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,hasher,put,string,node,get,operator,name,charset,for,name,utf,8,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1455548285;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		hasher.putString(node.getOperatorName(), Charset.forName("UTF-8"))___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,hasher,put,string,node,get,operator,name,charset,for,name,utf,8,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1456247173;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		hasher.putString(node.getOperatorName(), Charset.forName("UTF-8"))___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,hasher,put,string,node,get,operator,name,charset,for,name,utf,8,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1456347641;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		hasher.putString(node.getOperatorName(), Charset.forName("UTF-8"))___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,hasher,put,string,node,get,operator,name,charset,for,name,utf,8,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1456427030;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1457737669;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1459526979;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1463155298;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1463939897;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1470419821;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1470677230;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		hasher.putInt(node.getParallelism())___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,hasher,put,int,node,get,parallelism,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1472663071;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1472663401;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1476432306;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1476877808;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1477127608;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1477517188;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1477923122;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1478288497;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id);1478815184;Applies the {@link Hasher} to the {@link StreamNode} (only node local_attributes are taken into account). The hasher encapsulates the current_state of the hash.__<p>The specified ID is local to this node. We cannot use the_{@link StreamNode#id}, because it is incremented in a static counter._Therefore, the IDs for identical jobs will otherwise be different.;private void generateNodeLocalHash(StreamNode node, Hasher hasher, int id) {_		_		_		_		hasher.putInt(id)___		if (node.getOperator() instanceof AbstractUdfStreamOperator) {_			String udfClassName = ((AbstractUdfStreamOperator<?, ?>) node.getOperator())_					.getUserFunction().getClass().getName()___			hasher.putString(udfClassName, Charset.forName("UTF-8"))__		}_	};applies,the,link,hasher,to,the,link,stream,node,only,node,local,attributes,are,taken,into,account,the,hasher,encapsulates,the,current,state,of,the,hash,p,the,specified,id,is,local,to,this,node,we,cannot,use,the,link,stream,node,id,because,it,is,incremented,in,a,static,counter,therefore,the,ids,for,identical,jobs,will,otherwise,be,different;private,void,generate,node,local,hash,stream,node,node,hasher,hasher,int,id,hasher,put,int,id,if,node,get,operator,instanceof,abstract,udf,stream,operator,string,udf,class,name,abstract,udf,stream,operator,node,get,operator,get,user,function,get,class,get,name,hasher,put,string,udf,class,name,charset,for,name,utf,8
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1452526242;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1452854660;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1453730836;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1453987828;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1454527671;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1454933011;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1454959165;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1454960195;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1455486690;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1455548285;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1456247173;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1456347641;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1456427030;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1457737669;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1459526979;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1463155298;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1463939897;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1470419821;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1470677230;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1472663071;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1472663401;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1476432306;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1476877808;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1477127608;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1477517188;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1477923122;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1478288497;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private boolean generateNodeHash( 			StreamNode node, 			HashFunction hashFunction, 			Map<Integer, byte[]> hashes);1478815184;Generates a hash for the node and returns whether the operation was_successful.__@param node         The node to generate the hash for_@param hashFunction The hash function to use_@param hashes       The current state of generated hashes_@return <code>true</code> if the node hash has been generated._<code>false</code>, otherwise. If the operation is not successful, the_hash needs be generated at a later point when all input is available._@throws IllegalStateException If node has user-specified hash and is_intermediate node of a chain;private boolean generateNodeHash(_			StreamNode node,_			HashFunction hashFunction,_			Map<Integer, byte[]> hashes) {__		_		String userSpecifiedHash = node.getTransformationId()___		if (userSpecifiedHash == null) {_			_			for (StreamEdge inEdge : node.getInEdges()) {_				_				_				_				if (!hashes.containsKey(inEdge.getSourceId())) {_					return false__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateDeterministicHash(node, hasher, hashes)___			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_		else {_			_			_			_			_			for (StreamEdge inEdge : node.getInEdges()) {_				if (isChainable(inEdge)) {_					throw new UnsupportedOperationException("Cannot assign user-specified hash "_							+ "to intermediate node in chain. This will be supported in future "_							+ "versions of Flink. As a work around start new chain at task "_							+ node.getOperatorName() + ".")__				}_			}__			Hasher hasher = hashFunction.newHasher()__			byte[] hash = generateUserSpecifiedHash(node, hasher)___			for (byte[] previousHash : hashes.values()) {_				if (Arrays.equals(previousHash, hash)) {_					throw new IllegalArgumentException("Hash collision on user-specified ID. " +_							"Most likely cause is a non-unique ID. Please check that all IDs " +_							"specified via `uid(String)` are unique.")__				}_			}__			if (hashes.put(node.getId(), hash) != null) {_				_				throw new IllegalStateException("Unexpected state. Tried to add node hash " +_						"twice. This is probably a bug in the JobGraph generator.")__			}__			return true__		}_	};generates,a,hash,for,the,node,and,returns,whether,the,operation,was,successful,param,node,the,node,to,generate,the,hash,for,param,hash,function,the,hash,function,to,use,param,hashes,the,current,state,of,generated,hashes,return,code,true,code,if,the,node,hash,has,been,generated,code,false,code,otherwise,if,the,operation,is,not,successful,the,hash,needs,be,generated,at,a,later,point,when,all,input,is,available,throws,illegal,state,exception,if,node,has,user,specified,hash,and,is,intermediate,node,of,a,chain;private,boolean,generate,node,hash,stream,node,node,hash,function,hash,function,map,integer,byte,hashes,string,user,specified,hash,node,get,transformation,id,if,user,specified,hash,null,for,stream,edge,in,edge,node,get,in,edges,if,hashes,contains,key,in,edge,get,source,id,return,false,hasher,hasher,hash,function,new,hasher,byte,hash,generate,deterministic,hash,node,hasher,hashes,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true,else,for,stream,edge,in,edge,node,get,in,edges,if,is,chainable,in,edge,throw,new,unsupported,operation,exception,cannot,assign,user,specified,hash,to,intermediate,node,in,chain,this,will,be,supported,in,future,versions,of,flink,as,a,work,around,start,new,chain,at,task,node,get,operator,name,hasher,hasher,hash,function,new,hasher,byte,hash,generate,user,specified,hash,node,hasher,for,byte,previous,hash,hashes,values,if,arrays,equals,previous,hash,hash,throw,new,illegal,argument,exception,hash,collision,on,user,specified,id,most,likely,cause,is,a,non,unique,id,please,check,that,all,ids,specified,via,uid,string,are,unique,if,hashes,put,node,get,id,hash,null,throw,new,illegal,state,exception,unexpected,state,tried,to,add,node,hash,twice,this,is,probably,a,bug,in,the,job,graph,generator,return,true
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1452526242;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1452854660;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1453730836;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1453987828;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1454527671;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1454933011;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1454959165;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1454960195;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1455486690;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1455548285;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1456247173;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1456347641;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1456427030;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1457737669;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1459526979;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1463155298;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1463939897;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1470419821;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1470677230;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1472663071;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1472663401;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1476432306;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1476877808;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1477127608;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1477517188;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1477923122;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1478288497;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,0
StreamingJobGraphGenerator -> private void setChaining(Map<Integer, byte[]> hashes);1478815184;Sets up task chains from the source {@link StreamNode} instances.__<p>This will recursively create all {@link JobVertex} instances.;private void setChaining(Map<Integer, byte[]> hashes) {_		for (Integer sourceNodeId : streamGraph.getSourceIDs()) {_			createChain(sourceNodeId, sourceNodeId, hashes, 0)__		}_	};sets,up,task,chains,from,the,source,link,stream,node,instances,p,this,will,recursively,create,all,link,job,vertex,instances;private,void,set,chaining,map,integer,byte,hashes,for,integer,source,node,id,stream,graph,get,source,ids,create,chain,source,node,id,source,node,id,hashes,0
