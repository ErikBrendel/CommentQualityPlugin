commented;modifiers;parameterAmount;loc;comment;code
false;public;1;26;;@Override public void setKeyFields(String[] keyNames) {     if (keyNames == null) {         this.keyFieldIndices = new int[0].         return.     }     final String[] fieldNames = getFieldNames().     final int[] keyFieldIndices = new int[keyNames.length].     for (int i = 0. i < keyNames.length. i++) {         keyFieldIndices[i] = -1.         for (int j = 0. j < fieldNames.length. j++) {             if (keyNames[i].equals(fieldNames[j])) {                 keyFieldIndices[i] = j.                 break.             }         }         if (keyFieldIndices[i] == -1) {             throw new RuntimeException("Invalid key fields: " + Arrays.toString(keyNames)).         }     }     validateKeyTypes(keyFieldIndices).     this.keyFieldIndices = keyFieldIndices. }
false;public;1;9;;@Override public void setIsAppendOnly(Boolean isAppendOnly) {     if (this.isAppendOnly && !isAppendOnly) {         throw new ValidationException("The given query is not supported by this sink because the sink is configured to " + "operate in append mode only. Thus, it only support insertions (no queries " + "with updating results).").     } }
false;public;0;4;;@Override public TypeInformation<Row> getRecordType() {     return schema.toRowType(). }
false;public;1;20;;@Override public void emitDataStream(DataStream<Tuple2<Boolean, Row>> dataStream) {     final ElasticsearchUpsertSinkFunction upsertFunction = new ElasticsearchUpsertSinkFunction(index, docType, keyDelimiter, keyNullLiteral, serializationSchema, contentType, requestFactory, keyFieldIndices).     final SinkFunction<Tuple2<Boolean, Row>> sinkFunction = createSinkFunction(hosts, failureHandler, sinkOptions, upsertFunction).     dataStream.addSink(sinkFunction).name(TableConnectorUtils.generateRuntimeName(this.getClass(), getFieldNames())). }
false;public;0;4;;@Override public TypeInformation<Tuple2<Boolean, Row>> getOutputType() {     return Types.TUPLE(Types.BOOLEAN, getRecordType()). }
false;public;0;4;;@Override public String[] getFieldNames() {     return schema.getFieldNames(). }
false;public;0;4;;@Override public TypeInformation<?>[] getFieldTypes() {     return schema.getFieldTypes(). }
false;public;2;21;;@Override public TableSink<Tuple2<Boolean, Row>> configure(String[] fieldNames, TypeInformation<?>[] fieldTypes) {     if (!Arrays.equals(getFieldNames(), fieldNames) || !Arrays.equals(getFieldTypes(), fieldTypes)) {         throw new ValidationException("Reconfiguration with different fields is not allowed. " + "Expected: " + Arrays.toString(getFieldNames()) + " / " + Arrays.toString(getFieldTypes()) + ". " + "But was: " + Arrays.toString(fieldNames) + " / " + Arrays.toString(fieldTypes)).     }     return copy(isAppendOnly, schema, hosts, index, docType, keyDelimiter, keyNullLiteral, serializationSchema, contentType, failureHandler, sinkOptions, requestFactory). }
false;public;1;21;;@Override public boolean equals(Object o) {     if (this == o) {         return true.     }     if (o == null || getClass() != o.getClass()) {         return false.     }     ElasticsearchUpsertTableSinkBase that = (ElasticsearchUpsertTableSinkBase) o.     return Objects.equals(isAppendOnly, that.isAppendOnly) && Objects.equals(schema, that.schema) && Objects.equals(hosts, that.hosts) && Objects.equals(index, that.index) && Objects.equals(docType, that.docType) && Objects.equals(keyDelimiter, that.keyDelimiter) && Objects.equals(keyNullLiteral, that.keyNullLiteral) && Objects.equals(serializationSchema, that.serializationSchema) && Objects.equals(contentType, that.contentType) && Objects.equals(failureHandler, that.failureHandler) && Objects.equals(sinkOptions, that.sinkOptions). }
false;public;0;15;;@Override public int hashCode() {     return Objects.hash(isAppendOnly, schema, hosts, index, docType, keyDelimiter, keyNullLiteral, serializationSchema, contentType, failureHandler, sinkOptions). }
false;protected,abstract;12;13;;// -------------------------------------------------------------------------------------------- // For version-specific implementations // -------------------------------------------------------------------------------------------- protected abstract ElasticsearchUpsertTableSinkBase copy(boolean isAppendOnly, TableSchema schema, List<Host> hosts, String index, String docType, String keyDelimiter, String keyNullLiteral, SerializationSchema<Row> serializationSchema, XContentType contentType, ActionRequestFailureHandler failureHandler, Map<SinkOption, String> sinkOptions, RequestFactory requestFactory).
false;protected,abstract;4;5;;protected abstract SinkFunction<Tuple2<Boolean, Row>> createSinkFunction(List<Host> hosts, ActionRequestFailureHandler failureHandler, Map<SinkOption, String> sinkOptions, ElasticsearchUpsertSinkFunction upsertFunction).
true;private;1;11;/**  * Validate the types that are used for conversion to string.  */ ;// -------------------------------------------------------------------------------------------- // Helper methods // -------------------------------------------------------------------------------------------- /**  * Validate the types that are used for conversion to string.  */ private void validateKeyTypes(int[] keyFieldIndices) {     final TypeInformation<?>[] types = getFieldTypes().     for (int keyFieldIndex : keyFieldIndices) {         final TypeInformation<?> type = types[keyFieldIndex].         if (!TypeCheckUtils.isSimpleStringRepresentation(type)) {             throw new ValidationException("Only simple types that can be safely converted into a string representation " + "can be used as keys. But was: " + type).         }     } }
false;public;1;13;;@Override public boolean equals(Object o) {     if (this == o) {         return true.     }     if (o == null || getClass() != o.getClass()) {         return false.     }     Host host = (Host) o.     return port == host.port && Objects.equals(hostname, host.hostname) && Objects.equals(protocol, host.protocol). }
false;public;0;7;;@Override public int hashCode() {     return Objects.hash(hostname, port, protocol). }
true;;5;6;/**  * Creates an update request to be added to a {@link RequestIndexer}.  */ ;/**  * Creates an update request to be added to a {@link RequestIndexer}.  */ UpdateRequest createUpdateRequest(String index, String docType, String key, XContentType contentType, byte[] document).
true;;4;5;/**  * Creates an index request to be added to a {@link RequestIndexer}.  */ ;/**  * Creates an index request to be added to a {@link RequestIndexer}.  */ IndexRequest createIndexRequest(String index, String docType, XContentType contentType, byte[] document).
true;;3;4;/**  * Creates a delete request to be added to a {@link RequestIndexer}.  */ ;/**  * Creates a delete request to be added to a {@link RequestIndexer}.  */ DeleteRequest createDeleteRequest(String index, String docType, String key).
false;public;3;8;;@Override public void process(Tuple2<Boolean, Row> element, RuntimeContext ctx, RequestIndexer indexer) {     if (element.f0) {         processUpsert(element.f1, indexer).     } else {         processDelete(element.f1, indexer).     } }
false;private;2;20;;private void processUpsert(Row row, RequestIndexer indexer) {     final byte[] document = serializationSchema.serialize(row).     if (keyFieldIndices.length == 0) {         final IndexRequest indexRequest = requestFactory.createIndexRequest(index, docType, contentType, document).         indexer.add(indexRequest).     } else {         final String key = createKey(row).         final UpdateRequest updateRequest = requestFactory.createUpdateRequest(index, docType, key, contentType, document).         indexer.add(updateRequest).     } }
false;private;2;8;;private void processDelete(Row row, RequestIndexer indexer) {     final String key = createKey(row).     final DeleteRequest deleteRequest = requestFactory.createDeleteRequest(index, docType, key).     indexer.add(deleteRequest). }
false;private;1;16;;private String createKey(Row row) {     final StringBuilder builder = new StringBuilder().     for (int i = 0. i < keyFieldIndices.length. i++) {         final int keyFieldIndex = keyFieldIndices[i].         if (i > 0) {             builder.append(keyDelimiter).         }         final Object value = row.getField(keyFieldIndex).         if (value == null) {             builder.append(keyNullLiteral).         } else {             builder.append(value.toString()).         }     }     return builder.toString(). }
false;public;1;18;;@Override public boolean equals(Object o) {     if (this == o) {         return true.     }     if (o == null || getClass() != o.getClass()) {         return false.     }     ElasticsearchUpsertSinkFunction that = (ElasticsearchUpsertSinkFunction) o.     return Objects.equals(index, that.index) && Objects.equals(docType, that.docType) && Objects.equals(keyDelimiter, that.keyDelimiter) && Objects.equals(keyNullLiteral, that.keyNullLiteral) && Objects.equals(serializationSchema, that.serializationSchema) && contentType == that.contentType && Objects.equals(requestFactory, that.requestFactory) && Arrays.equals(keyFieldIndices, that.keyFieldIndices). }
false;public;0;13;;@Override public int hashCode() {     int result = Objects.hash(index, docType, keyDelimiter, keyNullLiteral, serializationSchema, contentType, requestFactory).     result = 31 * result + Arrays.hashCode(keyFieldIndices).     return result. }
