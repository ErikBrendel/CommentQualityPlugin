commented;modifiers;parameterAmount;loc;comment;code
false;protected;8;27;;@Override protected AbstractFetcher<T, ?> createFetcher(SourceContext<T> sourceContext, Map<KafkaTopicPartition, Long> assignedPartitionsWithInitialOffsets, SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, StreamingRuntimeContext runtimeContext, OffsetCommitMode offsetCommitMode, MetricGroup consumerMetricGroup, boolean useMetrics) throws Exception {     long autoCommitInterval = (offsetCommitMode == OffsetCommitMode.KAFKA_PERIODIC) ? PropertiesUtil.getLong(kafkaProperties, "auto.commit.interval.ms", 60000) : // this disables the periodic offset committer thread in the fetcher     -1.     return new Kafka08Fetcher<>(sourceContext, assignedPartitionsWithInitialOffsets, watermarksPeriodic, watermarksPunctuated, runtimeContext, deserializer, kafkaProperties, autoCommitInterval, consumerMetricGroup, useMetrics). }
false;protected;3;8;;@Override protected AbstractPartitionDiscoverer createPartitionDiscoverer(KafkaTopicsDescriptor topicsDescriptor, int indexOfThisSubtask, int numParallelSubtasks) {     return new Kafka08PartitionDiscoverer(topicsDescriptor, indexOfThisSubtask, numParallelSubtasks, kafkaProperties). }
false;protected;0;5;;@Override protected boolean getIsAutoCommitEnabled() {     return PropertiesUtil.getBoolean(kafkaProperties, "auto.commit.enable", true) && PropertiesUtil.getLong(kafkaProperties, "auto.commit.interval.ms", 60000) > 0. }
false;protected;2;6;;@Override protected Map<KafkaTopicPartition, Long> fetchOffsetsWithTimestamp(Collection<KafkaTopicPartition> partitions, long timestamp) {     // this should not be reached, since we do not expose the timestamp-based startup feature in version 0.8.     throw new UnsupportedOperationException("Fetching partition offsets using timestamps is only supported in Kafka versions 0.10 and above."). }
true;protected,static;1;25;/**  * Validate the ZK configuration, checking for required parameters.  *  * @param props Properties to check  */ ;// ------------------------------------------------------------------------ // Kafka / ZooKeeper configuration utilities // ------------------------------------------------------------------------ /**  * Validate the ZK configuration, checking for required parameters.  *  * @param props Properties to check  */ protected static void validateZooKeeperConfig(Properties props) {     if (props.getProperty("zookeeper.connect") == null) {         throw new IllegalArgumentException("Required property 'zookeeper.connect' has not been set in the properties").     }     if (props.getProperty(ConsumerConfig.GROUP_ID_CONFIG) == null) {         throw new IllegalArgumentException("Required property '" + ConsumerConfig.GROUP_ID_CONFIG + "' has not been set in the properties").     }     try {         // noinspection ResultOfMethodCallIgnored         Integer.parseInt(props.getProperty("zookeeper.session.timeout.ms", "0")).     } catch (NumberFormatException e) {         throw new IllegalArgumentException("Property 'zookeeper.session.timeout.ms' is not a valid integer").     }     try {         // noinspection ResultOfMethodCallIgnored         Integer.parseInt(props.getProperty("zookeeper.connection.timeout.ms", "0")).     } catch (NumberFormatException e) {         throw new IllegalArgumentException("Property 'zookeeper.connection.timeout.ms' is not a valid integer").     } }
true;private,static;1;8;/**  * Check for invalid "auto.offset.reset" values. Should be called in constructor for eager checking before submitting  * the job. Note that 'none' is also considered invalid, as we don't want to deliberately throw an exception  * right after a task is started.  *  * @param config kafka consumer properties to check  */ ;/**  * Check for invalid "auto.offset.reset" values. Should be called in constructor for eager checking before submitting  * the job. Note that 'none' is also considered invalid, as we don't want to deliberately throw an exception  * right after a task is started.  *  * @param config kafka consumer properties to check  */ private static void validateAutoOffsetResetValue(Properties config) {     final String val = config.getProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "largest").     if (!(val.equals("largest") || val.equals("latest") || val.equals("earliest") || val.equals("smallest"))) {         // largest/smallest is kafka 0.8, latest/earliest is kafka 0.9         throw new IllegalArgumentException("Cannot use '" + ConsumerConfig.AUTO_OFFSET_RESET_CONFIG + "' value '" + val + "'. Possible values: 'latest', 'largest', 'earliest', or 'smallest'.").     } }
