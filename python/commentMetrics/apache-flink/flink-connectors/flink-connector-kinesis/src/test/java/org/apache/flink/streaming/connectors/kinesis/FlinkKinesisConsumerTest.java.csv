commented;modifiers;parameterAmount;loc;comment;code
false;public;0;55;;// ---------------------------------------------------------------------- // Tests related to state initialization // ---------------------------------------------------------------------- @Test public void testUseRestoredStateForSnapshotIfFetcherNotInitialized() throws Exception {     Properties config = TestUtils.getStandardProperties().     List<Tuple2<StreamShardMetadata, SequenceNumber>> globalUnionState = new ArrayList<>(4).     globalUnionState.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(new StreamShardHandle("fakeStream", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(0)))), new SequenceNumber("1"))).     globalUnionState.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(new StreamShardHandle("fakeStream", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(1)))), new SequenceNumber("1"))).     globalUnionState.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(new StreamShardHandle("fakeStream", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(2)))), new SequenceNumber("1"))).     globalUnionState.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(new StreamShardHandle("fakeStream", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(3)))), new SequenceNumber("1"))).     TestingListState<Tuple2<StreamShardMetadata, SequenceNumber>> listState = new TestingListState<>().     for (Tuple2<StreamShardMetadata, SequenceNumber> state : globalUnionState) {         listState.add(state).     }     FlinkKinesisConsumer<String> consumer = new FlinkKinesisConsumer<>("fakeStream", new SimpleStringSchema(), config).     RuntimeContext context = mock(RuntimeContext.class).     when(context.getIndexOfThisSubtask()).thenReturn(0).     when(context.getNumberOfParallelSubtasks()).thenReturn(2).     consumer.setRuntimeContext(context).     OperatorStateStore operatorStateStore = mock(OperatorStateStore.class).     when(operatorStateStore.getUnionListState(Matchers.any(ListStateDescriptor.class))).thenReturn(listState).     StateInitializationContext initializationContext = mock(StateInitializationContext.class).     when(initializationContext.getOperatorStateStore()).thenReturn(operatorStateStore).     when(initializationContext.isRestored()).thenReturn(true).     consumer.initializeState(initializationContext).     // only opened, not run     consumer.open(new Configuration()).     // arbitrary checkpoint id and timestamp     consumer.snapshotState(new StateSnapshotContextSynchronousImpl(123, 123)).     assertTrue(listState.isClearCalled()).     // the checkpointed list state should contain only the shards that it should subscribe to     assertEquals(globalUnionState.size() / 2, listState.getList().size()).     assertTrue(listState.getList().contains(globalUnionState.get(0))).     assertTrue(listState.getList().contains(globalUnionState.get(2))). }
false;public;0;90;;@Test public void testListStateChangedAfterSnapshotState() throws Exception {     // ----------------------------------------------------------------------     // setup config, initial state and expected state snapshot     // ----------------------------------------------------------------------     Properties config = TestUtils.getStandardProperties().     ArrayList<Tuple2<StreamShardMetadata, SequenceNumber>> initialState = new ArrayList<>(1).     initialState.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(new StreamShardHandle("fakeStream1", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(0)))), new SequenceNumber("1"))).     ArrayList<Tuple2<StreamShardMetadata, SequenceNumber>> expectedStateSnapshot = new ArrayList<>(3).     expectedStateSnapshot.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(new StreamShardHandle("fakeStream1", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(0)))), new SequenceNumber("12"))).     expectedStateSnapshot.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(new StreamShardHandle("fakeStream1", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(1)))), new SequenceNumber("11"))).     expectedStateSnapshot.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(new StreamShardHandle("fakeStream1", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(2)))), new SequenceNumber("31"))).     // ----------------------------------------------------------------------     // mock operator state backend and initial state for initializeState()     // ----------------------------------------------------------------------     TestingListState<Tuple2<StreamShardMetadata, SequenceNumber>> listState = new TestingListState<>().     for (Tuple2<StreamShardMetadata, SequenceNumber> state : initialState) {         listState.add(state).     }     OperatorStateStore operatorStateStore = mock(OperatorStateStore.class).     when(operatorStateStore.getUnionListState(Matchers.any(ListStateDescriptor.class))).thenReturn(listState).     StateInitializationContext initializationContext = mock(StateInitializationContext.class).     when(initializationContext.getOperatorStateStore()).thenReturn(operatorStateStore).     when(initializationContext.isRestored()).thenReturn(true).     // ----------------------------------------------------------------------     // mock a running fetcher and its state for snapshot     // ----------------------------------------------------------------------     HashMap<StreamShardMetadata, SequenceNumber> stateSnapshot = new HashMap<>().     for (Tuple2<StreamShardMetadata, SequenceNumber> tuple : expectedStateSnapshot) {         stateSnapshot.put(tuple.f0, tuple.f1).     }     KinesisDataFetcher mockedFetcher = mock(KinesisDataFetcher.class).     when(mockedFetcher.snapshotState()).thenReturn(stateSnapshot).     // ----------------------------------------------------------------------     // create a consumer and test the snapshotState()     // ----------------------------------------------------------------------     FlinkKinesisConsumer<String> consumer = new FlinkKinesisConsumer<>("fakeStream", new SimpleStringSchema(), config).     FlinkKinesisConsumer<?> mockedConsumer = spy(consumer).     RuntimeContext context = mock(RuntimeContext.class).     when(context.getIndexOfThisSubtask()).thenReturn(1).     mockedConsumer.setRuntimeContext(context).     mockedConsumer.initializeState(initializationContext).     mockedConsumer.open(new Configuration()).     // mock consumer as running.     Whitebox.setInternalState(mockedConsumer, "fetcher", mockedFetcher).     mockedConsumer.snapshotState(mock(FunctionSnapshotContext.class)).     assertEquals(true, listState.clearCalled).     assertEquals(3, listState.getList().size()).     for (Tuple2<StreamShardMetadata, SequenceNumber> state : initialState) {         for (Tuple2<StreamShardMetadata, SequenceNumber> currentState : listState.getList()) {             assertNotEquals(state, currentState).         }     }     for (Tuple2<StreamShardMetadata, SequenceNumber> state : expectedStateSnapshot) {         boolean hasOneIsSame = false.         for (Tuple2<StreamShardMetadata, SequenceNumber> currentState : listState.getList()) {             hasOneIsSame = hasOneIsSame || state.equals(currentState).         }         assertEquals(true, hasOneIsSame).     } }
false;public;0;14;;// ---------------------------------------------------------------------- // Tests related to fetcher initialization // ---------------------------------------------------------------------- @Test @SuppressWarnings("unchecked") public void testFetcherShouldNotBeRestoringFromFailureIfNotRestoringFromCheckpoint() throws Exception {     KinesisDataFetcher mockedFetcher = mockKinesisDataFetcher().     // assume the given config is correct     PowerMockito.mockStatic(KinesisConfigUtil.class).     PowerMockito.doNothing().when(KinesisConfigUtil.class).     TestableFlinkKinesisConsumer consumer = new TestableFlinkKinesisConsumer("fakeStream", new Properties(), 10, 2).     consumer.open(new Configuration()).     consumer.run(Mockito.mock(SourceFunction.SourceContext.class)). }
false;public;0;55;;@Test @SuppressWarnings("unchecked") public void testFetcherShouldBeCorrectlySeededIfRestoringFromCheckpoint() throws Exception {     // ----------------------------------------------------------------------     // setup initial state     // ----------------------------------------------------------------------     HashMap<StreamShardHandle, SequenceNumber> fakeRestoredState = getFakeRestoredStore("all").     // ----------------------------------------------------------------------     // mock operator state backend and initial state for initializeState()     // ----------------------------------------------------------------------     TestingListState<Tuple2<StreamShardMetadata, SequenceNumber>> listState = new TestingListState<>().     for (Map.Entry<StreamShardHandle, SequenceNumber> state : fakeRestoredState.entrySet()) {         listState.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(state.getKey()), state.getValue())).     }     OperatorStateStore operatorStateStore = mock(OperatorStateStore.class).     when(operatorStateStore.getUnionListState(Matchers.any(ListStateDescriptor.class))).thenReturn(listState).     StateInitializationContext initializationContext = mock(StateInitializationContext.class).     when(initializationContext.getOperatorStateStore()).thenReturn(operatorStateStore).     when(initializationContext.isRestored()).thenReturn(true).     // ----------------------------------------------------------------------     // mock fetcher     // ----------------------------------------------------------------------     KinesisDataFetcher mockedFetcher = mockKinesisDataFetcher().     List<StreamShardHandle> shards = new ArrayList<>().     shards.addAll(fakeRestoredState.keySet()).     when(mockedFetcher.discoverNewShardsToSubscribe()).thenReturn(shards).     // assume the given config is correct     PowerMockito.mockStatic(KinesisConfigUtil.class).     PowerMockito.doNothing().when(KinesisConfigUtil.class).     // ----------------------------------------------------------------------     // start to test fetcher's initial state seeding     // ----------------------------------------------------------------------     TestableFlinkKinesisConsumer consumer = new TestableFlinkKinesisConsumer("fakeStream", new Properties(), 10, 2).     consumer.initializeState(initializationContext).     consumer.open(new Configuration()).     consumer.run(Mockito.mock(SourceFunction.SourceContext.class)).     for (Map.Entry<StreamShardHandle, SequenceNumber> restoredShard : fakeRestoredState.entrySet()) {         Mockito.verify(mockedFetcher).registerNewSubscribedShardState(new KinesisStreamShardState(KinesisDataFetcher.convertToStreamShardMetadata(restoredShard.getKey()), restoredShard.getKey(), restoredShard.getValue())).     } }
false;public;0;67;;@Test @SuppressWarnings("unchecked") public void testFetcherShouldBeCorrectlySeededOnlyItsOwnStates() throws Exception {     // ----------------------------------------------------------------------     // setup initial state     // ----------------------------------------------------------------------     HashMap<StreamShardHandle, SequenceNumber> fakeRestoredState = getFakeRestoredStore("fakeStream1").     HashMap<StreamShardHandle, SequenceNumber> fakeRestoredStateForOthers = getFakeRestoredStore("fakeStream2").     // ----------------------------------------------------------------------     // mock operator state backend and initial state for initializeState()     // ----------------------------------------------------------------------     TestingListState<Tuple2<StreamShardMetadata, SequenceNumber>> listState = new TestingListState<>().     for (Map.Entry<StreamShardHandle, SequenceNumber> state : fakeRestoredState.entrySet()) {         listState.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(state.getKey()), state.getValue())).     }     for (Map.Entry<StreamShardHandle, SequenceNumber> state : fakeRestoredStateForOthers.entrySet()) {         listState.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(state.getKey()), state.getValue())).     }     OperatorStateStore operatorStateStore = mock(OperatorStateStore.class).     when(operatorStateStore.getUnionListState(Matchers.any(ListStateDescriptor.class))).thenReturn(listState).     StateInitializationContext initializationContext = mock(StateInitializationContext.class).     when(initializationContext.getOperatorStateStore()).thenReturn(operatorStateStore).     when(initializationContext.isRestored()).thenReturn(true).     // ----------------------------------------------------------------------     // mock fetcher     // ----------------------------------------------------------------------     KinesisDataFetcher mockedFetcher = mockKinesisDataFetcher().     List<StreamShardHandle> shards = new ArrayList<>().     shards.addAll(fakeRestoredState.keySet()).     when(mockedFetcher.discoverNewShardsToSubscribe()).thenReturn(shards).     // assume the given config is correct     PowerMockito.mockStatic(KinesisConfigUtil.class).     PowerMockito.doNothing().when(KinesisConfigUtil.class).     // ----------------------------------------------------------------------     // start to test fetcher's initial state seeding     // ----------------------------------------------------------------------     TestableFlinkKinesisConsumer consumer = new TestableFlinkKinesisConsumer("fakeStream", new Properties(), 10, 2).     consumer.initializeState(initializationContext).     consumer.open(new Configuration()).     consumer.run(Mockito.mock(SourceFunction.SourceContext.class)).     for (Map.Entry<StreamShardHandle, SequenceNumber> restoredShard : fakeRestoredStateForOthers.entrySet()) {         // should never get restored state not belonging to itself         Mockito.verify(mockedFetcher, never()).registerNewSubscribedShardState(new KinesisStreamShardState(KinesisDataFetcher.convertToStreamShardMetadata(restoredShard.getKey()), restoredShard.getKey(), restoredShard.getValue())).     }     for (Map.Entry<StreamShardHandle, SequenceNumber> restoredShard : fakeRestoredState.entrySet()) {         // should get restored state belonging to itself         Mockito.verify(mockedFetcher).registerNewSubscribedShardState(new KinesisStreamShardState(KinesisDataFetcher.convertToStreamShardMetadata(restoredShard.getKey()), restoredShard.getKey(), restoredShard.getValue())).     } }
true;public;0;60;/* 	 * This tests that the consumer correctly picks up shards that were not discovered on the previous run. 	 * 	 * Case under test: 	 * 	 * If the original parallelism is 2 and states are: 	 *   Consumer subtask 1: 	 *     stream1, shard1, SequentialNumber(xxx) 	 *   Consumer subtask 2: 	 *     stream1, shard2, SequentialNumber(yyy) 	 * 	 * After discoverNewShardsToSubscribe() if there were two shards (shard3, shard4) created: 	 *   Consumer subtask 1 (late for discoverNewShardsToSubscribe()): 	 *     stream1, shard1, SequentialNumber(xxx) 	 *   Consumer subtask 2: 	 *     stream1, shard2, SequentialNumber(yyy) 	 *     stream1, shard4, SequentialNumber(zzz) 	 * 	 * If snapshotState() occurs and parallelism is changed to 1: 	 *   Union state will be: 	 *     stream1, shard1, SequentialNumber(xxx) 	 *     stream1, shard2, SequentialNumber(yyy) 	 *     stream1, shard4, SequentialNumber(zzz) 	 *   Fetcher should be seeded with: 	 *     stream1, shard1, SequentialNumber(xxx) 	 *     stream1, shard2, SequentialNumber(yyy) 	 *     stream1, share3, SentinelSequenceNumber.SENTINEL_EARLIEST_SEQUENCE_NUM 	 *     stream1, shard4, SequentialNumber(zzz) 	 */ ;/* 	 * This tests that the consumer correctly picks up shards that were not discovered on the previous run. 	 * 	 * Case under test: 	 * 	 * If the original parallelism is 2 and states are: 	 *   Consumer subtask 1: 	 *     stream1, shard1, SequentialNumber(xxx) 	 *   Consumer subtask 2: 	 *     stream1, shard2, SequentialNumber(yyy) 	 * 	 * After discoverNewShardsToSubscribe() if there were two shards (shard3, shard4) created: 	 *   Consumer subtask 1 (late for discoverNewShardsToSubscribe()): 	 *     stream1, shard1, SequentialNumber(xxx) 	 *   Consumer subtask 2: 	 *     stream1, shard2, SequentialNumber(yyy) 	 *     stream1, shard4, SequentialNumber(zzz) 	 * 	 * If snapshotState() occurs and parallelism is changed to 1: 	 *   Union state will be: 	 *     stream1, shard1, SequentialNumber(xxx) 	 *     stream1, shard2, SequentialNumber(yyy) 	 *     stream1, shard4, SequentialNumber(zzz) 	 *   Fetcher should be seeded with: 	 *     stream1, shard1, SequentialNumber(xxx) 	 *     stream1, shard2, SequentialNumber(yyy) 	 *     stream1, share3, SentinelSequenceNumber.SENTINEL_EARLIEST_SEQUENCE_NUM 	 *     stream1, shard4, SequentialNumber(zzz) 	 */ @Test @SuppressWarnings("unchecked") public void testFetcherShouldBeCorrectlySeededWithNewDiscoveredKinesisStreamShard() throws Exception {     // ----------------------------------------------------------------------     // setup initial state     // ----------------------------------------------------------------------     HashMap<StreamShardHandle, SequenceNumber> fakeRestoredState = getFakeRestoredStore("all").     // ----------------------------------------------------------------------     // mock operator state backend and initial state for initializeState()     // ----------------------------------------------------------------------     TestingListState<Tuple2<StreamShardMetadata, SequenceNumber>> listState = new TestingListState<>().     for (Map.Entry<StreamShardHandle, SequenceNumber> state : fakeRestoredState.entrySet()) {         listState.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(state.getKey()), state.getValue())).     }     OperatorStateStore operatorStateStore = mock(OperatorStateStore.class).     when(operatorStateStore.getUnionListState(Matchers.any(ListStateDescriptor.class))).thenReturn(listState).     StateInitializationContext initializationContext = mock(StateInitializationContext.class).     when(initializationContext.getOperatorStateStore()).thenReturn(operatorStateStore).     when(initializationContext.isRestored()).thenReturn(true).     // ----------------------------------------------------------------------     // mock fetcher     // ----------------------------------------------------------------------     KinesisDataFetcher mockedFetcher = mockKinesisDataFetcher().     List<StreamShardHandle> shards = new ArrayList<>().     shards.addAll(fakeRestoredState.keySet()).     shards.add(new StreamShardHandle("fakeStream2", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(2)))).     when(mockedFetcher.discoverNewShardsToSubscribe()).thenReturn(shards).     // assume the given config is correct     PowerMockito.mockStatic(KinesisConfigUtil.class).     PowerMockito.doNothing().when(KinesisConfigUtil.class).     // ----------------------------------------------------------------------     // start to test fetcher's initial state seeding     // ----------------------------------------------------------------------     TestableFlinkKinesisConsumer consumer = new TestableFlinkKinesisConsumer("fakeStream", new Properties(), 10, 2).     consumer.initializeState(initializationContext).     consumer.open(new Configuration()).     consumer.run(Mockito.mock(SourceFunction.SourceContext.class)).     fakeRestoredState.put(new StreamShardHandle("fakeStream2", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(2))), SentinelSequenceNumber.SENTINEL_EARLIEST_SEQUENCE_NUM.get()).     for (Map.Entry<StreamShardHandle, SequenceNumber> restoredShard : fakeRestoredState.entrySet()) {         Mockito.verify(mockedFetcher).registerNewSubscribedShardState(new KinesisStreamShardState(KinesisDataFetcher.convertToStreamShardMetadata(restoredShard.getKey()), restoredShard.getKey(), restoredShard.getValue())).     } }
false;public;0;35;;@Test public void testLegacyKinesisStreamShardToStreamShardMetadataConversion() {     String streamName = "fakeStream1".     String shardId = "shard-000001".     String parentShardId = "shard-000002".     String adjacentParentShardId = "shard-000003".     String startingHashKey = "key-000001".     String endingHashKey = "key-000010".     String startingSequenceNumber = "seq-0000021".     String endingSequenceNumber = "seq-00000031".     StreamShardMetadata streamShardMetadata = new StreamShardMetadata().     streamShardMetadata.setStreamName(streamName).     streamShardMetadata.setShardId(shardId).     streamShardMetadata.setParentShardId(parentShardId).     streamShardMetadata.setAdjacentParentShardId(adjacentParentShardId).     streamShardMetadata.setStartingHashKey(startingHashKey).     streamShardMetadata.setEndingHashKey(endingHashKey).     streamShardMetadata.setStartingSequenceNumber(startingSequenceNumber).     streamShardMetadata.setEndingSequenceNumber(endingSequenceNumber).     Shard shard = new Shard().withShardId(shardId).withParentShardId(parentShardId).withAdjacentParentShardId(adjacentParentShardId).withHashKeyRange(new HashKeyRange().withStartingHashKey(startingHashKey).withEndingHashKey(endingHashKey)).withSequenceNumberRange(new SequenceNumberRange().withStartingSequenceNumber(startingSequenceNumber).withEndingSequenceNumber(endingSequenceNumber)).     KinesisStreamShard kinesisStreamShard = new KinesisStreamShard(streamName, shard).     assertEquals(streamShardMetadata, KinesisStreamShard.convertToStreamShardMetadata(kinesisStreamShard)). }
false;public;0;5;;@Test public void testStreamShardMetadataSerializedUsingPojoSerializer() {     TypeInformation<StreamShardMetadata> typeInformation = TypeInformation.of(StreamShardMetadata.class).     assertTrue(typeInformation.createSerializer(new ExecutionConfig()) instanceof PojoSerializer). }
true;public;0;61;/**  * FLINK-8484: ensure that a state change in the StreamShardMetadata other than {@link StreamShardMetadata#shardId} or  * {@link StreamShardMetadata#streamName} does not result in the shard not being able to be restored.  * This handles the corner case where the stored shard metadata is open (no ending sequence number), but after the  * job restore, the shard has been closed (ending number set) due to re-sharding, and we can no longer rely on  * {@link StreamShardMetadata#equals(Object)} to find back the sequence number in the collection of restored shard metadata.  * <p></p>  * Therefore, we will rely on synchronizing the snapshot's state with the Kinesis shard before attempting to find back  * the sequence number to restore.  */ ;/**  * FLINK-8484: ensure that a state change in the StreamShardMetadata other than {@link StreamShardMetadata#shardId} or  * {@link StreamShardMetadata#streamName} does not result in the shard not being able to be restored.  * This handles the corner case where the stored shard metadata is open (no ending sequence number), but after the  * job restore, the shard has been closed (ending number set) due to re-sharding, and we can no longer rely on  * {@link StreamShardMetadata#equals(Object)} to find back the sequence number in the collection of restored shard metadata.  * <p></p>  * Therefore, we will rely on synchronizing the snapshot's state with the Kinesis shard before attempting to find back  * the sequence number to restore.  */ @Test public void testFindSequenceNumberToRestoreFromIfTheShardHasBeenClosedSinceTheStateWasStored() throws Exception {     // ----------------------------------------------------------------------     // setup initial state     // ----------------------------------------------------------------------     HashMap<StreamShardHandle, SequenceNumber> fakeRestoredState = getFakeRestoredStore("all").     // ----------------------------------------------------------------------     // mock operator state backend and initial state for initializeState()     // ----------------------------------------------------------------------     TestingListState<Tuple2<StreamShardMetadata, SequenceNumber>> listState = new TestingListState<>().     for (Map.Entry<StreamShardHandle, SequenceNumber> state : fakeRestoredState.entrySet()) {         listState.add(Tuple2.of(KinesisDataFetcher.convertToStreamShardMetadata(state.getKey()), state.getValue())).     }     OperatorStateStore operatorStateStore = mock(OperatorStateStore.class).     when(operatorStateStore.getUnionListState(Matchers.any(ListStateDescriptor.class))).thenReturn(listState).     StateInitializationContext initializationContext = mock(StateInitializationContext.class).     when(initializationContext.getOperatorStateStore()).thenReturn(operatorStateStore).     when(initializationContext.isRestored()).thenReturn(true).     // ----------------------------------------------------------------------     // mock fetcher     // ----------------------------------------------------------------------     KinesisDataFetcher mockedFetcher = mockKinesisDataFetcher().     List<StreamShardHandle> shards = new ArrayList<>().     // create a fake stream shard handle based on the first entry in the restored state     final StreamShardHandle originalStreamShardHandle = fakeRestoredState.keySet().iterator().next().     final StreamShardHandle closedStreamShardHandle = new StreamShardHandle(originalStreamShardHandle.getStreamName(), originalStreamShardHandle.getShard()).     // close the shard handle by setting an ending sequence number     final SequenceNumberRange sequenceNumberRange = new SequenceNumberRange().     sequenceNumberRange.setEndingSequenceNumber("1293844").     closedStreamShardHandle.getShard().setSequenceNumberRange(sequenceNumberRange).     shards.add(closedStreamShardHandle).     when(mockedFetcher.discoverNewShardsToSubscribe()).thenReturn(shards).     // assume the given config is correct     PowerMockito.mockStatic(KinesisConfigUtil.class).     PowerMockito.doNothing().when(KinesisConfigUtil.class).     // ----------------------------------------------------------------------     // start to test fetcher's initial state seeding     // ----------------------------------------------------------------------     TestableFlinkKinesisConsumer consumer = new TestableFlinkKinesisConsumer("fakeStream", new Properties(), 10, 2).     consumer.initializeState(initializationContext).     consumer.open(new Configuration()).     consumer.run(Mockito.mock(SourceFunction.SourceContext.class)).     Mockito.verify(mockedFetcher).registerNewSubscribedShardState(new KinesisStreamShardState(KinesisDataFetcher.convertToStreamShardMetadata(closedStreamShardHandle), closedStreamShardHandle, fakeRestoredState.get(closedStreamShardHandle))). }
false;public;0;5;;@Override public void clear() {     list.clear().     clearCalled = true. }
false;public;0;4;;@Override public Iterable<T> get() throws Exception {     return list. }
false;public;1;4;;@Override public void add(T value) throws Exception {     list.add(value). }
false;public;0;3;;public List<T> getList() {     return list. }
false;public;0;3;;public boolean isClearCalled() {     return clearCalled. }
false;public;1;6;;@Override public void update(List<T> values) throws Exception {     list.clear().     addAll(values). }
false;public;1;6;;@Override public void addAll(List<T> values) throws Exception {     if (values != null) {         list.addAll(values).     } }
false;private;1;31;;private HashMap<StreamShardHandle, SequenceNumber> getFakeRestoredStore(String streamName) {     HashMap<StreamShardHandle, SequenceNumber> fakeRestoredState = new HashMap<>().     if (streamName.equals("fakeStream1") || streamName.equals("all")) {         fakeRestoredState.put(new StreamShardHandle("fakeStream1", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(0))), new SequenceNumber(UUID.randomUUID().toString())).         fakeRestoredState.put(new StreamShardHandle("fakeStream1", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(1))), new SequenceNumber(UUID.randomUUID().toString())).         fakeRestoredState.put(new StreamShardHandle("fakeStream1", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(2))), new SequenceNumber(UUID.randomUUID().toString())).     }     if (streamName.equals("fakeStream2") || streamName.equals("all")) {         fakeRestoredState.put(new StreamShardHandle("fakeStream2", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(0))), new SequenceNumber(UUID.randomUUID().toString())).         fakeRestoredState.put(new StreamShardHandle("fakeStream2", new Shard().withShardId(KinesisShardIdGenerator.generateFromShardOrder(1))), new SequenceNumber(UUID.randomUUID().toString())).     }     return fakeRestoredState. }
false;private,static;0;18;;private static KinesisDataFetcher mockKinesisDataFetcher() throws Exception {     KinesisDataFetcher mockedFetcher = Mockito.mock(KinesisDataFetcher.class).     java.lang.reflect.Constructor<KinesisDataFetcher> ctor = (java.lang.reflect.Constructor<KinesisDataFetcher>) KinesisDataFetcher.class.getConstructors()[0].     Class<?>[] otherParamTypes = new Class<?>[ctor.getParameterTypes().length - 1].     System.arraycopy(ctor.getParameterTypes(), 1, otherParamTypes, 0, ctor.getParameterTypes().length - 1).     Supplier<Object[]> argumentSupplier = () -> {         Object[] otherParamArgs = new Object[otherParamTypes.length].         for (int i = 0. i < otherParamTypes.length. i++) {             otherParamArgs[i] = Mockito.nullable(otherParamTypes[i]).         }         return otherParamArgs.     }.     PowerMockito.whenNew(ctor).withArguments(Mockito.any(ctor.getParameterTypes()[0]), argumentSupplier.get()).thenReturn(mockedFetcher).     return mockedFetcher. }
false;protected;5;25;;@Override protected KinesisDataFetcher<String> createFetcher(List<String> streams, SourceContext<String> sourceContext, RuntimeContext runtimeContext, Properties configProps, KinesisDeserializationSchema<String> deserializationSchema) {     KinesisDataFetcher<String> fetcher = new KinesisDataFetcher<String>(streams, sourceContext, sourceContext.getCheckpointLock(), runtimeContext, configProps, deserializationSchema, getShardAssigner(), getPeriodicWatermarkAssigner(), new AtomicReference<>(), new ArrayList<>(), subscribedStreamsToLastDiscoveredShardIds, (props) -> FakeKinesisBehavioursFactory.blockingQueueGetRecords(streamToQueueMap)) {     }.     return fetcher. }
false;public;1;4;;@Override public void emitWatermark(Watermark mark) {     watermarks.add(mark). }
false;public;0;122;;@Test public void testPeriodicWatermark() throws Exception {     String streamName = "fakeStreamName".     Time maxOutOfOrderness = Time.milliseconds(5).     long autoWatermarkInterval = 1_000.     HashMap<String, String> subscribedStreamsToLastDiscoveredShardIds = new HashMap<>().     subscribedStreamsToLastDiscoveredShardIds.put(streamName, null).     KinesisDeserializationSchema<String> deserializationSchema = new KinesisDeserializationSchemaWrapper<>(new SimpleStringSchema()).     Properties props = new Properties().     props.setProperty(ConsumerConfigConstants.AWS_REGION, "us-east-1").     props.setProperty(ConsumerConfigConstants.SHARD_GETRECORDS_INTERVAL_MILLIS, Long.toString(10L)).     BlockingQueue<String> shard1 = new LinkedBlockingQueue().     BlockingQueue<String> shard2 = new LinkedBlockingQueue().     Map<String, List<BlockingQueue<String>>> streamToQueueMap = new HashMap<>().     streamToQueueMap.put(streamName, Lists.newArrayList(shard1, shard2)).     // override createFetcher to mock Kinesis     FlinkKinesisConsumer<String> sourceFunc = new FlinkKinesisConsumer<String>(streamName, deserializationSchema, props) {          @Override         protected KinesisDataFetcher<String> createFetcher(List<String> streams, SourceContext<String> sourceContext, RuntimeContext runtimeContext, Properties configProps, KinesisDeserializationSchema<String> deserializationSchema) {             KinesisDataFetcher<String> fetcher = new KinesisDataFetcher<String>(streams, sourceContext, sourceContext.getCheckpointLock(), runtimeContext, configProps, deserializationSchema, getShardAssigner(), getPeriodicWatermarkAssigner(), new AtomicReference<>(), new ArrayList<>(), subscribedStreamsToLastDiscoveredShardIds, (props) -> FakeKinesisBehavioursFactory.blockingQueueGetRecords(streamToQueueMap)) {             }.             return fetcher.         }     }.     sourceFunc.setShardAssigner((streamShardHandle, i) -> {         // shardId-000000000000         return Integer.parseInt(streamShardHandle.getShard().getShardId().substring("shardId-".length())).     }).     sourceFunc.setPeriodicWatermarkAssigner(new TestTimestampExtractor(maxOutOfOrderness)).     // there is currently no test harness specifically for sources,     // so we overlay the source thread here     AbstractStreamOperatorTestHarness<Object> testHarness = new AbstractStreamOperatorTestHarness<Object>(new StreamSource(sourceFunc), 1, 1, 0).     testHarness.setTimeCharacteristic(TimeCharacteristic.EventTime).     testHarness.getExecutionConfig().setAutoWatermarkInterval(autoWatermarkInterval).     testHarness.initializeEmptyState().     testHarness.open().     ConcurrentLinkedQueue<Watermark> watermarks = new ConcurrentLinkedQueue<>().     @SuppressWarnings("unchecked")     SourceFunction.SourceContext<String> sourceContext = new CollectingSourceContext(testHarness.getCheckpointLock(), testHarness.getOutput()) {          @Override         public void emitWatermark(Watermark mark) {             watermarks.add(mark).         }     }.     new Thread(() -> {         try {             sourceFunc.run(sourceContext).         } catch (InterruptedException e) {         // expected on cancel         } catch (Exception e) {             throw new RuntimeException(e).         }     }).start().     shard1.put("1").     shard1.put("2").     shard2.put("10").     int recordCount = 3.     int watermarkCount = 0.     awaitRecordCount(testHarness.getOutput(), recordCount).     // trigger watermark emit     testHarness.setProcessingTime(testHarness.getProcessingTime() + autoWatermarkInterval).     watermarkCount++.     // advance watermark     shard1.put("10").     recordCount++.     awaitRecordCount(testHarness.getOutput(), recordCount).     // trigger watermark emit     testHarness.setProcessingTime(testHarness.getProcessingTime() + autoWatermarkInterval).     watermarkCount++.     sourceFunc.cancel().     testHarness.close().     assertEquals("record count", recordCount, testHarness.getOutput().size()).     assertEquals("watermark count", watermarkCount, watermarks.size()).     assertThat(watermarks, org.hamcrest.Matchers.contains(new Watermark(-3), new Watermark(5))). }
false;private;2;6;;private void awaitRecordCount(ConcurrentLinkedQueue<? extends Object> queue, int count) throws Exception {     long timeoutMillis = System.currentTimeMillis() + 10_000.     while (System.currentTimeMillis() < timeoutMillis && queue.size() < count) {         Thread.sleep(10).     } }
false;public;1;4;;@Override public long extractTimestamp(String element) {     return Long.parseLong(element). }
