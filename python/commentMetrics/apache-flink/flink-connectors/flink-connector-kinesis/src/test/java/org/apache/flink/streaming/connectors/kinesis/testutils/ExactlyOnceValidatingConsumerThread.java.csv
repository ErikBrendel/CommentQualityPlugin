commented;modifiers;parameterAmount;loc;comment;code
false;public;0;30;;@Override public void run() {     try {         StreamExecutionEnvironment see = StreamExecutionEnvironment.createRemoteEnvironment("localhost", flinkPort, flinkConfig).         see.setParallelism(parallelism).         see.enableCheckpointing(checkpointInterval).         // we restart two times         see.setRestartStrategy(RestartStrategies.fixedDelayRestart(2, restartDelay)).         // consuming topology         Properties consumerProps = new Properties().         consumerProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, awsAccessKey).         consumerProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, awsSecretKey).         consumerProps.setProperty(ConsumerConfigConstants.AWS_REGION, awsRegion).         // start reading from beginning         consumerProps.setProperty(ConsumerConfigConstants.STREAM_INITIAL_POSITION, ConsumerConfigConstants.InitialPosition.TRIM_HORIZON.name()).         DataStream<String> consuming = see.addSource(new FlinkKinesisConsumer<>(kinesisStreamName, new SimpleStringSchema(), consumerProps)).         consuming.flatMap(new ArtificialFailOnceFlatMapper(failAtRecordCount)).flatMap(new ExactlyOnceValidatingMapper(totalEventCount)).setParallelism(1).         LOG.info("Starting consuming topology").         tryExecute(see, "Consuming topo").         LOG.info("Consuming topo finished").     } catch (Exception e) {         LOG.warn("Error while running consuming topology", e).         errorHandler.set(e).     } }
false;public,static;12;47;;public static Thread create(final int totalEventCount, final int failAtRecordCount, final int parallelism, final int checkpointInterval, final long restartDelay, final String awsAccessKey, final String awsSecretKey, final String awsRegion, final String kinesisStreamName, final AtomicReference<Throwable> errorHandler, final int flinkPort, final Configuration flinkConfig) {     Runnable exactlyOnceValidationConsumer = new Runnable() {          @Override         public void run() {             try {                 StreamExecutionEnvironment see = StreamExecutionEnvironment.createRemoteEnvironment("localhost", flinkPort, flinkConfig).                 see.setParallelism(parallelism).                 see.enableCheckpointing(checkpointInterval).                 // we restart two times                 see.setRestartStrategy(RestartStrategies.fixedDelayRestart(2, restartDelay)).                 // consuming topology                 Properties consumerProps = new Properties().                 consumerProps.setProperty(ConsumerConfigConstants.AWS_ACCESS_KEY_ID, awsAccessKey).                 consumerProps.setProperty(ConsumerConfigConstants.AWS_SECRET_ACCESS_KEY, awsSecretKey).                 consumerProps.setProperty(ConsumerConfigConstants.AWS_REGION, awsRegion).                 // start reading from beginning                 consumerProps.setProperty(ConsumerConfigConstants.STREAM_INITIAL_POSITION, ConsumerConfigConstants.InitialPosition.TRIM_HORIZON.name()).                 DataStream<String> consuming = see.addSource(new FlinkKinesisConsumer<>(kinesisStreamName, new SimpleStringSchema(), consumerProps)).                 consuming.flatMap(new ArtificialFailOnceFlatMapper(failAtRecordCount)).flatMap(new ExactlyOnceValidatingMapper(totalEventCount)).setParallelism(1).                 LOG.info("Starting consuming topology").                 tryExecute(see, "Consuming topo").                 LOG.info("Consuming topo finished").             } catch (Exception e) {                 LOG.warn("Error while running consuming topology", e).                 errorHandler.set(e).             }         }     }.     return new Thread(exactlyOnceValidationConsumer). }
false;public;2;17;;@Override public void flatMap(String value, Collector<String> out) throws Exception {     LOG.info("Consumed {}", value).     int id = Integer.parseInt(value.split("-")[0]).     if (validator.get(id)) {         throw new RuntimeException("Saw id " + id + " twice!").     }     validator.set(id).     if (id > totalEventCount - 1) {         throw new RuntimeException("Out of bounds ID observed").     }     if (validator.nextClearBit(0) == totalEventCount) {         throw new SuccessException().     } }
false;public;2;4;;@Override public List<BitSet> snapshotState(long checkpointId, long timestamp) throws Exception {     return Collections.singletonList(validator). }
false;public;1;9;;@Override public void restoreState(List<BitSet> state) throws Exception {     // we expect either 1 or 0 elements     if (state.size() == 1) {         validator = state.get(0).     } else {         Preconditions.checkState(state.isEmpty()).     } }
false;public;2;7;;@Override public void flatMap(String value, Collector<String> out) throws Exception {     if (count++ >= failAtRecordCount && getRuntimeContext().getAttemptNumber() == 0) {         throw new RuntimeException("Artificial failure. Restart please.").     }     out.collect(value). }
