commented;modifiers;parameterAmount;loc;comment;code
true;protected;1;9;/**  * Returns a shard iterator for the given {@link SequenceNumber}.  *  * @return shard iterator  * @throws Exception  */ ;/**  * Returns a shard iterator for the given {@link SequenceNumber}.  *  * @return shard iterator  * @throws Exception  */ protected String getShardIterator(SequenceNumber sequenceNumber) throws Exception {     if (isSentinelSequenceNumber(sequenceNumber)) {         return getShardIteratorForSentinel(sequenceNumber).     } else {         // we will be starting from an actual sequence number (due to restore from failure).         return getShardIteratorForRealSequenceNumber(sequenceNumber).     } }
false;protected;1;22;;protected String getShardIteratorForSentinel(SequenceNumber sentinelSequenceNumber) throws InterruptedException {     String nextShardItr.     if (sentinelSequenceNumber.equals(SentinelSequenceNumber.SENTINEL_LATEST_SEQUENCE_NUM.get())) {         // if the shard is already closed, there will be no latest next record to get for this shard         if (subscribedShard.isClosed()) {             nextShardItr = null.         } else {             nextShardItr = kinesis.getShardIterator(subscribedShard, ShardIteratorType.LATEST.toString(), null).         }     } else if (sentinelSequenceNumber.equals(SentinelSequenceNumber.SENTINEL_EARLIEST_SEQUENCE_NUM.get())) {         nextShardItr = kinesis.getShardIterator(subscribedShard, ShardIteratorType.TRIM_HORIZON.toString(), null).     } else if (sentinelSequenceNumber.equals(SentinelSequenceNumber.SENTINEL_SHARD_ENDING_SEQUENCE_NUM.get())) {         nextShardItr = null.     } else if (sentinelSequenceNumber.equals(SentinelSequenceNumber.SENTINEL_AT_TIMESTAMP_SEQUENCE_NUM.get())) {         nextShardItr = kinesis.getShardIterator(subscribedShard, ShardIteratorType.AT_TIMESTAMP.toString(), initTimestamp).     } else {         throw new RuntimeException("Unknown sentinel type: " + sentinelSequenceNumber).     }     return nextShardItr. }
false;protected;1;16;;protected String getShardIteratorForRealSequenceNumber(SequenceNumber sequenceNumber) throws Exception {     if (sequenceNumber.isAggregated()) {         return getShardIteratorForAggregatedSequenceNumber(sequenceNumber).     } else {         // the last record was non-aggregated, so we can simply start from the next record         return kinesis.getShardIterator(subscribedShard, ShardIteratorType.AFTER_SEQUENCE_NUMBER.toString(), sequenceNumber.getSequenceNumber()).     } }
false;protected;1;28;;protected String getShardIteratorForAggregatedSequenceNumber(SequenceNumber sequenceNumber) throws Exception {     String itrForLastAggregatedRecord = kinesis.getShardIterator(subscribedShard, ShardIteratorType.AT_SEQUENCE_NUMBER.toString(), sequenceNumber.getSequenceNumber()).     // get only the last aggregated record     GetRecordsResult getRecordsResult = getRecords(itrForLastAggregatedRecord, 1).     List<UserRecord> fetchedRecords = deaggregateRecords(getRecordsResult.getRecords(), subscribedShard.getShard().getHashKeyRange().getStartingHashKey(), subscribedShard.getShard().getHashKeyRange().getEndingHashKey()).     long lastSubSequenceNum = sequenceNumber.getSubSequenceNumber().     for (UserRecord record : fetchedRecords) {         // than our last sequence number. if so, collect the record and update state         if (record.getSubSequenceNumber() > lastSubSequenceNum) {             deserializeRecordForCollectionAndUpdateState(record).         }     }     return getRecordsResult.getNextShardIterator(). }
false;public;0;50;;@SuppressWarnings("unchecked") @Override public void run() {     try {         String nextShardItr = getShardIterator(lastSequenceNum).         long processingStartTimeNanos = System.nanoTime().         while (isRunning()) {             if (nextShardItr == null) {                 fetcherRef.updateState(subscribedShardStateIndex, SentinelSequenceNumber.SENTINEL_SHARD_ENDING_SEQUENCE_NUM.get()).                 // we can close this consumer thread once we've reached the end of the subscribed shard                 break.             } else {                 shardMetricsReporter.setMaxNumberOfRecordsPerFetch(maxNumberOfRecordsPerFetch).                 GetRecordsResult getRecordsResult = getRecords(nextShardItr, maxNumberOfRecordsPerFetch).                 List<Record> aggregatedRecords = getRecordsResult.getRecords().                 int numberOfAggregatedRecords = aggregatedRecords.size().                 shardMetricsReporter.setNumberOfAggregatedRecords(numberOfAggregatedRecords).                 // each of the Kinesis records may be aggregated, so we must deaggregate them before proceeding                 List<UserRecord> fetchedRecords = deaggregateRecords(aggregatedRecords, subscribedShard.getShard().getHashKeyRange().getStartingHashKey(), subscribedShard.getShard().getHashKeyRange().getEndingHashKey()).                 long recordBatchSizeBytes = 0L.                 for (UserRecord record : fetchedRecords) {                     recordBatchSizeBytes += record.getData().remaining().                     deserializeRecordForCollectionAndUpdateState(record).                 }                 int numberOfDeaggregatedRecords = fetchedRecords.size().                 shardMetricsReporter.setNumberOfDeaggregatedRecords(numberOfDeaggregatedRecords).                 nextShardItr = getRecordsResult.getNextShardIterator().                 long adjustmentEndTimeNanos = adjustRunLoopFrequency(processingStartTimeNanos, System.nanoTime()).                 long runLoopTimeNanos = adjustmentEndTimeNanos - processingStartTimeNanos.                 maxNumberOfRecordsPerFetch = adaptRecordsToRead(runLoopTimeNanos, fetchedRecords.size(), recordBatchSizeBytes, maxNumberOfRecordsPerFetch).                 shardMetricsReporter.setRunLoopTimeNanos(runLoopTimeNanos).                 // for next time through the loop                 processingStartTimeNanos = adjustmentEndTimeNanos.             }         }     } catch (Throwable t) {         fetcherRef.stopWithError(t).     } }
true;protected;2;14;/**  * Adjusts loop timing to match target frequency if specified.  * @param processingStartTimeNanos The start time of the run loop "work"  * @param processingEndTimeNanos The end time of the run loop "work"  * @return The System.nanoTime() after the sleep (if any)  * @throws InterruptedException  */ ;/**  * Adjusts loop timing to match target frequency if specified.  * @param processingStartTimeNanos The start time of the run loop "work"  * @param processingEndTimeNanos The end time of the run loop "work"  * @return The System.nanoTime() after the sleep (if any)  * @throws InterruptedException  */ protected long adjustRunLoopFrequency(long processingStartTimeNanos, long processingEndTimeNanos) throws InterruptedException {     long endTimeNanos = processingEndTimeNanos.     if (fetchIntervalMillis != 0) {         long processingTimeNanos = processingEndTimeNanos - processingStartTimeNanos.         long sleepTimeMillis = fetchIntervalMillis - (processingTimeNanos / 1_000_000).         if (sleepTimeMillis > 0) {             Thread.sleep(sleepTimeMillis).             endTimeNanos = System.nanoTime().             shardMetricsReporter.setSleepTimeMillis(sleepTimeMillis).         }     }     return endTimeNanos. }
true;private;4;19;/**  * Calculates how many records to read each time through the loop based on a target throughput  * and the measured frequenecy of the loop.  * @param runLoopTimeNanos The total time of one pass through the loop  * @param numRecords The number of records of the last read operation  * @param recordBatchSizeBytes The total batch size of the last read operation  * @param maxNumberOfRecordsPerFetch The current maxNumberOfRecordsPerFetch  */ ;/**  * Calculates how many records to read each time through the loop based on a target throughput  * and the measured frequenecy of the loop.  * @param runLoopTimeNanos The total time of one pass through the loop  * @param numRecords The number of records of the last read operation  * @param recordBatchSizeBytes The total batch size of the last read operation  * @param maxNumberOfRecordsPerFetch The current maxNumberOfRecordsPerFetch  */ private int adaptRecordsToRead(long runLoopTimeNanos, int numRecords, long recordBatchSizeBytes, int maxNumberOfRecordsPerFetch) {     if (useAdaptiveReads && numRecords != 0 && runLoopTimeNanos != 0) {         long averageRecordSizeBytes = recordBatchSizeBytes / numRecords.         // Adjust number of records to fetch from the shard depending on current average record size         // to optimize 2 Mb / sec read limits         double loopFrequencyHz = 1000000000.0d / runLoopTimeNanos.         double bytesPerRead = KINESIS_SHARD_BYTES_PER_SECOND_LIMIT / loopFrequencyHz.         maxNumberOfRecordsPerFetch = (int) (bytesPerRead / averageRecordSizeBytes).         // Ensure the value is greater than 0 and not more than 10000L         maxNumberOfRecordsPerFetch = Math.max(1, Math.min(maxNumberOfRecordsPerFetch, ConsumerConfigConstants.DEFAULT_SHARD_GETRECORDS_MAX)).         // Set metrics         shardMetricsReporter.setAverageRecordSizeBytes(averageRecordSizeBytes).         shardMetricsReporter.setLoopFrequencyHz(loopFrequencyHz).         shardMetricsReporter.setBytesPerRead(bytesPerRead).     }     return maxNumberOfRecordsPerFetch. }
true;private;0;3;/**  * The loop in run() checks this before fetching next batch of records. Since this runnable will be executed  * by the ExecutorService {@link KinesisDataFetcher#shardConsumersExecutor}, the only way to close down this thread  * would be by calling shutdownNow() on {@link KinesisDataFetcher#shardConsumersExecutor} and let the executor service  * interrupt all currently running {@link ShardConsumer}s.  */ ;/**  * The loop in run() checks this before fetching next batch of records. Since this runnable will be executed  * by the ExecutorService {@link KinesisDataFetcher#shardConsumersExecutor}, the only way to close down this thread  * would be by calling shutdownNow() on {@link KinesisDataFetcher#shardConsumersExecutor} and let the executor service  * interrupt all currently running {@link ShardConsumer}s.  */ private boolean isRunning() {     return !Thread.interrupted(). }
true;private;1;29;/**  * Deserializes a record for collection, and accordingly updates the shard state in the fetcher. The last  * successfully collected sequence number in this shard consumer is also updated so that  * {@link ShardConsumer#getRecords(String, int)} may be able to use the correct sequence number to refresh shard  * iterators if necessary.  *  * <p>Note that the server-side Kinesis timestamp is attached to the record when collected. When the  * user programs uses {@link TimeCharacteristic#EventTime}, this timestamp will be used by default.  *  * @param record record to deserialize and collect  * @throws IOException  */ ;/**  * Deserializes a record for collection, and accordingly updates the shard state in the fetcher. The last  * successfully collected sequence number in this shard consumer is also updated so that  * {@link ShardConsumer#getRecords(String, int)} may be able to use the correct sequence number to refresh shard  * iterators if necessary.  *  * <p>Note that the server-side Kinesis timestamp is attached to the record when collected. When the  * user programs uses {@link TimeCharacteristic#EventTime}, this timestamp will be used by default.  *  * @param record record to deserialize and collect  * @throws IOException  */ private void deserializeRecordForCollectionAndUpdateState(UserRecord record) throws IOException {     ByteBuffer recordData = record.getData().     byte[] dataBytes = new byte[recordData.remaining()].     recordData.get(dataBytes).     final long approxArrivalTimestamp = record.getApproximateArrivalTimestamp().getTime().     final T value = deserializer.deserialize(dataBytes, record.getPartitionKey(), record.getSequenceNumber(), approxArrivalTimestamp, subscribedShard.getStreamName(), subscribedShard.getShard().getShardId()).     SequenceNumber collectedSequenceNumber = (record.isAggregated()) ? new SequenceNumber(record.getSequenceNumber(), record.getSubSequenceNumber()) : new SequenceNumber(record.getSequenceNumber()).     fetcherRef.emitRecordAndUpdateState(value, approxArrivalTimestamp, subscribedShardStateIndex, collectedSequenceNumber).     lastSequenceNum = collectedSequenceNumber. }
true;private;2;25;/**  * Calls {@link KinesisProxyInterface#getRecords(String, int)}, while also handling unexpected  * AWS {@link ExpiredIteratorException}s to assure that we get results and don't just fail on  * such occasions. The returned shard iterator within the successful {@link GetRecordsResult} should  * be used for the next call to this method.  *  * <p>Note: it is important that this method is not called again before all the records from the last result have been  * fully collected with {@link ShardConsumer#deserializeRecordForCollectionAndUpdateState(UserRecord)}, otherwise  * {@link ShardConsumer#lastSequenceNum} may refer to a sub-record in the middle of an aggregated record, leading to  * incorrect shard iteration if the iterator had to be refreshed.  *  * @param shardItr shard iterator to use  * @param maxNumberOfRecords the maximum number of records to fetch for this getRecords attempt  * @return get records result  * @throws InterruptedException  */ ;/**  * Calls {@link KinesisProxyInterface#getRecords(String, int)}, while also handling unexpected  * AWS {@link ExpiredIteratorException}s to assure that we get results and don't just fail on  * such occasions. The returned shard iterator within the successful {@link GetRecordsResult} should  * be used for the next call to this method.  *  * <p>Note: it is important that this method is not called again before all the records from the last result have been  * fully collected with {@link ShardConsumer#deserializeRecordForCollectionAndUpdateState(UserRecord)}, otherwise  * {@link ShardConsumer#lastSequenceNum} may refer to a sub-record in the middle of an aggregated record, leading to  * incorrect shard iteration if the iterator had to be refreshed.  *  * @param shardItr shard iterator to use  * @param maxNumberOfRecords the maximum number of records to fetch for this getRecords attempt  * @return get records result  * @throws InterruptedException  */ private GetRecordsResult getRecords(String shardItr, int maxNumberOfRecords) throws Exception {     GetRecordsResult getRecordsResult = null.     while (getRecordsResult == null) {         try {             getRecordsResult = kinesis.getRecords(shardItr, maxNumberOfRecords).             // Update millis behind latest so it gets reported by the millisBehindLatest gauge             Long millisBehindLatest = getRecordsResult.getMillisBehindLatest().             if (millisBehindLatest != null) {                 shardMetricsReporter.setMillisBehindLatest(millisBehindLatest).             }         } catch (ExpiredIteratorException eiEx) {             LOG.warn("Encountered an unexpected expired iterator {} for shard {}." + " refreshing the iterator ...", shardItr, subscribedShard).             shardItr = getShardIterator(lastSequenceNum).             // sleep for the fetch interval before the next getRecords attempt with the refreshed iterator             if (fetchIntervalMillis != 0) {                 Thread.sleep(fetchIntervalMillis).             }         }     }     return getRecordsResult. }
false;protected,static;3;4;;@SuppressWarnings("unchecked") protected static List<UserRecord> deaggregateRecords(List<Record> records, String startingHashKey, String endingHashKey) {     return UserRecord.deaggregate(records, new BigInteger(startingHashKey), new BigInteger(endingHashKey)). }
