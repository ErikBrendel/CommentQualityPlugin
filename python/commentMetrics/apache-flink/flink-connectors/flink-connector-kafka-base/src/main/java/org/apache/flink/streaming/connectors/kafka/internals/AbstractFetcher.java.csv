# id;timestamp;commentText;codeText;commentWords;codeWords
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1480685315;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1482244974;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1487173364;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1488214488;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1489039537;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1489039538;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1489510697;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1495923077;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1498894422;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1501249950;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1501249950;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1509597235;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1510120531;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1515757408;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1515757408;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1515757409;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1517943538;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1517943538;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;protected void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;protected,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> private void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1517943538;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;private void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;private,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> private void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1527050648;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;private void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;private,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> private void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1527059261;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;private void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;private,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1480685315;Takes a snapshot of the partition offsets.__<p>Important: This method mus be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(allPartitions.length)__		for (KafkaTopicPartitionState<?> partition : subscribedPartitions()) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,mus,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,all,partitions,length,for,kafka,topic,partition,state,partition,subscribed,partitions,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1482244974;Takes a snapshot of the partition offsets.__<p>Important: This method mus be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(allPartitions.length)__		for (KafkaTopicPartitionState<?> partition : subscribedPartitions()) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,mus,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,all,partitions,length,for,kafka,topic,partition,state,partition,subscribed,partitions,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1487173364;Takes a snapshot of the partition offsets.__<p>Important: This method mus be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(allPartitions.length)__		for (KafkaTopicPartitionState<?> partition : subscribedPartitions()) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,mus,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,all,partitions,length,for,kafka,topic,partition,state,partition,subscribed,partitions,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1488214488;Takes a snapshot of the partition offsets.__<p>Important: This method mus be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.length)__		for (KafkaTopicPartitionState<?> partition : subscribedPartitionStates()) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,mus,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,length,for,kafka,topic,partition,state,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1489039537;Takes a snapshot of the partition offsets.__<p>Important: This method mus be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.length)__		for (KafkaTopicPartitionState<?> partition : subscribedPartitionStates()) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,mus,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,length,for,kafka,topic,partition,state,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1489039538;Takes a snapshot of the partition offsets.__<p>Important: This method mus be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.length)__		for (KafkaTopicPartitionState<?> partition : subscribedPartitionStates()) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,mus,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,length,for,kafka,topic,partition,state,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1489510697;Takes a snapshot of the partition offsets.__<p>Important: This method mus be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.length)__		for (KafkaTopicPartitionState<?> partition : subscribedPartitionStates()) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,mus,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,length,for,kafka,topic,partition,state,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1495923077;Takes a snapshot of the partition offsets.__<p>Important: This method mus be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.length)__		for (KafkaTopicPartitionState<?> partition : subscribedPartitionStates()) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,mus,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,length,for,kafka,topic,partition,state,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1498894422;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1501249950;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1501249950;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1509597235;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1510120531;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1515757408;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1515757408;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1515757409;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1517943538;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1517943538;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1517943538;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1527050648;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> public HashMap<KafkaTopicPartition, Long> snapshotCurrentState();1527059261;Takes a snapshot of the partition offsets.__<p>Important: This method must be called under the checkpoint lock.__@return A map from partition to current offset.;public HashMap<KafkaTopicPartition, Long> snapshotCurrentState() {_		_		assert Thread.holdsLock(checkpointLock)___		HashMap<KafkaTopicPartition, Long> state = new HashMap<>(subscribedPartitionStates.size())__		for (KafkaTopicPartitionState<KPH> partition : subscribedPartitionStates) {_			state.put(partition.getKafkaTopicPartition(), partition.getOffset())__		}_		return state__	};takes,a,snapshot,of,the,partition,offsets,p,important,this,method,must,be,called,under,the,checkpoint,lock,return,a,map,from,partition,to,current,offset;public,hash,map,kafka,topic,partition,long,snapshot,current,state,assert,thread,holds,lock,checkpoint,lock,hash,map,kafka,topic,partition,long,state,new,hash,map,subscribed,partition,states,size,for,kafka,topic,partition,state,kph,partition,subscribed,partition,states,state,put,partition,get,kafka,topic,partition,partition,get,offset,return,state
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1498894422;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		List<KafkaTopicPartitionState<KPH>> partitionStates = new LinkedList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,linked,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1501249950;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		List<KafkaTopicPartitionState<KPH>> partitionStates = new LinkedList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,linked,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1501249950;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		List<KafkaTopicPartitionState<KPH>> partitionStates = new LinkedList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,linked,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1509597235;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		List<KafkaTopicPartitionState<KPH>> partitionStates = new LinkedList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,linked,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1510120531;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		List<KafkaTopicPartitionState<KPH>> partitionStates = new LinkedList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,linked,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1515757408;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		List<KafkaTopicPartitionState<KPH>> partitionStates = new LinkedList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,linked,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1515757408;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		List<KafkaTopicPartitionState<KPH>> partitionStates = new LinkedList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,linked,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1515757409;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		List<KafkaTopicPartitionState<KPH>> partitionStates = new LinkedList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,linked,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1517943538;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		List<KafkaTopicPartitionState<KPH>> partitionStates = new LinkedList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,linked,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1517943538;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		List<KafkaTopicPartitionState<KPH>> partitionStates = new LinkedList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,linked,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1517943538;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		List<KafkaTopicPartitionState<KPH>> partitionStates = new LinkedList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,linked,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1527050648;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		_		List<KafkaTopicPartitionState<KPH>> partitionStates = new CopyOnWriteArrayList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,copy,on,write,array,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1527059261;Utility method that takes the topic partitions and creates the topic partition state_holders, depending on the timestamp / watermark mode.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_			Map<KafkaTopicPartition, Long> partitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		_		_		List<KafkaTopicPartitionState<KPH>> partitionStates = new CopyOnWriteArrayList<>()___		switch (timestampWatermarkMode) {_			case NO_TIMESTAMPS_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					KafkaTopicPartitionState<KPH> partitionState =_							new KafkaTopicPartitionState<>(partitionEntry.getKey(), kafkaHandle)__					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PERIODIC_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}__			case PUNCTUATED_WATERMARKS: {_				for (Map.Entry<KafkaTopicPartition, Long> partitionEntry : partitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partitionEntry.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> partitionState =_							new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_									partitionEntry.getKey(),_									kafkaHandle,_									assignerInstance)___					partitionState.setOffset(partitionEntry.getValue())___					partitionStates.add(partitionState)__				}__				return partitionStates__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,depending,on,the,timestamp,watermark,mode;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,map,kafka,topic,partition,long,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,partition,states,new,copy,on,write,array,list,switch,timestamp,watermark,mode,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,kafka,topic,partition,state,kph,partition,state,new,kafka,topic,partition,state,partition,entry,get,key,kafka,handle,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,periodic,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,case,for,map,entry,kafka,topic,partition,long,partition,entry,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,entry,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,entry,get,key,kafka,handle,assigner,instance,partition,state,set,offset,partition,entry,get,value,partition,states,add,partition,state,return,partition,states,default,throw,new,runtime,exception
AbstractFetcher -> private void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1517943538;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;private void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;private,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> private void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1527050648;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;private void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;private,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> private void emitRecordWithTimestampAndPeriodicWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1527059261;Record emission, if a timestamp will be attached from an assigner that is_also a periodic watermark generator.;private void emitRecordWithTimestampAndPeriodicWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>) partitionState___		_		_		_		final long timestamp__		_		synchronized (withWatermarksState) {_			timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		}__		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,periodic,watermark,generator;private,void,emit,record,with,timestamp,and,periodic,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,periodic,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partition,state,final,long,timestamp,synchronized,with,watermarks,state,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset
AbstractFetcher -> private KafkaTopicPartitionState<KPH>[] initializePartitions( 			List<KafkaTopicPartition> assignedPartitions, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) 		throws IOException, ClassNotFoundException;1480685315;Utility method that takes the topic partitions and creates the topic partition state_holders. If a watermark generator per partition exists, this will also initialize those.;private KafkaTopicPartitionState<KPH>[] initializePartitions(_			List<KafkaTopicPartition> assignedPartitions,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader)_		throws IOException, ClassNotFoundException_	{_		switch (timestampWatermarkMode) {_			_			case NO_TIMESTAMPS_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionState<KPH>[] partitions =_						(KafkaTopicPartitionState<KPH>[]) new KafkaTopicPartitionState<?>[assignedPartitions.size()]___				int pos = 0__				for (KafkaTopicPartition partition : assignedPartitions) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partition)__					partitions[pos++] = new KafkaTopicPartitionState<>(partition, kafkaHandle)__				}__				return partitions__			}__			case PERIODIC_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPeriodicWatermarks<?, ?>[assignedPartitions.size()]___				int pos = 0__				for (KafkaTopicPartition partition : assignedPartitions) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition)___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)__					_					partitions[pos++] = new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_							partition, kafkaHandle, assignerInstance)__				}__				return partitions__			}__			case PUNCTUATED_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPunctuatedWatermarks<?, ?>[assignedPartitions.size()]___				int pos = 0__				for (KafkaTopicPartition partition : assignedPartitions) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition)___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					partitions[pos++] = new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_							partition, kafkaHandle, assignerInstance)__				}__				return partitions__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,if,a,watermark,generator,per,partition,exists,this,will,also,initialize,those;private,kafka,topic,partition,state,kph,initialize,partitions,list,kafka,topic,partition,assigned,partitions,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,switch,timestamp,watermark,mode,case,suppress,warnings,unchecked,kafka,topic,partition,state,kph,partitions,kafka,topic,partition,state,kph,new,kafka,topic,partition,state,assigned,partitions,size,int,pos,0,for,kafka,topic,partition,partition,assigned,partitions,kph,kafka,handle,create,kafka,partition,handle,partition,partitions,pos,new,kafka,topic,partition,state,partition,kafka,handle,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partitions,kafka,topic,partition,state,with,periodic,watermarks,t,kph,new,kafka,topic,partition,state,with,periodic,watermarks,assigned,partitions,size,int,pos,0,for,kafka,topic,partition,partition,assigned,partitions,kph,kafka,handle,create,kafka,partition,handle,partition,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,periodic,watermarks,partition,kafka,handle,assigner,instance,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partitions,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,new,kafka,topic,partition,state,with,punctuated,watermarks,assigned,partitions,size,int,pos,0,for,kafka,topic,partition,partition,assigned,partitions,kph,kafka,handle,create,kafka,partition,handle,partition,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,kafka,handle,assigner,instance,return,partitions,default,throw,new,runtime,exception
AbstractFetcher -> private KafkaTopicPartitionState<KPH>[] initializePartitions( 			List<KafkaTopicPartition> assignedPartitions, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) 		throws IOException, ClassNotFoundException;1482244974;Utility method that takes the topic partitions and creates the topic partition state_holders. If a watermark generator per partition exists, this will also initialize those.;private KafkaTopicPartitionState<KPH>[] initializePartitions(_			List<KafkaTopicPartition> assignedPartitions,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader)_		throws IOException, ClassNotFoundException_	{_		switch (timestampWatermarkMode) {_			_			case NO_TIMESTAMPS_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionState<KPH>[] partitions =_						(KafkaTopicPartitionState<KPH>[]) new KafkaTopicPartitionState<?>[assignedPartitions.size()]___				int pos = 0__				for (KafkaTopicPartition partition : assignedPartitions) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partition)__					partitions[pos++] = new KafkaTopicPartitionState<>(partition, kafkaHandle)__				}__				return partitions__			}__			case PERIODIC_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPeriodicWatermarks<?, ?>[assignedPartitions.size()]___				int pos = 0__				for (KafkaTopicPartition partition : assignedPartitions) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition)___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)__					_					partitions[pos++] = new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_							partition, kafkaHandle, assignerInstance)__				}__				return partitions__			}__			case PUNCTUATED_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPunctuatedWatermarks<?, ?>[assignedPartitions.size()]___				int pos = 0__				for (KafkaTopicPartition partition : assignedPartitions) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition)___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					partitions[pos++] = new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_							partition, kafkaHandle, assignerInstance)__				}__				return partitions__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,if,a,watermark,generator,per,partition,exists,this,will,also,initialize,those;private,kafka,topic,partition,state,kph,initialize,partitions,list,kafka,topic,partition,assigned,partitions,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,switch,timestamp,watermark,mode,case,suppress,warnings,unchecked,kafka,topic,partition,state,kph,partitions,kafka,topic,partition,state,kph,new,kafka,topic,partition,state,assigned,partitions,size,int,pos,0,for,kafka,topic,partition,partition,assigned,partitions,kph,kafka,handle,create,kafka,partition,handle,partition,partitions,pos,new,kafka,topic,partition,state,partition,kafka,handle,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partitions,kafka,topic,partition,state,with,periodic,watermarks,t,kph,new,kafka,topic,partition,state,with,periodic,watermarks,assigned,partitions,size,int,pos,0,for,kafka,topic,partition,partition,assigned,partitions,kph,kafka,handle,create,kafka,partition,handle,partition,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,periodic,watermarks,partition,kafka,handle,assigner,instance,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partitions,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,new,kafka,topic,partition,state,with,punctuated,watermarks,assigned,partitions,size,int,pos,0,for,kafka,topic,partition,partition,assigned,partitions,kph,kafka,handle,create,kafka,partition,handle,partition,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,kafka,handle,assigner,instance,return,partitions,default,throw,new,runtime,exception
AbstractFetcher -> private KafkaTopicPartitionState<KPH>[] initializePartitions( 			List<KafkaTopicPartition> assignedPartitions, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) 		throws IOException, ClassNotFoundException;1487173364;Utility method that takes the topic partitions and creates the topic partition state_holders. If a watermark generator per partition exists, this will also initialize those.;private KafkaTopicPartitionState<KPH>[] initializePartitions(_			List<KafkaTopicPartition> assignedPartitions,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader)_		throws IOException, ClassNotFoundException_	{_		switch (timestampWatermarkMode) {_			_			case NO_TIMESTAMPS_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionState<KPH>[] partitions =_						(KafkaTopicPartitionState<KPH>[]) new KafkaTopicPartitionState<?>[assignedPartitions.size()]___				int pos = 0__				for (KafkaTopicPartition partition : assignedPartitions) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partition)__					partitions[pos++] = new KafkaTopicPartitionState<>(partition, kafkaHandle)__				}__				return partitions__			}__			case PERIODIC_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPeriodicWatermarks<?, ?>[assignedPartitions.size()]___				int pos = 0__				for (KafkaTopicPartition partition : assignedPartitions) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition)___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)__					_					partitions[pos++] = new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_							partition, kafkaHandle, assignerInstance)__				}__				return partitions__			}__			case PUNCTUATED_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPunctuatedWatermarks<?, ?>[assignedPartitions.size()]___				int pos = 0__				for (KafkaTopicPartition partition : assignedPartitions) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition)___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					partitions[pos++] = new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_							partition, kafkaHandle, assignerInstance)__				}__				return partitions__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,if,a,watermark,generator,per,partition,exists,this,will,also,initialize,those;private,kafka,topic,partition,state,kph,initialize,partitions,list,kafka,topic,partition,assigned,partitions,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,switch,timestamp,watermark,mode,case,suppress,warnings,unchecked,kafka,topic,partition,state,kph,partitions,kafka,topic,partition,state,kph,new,kafka,topic,partition,state,assigned,partitions,size,int,pos,0,for,kafka,topic,partition,partition,assigned,partitions,kph,kafka,handle,create,kafka,partition,handle,partition,partitions,pos,new,kafka,topic,partition,state,partition,kafka,handle,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partitions,kafka,topic,partition,state,with,periodic,watermarks,t,kph,new,kafka,topic,partition,state,with,periodic,watermarks,assigned,partitions,size,int,pos,0,for,kafka,topic,partition,partition,assigned,partitions,kph,kafka,handle,create,kafka,partition,handle,partition,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,periodic,watermarks,partition,kafka,handle,assigner,instance,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partitions,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,new,kafka,topic,partition,state,with,punctuated,watermarks,assigned,partitions,size,int,pos,0,for,kafka,topic,partition,partition,assigned,partitions,kph,kafka,handle,create,kafka,partition,handle,partition,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,kafka,handle,assigner,instance,return,partitions,default,throw,new,runtime,exception
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1498894422;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1501249950;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1501249950;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1509597235;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1510120531;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1515757408;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1515757408;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1515757409;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1517943538;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1517943538;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1517943538;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1527050648;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1527059261;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The version-specific Kafka representation of the Kafka topic partition.;protected abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,version,specific,kafka,representation,of,the,kafka,topic,partition;protected,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1480685315;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The specific Kafka representation of the Kafka topic partition.;public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,specific,kafka,representation,of,the,kafka,topic,partition;public,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1482244974;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The specific Kafka representation of the Kafka topic partition.;public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,specific,kafka,representation,of,the,kafka,topic,partition;public,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1487173364;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The specific Kafka representation of the Kafka topic partition.;public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,specific,kafka,representation,of,the,kafka,topic,partition;public,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1488214488;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The specific Kafka representation of the Kafka topic partition.;public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,specific,kafka,representation,of,the,kafka,topic,partition;public,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1489039537;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The specific Kafka representation of the Kafka topic partition.;public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,specific,kafka,representation,of,the,kafka,topic,partition;public,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1489039538;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The specific Kafka representation of the Kafka topic partition.;public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,specific,kafka,representation,of,the,kafka,topic,partition;public,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1489510697;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The specific Kafka representation of the Kafka topic partition.;public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,specific,kafka,representation,of,the,kafka,topic,partition;public,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;1495923077;Creates the Kafka version specific representation of the given_topic partition.__@param partition The Flink representation of the Kafka topic partition._@return The specific Kafka representation of the Kafka topic partition.;public abstract KPH createKafkaPartitionHandle(KafkaTopicPartition partition)_;creates,the,kafka,version,specific,representation,of,the,given,topic,partition,param,partition,the,flink,representation,of,the,kafka,topic,partition,return,the,specific,kafka,representation,of,the,kafka,topic,partition;public,abstract,kph,create,kafka,partition,handle,kafka,topic,partition,partition
AbstractFetcher -> public final void commitInternalOffsetsToKafka( 			Map<KafkaTopicPartition, Long> offsets, 			@Nonnull KafkaCommitCallback commitCallback) throws Exception;1509597235;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__<p>The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@param commitCallback The callback that the user should trigger when a commit request completes or fails._@throws Exception This method forwards exceptions.;public final void commitInternalOffsetsToKafka(_			Map<KafkaTopicPartition, Long> offsets,_			@Nonnull KafkaCommitCallback commitCallback) throws Exception {_		_		_		doCommitInternalOffsetsToKafka(filterOutSentinels(offsets), commitCallback)__	};commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,p,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,param,commit,callback,the,callback,that,the,user,should,trigger,when,a,commit,request,completes,or,fails,throws,exception,this,method,forwards,exceptions;public,final,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,nonnull,kafka,commit,callback,commit,callback,throws,exception,do,commit,internal,offsets,to,kafka,filter,out,sentinels,offsets,commit,callback
AbstractFetcher -> public final void commitInternalOffsetsToKafka( 			Map<KafkaTopicPartition, Long> offsets, 			@Nonnull KafkaCommitCallback commitCallback) throws Exception;1510120531;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__<p>The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@param commitCallback The callback that the user should trigger when a commit request completes or fails._@throws Exception This method forwards exceptions.;public final void commitInternalOffsetsToKafka(_			Map<KafkaTopicPartition, Long> offsets,_			@Nonnull KafkaCommitCallback commitCallback) throws Exception {_		_		_		doCommitInternalOffsetsToKafka(filterOutSentinels(offsets), commitCallback)__	};commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,p,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,param,commit,callback,the,callback,that,the,user,should,trigger,when,a,commit,request,completes,or,fails,throws,exception,this,method,forwards,exceptions;public,final,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,nonnull,kafka,commit,callback,commit,callback,throws,exception,do,commit,internal,offsets,to,kafka,filter,out,sentinels,offsets,commit,callback
AbstractFetcher -> public final void commitInternalOffsetsToKafka( 			Map<KafkaTopicPartition, Long> offsets, 			@Nonnull KafkaCommitCallback commitCallback) throws Exception;1515757408;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__<p>The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@param commitCallback The callback that the user should trigger when a commit request completes or fails._@throws Exception This method forwards exceptions.;public final void commitInternalOffsetsToKafka(_			Map<KafkaTopicPartition, Long> offsets,_			@Nonnull KafkaCommitCallback commitCallback) throws Exception {_		_		_		doCommitInternalOffsetsToKafka(filterOutSentinels(offsets), commitCallback)__	};commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,p,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,param,commit,callback,the,callback,that,the,user,should,trigger,when,a,commit,request,completes,or,fails,throws,exception,this,method,forwards,exceptions;public,final,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,nonnull,kafka,commit,callback,commit,callback,throws,exception,do,commit,internal,offsets,to,kafka,filter,out,sentinels,offsets,commit,callback
AbstractFetcher -> public final void commitInternalOffsetsToKafka( 			Map<KafkaTopicPartition, Long> offsets, 			@Nonnull KafkaCommitCallback commitCallback) throws Exception;1515757408;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__<p>The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@param commitCallback The callback that the user should trigger when a commit request completes or fails._@throws Exception This method forwards exceptions.;public final void commitInternalOffsetsToKafka(_			Map<KafkaTopicPartition, Long> offsets,_			@Nonnull KafkaCommitCallback commitCallback) throws Exception {_		_		_		doCommitInternalOffsetsToKafka(filterOutSentinels(offsets), commitCallback)__	};commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,p,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,param,commit,callback,the,callback,that,the,user,should,trigger,when,a,commit,request,completes,or,fails,throws,exception,this,method,forwards,exceptions;public,final,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,nonnull,kafka,commit,callback,commit,callback,throws,exception,do,commit,internal,offsets,to,kafka,filter,out,sentinels,offsets,commit,callback
AbstractFetcher -> public final void commitInternalOffsetsToKafka( 			Map<KafkaTopicPartition, Long> offsets, 			@Nonnull KafkaCommitCallback commitCallback) throws Exception;1515757409;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__<p>The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@param commitCallback The callback that the user should trigger when a commit request completes or fails._@throws Exception This method forwards exceptions.;public final void commitInternalOffsetsToKafka(_			Map<KafkaTopicPartition, Long> offsets,_			@Nonnull KafkaCommitCallback commitCallback) throws Exception {_		_		_		doCommitInternalOffsetsToKafka(filterOutSentinels(offsets), commitCallback)__	};commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,p,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,param,commit,callback,the,callback,that,the,user,should,trigger,when,a,commit,request,completes,or,fails,throws,exception,this,method,forwards,exceptions;public,final,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,nonnull,kafka,commit,callback,commit,callback,throws,exception,do,commit,internal,offsets,to,kafka,filter,out,sentinels,offsets,commit,callback
AbstractFetcher -> public final void commitInternalOffsetsToKafka( 			Map<KafkaTopicPartition, Long> offsets, 			@Nonnull KafkaCommitCallback commitCallback) throws Exception;1517943538;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__<p>The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@param commitCallback The callback that the user should trigger when a commit request completes or fails._@throws Exception This method forwards exceptions.;public final void commitInternalOffsetsToKafka(_			Map<KafkaTopicPartition, Long> offsets,_			@Nonnull KafkaCommitCallback commitCallback) throws Exception {_		_		_		doCommitInternalOffsetsToKafka(filterOutSentinels(offsets), commitCallback)__	};commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,p,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,param,commit,callback,the,callback,that,the,user,should,trigger,when,a,commit,request,completes,or,fails,throws,exception,this,method,forwards,exceptions;public,final,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,nonnull,kafka,commit,callback,commit,callback,throws,exception,do,commit,internal,offsets,to,kafka,filter,out,sentinels,offsets,commit,callback
AbstractFetcher -> public final void commitInternalOffsetsToKafka( 			Map<KafkaTopicPartition, Long> offsets, 			@Nonnull KafkaCommitCallback commitCallback) throws Exception;1517943538;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__<p>The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@param commitCallback The callback that the user should trigger when a commit request completes or fails._@throws Exception This method forwards exceptions.;public final void commitInternalOffsetsToKafka(_			Map<KafkaTopicPartition, Long> offsets,_			@Nonnull KafkaCommitCallback commitCallback) throws Exception {_		_		_		doCommitInternalOffsetsToKafka(filterOutSentinels(offsets), commitCallback)__	};commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,p,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,param,commit,callback,the,callback,that,the,user,should,trigger,when,a,commit,request,completes,or,fails,throws,exception,this,method,forwards,exceptions;public,final,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,nonnull,kafka,commit,callback,commit,callback,throws,exception,do,commit,internal,offsets,to,kafka,filter,out,sentinels,offsets,commit,callback
AbstractFetcher -> public final void commitInternalOffsetsToKafka( 			Map<KafkaTopicPartition, Long> offsets, 			@Nonnull KafkaCommitCallback commitCallback) throws Exception;1517943538;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__<p>The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@param commitCallback The callback that the user should trigger when a commit request completes or fails._@throws Exception This method forwards exceptions.;public final void commitInternalOffsetsToKafka(_			Map<KafkaTopicPartition, Long> offsets,_			@Nonnull KafkaCommitCallback commitCallback) throws Exception {_		_		_		doCommitInternalOffsetsToKafka(filterOutSentinels(offsets), commitCallback)__	};commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,p,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,param,commit,callback,the,callback,that,the,user,should,trigger,when,a,commit,request,completes,or,fails,throws,exception,this,method,forwards,exceptions;public,final,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,nonnull,kafka,commit,callback,commit,callback,throws,exception,do,commit,internal,offsets,to,kafka,filter,out,sentinels,offsets,commit,callback
AbstractFetcher -> public final void commitInternalOffsetsToKafka( 			Map<KafkaTopicPartition, Long> offsets, 			@Nonnull KafkaCommitCallback commitCallback) throws Exception;1527050648;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__<p>The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@param commitCallback The callback that the user should trigger when a commit request completes or fails._@throws Exception This method forwards exceptions.;public final void commitInternalOffsetsToKafka(_			Map<KafkaTopicPartition, Long> offsets,_			@Nonnull KafkaCommitCallback commitCallback) throws Exception {_		_		_		doCommitInternalOffsetsToKafka(filterOutSentinels(offsets), commitCallback)__	};commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,p,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,param,commit,callback,the,callback,that,the,user,should,trigger,when,a,commit,request,completes,or,fails,throws,exception,this,method,forwards,exceptions;public,final,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,nonnull,kafka,commit,callback,commit,callback,throws,exception,do,commit,internal,offsets,to,kafka,filter,out,sentinels,offsets,commit,callback
AbstractFetcher -> public final void commitInternalOffsetsToKafka( 			Map<KafkaTopicPartition, Long> offsets, 			@Nonnull KafkaCommitCallback commitCallback) throws Exception;1527059261;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__<p>The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@param commitCallback The callback that the user should trigger when a commit request completes or fails._@throws Exception This method forwards exceptions.;public final void commitInternalOffsetsToKafka(_			Map<KafkaTopicPartition, Long> offsets,_			@Nonnull KafkaCommitCallback commitCallback) throws Exception {_		_		_		doCommitInternalOffsetsToKafka(filterOutSentinels(offsets), commitCallback)__	};commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,p,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,param,commit,callback,the,callback,that,the,user,should,trigger,when,a,commit,request,completes,or,fails,throws,exception,this,method,forwards,exceptions;public,final,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,nonnull,kafka,commit,callback,commit,callback,throws,exception,do,commit,internal,offsets,to,kafka,filter,out,sentinels,offsets,commit,callback
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1480685315;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : allPartitions) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state__				_				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,all,partitions,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1482244974;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : allPartitions) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state__				_				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,all,partitions,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1487173364;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : allPartitions) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state__				_				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,all,partitions,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1488214488;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state__				_				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1489039537;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state__				_				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1489039538;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state__				_				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1489510697;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state__				_				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1495923077;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1498894422;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1501249950;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1501249950;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1509597235;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1510120531;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1515757408;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1515757408;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1515757409;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1517943538;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1517943538;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1517943538;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1527050648;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void updateMinPunctuatedWatermark(Watermark nextWatermark);1527059261;Checks whether a new per-partition watermark is also a new cross-partition watermark.;private void updateMinPunctuatedWatermark(Watermark nextWatermark) {_		if (nextWatermark.getTimestamp() > maxWatermarkSoFar) {_			long newMin = Long.MAX_VALUE___			for (KafkaTopicPartitionState<?> state : subscribedPartitionStates) {_				@SuppressWarnings("unchecked")_				final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) state___				newMin = Math.min(newMin, withWatermarksState.getCurrentPartitionWatermark())__			}__			_			if (newMin > maxWatermarkSoFar) {_				synchronized (checkpointLock) {_					if (newMin > maxWatermarkSoFar) {_						maxWatermarkSoFar = newMin__						sourceContext.emitWatermark(new Watermark(newMin))__					}_				}_			}_		}_	};checks,whether,a,new,per,partition,watermark,is,also,a,new,cross,partition,watermark;private,void,update,min,punctuated,watermark,watermark,next,watermark,if,next,watermark,get,timestamp,max,watermark,so,far,long,new,min,long,for,kafka,topic,partition,state,state,subscribed,partition,states,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,state,new,min,math,min,new,min,with,watermarks,state,get,current,partition,watermark,if,new,min,max,watermark,so,far,synchronized,checkpoint,lock,if,new,min,max,watermark,so,far,max,watermark,so,far,new,min,source,context,emit,watermark,new,watermark,new,min
AbstractFetcher -> private void registerOffsetMetrics( 			MetricGroup consumerMetricGroup, 			List<KafkaTopicPartitionState<KPH>> partitionOffsetStates);1517943538;For each partition, register a new metric group to expose current offsets and committed offsets._Per-partition metric groups can be scoped by user variables {@link KafkaConsumerMetricConstants#OFFSETS_BY_TOPIC_METRICS_GROUP}_and {@link KafkaConsumerMetricConstants#OFFSETS_BY_PARTITION_METRICS_GROUP}.__<p>Note: this method also registers gauges for deprecated offset metrics, to maintain backwards compatibility.__@param consumerMetricGroup The consumer metric group_@param partitionOffsetStates The partition offset state holders, whose values will be used to update metrics;private void registerOffsetMetrics(_			MetricGroup consumerMetricGroup,_			List<KafkaTopicPartitionState<KPH>> partitionOffsetStates) {__		for (KafkaTopicPartitionState<KPH> ktp : partitionOffsetStates) {_			MetricGroup topicPartitionGroup = consumerMetricGroup_				.addGroup(OFFSETS_BY_TOPIC_METRICS_GROUP, ktp.getTopic())_				.addGroup(OFFSETS_BY_PARTITION_METRICS_GROUP, Integer.toString(ktp.getPartition()))___			topicPartitionGroup.gauge(CURRENT_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			topicPartitionGroup.gauge(COMMITTED_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))___			legacyCurrentOffsetsMetricGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			legacyCommittedOffsetsMetricGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};for,each,partition,register,a,new,metric,group,to,expose,current,offsets,and,committed,offsets,per,partition,metric,groups,can,be,scoped,by,user,variables,link,kafka,consumer,metric,constants,and,link,kafka,consumer,metric,constants,p,note,this,method,also,registers,gauges,for,deprecated,offset,metrics,to,maintain,backwards,compatibility,param,consumer,metric,group,the,consumer,metric,group,param,partition,offset,states,the,partition,offset,state,holders,whose,values,will,be,used,to,update,metrics;private,void,register,offset,metrics,metric,group,consumer,metric,group,list,kafka,topic,partition,state,kph,partition,offset,states,for,kafka,topic,partition,state,kph,ktp,partition,offset,states,metric,group,topic,partition,group,consumer,metric,group,add,group,ktp,get,topic,add,group,integer,to,string,ktp,get,partition,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,legacy,current,offsets,metric,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type,legacy,committed,offsets,metric,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> private void registerOffsetMetrics( 			MetricGroup consumerMetricGroup, 			List<KafkaTopicPartitionState<KPH>> partitionOffsetStates);1517943538;For each partition, register a new metric group to expose current offsets and committed offsets._Per-partition metric groups can be scoped by user variables {@link KafkaConsumerMetricConstants#OFFSETS_BY_TOPIC_METRICS_GROUP}_and {@link KafkaConsumerMetricConstants#OFFSETS_BY_PARTITION_METRICS_GROUP}.__<p>Note: this method also registers gauges for deprecated offset metrics, to maintain backwards compatibility.__@param consumerMetricGroup The consumer metric group_@param partitionOffsetStates The partition offset state holders, whose values will be used to update metrics;private void registerOffsetMetrics(_			MetricGroup consumerMetricGroup,_			List<KafkaTopicPartitionState<KPH>> partitionOffsetStates) {__		for (KafkaTopicPartitionState<KPH> ktp : partitionOffsetStates) {_			MetricGroup topicPartitionGroup = consumerMetricGroup_				.addGroup(OFFSETS_BY_TOPIC_METRICS_GROUP, ktp.getTopic())_				.addGroup(OFFSETS_BY_PARTITION_METRICS_GROUP, Integer.toString(ktp.getPartition()))___			topicPartitionGroup.gauge(CURRENT_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			topicPartitionGroup.gauge(COMMITTED_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))___			legacyCurrentOffsetsMetricGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			legacyCommittedOffsetsMetricGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};for,each,partition,register,a,new,metric,group,to,expose,current,offsets,and,committed,offsets,per,partition,metric,groups,can,be,scoped,by,user,variables,link,kafka,consumer,metric,constants,and,link,kafka,consumer,metric,constants,p,note,this,method,also,registers,gauges,for,deprecated,offset,metrics,to,maintain,backwards,compatibility,param,consumer,metric,group,the,consumer,metric,group,param,partition,offset,states,the,partition,offset,state,holders,whose,values,will,be,used,to,update,metrics;private,void,register,offset,metrics,metric,group,consumer,metric,group,list,kafka,topic,partition,state,kph,partition,offset,states,for,kafka,topic,partition,state,kph,ktp,partition,offset,states,metric,group,topic,partition,group,consumer,metric,group,add,group,ktp,get,topic,add,group,integer,to,string,ktp,get,partition,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,legacy,current,offsets,metric,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type,legacy,committed,offsets,metric,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> private void registerOffsetMetrics( 			MetricGroup consumerMetricGroup, 			List<KafkaTopicPartitionState<KPH>> partitionOffsetStates);1527050648;For each partition, register a new metric group to expose current offsets and committed offsets._Per-partition metric groups can be scoped by user variables {@link KafkaConsumerMetricConstants#OFFSETS_BY_TOPIC_METRICS_GROUP}_and {@link KafkaConsumerMetricConstants#OFFSETS_BY_PARTITION_METRICS_GROUP}.__<p>Note: this method also registers gauges for deprecated offset metrics, to maintain backwards compatibility.__@param consumerMetricGroup The consumer metric group_@param partitionOffsetStates The partition offset state holders, whose values will be used to update metrics;private void registerOffsetMetrics(_			MetricGroup consumerMetricGroup,_			List<KafkaTopicPartitionState<KPH>> partitionOffsetStates) {__		for (KafkaTopicPartitionState<KPH> ktp : partitionOffsetStates) {_			MetricGroup topicPartitionGroup = consumerMetricGroup_				.addGroup(OFFSETS_BY_TOPIC_METRICS_GROUP, ktp.getTopic())_				.addGroup(OFFSETS_BY_PARTITION_METRICS_GROUP, Integer.toString(ktp.getPartition()))___			topicPartitionGroup.gauge(CURRENT_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			topicPartitionGroup.gauge(COMMITTED_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))___			legacyCurrentOffsetsMetricGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			legacyCommittedOffsetsMetricGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};for,each,partition,register,a,new,metric,group,to,expose,current,offsets,and,committed,offsets,per,partition,metric,groups,can,be,scoped,by,user,variables,link,kafka,consumer,metric,constants,and,link,kafka,consumer,metric,constants,p,note,this,method,also,registers,gauges,for,deprecated,offset,metrics,to,maintain,backwards,compatibility,param,consumer,metric,group,the,consumer,metric,group,param,partition,offset,states,the,partition,offset,state,holders,whose,values,will,be,used,to,update,metrics;private,void,register,offset,metrics,metric,group,consumer,metric,group,list,kafka,topic,partition,state,kph,partition,offset,states,for,kafka,topic,partition,state,kph,ktp,partition,offset,states,metric,group,topic,partition,group,consumer,metric,group,add,group,ktp,get,topic,add,group,integer,to,string,ktp,get,partition,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,legacy,current,offsets,metric,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type,legacy,committed,offsets,metric,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> private void registerOffsetMetrics( 			MetricGroup consumerMetricGroup, 			List<KafkaTopicPartitionState<KPH>> partitionOffsetStates);1527059261;For each partition, register a new metric group to expose current offsets and committed offsets._Per-partition metric groups can be scoped by user variables {@link KafkaConsumerMetricConstants#OFFSETS_BY_TOPIC_METRICS_GROUP}_and {@link KafkaConsumerMetricConstants#OFFSETS_BY_PARTITION_METRICS_GROUP}.__<p>Note: this method also registers gauges for deprecated offset metrics, to maintain backwards compatibility.__@param consumerMetricGroup The consumer metric group_@param partitionOffsetStates The partition offset state holders, whose values will be used to update metrics;private void registerOffsetMetrics(_			MetricGroup consumerMetricGroup,_			List<KafkaTopicPartitionState<KPH>> partitionOffsetStates) {__		for (KafkaTopicPartitionState<KPH> ktp : partitionOffsetStates) {_			MetricGroup topicPartitionGroup = consumerMetricGroup_				.addGroup(OFFSETS_BY_TOPIC_METRICS_GROUP, ktp.getTopic())_				.addGroup(OFFSETS_BY_PARTITION_METRICS_GROUP, Integer.toString(ktp.getPartition()))___			topicPartitionGroup.gauge(CURRENT_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			topicPartitionGroup.gauge(COMMITTED_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))___			legacyCurrentOffsetsMetricGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			legacyCommittedOffsetsMetricGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};for,each,partition,register,a,new,metric,group,to,expose,current,offsets,and,committed,offsets,per,partition,metric,groups,can,be,scoped,by,user,variables,link,kafka,consumer,metric,constants,and,link,kafka,consumer,metric,constants,p,note,this,method,also,registers,gauges,for,deprecated,offset,metrics,to,maintain,backwards,compatibility,param,consumer,metric,group,the,consumer,metric,group,param,partition,offset,states,the,partition,offset,state,holders,whose,values,will,be,used,to,update,metrics;private,void,register,offset,metrics,metric,group,consumer,metric,group,list,kafka,topic,partition,state,kph,partition,offset,states,for,kafka,topic,partition,state,kph,ktp,partition,offset,states,metric,group,topic,partition,group,consumer,metric,group,add,group,ktp,get,topic,add,group,integer,to,string,ktp,get,partition,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,legacy,current,offsets,metric,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type,legacy,committed,offsets,metric,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected final KafkaTopicPartitionState<KPH>[] subscribedPartitionStates();1488214488;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final KafkaTopicPartitionState<KPH>[] subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final KafkaTopicPartitionState<KPH>[] subscribedPartitionStates();1489039537;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final KafkaTopicPartitionState<KPH>[] subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final KafkaTopicPartitionState<KPH>[] subscribedPartitionStates();1489039538;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final KafkaTopicPartitionState<KPH>[] subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final KafkaTopicPartitionState<KPH>[] subscribedPartitionStates();1489510697;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final KafkaTopicPartitionState<KPH>[] subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final KafkaTopicPartitionState<KPH>[] subscribedPartitionStates();1495923077;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final KafkaTopicPartitionState<KPH>[] subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1480685315;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1482244974;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1487173364;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1488214488;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1489039537;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1489039538;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1489510697;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp)_	{_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1495923077;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1498894422;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1501249950;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1501249950;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1509597235;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1510120531;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1515757408;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1515757408;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1515757409;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1517943538;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> protected void emitRecordWithTimestampAndPunctuatedWatermark( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp);1517943538;Record emission, if a timestamp will be attached from an assigner that is_also a punctuated watermark generator.;protected void emitRecordWithTimestampAndPunctuatedWatermark(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long kafkaEventTimestamp) {_		@SuppressWarnings("unchecked")_		final KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH> withWatermarksState =_				(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>) partitionState___		_		_		final long timestamp = withWatermarksState.getTimestampForRecord(record, kafkaEventTimestamp)__		final Watermark newWatermark = withWatermarksState.checkAndGetNewWatermark(record, timestamp)___		_		_		synchronized (checkpointLock) {_			sourceContext.collectWithTimestamp(record, timestamp)__			partitionState.setOffset(offset)__		}__		_		_		if (newWatermark != null) {_			updateMinPunctuatedWatermark(newWatermark)__		}_	};record,emission,if,a,timestamp,will,be,attached,from,an,assigner,that,is,also,a,punctuated,watermark,generator;protected,void,emit,record,with,timestamp,and,punctuated,watermark,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,kafka,event,timestamp,suppress,warnings,unchecked,final,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,with,watermarks,state,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partition,state,final,long,timestamp,with,watermarks,state,get,timestamp,for,record,record,kafka,event,timestamp,final,watermark,new,watermark,with,watermarks,state,check,and,get,new,watermark,record,timestamp,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,if,new,watermark,null,update,min,punctuated,watermark,new,watermark
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1498894422;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1501249950;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1501249950;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1509597235;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1510120531;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1515757408;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1515757408;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1515757409;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1517943538;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1517943538;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		if (useMetrics) {_			registerOffsetMetrics(consumerMetricGroup, newPartitionStates)__		}__		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,if,use,metrics,register,offset,metrics,consumer,metric,group,new,partition,states,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1517943538;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		if (useMetrics) {_			registerOffsetMetrics(consumerMetricGroup, newPartitionStates)__		}__		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,if,use,metrics,register,offset,metrics,consumer,metric,group,new,partition,states,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1527050648;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		if (useMetrics) {_			registerOffsetMetrics(consumerMetricGroup, newPartitionStates)__		}__		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,if,use,metrics,register,offset,metrics,consumer,metric,group,new,partition,states,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException;1527059261;Adds a list of newly discovered partitions to the fetcher for consuming.__<p>This method creates the partition state holder for each new partition, using_{@link KafkaTopicPartitionStateSentinel#EARLIEST_OFFSET} as the starting offset._It uses the earliest offset because there may be delay in discovering a partition_after it was created and started receiving records.__<p>After the state representation for a partition is created, it is added to the_unassigned partitions queue to await to be consumed.__@param newPartitions discovered partitions to add;public void addDiscoveredPartitions(List<KafkaTopicPartition> newPartitions) throws IOException, ClassNotFoundException {_		List<KafkaTopicPartitionState<KPH>> newPartitionStates = createPartitionStateHolders(_				newPartitions,_				KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)___		if (useMetrics) {_			registerOffsetMetrics(consumerMetricGroup, newPartitionStates)__		}__		for (KafkaTopicPartitionState<KPH> newPartitionState : newPartitionStates) {_			_			_			subscribedPartitionStates.add(newPartitionState)__			unassignedPartitionsQueue.add(newPartitionState)__		}_	};adds,a,list,of,newly,discovered,partitions,to,the,fetcher,for,consuming,p,this,method,creates,the,partition,state,holder,for,each,new,partition,using,link,kafka,topic,partition,state,sentinel,as,the,starting,offset,it,uses,the,earliest,offset,because,there,may,be,delay,in,discovering,a,partition,after,it,was,created,and,started,receiving,records,p,after,the,state,representation,for,a,partition,is,created,it,is,added,to,the,unassigned,partitions,queue,to,await,to,be,consumed,param,new,partitions,discovered,partitions,to,add;public,void,add,discovered,partitions,list,kafka,topic,partition,new,partitions,throws,ioexception,class,not,found,exception,list,kafka,topic,partition,state,kph,new,partition,states,create,partition,state,holders,new,partitions,kafka,topic,partition,state,sentinel,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader,if,use,metrics,register,offset,metrics,consumer,metric,group,new,partition,states,for,kafka,topic,partition,state,kph,new,partition,state,new,partition,states,subscribed,partition,states,add,new,partition,state,unassigned,partitions,queue,add,new,partition,state
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1498894422;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1501249950;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1501249950;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1509597235;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1510120531;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1515757408;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1515757408;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1515757409;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1517943538;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1517943538;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1517943538;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1527050648;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates();1527059261;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final List<KafkaTopicPartitionState<KPH>> subscribedPartitionStates() {_		return subscribedPartitionStates__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,list,kafka,topic,partition,state,kph,subscribed,partition,states,return,subscribed,partition,states
AbstractFetcher -> public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;1480685315;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@throws Exception This method forwards exceptions.;public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,throws,exception,this,method,forwards,exceptions;public,abstract,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,throws,exception
AbstractFetcher -> public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;1482244974;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@throws Exception This method forwards exceptions.;public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,throws,exception,this,method,forwards,exceptions;public,abstract,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,throws,exception
AbstractFetcher -> public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;1487173364;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@throws Exception This method forwards exceptions.;public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,throws,exception,this,method,forwards,exceptions;public,abstract,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,throws,exception
AbstractFetcher -> public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;1488214488;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@throws Exception This method forwards exceptions.;public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,throws,exception,this,method,forwards,exceptions;public,abstract,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,throws,exception
AbstractFetcher -> public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;1489039537;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@throws Exception This method forwards exceptions.;public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,throws,exception,this,method,forwards,exceptions;public,abstract,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,throws,exception
AbstractFetcher -> public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;1489039538;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@throws Exception This method forwards exceptions.;public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,throws,exception,this,method,forwards,exceptions;public,abstract,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,throws,exception
AbstractFetcher -> public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;1489510697;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@throws Exception This method forwards exceptions.;public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,throws,exception,this,method,forwards,exceptions;public,abstract,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,throws,exception
AbstractFetcher -> public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;1495923077;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__<p>The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@throws Exception This method forwards exceptions.;public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,p,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,throws,exception,this,method,forwards,exceptions;public,abstract,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,throws,exception
AbstractFetcher -> public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;1498894422;Commits the given partition offsets to the Kafka brokers (or to ZooKeeper for_older Kafka versions). This method is only ever called when the offset commit mode of_the consumer is {@link OffsetCommitMode#ON_CHECKPOINTS}.__<p>The given offsets are the internal checkpointed offsets, representing_the last processed record of each partition. Version-specific implementations of this method_need to hold the contract that the given offsets must be incremented by 1 before_committing them, so that committed offsets to Kafka represent "the next record to process".__@param offsets The offsets to commit to Kafka (implementations must increment offsets by 1 before committing)._@throws Exception This method forwards exceptions.;public abstract void commitInternalOffsetsToKafka(Map<KafkaTopicPartition, Long> offsets) throws Exception_;commits,the,given,partition,offsets,to,the,kafka,brokers,or,to,zoo,keeper,for,older,kafka,versions,this,method,is,only,ever,called,when,the,offset,commit,mode,of,the,consumer,is,link,offset,commit,mode,p,the,given,offsets,are,the,internal,checkpointed,offsets,representing,the,last,processed,record,of,each,partition,version,specific,implementations,of,this,method,need,to,hold,the,contract,that,the,given,offsets,must,be,incremented,by,1,before,committing,them,so,that,committed,offsets,to,kafka,represent,the,next,record,to,process,param,offsets,the,offsets,to,commit,to,kafka,implementations,must,increment,offsets,by,1,before,committing,throws,exception,this,method,forwards,exceptions;public,abstract,void,commit,internal,offsets,to,kafka,map,kafka,topic,partition,long,offsets,throws,exception
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1480685315;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {_		if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_			__			_			_			synchronized (checkpointLock) {_				sourceContext.collect(record)__				partitionState.setOffset(offset)__			}_		}_		else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_			emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__		}_		else {_			emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1482244974;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {_		if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_			__			_			_			synchronized (checkpointLock) {_				sourceContext.collect(record)__				partitionState.setOffset(offset)__			}_		}_		else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_			emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__		}_		else {_			emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1487173364;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {_		if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_			__			_			_			synchronized (checkpointLock) {_				sourceContext.collect(record)__				partitionState.setOffset(offset)__			}_		}_		else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_			emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__		}_		else {_			emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1488214488;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {_		if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_			__			_			_			synchronized (checkpointLock) {_				sourceContext.collect(record)__				partitionState.setOffset(offset)__			}_		}_		else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_			emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__		}_		else {_			emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1489039537;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {_		if (record == null) {_			return__		}__		if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_			__			_			_			synchronized (checkpointLock) {_				sourceContext.collect(record)__				partitionState.setOffset(offset)__			}_		}_		else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_			emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__		}_		else {_			emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,return,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1489039538;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1489510697;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1495923077;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1498894422;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1501249950;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1501249950;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1509597235;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1510120531;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1515757408;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1515757408;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1515757409;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1517943538;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1517943538;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1517943538;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1527050648;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception;1527059261;Emits a record without attaching an existing timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecord(T record, KafkaTopicPartitionState<KPH> partitionState, long offset) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collect(record)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, Long.MIN_VALUE)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, Long.MIN_VALUE)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,without,attaching,an,existing,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,record,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,long,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,long,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected final KafkaTopicPartitionState<KPH>[] subscribedPartitions();1480685315;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final KafkaTopicPartitionState<KPH>[] subscribedPartitions() {_		return allPartitions__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,kafka,topic,partition,state,kph,subscribed,partitions,return,all,partitions
AbstractFetcher -> protected final KafkaTopicPartitionState<KPH>[] subscribedPartitions();1482244974;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final KafkaTopicPartitionState<KPH>[] subscribedPartitions() {_		return allPartitions__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,kafka,topic,partition,state,kph,subscribed,partitions,return,all,partitions
AbstractFetcher -> protected final KafkaTopicPartitionState<KPH>[] subscribedPartitions();1487173364;Gets all partitions (with partition state) that this fetcher is subscribed to.__@return All subscribed partitions.;protected final KafkaTopicPartitionState<KPH>[] subscribedPartitions() {_		return allPartitions__	};gets,all,partitions,with,partition,state,that,this,fetcher,is,subscribed,to,return,all,subscribed,partitions;protected,final,kafka,topic,partition,state,kph,subscribed,partitions,return,all,partitions
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1480685315;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_			__			_			_			synchronized (checkpointLock) {_				sourceContext.collectWithTimestamp(record, timestamp)__				partitionState.setOffset(offset)__			}_		}_		else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_			emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__		}_		else {_			emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1482244974;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_			__			_			_			synchronized (checkpointLock) {_				sourceContext.collectWithTimestamp(record, timestamp)__				partitionState.setOffset(offset)__			}_		}_		else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_			emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__		}_		else {_			emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1487173364;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_			__			_			_			synchronized (checkpointLock) {_				sourceContext.collectWithTimestamp(record, timestamp)__				partitionState.setOffset(offset)__			}_		}_		else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_			emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__		}_		else {_			emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1488214488;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_			__			_			_			synchronized (checkpointLock) {_				sourceContext.collectWithTimestamp(record, timestamp)__				partitionState.setOffset(offset)__			}_		}_		else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_			emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__		}_		else {_			emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1489039537;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_			__			_			_			synchronized (checkpointLock) {_				sourceContext.collectWithTimestamp(record, timestamp)__				partitionState.setOffset(offset)__			}_		}_		else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_			emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__		}_		else {_			emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1489039538;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1489510697;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1495923077;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1498894422;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1501249950;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1501249950;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1509597235;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1510120531;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1515757408;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1515757408;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1515757409;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1517943538;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1517943538;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1517943538;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1527050648;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> protected void emitRecordWithTimestamp( 			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception;1527059261;Emits a record attaching a timestamp to it.__<p>Implementation Note: This method is kept brief to be JIT inlining friendly._That makes the fast path efficient, the extended paths are called as separate methods.__@param record The record to emit_@param partitionState The state of the Kafka partition from which the record was fetched_@param offset The offset of the record;protected void emitRecordWithTimestamp(_			T record, KafkaTopicPartitionState<KPH> partitionState, long offset, long timestamp) throws Exception {__		if (record != null) {_			if (timestampWatermarkMode == NO_TIMESTAMPS_WATERMARKS) {_				__				_				_				synchronized (checkpointLock) {_					sourceContext.collectWithTimestamp(record, timestamp)__					partitionState.setOffset(offset)__				}_			} else if (timestampWatermarkMode == PERIODIC_WATERMARKS) {_				emitRecordWithTimestampAndPeriodicWatermark(record, partitionState, offset, timestamp)__			} else {_				emitRecordWithTimestampAndPunctuatedWatermark(record, partitionState, offset, timestamp)__			}_		} else {_			_			synchronized (checkpointLock) {_				partitionState.setOffset(offset)__			}_		}_	};emits,a,record,attaching,a,timestamp,to,it,p,implementation,note,this,method,is,kept,brief,to,be,jit,inlining,friendly,that,makes,the,fast,path,efficient,the,extended,paths,are,called,as,separate,methods,param,record,the,record,to,emit,param,partition,state,the,state,of,the,kafka,partition,from,which,the,record,was,fetched,param,offset,the,offset,of,the,record;protected,void,emit,record,with,timestamp,t,record,kafka,topic,partition,state,kph,partition,state,long,offset,long,timestamp,throws,exception,if,record,null,if,timestamp,watermark,mode,synchronized,checkpoint,lock,source,context,collect,with,timestamp,record,timestamp,partition,state,set,offset,offset,else,if,timestamp,watermark,mode,emit,record,with,timestamp,and,periodic,watermark,record,partition,state,offset,timestamp,else,emit,record,with,timestamp,and,punctuated,watermark,record,partition,state,offset,timestamp,else,synchronized,checkpoint,lock,partition,state,set,offset,offset
AbstractFetcher -> private KafkaTopicPartitionState<KPH>[] initializeSubscribedPartitionStates( 			Map<KafkaTopicPartition, Long> assignedPartitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) 		throws IOException, ClassNotFoundException;1488214488;Utility method that takes the topic partitions and creates the topic partition state_holders. If a watermark generator per partition exists, this will also initialize those.;private KafkaTopicPartitionState<KPH>[] initializeSubscribedPartitionStates(_			Map<KafkaTopicPartition, Long> assignedPartitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader)_		throws IOException, ClassNotFoundException_	{_		switch (timestampWatermarkMode) {_			_			case NO_TIMESTAMPS_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionState<KPH>[] partitions =_						(KafkaTopicPartitionState<KPH>[]) new KafkaTopicPartitionState<?>[assignedPartitionsToInitialOffsets.size()]___				int pos = 0__				for (Map.Entry<KafkaTopicPartition, Long> partition : assignedPartitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partition.getKey())__					partitions[pos] = new KafkaTopicPartitionState<>(partition.getKey(), kafkaHandle)__					partitions[pos].setOffset(partition.getValue())___					pos++__				}__				return partitions__			}__			case PERIODIC_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPeriodicWatermarks<?, ?>[assignedPartitionsToInitialOffsets.size()]___				int pos = 0__				for (Map.Entry<KafkaTopicPartition, Long> partition : assignedPartitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)__					_					partitions[pos] = new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_							partition.getKey(), kafkaHandle, assignerInstance)__					partitions[pos].setOffset(partition.getValue())___					pos++__				}__				return partitions__			}__			case PUNCTUATED_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPunctuatedWatermarks<?, ?>[assignedPartitionsToInitialOffsets.size()]___				int pos = 0__				for (Map.Entry<KafkaTopicPartition, Long> partition : assignedPartitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					partitions[pos] = new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_							partition.getKey(), kafkaHandle, assignerInstance)__					partitions[pos].setOffset(partition.getValue())___					pos++__				}__				return partitions__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,if,a,watermark,generator,per,partition,exists,this,will,also,initialize,those;private,kafka,topic,partition,state,kph,initialize,subscribed,partition,states,map,kafka,topic,partition,long,assigned,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,switch,timestamp,watermark,mode,case,suppress,warnings,unchecked,kafka,topic,partition,state,kph,partitions,kafka,topic,partition,state,kph,new,kafka,topic,partition,state,assigned,partitions,to,initial,offsets,size,int,pos,0,for,map,entry,kafka,topic,partition,long,partition,assigned,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,get,key,partitions,pos,new,kafka,topic,partition,state,partition,get,key,kafka,handle,partitions,pos,set,offset,partition,get,value,pos,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partitions,kafka,topic,partition,state,with,periodic,watermarks,t,kph,new,kafka,topic,partition,state,with,periodic,watermarks,assigned,partitions,to,initial,offsets,size,int,pos,0,for,map,entry,kafka,topic,partition,long,partition,assigned,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,periodic,watermarks,partition,get,key,kafka,handle,assigner,instance,partitions,pos,set,offset,partition,get,value,pos,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partitions,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,new,kafka,topic,partition,state,with,punctuated,watermarks,assigned,partitions,to,initial,offsets,size,int,pos,0,for,map,entry,kafka,topic,partition,long,partition,assigned,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,get,key,kafka,handle,assigner,instance,partitions,pos,set,offset,partition,get,value,pos,return,partitions,default,throw,new,runtime,exception
AbstractFetcher -> private KafkaTopicPartitionState<KPH>[] initializeSubscribedPartitionStates( 			Map<KafkaTopicPartition, Long> assignedPartitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) 		throws IOException, ClassNotFoundException;1489039537;Utility method that takes the topic partitions and creates the topic partition state_holders. If a watermark generator per partition exists, this will also initialize those.;private KafkaTopicPartitionState<KPH>[] initializeSubscribedPartitionStates(_			Map<KafkaTopicPartition, Long> assignedPartitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader)_		throws IOException, ClassNotFoundException_	{_		switch (timestampWatermarkMode) {_			_			case NO_TIMESTAMPS_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionState<KPH>[] partitions =_						(KafkaTopicPartitionState<KPH>[]) new KafkaTopicPartitionState<?>[assignedPartitionsToInitialOffsets.size()]___				int pos = 0__				for (Map.Entry<KafkaTopicPartition, Long> partition : assignedPartitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partition.getKey())__					partitions[pos] = new KafkaTopicPartitionState<>(partition.getKey(), kafkaHandle)__					partitions[pos].setOffset(partition.getValue())___					pos++__				}__				return partitions__			}__			case PERIODIC_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPeriodicWatermarks<?, ?>[assignedPartitionsToInitialOffsets.size()]___				int pos = 0__				for (Map.Entry<KafkaTopicPartition, Long> partition : assignedPartitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)__					_					partitions[pos] = new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_							partition.getKey(), kafkaHandle, assignerInstance)__					partitions[pos].setOffset(partition.getValue())___					pos++__				}__				return partitions__			}__			case PUNCTUATED_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPunctuatedWatermarks<?, ?>[assignedPartitionsToInitialOffsets.size()]___				int pos = 0__				for (Map.Entry<KafkaTopicPartition, Long> partition : assignedPartitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					partitions[pos] = new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_							partition.getKey(), kafkaHandle, assignerInstance)__					partitions[pos].setOffset(partition.getValue())___					pos++__				}__				return partitions__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,if,a,watermark,generator,per,partition,exists,this,will,also,initialize,those;private,kafka,topic,partition,state,kph,initialize,subscribed,partition,states,map,kafka,topic,partition,long,assigned,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,switch,timestamp,watermark,mode,case,suppress,warnings,unchecked,kafka,topic,partition,state,kph,partitions,kafka,topic,partition,state,kph,new,kafka,topic,partition,state,assigned,partitions,to,initial,offsets,size,int,pos,0,for,map,entry,kafka,topic,partition,long,partition,assigned,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,get,key,partitions,pos,new,kafka,topic,partition,state,partition,get,key,kafka,handle,partitions,pos,set,offset,partition,get,value,pos,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partitions,kafka,topic,partition,state,with,periodic,watermarks,t,kph,new,kafka,topic,partition,state,with,periodic,watermarks,assigned,partitions,to,initial,offsets,size,int,pos,0,for,map,entry,kafka,topic,partition,long,partition,assigned,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,periodic,watermarks,partition,get,key,kafka,handle,assigner,instance,partitions,pos,set,offset,partition,get,value,pos,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partitions,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,new,kafka,topic,partition,state,with,punctuated,watermarks,assigned,partitions,to,initial,offsets,size,int,pos,0,for,map,entry,kafka,topic,partition,long,partition,assigned,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,get,key,kafka,handle,assigner,instance,partitions,pos,set,offset,partition,get,value,pos,return,partitions,default,throw,new,runtime,exception
AbstractFetcher -> private KafkaTopicPartitionState<KPH>[] initializeSubscribedPartitionStates( 			Map<KafkaTopicPartition, Long> assignedPartitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) 		throws IOException, ClassNotFoundException;1489039538;Utility method that takes the topic partitions and creates the topic partition state_holders. If a watermark generator per partition exists, this will also initialize those.;private KafkaTopicPartitionState<KPH>[] initializeSubscribedPartitionStates(_			Map<KafkaTopicPartition, Long> assignedPartitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader)_		throws IOException, ClassNotFoundException_	{_		switch (timestampWatermarkMode) {_			_			case NO_TIMESTAMPS_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionState<KPH>[] partitions =_						(KafkaTopicPartitionState<KPH>[]) new KafkaTopicPartitionState<?>[assignedPartitionsToInitialOffsets.size()]___				int pos = 0__				for (Map.Entry<KafkaTopicPartition, Long> partition : assignedPartitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partition.getKey())__					partitions[pos] = new KafkaTopicPartitionState<>(partition.getKey(), kafkaHandle)__					partitions[pos].setOffset(partition.getValue())___					pos++__				}__				return partitions__			}__			case PERIODIC_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPeriodicWatermarks<?, ?>[assignedPartitionsToInitialOffsets.size()]___				int pos = 0__				for (Map.Entry<KafkaTopicPartition, Long> partition : assignedPartitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)__					_					partitions[pos] = new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_							partition.getKey(), kafkaHandle, assignerInstance)__					partitions[pos].setOffset(partition.getValue())___					pos++__				}__				return partitions__			}__			case PUNCTUATED_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPunctuatedWatermarks<?, ?>[assignedPartitionsToInitialOffsets.size()]___				int pos = 0__				for (Map.Entry<KafkaTopicPartition, Long> partition : assignedPartitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					partitions[pos] = new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_							partition.getKey(), kafkaHandle, assignerInstance)__					partitions[pos].setOffset(partition.getValue())___					pos++__				}__				return partitions__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,if,a,watermark,generator,per,partition,exists,this,will,also,initialize,those;private,kafka,topic,partition,state,kph,initialize,subscribed,partition,states,map,kafka,topic,partition,long,assigned,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,switch,timestamp,watermark,mode,case,suppress,warnings,unchecked,kafka,topic,partition,state,kph,partitions,kafka,topic,partition,state,kph,new,kafka,topic,partition,state,assigned,partitions,to,initial,offsets,size,int,pos,0,for,map,entry,kafka,topic,partition,long,partition,assigned,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,get,key,partitions,pos,new,kafka,topic,partition,state,partition,get,key,kafka,handle,partitions,pos,set,offset,partition,get,value,pos,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partitions,kafka,topic,partition,state,with,periodic,watermarks,t,kph,new,kafka,topic,partition,state,with,periodic,watermarks,assigned,partitions,to,initial,offsets,size,int,pos,0,for,map,entry,kafka,topic,partition,long,partition,assigned,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,periodic,watermarks,partition,get,key,kafka,handle,assigner,instance,partitions,pos,set,offset,partition,get,value,pos,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partitions,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,new,kafka,topic,partition,state,with,punctuated,watermarks,assigned,partitions,to,initial,offsets,size,int,pos,0,for,map,entry,kafka,topic,partition,long,partition,assigned,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,get,key,kafka,handle,assigner,instance,partitions,pos,set,offset,partition,get,value,pos,return,partitions,default,throw,new,runtime,exception
AbstractFetcher -> private KafkaTopicPartitionState<KPH>[] initializeSubscribedPartitionStates( 			Map<KafkaTopicPartition, Long> assignedPartitionsToInitialOffsets, 			int timestampWatermarkMode, 			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 			ClassLoader userCodeClassLoader) 		throws IOException, ClassNotFoundException;1489510697;Utility method that takes the topic partitions and creates the topic partition state_holders. If a watermark generator per partition exists, this will also initialize those.;private KafkaTopicPartitionState<KPH>[] initializeSubscribedPartitionStates(_			Map<KafkaTopicPartition, Long> assignedPartitionsToInitialOffsets,_			int timestampWatermarkMode,_			SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_			SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_			ClassLoader userCodeClassLoader)_		throws IOException, ClassNotFoundException_	{_		switch (timestampWatermarkMode) {_			_			case NO_TIMESTAMPS_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionState<KPH>[] partitions =_						(KafkaTopicPartitionState<KPH>[]) new KafkaTopicPartitionState<?>[assignedPartitionsToInitialOffsets.size()]___				int pos = 0__				for (Map.Entry<KafkaTopicPartition, Long> partition : assignedPartitionsToInitialOffsets.entrySet()) {_					_					KPH kafkaHandle = createKafkaPartitionHandle(partition.getKey())__					partitions[pos] = new KafkaTopicPartitionState<>(partition.getKey(), kafkaHandle)__					partitions[pos].setOffset(partition.getValue())___					pos++__				}__				return partitions__			}__			case PERIODIC_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPeriodicWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPeriodicWatermarks<?, ?>[assignedPartitionsToInitialOffsets.size()]___				int pos = 0__				for (Map.Entry<KafkaTopicPartition, Long> partition : assignedPartitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition.getKey())___					AssignerWithPeriodicWatermarks<T> assignerInstance =_							watermarksPeriodic.deserializeValue(userCodeClassLoader)__					_					partitions[pos] = new KafkaTopicPartitionStateWithPeriodicWatermarks<>(_							partition.getKey(), kafkaHandle, assignerInstance)__					partitions[pos].setOffset(partition.getValue())___					pos++__				}__				return partitions__			}__			case PUNCTUATED_WATERMARKS: {_				@SuppressWarnings("unchecked")_				KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[] partitions =_						(KafkaTopicPartitionStateWithPunctuatedWatermarks<T, KPH>[])_								new KafkaTopicPartitionStateWithPunctuatedWatermarks<?, ?>[assignedPartitionsToInitialOffsets.size()]___				int pos = 0__				for (Map.Entry<KafkaTopicPartition, Long> partition : assignedPartitionsToInitialOffsets.entrySet()) {_					KPH kafkaHandle = createKafkaPartitionHandle(partition.getKey())___					AssignerWithPunctuatedWatermarks<T> assignerInstance =_							watermarksPunctuated.deserializeValue(userCodeClassLoader)___					partitions[pos] = new KafkaTopicPartitionStateWithPunctuatedWatermarks<>(_							partition.getKey(), kafkaHandle, assignerInstance)__					partitions[pos].setOffset(partition.getValue())___					pos++__				}__				return partitions__			}_			default:_				_				throw new RuntimeException()__		}_	};utility,method,that,takes,the,topic,partitions,and,creates,the,topic,partition,state,holders,if,a,watermark,generator,per,partition,exists,this,will,also,initialize,those;private,kafka,topic,partition,state,kph,initialize,subscribed,partition,states,map,kafka,topic,partition,long,assigned,partitions,to,initial,offsets,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,switch,timestamp,watermark,mode,case,suppress,warnings,unchecked,kafka,topic,partition,state,kph,partitions,kafka,topic,partition,state,kph,new,kafka,topic,partition,state,assigned,partitions,to,initial,offsets,size,int,pos,0,for,map,entry,kafka,topic,partition,long,partition,assigned,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,get,key,partitions,pos,new,kafka,topic,partition,state,partition,get,key,kafka,handle,partitions,pos,set,offset,partition,get,value,pos,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,periodic,watermarks,t,kph,partitions,kafka,topic,partition,state,with,periodic,watermarks,t,kph,new,kafka,topic,partition,state,with,periodic,watermarks,assigned,partitions,to,initial,offsets,size,int,pos,0,for,map,entry,kafka,topic,partition,long,partition,assigned,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,get,key,assigner,with,periodic,watermarks,t,assigner,instance,watermarks,periodic,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,periodic,watermarks,partition,get,key,kafka,handle,assigner,instance,partitions,pos,set,offset,partition,get,value,pos,return,partitions,case,suppress,warnings,unchecked,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,partitions,kafka,topic,partition,state,with,punctuated,watermarks,t,kph,new,kafka,topic,partition,state,with,punctuated,watermarks,assigned,partitions,to,initial,offsets,size,int,pos,0,for,map,entry,kafka,topic,partition,long,partition,assigned,partitions,to,initial,offsets,entry,set,kph,kafka,handle,create,kafka,partition,handle,partition,get,key,assigner,with,punctuated,watermarks,t,assigner,instance,watermarks,punctuated,deserialize,value,user,code,class,loader,partitions,pos,new,kafka,topic,partition,state,with,punctuated,watermarks,partition,get,key,kafka,handle,assigner,instance,partitions,pos,set,offset,partition,get,value,pos,return,partitions,default,throw,new,runtime,exception
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1498894422;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1501249950;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1501249950;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1509597235;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1510120531;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1515757408;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1515757408;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1515757409;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1517943538;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1517943538;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1517943538;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1527050648;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders( 		List<KafkaTopicPartition> partitions, 		long initialOffset, 		int timestampWatermarkMode, 		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, 		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, 		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException;1527059261;Shortcut variant of {@link #createPartitionStateHolders(Map, int, SerializedValue, SerializedValue, ClassLoader)}_that uses the same offset for all partitions when creating their state holders.;private List<KafkaTopicPartitionState<KPH>> createPartitionStateHolders(_		List<KafkaTopicPartition> partitions,_		long initialOffset,_		int timestampWatermarkMode,_		SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic,_		SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated,_		ClassLoader userCodeClassLoader) throws IOException, ClassNotFoundException {__		Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size())__		for (KafkaTopicPartition partition : partitions) {_			partitionsToInitialOffset.put(partition, initialOffset)__		}__		return createPartitionStateHolders(_				partitionsToInitialOffset,_				timestampWatermarkMode,_				watermarksPeriodic,_				watermarksPunctuated,_				userCodeClassLoader)__	};shortcut,variant,of,link,create,partition,state,holders,map,int,serialized,value,serialized,value,class,loader,that,uses,the,same,offset,for,all,partitions,when,creating,their,state,holders;private,list,kafka,topic,partition,state,kph,create,partition,state,holders,list,kafka,topic,partition,partitions,long,initial,offset,int,timestamp,watermark,mode,serialized,value,assigner,with,periodic,watermarks,t,watermarks,periodic,serialized,value,assigner,with,punctuated,watermarks,t,watermarks,punctuated,class,loader,user,code,class,loader,throws,ioexception,class,not,found,exception,map,kafka,topic,partition,long,partitions,to,initial,offset,new,hash,map,partitions,size,for,kafka,topic,partition,partition,partitions,partitions,to,initial,offset,put,partition,initial,offset,return,create,partition,state,holders,partitions,to,initial,offset,timestamp,watermark,mode,watermarks,periodic,watermarks,punctuated,user,code,class,loader
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1480685315;Add current and committed offsets to metric group__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<?> ktp: subscribedPartitions()) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,ktp,subscribed,partitions,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1482244974;Add current and committed offsets to metric group__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<?> ktp: subscribedPartitions()) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,ktp,subscribed,partitions,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1487173364;Add current and committed offsets to metric group__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<?> ktp: subscribedPartitions()) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,ktp,subscribed,partitions,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1488214488;Add current and committed offsets to metric group__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<?> ktp: subscribedPartitionStates()) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,ktp,subscribed,partition,states,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1489039537;Add current and committed offsets to metric group__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<?> ktp: subscribedPartitionStates()) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,ktp,subscribed,partition,states,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1489039538;Add current and committed offsets to metric group__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<?> ktp: subscribedPartitionStates()) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,ktp,subscribed,partition,states,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1489510697;Add current and committed offsets to metric group__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<?> ktp: subscribedPartitionStates()) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,ktp,subscribed,partition,states,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1495923077;Add current and committed offsets to metric group.__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<?> ktp: subscribedPartitionStates()) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,ktp,subscribed,partition,states,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1498894422;Add current and committed offsets to metric group.__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<KPH> ktp : subscribedPartitionStates) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,kph,ktp,subscribed,partition,states,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1501249950;Add current and committed offsets to metric group.__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<KPH> ktp : subscribedPartitionStates) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,kph,ktp,subscribed,partition,states,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1501249950;Add current and committed offsets to metric group.__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<KPH> ktp : subscribedPartitionStates) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,kph,ktp,subscribed,partition,states,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1509597235;Add current and committed offsets to metric group.__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<KPH> ktp : subscribedPartitionStates) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,kph,ktp,subscribed,partition,states,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1510120531;Add current and committed offsets to metric group.__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<KPH> ktp : subscribedPartitionStates) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,kph,ktp,subscribed,partition,states,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1515757408;Add current and committed offsets to metric group.__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		_		MetricGroup currentOffsets = metricGroup.addGroup("current-offsets")__		MetricGroup committedOffsets = metricGroup.addGroup("committed-offsets")__		for (KafkaTopicPartitionState<KPH> ktp : subscribedPartitionStates) {_			currentOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			committedOffsets.gauge(ktp.getTopic() + "-" + ktp.getPartition(), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))___			MetricGroup topicPartitionGroup = metricGroup_				.addGroup("topic", ktp.getTopic())_				.addGroup("partition", Integer.toString(ktp.getPartition()))__			topicPartitionGroup.gauge("currentOffsets", new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			topicPartitionGroup.gauge("committedOffsets", new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,current,offsets,metric,group,add,group,current,offsets,metric,group,committed,offsets,metric,group,add,group,committed,offsets,for,kafka,topic,partition,state,kph,ktp,subscribed,partition,states,current,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,committed,offsets,gauge,ktp,get,topic,ktp,get,partition,new,offset,gauge,ktp,offset,gauge,type,metric,group,topic,partition,group,metric,group,add,group,topic,ktp,get,topic,add,group,partition,integer,to,string,ktp,get,partition,topic,partition,group,gauge,current,offsets,new,offset,gauge,ktp,offset,gauge,type,topic,partition,group,gauge,committed,offsets,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1515757408;Add current and committed offsets to metric group.__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		MetricGroup legacyCurrentOffsetsGroup = metricGroup.addGroup(LEGACY_CURRENT_OFFSETS_METRICS_GROUP)__		MetricGroup legacyCommittedOffsetsGroup = metricGroup.addGroup(LEGACY_COMMITTED_OFFSETS_METRICS_GROUP)___		for (KafkaTopicPartitionState<KPH> ktp : subscribedPartitionStates) {_			MetricGroup topicPartitionGroup = metricGroup_				.addGroup(OFFSETS_BY_TOPIC_METRICS_GROUP, ktp.getTopic())_				.addGroup(OFFSETS_BY_PARTITION_METRICS_GROUP, Integer.toString(ktp.getPartition()))__			topicPartitionGroup.gauge(CURRENT_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			topicPartitionGroup.gauge(COMMITTED_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))___			legacyCurrentOffsetsGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			legacyCommittedOffsetsGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,legacy,current,offsets,group,metric,group,add,group,metric,group,legacy,committed,offsets,group,metric,group,add,group,for,kafka,topic,partition,state,kph,ktp,subscribed,partition,states,metric,group,topic,partition,group,metric,group,add,group,ktp,get,topic,add,group,integer,to,string,ktp,get,partition,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,legacy,current,offsets,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type,legacy,committed,offsets,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1515757409;Add current and committed offsets to metric group.__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		MetricGroup legacyCurrentOffsetsGroup = metricGroup.addGroup(LEGACY_CURRENT_OFFSETS_METRICS_GROUP)__		MetricGroup legacyCommittedOffsetsGroup = metricGroup.addGroup(LEGACY_COMMITTED_OFFSETS_METRICS_GROUP)___		for (KafkaTopicPartitionState<KPH> ktp : subscribedPartitionStates) {_			MetricGroup topicPartitionGroup = metricGroup_				.addGroup(OFFSETS_BY_TOPIC_METRICS_GROUP, ktp.getTopic())_				.addGroup(OFFSETS_BY_PARTITION_METRICS_GROUP, Integer.toString(ktp.getPartition()))__			topicPartitionGroup.gauge(CURRENT_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			topicPartitionGroup.gauge(COMMITTED_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))___			legacyCurrentOffsetsGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			legacyCommittedOffsetsGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,legacy,current,offsets,group,metric,group,add,group,metric,group,legacy,committed,offsets,group,metric,group,add,group,for,kafka,topic,partition,state,kph,ktp,subscribed,partition,states,metric,group,topic,partition,group,metric,group,add,group,ktp,get,topic,add,group,integer,to,string,ktp,get,partition,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,legacy,current,offsets,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type,legacy,committed,offsets,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type
AbstractFetcher -> protected void addOffsetStateGauge(MetricGroup metricGroup);1517943538;Add current and committed offsets to metric group.__@param metricGroup The metric group to use;protected void addOffsetStateGauge(MetricGroup metricGroup) {_		MetricGroup legacyCurrentOffsetsGroup = metricGroup.addGroup(LEGACY_CURRENT_OFFSETS_METRICS_GROUP)__		MetricGroup legacyCommittedOffsetsGroup = metricGroup.addGroup(LEGACY_COMMITTED_OFFSETS_METRICS_GROUP)___		for (KafkaTopicPartitionState<KPH> ktp : subscribedPartitionStates) {_			MetricGroup topicPartitionGroup = metricGroup_				.addGroup(OFFSETS_BY_TOPIC_METRICS_GROUP, ktp.getTopic())_				.addGroup(OFFSETS_BY_PARTITION_METRICS_GROUP, Integer.toString(ktp.getPartition()))__			topicPartitionGroup.gauge(CURRENT_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			topicPartitionGroup.gauge(COMMITTED_OFFSETS_METRICS_GAUGE, new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))___			legacyCurrentOffsetsGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.CURRENT_OFFSET))__			legacyCommittedOffsetsGroup.gauge(getLegacyOffsetsMetricsGaugeName(ktp), new OffsetGauge(ktp, OffsetGaugeType.COMMITTED_OFFSET))__		}_	};add,current,and,committed,offsets,to,metric,group,param,metric,group,the,metric,group,to,use;protected,void,add,offset,state,gauge,metric,group,metric,group,metric,group,legacy,current,offsets,group,metric,group,add,group,metric,group,legacy,committed,offsets,group,metric,group,add,group,for,kafka,topic,partition,state,kph,ktp,subscribed,partition,states,metric,group,topic,partition,group,metric,group,add,group,ktp,get,topic,add,group,integer,to,string,ktp,get,partition,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,topic,partition,group,gauge,new,offset,gauge,ktp,offset,gauge,type,legacy,current,offsets,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type,legacy,committed,offsets,group,gauge,get,legacy,offsets,metrics,gauge,name,ktp,new,offset,gauge,ktp,offset,gauge,type
