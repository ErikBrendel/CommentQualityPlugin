commented;modifiers;parameterAmount;loc;comment;code
true;public;1;6;/**  * Adds a filter predicate to reduce the number of rows to be returned by the input format.  * Multiple conjunctive predicates can be added by calling this method multiple times.  *  * <p>Note: Predicates can significantly reduce the amount of data that is read.  * However, the OrcRowInputFormat does not guarantee that all returned rows qualify the  * predicates. Moreover, predicates are only applied if the referenced field is among the  * selected fields.  *  * @param predicate The filter predicate.  */ ;/**  * Adds a filter predicate to reduce the number of rows to be returned by the input format.  * Multiple conjunctive predicates can be added by calling this method multiple times.  *  * <p>Note: Predicates can significantly reduce the amount of data that is read.  * However, the OrcRowInputFormat does not guarantee that all returned rows qualify the  * predicates. Moreover, predicates are only applied if the referenced field is among the  * selected fields.  *  * @param predicate The filter predicate.  */ public void addPredicate(Predicate predicate) {     // validate     validatePredicate(predicate).     // add predicate     this.conjunctPredicates.add(predicate). }
false;private;1;16;;private void validatePredicate(Predicate pred) {     if (pred instanceof ColumnPredicate) {         // check column name         String colName = ((ColumnPredicate) pred).columnName.         if (!this.schema.getFieldNames().contains(colName)) {             throw new IllegalArgumentException("Predicate cannot be applied. " + "Column '" + colName + "' does not exist in ORC schema.").         }     } else if (pred instanceof Not) {         validatePredicate(((Not) pred).child()).     } else if (pred instanceof Or) {         for (Predicate p : ((Or) pred).children()) {             validatePredicate(p).         }     } }
true;public;1;6;/**  * Selects the fields from the ORC schema that are returned by InputFormat.  *  * @param selectedFields The indices of the fields of the ORC schema that are returned by the InputFormat.  */ ;/**  * Selects the fields from the ORC schema that are returned by InputFormat.  *  * @param selectedFields The indices of the fields of the ORC schema that are returned by the InputFormat.  */ public void selectFields(int... selectedFields) {     // set field mapping     this.selectedFields = selectedFields.     // adapt result type     this.rowType = RowTypeInfo.projectFields(this.rowType, selectedFields). }
true;private;0;13;/**  * Computes the ORC projection mask of the fields to include from the selected fields.rowOrcInputFormat.nextRecord(null).  *  * @return The ORC projection mask.  */ ;/**  * Computes the ORC projection mask of the fields to include from the selected fields.rowOrcInputFormat.nextRecord(null).  *  * @return The ORC projection mask.  */ private boolean[] computeProjectionMask() {     // mask with all fields of the schema     boolean[] projectionMask = new boolean[schema.getMaximumId() + 1].     // for each selected field     for (int inIdx : selectedFields) {         // set all nested fields of a selected field to true         TypeDescription fieldSchema = schema.getChildren().get(inIdx).         for (int i = fieldSchema.getId(). i <= fieldSchema.getMaximumId(). i++) {             projectionMask[i] = true.         }     }     return projectionMask. }
false;public;0;9;;@Override public void openInputFormat() throws IOException {     super.openInputFormat().     // create and initialize the row batch     this.rows = new Row[batchSize].     for (int i = 0. i < batchSize. i++) {         rows[i] = new Row(selectedFields.length).     } }
false;public;1;44;;@Override public void open(FileInputSplit fileSplit) throws IOException {     LOG.debug("Opening ORC file {}", fileSplit.getPath()).     // open ORC file and create reader     org.apache.hadoop.fs.Path hPath = new org.apache.hadoop.fs.Path(fileSplit.getPath().getPath()).     Reader orcReader = OrcFile.createReader(hPath, OrcFile.readerOptions(conf)).     // get offset and length for the stripes that start in the split     Tuple2<Long, Long> offsetAndLength = getOffsetAndLengthForSplit(fileSplit, getStripes(orcReader)).     // create ORC row reader configuration     Reader.Options options = getOptions(orcReader).schema(schema).range(offsetAndLength.f0, offsetAndLength.f1).useZeroCopy(OrcConf.USE_ZEROCOPY.getBoolean(conf)).skipCorruptRecords(OrcConf.SKIP_CORRUPT_DATA.getBoolean(conf)).tolerateMissingSchema(OrcConf.TOLERATE_MISSING_SCHEMA.getBoolean(conf)).     // configure filters     if (!conjunctPredicates.isEmpty()) {         SearchArgument.Builder b = SearchArgumentFactory.newBuilder().         b = b.startAnd().         for (Predicate predicate : conjunctPredicates) {             predicate.add(b).         }         b = b.end().         options.searchArgument(b.build(), new String[] {}).     }     // configure selected fields     options.include(computeProjectionMask()).     // create ORC row reader     this.orcRowsReader = orcReader.rows(options).     // assign ids     this.schema.getId().     // create row batch     this.rowBatch = schema.createRowBatch(batchSize).     rowsInBatch = 0.     nextRow = 0. }
false;;1;4;;@VisibleForTesting Reader.Options getOptions(Reader orcReader) {     return orcReader.options(). }
false;;1;4;;@VisibleForTesting List<StripeInformation> getStripes(Reader orcReader) {     return orcReader.getStripes(). }
false;private;2;22;;private Tuple2<Long, Long> getOffsetAndLengthForSplit(FileInputSplit split, List<StripeInformation> stripes) {     long splitStart = split.getStart().     long splitEnd = splitStart + split.getLength().     long readStart = Long.MAX_VALUE.     long readEnd = Long.MIN_VALUE.     for (StripeInformation s : stripes) {         if (splitStart <= s.getOffset() && s.getOffset() < splitEnd) {             // stripe starts in split, so it is included             readStart = Math.min(readStart, s.getOffset()).             readEnd = Math.max(readEnd, s.getOffset() + s.getLength()).         }     }     if (readStart < Long.MAX_VALUE) {         // at least one split is included         return Tuple2.of(readStart, readEnd - readStart).     } else {         return Tuple2.of(0L, 0L).     } }
false;public;0;7;;@Override public void close() throws IOException {     if (orcRowsReader != null) {         this.orcRowsReader.close().     }     this.orcRowsReader = null. }
false;public;0;6;;@Override public void closeInputFormat() throws IOException {     this.rows = null.     this.schema = null.     this.rowBatch = null. }
false;public;0;4;;@Override public boolean reachedEnd() throws IOException {     return !ensureBatch(). }
true;private;0;17;/**  * Checks if there is at least one row left in the batch to return.  * If no more row are available, it reads another batch of rows.  *  * @return Returns true if there is one more row to return, false otherwise.  * @throws IOException throw if an exception happens while reading a batch.  */ ;/**  * Checks if there is at least one row left in the batch to return.  * If no more row are available, it reads another batch of rows.  *  * @return Returns true if there is one more row to return, false otherwise.  * @throws IOException throw if an exception happens while reading a batch.  */ private boolean ensureBatch() throws IOException {     if (nextRow >= rowsInBatch) {         // No more rows available in the Rows array.         nextRow = 0.         // Try to read the next batch if rows from the ORC file.         boolean moreRows = orcRowsReader.nextBatch(rowBatch).         if (moreRows) {             // Load the data into the Rows array.             rowsInBatch = fillRows(rows, schema, rowBatch, selectedFields).         }         return moreRows.     }     // there is at least one Row left in the Rows array.     return true. }
false;public;1;5;;@Override public Row nextRecord(Row reuse) throws IOException {     // return the next row     return rows[this.nextRow++]. }
false;public;0;4;;@Override public TypeInformation<Row> getProducedType() {     return rowType. }
false;private;1;15;;// -------------------------------------------------------------------------------------------- // Custom serialization methods // -------------------------------------------------------------------------------------------- private void writeObject(ObjectOutputStream out) throws IOException {     out.writeInt(batchSize).     this.conf.write(out).     out.writeUTF(schema.toString()).     out.writeInt(selectedFields.length).     for (int f : selectedFields) {         out.writeInt(f).     }     out.writeInt(conjunctPredicates.size()).     for (Predicate p : conjunctPredicates) {         out.writeObject(p).     } }
false;private;1;22;;@SuppressWarnings("unchecked") private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {     batchSize = in.readInt().     org.apache.hadoop.conf.Configuration configuration = new org.apache.hadoop.conf.Configuration().     configuration.readFields(in).     if (this.conf == null) {         this.conf = configuration.     }     this.schema = TypeDescription.fromString(in.readUTF()).     this.selectedFields = new int[in.readInt()].     for (int i = 0. i < selectedFields.length. i++) {         this.selectedFields[i] = in.readInt().     }     this.conjunctPredicates = new ArrayList<>().     int numPreds = in.readInt().     for (int i = 0. i < numPreds. i++) {         conjunctPredicates.add((Predicate) in.readObject()).     } }
false;public;0;4;;@Override public boolean supportsMultiPaths() {     return true. }
false;;0;4;;// -------------------------------------------------------------------------------------------- // Getter methods for tests // -------------------------------------------------------------------------------------------- @VisibleForTesting Configuration getConfiguration() {     return conf. }
false;;0;4;;@VisibleForTesting int getBatchSize() {     return batchSize. }
false;;0;4;;@VisibleForTesting String getSchema() {     return schema.toString(). }
false;protected,abstract;1;1;;protected abstract SearchArgument.Builder add(SearchArgument.Builder builder).
false;;1;62;;Object castLiteral(Serializable literal) {     switch(literalType) {         case LONG:             if (literal instanceof Byte) {                 return new Long((Byte) literal).             } else if (literal instanceof Short) {                 return new Long((Short) literal).             } else if (literal instanceof Integer) {                 return new Long((Integer) literal).             } else if (literal instanceof Long) {                 return literal.             } else {                 throw new IllegalArgumentException("A predicate on a LONG column requires an integer " + "literal, i.e., Byte, Short, Integer, or Long.").             }         case FLOAT:             if (literal instanceof Float) {                 return new Double((Float) literal).             } else if (literal instanceof Double) {                 return literal.             } else if (literal instanceof BigDecimal) {                 return ((BigDecimal) literal).doubleValue().             } else {                 throw new IllegalArgumentException("A predicate on a FLOAT column requires a floating " + "literal, i.e., Float or Double.").             }         case STRING:             if (literal instanceof String) {                 return literal.             } else {                 throw new IllegalArgumentException("A predicate on a STRING column requires a floating " + "literal, i.e., Float or Double.").             }         case BOOLEAN:             if (literal instanceof Boolean) {                 return literal.             } else {                 throw new IllegalArgumentException("A predicate on a BOOLEAN column requires a Boolean literal.").             }         case DATE:             if (literal instanceof Date) {                 return literal.             } else {                 throw new IllegalArgumentException("A predicate on a DATE column requires a java.sql.Date literal.").             }         case TIMESTAMP:             if (literal instanceof Timestamp) {                 return literal.             } else {                 throw new IllegalArgumentException("A predicate on a TIMESTAMP column requires a java.sql.Timestamp literal.").             }         case DECIMAL:             if (literal instanceof BigDecimal) {                 return new HiveDecimalWritable(HiveDecimal.create((BigDecimal) literal)).             } else {                 throw new IllegalArgumentException("A predicate on a DECIMAL column requires a BigDecimal literal.").             }         default:             throw new IllegalArgumentException("Unknown literal type " + literalType).     } }
false;protected;1;4;;@Override protected SearchArgument.Builder add(SearchArgument.Builder builder) {     return builder.equals(columnName, literalType, castLiteral(literal)). }
false;public;0;4;;@Override public String toString() {     return columnName + " = " + literal. }
false;protected;1;4;;@Override protected SearchArgument.Builder add(SearchArgument.Builder builder) {     return builder.nullSafeEquals(columnName, literalType, castLiteral(literal)). }
false;public;0;4;;@Override public String toString() {     return columnName + " = " + literal. }
false;protected;1;4;;@Override protected SearchArgument.Builder add(SearchArgument.Builder builder) {     return builder.lessThan(columnName, literalType, castLiteral(literal)). }
false;public;0;4;;@Override public String toString() {     return columnName + " < " + literal. }
false;protected;1;4;;@Override protected SearchArgument.Builder add(SearchArgument.Builder builder) {     return builder.lessThanEquals(columnName, literalType, castLiteral(literal)). }
false;public;0;4;;@Override public String toString() {     return columnName + " <= " + literal. }
false;protected;1;4;;@Override protected SearchArgument.Builder add(SearchArgument.Builder builder) {     return builder.isNull(columnName, literalType). }
false;public;0;4;;@Override public String toString() {     return columnName + " IS NULL". }
false;protected;1;4;;@Override protected SearchArgument.Builder add(SearchArgument.Builder builder) {     return builder.between(columnName, literalType, castLiteral(lowerBound), castLiteral(upperBound)). }
false;public;0;4;;@Override public String toString() {     return lowerBound + " <= " + columnName + " <= " + upperBound. }
false;protected;1;8;;@Override protected SearchArgument.Builder add(SearchArgument.Builder builder) {     Object[] castedLiterals = new Object[literals.length].     for (int i = 0. i < literals.length. i++) {         castedLiterals[i] = castLiteral(literals[i]).     }     return builder.in(columnName, literalType, (Object[]) castedLiterals). }
false;public;0;4;;@Override public String toString() {     return columnName + " IN " + Arrays.toString(literals). }
false;protected;1;3;;protected SearchArgument.Builder add(SearchArgument.Builder builder) {     return pred.add(builder.startNot()).end(). }
false;protected;0;3;;protected Predicate child() {     return pred. }
false;public;0;4;;@Override public String toString() {     return "NOT(" + pred.toString() + ")". }
false;protected;1;8;;@Override protected SearchArgument.Builder add(SearchArgument.Builder builder) {     SearchArgument.Builder withOr = builder.startOr().     for (Predicate p : preds) {         withOr = p.add(withOr).     }     return withOr.end(). }
false;protected;0;3;;protected Iterable<Predicate> children() {     return Arrays.asList(preds). }
false;public;0;4;;@Override public String toString() {     return "OR(" + Arrays.toString(preds) + ")". }
