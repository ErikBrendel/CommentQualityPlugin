commented;modifiers;parameterAmount;loc;comment;code
true;public;1;5;/**  * Specify a custom {@code Configuration} that will be used when creating  * the {@link FileSystem} for writing.  */ ;/**  * Specify a custom {@code Configuration} that will be used when creating  * the {@link FileSystem} for writing.  */ public BucketingSink<T> setFSConfig(Configuration config) {     this.fsConfig = new Configuration().     fsConfig.addAll(config).     return this. }
true;public;1;7;/**  * Specify a custom {@code Configuration} that will be used when creating  * the {@link FileSystem} for writing.  */ ;/**  * Specify a custom {@code Configuration} that will be used when creating  * the {@link FileSystem} for writing.  */ public BucketingSink<T> setFSConfig(org.apache.hadoop.conf.Configuration config) {     this.fsConfig = new Configuration().     for (Map.Entry<String, String> entry : config) {         fsConfig.setString(entry.getKey(), entry.getValue()).     }     return this. }
false;public;2;7;;@Override @SuppressWarnings("unchecked") public void setInputType(TypeInformation<?> type, ExecutionConfig executionConfig) {     if (this.writerTemplate instanceof InputTypeConfigurable) {         ((InputTypeConfigurable) writerTemplate).setInputType(type, executionConfig).     } }
false;public;1;32;;@Override public void initializeState(FunctionInitializationContext context) throws Exception {     Preconditions.checkArgument(this.restoredBucketStates == null, "The operator has already been initialized.").     try {         initFileSystem().     } catch (IOException e) {         LOG.error("Error while creating FileSystem when initializing the state of the BucketingSink.", e).         throw new RuntimeException("Error while creating FileSystem when initializing the state of the BucketingSink.", e).     }     if (this.refTruncate == null) {         this.refTruncate = reflectTruncate(fs).     }     OperatorStateStore stateStore = context.getOperatorStateStore().     restoredBucketStates = stateStore.getSerializableListState("bucket-states").     int subtaskIndex = getRuntimeContext().getIndexOfThisSubtask().     if (context.isRestored()) {         LOG.info("Restoring state for the {} (taskIdx={}).", getClass().getSimpleName(), subtaskIndex).         for (State<T> recoveredState : restoredBucketStates.get()) {             handleRestoredBucketState(recoveredState).             if (LOG.isDebugEnabled()) {                 LOG.debug("{} idx {} restored {}", getClass().getSimpleName(), subtaskIndex, recoveredState).             }         }     } else {         LOG.info("No state to restore for the {} (taskIdx={}).", getClass().getSimpleName(), subtaskIndex).     } }
false;public;0;4;;@Override public long currentTimeMillis() {     return processingTimeService.getCurrentProcessingTime(). }
false;public;1;20;;@Override public void open(Configuration parameters) throws Exception {     super.open(parameters).     state = new State<>().     processingTimeService = ((StreamingRuntimeContext) getRuntimeContext()).getProcessingTimeService().     long currentProcessingTime = processingTimeService.getCurrentProcessingTime().     processingTimeService.registerTimer(currentProcessingTime + inactiveBucketCheckInterval, this).     this.clock = new Clock() {          @Override         public long currentTimeMillis() {             return processingTimeService.getCurrentProcessingTime().         }     }. }
true;private;0;6;/**  * Create a file system with the user-defined {@code HDFS} configuration.  * @throws IOException  */ ;/**  * Create a file system with the user-defined {@code HDFS} configuration.  * @throws IOException  */ private void initFileSystem() throws IOException {     if (fs == null) {         Path path = new Path(basePath).         fs = createHadoopFileSystem(path, fsConfig).     } }
false;public;0;8;;@Override public void close() throws Exception {     if (state != null) {         for (Map.Entry<String, BucketState<T>> entry : state.bucketStates.entrySet()) {             closeCurrentPartFile(entry.getValue()).         }     } }
false;public;1;19;;@Override public void invoke(T value) throws Exception {     Path bucketPath = bucketer.getBucketPath(clock, new Path(basePath), value).     long currentProcessingTime = processingTimeService.getCurrentProcessingTime().     BucketState<T> bucketState = state.getBucketState(bucketPath).     if (bucketState == null) {         bucketState = new BucketState<>(currentProcessingTime).         state.addBucketState(bucketPath, bucketState).     }     if (shouldRoll(bucketState, currentProcessingTime)) {         openNewPartFile(bucketPath, bucketState).     }     bucketState.writer.write(value).     bucketState.lastWrittenToTime = currentProcessingTime. }
true;private;2;27;/**  * Returns {@code true} if the current {@code part-file} should be closed and a new should be created.  * This happens if:  * <ol>  *     <li>no file is created yet for the task to write to, or</li>  *     <li>the current file has reached the maximum bucket size.</li>  *     <li>the current file is older than roll over interval</li>  * </ol>  */ ;/**  * Returns {@code true} if the current {@code part-file} should be closed and a new should be created.  * This happens if:  * <ol>  *     <li>no file is created yet for the task to write to, or</li>  *     <li>the current file has reached the maximum bucket size.</li>  *     <li>the current file is older than roll over interval</li>  * </ol>  */ private boolean shouldRoll(BucketState<T> bucketState, long currentProcessingTime) throws IOException {     boolean shouldRoll = false.     int subtaskIndex = getRuntimeContext().getIndexOfThisSubtask().     if (!bucketState.isWriterOpen) {         shouldRoll = true.         LOG.debug("BucketingSink {} starting new bucket.", subtaskIndex).     } else {         long writePosition = bucketState.writer.getPos().         if (writePosition > batchSize) {             shouldRoll = true.             LOG.debug("BucketingSink {} starting new bucket because file position {} is above batch size {}.", subtaskIndex, writePosition, batchSize).         } else {             if (currentProcessingTime - bucketState.creationTime > batchRolloverInterval) {                 shouldRoll = true.                 LOG.debug("BucketingSink {} starting new bucket because file is older than roll over interval {}.", subtaskIndex, batchRolloverInterval).             }         }     }     return shouldRoll. }
false;public;1;8;;@Override public void onProcessingTime(long timestamp) throws Exception {     long currentProcessingTime = processingTimeService.getCurrentProcessingTime().     closePartFilesByTime(currentProcessingTime).     processingTimeService.registerTimer(currentProcessingTime + inactiveBucketCheckInterval, this). }
true;private;1;13;/**  * Checks for inactive buckets, and closes them. Buckets are considered inactive if they have not been  * written to for a period greater than {@code inactiveBucketThreshold} ms. Buckets are also closed if they are  * older than {@code batchRolloverInterval} ms. This enables in-progress files to be moved to the pending state  * and be finalised on the next checkpoint.  */ ;/**  * Checks for inactive buckets, and closes them. Buckets are considered inactive if they have not been  * written to for a period greater than {@code inactiveBucketThreshold} ms. Buckets are also closed if they are  * older than {@code batchRolloverInterval} ms. This enables in-progress files to be moved to the pending state  * and be finalised on the next checkpoint.  */ private void closePartFilesByTime(long currentProcessingTime) throws Exception {     synchronized (state.bucketStates) {         for (Map.Entry<String, BucketState<T>> entry : state.bucketStates.entrySet()) {             if ((entry.getValue().lastWrittenToTime < currentProcessingTime - inactiveBucketThreshold) || (entry.getValue().creationTime < currentProcessingTime - batchRolloverInterval)) {                 LOG.debug("BucketingSink {} closing bucket due to inactivity of over {} ms.", getRuntimeContext().getIndexOfThisSubtask(), inactiveBucketThreshold).                 closeCurrentPartFile(entry.getValue()).             }         }     } }
true;private;2;50;/**  * Closes the current part file and opens a new one with a new bucket path, as returned by the  * {@link Bucketer}. If the bucket is not new, then this will create a new file with the same path  * as its predecessor, but with an increased rolling counter (see {@link BucketingSink}.  */ ;/**  * Closes the current part file and opens a new one with a new bucket path, as returned by the  * {@link Bucketer}. If the bucket is not new, then this will create a new file with the same path  * as its predecessor, but with an increased rolling counter (see {@link BucketingSink}.  */ private void openNewPartFile(Path bucketPath, BucketState<T> bucketState) throws Exception {     closeCurrentPartFile(bucketState).     if (!fs.exists(bucketPath)) {         try {             if (fs.mkdirs(bucketPath)) {                 LOG.debug("Created new bucket directory: {}", bucketPath).             }         } catch (IOException e) {             throw new RuntimeException("Could not create new bucket path.", e).         }     }     // The following loop tries different partCounter values in ascending order until it reaches the minimum     // that is not yet used. This works since there is only one parallel subtask that tries names with this     // subtask id. Otherwise we would run into concurrency issues here. This is aligned with the way we now     // clean the base directory in case of rescaling.     int subtaskIndex = getRuntimeContext().getIndexOfThisSubtask().     Path partPath = assemblePartPath(bucketPath, subtaskIndex, bucketState.partCounter).     while (fs.exists(partPath) || fs.exists(getPendingPathFor(partPath)) || fs.exists(getInProgressPathFor(partPath))) {         bucketState.partCounter++.         partPath = assemblePartPath(bucketPath, subtaskIndex, bucketState.partCounter).     }     // Record the creation time of the bucket     bucketState.creationTime = processingTimeService.getCurrentProcessingTime().     // increase, so we don't have to check for this name next time     bucketState.partCounter++.     LOG.debug("Next part path is {}", partPath.toString()).     bucketState.currentFile = partPath.toString().     Path inProgressPath = getInProgressPathFor(partPath).     if (bucketState.writer == null) {         bucketState.writer = writerTemplate.duplicate().         if (bucketState.writer == null) {             throw new UnsupportedOperationException("Could not duplicate writer. " + "Class '" + writerTemplate.getClass().getCanonicalName() + "' must implement the 'Writer.duplicate()' method.").         }     }     bucketState.writer.open(fs, inProgressPath).     bucketState.isWriterOpen = true. }
true;private;1;19;/**  * Closes the current part file and moves it from the in-progress state to the pending state.  */ ;/**  * Closes the current part file and moves it from the in-progress state to the pending state.  */ private void closeCurrentPartFile(BucketState<T> bucketState) throws Exception {     if (bucketState.isWriterOpen) {         bucketState.writer.close().         bucketState.isWriterOpen = false.     }     if (bucketState.currentFile != null) {         Path currentPartPath = new Path(bucketState.currentFile).         Path inProgressPath = getInProgressPathFor(currentPartPath).         Path pendingPath = getPendingPathFor(currentPartPath).         fs.rename(inProgressPath, pendingPath).         LOG.debug("Moving in-progress bucket {} to pending file {}", inProgressPath, pendingPath).         bucketState.pendingFiles.add(currentPartPath.toString()).         bucketState.currentFile = null.     } }
true;private;1;50;/**  * Gets the truncate() call using reflection.  *  * <p><b>NOTE:</b> This code comes from Flume.  */ ;/**  * Gets the truncate() call using reflection.  *  * <p><b>NOTE:</b> This code comes from Flume.  */ private Method reflectTruncate(FileSystem fs) {     // on some filesystem implementations     if (!useTruncate) {         return null.     }     Method m = null.     if (fs != null) {         Class<?> fsClass = fs.getClass().         try {             m = fsClass.getMethod("truncate", Path.class, long.class).         } catch (NoSuchMethodException ex) {             LOG.debug("Truncate not found. Will write a file with suffix '{}' " + " and prefix '{}' to specify how many bytes in a bucket are valid.", validLengthSuffix, validLengthPrefix).             return null.         }         // verify that truncate actually works         Path testPath = new Path(basePath, UUID.randomUUID().toString()).         try {             try (FSDataOutputStream outputStream = fs.create(testPath)) {                 outputStream.writeUTF("hello").             } catch (IOException e) {                 LOG.error("Could not create file for checking if truncate works.", e).                 throw new RuntimeException("Could not create file for checking if truncate works. " + "You can disable support for truncate() completely via " + "BucketingSink.setUseTruncate(false).", e).             }             try {                 m.invoke(fs, testPath, 2).             } catch (IllegalAccessException | InvocationTargetException e) {                 LOG.debug("Truncate is not supported.", e).                 m = null.             }         } finally {             try {                 fs.delete(testPath, false).             } catch (IOException e) {                 LOG.error("Could not delete truncate test file.", e).                 throw new RuntimeException("Could not delete truncate test file. " + "You can disable support for truncate() completely via " + "BucketingSink.setUseTruncate(false).", e).             }         }     }     return m. }
false;private;3;4;;private Path assemblePartPath(Path bucket, int subtaskIndex, int partIndex) {     String localPartSuffix = partSuffix != null ? partSuffix : "".     return new Path(bucket, String.format("%s-%s-%s%s", partPrefix, subtaskIndex, partIndex, localPartSuffix)). }
false;private;1;3;;private Path getPendingPathFor(Path path) {     return new Path(path.getParent(), pendingPrefix + path.getName()).suffix(pendingSuffix). }
false;private;1;3;;private Path getInProgressPathFor(Path path) {     return new Path(path.getParent(), inProgressPrefix + path.getName()).suffix(inProgressSuffix). }
false;private;1;3;;private Path getValidLengthPathFor(Path path) {     return new Path(path.getParent(), validLengthPrefix + path.getName()).suffix(validLengthSuffix). }
false;public;1;47;;@Override public void notifyCheckpointComplete(long checkpointId) throws Exception {     synchronized (state.bucketStates) {         Iterator<Map.Entry<String, BucketState<T>>> bucketStatesIt = state.bucketStates.entrySet().iterator().         while (bucketStatesIt.hasNext()) {             BucketState<T> bucketState = bucketStatesIt.next().getValue().             synchronized (bucketState.pendingFilesPerCheckpoint) {                 Iterator<Map.Entry<Long, List<String>>> pendingCheckpointsIt = bucketState.pendingFilesPerCheckpoint.entrySet().iterator().                 while (pendingCheckpointsIt.hasNext()) {                     Map.Entry<Long, List<String>> entry = pendingCheckpointsIt.next().                     Long pastCheckpointId = entry.getKey().                     List<String> pendingPaths = entry.getValue().                     if (pastCheckpointId <= checkpointId) {                         LOG.debug("Moving pending files to final location for checkpoint {}", pastCheckpointId).                         for (String filename : pendingPaths) {                             Path finalPath = new Path(filename).                             Path pendingPath = getPendingPathFor(finalPath).                             fs.rename(pendingPath, finalPath).                             LOG.debug("Moving pending file {} to final location having completed checkpoint {}.", pendingPath, pastCheckpointId).                         }                         pendingCheckpointsIt.remove().                     }                 }                 if (!bucketState.isWriterOpen && bucketState.pendingFiles.isEmpty() && bucketState.pendingFilesPerCheckpoint.isEmpty()) {                     // We've dealt with all the pending files and the writer for this bucket is not currently open.                     // Therefore this bucket is currently inactive and we can remove it from our state.                     bucketStatesIt.remove().                 }             }         }     } }
false;public;1;28;;@Override public void snapshotState(FunctionSnapshotContext context) throws Exception {     Preconditions.checkNotNull(restoredBucketStates, "The operator has not been properly initialized.").     restoredBucketStates.clear().     synchronized (state.bucketStates) {         int subtaskIdx = getRuntimeContext().getIndexOfThisSubtask().         for (Map.Entry<String, BucketState<T>> bucketStateEntry : state.bucketStates.entrySet()) {             BucketState<T> bucketState = bucketStateEntry.getValue().             if (bucketState.isWriterOpen) {                 bucketState.currentFileValidLength = bucketState.writer.flush().             }             synchronized (bucketState.pendingFilesPerCheckpoint) {                 bucketState.pendingFilesPerCheckpoint.put(context.getCheckpointId(), bucketState.pendingFiles).             }             bucketState.pendingFiles = new ArrayList<>().         }         restoredBucketStates.add(state).         if (LOG.isDebugEnabled()) {             LOG.debug("{} idx {} checkpointed {}.", getClass().getSimpleName(), subtaskIdx, state).         }     } }
false;private;1;22;;private void handleRestoredBucketState(State<T> restoredState) {     Preconditions.checkNotNull(restoredState).     for (BucketState<T> bucketState : restoredState.bucketStates.values()) {         // we can clean all the pending files since they were renamed to         // final files after this checkpoint was successful         // (we re-start from the last **successful** checkpoint)         bucketState.pendingFiles.clear().         handlePendingInProgressFile(bucketState.currentFile, bucketState.currentFileValidLength).         // Now that we've restored the bucket to a valid state, reset the current file info         bucketState.currentFile = null.         bucketState.currentFileValidLength = -1.         bucketState.isWriterOpen = false.         handlePendingFilesForPreviousCheckpoints(bucketState.pendingFilesPerCheckpoint).         bucketState.pendingFilesPerCheckpoint.clear().     } }
false;private;1;13;;private void handleRestoredRollingSinkState(RollingSink.BucketState restoredState) {     restoredState.pendingFiles.clear().     handlePendingInProgressFile(restoredState.currentFile, restoredState.currentFileValidLength).     // Now that we've restored the bucket to a valid state, reset the current file info     restoredState.currentFile = null.     restoredState.currentFileValidLength = -1.     handlePendingFilesForPreviousCheckpoints(restoredState.pendingFilesPerCheckpoint).     restoredState.pendingFilesPerCheckpoint.clear(). }
false;private;2;101;;private void handlePendingInProgressFile(String file, long validLength) {     if (file != null) {         // We were writing to a file when the last checkpoint occurred. This file can either         // be still in-progress or became a pending file at some point after the checkpoint.         // Either way, we have to truncate it back to a valid state (or write a .valid-length         // file that specifies up to which length it is valid) and rename it to the final name         // before starting a new bucket file.         Path partPath = new Path(file).         try {             Path partPendingPath = getPendingPathFor(partPath).             Path partInProgressPath = getInProgressPathFor(partPath).             if (fs.exists(partPendingPath)) {                 LOG.debug("In-progress file {} has been moved to pending after checkpoint, moving to final location.", partPath).                 // has been moved to pending in the mean time, rename to final location                 fs.rename(partPendingPath, partPath).             } else if (fs.exists(partInProgressPath)) {                 LOG.debug("In-progress file {} is still in-progress, moving to final location.", partPath).                 // it was still in progress, rename to final path                 fs.rename(partInProgressPath, partPath).             } else if (fs.exists(partPath)) {                 LOG.debug("In-Progress file {} was already moved to final location {}.", file, partPath).             } else {                 LOG.debug("In-Progress file {} was neither moved to pending nor is still in progress. Possibly, " + "it was moved to final location by a previous snapshot restore", file).             }             // is only available starting with Hadoop 2.7             if (this.refTruncate == null) {                 this.refTruncate = reflectTruncate(fs).             }             // truncate it or write a ".valid-length" file to specify up to which point it is valid             if (refTruncate != null) {                 LOG.debug("Truncating {} to valid length {}", partPath, validLength).                 // recovering, after all ...                 if (fs instanceof DistributedFileSystem) {                     DistributedFileSystem dfs = (DistributedFileSystem) fs.                     LOG.debug("Trying to recover file lease {}", partPath).                     dfs.recoverLease(partPath).                     boolean isclosed = dfs.isFileClosed(partPath).                     StopWatch sw = new StopWatch().                     sw.start().                     while (!isclosed) {                         if (sw.getTime() > asyncTimeout) {                             break.                         }                         try {                             Thread.sleep(500).                         } catch (InterruptedException e1) {                         // ignore it                         }                         isclosed = dfs.isFileClosed(partPath).                     }                 }                 Boolean truncated = (Boolean) refTruncate.invoke(fs, partPath, validLength).                 if (!truncated) {                     LOG.debug("Truncate did not immediately complete for {}, waiting...", partPath).                     // we must wait for the asynchronous truncate operation to complete                     StopWatch sw = new StopWatch().                     sw.start().                     long newLen = fs.getFileStatus(partPath).getLen().                     while (newLen != validLength) {                         if (sw.getTime() > asyncTimeout) {                             break.                         }                         try {                             Thread.sleep(500).                         } catch (InterruptedException e1) {                         // ignore it                         }                         newLen = fs.getFileStatus(partPath).getLen().                     }                     if (newLen != validLength) {                         throw new RuntimeException("Truncate did not truncate to right length. Should be " + validLength + " is " + newLen + ".").                     }                 }             } else {                 Path validLengthFilePath = getValidLengthPathFor(partPath).                 if (!fs.exists(validLengthFilePath) && fs.exists(partPath)) {                     LOG.debug("Writing valid-length file for {} to specify valid length {}", partPath, validLength).                     try (FSDataOutputStream lengthFileOut = fs.create(validLengthFilePath)) {                         lengthFileOut.writeUTF(Long.toString(validLength)).                     }                 }             }         } catch (IOException e) {             LOG.error("Error while restoring BucketingSink state.", e).             throw new RuntimeException("Error while restoring BucketingSink state.", e).         } catch (InvocationTargetException | IllegalAccessException e) {             LOG.error("Could not invoke truncate.", e).             throw new RuntimeException("Could not invoke truncate.", e).         }     } }
false;private;1;26;;private void handlePendingFilesForPreviousCheckpoints(Map<Long, List<String>> pendingFilesPerCheckpoint) {     // Move files that are confirmed by a checkpoint but did not get moved to final location     // because the checkpoint notification did not happen before a failure     LOG.debug("Moving pending files to final location on restore.").     Set<Long> pastCheckpointIds = pendingFilesPerCheckpoint.keySet().     for (Long pastCheckpointId : pastCheckpointIds) {         // to their final name         for (String filename : pendingFilesPerCheckpoint.get(pastCheckpointId)) {             Path finalPath = new Path(filename).             Path pendingPath = getPendingPathFor(finalPath).             try {                 if (fs.exists(pendingPath)) {                     LOG.debug("Restoring BucketingSink State: Moving pending file {} to final location after complete checkpoint {}.", pendingPath, pastCheckpointId).                     fs.rename(pendingPath, finalPath).                 }             } catch (IOException e) {                 LOG.error("Restoring BucketingSink State: Error while renaming pending file {} to final path {}: {}", pendingPath, finalPath, e).                 throw new RuntimeException("Error while renaming pending file " + pendingPath + " to final path " + finalPath, e).             }         }     } }
true;public;1;4;/**  * Sets the maximum bucket size in bytes.  *  * <p>When a bucket part file becomes larger than this size a new bucket part file is started and  * the old one is closed. The name of the bucket files depends on the {@link Bucketer}.  *  * @param batchSize The bucket part file size in bytes.  */ ;// -------------------------------------------------------------------------------------------- // Setters for User configuration values // -------------------------------------------------------------------------------------------- /**  * Sets the maximum bucket size in bytes.  *  * <p>When a bucket part file becomes larger than this size a new bucket part file is started and  * the old one is closed. The name of the bucket files depends on the {@link Bucketer}.  *  * @param batchSize The bucket part file size in bytes.  */ public BucketingSink<T> setBatchSize(long batchSize) {     this.batchSize = batchSize.     return this. }
true;public;1;7;/**  * Sets the roll over interval in milliseconds.  *  * <p>When a bucket part file is older than the roll over interval, a new bucket part file is  * started and the old one is closed. The name of the bucket file depends on the {@link Bucketer}.  * Additionally, the old part file is also closed if the bucket is not written to for a minimum of  * {@code inactiveBucketThreshold} ms.  *  * @param batchRolloverInterval The roll over interval in milliseconds  */ ;/**  * Sets the roll over interval in milliseconds.  *  * <p>When a bucket part file is older than the roll over interval, a new bucket part file is  * started and the old one is closed. The name of the bucket file depends on the {@link Bucketer}.  * Additionally, the old part file is also closed if the bucket is not written to for a minimum of  * {@code inactiveBucketThreshold} ms.  *  * @param batchRolloverInterval The roll over interval in milliseconds  */ public BucketingSink<T> setBatchRolloverInterval(long batchRolloverInterval) {     if (batchRolloverInterval > 0) {         this.batchRolloverInterval = batchRolloverInterval.     }     return this. }
true;public;1;4;/**  * Sets the default time between checks for inactive buckets.  *  * @param interval The timeout, in milliseconds.  */ ;/**  * Sets the default time between checks for inactive buckets.  *  * @param interval The timeout, in milliseconds.  */ public BucketingSink<T> setInactiveBucketCheckInterval(long interval) {     this.inactiveBucketCheckInterval = interval.     return this. }
true;public;1;4;/**  * Sets the default threshold for marking a bucket as inactive and closing its part files.  * Buckets which haven't been written to for at least this period of time become inactive.  * Additionally, part files for the bucket are also closed if the bucket is older than  * {@code batchRolloverInterval} ms.  *  * @param threshold The timeout, in milliseconds.  */ ;/**  * Sets the default threshold for marking a bucket as inactive and closing its part files.  * Buckets which haven't been written to for at least this period of time become inactive.  * Additionally, part files for the bucket are also closed if the bucket is older than  * {@code batchRolloverInterval} ms.  *  * @param threshold The timeout, in milliseconds.  */ public BucketingSink<T> setInactiveBucketThreshold(long threshold) {     this.inactiveBucketThreshold = threshold.     return this. }
true;public;1;4;/**  * Sets the {@link Bucketer} to use for determining the bucket files to write to.  *  * @param bucketer The bucketer to use.  */ ;/**  * Sets the {@link Bucketer} to use for determining the bucket files to write to.  *  * @param bucketer The bucketer to use.  */ public BucketingSink<T> setBucketer(Bucketer<T> bucketer) {     this.bucketer = bucketer.     return this. }
true;public;1;4;/**  * Sets the {@link Writer} to be used for writing the incoming elements to bucket files.  *  * @param writer The {@code Writer} to use.  */ ;/**  * Sets the {@link Writer} to be used for writing the incoming elements to bucket files.  *  * @param writer The {@code Writer} to use.  */ public BucketingSink<T> setWriter(Writer<T> writer) {     this.writerTemplate = writer.     return this. }
true;public;1;4;/**  * Sets the suffix of in-progress part files. The default is {@code ".in-progress"}.  */ ;/**  * Sets the suffix of in-progress part files. The default is {@code ".in-progress"}.  */ public BucketingSink<T> setInProgressSuffix(String inProgressSuffix) {     this.inProgressSuffix = inProgressSuffix.     return this. }
true;public;1;4;/**  * Sets the prefix of in-progress part files. The default is {@code "_"}.  */ ;/**  * Sets the prefix of in-progress part files. The default is {@code "_"}.  */ public BucketingSink<T> setInProgressPrefix(String inProgressPrefix) {     this.inProgressPrefix = inProgressPrefix.     return this. }
true;public;1;4;/**  * Sets the suffix of pending part files. The default is {@code ".pending"}.  */ ;/**  * Sets the suffix of pending part files. The default is {@code ".pending"}.  */ public BucketingSink<T> setPendingSuffix(String pendingSuffix) {     this.pendingSuffix = pendingSuffix.     return this. }
true;public;1;4;/**  * Sets the prefix of pending part files. The default is {@code "_"}.  */ ;/**  * Sets the prefix of pending part files. The default is {@code "_"}.  */ public BucketingSink<T> setPendingPrefix(String pendingPrefix) {     this.pendingPrefix = pendingPrefix.     return this. }
true;public;1;4;/**  * Sets the suffix of valid-length files. The default is {@code ".valid-length"}.  */ ;/**  * Sets the suffix of valid-length files. The default is {@code ".valid-length"}.  */ public BucketingSink<T> setValidLengthSuffix(String validLengthSuffix) {     this.validLengthSuffix = validLengthSuffix.     return this. }
true;public;1;4;/**  * Sets the prefix of valid-length files. The default is {@code "_"}.  */ ;/**  * Sets the prefix of valid-length files. The default is {@code "_"}.  */ public BucketingSink<T> setValidLengthPrefix(String validLengthPrefix) {     this.validLengthPrefix = validLengthPrefix.     return this. }
true;public;1;4;/**  * Sets the suffix of part files.  The default is no suffix.  */ ;/**  * Sets the suffix of part files.  The default is no suffix.  */ public BucketingSink<T> setPartSuffix(String partSuffix) {     this.partSuffix = partSuffix.     return this. }
true;public;1;4;/**  * Sets the prefix of part files.  The default is {@code "part"}.  */ ;/**  * Sets the prefix of part files.  The default is {@code "part"}.  */ public BucketingSink<T> setPartPrefix(String partPrefix) {     this.partPrefix = partPrefix.     return this. }
true;public;1;4;/**  * Sets whether to use {@code FileSystem.truncate()} to truncate written bucket files back to  * a consistent state in case of a restore from checkpoint. If {@code truncate()} is not used  * this sink will write valid-length files for corresponding bucket files that have to be used  * when reading from bucket files to make sure to not read too far.  */ ;/**  * Sets whether to use {@code FileSystem.truncate()} to truncate written bucket files back to  * a consistent state in case of a restore from checkpoint. If {@code truncate()} is not used  * this sink will write valid-length files for corresponding bucket files that have to be used  * when reading from bucket files to make sure to not read too far.  */ public BucketingSink<T> setUseTruncate(boolean useTruncate) {     this.useTruncate = useTruncate.     return this. }
true;public;0;4;/**  * Disable cleanup of leftover in-progress/pending files when the sink is opened.  *  * <p>This should only be disabled if using the sink without checkpoints, to not remove  * the files already in the directory.  *  * @deprecated This option is deprecated and remains only for backwards compatibility.  * We do not clean up lingering files anymore.  */ ;/**  * Disable cleanup of leftover in-progress/pending files when the sink is opened.  *  * <p>This should only be disabled if using the sink without checkpoints, to not remove  * the files already in the directory.  *  * @deprecated This option is deprecated and remains only for backwards compatibility.  * We do not clean up lingering files anymore.  */ @Deprecated public BucketingSink<T> disableCleanupOnOpen() {     return this. }
true;public;1;4;/**  * Sets the default timeout for asynchronous operations such as recoverLease and truncate.  *  * @param timeout The timeout, in milliseconds.  */ ;/**  * Sets the default timeout for asynchronous operations such as recoverLease and truncate.  *  * @param timeout The timeout, in milliseconds.  */ public BucketingSink<T> setAsyncTimeout(long timeout) {     this.asyncTimeout = timeout.     return this. }
false;public;0;4;;@VisibleForTesting public State<T> getState() {     return state. }
false;;2;5;;void addBucketState(Path bucketPath, BucketState<T> state) {     synchronized (bucketStates) {         bucketStates.put(bucketPath.toString(), state).     } }
false;;1;5;;BucketState<T> getBucketState(Path bucketPath) {     synchronized (bucketStates) {         return bucketStates.get(bucketPath.toString()).     } }
false;public;0;4;;@Override public String toString() {     return bucketStates.toString(). }
false;public;0;9;;@Override public String toString() {     return "In-progress=" + currentFile + " validLength=" + currentFileValidLength + " pendingForNextCheckpoint=" + pendingFiles + " pendingForPrevCheckpoints=" + pendingFilesPerCheckpoint + " lastModified@" + lastWrittenToTime. }
false;public,static;2;98;;// ------------------------------------------------------------------------ // Utilities // ------------------------------------------------------------------------ public static FileSystem createHadoopFileSystem(Path path, @Nullable Configuration extraUserConf) throws IOException {     // try to get the Hadoop File System via the Flink File Systems     // that way we get the proper configuration     final org.apache.flink.core.fs.FileSystem flinkFs = org.apache.flink.core.fs.FileSystem.getUnguardedFileSystem(path.toUri()).     final FileSystem hadoopFs = (flinkFs instanceof HadoopFileSystem) ? ((HadoopFileSystem) flinkFs).getHadoopFileSystem() : null.     // then we use it directly     if (extraUserConf == null && hadoopFs != null) {         return hadoopFs.     } else {         // we need to re-instantiate the Hadoop file system, because we either have         // a special config, or the Path gave us a Flink FS that is not backed by         // Hadoop (like file://)         final org.apache.hadoop.conf.Configuration hadoopConf.         if (hadoopFs != null) {             // have a Hadoop FS but need to apply extra config             hadoopConf = hadoopFs.getConf().         } else {             // the Path gave us a Flink FS that is not backed by Hadoop (like file://)             // we need to get access to the Hadoop file system first             // we access the Hadoop FS in Flink, which carries the proper             // Hadoop configuration. we should get rid of this once the bucketing sink is             // properly implemented against Flink's FS abstraction             URI genericHdfsUri = URI.create("hdfs://localhost:12345/").             org.apache.flink.core.fs.FileSystem accessor = org.apache.flink.core.fs.FileSystem.getUnguardedFileSystem(genericHdfsUri).             if (!(accessor instanceof HadoopFileSystem)) {                 throw new IOException("Cannot instantiate a Hadoop file system to access the Hadoop configuration. " + "FS for hdfs:// is " + accessor.getClass().getName()).             }             hadoopConf = ((HadoopFileSystem) accessor).getHadoopFileSystem().getConf().         }         // finalize the configuration         final org.apache.hadoop.conf.Configuration finalConf.         if (extraUserConf == null) {             finalConf = hadoopConf.         } else {             finalConf = new org.apache.hadoop.conf.Configuration(hadoopConf).             for (String key : extraUserConf.keySet()) {                 finalConf.set(key, extraUserConf.getString(key, null)).             }         }         // we explicitly re-instantiate the file system here in order to make sure         // that the configuration is applied.         URI fsUri = path.toUri().         final String scheme = fsUri.getScheme().         final String authority = fsUri.getAuthority().         if (scheme == null && authority == null) {             fsUri = FileSystem.getDefaultUri(finalConf).         } else if (scheme != null && authority == null) {             URI defaultUri = FileSystem.getDefaultUri(finalConf).             if (scheme.equals(defaultUri.getScheme()) && defaultUri.getAuthority() != null) {                 fsUri = defaultUri.             }         }         final Class<? extends FileSystem> fsClass = FileSystem.getFileSystemClass(fsUri.getScheme(), finalConf).         final FileSystem fs.         try {             fs = fsClass.newInstance().         } catch (Exception e) {             throw new IOException("Cannot instantiate the Hadoop file system", e).         }         fs.initialize(fsUri, finalConf).         // Otherwise buffers are not flushed entirely during checkpointing which results in data loss.         if (fs instanceof LocalFileSystem) {             return ((LocalFileSystem) fs).getRaw().         }         return fs.     } }
