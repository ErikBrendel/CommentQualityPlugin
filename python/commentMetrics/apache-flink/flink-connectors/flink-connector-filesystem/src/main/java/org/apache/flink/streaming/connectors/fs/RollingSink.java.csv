commented;modifiers;parameterAmount;loc;comment;code
true;public;1;5;/**  * Specify a custom {@code Configuration} that will be used when creating  * the {@link FileSystem} for writing.  */ ;/**  * Specify a custom {@code Configuration} that will be used when creating  * the {@link FileSystem} for writing.  */ public RollingSink<T> setFSConfig(Configuration config) {     this.fsConfig = new Configuration().     fsConfig.addAll(config).     return this. }
true;public;1;7;/**  * Specify a custom {@code Configuration} that will be used when creating  * the {@link FileSystem} for writing.  */ ;/**  * Specify a custom {@code Configuration} that will be used when creating  * the {@link FileSystem} for writing.  */ public RollingSink<T> setFSConfig(org.apache.hadoop.conf.Configuration config) {     this.fsConfig = new Configuration().     for (Map.Entry<String, String> entry : config) {         fsConfig.setString(entry.getKey(), entry.getValue()).     }     return this. }
false;public;2;7;;@Override @SuppressWarnings("unchecked") public void setInputType(TypeInformation<?> type, ExecutionConfig executionConfig) {     if (this.writerTemplate instanceof InputTypeConfigurable) {         ((InputTypeConfigurable) writerTemplate).setInputType(type, executionConfig).     } }
false;public;1;34;;@Override public void initializeState(FunctionInitializationContext context) throws Exception {     Preconditions.checkArgument(this.restoredBucketStates == null, "The " + getClass().getSimpleName() + " has already been initialized.").     try {         initFileSystem().     } catch (IOException e) {         LOG.error("Error while creating FileSystem when initializing the state of the RollingSink.", e).         throw new RuntimeException("Error while creating FileSystem when initializing the state of the RollingSink.", e).     }     if (this.refTruncate == null) {         this.refTruncate = reflectTruncate(fs).     }     OperatorStateStore stateStore = context.getOperatorStateStore().     restoredBucketStates = stateStore.getSerializableListState("rolling-states").     int subtaskIndex = getRuntimeContext().getIndexOfThisSubtask().     if (context.isRestored()) {         LOG.info("Restoring state for the {} (taskIdx={}).", getClass().getSimpleName(), subtaskIndex).         for (BucketState bucketState : restoredBucketStates.get()) {             handleRestoredBucketState(bucketState).         }         if (LOG.isDebugEnabled()) {             LOG.debug("{} (taskIdx= {}) restored {}", getClass().getSimpleName(), subtaskIndex, bucketState).         }     } else {         LOG.info("No state to restore for the {} (taskIdx= {}).", getClass().getSimpleName(), subtaskIndex).     } }
false;public;1;10;;@Override public void open(Configuration parameters) throws Exception {     super.open(parameters).     partCounter = 0.     this.writer = writerTemplate.duplicate().     bucketState = new BucketState(). }
true;private;0;6;/**  * Create a file system with the user-defined hdfs config.  * @throws IOException  */ ;/**  * Create a file system with the user-defined hdfs config.  * @throws IOException  */ private void initFileSystem() throws IOException {     if (fs == null) {         Path path = new Path(basePath).         fs = BucketingSink.createHadoopFileSystem(path, fsConfig).     } }
false;public;0;4;;@Override public void close() throws Exception {     closeCurrentPartFile(). }
false;public;1;7;;@Override public void invoke(T value) throws Exception {     if (shouldRoll()) {         openNewPartFile().     }     writer.write(value). }
true;private;0;26;/**  * Determines whether we should change the bucket file we are writing to.  *  * <p>This will roll if no file was created yet, if the file size is larger than the specified size  * or if the {@code Bucketer} determines that we should roll.  */ ;/**  * Determines whether we should change the bucket file we are writing to.  *  * <p>This will roll if no file was created yet, if the file size is larger than the specified size  * or if the {@code Bucketer} determines that we should roll.  */ private boolean shouldRoll() throws IOException {     boolean shouldRoll = false.     int subtaskIndex = getRuntimeContext().getIndexOfThisSubtask().     if (!isWriterOpen) {         shouldRoll = true.         LOG.debug("RollingSink {} starting new initial bucket. ", subtaskIndex).     }     if (bucketer.shouldStartNewBucket(new Path(basePath), currentBucketDirectory)) {         shouldRoll = true.         LOG.debug("RollingSink {} starting new bucket because {} said we should. ", subtaskIndex, bucketer).         // we will retrieve a new bucket base path in openNewPartFile so reset the part counter         partCounter = 0.     }     if (isWriterOpen) {         long writePosition = writer.getPos().         if (isWriterOpen && writePosition > batchSize) {             shouldRoll = true.             LOG.debug("RollingSink {} starting new bucket because file position {} is above batch size {}.", subtaskIndex, writePosition, batchSize).         }     }     return shouldRoll. }
true;private;0;37;/**  * Opens a new part file.  *  * <p>This closes the old bucket file and retrieves a new bucket path from the {@code Bucketer}.  */ ;/**  * Opens a new part file.  *  * <p>This closes the old bucket file and retrieves a new bucket path from the {@code Bucketer}.  */ private void openNewPartFile() throws Exception {     closeCurrentPartFile().     Path newBucketDirectory = bucketer.getNextBucketPath(new Path(basePath)).     if (!newBucketDirectory.equals(currentBucketDirectory)) {         currentBucketDirectory = newBucketDirectory.         try {             if (fs.mkdirs(currentBucketDirectory)) {                 LOG.debug("Created new bucket directory: {}", currentBucketDirectory).             }         } catch (IOException e) {             throw new RuntimeException("Could not create base path for new rolling file.", e).         }     }     int subtaskIndex = getRuntimeContext().getIndexOfThisSubtask().     currentPartPath = new Path(currentBucketDirectory, partPrefix + "-" + subtaskIndex + "-" + partCounter).     // our subtask id. Otherwise we would run into concurrency issues here.     while (fs.exists(currentPartPath) || fs.exists(getPendingPathFor(currentPartPath)) || fs.exists(getInProgressPathFor(currentPartPath))) {         partCounter++.         currentPartPath = new Path(currentBucketDirectory, partPrefix + "-" + subtaskIndex + "-" + partCounter).     }     // increase, so we don't have to check for this name next time     partCounter++.     LOG.debug("Next part path is {}", currentPartPath.toString()).     Path inProgressPath = getInProgressPathFor(currentPartPath).     writer.open(fs, inProgressPath).     isWriterOpen = true. }
false;private;1;3;;private Path getPendingPathFor(Path path) {     return new Path(path.getParent(), pendingPrefix + path.getName()).suffix(pendingSuffix). }
false;private;1;3;;private Path getInProgressPathFor(Path path) {     return new Path(path.getParent(), inProgressPrefix + path.getName()).suffix(inProgressSuffix). }
false;private;1;3;;private Path getValidLengthPathFor(Path path) {     return new Path(path.getParent(), validLengthPrefix + path.getName()).suffix(validLengthSuffix). }
true;private;0;14;/**  * Closes the current part file.  *  * <p>This moves the current in-progress part file to a pending file and adds it to the list  * of pending files in our bucket state.  */ ;/**  * Closes the current part file.  *  * <p>This moves the current in-progress part file to a pending file and adds it to the list  * of pending files in our bucket state.  */ private void closeCurrentPartFile() throws Exception {     if (isWriterOpen) {         writer.close().         isWriterOpen = false.     }     if (currentPartPath != null) {         Path inProgressPath = getInProgressPathFor(currentPartPath).         Path pendingPath = getPendingPathFor(currentPartPath).         fs.rename(inProgressPath, pendingPath).         LOG.debug("Moving in-progress bucket {} to pending file {}", inProgressPath, pendingPath).         this.bucketState.pendingFiles.add(currentPartPath.toString()).     } }
true;private;1;44;/**  * Gets the truncate() call using reflection.  *  * <p><b>NOTE: </b>This code comes from Flume  */ ;/**  * Gets the truncate() call using reflection.  *  * <p><b>NOTE: </b>This code comes from Flume  */ private Method reflectTruncate(FileSystem fs) {     Method m = null.     if (fs != null) {         Class<?> fsClass = fs.getClass().         try {             m = fsClass.getMethod("truncate", Path.class, long.class).         } catch (NoSuchMethodException ex) {             LOG.debug("Truncate not found. Will write a file with suffix '{}' " + " and prefix '{}' to specify how many bytes in a bucket are valid.", validLengthSuffix, validLengthPrefix).             return null.         }         // verify that truncate actually works         Path testPath = new Path(basePath, UUID.randomUUID().toString()).         try {             try (FSDataOutputStream outputStream = fs.create(testPath)) {                 outputStream.writeUTF("hello").             } catch (IOException e) {                 LOG.error("Could not create file for checking if truncate works.", e).                 throw new RuntimeException("Could not create file for checking if truncate works. " + "You can disable support for truncate() completely via " + "BucketingSink.setUseTruncate(false).", e).             }             try {                 m.invoke(fs, testPath, 2).             } catch (IllegalAccessException | InvocationTargetException e) {                 LOG.debug("Truncate is not supported.", e).                 m = null.             }         } finally {             try {                 fs.delete(testPath, false).             } catch (IOException e) {                 LOG.error("Could not delete truncate test file.", e).                 throw new RuntimeException("Could not delete truncate test file. " + "You can disable support for truncate() completely via " + "BucketingSink.setUseTruncate(false).", e).             }         }     }     return m. }
false;public;1;27;;@Override public void notifyCheckpointComplete(long checkpointId) throws Exception {     synchronized (bucketState.pendingFilesPerCheckpoint) {         Iterator<Map.Entry<Long, List<String>>> pendingCheckpointsIt = bucketState.pendingFilesPerCheckpoint.entrySet().iterator().         while (pendingCheckpointsIt.hasNext()) {             Map.Entry<Long, List<String>> entry = pendingCheckpointsIt.next().             Long pastCheckpointId = entry.getKey().             if (pastCheckpointId <= checkpointId) {                 LOG.debug("Moving pending files to final location for checkpoint {}", pastCheckpointId).                 // to their final name                 for (String filename : entry.getValue()) {                     Path finalPath = new Path(filename).                     Path pendingPath = getPendingPathFor(finalPath).                     fs.rename(pendingPath, finalPath).                     LOG.debug("Moving pending file {} to final location after complete checkpoint {}.", pendingPath, pastCheckpointId).                 }                 pendingCheckpointsIt.remove().             }         }     } }
false;public;1;24;;@Override public void snapshotState(FunctionSnapshotContext context) throws Exception {     Preconditions.checkNotNull(restoredBucketStates, "The " + getClass().getSimpleName() + " has not been properly initialized.").     int subtaskIdx = getRuntimeContext().getIndexOfThisSubtask().     if (isWriterOpen) {         bucketState.currentFile = currentPartPath.toString().         bucketState.currentFileValidLength = writer.flush().     }     synchronized (bucketState.pendingFilesPerCheckpoint) {         bucketState.pendingFilesPerCheckpoint.put(context.getCheckpointId(), bucketState.pendingFiles).     }     bucketState.pendingFiles = new ArrayList<>().     restoredBucketStates.clear().     restoredBucketStates.add(bucketState).     if (LOG.isDebugEnabled()) {         LOG.debug("{} (taskIdx={}) checkpointed {}.", getClass().getSimpleName(), subtaskIdx, bucketState).     } }
false;private;1;135;;private void handleRestoredBucketState(BucketState bucketState) {     // we can clean all the pending files since they were renamed to     // final files after this checkpoint was successful     // (we re-start from the last **successful** checkpoint)     bucketState.pendingFiles.clear().     if (bucketState.currentFile != null) {         // We were writing to a file when the last checkpoint occurred. This file can either         // be still in-progress or became a pending file at some point after the checkpoint.         // Either way, we have to truncate it back to a valid state (or write a .valid-length         // file that specifies up to which length it is valid) and rename it to the final name         // before starting a new bucket file.         Path partPath = new Path(bucketState.currentFile).         try {             Path partPendingPath = getPendingPathFor(partPath).             Path partInProgressPath = getInProgressPathFor(partPath).             if (fs.exists(partPendingPath)) {                 LOG.debug("In-progress file {} has been moved to pending after checkpoint, moving to final location.", partPath).                 // has been moved to pending in the mean time, rename to final location                 fs.rename(partPendingPath, partPath).             } else if (fs.exists(partInProgressPath)) {                 LOG.debug("In-progress file {} is still in-progress, moving to final location.", partPath).                 // it was still in progress, rename to final path                 fs.rename(partInProgressPath, partPath).             } else if (fs.exists(partPath)) {                 LOG.debug("In-Progress file {} was already moved to final location {}.", bucketState.currentFile, partPath).             } else {                 LOG.debug("In-Progress file {} was neither moved to pending nor is still in progress. Possibly, " + "it was moved to final location by a previous snapshot restore", bucketState.currentFile).             }             if (this.refTruncate == null) {                 this.refTruncate = reflectTruncate(fs).             }             // truncate it or write a ".valid-length" file to specify up to which point it is valid             if (refTruncate != null) {                 LOG.debug("Truncating {} to valid length {}", partPath, bucketState.currentFileValidLength).                 // recovering, after all ...                 if (fs instanceof DistributedFileSystem) {                     DistributedFileSystem dfs = (DistributedFileSystem) fs.                     LOG.debug("Trying to recover file lease {}", partPath).                     dfs.recoverLease(partPath).                     boolean isclosed = dfs.isFileClosed(partPath).                     StopWatch sw = new StopWatch().                     sw.start().                     while (!isclosed) {                         if (sw.getTime() > asyncTimeout) {                             break.                         }                         try {                             Thread.sleep(500).                         } catch (InterruptedException e1) {                         // ignore it                         }                         isclosed = dfs.isFileClosed(partPath).                     }                 }                 Boolean truncated = (Boolean) refTruncate.invoke(fs, partPath, bucketState.currentFileValidLength).                 if (!truncated) {                     LOG.debug("Truncate did not immediately complete for {}, waiting...", partPath).                     // we must wait for the asynchronous truncate operation to complete                     StopWatch sw = new StopWatch().                     sw.start().                     long newLen = fs.getFileStatus(partPath).getLen().                     while (newLen != bucketState.currentFileValidLength) {                         if (sw.getTime() > asyncTimeout) {                             break.                         }                         try {                             Thread.sleep(500).                         } catch (InterruptedException e1) {                         // ignore it                         }                         newLen = fs.getFileStatus(partPath).getLen().                     }                     if (newLen != bucketState.currentFileValidLength) {                         throw new RuntimeException("Truncate did not truncate to right length. Should be " + bucketState.currentFileValidLength + " is " + newLen + ".").                     }                 }             } else {                 Path validLengthFilePath = getValidLengthPathFor(partPath).                 if (!fs.exists(validLengthFilePath) && fs.exists(partPath)) {                     LOG.debug("Writing valid-length file for {} to specify valid length {}", partPath, bucketState.currentFileValidLength).                     try (FSDataOutputStream lengthFileOut = fs.create(validLengthFilePath)) {                         lengthFileOut.writeUTF(Long.toString(bucketState.currentFileValidLength)).                     }                 }             }             // invalidate in the state object             bucketState.currentFile = null.             bucketState.currentFileValidLength = -1.             isWriterOpen = false.         } catch (IOException e) {             LOG.error("Error while restoring RollingSink state.", e).             throw new RuntimeException("Error while restoring RollingSink state.", e).         } catch (InvocationTargetException | IllegalAccessException e) {             LOG.error("Could not invoke truncate.", e).             throw new RuntimeException("Could not invoke truncate.", e).         }     }     // Move files that are confirmed by a checkpoint but did not get moved to final location     // because the checkpoint notification did not happen before a failure     Set<Long> pastCheckpointIds = bucketState.pendingFilesPerCheckpoint.keySet().     LOG.debug("Moving pending files to final location on restore.").     for (Long pastCheckpointId : pastCheckpointIds) {         // to their final name         for (String filename : bucketState.pendingFilesPerCheckpoint.get(pastCheckpointId)) {             Path finalPath = new Path(filename).             Path pendingPath = getPendingPathFor(finalPath).             try {                 if (fs.exists(pendingPath)) {                     LOG.debug("(RESTORE) Moving pending file {} to final location after complete checkpoint {}.", pendingPath, pastCheckpointId).                     fs.rename(pendingPath, finalPath).                 }             } catch (IOException e) {                 LOG.error("(RESTORE) Error while renaming pending file {} to final path {}: {}", pendingPath, finalPath, e).                 throw new RuntimeException("Error while renaming pending file " + pendingPath + " to final path " + finalPath, e).             }         }     }     synchronized (bucketState.pendingFilesPerCheckpoint) {         bucketState.pendingFilesPerCheckpoint.clear().     } }
true;public;1;4;/**  * Sets the maximum bucket size in bytes.  *  * <p>When a bucket part file becomes larger than this size a new bucket part file is started and  * the old one is closed. The name of the bucket files depends on the {@link Bucketer}.  *  * @param batchSize The bucket part file size in bytes.  */ ;// -------------------------------------------------------------------------------------------- // Setters for User configuration values // -------------------------------------------------------------------------------------------- /**  * Sets the maximum bucket size in bytes.  *  * <p>When a bucket part file becomes larger than this size a new bucket part file is started and  * the old one is closed. The name of the bucket files depends on the {@link Bucketer}.  *  * @param batchSize The bucket part file size in bytes.  */ public RollingSink<T> setBatchSize(long batchSize) {     this.batchSize = batchSize.     return this. }
true;public;1;4;/**  * Sets the {@link Bucketer} to use for determining the bucket files to write to.  *  * @param bucketer The bucketer to use.  */ ;/**  * Sets the {@link Bucketer} to use for determining the bucket files to write to.  *  * @param bucketer The bucketer to use.  */ public RollingSink<T> setBucketer(Bucketer bucketer) {     this.bucketer = bucketer.     return this. }
true;public;1;4;/**  * Sets the {@link Writer} to be used for writing the incoming elements to bucket files.  *  * @param writer The {@code Writer} to use.  */ ;/**  * Sets the {@link Writer} to be used for writing the incoming elements to bucket files.  *  * @param writer The {@code Writer} to use.  */ public RollingSink<T> setWriter(Writer<T> writer) {     this.writerTemplate = writer.     return this. }
true;public;1;4;/**  * Sets the suffix of in-progress part files. The default is {@code "in-progress"}.  */ ;/**  * Sets the suffix of in-progress part files. The default is {@code "in-progress"}.  */ public RollingSink<T> setInProgressSuffix(String inProgressSuffix) {     this.inProgressSuffix = inProgressSuffix.     return this. }
true;public;1;4;/**  * Sets the prefix of in-progress part files. The default is {@code "_"}.  */ ;/**  * Sets the prefix of in-progress part files. The default is {@code "_"}.  */ public RollingSink<T> setInProgressPrefix(String inProgressPrefix) {     this.inProgressPrefix = inProgressPrefix.     return this. }
true;public;1;4;/**  * Sets the suffix of pending part files. The default is {@code ".pending"}.  */ ;/**  * Sets the suffix of pending part files. The default is {@code ".pending"}.  */ public RollingSink<T> setPendingSuffix(String pendingSuffix) {     this.pendingSuffix = pendingSuffix.     return this. }
true;public;1;4;/**  * Sets the prefix of pending part files. The default is {@code "_"}.  */ ;/**  * Sets the prefix of pending part files. The default is {@code "_"}.  */ public RollingSink<T> setPendingPrefix(String pendingPrefix) {     this.pendingPrefix = pendingPrefix.     return this. }
true;public;1;4;/**  * Sets the suffix of valid-length files. The default is {@code ".valid-length"}.  */ ;/**  * Sets the suffix of valid-length files. The default is {@code ".valid-length"}.  */ public RollingSink<T> setValidLengthSuffix(String validLengthSuffix) {     this.validLengthSuffix = validLengthSuffix.     return this. }
true;public;1;4;/**  * Sets the prefix of valid-length files. The default is {@code "_"}.  */ ;/**  * Sets the prefix of valid-length files. The default is {@code "_"}.  */ public RollingSink<T> setValidLengthPrefix(String validLengthPrefix) {     this.validLengthPrefix = validLengthPrefix.     return this. }
true;public;1;4;/**  * Sets the prefix of part files.  The default is {@code "part"}.  */ ;/**  * Sets the prefix of part files.  The default is {@code "part"}.  */ public RollingSink<T> setPartPrefix(String partPrefix) {     this.partPrefix = partPrefix.     return this. }
true;public;0;4;/**  * Disable cleanup of leftover in-progress/pending files when the sink is opened.  *  * <p>This should only be disabled if using the sink without checkpoints, to not remove  * the files already in the directory.  *  * @deprecated This option is deprecated and remains only for backwards compatibility.  * We do not clean up lingering files anymore.  */ ;/**  * Disable cleanup of leftover in-progress/pending files when the sink is opened.  *  * <p>This should only be disabled if using the sink without checkpoints, to not remove  * the files already in the directory.  *  * @deprecated This option is deprecated and remains only for backwards compatibility.  * We do not clean up lingering files anymore.  */ @Deprecated public RollingSink<T> disableCleanupOnOpen() {     return this. }
true;public;1;4;/**  * Sets the default timeout for asynchronous operations such as recoverLease and truncate.  *  * @param timeout The timeout, in milliseconds.  */ ;/**  * Sets the default timeout for asynchronous operations such as recoverLease and truncate.  *  * @param timeout The timeout, in milliseconds.  */ public RollingSink<T> setAsyncTimeout(long timeout) {     this.asyncTimeout = timeout.     return this. }
false;public;0;8;;@Override public String toString() {     return "In-progress=" + currentFile + " validLength=" + currentFileValidLength + " pendingForNextCheckpoint=" + pendingFiles + " pendingForPrevCheckpoints=" + pendingFilesPerCheckpoint. }
