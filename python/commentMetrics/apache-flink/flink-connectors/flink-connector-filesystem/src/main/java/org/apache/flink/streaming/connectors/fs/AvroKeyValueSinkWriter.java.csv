commented;modifiers;parameterAmount;loc;comment;code
false;private;0;13;;private void validateProperties() {     String keySchemaString = properties.get(CONF_OUTPUT_KEY_SCHEMA).     if (keySchemaString == null) {         throw new IllegalStateException("No key schema provided, set '" + CONF_OUTPUT_KEY_SCHEMA + "' property").     }     // verifying that schema valid     Schema.parse(keySchemaString).     String valueSchemaString = properties.get(CONF_OUTPUT_VALUE_SCHEMA).     if (valueSchemaString == null) {         throw new IllegalStateException("No value schema provided, set '" + CONF_OUTPUT_VALUE_SCHEMA + "' property").     }     // verifying that schema valid     Schema.parse(valueSchemaString). }
false;private;3;7;;private boolean getBoolean(Map<String, String> conf, String key, boolean def) {     String value = conf.get(key).     if (value == null) {         return def.     }     return Boolean.parseBoolean(value). }
false;private;3;7;;private int getInt(Map<String, String> conf, String key, int def) {     String value = conf.get(key).     if (value == null) {         return def.     }     return Integer.parseInt(value). }
true;private;1;17;// this derived from AvroOutputFormatBase.getCompressionCodec(..) ;// this derived from AvroOutputFormatBase.getCompressionCodec(..) private CodecFactory getCompressionCodec(Map<String, String> conf) {     if (getBoolean(conf, CONF_COMPRESS, false)) {         int deflateLevel = getInt(conf, CONF_DEFLATE_LEVEL, CodecFactory.DEFAULT_DEFLATE_LEVEL).         int xzLevel = getInt(conf, CONF_XZ_LEVEL, CodecFactory.DEFAULT_XZ_LEVEL).         String outputCodec = conf.get(CONF_COMPRESS_CODEC).         if (DataFileConstants.DEFLATE_CODEC.equals(outputCodec)) {             return CodecFactory.deflateCodec(deflateLevel).         } else if (DataFileConstants.XZ_CODEC.equals(outputCodec)) {             return CodecFactory.xzCodec(xzLevel).         } else {             return CodecFactory.fromString(outputCodec).         }     }     return CodecFactory.nullCodec(). }
false;public;2;20;;@Override @SuppressWarnings("deprecation") public void open(FileSystem fs, Path path) throws IOException {     super.open(fs, path).     try {         CodecFactory compressionCodec = getCompressionCodec(properties).         Schema keySchema = Schema.parse(properties.get(CONF_OUTPUT_KEY_SCHEMA)).         Schema valueSchema = Schema.parse(properties.get(CONF_OUTPUT_VALUE_SCHEMA)).         keyValueWriter = new AvroKeyValueWriter<K, V>(keySchema, valueSchema, compressionCodec, getStream()).     } finally {         if (keyValueWriter == null) {             close().         }     } }
false;public;0;9;;@Override public void close() throws IOException {     if (keyValueWriter != null) {         keyValueWriter.close().     } else {         // need to make sure we close this if we never created the Key/Value Writer.         super.close().     } }
false;public;0;7;;@Override public long flush() throws IOException {     if (keyValueWriter != null) {         keyValueWriter.sync().     }     return super.flush(). }
false;public;1;5;;@Override public void write(Tuple2<K, V> element) throws IOException {     // Throws if the stream is not open     getStream().     keyValueWriter.write(element.f0, element.f1). }
false;public;2;12;;@Override public void setInputType(TypeInformation<?> type, ExecutionConfig executionConfig) {     if (!type.isTupleType()) {         throw new IllegalArgumentException("Input TypeInformation is not a tuple type.").     }     TupleTypeInfoBase<?> tupleType = (TupleTypeInfoBase<?>) type.     if (tupleType.getArity() != 2) {         throw new IllegalArgumentException("Input TypeInformation must be a Tuple2 type.").     } }
false;public;0;4;;@Override public AvroKeyValueSinkWriter<K, V> duplicate() {     return new AvroKeyValueSinkWriter<>(this). }
false;;2;5;;void write(K key, V value) throws IOException {     mOutputRecord.setKey(key).     mOutputRecord.setValue(value).     mAvroFileWriter.append(mOutputRecord.get()). }
false;;0;3;;void close() throws IOException {     mAvroFileWriter.close(). }
false;;0;3;;long sync() throws IOException {     return mAvroFileWriter.sync(). }
false;public;0;3;;public GenericRecord get() {     return mKeyValueRecord. }
false;public;1;3;;public void setKey(K key) {     mKeyValueRecord.put(KEY_FIELD, key). }
false;public;1;3;;public void setValue(V value) {     mKeyValueRecord.put(VALUE_FIELD, value). }
false;public;0;4;;@SuppressWarnings("unchecked") public K getKey() {     return (K) mKeyValueRecord.get(KEY_FIELD). }
false;public;0;4;;@SuppressWarnings("unchecked") public V getValue() {     return (V) mKeyValueRecord.get(VALUE_FIELD). }
true;public,static;2;8;/**  * Creates a KeyValuePair generic record schema.  *  * @return A schema for a generic record with two fields: 'key' and  *         'value'.  */ ;/**  * Creates a KeyValuePair generic record schema.  *  * @return A schema for a generic record with two fields: 'key' and  *         'value'.  */ public static Schema getSchema(Schema keySchema, Schema valueSchema) {     Schema schema = Schema.createRecord(KEY_VALUE_PAIR_RECORD_NAME, "A key/value pair", KEY_VALUE_PAIR_RECORD_NAMESPACE, false).     schema.setFields(Arrays.asList(new Schema.Field(KEY_FIELD, keySchema, "The key", null), new Schema.Field(VALUE_FIELD, valueSchema, "The value", null))).     return schema. }
false;;0;3;;Map<String, String> getProperties() {     return properties. }
