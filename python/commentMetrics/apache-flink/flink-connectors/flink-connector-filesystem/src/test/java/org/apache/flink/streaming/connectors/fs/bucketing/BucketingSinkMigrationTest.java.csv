# id;timestamp;commentText;codeText;commentWords;codeWords
BucketingSinkMigrationTest -> @Ignore 	@Test 	public void writeSnapshot() throws Exception;1496852938;Manually run this to write binary snapshot data. Remove @Ignore to run.;@Ignore_	@Test_	public void writeSnapshot() throws Exception {__		final File outDir = tempFolder.newFolder()___		BucketingSink<String> sink = new BucketingSink<String>(outDir.getAbsolutePath())_			.setWriter(new StringWriter<String>())_			.setBatchSize(5)_			.setPartPrefix(PART_PREFIX)_			.setInProgressPrefix("")_			.setPendingPrefix("")_			.setValidLengthPrefix("")_			.setInProgressSuffix(IN_PROGRESS_SUFFIX)_			.setPendingSuffix(PENDING_SUFFIX)_			.setValidLengthSuffix(VALID_LENGTH_SUFFIX)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink))___		testHarness.setup()__		testHarness.open()___		testHarness.processElement(new StreamRecord<>("test1", 0L))__		testHarness.processElement(new StreamRecord<>("test2", 0L))___		checkFs(outDir, 1, 1, 0, 0)___		testHarness.processElement(new StreamRecord<>("test3", 0L))__		testHarness.processElement(new StreamRecord<>("test4", 0L))__		testHarness.processElement(new StreamRecord<>("test5", 0L))___		checkFs(outDir, 1, 4, 0, 0)___		OperatorStateHandles snapshot = testHarness.snapshot(0L, 0L)___		OperatorSnapshotUtil.writeStateHandle(snapshot, "src/test/resources/bucketing-sink-migration-test-flink" + flinkGenerateSavepointVersion + "-snapshot")__		testHarness.close()__	};manually,run,this,to,write,binary,snapshot,data,remove,ignore,to,run;ignore,test,public,void,write,snapshot,throws,exception,final,file,out,dir,temp,folder,new,folder,bucketing,sink,string,sink,new,bucketing,sink,string,out,dir,get,absolute,path,set,writer,new,string,writer,string,set,batch,size,5,set,part,prefix,set,in,progress,prefix,set,pending,prefix,set,valid,length,prefix,set,in,progress,suffix,set,pending,suffix,set,valid,length,suffix,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,sink,test,harness,setup,test,harness,open,test,harness,process,element,new,stream,record,test1,0l,test,harness,process,element,new,stream,record,test2,0l,check,fs,out,dir,1,1,0,0,test,harness,process,element,new,stream,record,test3,0l,test,harness,process,element,new,stream,record,test4,0l,test,harness,process,element,new,stream,record,test5,0l,check,fs,out,dir,1,4,0,0,operator,state,handles,snapshot,test,harness,snapshot,0l,0l,operator,snapshot,util,write,state,handle,snapshot,src,test,resources,bucketing,sink,migration,test,flink,flink,generate,savepoint,version,snapshot,test,harness,close
BucketingSinkMigrationTest -> @Ignore 	@Test 	public void writeSnapshot() throws Exception;1498894422;Manually run this to write binary snapshot data. Remove @Ignore to run.;@Ignore_	@Test_	public void writeSnapshot() throws Exception {__		final File outDir = tempFolder.newFolder()___		BucketingSink<String> sink = new BucketingSink<String>(outDir.getAbsolutePath())_			.setWriter(new StringWriter<String>())_			.setBatchSize(5)_			.setPartPrefix(PART_PREFIX)_			.setInProgressPrefix("")_			.setPendingPrefix("")_			.setValidLengthPrefix("")_			.setInProgressSuffix(IN_PROGRESS_SUFFIX)_			.setPendingSuffix(PENDING_SUFFIX)_			.setValidLengthSuffix(VALID_LENGTH_SUFFIX)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink))___		testHarness.setup()__		testHarness.open()___		testHarness.processElement(new StreamRecord<>("test1", 0L))__		testHarness.processElement(new StreamRecord<>("test2", 0L))___		checkFs(outDir, 1, 1, 0, 0)___		testHarness.processElement(new StreamRecord<>("test3", 0L))__		testHarness.processElement(new StreamRecord<>("test4", 0L))__		testHarness.processElement(new StreamRecord<>("test5", 0L))___		checkFs(outDir, 1, 4, 0, 0)___		OperatorStateHandles snapshot = testHarness.snapshot(0L, 0L)___		OperatorSnapshotUtil.writeStateHandle(snapshot, "src/test/resources/bucketing-sink-migration-test-flink" + flinkGenerateSavepointVersion + "-snapshot")__		testHarness.close()__	};manually,run,this,to,write,binary,snapshot,data,remove,ignore,to,run;ignore,test,public,void,write,snapshot,throws,exception,final,file,out,dir,temp,folder,new,folder,bucketing,sink,string,sink,new,bucketing,sink,string,out,dir,get,absolute,path,set,writer,new,string,writer,string,set,batch,size,5,set,part,prefix,set,in,progress,prefix,set,pending,prefix,set,valid,length,prefix,set,in,progress,suffix,set,pending,suffix,set,valid,length,suffix,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,sink,test,harness,setup,test,harness,open,test,harness,process,element,new,stream,record,test1,0l,test,harness,process,element,new,stream,record,test2,0l,check,fs,out,dir,1,1,0,0,test,harness,process,element,new,stream,record,test3,0l,test,harness,process,element,new,stream,record,test4,0l,test,harness,process,element,new,stream,record,test5,0l,check,fs,out,dir,1,4,0,0,operator,state,handles,snapshot,test,harness,snapshot,0l,0l,operator,snapshot,util,write,state,handle,snapshot,src,test,resources,bucketing,sink,migration,test,flink,flink,generate,savepoint,version,snapshot,test,harness,close
BucketingSinkMigrationTest -> @Ignore 	@Test 	public void writeSnapshot() throws Exception;1517943539;Manually run this to write binary snapshot data. Remove @Ignore to run.;@Ignore_	@Test_	public void writeSnapshot() throws Exception {__		final File outDir = tempFolder.newFolder()___		BucketingSink<String> sink = new BucketingSink<String>(outDir.getAbsolutePath())_			.setWriter(new StringWriter<String>())_			.setBatchSize(5)_			.setPartPrefix(PART_PREFIX)_			.setInProgressPrefix("")_			.setPendingPrefix("")_			.setValidLengthPrefix("")_			.setInProgressSuffix(IN_PROGRESS_SUFFIX)_			.setPendingSuffix(PENDING_SUFFIX)_			.setValidLengthSuffix(VALID_LENGTH_SUFFIX)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink))___		testHarness.setup()__		testHarness.open()___		testHarness.processElement(new StreamRecord<>("test1", 0L))__		testHarness.processElement(new StreamRecord<>("test2", 0L))___		checkFs(outDir, 1, 1, 0, 0)___		testHarness.processElement(new StreamRecord<>("test3", 0L))__		testHarness.processElement(new StreamRecord<>("test4", 0L))__		testHarness.processElement(new StreamRecord<>("test5", 0L))___		checkFs(outDir, 1, 4, 0, 0)___		OperatorStateHandles snapshot = testHarness.snapshot(0L, 0L)___		OperatorSnapshotUtil.writeStateHandle(snapshot, "src/test/resources/bucketing-sink-migration-test-flink" + flinkGenerateSavepointVersion + "-snapshot")__		testHarness.close()__	};manually,run,this,to,write,binary,snapshot,data,remove,ignore,to,run;ignore,test,public,void,write,snapshot,throws,exception,final,file,out,dir,temp,folder,new,folder,bucketing,sink,string,sink,new,bucketing,sink,string,out,dir,get,absolute,path,set,writer,new,string,writer,string,set,batch,size,5,set,part,prefix,set,in,progress,prefix,set,pending,prefix,set,valid,length,prefix,set,in,progress,suffix,set,pending,suffix,set,valid,length,suffix,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,sink,test,harness,setup,test,harness,open,test,harness,process,element,new,stream,record,test1,0l,test,harness,process,element,new,stream,record,test2,0l,check,fs,out,dir,1,1,0,0,test,harness,process,element,new,stream,record,test3,0l,test,harness,process,element,new,stream,record,test4,0l,test,harness,process,element,new,stream,record,test5,0l,check,fs,out,dir,1,4,0,0,operator,state,handles,snapshot,test,harness,snapshot,0l,0l,operator,snapshot,util,write,state,handle,snapshot,src,test,resources,bucketing,sink,migration,test,flink,flink,generate,savepoint,version,snapshot,test,harness,close
BucketingSinkMigrationTest -> @Ignore 	@Test 	public void writeSnapshot() throws Exception;1519567828;Manually run this to write binary snapshot data. Remove @Ignore to run.;@Ignore_	@Test_	public void writeSnapshot() throws Exception {__		final File outDir = tempFolder.newFolder()___		BucketingSink<String> sink = new BucketingSink<String>(outDir.getAbsolutePath())_			.setWriter(new StringWriter<String>())_			.setBatchSize(5)_			.setPartPrefix(PART_PREFIX)_			.setInProgressPrefix("")_			.setPendingPrefix("")_			.setValidLengthPrefix("")_			.setInProgressSuffix(IN_PROGRESS_SUFFIX)_			.setPendingSuffix(PENDING_SUFFIX)_			.setValidLengthSuffix(VALID_LENGTH_SUFFIX)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink))___		testHarness.setup()__		testHarness.open()___		testHarness.processElement(new StreamRecord<>("test1", 0L))__		testHarness.processElement(new StreamRecord<>("test2", 0L))___		checkFs(outDir, 1, 1, 0, 0)___		testHarness.processElement(new StreamRecord<>("test3", 0L))__		testHarness.processElement(new StreamRecord<>("test4", 0L))__		testHarness.processElement(new StreamRecord<>("test5", 0L))___		checkFs(outDir, 1, 4, 0, 0)___		OperatorSubtaskState snapshot = testHarness.snapshot(0L, 0L)___		OperatorSnapshotUtil.writeStateHandle(snapshot, "src/test/resources/bucketing-sink-migration-test-flink" + flinkGenerateSavepointVersion + "-snapshot")__		testHarness.close()__	};manually,run,this,to,write,binary,snapshot,data,remove,ignore,to,run;ignore,test,public,void,write,snapshot,throws,exception,final,file,out,dir,temp,folder,new,folder,bucketing,sink,string,sink,new,bucketing,sink,string,out,dir,get,absolute,path,set,writer,new,string,writer,string,set,batch,size,5,set,part,prefix,set,in,progress,prefix,set,pending,prefix,set,valid,length,prefix,set,in,progress,suffix,set,pending,suffix,set,valid,length,suffix,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,sink,test,harness,setup,test,harness,open,test,harness,process,element,new,stream,record,test1,0l,test,harness,process,element,new,stream,record,test2,0l,check,fs,out,dir,1,1,0,0,test,harness,process,element,new,stream,record,test3,0l,test,harness,process,element,new,stream,record,test4,0l,test,harness,process,element,new,stream,record,test5,0l,check,fs,out,dir,1,4,0,0,operator,subtask,state,snapshot,test,harness,snapshot,0l,0l,operator,snapshot,util,write,state,handle,snapshot,src,test,resources,bucketing,sink,migration,test,flink,flink,generate,savepoint,version,snapshot,test,harness,close
BucketingSinkMigrationTest -> @Ignore 	@Test 	public void writeSnapshot() throws Exception;1524138809;Manually run this to write binary snapshot data. Remove @Ignore to run.;@Ignore_	@Test_	public void writeSnapshot() throws Exception {__		final File outDir = tempFolder.newFolder()___		BucketingSink<String> sink = new BucketingSink<String>(outDir.getAbsolutePath())_			.setWriter(new StringWriter<String>())_			.setBatchSize(5)_			.setPartPrefix(PART_PREFIX)_			.setInProgressPrefix("")_			.setPendingPrefix("")_			.setValidLengthPrefix("")_			.setInProgressSuffix(IN_PROGRESS_SUFFIX)_			.setPendingSuffix(PENDING_SUFFIX)_			.setValidLengthSuffix(VALID_LENGTH_SUFFIX)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink))___		testHarness.setup()__		testHarness.open()___		testHarness.processElement(new StreamRecord<>("test1", 0L))__		testHarness.processElement(new StreamRecord<>("test2", 0L))___		checkLocalFs(outDir, 1, 1, 0, 0)___		testHarness.processElement(new StreamRecord<>("test3", 0L))__		testHarness.processElement(new StreamRecord<>("test4", 0L))__		testHarness.processElement(new StreamRecord<>("test5", 0L))___		checkLocalFs(outDir, 1, 4, 0, 0)___		OperatorSubtaskState snapshot = testHarness.snapshot(0L, 0L)___		OperatorSnapshotUtil.writeStateHandle(snapshot, "src/test/resources/bucketing-sink-migration-test-flink" + flinkGenerateSavepointVersion + "-snapshot")__		testHarness.close()__	};manually,run,this,to,write,binary,snapshot,data,remove,ignore,to,run;ignore,test,public,void,write,snapshot,throws,exception,final,file,out,dir,temp,folder,new,folder,bucketing,sink,string,sink,new,bucketing,sink,string,out,dir,get,absolute,path,set,writer,new,string,writer,string,set,batch,size,5,set,part,prefix,set,in,progress,prefix,set,pending,prefix,set,valid,length,prefix,set,in,progress,suffix,set,pending,suffix,set,valid,length,suffix,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,sink,test,harness,setup,test,harness,open,test,harness,process,element,new,stream,record,test1,0l,test,harness,process,element,new,stream,record,test2,0l,check,local,fs,out,dir,1,1,0,0,test,harness,process,element,new,stream,record,test3,0l,test,harness,process,element,new,stream,record,test4,0l,test,harness,process,element,new,stream,record,test5,0l,check,local,fs,out,dir,1,4,0,0,operator,subtask,state,snapshot,test,harness,snapshot,0l,0l,operator,snapshot,util,write,state,handle,snapshot,src,test,resources,bucketing,sink,migration,test,flink,flink,generate,savepoint,version,snapshot,test,harness,close
BucketingSinkMigrationTest -> @Ignore 	@Test 	public void writeSnapshot() throws Exception;1534233725;Manually run this to write binary snapshot data. Remove @Ignore to run.;@Ignore_	@Test_	public void writeSnapshot() throws Exception {__		final File outDir = tempFolder.newFolder()___		BucketingSink<String> sink = new BucketingSink<String>(outDir.getAbsolutePath())_			.setWriter(new StringWriter<String>())_			.setBatchSize(5)_			.setPartPrefix(PART_PREFIX)_			.setInProgressPrefix("")_			.setPendingPrefix("")_			.setValidLengthPrefix("")_			.setInProgressSuffix(IN_PROGRESS_SUFFIX)_			.setPendingSuffix(PENDING_SUFFIX)_			.setValidLengthSuffix(VALID_LENGTH_SUFFIX)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink))___		testHarness.setup()__		testHarness.open()___		testHarness.processElement(new StreamRecord<>("test1", 0L))__		testHarness.processElement(new StreamRecord<>("test2", 0L))___		checkLocalFs(outDir, 1, 1, 0, 0)___		testHarness.processElement(new StreamRecord<>("test3", 0L))__		testHarness.processElement(new StreamRecord<>("test4", 0L))__		testHarness.processElement(new StreamRecord<>("test5", 0L))___		checkLocalFs(outDir, 1, 4, 0, 0)___		OperatorSubtaskState snapshot = testHarness.snapshot(0L, 0L)___		OperatorSnapshotUtil.writeStateHandle(snapshot, "src/test/resources/bucketing-sink-migration-test-flink" + flinkGenerateSavepointVersion + "-snapshot")__		testHarness.close()__	};manually,run,this,to,write,binary,snapshot,data,remove,ignore,to,run;ignore,test,public,void,write,snapshot,throws,exception,final,file,out,dir,temp,folder,new,folder,bucketing,sink,string,sink,new,bucketing,sink,string,out,dir,get,absolute,path,set,writer,new,string,writer,string,set,batch,size,5,set,part,prefix,set,in,progress,prefix,set,pending,prefix,set,valid,length,prefix,set,in,progress,suffix,set,pending,suffix,set,valid,length,suffix,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,sink,test,harness,setup,test,harness,open,test,harness,process,element,new,stream,record,test1,0l,test,harness,process,element,new,stream,record,test2,0l,check,local,fs,out,dir,1,1,0,0,test,harness,process,element,new,stream,record,test3,0l,test,harness,process,element,new,stream,record,test4,0l,test,harness,process,element,new,stream,record,test5,0l,check,local,fs,out,dir,1,4,0,0,operator,subtask,state,snapshot,test,harness,snapshot,0l,0l,operator,snapshot,util,write,state,handle,snapshot,src,test,resources,bucketing,sink,migration,test,flink,flink,generate,savepoint,version,snapshot,test,harness,close
BucketingSinkMigrationTest -> @Ignore 	@Test 	public void writeSnapshot() throws Exception;1534779482;Manually run this to write binary snapshot data. Remove @Ignore to run.;@Ignore_	@Test_	public void writeSnapshot() throws Exception {__		final File outDir = tempFolder.newFolder()___		BucketingSink<String> sink = new BucketingSink<String>(outDir.getAbsolutePath())_			.setWriter(new StringWriter<String>())_			.setBatchSize(5)_			.setPartPrefix(PART_PREFIX)_			.setInProgressPrefix("")_			.setPendingPrefix("")_			.setValidLengthPrefix("")_			.setInProgressSuffix(IN_PROGRESS_SUFFIX)_			.setPendingSuffix(PENDING_SUFFIX)_			.setValidLengthSuffix(VALID_LENGTH_SUFFIX)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink))___		testHarness.setup()__		testHarness.open()___		testHarness.processElement(new StreamRecord<>("test1", 0L))__		testHarness.processElement(new StreamRecord<>("test2", 0L))___		checkLocalFs(outDir, 1, 1, 0, 0)___		testHarness.processElement(new StreamRecord<>("test3", 0L))__		testHarness.processElement(new StreamRecord<>("test4", 0L))__		testHarness.processElement(new StreamRecord<>("test5", 0L))___		checkLocalFs(outDir, 1, 4, 0, 0)___		OperatorSubtaskState snapshot = testHarness.snapshot(0L, 0L)___		OperatorSnapshotUtil.writeStateHandle(snapshot, "src/test/resources/bucketing-sink-migration-test-flink" + flinkGenerateSavepointVersion + "-snapshot")__		testHarness.close()__	};manually,run,this,to,write,binary,snapshot,data,remove,ignore,to,run;ignore,test,public,void,write,snapshot,throws,exception,final,file,out,dir,temp,folder,new,folder,bucketing,sink,string,sink,new,bucketing,sink,string,out,dir,get,absolute,path,set,writer,new,string,writer,string,set,batch,size,5,set,part,prefix,set,in,progress,prefix,set,pending,prefix,set,valid,length,prefix,set,in,progress,suffix,set,pending,suffix,set,valid,length,suffix,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,sink,test,harness,setup,test,harness,open,test,harness,process,element,new,stream,record,test1,0l,test,harness,process,element,new,stream,record,test2,0l,check,local,fs,out,dir,1,1,0,0,test,harness,process,element,new,stream,record,test3,0l,test,harness,process,element,new,stream,record,test4,0l,test,harness,process,element,new,stream,record,test5,0l,check,local,fs,out,dir,1,4,0,0,operator,subtask,state,snapshot,test,harness,snapshot,0l,0l,operator,snapshot,util,write,state,handle,snapshot,src,test,resources,bucketing,sink,migration,test,flink,flink,generate,savepoint,version,snapshot,test,harness,close
BucketingSinkMigrationTest -> @Ignore 	@Test 	public void writeSnapshot() throws Exception;1546427459;Manually run this to write binary snapshot data. Remove @Ignore to run.;@Ignore_	@Test_	public void writeSnapshot() throws Exception {__		final File outDir = tempFolder.newFolder()___		BucketingSink<String> sink = new BucketingSink<String>(outDir.getAbsolutePath())_			.setWriter(new StringWriter<String>())_			.setBatchSize(5)_			.setPartPrefix(PART_PREFIX)_			.setInProgressPrefix("")_			.setPendingPrefix("")_			.setValidLengthPrefix("")_			.setInProgressSuffix(IN_PROGRESS_SUFFIX)_			.setPendingSuffix(PENDING_SUFFIX)_			.setValidLengthSuffix(VALID_LENGTH_SUFFIX)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink))___		testHarness.setup()__		testHarness.open()___		testHarness.processElement(new StreamRecord<>("test1", 0L))__		testHarness.processElement(new StreamRecord<>("test2", 0L))___		checkLocalFs(outDir, 1, 1, 0, 0)___		testHarness.processElement(new StreamRecord<>("test3", 0L))__		testHarness.processElement(new StreamRecord<>("test4", 0L))__		testHarness.processElement(new StreamRecord<>("test5", 0L))___		checkLocalFs(outDir, 1, 4, 0, 0)___		OperatorSubtaskState snapshot = testHarness.snapshot(0L, 0L)___		OperatorSnapshotUtil.writeStateHandle(snapshot, "src/test/resources/bucketing-sink-migration-test-flink" + flinkGenerateSavepointVersion + "-snapshot")__		testHarness.close()__	};manually,run,this,to,write,binary,snapshot,data,remove,ignore,to,run;ignore,test,public,void,write,snapshot,throws,exception,final,file,out,dir,temp,folder,new,folder,bucketing,sink,string,sink,new,bucketing,sink,string,out,dir,get,absolute,path,set,writer,new,string,writer,string,set,batch,size,5,set,part,prefix,set,in,progress,prefix,set,pending,prefix,set,valid,length,prefix,set,in,progress,suffix,set,pending,suffix,set,valid,length,suffix,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,sink,test,harness,setup,test,harness,open,test,harness,process,element,new,stream,record,test1,0l,test,harness,process,element,new,stream,record,test2,0l,check,local,fs,out,dir,1,1,0,0,test,harness,process,element,new,stream,record,test3,0l,test,harness,process,element,new,stream,record,test4,0l,test,harness,process,element,new,stream,record,test5,0l,check,local,fs,out,dir,1,4,0,0,operator,subtask,state,snapshot,test,harness,snapshot,0l,0l,operator,snapshot,util,write,state,handle,snapshot,src,test,resources,bucketing,sink,migration,test,flink,flink,generate,savepoint,version,snapshot,test,harness,close
BucketingSinkMigrationTest -> @Ignore 	@Test 	public void writeSnapshot() throws Exception;1547026204;Manually run this to write binary snapshot data. Remove @Ignore to run.;@Ignore_	@Test_	public void writeSnapshot() throws Exception {__		final File outDir = tempFolder.newFolder()___		BucketingSink<String> sink = new BucketingSink<String>(outDir.getAbsolutePath())_			.setWriter(new StringWriter<String>())_			.setBatchSize(5)_			.setPartPrefix(PART_PREFIX)_			.setInProgressPrefix("")_			.setPendingPrefix("")_			.setValidLengthPrefix("")_			.setInProgressSuffix(IN_PROGRESS_SUFFIX)_			.setPendingSuffix(PENDING_SUFFIX)_			.setValidLengthSuffix(VALID_LENGTH_SUFFIX)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink))___		testHarness.setup()__		testHarness.open()___		testHarness.processElement(new StreamRecord<>("test1", 0L))__		testHarness.processElement(new StreamRecord<>("test2", 0L))___		checkLocalFs(outDir, 1, 1, 0, 0)___		testHarness.processElement(new StreamRecord<>("test3", 0L))__		testHarness.processElement(new StreamRecord<>("test4", 0L))__		testHarness.processElement(new StreamRecord<>("test5", 0L))___		checkLocalFs(outDir, 1, 4, 0, 0)___		OperatorSubtaskState snapshot = testHarness.snapshot(0L, 0L)___		OperatorSnapshotUtil.writeStateHandle(snapshot, "src/test/resources/bucketing-sink-migration-test-flink" + flinkGenerateSavepointVersion + "-snapshot")__		testHarness.close()__	};manually,run,this,to,write,binary,snapshot,data,remove,ignore,to,run;ignore,test,public,void,write,snapshot,throws,exception,final,file,out,dir,temp,folder,new,folder,bucketing,sink,string,sink,new,bucketing,sink,string,out,dir,get,absolute,path,set,writer,new,string,writer,string,set,batch,size,5,set,part,prefix,set,in,progress,prefix,set,pending,prefix,set,valid,length,prefix,set,in,progress,suffix,set,pending,suffix,set,valid,length,suffix,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,sink,test,harness,setup,test,harness,open,test,harness,process,element,new,stream,record,test1,0l,test,harness,process,element,new,stream,record,test2,0l,check,local,fs,out,dir,1,1,0,0,test,harness,process,element,new,stream,record,test3,0l,test,harness,process,element,new,stream,record,test4,0l,test,harness,process,element,new,stream,record,test5,0l,check,local,fs,out,dir,1,4,0,0,operator,subtask,state,snapshot,test,harness,snapshot,0l,0l,operator,snapshot,util,write,state,handle,snapshot,src,test,resources,bucketing,sink,migration,test,flink,flink,generate,savepoint,version,snapshot,test,harness,close
BucketingSinkMigrationTest -> @Ignore 	@Test 	public void writeSnapshot() throws Exception;1547725934;Manually run this to write binary snapshot data. Remove @Ignore to run.;@Ignore_	@Test_	public void writeSnapshot() throws Exception {__		final File outDir = tempFolder.newFolder()___		BucketingSink<String> sink = new BucketingSink<String>(outDir.getAbsolutePath())_			.setWriter(new StringWriter<String>())_			.setBatchSize(5)_			.setPartPrefix(PART_PREFIX)_			.setInProgressPrefix("")_			.setPendingPrefix("")_			.setValidLengthPrefix("")_			.setInProgressSuffix(IN_PROGRESS_SUFFIX)_			.setPendingSuffix(PENDING_SUFFIX)_			.setValidLengthSuffix(VALID_LENGTH_SUFFIX)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink))___		testHarness.setup()__		testHarness.open()___		testHarness.processElement(new StreamRecord<>("test1", 0L))__		testHarness.processElement(new StreamRecord<>("test2", 0L))___		checkLocalFs(outDir, 1, 1, 0, 0)___		testHarness.processElement(new StreamRecord<>("test3", 0L))__		testHarness.processElement(new StreamRecord<>("test4", 0L))__		testHarness.processElement(new StreamRecord<>("test5", 0L))___		checkLocalFs(outDir, 1, 4, 0, 0)___		OperatorSubtaskState snapshot = testHarness.snapshot(0L, 0L)___		OperatorSnapshotUtil.writeStateHandle(snapshot, "src/test/resources/bucketing-sink-migration-test-flink" + flinkGenerateSavepointVersion + "-snapshot")__		testHarness.close()__	};manually,run,this,to,write,binary,snapshot,data,remove,ignore,to,run;ignore,test,public,void,write,snapshot,throws,exception,final,file,out,dir,temp,folder,new,folder,bucketing,sink,string,sink,new,bucketing,sink,string,out,dir,get,absolute,path,set,writer,new,string,writer,string,set,batch,size,5,set,part,prefix,set,in,progress,prefix,set,pending,prefix,set,valid,length,prefix,set,in,progress,suffix,set,pending,suffix,set,valid,length,suffix,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,sink,test,harness,setup,test,harness,open,test,harness,process,element,new,stream,record,test1,0l,test,harness,process,element,new,stream,record,test2,0l,check,local,fs,out,dir,1,1,0,0,test,harness,process,element,new,stream,record,test3,0l,test,harness,process,element,new,stream,record,test4,0l,test,harness,process,element,new,stream,record,test5,0l,check,local,fs,out,dir,1,4,0,0,operator,subtask,state,snapshot,test,harness,snapshot,0l,0l,operator,snapshot,util,write,state,handle,snapshot,src,test,resources,bucketing,sink,migration,test,flink,flink,generate,savepoint,version,snapshot,test,harness,close
BucketingSinkMigrationTest -> @Ignore 	@Test 	public void writeSnapshot() throws Exception;1547725946;Manually run this to write binary snapshot data. Remove @Ignore to run.;@Ignore_	@Test_	public void writeSnapshot() throws Exception {__		final File outDir = tempFolder.newFolder()___		BucketingSink<String> sink = new BucketingSink<String>(outDir.getAbsolutePath())_			.setWriter(new StringWriter<String>())_			.setBatchSize(5)_			.setPartPrefix(PART_PREFIX)_			.setInProgressPrefix("")_			.setPendingPrefix("")_			.setValidLengthPrefix("")_			.setInProgressSuffix(IN_PROGRESS_SUFFIX)_			.setPendingSuffix(PENDING_SUFFIX)_			.setValidLengthSuffix(VALID_LENGTH_SUFFIX)___		OneInputStreamOperatorTestHarness<String, Object> testHarness =_			new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink))___		testHarness.setup()__		testHarness.open()___		testHarness.processElement(new StreamRecord<>("test1", 0L))__		testHarness.processElement(new StreamRecord<>("test2", 0L))___		checkLocalFs(outDir, 1, 1, 0, 0)___		testHarness.processElement(new StreamRecord<>("test3", 0L))__		testHarness.processElement(new StreamRecord<>("test4", 0L))__		testHarness.processElement(new StreamRecord<>("test5", 0L))___		checkLocalFs(outDir, 1, 4, 0, 0)___		OperatorSubtaskState snapshot = testHarness.snapshot(0L, 0L)___		OperatorSnapshotUtil.writeStateHandle(snapshot, "src/test/resources/bucketing-sink-migration-test-flink" + flinkGenerateSavepointVersion + "-snapshot")__		testHarness.close()__	};manually,run,this,to,write,binary,snapshot,data,remove,ignore,to,run;ignore,test,public,void,write,snapshot,throws,exception,final,file,out,dir,temp,folder,new,folder,bucketing,sink,string,sink,new,bucketing,sink,string,out,dir,get,absolute,path,set,writer,new,string,writer,string,set,batch,size,5,set,part,prefix,set,in,progress,prefix,set,pending,prefix,set,valid,length,prefix,set,in,progress,suffix,set,pending,suffix,set,valid,length,suffix,one,input,stream,operator,test,harness,string,object,test,harness,new,one,input,stream,operator,test,harness,new,stream,sink,sink,test,harness,setup,test,harness,open,test,harness,process,element,new,stream,record,test1,0l,test,harness,process,element,new,stream,record,test2,0l,check,local,fs,out,dir,1,1,0,0,test,harness,process,element,new,stream,record,test3,0l,test,harness,process,element,new,stream,record,test4,0l,test,harness,process,element,new,stream,record,test5,0l,check,local,fs,out,dir,1,4,0,0,operator,subtask,state,snapshot,test,harness,snapshot,0l,0l,operator,snapshot,util,write,state,handle,snapshot,src,test,resources,bucketing,sink,migration,test,flink,flink,generate,savepoint,version,snapshot,test,harness,close
BucketingSinkMigrationTest -> ValidatingBucketingSink -> @Override 		public void initializeState(FunctionInitializationContext context) throws Exception;1496852938;The actual paths in this depend on the binary checkpoint so it you update this the paths_here have to be updated as well.;@Override_		public void initializeState(FunctionInitializationContext context) throws Exception {_			OperatorStateStore stateStore = context.getOperatorStateStore()___			ListState<State<T>> restoredBucketStates = stateStore.getSerializableListState("bucket-states")___			if (context.isRestored()) {__				for (State<T> states : restoredBucketStates.get()) {_					for (String bucketPath : states.bucketStates.keySet()) {_						BucketState state = states.getBucketState(new Path(bucketPath))__						String current = state.currentFile__						long validLength = state.currentFileValidLength___						Assert.assertEquals(expectedBucketFilesPrefix + "4", current)__						Assert.assertEquals(6, validLength)___						List<String> pendingFiles = state.pendingFiles__						assertTrue(pendingFiles.isEmpty())___						final Map<Long, List<String>> pendingFilesPerCheckpoint = state.pendingFilesPerCheckpoint__						Assert.assertEquals(1, pendingFilesPerCheckpoint.size())___						for (Map.Entry<Long, List<String>> entry: pendingFilesPerCheckpoint.entrySet()) {_							long checkpoint = entry.getKey()__							List<String> files = entry.getValue()___							Assert.assertEquals(0L, checkpoint)__							Assert.assertEquals(4, files.size())___							for (int i = 0_ i < 4_ i++) {_								Assert.assertEquals(_										expectedBucketFilesPrefix + i,_										files.get(i))__							}_						}_					}_				}_			}__			initializeCalled = true__			super.initializeState(context)__		};the,actual,paths,in,this,depend,on,the,binary,checkpoint,so,it,you,update,this,the,paths,here,have,to,be,updated,as,well;override,public,void,initialize,state,function,initialization,context,context,throws,exception,operator,state,store,state,store,context,get,operator,state,store,list,state,state,t,restored,bucket,states,state,store,get,serializable,list,state,bucket,states,if,context,is,restored,for,state,t,states,restored,bucket,states,get,for,string,bucket,path,states,bucket,states,key,set,bucket,state,state,states,get,bucket,state,new,path,bucket,path,string,current,state,current,file,long,valid,length,state,current,file,valid,length,assert,assert,equals,expected,bucket,files,prefix,4,current,assert,assert,equals,6,valid,length,list,string,pending,files,state,pending,files,assert,true,pending,files,is,empty,final,map,long,list,string,pending,files,per,checkpoint,state,pending,files,per,checkpoint,assert,assert,equals,1,pending,files,per,checkpoint,size,for,map,entry,long,list,string,entry,pending,files,per,checkpoint,entry,set,long,checkpoint,entry,get,key,list,string,files,entry,get,value,assert,assert,equals,0l,checkpoint,assert,assert,equals,4,files,size,for,int,i,0,i,4,i,assert,assert,equals,expected,bucket,files,prefix,i,files,get,i,initialize,called,true,super,initialize,state,context
BucketingSinkMigrationTest -> ValidatingBucketingSink -> @Override 		public void initializeState(FunctionInitializationContext context) throws Exception;1498894422;The actual paths in this depend on the binary checkpoint so it you update this the paths_here have to be updated as well.;@Override_		public void initializeState(FunctionInitializationContext context) throws Exception {_			OperatorStateStore stateStore = context.getOperatorStateStore()___			ListState<State<T>> restoredBucketStates = stateStore.getSerializableListState("bucket-states")___			if (context.isRestored()) {__				for (State<T> states : restoredBucketStates.get()) {_					for (String bucketPath : states.bucketStates.keySet()) {_						BucketState state = states.getBucketState(new Path(bucketPath))__						String current = state.currentFile__						long validLength = state.currentFileValidLength___						Assert.assertEquals(expectedBucketFilesPrefix + "4", current)__						Assert.assertEquals(6, validLength)___						List<String> pendingFiles = state.pendingFiles__						assertTrue(pendingFiles.isEmpty())___						final Map<Long, List<String>> pendingFilesPerCheckpoint = state.pendingFilesPerCheckpoint__						Assert.assertEquals(1, pendingFilesPerCheckpoint.size())___						for (Map.Entry<Long, List<String>> entry: pendingFilesPerCheckpoint.entrySet()) {_							long checkpoint = entry.getKey()__							List<String> files = entry.getValue()___							Assert.assertEquals(0L, checkpoint)__							Assert.assertEquals(4, files.size())___							for (int i = 0_ i < 4_ i++) {_								Assert.assertEquals(_										expectedBucketFilesPrefix + i,_										files.get(i))__							}_						}_					}_				}_			}__			initializeCalled = true__			super.initializeState(context)__		};the,actual,paths,in,this,depend,on,the,binary,checkpoint,so,it,you,update,this,the,paths,here,have,to,be,updated,as,well;override,public,void,initialize,state,function,initialization,context,context,throws,exception,operator,state,store,state,store,context,get,operator,state,store,list,state,state,t,restored,bucket,states,state,store,get,serializable,list,state,bucket,states,if,context,is,restored,for,state,t,states,restored,bucket,states,get,for,string,bucket,path,states,bucket,states,key,set,bucket,state,state,states,get,bucket,state,new,path,bucket,path,string,current,state,current,file,long,valid,length,state,current,file,valid,length,assert,assert,equals,expected,bucket,files,prefix,4,current,assert,assert,equals,6,valid,length,list,string,pending,files,state,pending,files,assert,true,pending,files,is,empty,final,map,long,list,string,pending,files,per,checkpoint,state,pending,files,per,checkpoint,assert,assert,equals,1,pending,files,per,checkpoint,size,for,map,entry,long,list,string,entry,pending,files,per,checkpoint,entry,set,long,checkpoint,entry,get,key,list,string,files,entry,get,value,assert,assert,equals,0l,checkpoint,assert,assert,equals,4,files,size,for,int,i,0,i,4,i,assert,assert,equals,expected,bucket,files,prefix,i,files,get,i,initialize,called,true,super,initialize,state,context
BucketingSinkMigrationTest -> ValidatingBucketingSink -> @Override 		public void initializeState(FunctionInitializationContext context) throws Exception;1517943539;The actual paths in this depend on the binary checkpoint so it you update this the paths_here have to be updated as well.;@Override_		public void initializeState(FunctionInitializationContext context) throws Exception {_			OperatorStateStore stateStore = context.getOperatorStateStore()___			ListState<State<T>> restoredBucketStates = stateStore.getSerializableListState("bucket-states")___			if (context.isRestored()) {__				for (State<T> states : restoredBucketStates.get()) {_					for (String bucketPath : states.bucketStates.keySet()) {_						BucketState state = states.getBucketState(new Path(bucketPath))__						String current = state.currentFile__						long validLength = state.currentFileValidLength___						Assert.assertEquals(expectedBucketFilesPrefix + "4", current)__						Assert.assertEquals(6, validLength)___						List<String> pendingFiles = state.pendingFiles__						assertTrue(pendingFiles.isEmpty())___						final Map<Long, List<String>> pendingFilesPerCheckpoint = state.pendingFilesPerCheckpoint__						Assert.assertEquals(1, pendingFilesPerCheckpoint.size())___						for (Map.Entry<Long, List<String>> entry: pendingFilesPerCheckpoint.entrySet()) {_							long checkpoint = entry.getKey()__							List<String> files = entry.getValue()___							Assert.assertEquals(0L, checkpoint)__							Assert.assertEquals(4, files.size())___							for (int i = 0_ i < 4_ i++) {_								Assert.assertEquals(_										expectedBucketFilesPrefix + i,_										files.get(i))__							}_						}_					}_				}_			}__			initializeCalled = true__			super.initializeState(context)__		};the,actual,paths,in,this,depend,on,the,binary,checkpoint,so,it,you,update,this,the,paths,here,have,to,be,updated,as,well;override,public,void,initialize,state,function,initialization,context,context,throws,exception,operator,state,store,state,store,context,get,operator,state,store,list,state,state,t,restored,bucket,states,state,store,get,serializable,list,state,bucket,states,if,context,is,restored,for,state,t,states,restored,bucket,states,get,for,string,bucket,path,states,bucket,states,key,set,bucket,state,state,states,get,bucket,state,new,path,bucket,path,string,current,state,current,file,long,valid,length,state,current,file,valid,length,assert,assert,equals,expected,bucket,files,prefix,4,current,assert,assert,equals,6,valid,length,list,string,pending,files,state,pending,files,assert,true,pending,files,is,empty,final,map,long,list,string,pending,files,per,checkpoint,state,pending,files,per,checkpoint,assert,assert,equals,1,pending,files,per,checkpoint,size,for,map,entry,long,list,string,entry,pending,files,per,checkpoint,entry,set,long,checkpoint,entry,get,key,list,string,files,entry,get,value,assert,assert,equals,0l,checkpoint,assert,assert,equals,4,files,size,for,int,i,0,i,4,i,assert,assert,equals,expected,bucket,files,prefix,i,files,get,i,initialize,called,true,super,initialize,state,context
BucketingSinkMigrationTest -> ValidatingBucketingSink -> @Override 		public void initializeState(FunctionInitializationContext context) throws Exception;1519567828;The actual paths in this depend on the binary checkpoint so it you update this the paths_here have to be updated as well.;@Override_		public void initializeState(FunctionInitializationContext context) throws Exception {_			OperatorStateStore stateStore = context.getOperatorStateStore()___			ListState<State<T>> restoredBucketStates = stateStore.getSerializableListState("bucket-states")___			if (context.isRestored()) {__				for (State<T> states : restoredBucketStates.get()) {_					for (String bucketPath : states.bucketStates.keySet()) {_						BucketState state = states.getBucketState(new Path(bucketPath))__						String current = state.currentFile__						long validLength = state.currentFileValidLength___						Assert.assertEquals(expectedBucketFilesPrefix + "4", current)__						Assert.assertEquals(6, validLength)___						List<String> pendingFiles = state.pendingFiles__						assertTrue(pendingFiles.isEmpty())___						final Map<Long, List<String>> pendingFilesPerCheckpoint = state.pendingFilesPerCheckpoint__						Assert.assertEquals(1, pendingFilesPerCheckpoint.size())___						for (Map.Entry<Long, List<String>> entry: pendingFilesPerCheckpoint.entrySet()) {_							long checkpoint = entry.getKey()__							List<String> files = entry.getValue()___							Assert.assertEquals(0L, checkpoint)__							Assert.assertEquals(4, files.size())___							for (int i = 0_ i < 4_ i++) {_								Assert.assertEquals(_										expectedBucketFilesPrefix + i,_										files.get(i))__							}_						}_					}_				}_			}__			initializeCalled = true__			super.initializeState(context)__		};the,actual,paths,in,this,depend,on,the,binary,checkpoint,so,it,you,update,this,the,paths,here,have,to,be,updated,as,well;override,public,void,initialize,state,function,initialization,context,context,throws,exception,operator,state,store,state,store,context,get,operator,state,store,list,state,state,t,restored,bucket,states,state,store,get,serializable,list,state,bucket,states,if,context,is,restored,for,state,t,states,restored,bucket,states,get,for,string,bucket,path,states,bucket,states,key,set,bucket,state,state,states,get,bucket,state,new,path,bucket,path,string,current,state,current,file,long,valid,length,state,current,file,valid,length,assert,assert,equals,expected,bucket,files,prefix,4,current,assert,assert,equals,6,valid,length,list,string,pending,files,state,pending,files,assert,true,pending,files,is,empty,final,map,long,list,string,pending,files,per,checkpoint,state,pending,files,per,checkpoint,assert,assert,equals,1,pending,files,per,checkpoint,size,for,map,entry,long,list,string,entry,pending,files,per,checkpoint,entry,set,long,checkpoint,entry,get,key,list,string,files,entry,get,value,assert,assert,equals,0l,checkpoint,assert,assert,equals,4,files,size,for,int,i,0,i,4,i,assert,assert,equals,expected,bucket,files,prefix,i,files,get,i,initialize,called,true,super,initialize,state,context
BucketingSinkMigrationTest -> ValidatingBucketingSink -> @Override 		public void initializeState(FunctionInitializationContext context) throws Exception;1524138809;The actual paths in this depend on the binary checkpoint so it you update this the paths_here have to be updated as well.;@Override_		public void initializeState(FunctionInitializationContext context) throws Exception {_			OperatorStateStore stateStore = context.getOperatorStateStore()___			ListState<State<T>> restoredBucketStates = stateStore.getSerializableListState("bucket-states")___			if (context.isRestored()) {__				for (State<T> states : restoredBucketStates.get()) {_					for (String bucketPath : states.bucketStates.keySet()) {_						BucketState state = states.getBucketState(new Path(bucketPath))__						String current = state.currentFile__						long validLength = state.currentFileValidLength___						Assert.assertEquals(expectedBucketFilesPrefix + "4", current)__						Assert.assertEquals(6, validLength)___						List<String> pendingFiles = state.pendingFiles__						assertTrue(pendingFiles.isEmpty())___						final Map<Long, List<String>> pendingFilesPerCheckpoint = state.pendingFilesPerCheckpoint__						Assert.assertEquals(1, pendingFilesPerCheckpoint.size())___						for (Map.Entry<Long, List<String>> entry: pendingFilesPerCheckpoint.entrySet()) {_							long checkpoint = entry.getKey()__							List<String> files = entry.getValue()___							Assert.assertEquals(0L, checkpoint)__							Assert.assertEquals(4, files.size())___							for (int i = 0_ i < 4_ i++) {_								Assert.assertEquals(_										expectedBucketFilesPrefix + i,_										files.get(i))__							}_						}_					}_				}_			}__			initializeCalled = true__			super.initializeState(context)__		};the,actual,paths,in,this,depend,on,the,binary,checkpoint,so,it,you,update,this,the,paths,here,have,to,be,updated,as,well;override,public,void,initialize,state,function,initialization,context,context,throws,exception,operator,state,store,state,store,context,get,operator,state,store,list,state,state,t,restored,bucket,states,state,store,get,serializable,list,state,bucket,states,if,context,is,restored,for,state,t,states,restored,bucket,states,get,for,string,bucket,path,states,bucket,states,key,set,bucket,state,state,states,get,bucket,state,new,path,bucket,path,string,current,state,current,file,long,valid,length,state,current,file,valid,length,assert,assert,equals,expected,bucket,files,prefix,4,current,assert,assert,equals,6,valid,length,list,string,pending,files,state,pending,files,assert,true,pending,files,is,empty,final,map,long,list,string,pending,files,per,checkpoint,state,pending,files,per,checkpoint,assert,assert,equals,1,pending,files,per,checkpoint,size,for,map,entry,long,list,string,entry,pending,files,per,checkpoint,entry,set,long,checkpoint,entry,get,key,list,string,files,entry,get,value,assert,assert,equals,0l,checkpoint,assert,assert,equals,4,files,size,for,int,i,0,i,4,i,assert,assert,equals,expected,bucket,files,prefix,i,files,get,i,initialize,called,true,super,initialize,state,context
BucketingSinkMigrationTest -> ValidatingBucketingSink -> @Override 		public void initializeState(FunctionInitializationContext context) throws Exception;1534233725;The actual paths in this depend on the binary checkpoint so it you update this the paths_here have to be updated as well.;@Override_		public void initializeState(FunctionInitializationContext context) throws Exception {_			OperatorStateStore stateStore = context.getOperatorStateStore()___			ListState<State<T>> restoredBucketStates = stateStore.getSerializableListState("bucket-states")___			if (context.isRestored()) {__				for (State<T> states : restoredBucketStates.get()) {_					for (String bucketPath : states.bucketStates.keySet()) {_						BucketState state = states.getBucketState(new Path(bucketPath))__						String current = state.currentFile__						long validLength = state.currentFileValidLength___						Assert.assertEquals(expectedBucketFilesPrefix + "4", current)__						Assert.assertEquals(6, validLength)___						List<String> pendingFiles = state.pendingFiles__						assertTrue(pendingFiles.isEmpty())___						final Map<Long, List<String>> pendingFilesPerCheckpoint = state.pendingFilesPerCheckpoint__						Assert.assertEquals(1, pendingFilesPerCheckpoint.size())___						for (Map.Entry<Long, List<String>> entry: pendingFilesPerCheckpoint.entrySet()) {_							long checkpoint = entry.getKey()__							List<String> files = entry.getValue()___							Assert.assertEquals(0L, checkpoint)__							Assert.assertEquals(4, files.size())___							for (int i = 0_ i < 4_ i++) {_								Assert.assertEquals(_										expectedBucketFilesPrefix + i,_										files.get(i))__							}_						}_					}_				}_			}__			initializeCalled = true__			super.initializeState(context)__		};the,actual,paths,in,this,depend,on,the,binary,checkpoint,so,it,you,update,this,the,paths,here,have,to,be,updated,as,well;override,public,void,initialize,state,function,initialization,context,context,throws,exception,operator,state,store,state,store,context,get,operator,state,store,list,state,state,t,restored,bucket,states,state,store,get,serializable,list,state,bucket,states,if,context,is,restored,for,state,t,states,restored,bucket,states,get,for,string,bucket,path,states,bucket,states,key,set,bucket,state,state,states,get,bucket,state,new,path,bucket,path,string,current,state,current,file,long,valid,length,state,current,file,valid,length,assert,assert,equals,expected,bucket,files,prefix,4,current,assert,assert,equals,6,valid,length,list,string,pending,files,state,pending,files,assert,true,pending,files,is,empty,final,map,long,list,string,pending,files,per,checkpoint,state,pending,files,per,checkpoint,assert,assert,equals,1,pending,files,per,checkpoint,size,for,map,entry,long,list,string,entry,pending,files,per,checkpoint,entry,set,long,checkpoint,entry,get,key,list,string,files,entry,get,value,assert,assert,equals,0l,checkpoint,assert,assert,equals,4,files,size,for,int,i,0,i,4,i,assert,assert,equals,expected,bucket,files,prefix,i,files,get,i,initialize,called,true,super,initialize,state,context
BucketingSinkMigrationTest -> ValidatingBucketingSink -> @Override 		public void initializeState(FunctionInitializationContext context) throws Exception;1534779482;The actual paths in this depend on the binary checkpoint so it you update this the paths_here have to be updated as well.;@Override_		public void initializeState(FunctionInitializationContext context) throws Exception {_			OperatorStateStore stateStore = context.getOperatorStateStore()___			ListState<State<T>> restoredBucketStates = stateStore.getSerializableListState("bucket-states")___			if (context.isRestored()) {__				for (State<T> states : restoredBucketStates.get()) {_					for (String bucketPath : states.bucketStates.keySet()) {_						BucketState state = states.getBucketState(new Path(bucketPath))__						String current = state.currentFile__						long validLength = state.currentFileValidLength___						Assert.assertEquals(expectedBucketFilesPrefix + "4", current)__						Assert.assertEquals(6, validLength)___						List<String> pendingFiles = state.pendingFiles__						assertTrue(pendingFiles.isEmpty())___						final Map<Long, List<String>> pendingFilesPerCheckpoint = state.pendingFilesPerCheckpoint__						Assert.assertEquals(1, pendingFilesPerCheckpoint.size())___						for (Map.Entry<Long, List<String>> entry: pendingFilesPerCheckpoint.entrySet()) {_							long checkpoint = entry.getKey()__							List<String> files = entry.getValue()___							Assert.assertEquals(0L, checkpoint)__							Assert.assertEquals(4, files.size())___							for (int i = 0_ i < 4_ i++) {_								Assert.assertEquals(_										expectedBucketFilesPrefix + i,_										files.get(i))__							}_						}_					}_				}_			}__			initializeCalled = true__			super.initializeState(context)__		};the,actual,paths,in,this,depend,on,the,binary,checkpoint,so,it,you,update,this,the,paths,here,have,to,be,updated,as,well;override,public,void,initialize,state,function,initialization,context,context,throws,exception,operator,state,store,state,store,context,get,operator,state,store,list,state,state,t,restored,bucket,states,state,store,get,serializable,list,state,bucket,states,if,context,is,restored,for,state,t,states,restored,bucket,states,get,for,string,bucket,path,states,bucket,states,key,set,bucket,state,state,states,get,bucket,state,new,path,bucket,path,string,current,state,current,file,long,valid,length,state,current,file,valid,length,assert,assert,equals,expected,bucket,files,prefix,4,current,assert,assert,equals,6,valid,length,list,string,pending,files,state,pending,files,assert,true,pending,files,is,empty,final,map,long,list,string,pending,files,per,checkpoint,state,pending,files,per,checkpoint,assert,assert,equals,1,pending,files,per,checkpoint,size,for,map,entry,long,list,string,entry,pending,files,per,checkpoint,entry,set,long,checkpoint,entry,get,key,list,string,files,entry,get,value,assert,assert,equals,0l,checkpoint,assert,assert,equals,4,files,size,for,int,i,0,i,4,i,assert,assert,equals,expected,bucket,files,prefix,i,files,get,i,initialize,called,true,super,initialize,state,context
BucketingSinkMigrationTest -> ValidatingBucketingSink -> @Override 		public void initializeState(FunctionInitializationContext context) throws Exception;1546427459;The actual paths in this depend on the binary checkpoint so it you update this the paths_here have to be updated as well.;@Override_		public void initializeState(FunctionInitializationContext context) throws Exception {_			OperatorStateStore stateStore = context.getOperatorStateStore()___			ListState<State<T>> restoredBucketStates = stateStore.getSerializableListState("bucket-states")___			if (context.isRestored()) {__				for (State<T> states : restoredBucketStates.get()) {_					for (String bucketPath : states.bucketStates.keySet()) {_						BucketState state = states.getBucketState(new Path(bucketPath))__						String current = state.currentFile__						long validLength = state.currentFileValidLength___						Assert.assertEquals(expectedBucketFilesPrefix + "4", current)__						Assert.assertEquals(6, validLength)___						List<String> pendingFiles = state.pendingFiles__						assertTrue(pendingFiles.isEmpty())___						final Map<Long, List<String>> pendingFilesPerCheckpoint = state.pendingFilesPerCheckpoint__						Assert.assertEquals(1, pendingFilesPerCheckpoint.size())___						for (Map.Entry<Long, List<String>> entry: pendingFilesPerCheckpoint.entrySet()) {_							long checkpoint = entry.getKey()__							List<String> files = entry.getValue()___							Assert.assertEquals(0L, checkpoint)__							Assert.assertEquals(4, files.size())___							for (int i = 0_ i < 4_ i++) {_								Assert.assertEquals(_										expectedBucketFilesPrefix + i,_										files.get(i))__							}_						}_					}_				}_			}__			initializeCalled = true__			super.initializeState(context)__		};the,actual,paths,in,this,depend,on,the,binary,checkpoint,so,it,you,update,this,the,paths,here,have,to,be,updated,as,well;override,public,void,initialize,state,function,initialization,context,context,throws,exception,operator,state,store,state,store,context,get,operator,state,store,list,state,state,t,restored,bucket,states,state,store,get,serializable,list,state,bucket,states,if,context,is,restored,for,state,t,states,restored,bucket,states,get,for,string,bucket,path,states,bucket,states,key,set,bucket,state,state,states,get,bucket,state,new,path,bucket,path,string,current,state,current,file,long,valid,length,state,current,file,valid,length,assert,assert,equals,expected,bucket,files,prefix,4,current,assert,assert,equals,6,valid,length,list,string,pending,files,state,pending,files,assert,true,pending,files,is,empty,final,map,long,list,string,pending,files,per,checkpoint,state,pending,files,per,checkpoint,assert,assert,equals,1,pending,files,per,checkpoint,size,for,map,entry,long,list,string,entry,pending,files,per,checkpoint,entry,set,long,checkpoint,entry,get,key,list,string,files,entry,get,value,assert,assert,equals,0l,checkpoint,assert,assert,equals,4,files,size,for,int,i,0,i,4,i,assert,assert,equals,expected,bucket,files,prefix,i,files,get,i,initialize,called,true,super,initialize,state,context
BucketingSinkMigrationTest -> ValidatingBucketingSink -> @Override 		public void initializeState(FunctionInitializationContext context) throws Exception;1547026204;The actual paths in this depend on the binary checkpoint so it you update this the paths_here have to be updated as well.;@Override_		public void initializeState(FunctionInitializationContext context) throws Exception {_			OperatorStateStore stateStore = context.getOperatorStateStore()___			ListState<State<T>> restoredBucketStates = stateStore.getSerializableListState("bucket-states")___			if (context.isRestored()) {__				for (State<T> states : restoredBucketStates.get()) {_					for (String bucketPath : states.bucketStates.keySet()) {_						BucketState state = states.getBucketState(new Path(bucketPath))__						String current = state.currentFile__						long validLength = state.currentFileValidLength___						Assert.assertEquals(expectedBucketFilesPrefix + "4", current)__						Assert.assertEquals(6, validLength)___						List<String> pendingFiles = state.pendingFiles__						assertTrue(pendingFiles.isEmpty())___						final Map<Long, List<String>> pendingFilesPerCheckpoint = state.pendingFilesPerCheckpoint__						Assert.assertEquals(1, pendingFilesPerCheckpoint.size())___						for (Map.Entry<Long, List<String>> entry: pendingFilesPerCheckpoint.entrySet()) {_							long checkpoint = entry.getKey()__							List<String> files = entry.getValue()___							Assert.assertEquals(0L, checkpoint)__							Assert.assertEquals(4, files.size())___							for (int i = 0_ i < 4_ i++) {_								Assert.assertEquals(_										expectedBucketFilesPrefix + i,_										files.get(i))__							}_						}_					}_				}_			}__			initializeCalled = true__			super.initializeState(context)__		};the,actual,paths,in,this,depend,on,the,binary,checkpoint,so,it,you,update,this,the,paths,here,have,to,be,updated,as,well;override,public,void,initialize,state,function,initialization,context,context,throws,exception,operator,state,store,state,store,context,get,operator,state,store,list,state,state,t,restored,bucket,states,state,store,get,serializable,list,state,bucket,states,if,context,is,restored,for,state,t,states,restored,bucket,states,get,for,string,bucket,path,states,bucket,states,key,set,bucket,state,state,states,get,bucket,state,new,path,bucket,path,string,current,state,current,file,long,valid,length,state,current,file,valid,length,assert,assert,equals,expected,bucket,files,prefix,4,current,assert,assert,equals,6,valid,length,list,string,pending,files,state,pending,files,assert,true,pending,files,is,empty,final,map,long,list,string,pending,files,per,checkpoint,state,pending,files,per,checkpoint,assert,assert,equals,1,pending,files,per,checkpoint,size,for,map,entry,long,list,string,entry,pending,files,per,checkpoint,entry,set,long,checkpoint,entry,get,key,list,string,files,entry,get,value,assert,assert,equals,0l,checkpoint,assert,assert,equals,4,files,size,for,int,i,0,i,4,i,assert,assert,equals,expected,bucket,files,prefix,i,files,get,i,initialize,called,true,super,initialize,state,context
BucketingSinkMigrationTest -> ValidatingBucketingSink -> @Override 		public void initializeState(FunctionInitializationContext context) throws Exception;1547725934;The actual paths in this depend on the binary checkpoint so it you update this the paths_here have to be updated as well.;@Override_		public void initializeState(FunctionInitializationContext context) throws Exception {_			OperatorStateStore stateStore = context.getOperatorStateStore()___			ListState<State<T>> restoredBucketStates = stateStore.getSerializableListState("bucket-states")___			if (context.isRestored()) {__				for (State<T> states : restoredBucketStates.get()) {_					for (String bucketPath : states.bucketStates.keySet()) {_						BucketState state = states.getBucketState(new Path(bucketPath))__						String current = state.currentFile__						long validLength = state.currentFileValidLength___						Assert.assertEquals(expectedBucketFilesPrefix + "4", current)__						Assert.assertEquals(6, validLength)___						List<String> pendingFiles = state.pendingFiles__						assertTrue(pendingFiles.isEmpty())___						final Map<Long, List<String>> pendingFilesPerCheckpoint = state.pendingFilesPerCheckpoint__						Assert.assertEquals(1, pendingFilesPerCheckpoint.size())___						for (Map.Entry<Long, List<String>> entry: pendingFilesPerCheckpoint.entrySet()) {_							long checkpoint = entry.getKey()__							List<String> files = entry.getValue()___							Assert.assertEquals(0L, checkpoint)__							Assert.assertEquals(4, files.size())___							for (int i = 0_ i < 4_ i++) {_								Assert.assertEquals(_										expectedBucketFilesPrefix + i,_										files.get(i))__							}_						}_					}_				}_			}__			initializeCalled = true__			super.initializeState(context)__		};the,actual,paths,in,this,depend,on,the,binary,checkpoint,so,it,you,update,this,the,paths,here,have,to,be,updated,as,well;override,public,void,initialize,state,function,initialization,context,context,throws,exception,operator,state,store,state,store,context,get,operator,state,store,list,state,state,t,restored,bucket,states,state,store,get,serializable,list,state,bucket,states,if,context,is,restored,for,state,t,states,restored,bucket,states,get,for,string,bucket,path,states,bucket,states,key,set,bucket,state,state,states,get,bucket,state,new,path,bucket,path,string,current,state,current,file,long,valid,length,state,current,file,valid,length,assert,assert,equals,expected,bucket,files,prefix,4,current,assert,assert,equals,6,valid,length,list,string,pending,files,state,pending,files,assert,true,pending,files,is,empty,final,map,long,list,string,pending,files,per,checkpoint,state,pending,files,per,checkpoint,assert,assert,equals,1,pending,files,per,checkpoint,size,for,map,entry,long,list,string,entry,pending,files,per,checkpoint,entry,set,long,checkpoint,entry,get,key,list,string,files,entry,get,value,assert,assert,equals,0l,checkpoint,assert,assert,equals,4,files,size,for,int,i,0,i,4,i,assert,assert,equals,expected,bucket,files,prefix,i,files,get,i,initialize,called,true,super,initialize,state,context
BucketingSinkMigrationTest -> ValidatingBucketingSink -> @Override 		public void initializeState(FunctionInitializationContext context) throws Exception;1547725946;The actual paths in this depend on the binary checkpoint so it you update this the paths_here have to be updated as well.;@Override_		public void initializeState(FunctionInitializationContext context) throws Exception {_			OperatorStateStore stateStore = context.getOperatorStateStore()___			ListState<State<T>> restoredBucketStates = stateStore.getSerializableListState("bucket-states")___			if (context.isRestored()) {__				for (State<T> states : restoredBucketStates.get()) {_					for (String bucketPath : states.bucketStates.keySet()) {_						BucketState state = states.getBucketState(new Path(bucketPath))__						String current = state.currentFile__						long validLength = state.currentFileValidLength___						Assert.assertEquals(expectedBucketFilesPrefix + "4", current)__						Assert.assertEquals(6, validLength)___						List<String> pendingFiles = state.pendingFiles__						assertTrue(pendingFiles.isEmpty())___						final Map<Long, List<String>> pendingFilesPerCheckpoint = state.pendingFilesPerCheckpoint__						Assert.assertEquals(1, pendingFilesPerCheckpoint.size())___						for (Map.Entry<Long, List<String>> entry: pendingFilesPerCheckpoint.entrySet()) {_							long checkpoint = entry.getKey()__							List<String> files = entry.getValue()___							Assert.assertEquals(0L, checkpoint)__							Assert.assertEquals(4, files.size())___							for (int i = 0_ i < 4_ i++) {_								Assert.assertEquals(_										expectedBucketFilesPrefix + i,_										files.get(i))__							}_						}_					}_				}_			}__			initializeCalled = true__			super.initializeState(context)__		};the,actual,paths,in,this,depend,on,the,binary,checkpoint,so,it,you,update,this,the,paths,here,have,to,be,updated,as,well;override,public,void,initialize,state,function,initialization,context,context,throws,exception,operator,state,store,state,store,context,get,operator,state,store,list,state,state,t,restored,bucket,states,state,store,get,serializable,list,state,bucket,states,if,context,is,restored,for,state,t,states,restored,bucket,states,get,for,string,bucket,path,states,bucket,states,key,set,bucket,state,state,states,get,bucket,state,new,path,bucket,path,string,current,state,current,file,long,valid,length,state,current,file,valid,length,assert,assert,equals,expected,bucket,files,prefix,4,current,assert,assert,equals,6,valid,length,list,string,pending,files,state,pending,files,assert,true,pending,files,is,empty,final,map,long,list,string,pending,files,per,checkpoint,state,pending,files,per,checkpoint,assert,assert,equals,1,pending,files,per,checkpoint,size,for,map,entry,long,list,string,entry,pending,files,per,checkpoint,entry,set,long,checkpoint,entry,get,key,list,string,files,entry,get,value,assert,assert,equals,0l,checkpoint,assert,assert,equals,4,files,size,for,int,i,0,i,4,i,assert,assert,equals,expected,bucket,files,prefix,i,files,get,i,initialize,called,true,super,initialize,state,context
BucketingSinkMigrationTest -> @Parameterized.Parameters(name = "Migration Savepoint / Bucket Files Prefix: {0}") 	public static Collection<Tuple2<MigrationVersion, String>> parameters ();1534233725;The bucket file prefix is the absolute path to the part files, which is stored within the savepoint.;@Parameterized.Parameters(name = "Migration Savepoint / Bucket Files Prefix: {0}")_	public static Collection<Tuple2<MigrationVersion, String>> parameters () {_		return Arrays.asList(_			Tuple2.of(MigrationVersion.v1_2, "/var/folders/v_/ry2wp5fx0y7c1rvr41xy9_700000gn/T/junit9160378385359106772/junit479663758539998903/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_3, "/var/folders/tv/b_1d8fvx23dgk1_xs8db_95h0000gn/T/junit4273542175898623023/junit3801102997056424640/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_4, "/var/folders/tv/b_1d8fvx23dgk1_xs8db_95h0000gn/T/junit3198043255809479705/junit8947526563966405708/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_5, "/tmp/junit4927100426019463155/junit2465610012100182280/1970-01-01--00/part-0-"))__	};the,bucket,file,prefix,is,the,absolute,path,to,the,part,files,which,is,stored,within,the,savepoint;parameterized,parameters,name,migration,savepoint,bucket,files,prefix,0,public,static,collection,tuple2,migration,version,string,parameters,return,arrays,as,list,tuple2,of,migration,version,var,folders,t,junit9160378385359106772,junit479663758539998903,1970,01,01,01,part,0,tuple2,of,migration,version,var,folders,tv,t,junit4273542175898623023,junit3801102997056424640,1970,01,01,01,part,0,tuple2,of,migration,version,var,folders,tv,t,junit3198043255809479705,junit8947526563966405708,1970,01,01,01,part,0,tuple2,of,migration,version,tmp,junit4927100426019463155,junit2465610012100182280,1970,01,01,00,part,0
BucketingSinkMigrationTest -> @Parameterized.Parameters(name = "Migration Savepoint / Bucket Files Prefix: {0}") 	public static Collection<Tuple2<MigrationVersion, String>> parameters ();1534779482;The bucket file prefix is the absolute path to the part files, which is stored within the savepoint.;@Parameterized.Parameters(name = "Migration Savepoint / Bucket Files Prefix: {0}")_	public static Collection<Tuple2<MigrationVersion, String>> parameters () {_		return Arrays.asList(_			Tuple2.of(MigrationVersion.v1_2, "/var/folders/v_/ry2wp5fx0y7c1rvr41xy9_700000gn/T/junit9160378385359106772/junit479663758539998903/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_3, "/var/folders/tv/b_1d8fvx23dgk1_xs8db_95h0000gn/T/junit4273542175898623023/junit3801102997056424640/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_4, "/var/folders/tv/b_1d8fvx23dgk1_xs8db_95h0000gn/T/junit3198043255809479705/junit8947526563966405708/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_5, "/tmp/junit4927100426019463155/junit2465610012100182280/1970-01-01--00/part-0-"),_			Tuple2.of(MigrationVersion.v1_6, "/tmp/junit3459711376354834545/junit5114611885650086135/1970-01-01--00/part-0-"))__	};the,bucket,file,prefix,is,the,absolute,path,to,the,part,files,which,is,stored,within,the,savepoint;parameterized,parameters,name,migration,savepoint,bucket,files,prefix,0,public,static,collection,tuple2,migration,version,string,parameters,return,arrays,as,list,tuple2,of,migration,version,var,folders,t,junit9160378385359106772,junit479663758539998903,1970,01,01,01,part,0,tuple2,of,migration,version,var,folders,tv,t,junit4273542175898623023,junit3801102997056424640,1970,01,01,01,part,0,tuple2,of,migration,version,var,folders,tv,t,junit3198043255809479705,junit8947526563966405708,1970,01,01,01,part,0,tuple2,of,migration,version,tmp,junit4927100426019463155,junit2465610012100182280,1970,01,01,00,part,0,tuple2,of,migration,version,tmp,junit3459711376354834545,junit5114611885650086135,1970,01,01,00,part,0
BucketingSinkMigrationTest -> @Parameterized.Parameters(name = "Migration Savepoint / Bucket Files Prefix: {0}") 	public static Collection<Tuple2<MigrationVersion, String>> parameters ();1546427459;The bucket file prefix is the absolute path to the part files, which is stored within the savepoint.;@Parameterized.Parameters(name = "Migration Savepoint / Bucket Files Prefix: {0}")_	public static Collection<Tuple2<MigrationVersion, String>> parameters () {_		return Arrays.asList(_			Tuple2.of(MigrationVersion.v1_2, "/var/folders/v_/ry2wp5fx0y7c1rvr41xy9_700000gn/T/junit9160378385359106772/junit479663758539998903/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_3, "/var/folders/tv/b_1d8fvx23dgk1_xs8db_95h0000gn/T/junit4273542175898623023/junit3801102997056424640/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_4, "/var/folders/tv/b_1d8fvx23dgk1_xs8db_95h0000gn/T/junit3198043255809479705/junit8947526563966405708/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_5, "/tmp/junit4927100426019463155/junit2465610012100182280/1970-01-01--00/part-0-"),_			Tuple2.of(MigrationVersion.v1_6, "/tmp/junit3459711376354834545/junit5114611885650086135/1970-01-01--00/part-0-"),_			Tuple2.of(MigrationVersion.v1_7, "/var/folders/r2/tdhx810x7yxb7q9_brnp49x40000gp/T/junit4288325607215628863/junit8132783417241536320/1970-01-01--08/part-0-"))__	};the,bucket,file,prefix,is,the,absolute,path,to,the,part,files,which,is,stored,within,the,savepoint;parameterized,parameters,name,migration,savepoint,bucket,files,prefix,0,public,static,collection,tuple2,migration,version,string,parameters,return,arrays,as,list,tuple2,of,migration,version,var,folders,t,junit9160378385359106772,junit479663758539998903,1970,01,01,01,part,0,tuple2,of,migration,version,var,folders,tv,t,junit4273542175898623023,junit3801102997056424640,1970,01,01,01,part,0,tuple2,of,migration,version,var,folders,tv,t,junit3198043255809479705,junit8947526563966405708,1970,01,01,01,part,0,tuple2,of,migration,version,tmp,junit4927100426019463155,junit2465610012100182280,1970,01,01,00,part,0,tuple2,of,migration,version,tmp,junit3459711376354834545,junit5114611885650086135,1970,01,01,00,part,0,tuple2,of,migration,version,var,folders,r2,t,junit4288325607215628863,junit8132783417241536320,1970,01,01,08,part,0
BucketingSinkMigrationTest -> @Parameterized.Parameters(name = "Migration Savepoint / Bucket Files Prefix: {0}") 	public static Collection<Tuple2<MigrationVersion, String>> parameters ();1547026204;The bucket file prefix is the absolute path to the part files, which is stored within the savepoint.;@Parameterized.Parameters(name = "Migration Savepoint / Bucket Files Prefix: {0}")_	public static Collection<Tuple2<MigrationVersion, String>> parameters () {_		return Arrays.asList(_			Tuple2.of(MigrationVersion.v1_2, "/var/folders/v_/ry2wp5fx0y7c1rvr41xy9_700000gn/T/junit9160378385359106772/junit479663758539998903/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_3, "/var/folders/tv/b_1d8fvx23dgk1_xs8db_95h0000gn/T/junit4273542175898623023/junit3801102997056424640/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_4, "/var/folders/tv/b_1d8fvx23dgk1_xs8db_95h0000gn/T/junit3198043255809479705/junit8947526563966405708/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_5, "/tmp/junit4927100426019463155/junit2465610012100182280/1970-01-01--00/part-0-"),_			Tuple2.of(MigrationVersion.v1_6, "/tmp/junit3459711376354834545/junit5114611885650086135/1970-01-01--00/part-0-"),_			Tuple2.of(MigrationVersion.v1_7, "/var/folders/r2/tdhx810x7yxb7q9_brnp49x40000gp/T/junit4288325607215628863/junit8132783417241536320/1970-01-01--08/part-0-"))__	};the,bucket,file,prefix,is,the,absolute,path,to,the,part,files,which,is,stored,within,the,savepoint;parameterized,parameters,name,migration,savepoint,bucket,files,prefix,0,public,static,collection,tuple2,migration,version,string,parameters,return,arrays,as,list,tuple2,of,migration,version,var,folders,t,junit9160378385359106772,junit479663758539998903,1970,01,01,01,part,0,tuple2,of,migration,version,var,folders,tv,t,junit4273542175898623023,junit3801102997056424640,1970,01,01,01,part,0,tuple2,of,migration,version,var,folders,tv,t,junit3198043255809479705,junit8947526563966405708,1970,01,01,01,part,0,tuple2,of,migration,version,tmp,junit4927100426019463155,junit2465610012100182280,1970,01,01,00,part,0,tuple2,of,migration,version,tmp,junit3459711376354834545,junit5114611885650086135,1970,01,01,00,part,0,tuple2,of,migration,version,var,folders,r2,t,junit4288325607215628863,junit8132783417241536320,1970,01,01,08,part,0
BucketingSinkMigrationTest -> @Parameterized.Parameters(name = "Migration Savepoint / Bucket Files Prefix: {0}") 	public static Collection<Tuple2<MigrationVersion, String>> parameters ();1547725934;The bucket file prefix is the absolute path to the part files, which is stored within the savepoint.;@Parameterized.Parameters(name = "Migration Savepoint / Bucket Files Prefix: {0}")_	public static Collection<Tuple2<MigrationVersion, String>> parameters () {_		return Arrays.asList(_			Tuple2.of(MigrationVersion.v1_2, "/var/folders/v_/ry2wp5fx0y7c1rvr41xy9_700000gn/T/junit9160378385359106772/junit479663758539998903/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_3, "/var/folders/tv/b_1d8fvx23dgk1_xs8db_95h0000gn/T/junit4273542175898623023/junit3801102997056424640/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_4, "/var/folders/tv/b_1d8fvx23dgk1_xs8db_95h0000gn/T/junit3198043255809479705/junit8947526563966405708/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_5, "/tmp/junit4927100426019463155/junit2465610012100182280/1970-01-01--00/part-0-"),_			Tuple2.of(MigrationVersion.v1_6, "/tmp/junit3459711376354834545/junit5114611885650086135/1970-01-01--00/part-0-"),_			Tuple2.of(MigrationVersion.v1_7, "/var/folders/r2/tdhx810x7yxb7q9_brnp49x40000gp/T/junit4288325607215628863/junit8132783417241536320/1970-01-01--08/part-0-"))__	};the,bucket,file,prefix,is,the,absolute,path,to,the,part,files,which,is,stored,within,the,savepoint;parameterized,parameters,name,migration,savepoint,bucket,files,prefix,0,public,static,collection,tuple2,migration,version,string,parameters,return,arrays,as,list,tuple2,of,migration,version,var,folders,t,junit9160378385359106772,junit479663758539998903,1970,01,01,01,part,0,tuple2,of,migration,version,var,folders,tv,t,junit4273542175898623023,junit3801102997056424640,1970,01,01,01,part,0,tuple2,of,migration,version,var,folders,tv,t,junit3198043255809479705,junit8947526563966405708,1970,01,01,01,part,0,tuple2,of,migration,version,tmp,junit4927100426019463155,junit2465610012100182280,1970,01,01,00,part,0,tuple2,of,migration,version,tmp,junit3459711376354834545,junit5114611885650086135,1970,01,01,00,part,0,tuple2,of,migration,version,var,folders,r2,t,junit4288325607215628863,junit8132783417241536320,1970,01,01,08,part,0
BucketingSinkMigrationTest -> @Parameterized.Parameters(name = "Migration Savepoint / Bucket Files Prefix: {0}") 	public static Collection<Tuple2<MigrationVersion, String>> parameters ();1547725946;The bucket file prefix is the absolute path to the part files, which is stored within the savepoint.;@Parameterized.Parameters(name = "Migration Savepoint / Bucket Files Prefix: {0}")_	public static Collection<Tuple2<MigrationVersion, String>> parameters () {_		return Arrays.asList(_			Tuple2.of(MigrationVersion.v1_2, "/var/folders/v_/ry2wp5fx0y7c1rvr41xy9_700000gn/T/junit9160378385359106772/junit479663758539998903/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_3, "/var/folders/tv/b_1d8fvx23dgk1_xs8db_95h0000gn/T/junit4273542175898623023/junit3801102997056424640/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_4, "/var/folders/tv/b_1d8fvx23dgk1_xs8db_95h0000gn/T/junit3198043255809479705/junit8947526563966405708/1970-01-01--01/part-0-"),_			Tuple2.of(MigrationVersion.v1_5, "/tmp/junit4927100426019463155/junit2465610012100182280/1970-01-01--00/part-0-"),_			Tuple2.of(MigrationVersion.v1_6, "/tmp/junit3459711376354834545/junit5114611885650086135/1970-01-01--00/part-0-"),_			Tuple2.of(MigrationVersion.v1_7, "/var/folders/r2/tdhx810x7yxb7q9_brnp49x40000gp/T/junit4288325607215628863/junit8132783417241536320/1970-01-01--08/part-0-"))__	};the,bucket,file,prefix,is,the,absolute,path,to,the,part,files,which,is,stored,within,the,savepoint;parameterized,parameters,name,migration,savepoint,bucket,files,prefix,0,public,static,collection,tuple2,migration,version,string,parameters,return,arrays,as,list,tuple2,of,migration,version,var,folders,t,junit9160378385359106772,junit479663758539998903,1970,01,01,01,part,0,tuple2,of,migration,version,var,folders,tv,t,junit4273542175898623023,junit3801102997056424640,1970,01,01,01,part,0,tuple2,of,migration,version,var,folders,tv,t,junit3198043255809479705,junit8947526563966405708,1970,01,01,01,part,0,tuple2,of,migration,version,tmp,junit4927100426019463155,junit2465610012100182280,1970,01,01,00,part,0,tuple2,of,migration,version,tmp,junit3459711376354834545,junit5114611885650086135,1970,01,01,00,part,0,tuple2,of,migration,version,var,folders,r2,t,junit4288325607215628863,junit8132783417241536320,1970,01,01,08,part,0
