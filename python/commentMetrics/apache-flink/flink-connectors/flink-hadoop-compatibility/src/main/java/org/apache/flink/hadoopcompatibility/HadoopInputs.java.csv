commented;modifiers;parameterAmount;loc;comment;code
true;public,static;5;6;/**  * Creates a Flink {@link InputFormat} that wraps the given Hadoop {@link org.apache.hadoop.mapred.FileInputFormat}.  *  * @return A Flink InputFormat that wraps the Hadoop FileInputFormat.  */ ;// ----------------------------------- Hadoop Input Format --------------------------------------- /**  * Creates a Flink {@link InputFormat} that wraps the given Hadoop {@link org.apache.hadoop.mapred.FileInputFormat}.  *  * @return A Flink InputFormat that wraps the Hadoop FileInputFormat.  */ public static <K, V> HadoopInputFormat<K, V> readHadoopFile(org.apache.hadoop.mapred.FileInputFormat<K, V> mapredInputFormat, Class<K> key, Class<V> value, String inputPath, JobConf job) {     // set input path in JobConf     org.apache.hadoop.mapred.FileInputFormat.addInputPath(job, new org.apache.hadoop.fs.Path(inputPath)).     // return wrapping InputFormat     return createHadoopInput(mapredInputFormat, key, value, job). }
true;public,static;4;3;/**  * Creates a Flink {@link InputFormat} that wraps the given Hadoop {@link org.apache.hadoop.mapred.FileInputFormat}.  *  * @return A Flink InputFormat that wraps the Hadoop FileInputFormat.  */ ;/**  * Creates a Flink {@link InputFormat} that wraps the given Hadoop {@link org.apache.hadoop.mapred.FileInputFormat}.  *  * @return A Flink InputFormat that wraps the Hadoop FileInputFormat.  */ public static <K, V> HadoopInputFormat<K, V> readHadoopFile(org.apache.hadoop.mapred.FileInputFormat<K, V> mapredInputFormat, Class<K> key, Class<V> value, String inputPath) {     return readHadoopFile(mapredInputFormat, key, value, inputPath, new JobConf()). }
true;public,static;3;3;/**  * Creates a Flink {@link InputFormat} to read a Hadoop sequence file for the given key and value classes.  *  * @return A Flink InputFormat that wraps a Hadoop SequenceFileInputFormat.  */ ;/**  * Creates a Flink {@link InputFormat} to read a Hadoop sequence file for the given key and value classes.  *  * @return A Flink InputFormat that wraps a Hadoop SequenceFileInputFormat.  */ public static <K, V> HadoopInputFormat<K, V> readSequenceFile(Class<K> key, Class<V> value, String inputPath) throws IOException {     return readHadoopFile(new org.apache.hadoop.mapred.SequenceFileInputFormat<K, V>(), key, value, inputPath). }
true;public,static;4;3;/**  * Creates a Flink {@link InputFormat} that wraps the given Hadoop {@link org.apache.hadoop.mapred.InputFormat}.  *  * @return A Flink InputFormat that wraps the Hadoop InputFormat.  */ ;/**  * Creates a Flink {@link InputFormat} that wraps the given Hadoop {@link org.apache.hadoop.mapred.InputFormat}.  *  * @return A Flink InputFormat that wraps the Hadoop InputFormat.  */ public static <K, V> HadoopInputFormat<K, V> createHadoopInput(org.apache.hadoop.mapred.InputFormat<K, V> mapredInputFormat, Class<K> key, Class<V> value, JobConf job) {     return new HadoopInputFormat<>(mapredInputFormat, key, value, job). }
true;public,static;5;7;/**  * Creates a Flink {@link InputFormat} that wraps the given Hadoop {@link org.apache.hadoop.mapreduce.lib.input.FileInputFormat}.  *  * @return A Flink InputFormat that wraps the Hadoop FileInputFormat.  */ ;/**  * Creates a Flink {@link InputFormat} that wraps the given Hadoop {@link org.apache.hadoop.mapreduce.lib.input.FileInputFormat}.  *  * @return A Flink InputFormat that wraps the Hadoop FileInputFormat.  */ public static <K, V> org.apache.flink.api.java.hadoop.mapreduce.HadoopInputFormat<K, V> readHadoopFile(org.apache.hadoop.mapreduce.lib.input.FileInputFormat<K, V> mapreduceInputFormat, Class<K> key, Class<V> value, String inputPath, Job job) throws IOException {     // set input path in Job     org.apache.hadoop.mapreduce.lib.input.FileInputFormat.addInputPath(job, new org.apache.hadoop.fs.Path(inputPath)).     // return wrapping InputFormat     return createHadoopInput(mapreduceInputFormat, key, value, job). }
true;public,static;4;4;/**  * Creates a Flink {@link InputFormat} that wraps the given Hadoop {@link org.apache.hadoop.mapreduce.lib.input.FileInputFormat}.  *  * @return A Flink InputFormat that wraps the Hadoop FileInputFormat.  */ ;/**  * Creates a Flink {@link InputFormat} that wraps the given Hadoop {@link org.apache.hadoop.mapreduce.lib.input.FileInputFormat}.  *  * @return A Flink InputFormat that wraps the Hadoop FileInputFormat.  */ public static <K, V> org.apache.flink.api.java.hadoop.mapreduce.HadoopInputFormat<K, V> readHadoopFile(org.apache.hadoop.mapreduce.lib.input.FileInputFormat<K, V> mapreduceInputFormat, Class<K> key, Class<V> value, String inputPath) throws IOException {     return readHadoopFile(mapreduceInputFormat, key, value, inputPath, Job.getInstance()). }
true;public,static;4;4;/**  * Creates a Flink {@link InputFormat} that wraps the given Hadoop {@link org.apache.hadoop.mapreduce.InputFormat}.  *  * @return A Flink InputFormat that wraps the Hadoop InputFormat.  */ ;/**  * Creates a Flink {@link InputFormat} that wraps the given Hadoop {@link org.apache.hadoop.mapreduce.InputFormat}.  *  * @return A Flink InputFormat that wraps the Hadoop InputFormat.  */ public static <K, V> org.apache.flink.api.java.hadoop.mapreduce.HadoopInputFormat<K, V> createHadoopInput(org.apache.hadoop.mapreduce.InputFormat<K, V> mapreduceInputFormat, Class<K> key, Class<V> value, Job job) {     return new org.apache.flink.api.java.hadoop.mapreduce.HadoopInputFormat<>(mapreduceInputFormat, key, value, job). }
