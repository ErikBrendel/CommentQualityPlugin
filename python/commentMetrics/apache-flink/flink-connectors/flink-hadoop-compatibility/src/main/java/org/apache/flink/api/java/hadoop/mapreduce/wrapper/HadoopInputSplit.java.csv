commented;modifiers;parameterAmount;loc;comment;code
false;public;0;3;;// ------------------------------------------------------------------------ // Properties // ------------------------------------------------------------------------ public org.apache.hadoop.mapreduce.InputSplit getHadoopInputSplit() {     return mapreduceInputSplit. }
false;public;0;9;;@Override public String[] getHostnames() {     try {         return mapreduceInputSplit.getLocations().     } catch (Exception e) {         return new String[0].     } }
false;private;1;7;;// ------------------------------------------------------------------------ // Serialization // ------------------------------------------------------------------------ private void writeObject(ObjectOutputStream out) throws IOException {     // serialize the parent fields and the final fields     out.defaultWriteObject().     // write the input split     ((Writable) mapreduceInputSplit).write(out). }
false;private;1;15;;private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {     // read the parent fields and the final fields     in.defaultReadObject().     try {         Class<? extends Writable> writableSplit = splitType.asSubclass(Writable.class).         mapreduceInputSplit = (org.apache.hadoop.mapreduce.InputSplit) WritableFactories.newInstance(writableSplit).     } catch (Exception e) {         throw new RuntimeException("Unable to instantiate the Hadoop InputSplit", e).     }     ((Writable) mapreduceInputSplit).readFields(in). }
