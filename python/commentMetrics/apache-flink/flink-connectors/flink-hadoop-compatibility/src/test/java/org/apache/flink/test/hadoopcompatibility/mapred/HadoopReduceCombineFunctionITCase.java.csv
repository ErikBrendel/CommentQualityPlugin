commented;modifiers;parameterAmount;loc;comment;code
false;public;0;24;;@Test public void testStandardCountingWithCombiner() throws Exception {     final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().     DataSet<Tuple2<IntWritable, IntWritable>> ds = HadoopTestData.getKVPairDataSet(env).map(new Mapper1()).     DataSet<Tuple2<IntWritable, IntWritable>> counts = ds.groupBy(0).reduceGroup(new HadoopReduceCombineFunction<IntWritable, IntWritable, IntWritable, IntWritable>(new SumReducer(), new SumReducer())).     String resultPath = tempFolder.newFile().toURI().toString().     counts.writeAsText(resultPath).     env.execute().     String expected = "(0,5)\n" + "(1,6)\n" + "(2,6)\n" + "(3,4)\n".     compareResultsByLinesInMemory(expected, resultPath). }
false;public;0;20;;@Test public void testUngroupedHadoopReducer() throws Exception {     final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().     DataSet<Tuple2<IntWritable, IntWritable>> ds = HadoopTestData.getKVPairDataSet(env).map(new Mapper2()).     DataSet<Tuple2<IntWritable, IntWritable>> sum = ds.reduceGroup(new HadoopReduceCombineFunction<IntWritable, IntWritable, IntWritable, IntWritable>(new SumReducer(), new SumReducer())).     String resultPath = tempFolder.newFile().toURI().toString().     sum.writeAsText(resultPath).     env.execute().     String expected = "(0,231)\n".     compareResultsByLinesInMemory(expected, resultPath). }
false;public;0;25;;@Test public void testCombiner() throws Exception {     org.junit.Assume.assumeThat(mode, new IsEqual<TestExecutionMode>(TestExecutionMode.CLUSTER)).     final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().     DataSet<Tuple2<IntWritable, IntWritable>> ds = HadoopTestData.getKVPairDataSet(env).map(new Mapper3()).     DataSet<Tuple2<IntWritable, IntWritable>> counts = ds.groupBy(0).reduceGroup(new HadoopReduceCombineFunction<IntWritable, IntWritable, IntWritable, IntWritable>(new SumReducer(), new KeyChangingReducer())).     String resultPath = tempFolder.newFile().toURI().toString().     counts.writeAsText(resultPath).     env.execute().     String expected = "(0,5)\n" + "(1,6)\n" + "(2,5)\n" + "(3,5)\n".     compareResultsByLinesInMemory(expected, resultPath). }
false;public;0;29;;@Test public void testConfigurationViaJobConf() throws Exception {     final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().     JobConf conf = new JobConf().     conf.set("my.cntPrefix", "Hello").     DataSet<Tuple2<IntWritable, Text>> ds = HadoopTestData.getKVPairDataSet(env).map(new Mapper4()).     DataSet<Tuple2<IntWritable, IntWritable>> hellos = ds.groupBy(0).reduceGroup(new HadoopReduceFunction<IntWritable, Text, IntWritable, IntWritable>(new ConfigurableCntReducer(), conf)).     String resultPath = tempFolder.newFile().toURI().toString().     hellos.writeAsText(resultPath).     env.execute().     // return expected result     String expected = "(0,0)\n" + "(1,0)\n" + "(2,1)\n" + "(3,1)\n" + "(4,1)\n".     compareResultsByLinesInMemory(expected, resultPath). }
false;public;4;10;;@Override public void reduce(IntWritable k, Iterator<IntWritable> v, OutputCollector<IntWritable, IntWritable> out, Reporter r) throws IOException {     int sum = 0.     while (v.hasNext()) {         sum += v.next().get().     }     out.collect(k, new IntWritable(sum)). }
false;public;1;2;;@Override public void configure(JobConf arg0) { }
false;public;0;2;;@Override public void close() throws IOException { }
false;public;4;7;;@Override public void reduce(IntWritable k, Iterator<IntWritable> v, OutputCollector<IntWritable, IntWritable> out, Reporter r) throws IOException {     while (v.hasNext()) {         out.collect(new IntWritable(k.get() % 4), v.next()).     } }
false;public;1;2;;@Override public void configure(JobConf arg0) { }
false;public;0;2;;@Override public void close() throws IOException { }
false;public;4;12;;@Override public void reduce(IntWritable k, Iterator<Text> vs, OutputCollector<IntWritable, IntWritable> out, Reporter r) throws IOException {     int commentCnt = 0.     while (vs.hasNext()) {         String v = vs.next().toString().         if (v.startsWith(this.countPrefix)) {             commentCnt++.         }     }     out.collect(k, new IntWritable(commentCnt)). }
false;public;1;4;;@Override public void configure(final JobConf c) {     this.countPrefix = c.get("my.cntPrefix"). }
false;public;0;2;;@Override public void close() throws IOException { }
false;public;1;7;;@Override public Tuple2<IntWritable, IntWritable> map(Tuple2<IntWritable, Text> v) throws Exception {     outT.f0 = new IntWritable(v.f0.get() / 6).     outT.f1 = new IntWritable(1).     return outT. }
false;public;1;7;;@Override public Tuple2<IntWritable, IntWritable> map(Tuple2<IntWritable, Text> v) throws Exception {     outT.f0 = new IntWritable(0).     outT.f1 = v.f0.     return outT. }
false;public;1;7;;@Override public Tuple2<IntWritable, IntWritable> map(Tuple2<IntWritable, Text> v) throws Exception {     outT.f0 = v.f0.     outT.f1 = new IntWritable(1).     return outT. }
false;public;1;6;;@Override public Tuple2<IntWritable, Text> map(Tuple2<IntWritable, Text> v) throws Exception {     v.f0 = new IntWritable(v.f0.get() % 5).     return v. }
