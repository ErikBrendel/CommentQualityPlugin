commented;modifiers;parameterAmount;loc;comment;code
false;public;0;5;;@Before public void checkOperatingSystem() {     // FLINK-5164 - see https://wiki.apache.org/hadoop/WindowsProblems     Assume.assumeTrue("This test can't run successfully on Windows.", !OperatingSystem.isWindows()). }
false;protected;0;5;;@Override protected void preSubmit() throws Exception {     textPath = createTempFile("text.txt", WordCountData.TEXT).     resultPath = getTempDirPath("result"). }
false;protected;0;4;;@Override protected void postSubmit() throws Exception {     compareResultsByLinesInMemory(WordCountData.COUNTS, resultPath, new String[] { ".", "_" }). }
false;protected;0;5;;@Override protected void testProgram() throws Exception {     internalRun().     postSubmit(). }
false;public;1;4;;@Override public String map(Tuple2<LongWritable, Text> value) throws Exception {     return value.f1.toString(). }
false;public;1;4;;@Override public Tuple2<Text, LongWritable> map(Tuple2<String, Integer> value) throws Exception {     return new Tuple2<Text, LongWritable>(new Text(value.f0), new LongWritable(value.f1)). }
false;private;0;40;;private void internalRun() throws Exception {     final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().     DataSet<Tuple2<LongWritable, Text>> input.     input = env.createInput(HadoopInputs.readHadoopFile(new TextInputFormat(), LongWritable.class, Text.class, textPath)).     DataSet<String> text = input.map(new MapFunction<Tuple2<LongWritable, Text>, String>() {          @Override         public String map(Tuple2<LongWritable, Text> value) throws Exception {             return value.f1.toString().         }     }).     DataSet<Tuple2<String, Integer>> counts = // split up the lines in pairs (2-tuples) containing: (word,1)     text.flatMap(new Tokenizer()).groupBy(0).sum(1).     DataSet<Tuple2<Text, LongWritable>> words = counts.map(new MapFunction<Tuple2<String, Integer>, Tuple2<Text, LongWritable>>() {          @Override         public Tuple2<Text, LongWritable> map(Tuple2<String, Integer> value) throws Exception {             return new Tuple2<Text, LongWritable>(new Text(value.f0), new LongWritable(value.f1)).         }     }).     // Set up Hadoop Output Format     HadoopOutputFormat<Text, LongWritable> hadoopOutputFormat = new HadoopOutputFormat<Text, LongWritable>(new TextOutputFormat<Text, LongWritable>(), new JobConf()).     hadoopOutputFormat.getJobConf().set("mapred.textoutputformat.separator", " ").     TextOutputFormat.setOutputPath(hadoopOutputFormat.getJobConf(), new Path(resultPath)).     // Output & Execute     words.output(hadoopOutputFormat).     env.execute("Hadoop Compat WordCount"). }
false;public;2;9;;@Override public void flatMap(String value, Collector<Tuple2<String, Integer>> out) {     String[] tokens = value.toLowerCase().split("\\W+").     for (String token : tokens) {         if (token.length() > 0) {             out.collect(new Tuple2<>(token, 1)).         }     } }
