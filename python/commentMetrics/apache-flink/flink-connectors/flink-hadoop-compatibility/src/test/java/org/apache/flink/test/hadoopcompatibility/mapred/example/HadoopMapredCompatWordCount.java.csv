commented;modifiers;parameterAmount;loc;comment;code
false;public,static;1;32;;public static void main(String[] args) throws Exception {     if (args.length < 2) {         System.err.println("Usage: WordCount <input path> <result path>").         return.     }     final String inputPath = args[0].     final String outputPath = args[1].     final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().     // Set up the Hadoop Input Format     HadoopInputFormat<LongWritable, Text> hadoopInputFormat = new HadoopInputFormat<LongWritable, Text>(new TextInputFormat(), LongWritable.class, Text.class, new JobConf()).     TextInputFormat.addInputPath(hadoopInputFormat.getJobConf(), new Path(inputPath)).     // Create a Flink job with it     DataSet<Tuple2<LongWritable, Text>> text = env.createInput(hadoopInputFormat).     DataSet<Tuple2<Text, LongWritable>> words = text.flatMap(new HadoopMapFunction<LongWritable, Text, Text, LongWritable>(new Tokenizer())).groupBy(0).reduceGroup(new HadoopReduceCombineFunction<Text, LongWritable, Text, LongWritable>(new Counter(), new Counter())).     // Set up Hadoop Output Format     HadoopOutputFormat<Text, LongWritable> hadoopOutputFormat = new HadoopOutputFormat<Text, LongWritable>(new TextOutputFormat<Text, LongWritable>(), new JobConf()).     hadoopOutputFormat.getJobConf().set("mapred.textoutputformat.separator", " ").     TextOutputFormat.setOutputPath(hadoopOutputFormat.getJobConf(), new Path(outputPath)).     // Output & Execute     words.output(hadoopOutputFormat).setParallelism(1).     env.execute("Hadoop Compat WordCount"). }
false;public;4;14;;@Override public void map(LongWritable k, Text v, OutputCollector<Text, LongWritable> out, Reporter rep) throws IOException {     // normalize and split the line     String line = v.toString().     String[] tokens = line.toLowerCase().split("\\W+").     // emit the pairs     for (String token : tokens) {         if (token.length() > 0) {             out.collect(new Text(token), new LongWritable(1L)).         }     } }
false;public;1;2;;@Override public void configure(JobConf arg0) { }
false;public;0;2;;@Override public void close() throws IOException { }
false;public;4;11;;@Override public void reduce(Text k, Iterator<LongWritable> vs, OutputCollector<Text, LongWritable> out, Reporter rep) throws IOException {     long cnt = 0.     while (vs.hasNext()) {         cnt += vs.next().get().     }     out.collect(k, new LongWritable(cnt)). }
false;public;1;2;;@Override public void configure(JobConf arg0) { }
false;public;0;2;;@Override public void close() throws IOException { }
