commented;modifiers;parameterAmount;loc;comment;code
false;protected;8;38;;@Override protected AbstractFetcher<T, ?> createFetcher(SourceContext<T> sourceContext, Map<KafkaTopicPartition, Long> assignedPartitionsWithInitialOffsets, SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, StreamingRuntimeContext runtimeContext, OffsetCommitMode offsetCommitMode, MetricGroup consumerMetricGroup, boolean useMetrics) throws Exception {     // make sure that auto commit is disabled when our offset commit mode is ON_CHECKPOINTS.     // this overwrites whatever setting the user configured in the properties     adjustAutoCommitConfig(properties, offsetCommitMode).     FlinkConnectorRateLimiter rateLimiter = super.getRateLimiter().     // If a rateLimiter is set, then call rateLimiter.open() with the runtime context.     if (rateLimiter != null) {         rateLimiter.open(runtimeContext).     }     return new Kafka010Fetcher<>(sourceContext, assignedPartitionsWithInitialOffsets, watermarksPeriodic, watermarksPunctuated, runtimeContext.getProcessingTimeService(), runtimeContext.getExecutionConfig().getAutoWatermarkInterval(), runtimeContext.getUserCodeClassLoader(), runtimeContext.getTaskNameWithSubtasks(), deserializer, properties, pollTimeout, runtimeContext.getMetricGroup(), consumerMetricGroup, useMetrics, rateLimiter). }
false;protected;3;8;;@Override protected AbstractPartitionDiscoverer createPartitionDiscoverer(KafkaTopicsDescriptor topicsDescriptor, int indexOfThisSubtask, int numParallelSubtasks) {     return new Kafka010PartitionDiscoverer(topicsDescriptor, indexOfThisSubtask, numParallelSubtasks, properties). }
false;public;1;6;;// ------------------------------------------------------------------------ // Timestamp-based startup // ------------------------------------------------------------------------ @Override public FlinkKafkaConsumerBase<T> setStartFromTimestamp(long startupOffsetsTimestamp) {     // the base class doesn't publicly expose it since not all Kafka versions support the functionality     return super.setStartFromTimestamp(startupOffsetsTimestamp). }
false;protected;2;28;;@Override protected Map<KafkaTopicPartition, Long> fetchOffsetsWithTimestamp(Collection<KafkaTopicPartition> partitions, long timestamp) {     Map<TopicPartition, Long> partitionOffsetsRequest = new HashMap<>(partitions.size()).     for (KafkaTopicPartition partition : partitions) {         partitionOffsetsRequest.put(new TopicPartition(partition.getTopic(), partition.getPartition()), timestamp).     }     final Map<KafkaTopicPartition, Long> result = new HashMap<>(partitions.size()).     // this is ok because this is a one-time operation that happens only on startup     try (KafkaConsumer<?, ?> consumer = new KafkaConsumer(properties)) {         for (Map.Entry<TopicPartition, OffsetAndTimestamp> partitionToOffset : consumer.offsetsForTimes(partitionOffsetsRequest).entrySet()) {             result.put(new KafkaTopicPartition(partitionToOffset.getKey().topic(), partitionToOffset.getKey().partition()), (partitionToOffset.getValue() == null) ? null : partitionToOffset.getValue().offset()).         }     }     return result. }
