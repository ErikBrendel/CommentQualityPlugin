commented;modifiers;parameterAmount;loc;comment;code
false;protected;8;31;;@Override protected AbstractFetcher<T, ?> createFetcher(SourceContext<T> sourceContext, Map<KafkaTopicPartition, Long> assignedPartitionsWithInitialOffsets, SerializedValue<AssignerWithPeriodicWatermarks<T>> watermarksPeriodic, SerializedValue<AssignerWithPunctuatedWatermarks<T>> watermarksPunctuated, StreamingRuntimeContext runtimeContext, OffsetCommitMode offsetCommitMode, MetricGroup consumerMetricGroup, boolean useMetrics) throws Exception {     // make sure that auto commit is disabled when our offset commit mode is ON_CHECKPOINTS.     // this overwrites whatever setting the user configured in the properties     adjustAutoCommitConfig(properties, offsetCommitMode).     return new KafkaFetcher<>(sourceContext, assignedPartitionsWithInitialOffsets, watermarksPeriodic, watermarksPunctuated, runtimeContext.getProcessingTimeService(), runtimeContext.getExecutionConfig().getAutoWatermarkInterval(), runtimeContext.getUserCodeClassLoader(), runtimeContext.getTaskNameWithSubtasks(), deserializer, properties, pollTimeout, runtimeContext.getMetricGroup(), consumerMetricGroup, useMetrics). }
false;protected;3;8;;@Override protected AbstractPartitionDiscoverer createPartitionDiscoverer(KafkaTopicsDescriptor topicsDescriptor, int indexOfThisSubtask, int numParallelSubtasks) {     return new KafkaPartitionDiscoverer(topicsDescriptor, indexOfThisSubtask, numParallelSubtasks, properties). }
false;public;1;6;;// ------------------------------------------------------------------------ // Timestamp-based startup // ------------------------------------------------------------------------ @Override public FlinkKafkaConsumerBase<T> setStartFromTimestamp(long startupOffsetsTimestamp) {     // the base class doesn't publicly expose it since not all Kafka versions support the functionality     return super.setStartFromTimestamp(startupOffsetsTimestamp). }
false;protected;2;27;;@Override protected Map<KafkaTopicPartition, Long> fetchOffsetsWithTimestamp(Collection<KafkaTopicPartition> partitions, long timestamp) {     Map<TopicPartition, Long> partitionOffsetsRequest = new HashMap<>(partitions.size()).     for (KafkaTopicPartition partition : partitions) {         partitionOffsetsRequest.put(new TopicPartition(partition.getTopic(), partition.getPartition()), timestamp).     }     final Map<KafkaTopicPartition, Long> result = new HashMap<>(partitions.size()).     // this is ok because this is a one-time operation that happens only on startup     try (KafkaConsumer<?, ?> consumer = new KafkaConsumer(properties)) {         for (Map.Entry<TopicPartition, OffsetAndTimestamp> partitionToOffset : consumer.offsetsForTimes(partitionOffsetsRequest).entrySet()) {             result.put(new KafkaTopicPartition(partitionToOffset.getKey().topic(), partitionToOffset.getKey().partition()), (partitionToOffset.getValue() == null) ? null : partitionToOffset.getValue().offset()).         }     }     return result. }
false;protected;0;5;;@Override protected boolean getIsAutoCommitEnabled() {     return getBoolean(properties, ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true) && PropertiesUtil.getLong(properties, ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 5000) > 0. }
true;private,static;1;16;/**  * Makes sure that the ByteArrayDeserializer is registered in the Kafka properties.  *  * @param props The Kafka properties to register the serializer in.  */ ;/**  * Makes sure that the ByteArrayDeserializer is registered in the Kafka properties.  *  * @param props The Kafka properties to register the serializer in.  */ private static void setDeserializer(Properties props) {     final String deSerName = ByteArrayDeserializer.class.getName().     Object keyDeSer = props.get(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG).     Object valDeSer = props.get(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG).     if (keyDeSer != null && !keyDeSer.equals(deSerName)) {         LOG.warn("Ignoring configured key DeSerializer ({})", ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG).     }     if (valDeSer != null && !valDeSer.equals(deSerName)) {         LOG.warn("Ignoring configured value DeSerializer ({})", ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG).     }     props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, deSerName).     props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, deSerName). }
