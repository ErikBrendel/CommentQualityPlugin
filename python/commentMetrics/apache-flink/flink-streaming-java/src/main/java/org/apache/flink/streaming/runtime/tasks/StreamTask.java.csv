commented;modifiers;parameterAmount;loc;comment;code
false;protected,abstract;0;1;;// ------------------------------------------------------------------------ // Life cycle methods for specific implementations // ------------------------------------------------------------------------ protected abstract void init() throws Exception.
false;protected,abstract;0;1;;protected abstract void run() throws Exception.
false;protected,abstract;0;1;;protected abstract void cleanup() throws Exception.
false;protected,abstract;0;1;;protected abstract void cancelTask() throws Exception.
false;public;0;6;;// ------------------------------------------------------------------------ // Core work methods of the Stream Task // ------------------------------------------------------------------------ public StreamTaskStateInitializer createStreamTaskStateInitializer() {     return new StreamTaskStateInitializerImpl(getEnvironment(), stateBackend, timerService). }
false;public,final;0;153;;@Override public final void invoke() throws Exception {     boolean disposed = false.     try {         // -------- Initialize ---------         LOG.debug("Initializing {}.", getName()).         asyncOperationsThreadPool = Executors.newCachedThreadPool().         CheckpointExceptionHandlerFactory cpExceptionHandlerFactory = createCheckpointExceptionHandlerFactory().         synchronousCheckpointExceptionHandler = cpExceptionHandlerFactory.createCheckpointExceptionHandler(getExecutionConfig().isFailTaskOnCheckpointError(), getEnvironment()).         asynchronousCheckpointExceptionHandler = new AsyncCheckpointExceptionHandler(this).         stateBackend = createStateBackend().         checkpointStorage = stateBackend.createCheckpointStorage(getEnvironment().getJobID()).         // if the clock is not already set, then assign a default TimeServiceProvider         if (timerService == null) {             ThreadFactory timerThreadFactory = new DispatcherThreadFactory(TRIGGER_THREAD_GROUP, "Time Trigger for " + getName(), getUserCodeClassLoader()).             timerService = new SystemProcessingTimeService(this, getCheckpointLock(), timerThreadFactory).         }         operatorChain = new OperatorChain<>(this, recordWriters).         headOperator = operatorChain.getHeadOperator().         // task specific initialization         init().         // save the work of reloading state, etc, if the task is already canceled         if (canceled) {             throw new CancelTaskException().         }         // -------- Invoke --------         LOG.debug("Invoking {}", getName()).         // executed before all operators are opened         synchronized (lock) {             // both the following operations are protected by the lock             // so that we avoid race conditions in the case that initializeState()             // registers a timer, that fires before the open() is called.             initializeState().             openAllOperators().         }         // final check to exit early before starting to run         if (canceled) {             throw new CancelTaskException().         }         // let the task do its work         isRunning = true.         run().         // make sure the "clean shutdown" is not attempted         if (canceled) {             throw new CancelTaskException().         }         LOG.debug("Finished task {}", getName()).         // at the same time, this makes sure that during any "regular" exit where still         synchronized (lock) {             // this is part of the main logic, so if this fails, the task is considered failed             closeAllOperators().             // make sure no new timers can come             timerService.quiesce().             // only set the StreamTask to not running after all operators have been closed!             // See FLINK-7430             isRunning = false.         }         // make sure all timers finish         timerService.awaitPendingAfterQuiesce().         LOG.debug("Closed operators for task {}", getName()).         // make sure all buffered data is flushed         operatorChain.flushOutputs().         // make an attempt to dispose the operators such that failures in the dispose call         // still let the computation fail         tryDisposeAllOperators().         disposed = true.     } finally {         // clean up everything we initialized         isRunning = false.         // Now that we are outside the user code, we do not want to be interrupted further         // upon cancellation. The shutdown logic below needs to make sure it does not issue calls         // that block and stall shutdown.         // Additionally, the cancellation watch dog will issue a hard-cancel (kill the TaskManager         // process) as a backup in case some shutdown procedure blocks outside our control.         setShouldInterruptOnCancel(false).         // clear any previously issued interrupt for a more graceful shutdown         Thread.interrupted().         // stop all timers and threads         tryShutdownTimerService().         // stop all asynchronous checkpoint threads         try {             cancelables.close().             shutdownAsyncThreads().         } catch (Throwable t) {             // catch and log the exception to not replace the original exception             LOG.error("Could not shut down async checkpoint threads", t).         }         // we must! perform this cleanup         try {             cleanup().         } catch (Throwable t) {             // catch and log the exception to not replace the original exception             LOG.error("Error during cleanup of stream task", t).         }         // if the operators were not disposed before, do a hard dispose         if (!disposed) {             disposeAllOperators().         }         // release the output resources. this method should never fail.         if (operatorChain != null) {             // parallel and this call is not thread-safe             synchronized (lock) {                 operatorChain.releaseOutputs().             }         }     } }
false;public,final;0;14;;@Override public final void cancel() throws Exception {     isRunning = false.     canceled = true.     // closed no matter what     try {         cancelTask().     } finally {         cancelables.close().     } }
false;public,final;0;3;;public final boolean isRunning() {     return isRunning. }
false;public,final;0;3;;public final boolean isCanceled() {     return canceled. }
true;private;0;7;/**  * Execute {@link StreamOperator#open()} of each operator in the chain of this  * {@link StreamTask}. Opening happens from <b>tail to head</b> operator in the chain, contrary  * to {@link StreamOperator#close()} which happens <b>head to tail</b>  * (see {@link #closeAllOperators()}.  */ ;/**  * Execute {@link StreamOperator#open()} of each operator in the chain of this  * {@link StreamTask}. Opening happens from <b>tail to head</b> operator in the chain, contrary  * to {@link StreamOperator#close()} which happens <b>head to tail</b>  * (see {@link #closeAllOperators()}.  */ private void openAllOperators() throws Exception {     for (StreamOperator<?> operator : operatorChain.getAllOperators()) {         if (operator != null) {             operator.open().         }     } }
true;private;0;11;/**  * Execute {@link StreamOperator#close()} of each operator in the chain of this  * {@link StreamTask}. Closing happens from <b>head to tail</b> operator in the chain,  * contrary to {@link StreamOperator#open()} which happens <b>tail to head</b>  * (see {@link #openAllOperators()}.  */ ;/**  * Execute {@link StreamOperator#close()} of each operator in the chain of this  * {@link StreamTask}. Closing happens from <b>head to tail</b> operator in the chain,  * contrary to {@link StreamOperator#open()} which happens <b>tail to head</b>  * (see {@link #openAllOperators()}.  */ private void closeAllOperators() throws Exception {     // We need to close them first to last, since upstream operators in the chain might emit     // elements in their close methods.     StreamOperator<?>[] allOperators = operatorChain.getAllOperators().     for (int i = allOperators.length - 1. i >= 0. i--) {         StreamOperator<?> operator = allOperators[i].         if (operator != null) {             operator.close().         }     } }
true;private;0;7;/**  * Execute {@link StreamOperator#dispose()} of each operator in the chain of this  * {@link StreamTask}. Disposing happens from <b>tail to head</b> operator in the chain.  */ ;/**  * Execute {@link StreamOperator#dispose()} of each operator in the chain of this  * {@link StreamTask}. Disposing happens from <b>tail to head</b> operator in the chain.  */ private void tryDisposeAllOperators() throws Exception {     for (StreamOperator<?> operator : operatorChain.getAllOperators()) {         if (operator != null) {             operator.dispose().         }     } }
false;private;0;5;;private void shutdownAsyncThreads() throws Exception {     if (!asyncOperationsThreadPool.isShutdown()) {         asyncOperationsThreadPool.shutdownNow().     } }
true;private;0;14;/**  * Execute @link StreamOperator#dispose()} of each operator in the chain of this  * {@link StreamTask}. Disposing happens from <b>tail to head</b> operator in the chain.  *  * <p>The difference with the {@link #tryDisposeAllOperators()} is that in case of an  * exception, this method catches it and logs the message.  */ ;/**  * Execute @link StreamOperator#dispose()} of each operator in the chain of this  * {@link StreamTask}. Disposing happens from <b>tail to head</b> operator in the chain.  *  * <p>The difference with the {@link #tryDisposeAllOperators()} is that in case of an  * exception, this method catches it and logs the message.  */ private void disposeAllOperators() {     if (operatorChain != null) {         for (StreamOperator<?> operator : operatorChain.getAllOperators()) {             try {                 if (operator != null) {                     operator.dispose().                 }             } catch (Throwable t) {                 LOG.error("Error during disposal of stream operator.", t).             }         }     } }
true;protected;0;12;/**  * The finalize method shuts down the timer. This is a fail-safe shutdown, in case the original  * shutdown method was never called.  *  * <p>This should not be relied upon! It will cause shutdown to happen much later than if manual  * shutdown is attempted, and cause threads to linger for longer than needed.  */ ;/**  * The finalize method shuts down the timer. This is a fail-safe shutdown, in case the original  * shutdown method was never called.  *  * <p>This should not be relied upon! It will cause shutdown to happen much later than if manual  * shutdown is attempted, and cause threads to linger for longer than needed.  */ @Override protected void finalize() throws Throwable {     super.finalize().     if (timerService != null) {         if (!timerService.isTerminated()) {             LOG.info("Timer service is shutting down.").             timerService.shutdownService().         }     }     cancelables.close(). }
false;;0;4;;boolean isSerializingTimestamps() {     TimeCharacteristic tc = configuration.getTimeCharacteristic().     return tc == TimeCharacteristic.EventTime | tc == TimeCharacteristic.IngestionTime. }
true;public;0;3;/**  * Gets the name of the task, in the form "taskname (2/5)".  * @return The name of the task.  */ ;// ------------------------------------------------------------------------ // Access to properties and utilities // ------------------------------------------------------------------------ /**  * Gets the name of the task, in the form "taskname (2/5)".  * @return The name of the task.  */ public String getName() {     return getEnvironment().getTaskInfo().getTaskNameWithSubtasks(). }
true;public;0;3;/**  * Gets the lock object on which all operations that involve data and state mutation have to lock.  * @return The checkpoint lock object.  */ ;/**  * Gets the lock object on which all operations that involve data and state mutation have to lock.  * @return The checkpoint lock object.  */ public Object getCheckpointLock() {     return lock. }
false;public;0;3;;public CheckpointStorage getCheckpointStorage() {     return checkpointStorage. }
false;public;0;3;;public StreamConfig getConfiguration() {     return configuration. }
false;public;0;3;;public Map<String, Accumulator<?, ?>> getAccumulatorMap() {     return accumulatorMap. }
false;public;0;3;;public StreamStatusMaintainer getStreamStatusMaintainer() {     return operatorChain. }
false;;0;3;;RecordWriterOutput<?>[] getStreamOutputs() {     return operatorChain.getStreamOutputs(). }
false;public;2;22;;// ------------------------------------------------------------------------ // Checkpoint and Restore // ------------------------------------------------------------------------ @Override public boolean triggerCheckpoint(CheckpointMetaData checkpointMetaData, CheckpointOptions checkpointOptions) throws Exception {     try {         // No alignment if we inject a checkpoint         CheckpointMetrics checkpointMetrics = new CheckpointMetrics().setBytesBufferedInAlignment(0L).setAlignmentDurationNanos(0L).         return performCheckpoint(checkpointMetaData, checkpointOptions, checkpointMetrics).     } catch (Exception e) {         // propagate exceptions only if the task is still in "running" state         if (isRunning) {             throw new Exception("Could not perform checkpoint " + checkpointMetaData.getCheckpointId() + " for operator " + getName() + '.', e).         } else {             LOG.debug("Could not perform checkpoint {} for operator {} while the " + "invokable was not in state running.", checkpointMetaData.getCheckpointId(), getName(), e).             return false.         }     } }
false;public;3;19;;@Override public void triggerCheckpointOnBarrier(CheckpointMetaData checkpointMetaData, CheckpointOptions checkpointOptions, CheckpointMetrics checkpointMetrics) throws Exception {     try {         performCheckpoint(checkpointMetaData, checkpointOptions, checkpointMetrics).     } catch (CancelTaskException e) {         LOG.info("Operator {} was cancelled while performing checkpoint {}.", getName(), checkpointMetaData.getCheckpointId()).         throw e.     } catch (Exception e) {         throw new Exception("Could not perform checkpoint " + checkpointMetaData.getCheckpointId() + " for operator " + getName() + '.', e).     } }
false;public;2;12;;@Override public void abortCheckpointOnBarrier(long checkpointId, Throwable cause) throws Exception {     LOG.debug("Aborting checkpoint via cancel-barrier {} for task {}", checkpointId, getName()).     // notify the coordinator that we decline this checkpoint     getEnvironment().declineCheckpoint(checkpointId, cause).     // notify all downstream operators that they should not wait for a barrier from us     synchronized (lock) {         operatorChain.broadcastCheckpointCancelMarker(checkpointId).     } }
false;private;3;59;;private boolean performCheckpoint(CheckpointMetaData checkpointMetaData, CheckpointOptions checkpointOptions, CheckpointMetrics checkpointMetrics) throws Exception {     LOG.debug("Starting checkpoint ({}) {} on task {}", checkpointMetaData.getCheckpointId(), checkpointOptions.getCheckpointType(), getName()).     synchronized (lock) {         if (isRunning) {             // we can do a checkpoint             // All of the following steps happen as an atomic step from the perspective of barriers and             // records/watermarks/timers/callbacks.             // We generally try to emit the checkpoint barrier as soon as possible to not affect downstream             // checkpoint alignments             // Step (1): Prepare the checkpoint, allow operators to do some pre-barrier work.             // The pre-barrier work should be nothing or minimal in the common case.             operatorChain.prepareSnapshotPreBarrier(checkpointMetaData.getCheckpointId()).             // Step (2): Send the checkpoint barrier downstream             operatorChain.broadcastCheckpointBarrier(checkpointMetaData.getCheckpointId(), checkpointMetaData.getTimestamp(), checkpointOptions).             // Step (3): Take the state snapshot. This should be largely asynchronous, to not             // impact progress of the streaming topology             checkpointState(checkpointMetaData, checkpointOptions, checkpointMetrics).             return true.         } else {             // we cannot perform our checkpoint - let the downstream operators know that they             // should not wait for any input from this operator             // we cannot broadcast the cancellation markers on the 'operator chain', because it may not             // yet be created             final CancelCheckpointMarker message = new CancelCheckpointMarker(checkpointMetaData.getCheckpointId()).             Exception exception = null.             for (RecordWriter<SerializationDelegate<StreamRecord<OUT>>> recordWriter : recordWriters) {                 try {                     recordWriter.broadcastEvent(message).                 } catch (Exception e) {                     exception = ExceptionUtils.firstOrSuppressed(new Exception("Could not send cancel checkpoint marker to downstream tasks.", e), exception).                 }             }             if (exception != null) {                 throw exception.             }             return false.         }     } }
false;public;0;3;;public ExecutorService getAsyncOperationsThreadPool() {     return asyncOperationsThreadPool. }
false;public;1;17;;@Override public void notifyCheckpointComplete(long checkpointId) throws Exception {     synchronized (lock) {         if (isRunning) {             LOG.debug("Notification of complete checkpoint for task {}", getName()).             for (StreamOperator<?> operator : operatorChain.getAllOperators()) {                 if (operator != null) {                     operator.notifyCheckpointComplete(checkpointId).                 }             }         } else {             LOG.debug("Ignoring notification of complete checkpoint for not-running task {}", getName()).         }     } }
false;private;0;18;;private void tryShutdownTimerService() {     if (timerService != null && !timerService.isTerminated()) {         try {             final long timeoutMs = getEnvironment().getTaskManagerInfo().getConfiguration().getLong(TaskManagerOptions.TASK_CANCELLATION_TIMEOUT_TIMERS).             if (!timerService.shutdownServiceUninterruptible(timeoutMs)) {                 LOG.warn("Timer service shutdown exceeded time limit of {} ms while waiting for pending " + "timers. Will continue with shutdown procedure.", timeoutMs).             }         } catch (Throwable t) {             // catch and log the exception to not replace the original exception             LOG.error("Could not shut down timer service", t).         }     } }
false;private;3;18;;private void checkpointState(CheckpointMetaData checkpointMetaData, CheckpointOptions checkpointOptions, CheckpointMetrics checkpointMetrics) throws Exception {     CheckpointStreamFactory storage = checkpointStorage.resolveCheckpointStorageLocation(checkpointMetaData.getCheckpointId(), checkpointOptions.getTargetLocation()).     CheckpointingOperation checkpointingOperation = new CheckpointingOperation(this, checkpointMetaData, checkpointOptions, storage, checkpointMetrics).     checkpointingOperation.executeCheckpointing(). }
false;private;0;10;;private void initializeState() throws Exception {     StreamOperator<?>[] allOperators = operatorChain.getAllOperators().     for (StreamOperator<?> operator : allOperators) {         if (null != operator) {             operator.initializeState().         }     } }
false;private;0;9;;// ------------------------------------------------------------------------ // State backend // ------------------------------------------------------------------------ private StateBackend createStateBackend() throws Exception {     final StateBackend fromApplication = configuration.getStateBackend(getUserCodeClassLoader()).     return StateBackendLoader.fromApplicationOrConfigOrDefault(fromApplication, getEnvironment().getTaskManagerInfo().getConfiguration(), getUserCodeClassLoader(), LOG). }
false;protected;0;3;;protected CheckpointExceptionHandlerFactory createCheckpointExceptionHandlerFactory() {     return new CheckpointExceptionHandlerFactory(). }
true;public;0;6;/**  * Returns the {@link ProcessingTimeService} responsible for telling the current  * processing time and registering timers.  */ ;/**  * Returns the {@link ProcessingTimeService} responsible for telling the current  * processing time and registering timers.  */ public ProcessingTimeService getProcessingTimeService() {     if (timerService == null) {         throw new IllegalStateException("The timer service has not been initialized.").     }     return timerService. }
true;public;2;7;/**  * Handles an exception thrown by another thread (e.g. a TriggerTask),  * other than the one executing the main task by failing the task entirely.  *  * <p>In more detail, it marks task execution failed for an external reason  * (a reason other than the task code itself throwing an exception). If the task  * is already in a terminal state (such as FINISHED, CANCELED, FAILED), or if the  * task is already canceling this does nothing. Otherwise it sets the state to  * FAILED, and, if the invokable code is running, starts an asynchronous thread  * that aborts that code.  *  * <p>This method never blocks.  */ ;/**  * Handles an exception thrown by another thread (e.g. a TriggerTask),  * other than the one executing the main task by failing the task entirely.  *  * <p>In more detail, it marks task execution failed for an external reason  * (a reason other than the task code itself throwing an exception). If the task  * is already in a terminal state (such as FINISHED, CANCELED, FAILED), or if the  * task is already canceling this does nothing. Otherwise it sets the state to  * FAILED, and, if the invokable code is running, starts an asynchronous thread  * that aborts that code.  *  * <p>This method never blocks.  */ @Override public void handleAsyncException(String message, Throwable exception) {     if (isRunning) {         // only fail if the task is still running         getEnvironment().failExternally(exception).     } }
false;public;0;4;;// ------------------------------------------------------------------------ // Utilities // ------------------------------------------------------------------------ @Override public String toString() {     return getName(). }
false;public;0;54;;@Override public void run() {     FileSystemSafetyNet.initializeSafetyNetForThread().     try {         TaskStateSnapshot jobManagerTaskOperatorSubtaskStates = new TaskStateSnapshot(operatorSnapshotsInProgress.size()).         TaskStateSnapshot localTaskOperatorSubtaskStates = new TaskStateSnapshot(operatorSnapshotsInProgress.size()).         for (Map.Entry<OperatorID, OperatorSnapshotFutures> entry : operatorSnapshotsInProgress.entrySet()) {             OperatorID operatorID = entry.getKey().             OperatorSnapshotFutures snapshotInProgress = entry.getValue().             // finalize the async part of all by executing all snapshot runnables             OperatorSnapshotFinalizer finalizedSnapshots = new OperatorSnapshotFinalizer(snapshotInProgress).             jobManagerTaskOperatorSubtaskStates.putSubtaskStateByOperatorID(operatorID, finalizedSnapshots.getJobManagerOwnedState()).             localTaskOperatorSubtaskStates.putSubtaskStateByOperatorID(operatorID, finalizedSnapshots.getTaskLocalState()).         }         final long asyncEndNanos = System.nanoTime().         final long asyncDurationMillis = (asyncEndNanos - asyncStartNanos) / 1_000_000L.         checkpointMetrics.setAsyncDurationMillis(asyncDurationMillis).         if (asyncCheckpointState.compareAndSet(CheckpointingOperation.AsyncCheckpointState.RUNNING, CheckpointingOperation.AsyncCheckpointState.COMPLETED)) {             reportCompletedSnapshotStates(jobManagerTaskOperatorSubtaskStates, localTaskOperatorSubtaskStates, asyncDurationMillis).         } else {             LOG.debug("{} - asynchronous part of checkpoint {} could not be completed because it was closed before.", owner.getName(), checkpointMetaData.getCheckpointId()).         }     } catch (Exception e) {         handleExecutionException(e).     } finally {         owner.cancelables.unregisterCloseable(this).         FileSystemSafetyNet.closeSafetyNetAndGuardedResourcesForThread().     } }
false;private;3;29;;private void reportCompletedSnapshotStates(TaskStateSnapshot acknowledgedTaskStateSnapshot, TaskStateSnapshot localTaskStateSnapshot, long asyncDurationMillis) {     TaskStateManager taskStateManager = owner.getEnvironment().getTaskStateManager().     boolean hasAckState = acknowledgedTaskStateSnapshot.hasState().     boolean hasLocalState = localTaskStateSnapshot.hasState().     Preconditions.checkState(hasAckState || !hasLocalState, "Found cached state but no corresponding primary state is reported to the job " + "manager. This indicates a problem.").     // we signal stateless tasks by reporting null, so that there are no attempts to assign empty state     // to stateless tasks on restore. This enables simple job modifications that only concern     // stateless without the need to assign them uids to match their (always empty) states.     taskStateManager.reportTaskStateSnapshots(checkpointMetaData, checkpointMetrics, hasAckState ? acknowledgedTaskStateSnapshot : null, hasLocalState ? localTaskStateSnapshot : null).     LOG.debug("{} - finished asynchronous part of checkpoint {}. Asynchronous duration: {} ms", owner.getName(), checkpointMetaData.getCheckpointId(), asyncDurationMillis).     LOG.trace("{} - reported the following states in snapshot for checkpoint {}: {}.", owner.getName(), checkpointMetaData.getCheckpointId(), acknowledgedTaskStateSnapshot). }
false;private;1;40;;private void handleExecutionException(Exception e) {     boolean didCleanup = false.     CheckpointingOperation.AsyncCheckpointState currentState = asyncCheckpointState.get().     while (CheckpointingOperation.AsyncCheckpointState.DISCARDED != currentState) {         if (asyncCheckpointState.compareAndSet(currentState, CheckpointingOperation.AsyncCheckpointState.DISCARDED)) {             didCleanup = true.             try {                 cleanup().             } catch (Exception cleanupException) {                 e.addSuppressed(cleanupException).             }             Exception checkpointException = new Exception("Could not materialize checkpoint " + checkpointMetaData.getCheckpointId() + " for operator " + owner.getName() + '.', e).             // We only report the exception for the original cause of fail and cleanup.             // Otherwise this followup exception could race the original exception in failing the task.             owner.asynchronousCheckpointExceptionHandler.tryHandleCheckpointException(checkpointMetaData, checkpointException).             currentState = CheckpointingOperation.AsyncCheckpointState.DISCARDED.         } else {             currentState = asyncCheckpointState.get().         }     }     if (!didCleanup) {         LOG.trace("Caught followup exception from a failed checkpoint thread. This can be ignored.", e).     } }
false;public;0;15;;@Override public void close() {     if (asyncCheckpointState.compareAndSet(CheckpointingOperation.AsyncCheckpointState.RUNNING, CheckpointingOperation.AsyncCheckpointState.DISCARDED)) {         try {             cleanup().         } catch (Exception cleanupException) {             LOG.warn("Could not properly clean up the async checkpoint runnable.", cleanupException).         }     } else {         logFailedCleanupAttempt().     } }
false;private;0;23;;private void cleanup() throws Exception {     LOG.debug("Cleanup AsyncCheckpointRunnable for checkpoint {} of {}.", checkpointMetaData.getCheckpointId(), owner.getName()).     Exception exception = null.     // clean up ongoing operator snapshot results and non partitioned state handles     for (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {         if (operatorSnapshotResult != null) {             try {                 operatorSnapshotResult.cancel().             } catch (Exception cancelException) {                 exception = ExceptionUtils.firstOrSuppressed(cancelException, exception).             }         }     }     if (null != exception) {         throw exception.     } }
false;private;0;6;;private void logFailedCleanupAttempt() {     LOG.debug("{} - asynchronous checkpointing operation for checkpoint {} has " + "already been completed. Thus, the state handles are not cleaned up.", owner.getName(), checkpointMetaData.getCheckpointId()). }
false;public;0;3;;public CloseableRegistry getCancelables() {     return cancelables. }
false;public;0;58;;public void executeCheckpointing() throws Exception {     startSyncPartNano = System.nanoTime().     try {         for (StreamOperator<?> op : allOperators) {             checkpointStreamOperator(op).         }         if (LOG.isDebugEnabled()) {             LOG.debug("Finished synchronous checkpoints for checkpoint {} on task {}", checkpointMetaData.getCheckpointId(), owner.getName()).         }         startAsyncPartNano = System.nanoTime().         checkpointMetrics.setSyncDurationMillis((startAsyncPartNano - startSyncPartNano) / 1_000_000).         // we are transferring ownership over snapshotInProgressList for cleanup to the thread, active on submit         AsyncCheckpointRunnable asyncCheckpointRunnable = new AsyncCheckpointRunnable(owner, operatorSnapshotsInProgress, checkpointMetaData, checkpointMetrics, startAsyncPartNano).         owner.cancelables.registerCloseable(asyncCheckpointRunnable).         owner.asyncOperationsThreadPool.submit(asyncCheckpointRunnable).         if (LOG.isDebugEnabled()) {             LOG.debug("{} - finished synchronous part of checkpoint {}. " + "Alignment duration: {} ms, snapshot duration {} ms", owner.getName(), checkpointMetaData.getCheckpointId(), checkpointMetrics.getAlignmentDurationNanos() / 1_000_000, checkpointMetrics.getSyncDurationMillis()).         }     } catch (Exception ex) {         // Cleanup to release resources         for (OperatorSnapshotFutures operatorSnapshotResult : operatorSnapshotsInProgress.values()) {             if (null != operatorSnapshotResult) {                 try {                     operatorSnapshotResult.cancel().                 } catch (Exception e) {                     LOG.warn("Could not properly cancel an operator snapshot result.", e).                 }             }         }         if (LOG.isDebugEnabled()) {             LOG.debug("{} - did NOT finish synchronous part of checkpoint {}. " + "Alignment duration: {} ms, snapshot duration {} ms", owner.getName(), checkpointMetaData.getCheckpointId(), checkpointMetrics.getAlignmentDurationNanos() / 1_000_000, checkpointMetrics.getSyncDurationMillis()).         }         owner.synchronousCheckpointExceptionHandler.tryHandleCheckpointException(checkpointMetaData, ex).     } }
false;private;1;12;;@SuppressWarnings("deprecation") private void checkpointStreamOperator(StreamOperator<?> op) throws Exception {     if (null != op) {         OperatorSnapshotFutures snapshotInProgress = op.snapshotState(checkpointMetaData.getCheckpointId(), checkpointMetaData.getTimestamp(), checkpointOptions, storageLocation).         operatorSnapshotsInProgress.put(op.getOperatorID(), snapshotInProgress).     } }
false;public;2;9;;@Override public void tryHandleCheckpointException(CheckpointMetaData checkpointMetaData, Exception exception) {     try {         synchronousCheckpointExceptionHandler.tryHandleCheckpointException(checkpointMetaData, exception).     } catch (Exception unhandled) {         AsynchronousException asyncException = new AsynchronousException(unhandled).         owner.handleAsyncException("Failure in asynchronous checkpoint materialization", asyncException).     } }
false;public,static;2;20;;@VisibleForTesting public static <OUT> List<RecordWriter<SerializationDelegate<StreamRecord<OUT>>>> createRecordWriters(StreamConfig configuration, Environment environment) {     List<RecordWriter<SerializationDelegate<StreamRecord<OUT>>>> recordWriters = new ArrayList<>().     List<StreamEdge> outEdgesInOrder = configuration.getOutEdgesInOrder(environment.getUserClassLoader()).     Map<Integer, StreamConfig> chainedConfigs = configuration.getTransitiveChainedTaskConfigsWithSelf(environment.getUserClassLoader()).     for (int i = 0. i < outEdgesInOrder.size(). i++) {         StreamEdge edge = outEdgesInOrder.get(i).         recordWriters.add(createRecordWriter(edge, i, environment, environment.getTaskInfo().getTaskName(), chainedConfigs.get(edge.getSourceId()).getBufferTimeout())).     }     return recordWriters. }
false;private,static;5;26;;private static <OUT> RecordWriter<SerializationDelegate<StreamRecord<OUT>>> createRecordWriter(StreamEdge edge, int outputIndex, Environment environment, String taskName, long bufferTimeout) {     @SuppressWarnings("unchecked")     StreamPartitioner<OUT> outputPartitioner = (StreamPartitioner<OUT>) edge.getPartitioner().     LOG.debug("Using partitioner {} for output {} of task {}", outputPartitioner, outputIndex, taskName).     ResultPartitionWriter bufferWriter = environment.getWriter(outputIndex).     // we initialize the partitioner here with the number of key groups (aka max. parallelism)     if (outputPartitioner instanceof ConfigurableStreamPartitioner) {         int numKeyGroups = bufferWriter.getNumTargetKeyGroups().         if (0 < numKeyGroups) {             ((ConfigurableStreamPartitioner) outputPartitioner).configure(numKeyGroups).         }     }     RecordWriter<SerializationDelegate<StreamRecord<OUT>>> output = RecordWriter.createRecordWriter(bufferWriter, outputPartitioner, bufferTimeout, taskName).     output.setMetricGroup(environment.getMetricGroup().getIOMetricGroup()).     return output. }
