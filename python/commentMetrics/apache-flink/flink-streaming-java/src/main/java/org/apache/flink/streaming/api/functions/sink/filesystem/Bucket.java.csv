commented;modifiers;parameterAmount;loc;comment;code
false;private;1;23;;private void restoreInProgressFile(final BucketState<BucketID> state) throws IOException {     if (!state.hasInProgressResumableFile()) {         return.     }     // we try to resume the previous in-progress file     final ResumeRecoverable resumable = state.getInProgressResumableFile().     if (fsWriter.supportsResume()) {         final RecoverableFsDataOutputStream stream = fsWriter.recover(resumable).         inProgressPart = partFileFactory.resumeFrom(bucketId, stream, resumable, state.getInProgressFileCreationTime()).     } else {         // if the writer does not support resume, then we close the         // in-progress part and commit it, as done in the case of pending files.         fsWriter.recoverForCommit(resumable).commitAfterRecovery().     }     if (fsWriter.requiresCleanupOfRecoverableState()) {         fsWriter.cleanupRecoverableState(resumable).     } }
false;private;1;9;;private void commitRecoveredPendingFiles(final BucketState<BucketID> state) throws IOException {     // we commit pending files for checkpoints that precess the last successful one, from which we are recovering     for (List<CommitRecoverable> committables : state.getCommittableFilesPerCheckpoint().values()) {         for (CommitRecoverable committable : committables) {             fsWriter.recoverForCommit(committable).commitAfterRecovery().         }     } }
false;;0;3;;BucketID getBucketId() {     return bucketId. }
false;;0;3;;Path getBucketPath() {     return bucketPath. }
false;;0;3;;long getPartCounter() {     return partCounter. }
false;;0;3;;boolean isActive() {     return inProgressPart != null || !pendingPartsForCurrentCheckpoint.isEmpty() || !pendingPartsPerCheckpoint.isEmpty(). }
false;;1;22;;void merge(final Bucket<IN, BucketID> bucket) throws IOException {     checkNotNull(bucket).     checkState(Objects.equals(bucket.bucketPath, bucketPath)).     // There should be no pending files in the "to-merge" states.     // The reason is that:     // 1) the pendingPartsForCurrentCheckpoint is emptied whenever we take a snapshot (see prepareBucketForCheckpointing()).     // So a snapshot, including the one we are recovering from, will never contain such files.     // 2) the files in pendingPartsPerCheckpoint are committed upon recovery (see commitRecoveredPendingFiles()).     checkState(bucket.pendingPartsForCurrentCheckpoint.isEmpty()).     checkState(bucket.pendingPartsPerCheckpoint.isEmpty()).     CommitRecoverable committable = bucket.closePartFile().     if (committable != null) {         pendingPartsForCurrentCheckpoint.add(committable).     }     if (LOG.isDebugEnabled()) {         LOG.debug("Subtask {} merging buckets for bucket id={}", subtaskIndex, bucketId).     } }
false;;2;12;;void write(IN element, long currentTime) throws IOException {     if (inProgressPart == null || rollingPolicy.shouldRollOnEvent(inProgressPart, element)) {         if (LOG.isDebugEnabled()) {             LOG.debug("Subtask {} closing in-progress part file for bucket id={} due to element {}.", subtaskIndex, bucketId, element).         }         rollPartFile(currentTime).     }     inProgressPart.write(element, currentTime). }
false;private;1;14;;private void rollPartFile(final long currentTime) throws IOException {     closePartFile().     final Path partFilePath = assembleNewPartPath().     final RecoverableFsDataOutputStream stream = fsWriter.open(partFilePath).     inProgressPart = partFileFactory.openNew(bucketId, stream, partFilePath, currentTime).     if (LOG.isDebugEnabled()) {         LOG.debug("Subtask {} opening new part file \"{}\" for bucket id={}.", subtaskIndex, partFilePath.getName(), bucketId).     }     partCounter++. }
false;private;0;3;;private Path assembleNewPartPath() {     return new Path(bucketPath, PART_PREFIX + '-' + subtaskIndex + '-' + partCounter). }
false;private;0;9;;private CommitRecoverable closePartFile() throws IOException {     CommitRecoverable committable = null.     if (inProgressPart != null) {         committable = inProgressPart.closeForCommit().         pendingPartsForCurrentCheckpoint.add(committable).         inProgressPart = null.     }     return committable. }
false;;0;5;;void disposePartFile() {     if (inProgressPart != null) {         inProgressPart.dispose().     } }
false;;1;22;;BucketState<BucketID> onReceptionOfCheckpoint(long checkpointId) throws IOException {     prepareBucketForCheckpointing(checkpointId).     ResumeRecoverable inProgressResumable = null.     long inProgressFileCreationTime = Long.MAX_VALUE.     if (inProgressPart != null) {         inProgressResumable = inProgressPart.persist().         inProgressFileCreationTime = inProgressPart.getCreationTime().         if (fsWriter.requiresCleanupOfRecoverableState()) {             this.resumablesPerCheckpoint.put(checkpointId, inProgressResumable).         }     }     return new BucketState<>(bucketId, bucketPath, inProgressFileCreationTime, inProgressResumable, pendingPartsPerCheckpoint). }
false;private;1;13;;private void prepareBucketForCheckpointing(long checkpointId) throws IOException {     if (inProgressPart != null && rollingPolicy.shouldRollOnCheckpoint(inProgressPart)) {         if (LOG.isDebugEnabled()) {             LOG.debug("Subtask {} closing in-progress part file for bucket id={} on checkpoint.", subtaskIndex, bucketId).         }         closePartFile().     }     if (!pendingPartsForCurrentCheckpoint.isEmpty()) {         pendingPartsPerCheckpoint.put(checkpointId, pendingPartsForCurrentCheckpoint).         pendingPartsForCurrentCheckpoint = new ArrayList<>().     } }
false;;1;18;;void onSuccessfulCompletionOfCheckpoint(long checkpointId) throws IOException {     checkNotNull(fsWriter).     Iterator<Map.Entry<Long, List<CommitRecoverable>>> it = pendingPartsPerCheckpoint.headMap(checkpointId, true).entrySet().iterator().     while (it.hasNext()) {         Map.Entry<Long, List<CommitRecoverable>> entry = it.next().         for (CommitRecoverable committable : entry.getValue()) {             fsWriter.recoverForCommit(committable).commit().         }         it.remove().     }     cleanupOutdatedResumables(checkpointId). }
false;private;1;15;;private void cleanupOutdatedResumables(long checkpointId) throws IOException {     Iterator<Map.Entry<Long, ResumeRecoverable>> it = resumablesPerCheckpoint.headMap(checkpointId, false).entrySet().iterator().     while (it.hasNext()) {         final ResumeRecoverable recoverable = it.next().getValue().         final boolean successfullyDeleted = fsWriter.cleanupRecoverableState(recoverable).         it.remove().         if (LOG.isDebugEnabled() && successfullyDeleted) {             LOG.debug("Subtask {} successfully deleted incomplete part for bucket id={}.", subtaskIndex, bucketId).         }     } }
false;;1;10;;void onProcessingTime(long timestamp) throws IOException {     if (inProgressPart != null && rollingPolicy.shouldRollOnProcessingTime(inProgressPart, timestamp)) {         if (LOG.isDebugEnabled()) {             LOG.debug("Subtask {} closing in-progress part file for bucket id={} due to processing time rolling policy " + "(in-progress file created @ {}, last updated @ {} and current time is {}).", subtaskIndex, bucketId, inProgressPart.getCreationTime(), inProgressPart.getLastUpdateTime(), timestamp).         }         closePartFile().     } }
false;;0;4;;// --------------------------- Testing Methods ----------------------------- @VisibleForTesting Map<Long, List<CommitRecoverable>> getPendingPartsPerCheckpoint() {     return pendingPartsPerCheckpoint. }
false;;0;5;;@Nullable @VisibleForTesting PartFileWriter<IN, BucketID> getInProgressPart() {     return inProgressPart. }
false;;0;4;;@VisibleForTesting List<CommitRecoverable> getPendingPartsForCurrentCheckpoint() {     return pendingPartsForCurrentCheckpoint. }
true;static;7;10;/**  * Creates a new empty {@code Bucket}.  * @param fsWriter the filesystem-specific {@link RecoverableWriter}.  * @param subtaskIndex the index of the subtask creating the bucket.  * @param bucketId the identifier of the bucket, as returned by the {@link BucketAssigner}.  * @param bucketPath the path to where the part files for the bucket will be written to.  * @param initialPartCounter the initial counter for the part files of the bucket.  * @param partFileFactory the {@link PartFileWriter.PartFileFactory} the factory creating part file writers.  * @param <IN> the type of input elements to the sink.  * @param <BucketID> the type of the identifier of the bucket, as returned by the {@link BucketAssigner}  * @return The new Bucket.  */ ;// --------------------------- Static Factory Methods ----------------------------- /**  * Creates a new empty {@code Bucket}.  * @param fsWriter the filesystem-specific {@link RecoverableWriter}.  * @param subtaskIndex the index of the subtask creating the bucket.  * @param bucketId the identifier of the bucket, as returned by the {@link BucketAssigner}.  * @param bucketPath the path to where the part files for the bucket will be written to.  * @param initialPartCounter the initial counter for the part files of the bucket.  * @param partFileFactory the {@link PartFileWriter.PartFileFactory} the factory creating part file writers.  * @param <IN> the type of input elements to the sink.  * @param <BucketID> the type of the identifier of the bucket, as returned by the {@link BucketAssigner}  * @return The new Bucket.  */ static <IN, BucketID> Bucket<IN, BucketID> getNew(final RecoverableWriter fsWriter, final int subtaskIndex, final BucketID bucketId, final Path bucketPath, final long initialPartCounter, final PartFileWriter.PartFileFactory<IN, BucketID> partFileFactory, final RollingPolicy<IN, BucketID> rollingPolicy) {     return new Bucket<>(fsWriter, subtaskIndex, bucketId, bucketPath, initialPartCounter, partFileFactory, rollingPolicy). }
true;static;6;9;/**  * Restores a {@code Bucket} from the state included in the provided {@link BucketState}.  * @param fsWriter the filesystem-specific {@link RecoverableWriter}.  * @param subtaskIndex the index of the subtask creating the bucket.  * @param initialPartCounter the initial counter for the part files of the bucket.  * @param partFileFactory the {@link PartFileWriter.PartFileFactory} the factory creating part file writers.  * @param bucketState the initial state of the restored bucket.  * @param <IN> the type of input elements to the sink.  * @param <BucketID> the type of the identifier of the bucket, as returned by the {@link BucketAssigner}  * @return The restored Bucket.  */ ;/**  * Restores a {@code Bucket} from the state included in the provided {@link BucketState}.  * @param fsWriter the filesystem-specific {@link RecoverableWriter}.  * @param subtaskIndex the index of the subtask creating the bucket.  * @param initialPartCounter the initial counter for the part files of the bucket.  * @param partFileFactory the {@link PartFileWriter.PartFileFactory} the factory creating part file writers.  * @param bucketState the initial state of the restored bucket.  * @param <IN> the type of input elements to the sink.  * @param <BucketID> the type of the identifier of the bucket, as returned by the {@link BucketAssigner}  * @return The restored Bucket.  */ static <IN, BucketID> Bucket<IN, BucketID> restore(final RecoverableWriter fsWriter, final int subtaskIndex, final long initialPartCounter, final PartFileWriter.PartFileFactory<IN, BucketID> partFileFactory, final RollingPolicy<IN, BucketID> rollingPolicy, final BucketState<BucketID> bucketState) throws IOException {     return new Bucket<>(fsWriter, subtaskIndex, initialPartCounter, partFileFactory, rollingPolicy, bucketState). }
