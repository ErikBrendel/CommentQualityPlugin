commented;modifiers;parameterAmount;loc;comment;code
false;static;5;32;;static OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createRescalingTestSink(File outDir, int totalParallelism, int taskIdx, long inactivityInterval, long partMaxSize) throws Exception {     final RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy = DefaultRollingPolicy.create().withMaxPartSize(partMaxSize).withRolloverInterval(inactivityInterval).withInactivityInterval(inactivityInterval).build().     final BucketAssigner<Tuple2<String, Integer>, String> bucketer = new TupleToStringBucketer().     final Encoder<Tuple2<String, Integer>> encoder = (element, stream) -> {         stream.write((element.f0 + '@' + element.f1).getBytes(StandardCharsets.UTF_8)).         stream.write('\n').     }.     return createCustomRescalingTestSink(outDir, totalParallelism, taskIdx, 10L, bucketer, encoder, rollingPolicy, new DefaultBucketFactoryImpl<>()). }
false;static;8;20;;static OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createCustomRescalingTestSink(final File outDir, final int totalParallelism, final int taskIdx, final long bucketCheckInterval, final BucketAssigner<Tuple2<String, Integer>, String> bucketer, final Encoder<Tuple2<String, Integer>> writer, final RollingPolicy<Tuple2<String, Integer>, String> rollingPolicy, final BucketFactory<Tuple2<String, Integer>, String> bucketFactory) throws Exception {     StreamingFileSink<Tuple2<String, Integer>> sink = StreamingFileSink.forRowFormat(new Path(outDir.toURI()), writer).withBucketAssigner(bucketer).withRollingPolicy(rollingPolicy).withBucketCheckInterval(bucketCheckInterval).withBucketFactory(bucketFactory).build().     return new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink), MAX_PARALLELISM, totalParallelism, taskIdx). }
false;static;7;18;;static OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Object> createTestSinkWithBulkEncoder(final File outDir, final int totalParallelism, final int taskIdx, final long bucketCheckInterval, final BucketAssigner<Tuple2<String, Integer>, String> bucketer, final BulkWriter.Factory<Tuple2<String, Integer>> writer, final BucketFactory<Tuple2<String, Integer>, String> bucketFactory) throws Exception {     StreamingFileSink<Tuple2<String, Integer>> sink = StreamingFileSink.forBulkFormat(new Path(outDir.toURI()), writer).withBucketAssigner(bucketer).withBucketCheckInterval(bucketCheckInterval).withBucketFactory(bucketFactory).build().     return new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink), MAX_PARALLELISM, totalParallelism, taskIdx). }
false;static;3;19;;static void checkLocalFs(File outDir, int expectedInProgress, int expectedCompleted) {     int inProgress = 0.     int finished = 0.     for (File file : FileUtils.listFiles(outDir, null, true)) {         if (file.getAbsolutePath().endsWith("crc")) {             continue.         }         if (file.toPath().getFileName().toString().startsWith(".")) {             inProgress++.         } else {             finished++.         }     }     Assert.assertEquals(expectedInProgress, inProgress).     Assert.assertEquals(expectedCompleted, finished). }
false;static;1;9;;static Map<File, String> getFileContentByPath(File directory) throws IOException {     Map<File, String> contents = new HashMap<>(4).     final Collection<File> filesInBucket = FileUtils.listFiles(directory, null, true).     for (File file : filesInBucket) {         contents.put(file, FileUtils.readFileToString(file)).     }     return contents. }
false;public;2;4;;@Override public String getBucketId(Tuple2<String, Integer> element, Context context) {     return element.f0. }
false;public;0;4;;@Override public SimpleVersionedSerializer<String> getSerializer() {     return SimpleVersionedStringSerializer.INSTANCE. }
false;public;2;4;;@Override public String getBucketId(String element, BucketAssigner.Context context) {     return element. }
false;public;0;4;;@Override public SimpleVersionedSerializer<String> getSerializer() {     return SimpleVersionedStringSerializer.INSTANCE. }
false;public;0;4;;@Override public long currentProcessingTime() {     return processingTime. }
false;public;0;4;;@Override public long currentWatermark() {     return watermark. }
false;public;0;5;;@Nullable @Override public Long timestamp() {     return elementTimestamp. }
false;public;0;3;;public List<T> getBackingList() {     return backingList. }
false;public;1;5;;@Override public void update(List<T> values) {     backingList.clear().     addAll(values). }
false;public;1;4;;@Override public void addAll(List<T> values) {     backingList.addAll(values). }
false;public;0;5;;@Nonnull @Override public Iterator<T> iterator() {     return backingList.iterator(). }
false;public;0;11;;@Override public Iterable<T> get() {     return new Iterable<T>() {          @Nonnull         @Override         public Iterator<T> iterator() {             return backingList.iterator().         }     }. }
false;public;1;4;;@Override public void add(T value) {     backingList.add(value). }
false;public;0;4;;@Override public void clear() {     backingList.clear(). }
