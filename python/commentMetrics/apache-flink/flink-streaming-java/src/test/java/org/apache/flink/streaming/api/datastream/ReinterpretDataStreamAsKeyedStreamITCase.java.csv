commented;modifiers;parameterAmount;loc;comment;code
true;public;0;39;/**  * This test checks that reinterpreting a data stream to a keyed stream works as expected. This test consists of  * two jobs. The first job materializes a keyBy into files, one files per partition. The second job opens the  * files created by the first jobs as sources (doing the correct assignment of files to partitions) and  * reinterprets the sources as keyed, because we know they have been partitioned in a keyBy from the first job.  */ ;/**  * This test checks that reinterpreting a data stream to a keyed stream works as expected. This test consists of  * two jobs. The first job materializes a keyBy into files, one files per partition. The second job opens the  * files created by the first jobs as sources (doing the correct assignment of files to partitions) and  * reinterprets the sources as keyed, because we know they have been partitioned in a keyBy from the first job.  */ @Test public void testReinterpretAsKeyedStream() throws Exception {     final int maxParallelism = 8.     final int numEventsPerInstance = 100.     final int parallelism = 3.     final int numTotalEvents = numEventsPerInstance * parallelism.     final int numUniqueKeys = 100.     final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment().     env.setStreamTimeCharacteristic(TimeCharacteristic.IngestionTime).     env.setMaxParallelism(maxParallelism).     env.setParallelism(parallelism).     env.enableCheckpointing(100).     env.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0L)).     final List<File> partitionFiles = new ArrayList<>(parallelism).     for (int i = 0. i < parallelism. ++i) {         File partitionFile = temporaryFolder.newFile().         partitionFiles.add(i, partitionFile).     }     env.addSource(new RandomTupleSource(numEventsPerInstance, numUniqueKeys)).keyBy(0).addSink(new ToPartitionFileSink(partitionFiles)).     env.execute().     DataStreamUtils.reinterpretAsKeyedStream(env.addSource(new FromPartitionFileSource(partitionFiles)), (KeySelector<Tuple2<Integer, Integer>, Integer>) value -> value.f0, TypeInformation.of(Integer.class)).timeWindow(// test that also timers and aggregated state work as expected     Time.seconds(1)).reduce((ReduceFunction<Tuple2<Integer, Integer>>) (value1, value2) -> new Tuple2<>(value1.f0, value1.f1 + value2.f1)).addSink(new ValidatingSink(numTotalEvents)).setParallelism(1).     env.execute(). }
false;public;1;10;;@Override public void run(SourceContext<Tuple2<Integer, Integer>> out) throws Exception {     Random random = new Random(42).     while (remainingEvents > 0) {         synchronized (out.getCheckpointLock()) {             out.collect(new Tuple2<>(random.nextInt(numKeys), 1)).             --remainingEvents.         }     } }
false;public;0;4;;@Override public void cancel() {     this.remainingEvents = 0. }
false;public;1;8;;@Override public void open(Configuration parameters) throws Exception {     super.open(parameters).     int subtaskIdx = getRuntimeContext().getIndexOfThisSubtask().     dos = new DataOutputStream(new BufferedOutputStream(new FileOutputStream(allPartitions.get(subtaskIdx)))). }
false;public;0;5;;@Override public void close() throws Exception {     super.close().     dos.close(). }
false;public;2;5;;@Override public void invoke(Tuple2<Integer, Integer> value, Context context) throws Exception {     dos.writeInt(value.f0).     dos.writeInt(value.f1). }
false;public;1;16;;@Override public void open(Configuration parameters) throws Exception {     super.open(parameters).     int subtaskIdx = getRuntimeContext().getIndexOfThisSubtask().     File partitionFile = allPartitions.get(subtaskIdx).     fileLength = partitionFile.length().     waitForFailurePos = fileLength * 3 / 4.     din = new DataInputStream(new BufferedInputStream(new FileInputStream(partitionFile))).     long toSkip = position.     while (toSkip > 0L) {         toSkip -= din.skip(toSkip).     } }
false;public;0;5;;@Override public void close() throws Exception {     super.close().     din.close(). }
false;public;1;24;;@Override public void run(SourceContext<Tuple2<Integer, Integer>> out) throws Exception {     running = true.     while (running && hasMoreDataToRead()) {         synchronized (out.getCheckpointLock()) {             Integer key = din.readInt().             Integer val = din.readInt().             out.collect(new Tuple2<>(key, val)).             position += 2 * Integer.BYTES.         }         if (shouldWaitForCompletedCheckpointAndFailNow()) {             while (!canFail) {                 // wait for a checkpoint to complete                 Thread.sleep(10L).             }             throw new Exception("Artificial failure.").         }     } }
false;private;0;3;;private boolean shouldWaitForCompletedCheckpointAndFailNow() {     return !isRestored && position > waitForFailurePos. }
false;private;0;3;;private boolean hasMoreDataToRead() {     return position < fileLength. }
false;public;0;4;;@Override public void cancel() {     this.running = false. }
false;public;1;4;;@Override public void notifyCheckpointComplete(long checkpointId) {     canFail = !isRestored. }
false;public;1;5;;@Override public void snapshotState(FunctionSnapshotContext context) throws Exception {     positionState.clear().     positionState.add(position). }
false;public;1;14;;@Override public void initializeState(FunctionInitializationContext context) throws Exception {     canFail = false.     position = 0L.     isRestored = context.isRestored().     positionState = context.getOperatorStateStore().getListState(new ListStateDescriptor<>("posState", Long.class)).     if (isRestored) {         for (long value : positionState.get()) {             position += value.         }     } }
false;public;1;5;;@Override public void open(Configuration parameters) throws Exception {     super.open(parameters).     Preconditions.checkState(getRuntimeContext().getNumberOfParallelSubtasks() == 1). }
false;public;2;4;;@Override public void invoke(Tuple2<Integer, Integer> value, Context context) throws Exception {     runningSum += value.f1. }
false;public;0;5;;@Override public void close() throws Exception {     Assert.assertEquals(expectedSum, runningSum).     super.close(). }
false;public;1;5;;@Override public void snapshotState(FunctionSnapshotContext context) throws Exception {     sumState.clear().     sumState.add(runningSum). }
false;public;1;11;;@Override public void initializeState(FunctionInitializationContext context) throws Exception {     sumState = context.getOperatorStateStore().getListState(new ListStateDescriptor<>("sumState", Integer.class)).     if (context.isRestored()) {         for (int value : sumState.get()) {             runningSum += value.         }     } }
