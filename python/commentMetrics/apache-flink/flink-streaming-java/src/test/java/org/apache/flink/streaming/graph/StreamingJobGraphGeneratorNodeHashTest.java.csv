# id;timestamp;commentText;codeText;commentWords;codeWords
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterSourceUnchaining() throws Exception;1452526242;Tests that (un)chaining affects the node hash (for sources).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterSourceUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID sourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID unchainedSourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		assertNotEquals(sourceId, unchainedSourceId)__	};tests,that,un,chaining,affects,the,node,hash,for,sources,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,source,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,unchained,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,assert,not,equals,source,id,unchained,source,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterSourceUnchaining() throws Exception;1456427030;Tests that (un)chaining affects the node hash (for sources).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterSourceUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID sourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID unchainedSourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		assertNotEquals(sourceId, unchainedSourceId)__	};tests,that,un,chaining,affects,the,node,hash,for,sources,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,source,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,unchained,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,assert,not,equals,source,id,unchained,source,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterSourceUnchaining() throws Exception;1467726666;Tests that (un)chaining affects the node hash (for sources).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterSourceUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID sourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID unchainedSourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		assertNotEquals(sourceId, unchainedSourceId)__	};tests,that,un,chaining,affects,the,node,hash,for,sources,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,source,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,unchained,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,assert,not,equals,source,id,unchained,source,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterSourceUnchaining() throws Exception;1472663071;Tests that (un)chaining affects the node hash (for sources).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterSourceUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID sourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID unchainedSourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		assertNotEquals(sourceId, unchainedSourceId)__	};tests,that,un,chaining,affects,the,node,hash,for,sources,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,source,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,unchained,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,assert,not,equals,source,id,unchained,source,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterSourceUnchaining() throws Exception;1485181339;Tests that (un)chaining affects the node hash (for sources).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterSourceUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID sourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID unchainedSourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		assertNotEquals(sourceId, unchainedSourceId)__	};tests,that,un,chaining,affects,the,node,hash,for,sources,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,source,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,unchained,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,assert,not,equals,source,id,unchained,source,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterSourceUnchaining() throws Exception;1493403095;Tests that (un)chaining affects the node hash (for sources).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterSourceUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID sourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID unchainedSourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		assertNotEquals(sourceId, unchainedSourceId)__	};tests,that,un,chaining,affects,the,node,hash,for,sources,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,source,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,unchained,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,assert,not,equals,source,id,unchained,source,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterSourceUnchaining() throws Exception;1495484544;Tests that (un)chaining affects the node hash (for sources).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__<p>The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterSourceUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID sourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID unchainedSourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		assertNotEquals(sourceId, unchainedSourceId)__	};tests,that,un,chaining,affects,the,node,hash,for,sources,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,p,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,source,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,unchained,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,assert,not,equals,source,id,unchained,source,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterSourceUnchaining() throws Exception;1503598628;Tests that (un)chaining affects the node hash (for sources).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__<p>The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterSourceUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID sourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction())_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID unchainedSourceId = jobGraph.getVerticesSortedTopologicallyFromSources()_				.get(0).getID()___		assertNotEquals(sourceId, unchainedSourceId)__	};tests,that,un,chaining,affects,the,node,hash,for,sources,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,p,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,source,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,unchained,source,id,job,graph,get,vertices,sorted,topologically,from,sources,get,0,get,id,assert,not,equals,source,id,unchained,source,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignmentForIntermediateNodeInChain() throws Exception;1493403095;Tests that a manual hash for an intermediate chain node is accepted.;@Test_	public void testManualHashAssignmentForIntermediateNodeInChain() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction()).uid("map")_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,for,an,intermediate,chain,node,is,accepted;test,public,void,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,uid,map,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignmentForIntermediateNodeInChain() throws Exception;1495484544;Tests that a manual hash for an intermediate chain node is accepted.;@Test_	public void testManualHashAssignmentForIntermediateNodeInChain() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction()).uid("map")_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,for,an,intermediate,chain,node,is,accepted;test,public,void,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,uid,map,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignmentForIntermediateNodeInChain() throws Exception;1503598628;Tests that a manual hash for an intermediate chain node is accepted.;@Test_	public void testManualHashAssignmentForIntermediateNodeInChain() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction()).uid("map")_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,for,an,intermediate,chain,node,is,accepted;test,public,void,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,uid,map,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = UnsupportedOperationException.class) 	public void testManualHashAssignmentForIntermediateNodeInChainThrowsException() throws Exception;1452526242;Tests that a manual hash for an intermediate chain node throws an Exception.;@Test(expected = UnsupportedOperationException.class)_	public void testManualHashAssignmentForIntermediateNodeInChainThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction()).uid("map")_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,for,an,intermediate,chain,node,throws,an,exception;test,expected,unsupported,operation,exception,class,public,void,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,uid,map,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = UnsupportedOperationException.class) 	public void testManualHashAssignmentForIntermediateNodeInChainThrowsException() throws Exception;1456427030;Tests that a manual hash for an intermediate chain node throws an Exception.;@Test(expected = UnsupportedOperationException.class)_	public void testManualHashAssignmentForIntermediateNodeInChainThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction()).uid("map")_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,for,an,intermediate,chain,node,throws,an,exception;test,expected,unsupported,operation,exception,class,public,void,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,uid,map,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = UnsupportedOperationException.class) 	public void testManualHashAssignmentForIntermediateNodeInChainThrowsException() throws Exception;1467726666;Tests that a manual hash for an intermediate chain node throws an Exception.;@Test(expected = UnsupportedOperationException.class)_	public void testManualHashAssignmentForIntermediateNodeInChainThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction()).uid("map")_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,for,an,intermediate,chain,node,throws,an,exception;test,expected,unsupported,operation,exception,class,public,void,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,uid,map,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = UnsupportedOperationException.class) 	public void testManualHashAssignmentForIntermediateNodeInChainThrowsException() throws Exception;1472663071;Tests that a manual hash for an intermediate chain node throws an Exception.;@Test(expected = UnsupportedOperationException.class)_	public void testManualHashAssignmentForIntermediateNodeInChainThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction()).uid("map")_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,for,an,intermediate,chain,node,throws,an,exception;test,expected,unsupported,operation,exception,class,public,void,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,uid,map,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = UnsupportedOperationException.class) 	public void testManualHashAssignmentForIntermediateNodeInChainThrowsException() throws Exception;1485181339;Tests that a manual hash for an intermediate chain node throws an Exception.;@Test(expected = UnsupportedOperationException.class)_	public void testManualHashAssignmentForIntermediateNodeInChainThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction()).uid("map")_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,for,an,intermediate,chain,node,throws,an,exception;test,expected,unsupported,operation,exception,class,public,void,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,uid,map,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1452526242;Verifies that each {@link JobVertexID} of the {@link JobGraph} is contained in the given map_and mapped to the same vertex name.;private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			String expectedName = ids.get(vertex.getID())__			assertNotNull(expectedName)__			assertEquals(expectedName, vertex.getName())__		}_	};verifies,that,each,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map,and,mapped,to,the,same,vertex,name;private,void,verify,ids,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,string,expected,name,ids,get,vertex,get,id,assert,not,null,expected,name,assert,equals,expected,name,vertex,get,name
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1456427030;Verifies that each {@link JobVertexID} of the {@link JobGraph} is contained in the given map_and mapped to the same vertex name.;private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			String expectedName = ids.get(vertex.getID())__			assertNotNull(expectedName)__			assertEquals(expectedName, vertex.getName())__		}_	};verifies,that,each,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map,and,mapped,to,the,same,vertex,name;private,void,verify,ids,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,string,expected,name,ids,get,vertex,get,id,assert,not,null,expected,name,assert,equals,expected,name,vertex,get,name
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1467726666;Verifies that each {@link JobVertexID} of the {@link JobGraph} is contained in the given map_and mapped to the same vertex name.;private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			String expectedName = ids.get(vertex.getID())__			assertNotNull(expectedName)__			assertEquals(expectedName, vertex.getName())__		}_	};verifies,that,each,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map,and,mapped,to,the,same,vertex,name;private,void,verify,ids,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,string,expected,name,ids,get,vertex,get,id,assert,not,null,expected,name,assert,equals,expected,name,vertex,get,name
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1472663071;Verifies that each {@link JobVertexID} of the {@link JobGraph} is contained in the given map_and mapped to the same vertex name.;private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			String expectedName = ids.get(vertex.getID())__			assertNotNull(expectedName)__			assertEquals(expectedName, vertex.getName())__		}_	};verifies,that,each,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map,and,mapped,to,the,same,vertex,name;private,void,verify,ids,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,string,expected,name,ids,get,vertex,get,id,assert,not,null,expected,name,assert,equals,expected,name,vertex,get,name
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1485181339;Verifies that each {@link JobVertexID} of the {@link JobGraph} is contained in the given map_and mapped to the same vertex name.;private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			String expectedName = ids.get(vertex.getID())__			assertNotNull(expectedName)__			assertEquals(expectedName, vertex.getName())__		}_	};verifies,that,each,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map,and,mapped,to,the,same,vertex,name;private,void,verify,ids,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,string,expected,name,ids,get,vertex,get,id,assert,not,null,expected,name,assert,equals,expected,name,vertex,get,name
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1493403095;Verifies that each {@link JobVertexID} of the {@link JobGraph} is contained in the given map_and mapped to the same vertex name.;private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			String expectedName = ids.get(vertex.getID())__			assertNotNull(expectedName)__			assertEquals(expectedName, vertex.getName())__		}_	};verifies,that,each,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map,and,mapped,to,the,same,vertex,name;private,void,verify,ids,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,string,expected,name,ids,get,vertex,get,id,assert,not,null,expected,name,assert,equals,expected,name,vertex,get,name
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1495484544;Verifies that each {@link JobVertexID} of the {@link JobGraph} is contained in the given map_and mapped to the same vertex name.;private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			String expectedName = ids.get(vertex.getID())__			assertNotNull(expectedName)__			assertEquals(expectedName, vertex.getName())__		}_	};verifies,that,each,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map,and,mapped,to,the,same,vertex,name;private,void,verify,ids,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,string,expected,name,ids,get,vertex,get,id,assert,not,null,expected,name,assert,equals,expected,name,vertex,get,name
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1503598628;Verifies that each {@link JobVertexID} of the {@link JobGraph} is contained in the given map_and mapped to the same vertex name.;private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			String expectedName = ids.get(vertex.getID())__			assertNotNull(expectedName)__			assertEquals(expectedName, vertex.getName())__		}_	};verifies,that,each,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map,and,mapped,to,the,same,vertex,name;private,void,verify,ids,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,string,expected,name,ids,get,vertex,get,id,assert,not,null,expected,name,assert,equals,expected,name,vertex,get,name
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignment() throws Exception;1452526242;Tests that manual hash assignments are mapped to the same operator ID.__<pre>_/-> [ (map) ] -> [ (sink)@sink0 ]_[ (src@source ) ] -+_\-> [ (map) ] -> [ (sink)@sink1 ]_</pre>__<pre>_/-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink0 ]_[ (src)@source ] -+_\-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink1 ]_</pre>;@Test_	public void testManualHashAssignment() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> ids = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(ids.add(vertex.getID()))__		}__		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		src = env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph newJobGraph = env.getStreamGraph().getJobGraph()__		assertNotEquals(jobGraph.getJobID(), newJobGraph.getJobID())___		for (JobVertex vertex : newJobGraph.getVertices()) {_			_			if (vertex.getName().endsWith("source")_					|| vertex.getName().endsWith("sink0")_					|| vertex.getName().endsWith("sink1")) {__				assertTrue(ids.contains(vertex.getID()))__			}_		}_	};tests,that,manual,hash,assignments,are,mapped,to,the,same,operator,id,pre,map,sink,sink0,src,source,map,sink,sink1,pre,pre,map,reduce,sink,sink0,src,source,map,reduce,sink,sink1,pre;test,public,void,test,manual,hash,assignment,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,name,source,uid,source,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,ids,add,vertex,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,src,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,source,uid,source,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,new,job,graph,env,get,stream,graph,get,job,graph,assert,not,equals,job,graph,get,job,id,new,job,graph,get,job,id,for,job,vertex,vertex,new,job,graph,get,vertices,if,vertex,get,name,ends,with,source,vertex,get,name,ends,with,sink0,vertex,get,name,ends,with,sink1,assert,true,ids,contains,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignment() throws Exception;1456427030;Tests that manual hash assignments are mapped to the same operator ID.__<pre>_/-> [ (map) ] -> [ (sink)@sink0 ]_[ (src@source ) ] -+_\-> [ (map) ] -> [ (sink)@sink1 ]_</pre>__<pre>_/-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink0 ]_[ (src)@source ] -+_\-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink1 ]_</pre>;@Test_	public void testManualHashAssignment() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> ids = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(ids.add(vertex.getID()))__		}__		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		src = env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph newJobGraph = env.getStreamGraph().getJobGraph()__		assertNotEquals(jobGraph.getJobID(), newJobGraph.getJobID())___		for (JobVertex vertex : newJobGraph.getVertices()) {_			_			if (vertex.getName().endsWith("source")_					|| vertex.getName().endsWith("sink0")_					|| vertex.getName().endsWith("sink1")) {__				assertTrue(ids.contains(vertex.getID()))__			}_		}_	};tests,that,manual,hash,assignments,are,mapped,to,the,same,operator,id,pre,map,sink,sink0,src,source,map,sink,sink1,pre,pre,map,reduce,sink,sink0,src,source,map,reduce,sink,sink1,pre;test,public,void,test,manual,hash,assignment,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,name,source,uid,source,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,ids,add,vertex,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,src,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,source,uid,source,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,new,job,graph,env,get,stream,graph,get,job,graph,assert,not,equals,job,graph,get,job,id,new,job,graph,get,job,id,for,job,vertex,vertex,new,job,graph,get,vertices,if,vertex,get,name,ends,with,source,vertex,get,name,ends,with,sink0,vertex,get,name,ends,with,sink1,assert,true,ids,contains,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignment() throws Exception;1467726666;Tests that manual hash assignments are mapped to the same operator ID.__<pre>_/-> [ (map) ] -> [ (sink)@sink0 ]_[ (src@source ) ] -+_\-> [ (map) ] -> [ (sink)@sink1 ]_</pre>__<pre>_/-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink0 ]_[ (src)@source ] -+_\-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink1 ]_</pre>;@Test_	public void testManualHashAssignment() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> ids = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(ids.add(vertex.getID()))__		}__		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		src = env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph newJobGraph = env.getStreamGraph().getJobGraph()__		assertNotEquals(jobGraph.getJobID(), newJobGraph.getJobID())___		for (JobVertex vertex : newJobGraph.getVertices()) {_			_			if (vertex.getName().endsWith("source")_					|| vertex.getName().endsWith("sink0")_					|| vertex.getName().endsWith("sink1")) {__				assertTrue(ids.contains(vertex.getID()))__			}_		}_	};tests,that,manual,hash,assignments,are,mapped,to,the,same,operator,id,pre,map,sink,sink0,src,source,map,sink,sink1,pre,pre,map,reduce,sink,sink0,src,source,map,reduce,sink,sink1,pre;test,public,void,test,manual,hash,assignment,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,name,source,uid,source,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,ids,add,vertex,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,src,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,source,uid,source,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,new,job,graph,env,get,stream,graph,get,job,graph,assert,not,equals,job,graph,get,job,id,new,job,graph,get,job,id,for,job,vertex,vertex,new,job,graph,get,vertices,if,vertex,get,name,ends,with,source,vertex,get,name,ends,with,sink0,vertex,get,name,ends,with,sink1,assert,true,ids,contains,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignment() throws Exception;1472663071;Tests that manual hash assignments are mapped to the same operator ID.__<pre>_/-> [ (map) ] -> [ (sink)@sink0 ]_[ (src@source ) ] -+_\-> [ (map) ] -> [ (sink)@sink1 ]_</pre>__<pre>_/-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink0 ]_[ (src)@source ] -+_\-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink1 ]_</pre>;@Test_	public void testManualHashAssignment() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> ids = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(ids.add(vertex.getID()))__		}__		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		src = env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph newJobGraph = env.getStreamGraph().getJobGraph()__		assertNotEquals(jobGraph.getJobID(), newJobGraph.getJobID())___		for (JobVertex vertex : newJobGraph.getVertices()) {_			_			if (vertex.getName().endsWith("source")_					|| vertex.getName().endsWith("sink0")_					|| vertex.getName().endsWith("sink1")) {__				assertTrue(ids.contains(vertex.getID()))__			}_		}_	};tests,that,manual,hash,assignments,are,mapped,to,the,same,operator,id,pre,map,sink,sink0,src,source,map,sink,sink1,pre,pre,map,reduce,sink,sink0,src,source,map,reduce,sink,sink1,pre;test,public,void,test,manual,hash,assignment,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,name,source,uid,source,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,ids,add,vertex,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,src,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,source,uid,source,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,new,job,graph,env,get,stream,graph,get,job,graph,assert,not,equals,job,graph,get,job,id,new,job,graph,get,job,id,for,job,vertex,vertex,new,job,graph,get,vertices,if,vertex,get,name,ends,with,source,vertex,get,name,ends,with,sink0,vertex,get,name,ends,with,sink1,assert,true,ids,contains,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignment() throws Exception;1485181339;Tests that manual hash assignments are mapped to the same operator ID.__<pre>_/-> [ (map) ] -> [ (sink)@sink0 ]_[ (src@source ) ] -+_\-> [ (map) ] -> [ (sink)@sink1 ]_</pre>__<pre>_/-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink0 ]_[ (src)@source ] -+_\-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink1 ]_</pre>;@Test_	public void testManualHashAssignment() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> ids = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(ids.add(vertex.getID()))__		}__		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		src = env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph newJobGraph = env.getStreamGraph().getJobGraph()__		assertNotEquals(jobGraph.getJobID(), newJobGraph.getJobID())___		for (JobVertex vertex : newJobGraph.getVertices()) {_			_			if (vertex.getName().endsWith("source")_					|| vertex.getName().endsWith("sink0")_					|| vertex.getName().endsWith("sink1")) {__				assertTrue(ids.contains(vertex.getID()))__			}_		}_	};tests,that,manual,hash,assignments,are,mapped,to,the,same,operator,id,pre,map,sink,sink0,src,source,map,sink,sink1,pre,pre,map,reduce,sink,sink0,src,source,map,reduce,sink,sink1,pre;test,public,void,test,manual,hash,assignment,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,name,source,uid,source,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,ids,add,vertex,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,src,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,source,uid,source,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,new,job,graph,env,get,stream,graph,get,job,graph,assert,not,equals,job,graph,get,job,id,new,job,graph,get,job,id,for,job,vertex,vertex,new,job,graph,get,vertices,if,vertex,get,name,ends,with,source,vertex,get,name,ends,with,sink0,vertex,get,name,ends,with,sink1,assert,true,ids,contains,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignment() throws Exception;1493403095;Tests that manual hash assignments are mapped to the same operator ID.__<pre>_/-> [ (map) ] -> [ (sink)@sink0 ]_[ (src@source ) ] -+_\-> [ (map) ] -> [ (sink)@sink1 ]_</pre>__<pre>_/-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink0 ]_[ (src)@source ] -+_\-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink1 ]_</pre>;@Test_	public void testManualHashAssignment() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> ids = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(ids.add(vertex.getID()))__		}__		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		src = env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph newJobGraph = env.getStreamGraph().getJobGraph()__		assertNotEquals(jobGraph.getJobID(), newJobGraph.getJobID())___		for (JobVertex vertex : newJobGraph.getVertices()) {_			_			if (vertex.getName().endsWith("source")_					|| vertex.getName().endsWith("sink0")_					|| vertex.getName().endsWith("sink1")) {__				assertTrue(ids.contains(vertex.getID()))__			}_		}_	};tests,that,manual,hash,assignments,are,mapped,to,the,same,operator,id,pre,map,sink,sink0,src,source,map,sink,sink1,pre,pre,map,reduce,sink,sink0,src,source,map,reduce,sink,sink1,pre;test,public,void,test,manual,hash,assignment,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,name,source,uid,source,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,ids,add,vertex,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,src,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,source,uid,source,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,new,job,graph,env,get,stream,graph,get,job,graph,assert,not,equals,job,graph,get,job,id,new,job,graph,get,job,id,for,job,vertex,vertex,new,job,graph,get,vertices,if,vertex,get,name,ends,with,source,vertex,get,name,ends,with,sink0,vertex,get,name,ends,with,sink1,assert,true,ids,contains,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignment() throws Exception;1495484544;Tests that manual hash assignments are mapped to the same operator ID.__<pre>_/-> [ (map) ] -> [ (sink)@sink0 ]_[ (src@source ) ] -+_\-> [ (map) ] -> [ (sink)@sink1 ]_</pre>__<pre>_/-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink0 ]_[ (src)@source ] -+_\-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink1 ]_</pre>;@Test_	public void testManualHashAssignment() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> ids = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(ids.add(vertex.getID()))__		}__		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		src = env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph newJobGraph = env.getStreamGraph().getJobGraph()__		assertNotEquals(jobGraph.getJobID(), newJobGraph.getJobID())___		for (JobVertex vertex : newJobGraph.getVertices()) {_			_			if (vertex.getName().endsWith("source")_					|| vertex.getName().endsWith("sink0")_					|| vertex.getName().endsWith("sink1")) {__				assertTrue(ids.contains(vertex.getID()))__			}_		}_	};tests,that,manual,hash,assignments,are,mapped,to,the,same,operator,id,pre,map,sink,sink0,src,source,map,sink,sink1,pre,pre,map,reduce,sink,sink0,src,source,map,reduce,sink,sink1,pre;test,public,void,test,manual,hash,assignment,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,name,source,uid,source,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,ids,add,vertex,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,src,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,source,uid,source,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,new,job,graph,env,get,stream,graph,get,job,graph,assert,not,equals,job,graph,get,job,id,new,job,graph,get,job,id,for,job,vertex,vertex,new,job,graph,get,vertices,if,vertex,get,name,ends,with,source,vertex,get,name,ends,with,sink0,vertex,get,name,ends,with,sink1,assert,true,ids,contains,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignment() throws Exception;1503598628;Tests that manual hash assignments are mapped to the same operator ID.__<pre>_/-> [ (map) ] -> [ (sink)@sink0 ]_[ (src@source ) ] -+_\-> [ (map) ] -> [ (sink)@sink1 ]_</pre>__<pre>_/-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink0 ]_[ (src)@source ] -+_\-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink1 ]_</pre>;@Test_	public void testManualHashAssignment() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> ids = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(ids.add(vertex.getID()))__		}__		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		src = env.addSource(new NoOpSourceFunction())_				_				.map(new NoOpMapFunction())_				.name("source").uid("source")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink0").uid("sink0")___		src.map(new NoOpMapFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction())_				.addSink(new NoOpSinkFunction())_				.name("sink1").uid("sink1")___		JobGraph newJobGraph = env.getStreamGraph().getJobGraph()__		assertNotEquals(jobGraph.getJobID(), newJobGraph.getJobID())___		for (JobVertex vertex : newJobGraph.getVertices()) {_			_			if (vertex.getName().endsWith("source")_					|| vertex.getName().endsWith("sink0")_					|| vertex.getName().endsWith("sink1")) {__				assertTrue(ids.contains(vertex.getID()))__			}_		}_	};tests,that,manual,hash,assignments,are,mapped,to,the,same,operator,id,pre,map,sink,sink0,src,source,map,sink,sink1,pre,pre,map,reduce,sink,sink0,src,source,map,reduce,sink,sink1,pre;test,public,void,test,manual,hash,assignment,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,name,source,uid,source,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,ids,add,vertex,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,src,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,source,uid,source,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink0,uid,sink0,src,map,new,no,op,map,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,add,sink,new,no,op,sink,function,name,sink1,uid,sink1,job,graph,new,job,graph,env,get,stream,graph,get,job,graph,assert,not,equals,job,graph,get,job,id,new,job,graph,get,job,id,for,job,vertex,vertex,new,job,graph,get,vertices,if,vertex,get,name,ends,with,source,vertex,get,name,ends,with,sink0,vertex,get,name,ends,with,sink1,assert,true,ids,contains,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> private Map<JobVertexID, String> rememberIds(JobGraph jobGraph);1452526242;Returns a {@link JobVertexID} to vertex name mapping for the given graph.;private Map<JobVertexID, String> rememberIds(JobGraph jobGraph) {_		final Map<JobVertexID, String> ids = new HashMap<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			ids.put(vertex.getID(), vertex.getName())__		}_		return ids__	};returns,a,link,job,vertex,id,to,vertex,name,mapping,for,the,given,graph;private,map,job,vertex,id,string,remember,ids,job,graph,job,graph,final,map,job,vertex,id,string,ids,new,hash,map,for,job,vertex,vertex,job,graph,get,vertices,ids,put,vertex,get,id,vertex,get,name,return,ids
StreamingJobGraphGeneratorNodeHashTest -> private Map<JobVertexID, String> rememberIds(JobGraph jobGraph);1456427030;Returns a {@link JobVertexID} to vertex name mapping for the given graph.;private Map<JobVertexID, String> rememberIds(JobGraph jobGraph) {_		final Map<JobVertexID, String> ids = new HashMap<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			ids.put(vertex.getID(), vertex.getName())__		}_		return ids__	};returns,a,link,job,vertex,id,to,vertex,name,mapping,for,the,given,graph;private,map,job,vertex,id,string,remember,ids,job,graph,job,graph,final,map,job,vertex,id,string,ids,new,hash,map,for,job,vertex,vertex,job,graph,get,vertices,ids,put,vertex,get,id,vertex,get,name,return,ids
StreamingJobGraphGeneratorNodeHashTest -> private Map<JobVertexID, String> rememberIds(JobGraph jobGraph);1467726666;Returns a {@link JobVertexID} to vertex name mapping for the given graph.;private Map<JobVertexID, String> rememberIds(JobGraph jobGraph) {_		final Map<JobVertexID, String> ids = new HashMap<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			ids.put(vertex.getID(), vertex.getName())__		}_		return ids__	};returns,a,link,job,vertex,id,to,vertex,name,mapping,for,the,given,graph;private,map,job,vertex,id,string,remember,ids,job,graph,job,graph,final,map,job,vertex,id,string,ids,new,hash,map,for,job,vertex,vertex,job,graph,get,vertices,ids,put,vertex,get,id,vertex,get,name,return,ids
StreamingJobGraphGeneratorNodeHashTest -> private Map<JobVertexID, String> rememberIds(JobGraph jobGraph);1472663071;Returns a {@link JobVertexID} to vertex name mapping for the given graph.;private Map<JobVertexID, String> rememberIds(JobGraph jobGraph) {_		final Map<JobVertexID, String> ids = new HashMap<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			ids.put(vertex.getID(), vertex.getName())__		}_		return ids__	};returns,a,link,job,vertex,id,to,vertex,name,mapping,for,the,given,graph;private,map,job,vertex,id,string,remember,ids,job,graph,job,graph,final,map,job,vertex,id,string,ids,new,hash,map,for,job,vertex,vertex,job,graph,get,vertices,ids,put,vertex,get,id,vertex,get,name,return,ids
StreamingJobGraphGeneratorNodeHashTest -> private Map<JobVertexID, String> rememberIds(JobGraph jobGraph);1485181339;Returns a {@link JobVertexID} to vertex name mapping for the given graph.;private Map<JobVertexID, String> rememberIds(JobGraph jobGraph) {_		final Map<JobVertexID, String> ids = new HashMap<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			ids.put(vertex.getID(), vertex.getName())__		}_		return ids__	};returns,a,link,job,vertex,id,to,vertex,name,mapping,for,the,given,graph;private,map,job,vertex,id,string,remember,ids,job,graph,job,graph,final,map,job,vertex,id,string,ids,new,hash,map,for,job,vertex,vertex,job,graph,get,vertices,ids,put,vertex,get,id,vertex,get,name,return,ids
StreamingJobGraphGeneratorNodeHashTest -> private Map<JobVertexID, String> rememberIds(JobGraph jobGraph);1493403095;Returns a {@link JobVertexID} to vertex name mapping for the given graph.;private Map<JobVertexID, String> rememberIds(JobGraph jobGraph) {_		final Map<JobVertexID, String> ids = new HashMap<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			ids.put(vertex.getID(), vertex.getName())__		}_		return ids__	};returns,a,link,job,vertex,id,to,vertex,name,mapping,for,the,given,graph;private,map,job,vertex,id,string,remember,ids,job,graph,job,graph,final,map,job,vertex,id,string,ids,new,hash,map,for,job,vertex,vertex,job,graph,get,vertices,ids,put,vertex,get,id,vertex,get,name,return,ids
StreamingJobGraphGeneratorNodeHashTest -> private Map<JobVertexID, String> rememberIds(JobGraph jobGraph);1495484544;Returns a {@link JobVertexID} to vertex name mapping for the given graph.;private Map<JobVertexID, String> rememberIds(JobGraph jobGraph) {_		final Map<JobVertexID, String> ids = new HashMap<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			ids.put(vertex.getID(), vertex.getName())__		}_		return ids__	};returns,a,link,job,vertex,id,to,vertex,name,mapping,for,the,given,graph;private,map,job,vertex,id,string,remember,ids,job,graph,job,graph,final,map,job,vertex,id,string,ids,new,hash,map,for,job,vertex,vertex,job,graph,get,vertices,ids,put,vertex,get,id,vertex,get,name,return,ids
StreamingJobGraphGeneratorNodeHashTest -> private Map<JobVertexID, String> rememberIds(JobGraph jobGraph);1503598628;Returns a {@link JobVertexID} to vertex name mapping for the given graph.;private Map<JobVertexID, String> rememberIds(JobGraph jobGraph) {_		final Map<JobVertexID, String> ids = new HashMap<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			ids.put(vertex.getID(), vertex.getName())__		}_		return ids__	};returns,a,link,job,vertex,id,to,vertex,name,mapping,for,the,given,graph;private,map,job,vertex,id,string,remember,ids,job,graph,job,graph,final,map,job,vertex,id,string,ids,new,hash,map,for,job,vertex,vertex,job,graph,get,vertices,ids,put,vertex,get,id,vertex,get,name,return,ids
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashParallelism() throws Exception;1452526242;Verifies that parallelism affects the node hash.;@Test_	public void testNodeHashParallelism() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction(), "src").setParallelism(4)_				.addSink(new NoOpSink<String>()).name("sink").setParallelism(4)___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		Map<JobVertexID, String> ids = rememberIds(jobGraph)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction(), "src").setParallelism(8)_				.addSink(new NoOpSink<String>()).name("sink").setParallelism(4)___		jobGraph = env.getStreamGraph().getJobGraph()___		verifyIdsNotEqual(jobGraph, ids)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction(), "src").setParallelism(4)_				.addSink(new NoOpSink<String>()).name("sink").setParallelism(8)___		jobGraph = env.getStreamGraph().getJobGraph()___		_		JobVertex[] vertices = jobGraph.getVerticesAsArray()__		if (vertices[0].isInputVertex()) {_			assertTrue(ids.containsKey(vertices[0].getID()))__			assertFalse(ids.containsKey(vertices[1].getID()))__		}_		else {_			assertTrue(ids.containsKey(vertices[1].getID()))__			assertFalse(ids.containsKey(vertices[0].getID()))__		}_	};verifies,that,parallelism,affects,the,node,hash;test,public,void,test,node,hash,parallelism,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,disable,operator,chaining,env,add,source,new,no,op,source,function,src,set,parallelism,4,add,sink,new,no,op,sink,string,name,sink,set,parallelism,4,job,graph,job,graph,env,get,stream,graph,get,job,graph,map,job,vertex,id,string,ids,remember,ids,job,graph,env,stream,execution,environment,create,local,environment,env,disable,operator,chaining,env,add,source,new,no,op,source,function,src,set,parallelism,8,add,sink,new,no,op,sink,string,name,sink,set,parallelism,4,job,graph,env,get,stream,graph,get,job,graph,verify,ids,not,equal,job,graph,ids,env,stream,execution,environment,create,local,environment,env,disable,operator,chaining,env,add,source,new,no,op,source,function,src,set,parallelism,4,add,sink,new,no,op,sink,string,name,sink,set,parallelism,8,job,graph,env,get,stream,graph,get,job,graph,job,vertex,vertices,job,graph,get,vertices,as,array,if,vertices,0,is,input,vertex,assert,true,ids,contains,key,vertices,0,get,id,assert,false,ids,contains,key,vertices,1,get,id,else,assert,true,ids,contains,key,vertices,1,get,id,assert,false,ids,contains,key,vertices,0,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashParallelism() throws Exception;1456427030;Verifies that parallelism affects the node hash.;@Test_	public void testNodeHashParallelism() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction(), "src").setParallelism(4)_				.addSink(new NoOpSink<String>()).name("sink").setParallelism(4)___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		Map<JobVertexID, String> ids = rememberIds(jobGraph)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction(), "src").setParallelism(8)_				.addSink(new NoOpSink<String>()).name("sink").setParallelism(4)___		jobGraph = env.getStreamGraph().getJobGraph()___		verifyIdsNotEqual(jobGraph, ids)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction(), "src").setParallelism(4)_				.addSink(new NoOpSink<String>()).name("sink").setParallelism(8)___		jobGraph = env.getStreamGraph().getJobGraph()___		_		JobVertex[] vertices = jobGraph.getVerticesAsArray()__		if (vertices[0].isInputVertex()) {_			assertTrue(ids.containsKey(vertices[0].getID()))__			assertFalse(ids.containsKey(vertices[1].getID()))__		}_		else {_			assertTrue(ids.containsKey(vertices[1].getID()))__			assertFalse(ids.containsKey(vertices[0].getID()))__		}_	};verifies,that,parallelism,affects,the,node,hash;test,public,void,test,node,hash,parallelism,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,disable,operator,chaining,env,add,source,new,no,op,source,function,src,set,parallelism,4,add,sink,new,no,op,sink,string,name,sink,set,parallelism,4,job,graph,job,graph,env,get,stream,graph,get,job,graph,map,job,vertex,id,string,ids,remember,ids,job,graph,env,stream,execution,environment,create,local,environment,env,disable,operator,chaining,env,add,source,new,no,op,source,function,src,set,parallelism,8,add,sink,new,no,op,sink,string,name,sink,set,parallelism,4,job,graph,env,get,stream,graph,get,job,graph,verify,ids,not,equal,job,graph,ids,env,stream,execution,environment,create,local,environment,env,disable,operator,chaining,env,add,source,new,no,op,source,function,src,set,parallelism,4,add,sink,new,no,op,sink,string,name,sink,set,parallelism,8,job,graph,env,get,stream,graph,get,job,graph,job,vertex,vertices,job,graph,get,vertices,as,array,if,vertices,0,is,input,vertex,assert,true,ids,contains,key,vertices,0,get,id,assert,false,ids,contains,key,vertices,1,get,id,else,assert,true,ids,contains,key,vertices,1,get,id,assert,false,ids,contains,key,vertices,0,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashParallelism() throws Exception;1467726666;Verifies that parallelism affects the node hash.;@Test_	public void testNodeHashParallelism() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction(), "src").setParallelism(4)_				.addSink(new DiscardingSink<String>()).name("sink").setParallelism(4)___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		Map<JobVertexID, String> ids = rememberIds(jobGraph)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction(), "src").setParallelism(8)_				.addSink(new DiscardingSink<String>()).name("sink").setParallelism(4)___		jobGraph = env.getStreamGraph().getJobGraph()___		verifyIdsNotEqual(jobGraph, ids)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction(), "src").setParallelism(4)_				.addSink(new DiscardingSink<String>()).name("sink").setParallelism(8)___		jobGraph = env.getStreamGraph().getJobGraph()___		_		JobVertex[] vertices = jobGraph.getVerticesAsArray()__		if (vertices[0].isInputVertex()) {_			assertTrue(ids.containsKey(vertices[0].getID()))__			assertFalse(ids.containsKey(vertices[1].getID()))__		}_		else {_			assertTrue(ids.containsKey(vertices[1].getID()))__			assertFalse(ids.containsKey(vertices[0].getID()))__		}_	};verifies,that,parallelism,affects,the,node,hash;test,public,void,test,node,hash,parallelism,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,disable,operator,chaining,env,add,source,new,no,op,source,function,src,set,parallelism,4,add,sink,new,discarding,sink,string,name,sink,set,parallelism,4,job,graph,job,graph,env,get,stream,graph,get,job,graph,map,job,vertex,id,string,ids,remember,ids,job,graph,env,stream,execution,environment,create,local,environment,env,disable,operator,chaining,env,add,source,new,no,op,source,function,src,set,parallelism,8,add,sink,new,discarding,sink,string,name,sink,set,parallelism,4,job,graph,env,get,stream,graph,get,job,graph,verify,ids,not,equal,job,graph,ids,env,stream,execution,environment,create,local,environment,env,disable,operator,chaining,env,add,source,new,no,op,source,function,src,set,parallelism,4,add,sink,new,discarding,sink,string,name,sink,set,parallelism,8,job,graph,env,get,stream,graph,get,job,graph,job,vertex,vertices,job,graph,get,vertices,as,array,if,vertices,0,is,input,vertex,assert,true,ids,contains,key,vertices,0,get,id,assert,false,ids,contains,key,vertices,1,get,id,else,assert,true,ids,contains,key,vertices,1,get,id,assert,false,ids,contains,key,vertices,0,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterIntermediateUnchaining() throws Exception;1452526242;Tests that (un)chaining affects the node hash (for intermediate nodes).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterIntermediateUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex chainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertTrue(chainedMap.getName().startsWith("map"))__		JobVertexID chainedMapId = chainedMap.getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.startNewChain()_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex unchainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertEquals("map", unchainedMap.getName())__		JobVertexID unchainedMapId = unchainedMap.getID()___		assertNotEquals(chainedMapId, unchainedMapId)__	};tests,that,un,chaining,affects,the,node,hash,for,intermediate,nodes,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,intermediate,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,chained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,true,chained,map,get,name,starts,with,map,job,vertex,id,chained,map,id,chained,map,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,start,new,chain,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,unchained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,equals,map,unchained,map,get,name,job,vertex,id,unchained,map,id,unchained,map,get,id,assert,not,equals,chained,map,id,unchained,map,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterIntermediateUnchaining() throws Exception;1456427030;Tests that (un)chaining affects the node hash (for intermediate nodes).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterIntermediateUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex chainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertTrue(chainedMap.getName().startsWith("map"))__		JobVertexID chainedMapId = chainedMap.getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.startNewChain()_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex unchainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertEquals("map", unchainedMap.getName())__		JobVertexID unchainedMapId = unchainedMap.getID()___		assertNotEquals(chainedMapId, unchainedMapId)__	};tests,that,un,chaining,affects,the,node,hash,for,intermediate,nodes,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,intermediate,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,chained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,true,chained,map,get,name,starts,with,map,job,vertex,id,chained,map,id,chained,map,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,start,new,chain,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,unchained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,equals,map,unchained,map,get,name,job,vertex,id,unchained,map,id,unchained,map,get,id,assert,not,equals,chained,map,id,unchained,map,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterIntermediateUnchaining() throws Exception;1467726666;Tests that (un)chaining affects the node hash (for intermediate nodes).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterIntermediateUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex chainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertTrue(chainedMap.getName().startsWith("map"))__		JobVertexID chainedMapId = chainedMap.getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.startNewChain()_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex unchainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertEquals("map", unchainedMap.getName())__		JobVertexID unchainedMapId = unchainedMap.getID()___		assertNotEquals(chainedMapId, unchainedMapId)__	};tests,that,un,chaining,affects,the,node,hash,for,intermediate,nodes,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,intermediate,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,chained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,true,chained,map,get,name,starts,with,map,job,vertex,id,chained,map,id,chained,map,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,start,new,chain,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,unchained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,equals,map,unchained,map,get,name,job,vertex,id,unchained,map,id,unchained,map,get,id,assert,not,equals,chained,map,id,unchained,map,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterIntermediateUnchaining() throws Exception;1472663071;Tests that (un)chaining affects the node hash (for intermediate nodes).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterIntermediateUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex chainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertTrue(chainedMap.getName().startsWith("map"))__		JobVertexID chainedMapId = chainedMap.getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.startNewChain()_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex unchainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertEquals("map", unchainedMap.getName())__		JobVertexID unchainedMapId = unchainedMap.getID()___		assertNotEquals(chainedMapId, unchainedMapId)__	};tests,that,un,chaining,affects,the,node,hash,for,intermediate,nodes,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,intermediate,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,chained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,true,chained,map,get,name,starts,with,map,job,vertex,id,chained,map,id,chained,map,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,start,new,chain,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,unchained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,equals,map,unchained,map,get,name,job,vertex,id,unchained,map,id,unchained,map,get,id,assert,not,equals,chained,map,id,unchained,map,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterIntermediateUnchaining() throws Exception;1485181339;Tests that (un)chaining affects the node hash (for intermediate nodes).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterIntermediateUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex chainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertTrue(chainedMap.getName().startsWith("map"))__		JobVertexID chainedMapId = chainedMap.getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.startNewChain()_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex unchainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertEquals("map", unchainedMap.getName())__		JobVertexID unchainedMapId = unchainedMap.getID()___		assertNotEquals(chainedMapId, unchainedMapId)__	};tests,that,un,chaining,affects,the,node,hash,for,intermediate,nodes,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,intermediate,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,chained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,true,chained,map,get,name,starts,with,map,job,vertex,id,chained,map,id,chained,map,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,start,new,chain,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,unchained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,equals,map,unchained,map,get,name,job,vertex,id,unchained,map,id,unchained,map,get,id,assert,not,equals,chained,map,id,unchained,map,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterIntermediateUnchaining() throws Exception;1493403095;Tests that (un)chaining affects the node hash (for intermediate nodes).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterIntermediateUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex chainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertTrue(chainedMap.getName().startsWith("map"))__		JobVertexID chainedMapId = chainedMap.getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.startNewChain()_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex unchainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertEquals("map", unchainedMap.getName())__		JobVertexID unchainedMapId = unchainedMap.getID()___		assertNotEquals(chainedMapId, unchainedMapId)__	};tests,that,un,chaining,affects,the,node,hash,for,intermediate,nodes,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,intermediate,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,chained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,true,chained,map,get,name,starts,with,map,job,vertex,id,chained,map,id,chained,map,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,start,new,chain,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,unchained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,equals,map,unchained,map,get,name,job,vertex,id,unchained,map,id,unchained,map,get,id,assert,not,equals,chained,map,id,unchained,map,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterIntermediateUnchaining() throws Exception;1495484544;Tests that (un)chaining affects the node hash (for intermediate nodes).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__<p>The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterIntermediateUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex chainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertTrue(chainedMap.getName().startsWith("map"))__		JobVertexID chainedMapId = chainedMap.getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.startNewChain()_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex unchainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertEquals("map", unchainedMap.getName())__		JobVertexID unchainedMapId = unchainedMap.getID()___		assertNotEquals(chainedMapId, unchainedMapId)__	};tests,that,un,chaining,affects,the,node,hash,for,intermediate,nodes,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,p,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,intermediate,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,chained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,true,chained,map,get,name,starts,with,map,job,vertex,id,chained,map,id,chained,map,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,start,new,chain,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,unchained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,equals,map,unchained,map,get,name,job,vertex,id,unchained,map,id,unchained,map,get,id,assert,not,equals,chained,map,id,unchained,map,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashAfterIntermediateUnchaining() throws Exception;1503598628;Tests that (un)chaining affects the node hash (for intermediate nodes).__<pre>_A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]_B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]_</pre>__<p>The hashes for the single vertex in A and the source vertex in B need to be different.;@Test_	public void testNodeHashAfterIntermediateUnchaining() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex chainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertTrue(chainedMap.getName().startsWith("map"))__		JobVertexID chainedMapId = chainedMap.getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction())_				.map(new NoOpMapFunction()).name("map")_				.startNewChain()_				.filter(new NoOpFilterFunction())_				.startNewChain()_				.addSink(new NoOpSinkFunction())___		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertex unchainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1)__		assertEquals("map", unchainedMap.getName())__		JobVertexID unchainedMapId = unchainedMap.getID()___		assertNotEquals(chainedMapId, unchainedMapId)__	};tests,that,un,chaining,affects,the,node,hash,for,intermediate,nodes,pre,a,chained,src0,map,filter,sink,b,unchained,src0,map,filter,sink,pre,p,the,hashes,for,the,single,vertex,in,a,and,the,source,vertex,in,b,need,to,be,different;test,public,void,test,node,hash,after,intermediate,unchaining,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,chained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,true,chained,map,get,name,starts,with,map,job,vertex,id,chained,map,id,chained,map,get,id,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,map,new,no,op,map,function,name,map,start,new,chain,filter,new,no,op,filter,function,start,new,chain,add,sink,new,no,op,sink,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,unchained,map,job,graph,get,vertices,sorted,topologically,from,sources,get,1,assert,equals,map,unchained,map,get,name,job,vertex,id,unchained,map,id,unchained,map,get,id,assert,not,equals,chained,map,id,unchained,map,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIsDeterministic() throws Exception;1452526242;Creates the same flow twice and checks that all IDs are the same.__<pre>_[ (src) -> (map) -> (filter) -> (reduce) -> (map) -> (sink) ]__[ (src) -> (filter) ] -------------------------------//__[ (src) -> (filter) ] ------------------------------/_</pre>;@Test_	public void testNodeHashIsDeterministic() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		DataStream<String> src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		DataStream<String> src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		DataStream<String> src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		final Map<JobVertexID, String> ids = rememberIds(jobGraph)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		jobGraph = env.getStreamGraph().getJobGraph()___		verifyIdsEqual(jobGraph, ids)__	};creates,the,same,flow,twice,and,checks,that,all,ids,are,the,same,pre,src,map,filter,reduce,map,sink,src,filter,src,filter,pre;test,public,void,test,node,hash,is,deterministic,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,data,stream,string,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,data,stream,string,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,data,stream,string,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,map,job,vertex,id,string,ids,remember,ids,job,graph,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,env,get,stream,graph,get,job,graph,verify,ids,equal,job,graph,ids
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIsDeterministic() throws Exception;1456427030;Creates the same flow twice and checks that all IDs are the same.__<pre>_[ (src) -> (map) -> (filter) -> (reduce) -> (map) -> (sink) ]__[ (src) -> (filter) ] -------------------------------//__[ (src) -> (filter) ] ------------------------------/_</pre>;@Test_	public void testNodeHashIsDeterministic() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		DataStream<String> src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		DataStream<String> src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		DataStream<String> src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		final Map<JobVertexID, String> ids = rememberIds(jobGraph)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		jobGraph = env.getStreamGraph().getJobGraph()___		verifyIdsEqual(jobGraph, ids)__	};creates,the,same,flow,twice,and,checks,that,all,ids,are,the,same,pre,src,map,filter,reduce,map,sink,src,filter,src,filter,pre;test,public,void,test,node,hash,is,deterministic,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,data,stream,string,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,data,stream,string,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,data,stream,string,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,map,job,vertex,id,string,ids,remember,ids,job,graph,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,env,get,stream,graph,get,job,graph,verify,ids,equal,job,graph,ids
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIsDeterministic() throws Exception;1467726666;Creates the same flow twice and checks that all IDs are the same.__<pre>_[ (src) -> (map) -> (filter) -> (reduce) -> (map) -> (sink) ]__[ (src) -> (filter) ] -------------------------------//__[ (src) -> (filter) ] ------------------------------/_</pre>;@Test_	public void testNodeHashIsDeterministic() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		DataStream<String> src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		DataStream<String> src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		DataStream<String> src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		final Map<JobVertexID, String> ids = rememberIds(jobGraph)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		jobGraph = env.getStreamGraph().getJobGraph()___		verifyIdsEqual(jobGraph, ids)__	};creates,the,same,flow,twice,and,checks,that,all,ids,are,the,same,pre,src,map,filter,reduce,map,sink,src,filter,src,filter,pre;test,public,void,test,node,hash,is,deterministic,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,data,stream,string,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,data,stream,string,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,data,stream,string,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,map,job,vertex,id,string,ids,remember,ids,job,graph,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,env,get,stream,graph,get,job,graph,verify,ids,equal,job,graph,ids
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIsDeterministic() throws Exception;1472663071;Creates the same flow twice and checks that all IDs are the same.__<pre>_[ (src) -> (map) -> (filter) -> (reduce) -> (map) -> (sink) ]__[ (src) -> (filter) ] -------------------------------//__[ (src) -> (filter) ] ------------------------------/_</pre>;@Test_	public void testNodeHashIsDeterministic() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		DataStream<String> src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		DataStream<String> src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		DataStream<String> src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		final Map<JobVertexID, String> ids = rememberIds(jobGraph)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		jobGraph = env.getStreamGraph().getJobGraph()___		verifyIdsEqual(jobGraph, ids)__	};creates,the,same,flow,twice,and,checks,that,all,ids,are,the,same,pre,src,map,filter,reduce,map,sink,src,filter,src,filter,pre;test,public,void,test,node,hash,is,deterministic,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,data,stream,string,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,data,stream,string,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,data,stream,string,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,map,job,vertex,id,string,ids,remember,ids,job,graph,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,env,get,stream,graph,get,job,graph,verify,ids,equal,job,graph,ids
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIsDeterministic() throws Exception;1485181339;Creates the same flow twice and checks that all IDs are the same.__<pre>_[ (src) -> (map) -> (filter) -> (reduce) -> (map) -> (sink) ]__[ (src) -> (filter) ] -------------------------------//__[ (src) -> (filter) ] ------------------------------/_</pre>;@Test_	public void testNodeHashIsDeterministic() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		DataStream<String> src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		DataStream<String> src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		DataStream<String> src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		final Map<JobVertexID, String> ids = rememberIds(jobGraph)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		jobGraph = env.getStreamGraph().getJobGraph()___		verifyIdsEqual(jobGraph, ids)__	};creates,the,same,flow,twice,and,checks,that,all,ids,are,the,same,pre,src,map,filter,reduce,map,sink,src,filter,src,filter,pre;test,public,void,test,node,hash,is,deterministic,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,data,stream,string,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,data,stream,string,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,data,stream,string,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,map,job,vertex,id,string,ids,remember,ids,job,graph,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,env,get,stream,graph,get,job,graph,verify,ids,equal,job,graph,ids
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIsDeterministic() throws Exception;1493403095;Creates the same flow twice and checks that all IDs are the same.__<pre>_[ (src) -> (map) -> (filter) -> (reduce) -> (map) -> (sink) ]__[ (src) -> (filter) ] -------------------------------//__[ (src) -> (filter) ] ------------------------------/_</pre>;@Test_	public void testNodeHashIsDeterministic() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		DataStream<String> src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		DataStream<String> src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		DataStream<String> src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		final Map<JobVertexID, String> ids = rememberIds(jobGraph)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		jobGraph = env.getStreamGraph().getJobGraph()___		verifyIdsEqual(jobGraph, ids)__	};creates,the,same,flow,twice,and,checks,that,all,ids,are,the,same,pre,src,map,filter,reduce,map,sink,src,filter,src,filter,pre;test,public,void,test,node,hash,is,deterministic,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,data,stream,string,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,data,stream,string,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,data,stream,string,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,map,job,vertex,id,string,ids,remember,ids,job,graph,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,env,get,stream,graph,get,job,graph,verify,ids,equal,job,graph,ids
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIsDeterministic() throws Exception;1495484544;Creates the same flow twice and checks that all IDs are the same.__<pre>_[ (src) -> (map) -> (filter) -> (reduce) -> (map) -> (sink) ]__[ (src) -> (filter) ] -------------------------------//__[ (src) -> (filter) ] ------------------------------/_</pre>;@Test_	public void testNodeHashIsDeterministic() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		DataStream<String> src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		DataStream<String> src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		DataStream<String> src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		final Map<JobVertexID, String> ids = rememberIds(jobGraph)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		jobGraph = env.getStreamGraph().getJobGraph()___		verifyIdsEqual(jobGraph, ids)__	};creates,the,same,flow,twice,and,checks,that,all,ids,are,the,same,pre,src,map,filter,reduce,map,sink,src,filter,src,filter,pre;test,public,void,test,node,hash,is,deterministic,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,data,stream,string,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,data,stream,string,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,data,stream,string,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,map,job,vertex,id,string,ids,remember,ids,job,graph,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,env,get,stream,graph,get,job,graph,verify,ids,equal,job,graph,ids
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIsDeterministic() throws Exception;1503598628;Creates the same flow twice and checks that all IDs are the same.__<pre>_[ (src) -> (map) -> (filter) -> (reduce) -> (map) -> (sink) ]__[ (src) -> (filter) ] -------------------------------//__[ (src) -> (filter) ] ------------------------------/_</pre>;@Test_	public void testNodeHashIsDeterministic() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		DataStream<String> src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		DataStream<String> src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		DataStream<String> src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		final Map<JobVertexID, String> ids = rememberIds(jobGraph)___		_		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		src0 = env_				.addSource(new NoOpSourceFunction(), "src0")_				.map(new NoOpMapFunction())_				.filter(new NoOpFilterFunction())_				.keyBy(new NoOpKeySelector())_				.reduce(new NoOpReduceFunction()).name("reduce")___		src1 = env_				.addSource(new NoOpSourceFunction(), "src1")_				.filter(new NoOpFilterFunction())___		src2 = env_				.addSource(new NoOpSourceFunction(), "src2")_				.filter(new NoOpFilterFunction())___		src0.map(new NoOpMapFunction())_				.union(src1, src2)_				.addSink(new NoOpSinkFunction()).name("sink")___		jobGraph = env.getStreamGraph().getJobGraph()___		verifyIdsEqual(jobGraph, ids)__	};creates,the,same,flow,twice,and,checks,that,all,ids,are,the,same,pre,src,map,filter,reduce,map,sink,src,filter,src,filter,pre;test,public,void,test,node,hash,is,deterministic,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,data,stream,string,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,data,stream,string,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,data,stream,string,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,job,graph,env,get,stream,graph,get,job,graph,final,map,job,vertex,id,string,ids,remember,ids,job,graph,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,src0,env,add,source,new,no,op,source,function,src0,map,new,no,op,map,function,filter,new,no,op,filter,function,key,by,new,no,op,key,selector,reduce,new,no,op,reduce,function,name,reduce,src1,env,add,source,new,no,op,source,function,src1,filter,new,no,op,filter,function,src2,env,add,source,new,no,op,source,function,src2,filter,new,no,op,filter,function,src0,map,new,no,op,map,function,union,src1,src2,add,sink,new,no,op,sink,function,name,sink,job,graph,env,get,stream,graph,get,job,graph,verify,ids,equal,job,graph,ids
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalSources() throws Exception;1452526242;Tests that there are no collisions with two identical sources.__<pre>_[ (src0) ] --\_+--> [ (sink) ]_[ (src1) ] --/_</pre>;@Test_	public void testNodeHashIdenticalSources() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src0 = env.addSource(new NoOpSourceFunction())__		DataStream<String> src1 = env.addSource(new NoOpSourceFunction())___		src0.union(src1).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		List<JobVertex> vertices = jobGraph.getVerticesSortedTopologicallyFromSources()__		assertTrue(vertices.get(0).isInputVertex())__		assertTrue(vertices.get(1).isInputVertex())___		assertNotNull(vertices.get(0).getID())__		assertNotNull(vertices.get(1).getID())___		assertNotEquals(vertices.get(0).getID(), vertices.get(1).getID())__	};tests,that,there,are,no,collisions,with,two,identical,sources,pre,src0,sink,src1,pre;test,public,void,test,node,hash,identical,sources,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src0,env,add,source,new,no,op,source,function,data,stream,string,src1,env,add,source,new,no,op,source,function,src0,union,src1,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,list,job,vertex,vertices,job,graph,get,vertices,sorted,topologically,from,sources,assert,true,vertices,get,0,is,input,vertex,assert,true,vertices,get,1,is,input,vertex,assert,not,null,vertices,get,0,get,id,assert,not,null,vertices,get,1,get,id,assert,not,equals,vertices,get,0,get,id,vertices,get,1,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalSources() throws Exception;1456427030;Tests that there are no collisions with two identical sources.__<pre>_[ (src0) ] --\_+--> [ (sink) ]_[ (src1) ] --/_</pre>;@Test_	public void testNodeHashIdenticalSources() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src0 = env.addSource(new NoOpSourceFunction())__		DataStream<String> src1 = env.addSource(new NoOpSourceFunction())___		src0.union(src1).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		List<JobVertex> vertices = jobGraph.getVerticesSortedTopologicallyFromSources()__		assertTrue(vertices.get(0).isInputVertex())__		assertTrue(vertices.get(1).isInputVertex())___		assertNotNull(vertices.get(0).getID())__		assertNotNull(vertices.get(1).getID())___		assertNotEquals(vertices.get(0).getID(), vertices.get(1).getID())__	};tests,that,there,are,no,collisions,with,two,identical,sources,pre,src0,sink,src1,pre;test,public,void,test,node,hash,identical,sources,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src0,env,add,source,new,no,op,source,function,data,stream,string,src1,env,add,source,new,no,op,source,function,src0,union,src1,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,list,job,vertex,vertices,job,graph,get,vertices,sorted,topologically,from,sources,assert,true,vertices,get,0,is,input,vertex,assert,true,vertices,get,1,is,input,vertex,assert,not,null,vertices,get,0,get,id,assert,not,null,vertices,get,1,get,id,assert,not,equals,vertices,get,0,get,id,vertices,get,1,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalSources() throws Exception;1467726666;Tests that there are no collisions with two identical sources.__<pre>_[ (src0) ] --\_+--> [ (sink) ]_[ (src1) ] --/_</pre>;@Test_	public void testNodeHashIdenticalSources() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src0 = env.addSource(new NoOpSourceFunction())__		DataStream<String> src1 = env.addSource(new NoOpSourceFunction())___		src0.union(src1).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		List<JobVertex> vertices = jobGraph.getVerticesSortedTopologicallyFromSources()__		assertTrue(vertices.get(0).isInputVertex())__		assertTrue(vertices.get(1).isInputVertex())___		assertNotNull(vertices.get(0).getID())__		assertNotNull(vertices.get(1).getID())___		assertNotEquals(vertices.get(0).getID(), vertices.get(1).getID())__	};tests,that,there,are,no,collisions,with,two,identical,sources,pre,src0,sink,src1,pre;test,public,void,test,node,hash,identical,sources,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src0,env,add,source,new,no,op,source,function,data,stream,string,src1,env,add,source,new,no,op,source,function,src0,union,src1,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,list,job,vertex,vertices,job,graph,get,vertices,sorted,topologically,from,sources,assert,true,vertices,get,0,is,input,vertex,assert,true,vertices,get,1,is,input,vertex,assert,not,null,vertices,get,0,get,id,assert,not,null,vertices,get,1,get,id,assert,not,equals,vertices,get,0,get,id,vertices,get,1,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalSources() throws Exception;1472663071;Tests that there are no collisions with two identical sources.__<pre>_[ (src0) ] --\_+--> [ (sink) ]_[ (src1) ] --/_</pre>;@Test_	public void testNodeHashIdenticalSources() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src0 = env.addSource(new NoOpSourceFunction())__		DataStream<String> src1 = env.addSource(new NoOpSourceFunction())___		src0.union(src1).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		List<JobVertex> vertices = jobGraph.getVerticesSortedTopologicallyFromSources()__		assertTrue(vertices.get(0).isInputVertex())__		assertTrue(vertices.get(1).isInputVertex())___		assertNotNull(vertices.get(0).getID())__		assertNotNull(vertices.get(1).getID())___		assertNotEquals(vertices.get(0).getID(), vertices.get(1).getID())__	};tests,that,there,are,no,collisions,with,two,identical,sources,pre,src0,sink,src1,pre;test,public,void,test,node,hash,identical,sources,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src0,env,add,source,new,no,op,source,function,data,stream,string,src1,env,add,source,new,no,op,source,function,src0,union,src1,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,list,job,vertex,vertices,job,graph,get,vertices,sorted,topologically,from,sources,assert,true,vertices,get,0,is,input,vertex,assert,true,vertices,get,1,is,input,vertex,assert,not,null,vertices,get,0,get,id,assert,not,null,vertices,get,1,get,id,assert,not,equals,vertices,get,0,get,id,vertices,get,1,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalSources() throws Exception;1485181339;Tests that there are no collisions with two identical sources.__<pre>_[ (src0) ] --\_+--> [ (sink) ]_[ (src1) ] --/_</pre>;@Test_	public void testNodeHashIdenticalSources() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src0 = env.addSource(new NoOpSourceFunction())__		DataStream<String> src1 = env.addSource(new NoOpSourceFunction())___		src0.union(src1).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		List<JobVertex> vertices = jobGraph.getVerticesSortedTopologicallyFromSources()__		assertTrue(vertices.get(0).isInputVertex())__		assertTrue(vertices.get(1).isInputVertex())___		assertNotNull(vertices.get(0).getID())__		assertNotNull(vertices.get(1).getID())___		assertNotEquals(vertices.get(0).getID(), vertices.get(1).getID())__	};tests,that,there,are,no,collisions,with,two,identical,sources,pre,src0,sink,src1,pre;test,public,void,test,node,hash,identical,sources,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src0,env,add,source,new,no,op,source,function,data,stream,string,src1,env,add,source,new,no,op,source,function,src0,union,src1,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,list,job,vertex,vertices,job,graph,get,vertices,sorted,topologically,from,sources,assert,true,vertices,get,0,is,input,vertex,assert,true,vertices,get,1,is,input,vertex,assert,not,null,vertices,get,0,get,id,assert,not,null,vertices,get,1,get,id,assert,not,equals,vertices,get,0,get,id,vertices,get,1,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalSources() throws Exception;1493403095;Tests that there are no collisions with two identical sources.__<pre>_[ (src0) ] --\_+--> [ (sink) ]_[ (src1) ] --/_</pre>;@Test_	public void testNodeHashIdenticalSources() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src0 = env.addSource(new NoOpSourceFunction())__		DataStream<String> src1 = env.addSource(new NoOpSourceFunction())___		src0.union(src1).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		List<JobVertex> vertices = jobGraph.getVerticesSortedTopologicallyFromSources()__		assertTrue(vertices.get(0).isInputVertex())__		assertTrue(vertices.get(1).isInputVertex())___		assertNotNull(vertices.get(0).getID())__		assertNotNull(vertices.get(1).getID())___		assertNotEquals(vertices.get(0).getID(), vertices.get(1).getID())__	};tests,that,there,are,no,collisions,with,two,identical,sources,pre,src0,sink,src1,pre;test,public,void,test,node,hash,identical,sources,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src0,env,add,source,new,no,op,source,function,data,stream,string,src1,env,add,source,new,no,op,source,function,src0,union,src1,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,list,job,vertex,vertices,job,graph,get,vertices,sorted,topologically,from,sources,assert,true,vertices,get,0,is,input,vertex,assert,true,vertices,get,1,is,input,vertex,assert,not,null,vertices,get,0,get,id,assert,not,null,vertices,get,1,get,id,assert,not,equals,vertices,get,0,get,id,vertices,get,1,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalSources() throws Exception;1495484544;Tests that there are no collisions with two identical sources.__<pre>_[ (src0) ] --\_+--> [ (sink) ]_[ (src1) ] --/_</pre>;@Test_	public void testNodeHashIdenticalSources() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src0 = env.addSource(new NoOpSourceFunction())__		DataStream<String> src1 = env.addSource(new NoOpSourceFunction())___		src0.union(src1).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		List<JobVertex> vertices = jobGraph.getVerticesSortedTopologicallyFromSources()__		assertTrue(vertices.get(0).isInputVertex())__		assertTrue(vertices.get(1).isInputVertex())___		assertNotNull(vertices.get(0).getID())__		assertNotNull(vertices.get(1).getID())___		assertNotEquals(vertices.get(0).getID(), vertices.get(1).getID())__	};tests,that,there,are,no,collisions,with,two,identical,sources,pre,src0,sink,src1,pre;test,public,void,test,node,hash,identical,sources,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src0,env,add,source,new,no,op,source,function,data,stream,string,src1,env,add,source,new,no,op,source,function,src0,union,src1,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,list,job,vertex,vertices,job,graph,get,vertices,sorted,topologically,from,sources,assert,true,vertices,get,0,is,input,vertex,assert,true,vertices,get,1,is,input,vertex,assert,not,null,vertices,get,0,get,id,assert,not,null,vertices,get,1,get,id,assert,not,equals,vertices,get,0,get,id,vertices,get,1,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalSources() throws Exception;1503598628;Tests that there are no collisions with two identical sources.__<pre>_[ (src0) ] --\_+--> [ (sink) ]_[ (src1) ] --/_</pre>;@Test_	public void testNodeHashIdenticalSources() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src0 = env.addSource(new NoOpSourceFunction())__		DataStream<String> src1 = env.addSource(new NoOpSourceFunction())___		src0.union(src1).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		List<JobVertex> vertices = jobGraph.getVerticesSortedTopologicallyFromSources()__		assertTrue(vertices.get(0).isInputVertex())__		assertTrue(vertices.get(1).isInputVertex())___		assertNotNull(vertices.get(0).getID())__		assertNotNull(vertices.get(1).getID())___		assertNotEquals(vertices.get(0).getID(), vertices.get(1).getID())__	};tests,that,there,are,no,collisions,with,two,identical,sources,pre,src0,sink,src1,pre;test,public,void,test,node,hash,identical,sources,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src0,env,add,source,new,no,op,source,function,data,stream,string,src1,env,add,source,new,no,op,source,function,src0,union,src1,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,list,job,vertex,vertices,job,graph,get,vertices,sorted,topologically,from,sources,assert,true,vertices,get,0,is,input,vertex,assert,true,vertices,get,1,is,input,vertex,assert,not,null,vertices,get,0,get,id,assert,not,null,vertices,get,1,get,id,assert,not,equals,vertices,get,0,get,id,vertices,get,1,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = IllegalArgumentException.class) 	public void testManualHashAssignmentCollisionThrowsException() throws Exception;1452526242;Tests that a collision on the manual hash throws an Exception.;@Test(expected = IllegalArgumentException.class)_	public void testManualHashAssignmentCollisionThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction()).uid("source") _				.addSink(new NoOpSinkFunction())___		_		env.getStreamGraph().getJobGraph()__	};tests,that,a,collision,on,the,manual,hash,throws,an,exception;test,expected,illegal,argument,exception,class,public,void,test,manual,hash,assignment,collision,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,uid,source,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = IllegalArgumentException.class) 	public void testManualHashAssignmentCollisionThrowsException() throws Exception;1456427030;Tests that a collision on the manual hash throws an Exception.;@Test(expected = IllegalArgumentException.class)_	public void testManualHashAssignmentCollisionThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction()).uid("source") _				.addSink(new NoOpSinkFunction())___		_		env.getStreamGraph().getJobGraph()__	};tests,that,a,collision,on,the,manual,hash,throws,an,exception;test,expected,illegal,argument,exception,class,public,void,test,manual,hash,assignment,collision,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,uid,source,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = IllegalArgumentException.class) 	public void testManualHashAssignmentCollisionThrowsException() throws Exception;1467726666;Tests that a collision on the manual hash throws an Exception.;@Test(expected = IllegalArgumentException.class)_	public void testManualHashAssignmentCollisionThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction()).uid("source") _				.addSink(new NoOpSinkFunction())___		_		env.getStreamGraph().getJobGraph()__	};tests,that,a,collision,on,the,manual,hash,throws,an,exception;test,expected,illegal,argument,exception,class,public,void,test,manual,hash,assignment,collision,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,uid,source,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = IllegalArgumentException.class) 	public void testManualHashAssignmentCollisionThrowsException() throws Exception;1472663071;Tests that a collision on the manual hash throws an Exception.;@Test(expected = IllegalArgumentException.class)_	public void testManualHashAssignmentCollisionThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction()).uid("source") _				.addSink(new NoOpSinkFunction())___		_		env.getStreamGraph().getJobGraph()__	};tests,that,a,collision,on,the,manual,hash,throws,an,exception;test,expected,illegal,argument,exception,class,public,void,test,manual,hash,assignment,collision,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,uid,source,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = IllegalArgumentException.class) 	public void testManualHashAssignmentCollisionThrowsException() throws Exception;1485181339;Tests that a collision on the manual hash throws an Exception.;@Test(expected = IllegalArgumentException.class)_	public void testManualHashAssignmentCollisionThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction()).uid("source") _				.addSink(new NoOpSinkFunction())___		_		env.getStreamGraph().getJobGraph()__	};tests,that,a,collision,on,the,manual,hash,throws,an,exception;test,expected,illegal,argument,exception,class,public,void,test,manual,hash,assignment,collision,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,uid,source,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = IllegalArgumentException.class) 	public void testManualHashAssignmentCollisionThrowsException() throws Exception;1493403095;Tests that a collision on the manual hash throws an Exception.;@Test(expected = IllegalArgumentException.class)_	public void testManualHashAssignmentCollisionThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction()).uid("source") _				.addSink(new NoOpSinkFunction())___		_		env.getStreamGraph().getJobGraph()__	};tests,that,a,collision,on,the,manual,hash,throws,an,exception;test,expected,illegal,argument,exception,class,public,void,test,manual,hash,assignment,collision,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,uid,source,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = IllegalArgumentException.class) 	public void testManualHashAssignmentCollisionThrowsException() throws Exception;1495484544;Tests that a collision on the manual hash throws an Exception.;@Test(expected = IllegalArgumentException.class)_	public void testManualHashAssignmentCollisionThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction()).uid("source") _				.addSink(new NoOpSinkFunction())___		_		env.getStreamGraph().getJobGraph()__	};tests,that,a,collision,on,the,manual,hash,throws,an,exception;test,expected,illegal,argument,exception,class,public,void,test,manual,hash,assignment,collision,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,uid,source,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test(expected = IllegalArgumentException.class) 	public void testManualHashAssignmentCollisionThrowsException() throws Exception;1503598628;Tests that a collision on the manual hash throws an Exception.;@Test(expected = IllegalArgumentException.class)_	public void testManualHashAssignmentCollisionThrowsException() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction()).uid("source") _				.addSink(new NoOpSinkFunction())___		_		env.getStreamGraph().getJobGraph()__	};tests,that,a,collision,on,the,manual,hash,throws,an,exception;test,expected,illegal,argument,exception,class,public,void,test,manual,hash,assignment,collision,throws,exception,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,uid,source,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1452526242;Verifies that no {@link JobVertexID} of the {@link JobGraph} is contained in the given map.;private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			assertFalse(ids.containsKey(vertex.getID()))__		}_	};verifies,that,no,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map;private,void,verify,ids,not,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,assert,false,ids,contains,key,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1456427030;Verifies that no {@link JobVertexID} of the {@link JobGraph} is contained in the given map.;private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			assertFalse(ids.containsKey(vertex.getID()))__		}_	};verifies,that,no,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map;private,void,verify,ids,not,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,assert,false,ids,contains,key,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1467726666;Verifies that no {@link JobVertexID} of the {@link JobGraph} is contained in the given map.;private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			assertFalse(ids.containsKey(vertex.getID()))__		}_	};verifies,that,no,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map;private,void,verify,ids,not,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,assert,false,ids,contains,key,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1472663071;Verifies that no {@link JobVertexID} of the {@link JobGraph} is contained in the given map.;private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			assertFalse(ids.containsKey(vertex.getID()))__		}_	};verifies,that,no,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map;private,void,verify,ids,not,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,assert,false,ids,contains,key,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1485181339;Verifies that no {@link JobVertexID} of the {@link JobGraph} is contained in the given map.;private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			assertFalse(ids.containsKey(vertex.getID()))__		}_	};verifies,that,no,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map;private,void,verify,ids,not,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,assert,false,ids,contains,key,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1493403095;Verifies that no {@link JobVertexID} of the {@link JobGraph} is contained in the given map.;private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			assertFalse(ids.containsKey(vertex.getID()))__		}_	};verifies,that,no,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map;private,void,verify,ids,not,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,assert,false,ids,contains,key,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1495484544;Verifies that no {@link JobVertexID} of the {@link JobGraph} is contained in the given map.;private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			assertFalse(ids.containsKey(vertex.getID()))__		}_	};verifies,that,no,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map;private,void,verify,ids,not,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,assert,false,ids,contains,key,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids);1503598628;Verifies that no {@link JobVertexID} of the {@link JobGraph} is contained in the given map.;private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {_		_		assertEquals(jobGraph.getNumberOfVertices(), ids.size())___		_		for (JobVertex vertex : jobGraph.getVertices()) {_			assertFalse(ids.containsKey(vertex.getID()))__		}_	};verifies,that,no,link,job,vertex,id,of,the,link,job,graph,is,contained,in,the,given,map;private,void,verify,ids,not,equal,job,graph,job,graph,map,job,vertex,id,string,ids,assert,equals,job,graph,get,number,of,vertices,ids,size,for,job,vertex,vertex,job,graph,get,vertices,assert,false,ids,contains,key,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testChangedOperatorName() throws Exception;1456427030;Tests that a changed operator name does not affect the hash.;@Test_	public void testChangedOperatorName() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "A").map(new NoOpMapFunction())__		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID expected = jobGraph.getVerticesAsArray()[0].getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "B").map(new NoOpMapFunction())__		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID actual = jobGraph.getVerticesAsArray()[0].getID()___		assertEquals(expected, actual)__	};tests,that,a,changed,operator,name,does,not,affect,the,hash;test,public,void,test,changed,operator,name,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,a,map,new,no,op,map,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,expected,job,graph,get,vertices,as,array,0,get,id,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,b,map,new,no,op,map,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,actual,job,graph,get,vertices,as,array,0,get,id,assert,equals,expected,actual
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testChangedOperatorName() throws Exception;1467726666;Tests that a changed operator name does not affect the hash.;@Test_	public void testChangedOperatorName() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "A").map(new NoOpMapFunction())__		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID expected = jobGraph.getVerticesAsArray()[0].getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "B").map(new NoOpMapFunction())__		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID actual = jobGraph.getVerticesAsArray()[0].getID()___		assertEquals(expected, actual)__	};tests,that,a,changed,operator,name,does,not,affect,the,hash;test,public,void,test,changed,operator,name,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,a,map,new,no,op,map,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,expected,job,graph,get,vertices,as,array,0,get,id,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,b,map,new,no,op,map,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,actual,job,graph,get,vertices,as,array,0,get,id,assert,equals,expected,actual
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testChangedOperatorName() throws Exception;1472663071;Tests that a changed operator name does not affect the hash.;@Test_	public void testChangedOperatorName() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "A").map(new NoOpMapFunction())__		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID expected = jobGraph.getVerticesAsArray()[0].getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "B").map(new NoOpMapFunction())__		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID actual = jobGraph.getVerticesAsArray()[0].getID()___		assertEquals(expected, actual)__	};tests,that,a,changed,operator,name,does,not,affect,the,hash;test,public,void,test,changed,operator,name,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,a,map,new,no,op,map,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,expected,job,graph,get,vertices,as,array,0,get,id,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,b,map,new,no,op,map,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,actual,job,graph,get,vertices,as,array,0,get,id,assert,equals,expected,actual
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testChangedOperatorName() throws Exception;1485181339;Tests that a changed operator name does not affect the hash.;@Test_	public void testChangedOperatorName() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "A").map(new NoOpMapFunction())__		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID expected = jobGraph.getVerticesAsArray()[0].getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "B").map(new NoOpMapFunction())__		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID actual = jobGraph.getVerticesAsArray()[0].getID()___		assertEquals(expected, actual)__	};tests,that,a,changed,operator,name,does,not,affect,the,hash;test,public,void,test,changed,operator,name,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,a,map,new,no,op,map,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,expected,job,graph,get,vertices,as,array,0,get,id,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,b,map,new,no,op,map,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,actual,job,graph,get,vertices,as,array,0,get,id,assert,equals,expected,actual
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testChangedOperatorName() throws Exception;1493403095;Tests that a changed operator name does not affect the hash.;@Test_	public void testChangedOperatorName() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "A").map(new NoOpMapFunction())__		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID expected = jobGraph.getVerticesAsArray()[0].getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "B").map(new NoOpMapFunction())__		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID actual = jobGraph.getVerticesAsArray()[0].getID()___		assertEquals(expected, actual)__	};tests,that,a,changed,operator,name,does,not,affect,the,hash;test,public,void,test,changed,operator,name,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,a,map,new,no,op,map,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,expected,job,graph,get,vertices,as,array,0,get,id,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,b,map,new,no,op,map,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,actual,job,graph,get,vertices,as,array,0,get,id,assert,equals,expected,actual
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testChangedOperatorName() throws Exception;1495484544;Tests that a changed operator name does not affect the hash.;@Test_	public void testChangedOperatorName() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "A").map(new NoOpMapFunction())__		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID expected = jobGraph.getVerticesAsArray()[0].getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "B").map(new NoOpMapFunction())__		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID actual = jobGraph.getVerticesAsArray()[0].getID()___		assertEquals(expected, actual)__	};tests,that,a,changed,operator,name,does,not,affect,the,hash;test,public,void,test,changed,operator,name,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,a,map,new,no,op,map,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,expected,job,graph,get,vertices,as,array,0,get,id,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,b,map,new,no,op,map,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,actual,job,graph,get,vertices,as,array,0,get,id,assert,equals,expected,actual
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testChangedOperatorName() throws Exception;1503598628;Tests that a changed operator name does not affect the hash.;@Test_	public void testChangedOperatorName() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "A").map(new NoOpMapFunction())__		JobGraph jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID expected = jobGraph.getVerticesAsArray()[0].getID()___		env = StreamExecutionEnvironment.createLocalEnvironment()__		env.addSource(new NoOpSourceFunction(), "B").map(new NoOpMapFunction())__		jobGraph = env.getStreamGraph().getJobGraph()___		JobVertexID actual = jobGraph.getVerticesAsArray()[0].getID()___		assertEquals(expected, actual)__	};tests,that,a,changed,operator,name,does,not,affect,the,hash;test,public,void,test,changed,operator,name,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,a,map,new,no,op,map,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,expected,job,graph,get,vertices,as,array,0,get,id,env,stream,execution,environment,create,local,environment,env,add,source,new,no,op,source,function,b,map,new,no,op,map,function,job,graph,env,get,stream,graph,get,job,graph,job,vertex,id,actual,job,graph,get,vertices,as,array,0,get,id,assert,equals,expected,actual
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignmentForStartNodeInInChain() throws Exception;1452526242;Tests that a manual hash at the beginning of a chain is accepted.__<p>This should work, because the ID is used at the beginning of a chain. This is currently_not allowed for intermediate nodes (see {@link #testManualHashAssignmentForIntermediateNodeInChainThrowsException()}).;@Test_	public void testManualHashAssignmentForStartNodeInInChain() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,at,the,beginning,of,a,chain,is,accepted,p,this,should,work,because,the,id,is,used,at,the,beginning,of,a,chain,this,is,currently,not,allowed,for,intermediate,nodes,see,link,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception;test,public,void,test,manual,hash,assignment,for,start,node,in,in,chain,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignmentForStartNodeInInChain() throws Exception;1456427030;Tests that a manual hash at the beginning of a chain is accepted.__<p>This should work, because the ID is used at the beginning of a chain. This is currently_not allowed for intermediate nodes (see {@link #testManualHashAssignmentForIntermediateNodeInChainThrowsException()}).;@Test_	public void testManualHashAssignmentForStartNodeInInChain() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,at,the,beginning,of,a,chain,is,accepted,p,this,should,work,because,the,id,is,used,at,the,beginning,of,a,chain,this,is,currently,not,allowed,for,intermediate,nodes,see,link,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception;test,public,void,test,manual,hash,assignment,for,start,node,in,in,chain,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignmentForStartNodeInInChain() throws Exception;1467726666;Tests that a manual hash at the beginning of a chain is accepted.__<p>This should work, because the ID is used at the beginning of a chain. This is currently_not allowed for intermediate nodes (see {@link #testManualHashAssignmentForIntermediateNodeInChainThrowsException()}).;@Test_	public void testManualHashAssignmentForStartNodeInInChain() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,at,the,beginning,of,a,chain,is,accepted,p,this,should,work,because,the,id,is,used,at,the,beginning,of,a,chain,this,is,currently,not,allowed,for,intermediate,nodes,see,link,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception;test,public,void,test,manual,hash,assignment,for,start,node,in,in,chain,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignmentForStartNodeInInChain() throws Exception;1472663071;Tests that a manual hash at the beginning of a chain is accepted.__<p>This should work, because the ID is used at the beginning of a chain. This is currently_not allowed for intermediate nodes (see {@link #testManualHashAssignmentForIntermediateNodeInChainThrowsException()}).;@Test_	public void testManualHashAssignmentForStartNodeInInChain() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,at,the,beginning,of,a,chain,is,accepted,p,this,should,work,because,the,id,is,used,at,the,beginning,of,a,chain,this,is,currently,not,allowed,for,intermediate,nodes,see,link,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception;test,public,void,test,manual,hash,assignment,for,start,node,in,in,chain,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignmentForStartNodeInInChain() throws Exception;1485181339;Tests that a manual hash at the beginning of a chain is accepted.__<p>This should work, because the ID is used at the beginning of a chain. This is currently_not allowed for intermediate nodes (see {@link #testManualHashAssignmentForIntermediateNodeInChainThrowsException()}).;@Test_	public void testManualHashAssignmentForStartNodeInInChain() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,at,the,beginning,of,a,chain,is,accepted,p,this,should,work,because,the,id,is,used,at,the,beginning,of,a,chain,this,is,currently,not,allowed,for,intermediate,nodes,see,link,test,manual,hash,assignment,for,intermediate,node,in,chain,throws,exception;test,public,void,test,manual,hash,assignment,for,start,node,in,in,chain,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignmentForStartNodeInInChain() throws Exception;1493403095;Tests that a manual hash at the beginning of a chain is accepted.;@Test_	public void testManualHashAssignmentForStartNodeInInChain() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,at,the,beginning,of,a,chain,is,accepted;test,public,void,test,manual,hash,assignment,for,start,node,in,in,chain,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignmentForStartNodeInInChain() throws Exception;1495484544;Tests that a manual hash at the beginning of a chain is accepted.;@Test_	public void testManualHashAssignmentForStartNodeInInChain() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,at,the,beginning,of,a,chain,is,accepted;test,public,void,test,manual,hash,assignment,for,start,node,in,in,chain,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testManualHashAssignmentForStartNodeInInChain() throws Exception;1503598628;Tests that a manual hash at the beginning of a chain is accepted.;@Test_	public void testManualHashAssignmentForStartNodeInInChain() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)___		env.addSource(new NoOpSourceFunction()).uid("source")_				.map(new NoOpMapFunction())_				.addSink(new NoOpSinkFunction())___		env.getStreamGraph().getJobGraph()__	};tests,that,a,manual,hash,at,the,beginning,of,a,chain,is,accepted;test,public,void,test,manual,hash,assignment,for,start,node,in,in,chain,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,add,source,new,no,op,source,function,uid,source,map,new,no,op,map,function,add,sink,new,no,op,sink,function,env,get,stream,graph,get,job,graph
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalNodes() throws Exception;1452526242;Tests that there are no collisions with two identical intermediate nodes connected to the_same predecessor.__<pre>_/-> [ (map) ] -> [ (sink) ]_[ (src) ] -+_\-> [ (map) ] -> [ (sink) ]_</pre>;@Test_	public void testNodeHashIdenticalNodes() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> vertexIds = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(vertexIds.add(vertex.getID()))__		}_	};tests,that,there,are,no,collisions,with,two,identical,intermediate,nodes,connected,to,the,same,predecessor,pre,map,sink,src,map,sink,pre;test,public,void,test,node,hash,identical,nodes,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,vertex,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,vertex,ids,add,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalNodes() throws Exception;1456427030;Tests that there are no collisions with two identical intermediate nodes connected to the_same predecessor.__<pre>_/-> [ (map) ] -> [ (sink) ]_[ (src) ] -+_\-> [ (map) ] -> [ (sink) ]_</pre>;@Test_	public void testNodeHashIdenticalNodes() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> vertexIds = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(vertexIds.add(vertex.getID()))__		}_	};tests,that,there,are,no,collisions,with,two,identical,intermediate,nodes,connected,to,the,same,predecessor,pre,map,sink,src,map,sink,pre;test,public,void,test,node,hash,identical,nodes,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,vertex,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,vertex,ids,add,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalNodes() throws Exception;1467726666;Tests that there are no collisions with two identical intermediate nodes connected to the_same predecessor.__<pre>_/-> [ (map) ] -> [ (sink) ]_[ (src) ] -+_\-> [ (map) ] -> [ (sink) ]_</pre>;@Test_	public void testNodeHashIdenticalNodes() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> vertexIds = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(vertexIds.add(vertex.getID()))__		}_	};tests,that,there,are,no,collisions,with,two,identical,intermediate,nodes,connected,to,the,same,predecessor,pre,map,sink,src,map,sink,pre;test,public,void,test,node,hash,identical,nodes,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,vertex,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,vertex,ids,add,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalNodes() throws Exception;1472663071;Tests that there are no collisions with two identical intermediate nodes connected to the_same predecessor.__<pre>_/-> [ (map) ] -> [ (sink) ]_[ (src) ] -+_\-> [ (map) ] -> [ (sink) ]_</pre>;@Test_	public void testNodeHashIdenticalNodes() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> vertexIds = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(vertexIds.add(vertex.getID()))__		}_	};tests,that,there,are,no,collisions,with,two,identical,intermediate,nodes,connected,to,the,same,predecessor,pre,map,sink,src,map,sink,pre;test,public,void,test,node,hash,identical,nodes,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,vertex,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,vertex,ids,add,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalNodes() throws Exception;1485181339;Tests that there are no collisions with two identical intermediate nodes connected to the_same predecessor.__<pre>_/-> [ (map) ] -> [ (sink) ]_[ (src) ] -+_\-> [ (map) ] -> [ (sink) ]_</pre>;@Test_	public void testNodeHashIdenticalNodes() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> vertexIds = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(vertexIds.add(vertex.getID()))__		}_	};tests,that,there,are,no,collisions,with,two,identical,intermediate,nodes,connected,to,the,same,predecessor,pre,map,sink,src,map,sink,pre;test,public,void,test,node,hash,identical,nodes,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,vertex,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,vertex,ids,add,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalNodes() throws Exception;1493403095;Tests that there are no collisions with two identical intermediate nodes connected to the_same predecessor.__<pre>_/-> [ (map) ] -> [ (sink) ]_[ (src) ] -+_\-> [ (map) ] -> [ (sink) ]_</pre>;@Test_	public void testNodeHashIdenticalNodes() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> vertexIds = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(vertexIds.add(vertex.getID()))__		}_	};tests,that,there,are,no,collisions,with,two,identical,intermediate,nodes,connected,to,the,same,predecessor,pre,map,sink,src,map,sink,pre;test,public,void,test,node,hash,identical,nodes,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,vertex,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,vertex,ids,add,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalNodes() throws Exception;1495484544;Tests that there are no collisions with two identical intermediate nodes connected to the_same predecessor.__<pre>_/-> [ (map) ] -> [ (sink) ]_[ (src) ] -+_\-> [ (map) ] -> [ (sink) ]_</pre>;@Test_	public void testNodeHashIdenticalNodes() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> vertexIds = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(vertexIds.add(vertex.getID()))__		}_	};tests,that,there,are,no,collisions,with,two,identical,intermediate,nodes,connected,to,the,same,predecessor,pre,map,sink,src,map,sink,pre;test,public,void,test,node,hash,identical,nodes,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,vertex,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,vertex,ids,add,vertex,get,id
StreamingJobGraphGeneratorNodeHashTest -> @Test 	public void testNodeHashIdenticalNodes() throws Exception;1503598628;Tests that there are no collisions with two identical intermediate nodes connected to the_same predecessor.__<pre>_/-> [ (map) ] -> [ (sink) ]_[ (src) ] -+_\-> [ (map) ] -> [ (sink) ]_</pre>;@Test_	public void testNodeHashIdenticalNodes() throws Exception {_		StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment()__		env.setParallelism(4)__		env.disableOperatorChaining()___		DataStream<String> src = env.addSource(new NoOpSourceFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction())___		JobGraph jobGraph = env.getStreamGraph().getJobGraph()__		Set<JobVertexID> vertexIds = new HashSet<>()__		for (JobVertex vertex : jobGraph.getVertices()) {_			assertTrue(vertexIds.add(vertex.getID()))__		}_	};tests,that,there,are,no,collisions,with,two,identical,intermediate,nodes,connected,to,the,same,predecessor,pre,map,sink,src,map,sink,pre;test,public,void,test,node,hash,identical,nodes,throws,exception,stream,execution,environment,env,stream,execution,environment,create,local,environment,env,set,parallelism,4,env,disable,operator,chaining,data,stream,string,src,env,add,source,new,no,op,source,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,src,map,new,no,op,map,function,add,sink,new,no,op,sink,function,job,graph,job,graph,env,get,stream,graph,get,job,graph,set,job,vertex,id,vertex,ids,new,hash,set,for,job,vertex,vertex,job,graph,get,vertices,assert,true,vertex,ids,add,vertex,get,id
