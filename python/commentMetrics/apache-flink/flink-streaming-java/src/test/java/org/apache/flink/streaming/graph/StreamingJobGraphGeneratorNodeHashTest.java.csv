commented;modifiers;parameterAmount;loc;comment;code
true;public;0;55;/**  * Creates the same flow twice and checks that all IDs are the same.  *  * <pre>  * [ (src) -> (map) -> (filter) -> (reduce) -> (map) -> (sink) ]  *                                                       //  * [ (src) -> (filter) ] -------------------------------//  *                                                      /  * [ (src) -> (filter) ] ------------------------------/  * </pre>  */ ;// ------------------------------------------------------------------------ // Deterministic hash assignment // ------------------------------------------------------------------------ /**  * Creates the same flow twice and checks that all IDs are the same.  *  * <pre>  * [ (src) -> (map) -> (filter) -> (reduce) -> (map) -> (sink) ]  *                                                       //  * [ (src) -> (filter) ] -------------------------------//  *                                                      /  * [ (src) -> (filter) ] ------------------------------/  * </pre>  */ @Test public void testNodeHashIsDeterministic() throws Exception {     StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     DataStream<String> src0 = env.addSource(new NoOpSourceFunction(), "src0").map(new NoOpMapFunction()).filter(new NoOpFilterFunction()).keyBy(new NoOpKeySelector()).reduce(new NoOpReduceFunction()).name("reduce").     DataStream<String> src1 = env.addSource(new NoOpSourceFunction(), "src1").filter(new NoOpFilterFunction()).     DataStream<String> src2 = env.addSource(new NoOpSourceFunction(), "src2").filter(new NoOpFilterFunction()).     src0.map(new NoOpMapFunction()).union(src1, src2).addSink(new NoOpSinkFunction()).name("sink").     JobGraph jobGraph = env.getStreamGraph().getJobGraph().     final Map<JobVertexID, String> ids = rememberIds(jobGraph).     // Do it again and verify     env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     src0 = env.addSource(new NoOpSourceFunction(), "src0").map(new NoOpMapFunction()).filter(new NoOpFilterFunction()).keyBy(new NoOpKeySelector()).reduce(new NoOpReduceFunction()).name("reduce").     src1 = env.addSource(new NoOpSourceFunction(), "src1").filter(new NoOpFilterFunction()).     src2 = env.addSource(new NoOpSourceFunction(), "src2").filter(new NoOpFilterFunction()).     src0.map(new NoOpMapFunction()).union(src1, src2).addSink(new NoOpSinkFunction()).name("sink").     jobGraph = env.getStreamGraph().getJobGraph().     verifyIdsEqual(jobGraph, ids). }
true;public;0;22;/**  * Tests that there are no collisions with two identical sources.  *  * <pre>  * [ (src0) ] --\  *               +--> [ (sink) ]  * [ (src1) ] --/  * </pre>  */ ;/**  * Tests that there are no collisions with two identical sources.  *  * <pre>  * [ (src0) ] --\  *               +--> [ (sink) ]  * [ (src1) ] --/  * </pre>  */ @Test public void testNodeHashIdenticalSources() throws Exception {     StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     env.disableOperatorChaining().     DataStream<String> src0 = env.addSource(new NoOpSourceFunction()).     DataStream<String> src1 = env.addSource(new NoOpSourceFunction()).     src0.union(src1).addSink(new NoOpSinkFunction()).     JobGraph jobGraph = env.getStreamGraph().getJobGraph().     List<JobVertex> vertices = jobGraph.getVerticesSortedTopologicallyFromSources().     assertTrue(vertices.get(0).isInputVertex()).     assertTrue(vertices.get(1).isInputVertex()).     assertNotNull(vertices.get(0).getID()).     assertNotNull(vertices.get(1).getID()).     assertNotEquals(vertices.get(0).getID(), vertices.get(1).getID()). }
true;public;0;31;/**  * Tests that (un)chaining affects the node hash (for sources).  *  * <pre>  * A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]  * B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]  * </pre>  *  * <p>The hashes for the single vertex in A and the source vertex in B need to be different.  */ ;/**  * Tests that (un)chaining affects the node hash (for sources).  *  * <pre>  * A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]  * B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]  * </pre>  *  * <p>The hashes for the single vertex in A and the source vertex in B need to be different.  */ @Test public void testNodeHashAfterSourceUnchaining() throws Exception {     StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     env.addSource(new NoOpSourceFunction()).map(new NoOpMapFunction()).filter(new NoOpFilterFunction()).addSink(new NoOpSinkFunction()).     JobGraph jobGraph = env.getStreamGraph().getJobGraph().     JobVertexID sourceId = jobGraph.getVerticesSortedTopologicallyFromSources().get(0).getID().     env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     env.addSource(new NoOpSourceFunction()).map(new NoOpMapFunction()).startNewChain().filter(new NoOpFilterFunction()).addSink(new NoOpSinkFunction()).     jobGraph = env.getStreamGraph().getJobGraph().     JobVertexID unchainedSourceId = jobGraph.getVerticesSortedTopologicallyFromSources().get(0).getID().     assertNotEquals(sourceId, unchainedSourceId). }
true;public;0;35;/**  * Tests that (un)chaining affects the node hash (for intermediate nodes).  *  * <pre>  * A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]  * B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]  * </pre>  *  * <p>The hashes for the single vertex in A and the source vertex in B need to be different.  */ ;/**  * Tests that (un)chaining affects the node hash (for intermediate nodes).  *  * <pre>  * A (chained): [ (src0) -> (map) -> (filter) -> (sink) ]  * B (unchained): [ (src0) ] -> [ (map) -> (filter) -> (sink) ]  * </pre>  *  * <p>The hashes for the single vertex in A and the source vertex in B need to be different.  */ @Test public void testNodeHashAfterIntermediateUnchaining() throws Exception {     StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     env.addSource(new NoOpSourceFunction()).map(new NoOpMapFunction()).name("map").startNewChain().filter(new NoOpFilterFunction()).addSink(new NoOpSinkFunction()).     JobGraph jobGraph = env.getStreamGraph().getJobGraph().     JobVertex chainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1).     assertTrue(chainedMap.getName().startsWith("map")).     JobVertexID chainedMapId = chainedMap.getID().     env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     env.addSource(new NoOpSourceFunction()).map(new NoOpMapFunction()).name("map").startNewChain().filter(new NoOpFilterFunction()).startNewChain().addSink(new NoOpSinkFunction()).     jobGraph = env.getStreamGraph().getJobGraph().     JobVertex unchainedMap = jobGraph.getVerticesSortedTopologicallyFromSources().get(1).     assertEquals("map", unchainedMap.getName()).     JobVertexID unchainedMapId = unchainedMap.getID().     assertNotEquals(chainedMapId, unchainedMapId). }
true;public;0;18;/**  * Tests that there are no collisions with two identical intermediate nodes connected to the  * same predecessor.  *  * <pre>  *             /-> [ (map) ] -> [ (sink) ]  * [ (src) ] -+  *             \-> [ (map) ] -> [ (sink) ]  * </pre>  */ ;/**  * Tests that there are no collisions with two identical intermediate nodes connected to the  * same predecessor.  *  * <pre>  *             /-> [ (map) ] -> [ (sink) ]  * [ (src) ] -+  *             \-> [ (map) ] -> [ (sink) ]  * </pre>  */ @Test public void testNodeHashIdenticalNodes() throws Exception {     StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     env.disableOperatorChaining().     DataStream<String> src = env.addSource(new NoOpSourceFunction()).     src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction()).     src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction()).     JobGraph jobGraph = env.getStreamGraph().getJobGraph().     Set<JobVertexID> vertexIds = new HashSet<>().     for (JobVertex vertex : jobGraph.getVertices()) {         assertTrue(vertexIds.add(vertex.getID())).     } }
true;public;0;16;/**  * Tests that a changed operator name does not affect the hash.  */ ;/**  * Tests that a changed operator name does not affect the hash.  */ @Test public void testChangedOperatorName() throws Exception {     StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment().     env.addSource(new NoOpSourceFunction(), "A").map(new NoOpMapFunction()).     JobGraph jobGraph = env.getStreamGraph().getJobGraph().     JobVertexID expected = jobGraph.getVerticesAsArray()[0].getID().     env = StreamExecutionEnvironment.createLocalEnvironment().     env.addSource(new NoOpSourceFunction(), "B").map(new NoOpMapFunction()).     jobGraph = env.getStreamGraph().getJobGraph().     JobVertexID actual = jobGraph.getVerticesAsArray()[0].getID().     assertEquals(expected, actual). }
true;public;0;58;/**  * Tests that manual hash assignments are mapped to the same operator ID.  *  * <pre>  *                     /-> [ (map) ] -> [ (sink)@sink0 ]  * [ (src@source ) ] -+  *                     \-> [ (map) ] -> [ (sink)@sink1 ]  * </pre>  *  * <pre>  *                    /-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink0 ]  * [ (src)@source ] -+  *                   \-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink1 ]  * </pre>  */ ;// ------------------------------------------------------------------------ // Manual hash assignment // ------------------------------------------------------------------------ /**  * Tests that manual hash assignments are mapped to the same operator ID.  *  * <pre>  *                     /-> [ (map) ] -> [ (sink)@sink0 ]  * [ (src@source ) ] -+  *                     \-> [ (map) ] -> [ (sink)@sink1 ]  * </pre>  *  * <pre>  *                    /-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink0 ]  * [ (src)@source ] -+  *                   \-> [ (map) ] -> [ (reduce) ] -> [ (sink)@sink1 ]  * </pre>  */ @Test public void testManualHashAssignment() throws Exception {     StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     env.disableOperatorChaining().     DataStream<String> src = env.addSource(new NoOpSourceFunction()).name("source").uid("source").     src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction()).name("sink0").uid("sink0").     src.map(new NoOpMapFunction()).addSink(new NoOpSinkFunction()).name("sink1").uid("sink1").     JobGraph jobGraph = env.getStreamGraph().getJobGraph().     Set<JobVertexID> ids = new HashSet<>().     for (JobVertex vertex : jobGraph.getVertices()) {         assertTrue(ids.add(vertex.getID())).     }     // Resubmit a slightly different program     env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     env.disableOperatorChaining().     src = env.addSource(new NoOpSourceFunction()).map(new NoOpMapFunction()).name("source").uid("source").     src.map(new NoOpMapFunction()).keyBy(new NoOpKeySelector()).reduce(new NoOpReduceFunction()).addSink(new NoOpSinkFunction()).name("sink0").uid("sink0").     src.map(new NoOpMapFunction()).keyBy(new NoOpKeySelector()).reduce(new NoOpReduceFunction()).addSink(new NoOpSinkFunction()).name("sink1").uid("sink1").     JobGraph newJobGraph = env.getStreamGraph().getJobGraph().     assertNotEquals(jobGraph.getJobID(), newJobGraph.getJobID()).     for (JobVertex vertex : newJobGraph.getVertices()) {         // Verify that the expected IDs are the same         if (vertex.getName().endsWith("source") || vertex.getName().endsWith("sink0") || vertex.getName().endsWith("sink1")) {             assertTrue(ids.contains(vertex.getID())).         }     } }
true;public;0;13;/**  * Tests that a collision on the manual hash throws an Exception.  */ ;/**  * Tests that a collision on the manual hash throws an Exception.  */ @Test(expected = IllegalArgumentException.class) public void testManualHashAssignmentCollisionThrowsException() throws Exception {     StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     env.disableOperatorChaining().     env.addSource(new NoOpSourceFunction()).uid("source").map(new NoOpMapFunction()).uid(// Collision     "source").addSink(new NoOpSinkFunction()).     // This call is necessary to generate the job graph     env.getStreamGraph().getJobGraph(). }
true;public;0;12;/**  * Tests that a manual hash for an intermediate chain node is accepted.  */ ;/**  * Tests that a manual hash for an intermediate chain node is accepted.  */ @Test public void testManualHashAssignmentForIntermediateNodeInChain() throws Exception {     StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     env.addSource(new NoOpSourceFunction()).map(new NoOpMapFunction()).uid("map").addSink(new NoOpSinkFunction()).     env.getStreamGraph().getJobGraph(). }
true;public;0;11;/**  * Tests that a manual hash at the beginning of a chain is accepted.  */ ;/**  * Tests that a manual hash at the beginning of a chain is accepted.  */ @Test public void testManualHashAssignmentForStartNodeInInChain() throws Exception {     StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment().     env.setParallelism(4).     env.addSource(new NoOpSourceFunction()).uid("source").map(new NoOpMapFunction()).addSink(new NoOpSinkFunction()).     env.getStreamGraph().getJobGraph(). }
false;public;0;20;;@Test public void testUserProvidedHashing() {     StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment().     List<String> userHashes = Arrays.asList("aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb").     env.addSource(new NoOpSourceFunction(), "src").setUidHash(userHashes.get(0)).map(new NoOpMapFunction()).filter(new NoOpFilterFunction()).keyBy(new NoOpKeySelector()).reduce(new NoOpReduceFunction()).name("reduce").setUidHash(userHashes.get(1)).     StreamGraph streamGraph = env.getStreamGraph().     int idx = 1.     for (JobVertex jobVertex : streamGraph.getJobGraph().getVertices()) {         List<JobVertexID> idAlternatives = jobVertex.getIdAlternatives().         Assert.assertEquals(idAlternatives.get(idAlternatives.size() - 1).toString(), userHashes.get(idx)).         --idx.     } }
false;public;0;12;;@Test public void testUserProvidedHashingOnChainSupported() {     StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment().     env.addSource(new NoOpSourceFunction(), "src").setUidHash("aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa").map(new NoOpMapFunction()).setUidHash("bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb").filter(new NoOpFilterFunction()).setUidHash("cccccccccccccccccccccccccccccccc").keyBy(new NoOpKeySelector()).reduce(new NoOpReduceFunction()).name("reduce").setUidHash("dddddddddddddddddddddddddddddddd").     env.getStreamGraph().getJobGraph(). }
true;private;1;7;/**  * Returns a {@link JobVertexID} to vertex name mapping for the given graph.  */ ;// ------------------------------------------------------------------------ /**  * Returns a {@link JobVertexID} to vertex name mapping for the given graph.  */ private Map<JobVertexID, String> rememberIds(JobGraph jobGraph) {     final Map<JobVertexID, String> ids = new HashMap<>().     for (JobVertex vertex : jobGraph.getVertices()) {         ids.put(vertex.getID(), vertex.getName()).     }     return ids. }
true;private;2;11;/**  * Verifies that each {@link JobVertexID} of the {@link JobGraph} is contained in the given map  * and mapped to the same vertex name.  */ ;/**  * Verifies that each {@link JobVertexID} of the {@link JobGraph} is contained in the given map  * and mapped to the same vertex name.  */ private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {     // Verify same number of vertices     assertEquals(jobGraph.getNumberOfVertices(), ids.size()).     // Verify that all IDs->name mappings are identical     for (JobVertex vertex : jobGraph.getVertices()) {         String expectedName = ids.get(vertex.getID()).         assertNotNull(expectedName).         assertEquals(expectedName, vertex.getName()).     } }
true;private;2;9;/**  * Verifies that no {@link JobVertexID} of the {@link JobGraph} is contained in the given map.  */ ;/**  * Verifies that no {@link JobVertexID} of the {@link JobGraph} is contained in the given map.  */ private void verifyIdsNotEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {     // Verify same number of vertices     assertEquals(jobGraph.getNumberOfVertices(), ids.size()).     // Verify that all IDs->name mappings are identical     for (JobVertex vertex : jobGraph.getVertices()) {         assertFalse(ids.containsKey(vertex.getID())).     } }
false;public;1;3;;@Override public void run(SourceContext<String> ctx) throws Exception { }
false;public;0;3;;@Override public void cancel() { }
false;public;1;3;;@Override public void invoke(String value) throws Exception { }
false;public;1;4;;@Override public String map(String value) throws Exception {     return value. }
false;public;1;4;;@Override public boolean filter(String value) throws Exception {     return true. }
false;public;1;4;;@Override public String getKey(String value) throws Exception {     return value. }
false;public;2;4;;@Override public String reduce(String value1, String value2) throws Exception {     return value1. }
