commented;modifiers;parameterAmount;loc;comment;code
false;private;4;106;;private AbstractYarnClusterDescriptor createDescriptor(Configuration configuration, YarnConfiguration yarnConfiguration, String configurationDirectory, CommandLine cmd) {     AbstractYarnClusterDescriptor yarnClusterDescriptor = getClusterDescriptor(configuration, yarnConfiguration, configurationDirectory).     // Jar Path     final Path localJarPath.     if (cmd.hasOption(flinkJar.getOpt())) {         String userPath = cmd.getOptionValue(flinkJar.getOpt()).         if (!userPath.startsWith("file://")) {             userPath = "file://" + userPath.         }         localJarPath = new Path(userPath).     } else {         LOG.info("No path for the flink jar passed. Using the location of " + yarnClusterDescriptor.getClass() + " to locate the jar").         String encodedJarPath = yarnClusterDescriptor.getClass().getProtectionDomain().getCodeSource().getLocation().getPath().         final String decodedPath.         try {             // we have to decode the url encoded parts of the path             decodedPath = URLDecoder.decode(encodedJarPath, Charset.defaultCharset().name()).         } catch (UnsupportedEncodingException e) {             throw new RuntimeException("Couldn't decode the encoded Flink dist jar path: " + encodedJarPath + " Please supply a path manually via the -" + flinkJar.getOpt() + " option.").         }         // check whether it's actually a jar file --> when testing we execute this class without a flink-dist jar         if (decodedPath.endsWith(".jar")) {             localJarPath = new Path(new File(decodedPath).toURI()).         } else {             localJarPath = null.         }     }     if (localJarPath != null) {         yarnClusterDescriptor.setLocalJarPath(localJarPath).     }     List<File> shipFiles = new ArrayList<>().     // path to directories to ship     if (cmd.hasOption(shipPath.getOpt())) {         String[] shipPaths = cmd.getOptionValues(this.shipPath.getOpt()).         for (String shipPath : shipPaths) {             File shipDir = new File(shipPath).             if (shipDir.isDirectory()) {                 shipFiles.add(shipDir).             } else {                 LOG.warn("Ship directory {} is not a directory. Ignoring it.", shipDir.getAbsolutePath()).             }         }     }     yarnClusterDescriptor.addShipFiles(shipFiles).     // queue     if (cmd.hasOption(queue.getOpt())) {         yarnClusterDescriptor.setQueue(cmd.getOptionValue(queue.getOpt())).     }     final Properties properties = cmd.getOptionProperties(dynamicproperties.getOpt()).     String[] dynamicProperties = properties.stringPropertyNames().stream().flatMap((String key) -> {         final String value = properties.getProperty(key).         if (value != null) {             return Stream.of(key + dynamicproperties.getValueSeparator() + value).         } else {             return Stream.empty().         }     }).toArray(String[]::new).     String dynamicPropertiesEncoded = StringUtils.join(dynamicProperties, YARN_DYNAMIC_PROPERTIES_SEPARATOR).     yarnClusterDescriptor.setDynamicPropertiesEncoded(dynamicPropertiesEncoded).     if (cmd.hasOption(YARN_DETACHED_OPTION.getOpt()) || cmd.hasOption(DETACHED_OPTION.getOpt())) {         yarnClusterDescriptor.setDetachedMode(true).     }     if (cmd.hasOption(name.getOpt())) {         yarnClusterDescriptor.setName(cmd.getOptionValue(name.getOpt())).     }     if (cmd.hasOption(zookeeperNamespace.getOpt())) {         String zookeeperNamespaceValue = cmd.getOptionValue(this.zookeeperNamespace.getOpt()).         yarnClusterDescriptor.setZookeeperNamespace(zookeeperNamespaceValue).     }     if (cmd.hasOption(nodeLabel.getOpt())) {         String nodeLabelValue = cmd.getOptionValue(this.nodeLabel.getOpt()).         yarnClusterDescriptor.setNodeLabel(nodeLabelValue).     }     return yarnClusterDescriptor. }
false;private;2;29;;private ClusterSpecification createClusterSpecification(Configuration configuration, CommandLine cmd) {     if (cmd.hasOption(container.getOpt())) {         // number of containers is required option!         LOG.info("The argument {} is deprecated in will be ignored.", container.getOpt()).     }     // TODO: The number of task manager should be deprecated soon     final int numberTaskManagers.     if (cmd.hasOption(container.getOpt())) {         numberTaskManagers = Integer.valueOf(cmd.getOptionValue(container.getOpt())).     } else {         numberTaskManagers = 1.     }     // JobManager Memory     final int jobManagerMemoryMB = ConfigurationUtils.getJobManagerHeapMemory(configuration).getMebiBytes().     // Task Managers memory     final int taskManagerMemoryMB = ConfigurationUtils.getTaskManagerHeapMemory(configuration).getMebiBytes().     int slotsPerTaskManager = configuration.getInteger(TaskManagerOptions.NUM_TASK_SLOTS).     return new ClusterSpecification.ClusterSpecificationBuilder().setMasterMemoryMB(jobManagerMemoryMB).setTaskManagerMemoryMB(taskManagerMemoryMB).setNumberTaskManagers(numberTaskManagers).setSlotsPerTaskManager(slotsPerTaskManager).createClusterSpecification(). }
false;private;0;16;;private void printUsage() {     System.out.println("Usage:").     HelpFormatter formatter = new HelpFormatter().     formatter.setWidth(200).     formatter.setLeftPadding(5).     formatter.setSyntaxPrefix("   Required").     Options req = new Options().     req.addOption(container).     formatter.printHelp(" ", req).     formatter.setSyntaxPrefix("   Optional").     Options options = new Options().     addGeneralOptions(options).     addRunOptions(options).     formatter.printHelp(" ", options). }
false;public;1;7;;@Override public boolean isActive(CommandLine commandLine) {     String jobManagerOption = commandLine.getOptionValue(addressOption.getOpt(), null).     boolean yarnJobManager = ID.equals(jobManagerOption).     boolean yarnAppId = commandLine.hasOption(applicationId.getOpt()).     return yarnJobManager || yarnAppId || (isYarnPropertiesFileMode(commandLine) && yarnApplicationIdFromYarnProperties != null). }
false;public;0;4;;@Override public String getId() {     return ID. }
false;public;1;8;;@Override public void addRunOptions(Options baseOptions) {     super.addRunOptions(baseOptions).     for (Object option : allOptions.getOptions()) {         baseOptions.addOption((Option) option).     } }
false;public;1;5;;@Override public void addGeneralOptions(Options baseOptions) {     super.addGeneralOptions(baseOptions).     baseOptions.addOption(applicationId). }
false;public;1;10;;@Override public AbstractYarnClusterDescriptor createClusterDescriptor(CommandLine commandLine) throws FlinkException {     final Configuration effectiveConfiguration = applyCommandLineOptionsToConfiguration(commandLine).     return createDescriptor(effectiveConfiguration, yarnConfiguration, configurationDirectory, commandLine). }
false;public;1;11;;@Override @Nullable public ApplicationId getClusterId(CommandLine commandLine) {     if (commandLine.hasOption(applicationId.getOpt())) {         return ConverterUtils.toApplicationId(commandLine.getOptionValue(applicationId.getOpt())).     } else if (isYarnPropertiesFileMode(commandLine)) {         return yarnApplicationIdFromYarnProperties.     } else {         return null.     } }
false;public;1;6;;@Override public ClusterSpecification getClusterSpecification(CommandLine commandLine) throws FlinkException {     final Configuration effectiveConfiguration = applyCommandLineOptionsToConfiguration(commandLine).     return createClusterSpecification(effectiveConfiguration, commandLine). }
false;protected;1;49;;@Override protected Configuration applyCommandLineOptionsToConfiguration(CommandLine commandLine) throws FlinkException {     // we ignore the addressOption because it can only contain "yarn-cluster"     final Configuration effectiveConfiguration = new Configuration(configuration).     if (commandLine.hasOption(zookeeperNamespaceOption.getOpt())) {         String zkNamespace = commandLine.getOptionValue(zookeeperNamespaceOption.getOpt()).         effectiveConfiguration.setString(HA_CLUSTER_ID, zkNamespace).     }     final ApplicationId applicationId = getClusterId(commandLine).     if (applicationId != null) {         final String zooKeeperNamespace.         if (commandLine.hasOption(zookeeperNamespace.getOpt())) {             zooKeeperNamespace = commandLine.getOptionValue(zookeeperNamespace.getOpt()).         } else {             zooKeeperNamespace = effectiveConfiguration.getString(HA_CLUSTER_ID, applicationId.toString()).         }         effectiveConfiguration.setString(HA_CLUSTER_ID, zooKeeperNamespace).     }     if (commandLine.hasOption(jmMemory.getOpt())) {         String jmMemoryVal = commandLine.getOptionValue(jmMemory.getOpt()).         if (!MemorySize.MemoryUnit.hasUnit(jmMemoryVal)) {             jmMemoryVal += "m".         }         effectiveConfiguration.setString(JobManagerOptions.JOB_MANAGER_HEAP_MEMORY, jmMemoryVal).     }     if (commandLine.hasOption(tmMemory.getOpt())) {         String tmMemoryVal = commandLine.getOptionValue(tmMemory.getOpt()).         if (!MemorySize.MemoryUnit.hasUnit(tmMemoryVal)) {             tmMemoryVal += "m".         }         effectiveConfiguration.setString(TaskManagerOptions.TASK_MANAGER_HEAP_MEMORY, tmMemoryVal).     }     if (commandLine.hasOption(slots.getOpt())) {         effectiveConfiguration.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, Integer.parseInt(commandLine.getOptionValue(slots.getOpt()))).     }     if (isYarnPropertiesFileMode(commandLine)) {         return applyYarnProperties(effectiveConfiguration).     } else {         return effectiveConfiguration.     } }
false;private;1;17;;private boolean isYarnPropertiesFileMode(CommandLine commandLine) {     boolean canApplyYarnProperties = !commandLine.hasOption(addressOption.getOpt()).     if (canApplyYarnProperties) {         for (Option option : commandLine.getOptions()) {             if (allOptions.hasOption(option.getOpt())) {                 if (!isDetachedOption(option)) {                     // don't resume from properties file if yarn options have been specified                     canApplyYarnProperties = false.                     break.                 }             }         }     }     return canApplyYarnProperties. }
false;private;1;3;;private boolean isDetachedOption(Option option) {     return option.getOpt().equals(YARN_DETACHED_OPTION.getOpt()) || option.getOpt().equals(DETACHED_OPTION.getOpt()). }
false;private;1;27;;private Configuration applyYarnProperties(Configuration configuration) throws FlinkException {     final Configuration effectiveConfiguration = new Configuration(configuration).     // configure the default parallelism from YARN     String propParallelism = yarnPropertiesFile.getProperty(YARN_PROPERTIES_PARALLELISM).     if (propParallelism != null) {         // maybe the property is not set         try {             int parallelism = Integer.parseInt(propParallelism).             effectiveConfiguration.setInteger(CoreOptions.DEFAULT_PARALLELISM, parallelism).             logAndSysout("YARN properties set default parallelism to " + parallelism).         } catch (NumberFormatException e) {             throw new FlinkException("Error while parsing the YARN properties: " + "Property " + YARN_PROPERTIES_PARALLELISM + " is not an integer.", e).         }     }     // handle the YARN client's dynamic properties     String dynamicPropertiesEncoded = yarnPropertiesFile.getProperty(YARN_PROPERTIES_DYNAMIC_PROPERTIES_STRING).     Map<String, String> dynamicProperties = getDynamicProperties(dynamicPropertiesEncoded).     for (Map.Entry<String, String> dynamicProperty : dynamicProperties.entrySet()) {         effectiveConfiguration.setString(dynamicProperty.getKey(), dynamicProperty.getValue()).     }     return effectiveConfiguration. }
false;public;1;113;;public int run(String[] args) throws CliArgsException, FlinkException {     //      // Command Line Options     //      final CommandLine cmd = parseCommandLineOptions(args, true).     if (cmd.hasOption(help.getOpt())) {         printUsage().         return 0.     }     final AbstractYarnClusterDescriptor yarnClusterDescriptor = createClusterDescriptor(cmd).     try {         // Query cluster for metrics         if (cmd.hasOption(query.getOpt())) {             final String description = yarnClusterDescriptor.getClusterDescription().             System.out.println(description).             return 0.         } else {             final ClusterClient<ApplicationId> clusterClient.             final ApplicationId yarnApplicationId.             if (cmd.hasOption(applicationId.getOpt())) {                 yarnApplicationId = ConverterUtils.toApplicationId(cmd.getOptionValue(applicationId.getOpt())).                 clusterClient = yarnClusterDescriptor.retrieve(yarnApplicationId).             } else {                 final ClusterSpecification clusterSpecification = getClusterSpecification(cmd).                 clusterClient = yarnClusterDescriptor.deploySessionCluster(clusterSpecification).                 // ------------------ ClusterClient deployed, handle connection details                 yarnApplicationId = clusterClient.getClusterId().                 try {                     final LeaderConnectionInfo connectionInfo = clusterClient.getClusterConnectionInfo().                     System.out.println("Flink JobManager is now running on " + connectionInfo.getHostname() + ':' + connectionInfo.getPort() + " with leader id " + connectionInfo.getLeaderSessionID() + '.').                     System.out.println("JobManager Web Interface: " + clusterClient.getWebInterfaceURL()).                     writeYarnPropertiesFile(yarnApplicationId, clusterSpecification.getNumberTaskManagers() * clusterSpecification.getSlotsPerTaskManager(), yarnClusterDescriptor.getDynamicPropertiesEncoded()).                 } catch (Exception e) {                     try {                         clusterClient.shutdown().                     } catch (Exception ex) {                         LOG.info("Could not properly shutdown cluster client.", ex).                     }                     try {                         yarnClusterDescriptor.killCluster(yarnApplicationId).                     } catch (FlinkException fe) {                         LOG.info("Could not properly terminate the Flink cluster.", fe).                     }                     throw new FlinkException("Could not write the Yarn connection information.", e).                 }             }             if (yarnClusterDescriptor.isDetachedMode()) {                 LOG.info("The Flink YARN client has been started in detached mode. In order to stop " + "Flink on YARN, use the following command or a YARN web interface to stop it:\n" + "yarn application -kill " + yarnApplicationId).             } else {                 ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor().                 final YarnApplicationStatusMonitor yarnApplicationStatusMonitor = new YarnApplicationStatusMonitor(yarnClusterDescriptor.getYarnClient(), yarnApplicationId, new ScheduledExecutorServiceAdapter(scheduledExecutorService)).                 Thread shutdownHook = ShutdownHookUtil.addShutdownHook(() -> shutdownCluster(clusterClient, scheduledExecutorService, yarnApplicationStatusMonitor), getClass().getSimpleName(), LOG).                 try {                     runInteractiveCli(clusterClient, yarnApplicationStatusMonitor, acceptInteractiveInput).                 } finally {                     shutdownCluster(clusterClient, scheduledExecutorService, yarnApplicationStatusMonitor).                     if (shutdownHook != null) {                         // we do not need the hook anymore as we have just tried to shutdown the cluster.                         ShutdownHookUtil.removeShutdownHook(shutdownHook, getClass().getSimpleName(), LOG).                     }                     tryRetrieveAndLogApplicationReport(yarnClusterDescriptor.getYarnClient(), yarnApplicationId).                 }             }         }     } finally {         try {             yarnClusterDescriptor.close().         } catch (Exception e) {             LOG.info("Could not properly close the yarn cluster descriptor.", e).         }     }     return 0. }
false;private;3;26;;private void shutdownCluster(ClusterClient clusterClient, ScheduledExecutorService scheduledExecutorService, YarnApplicationStatusMonitor yarnApplicationStatusMonitor) {     try {         yarnApplicationStatusMonitor.close().     } catch (Exception e) {         LOG.info("Could not properly close the Yarn application status monitor.", e).     }     clusterClient.shutDownCluster().     try {         clusterClient.shutdown().     } catch (Exception e) {         LOG.info("Could not properly shutdown cluster client.", e).     }     // shut down the scheduled executor service     ExecutorUtils.gracefulShutdown(1000L, TimeUnit.MILLISECONDS, scheduledExecutorService).     deleteYarnPropertiesFile(). }
false;private;2;14;;private void tryRetrieveAndLogApplicationReport(YarnClient yarnClient, ApplicationId yarnApplicationId) {     ApplicationReport applicationReport.     try {         applicationReport = yarnClient.getApplicationReport(yarnApplicationId).     } catch (YarnException | IOException e) {         LOG.info("Could not log the final application report.", e).         applicationReport = null.     }     if (applicationReport != null) {         logApplicationReport(applicationReport).     } }
false;private;1;15;;private void logApplicationReport(ApplicationReport appReport) {     LOG.info("Application " + appReport.getApplicationId() + " finished with state " + appReport.getYarnApplicationState() + " and final state " + appReport.getFinalApplicationStatus() + " at " + appReport.getFinishTime()).     if (appReport.getYarnApplicationState() == YarnApplicationState.FAILED) {         LOG.warn("Application failed. Diagnostics " + appReport.getDiagnostics()).         LOG.warn("If log aggregation is activated in the Hadoop cluster, we recommend to retrieve " + "the full application log using this command:" + System.lineSeparator() + "\tyarn logs -applicationId " + appReport.getApplicationId() + System.lineSeparator() + "(It sometimes takes a few seconds until the logs are aggregated)").     } }
false;private;0;15;;private void deleteYarnPropertiesFile() {     // try to clean up the old yarn properties file     try {         File propertiesFile = getYarnPropertiesLocation(yarnPropertiesFileLocation).         if (propertiesFile.isFile()) {             if (propertiesFile.delete()) {                 LOG.info("Deleted Yarn properties file at {}", propertiesFile.getAbsoluteFile()).             } else {                 LOG.warn("Couldn't delete Yarn properties file at {}", propertiesFile.getAbsoluteFile()).             }         }     } catch (Exception e) {         LOG.warn("Exception while deleting the JobManager address file", e).     } }
false;private;3;20;;private void writeYarnPropertiesFile(ApplicationId yarnApplicationId, int parallelism, @Nullable String dynamicProperties) {     // file that we write into the conf/ dir containing the jobManager address and the dop.     final File yarnPropertiesFile = getYarnPropertiesLocation(yarnPropertiesFileLocation).     Properties yarnProps = new Properties().     yarnProps.setProperty(YARN_APPLICATION_ID_KEY, yarnApplicationId.toString()).     if (parallelism > 0) {         yarnProps.setProperty(YARN_PROPERTIES_PARALLELISM, Integer.toString(parallelism)).     }     // add dynamic properties     if (dynamicProperties != null) {         yarnProps.setProperty(YARN_PROPERTIES_DYNAMIC_PROPERTIES_STRING, dynamicProperties).     }     writeYarnProperties(yarnProps, yarnPropertiesFile). }
false;private;1;4;;private void logAndSysout(String message) {     LOG.info(message).     System.out.println(message). }
false;public,static;1;27;;public static Map<String, String> getDynamicProperties(String dynamicPropertiesEncoded) {     if (dynamicPropertiesEncoded != null && dynamicPropertiesEncoded.length() > 0) {         Map<String, String> properties = new HashMap<>().         String[] propertyLines = dynamicPropertiesEncoded.split(YARN_DYNAMIC_PROPERTIES_SEPARATOR).         for (String propLine : propertyLines) {             if (propLine == null) {                 continue.             }             int firstEquals = propLine.indexOf("=").             if (firstEquals >= 0) {                 String key = propLine.substring(0, firstEquals).trim().                 String value = propLine.substring(firstEquals + 1, propLine.length()).trim().                 if (!key.isEmpty()) {                     properties.put(key, value).                 }             }         }         return properties.     } else {         return Collections.emptyMap().     } }
false;public,static;1;26;;public static void main(final String[] args) {     final String configurationDirectory = CliFrontend.getConfigurationDirectoryFromEnv().     final Configuration flinkConfiguration = GlobalConfiguration.loadConfiguration().     int retCode.     try {         final FlinkYarnSessionCli cli = new FlinkYarnSessionCli(flinkConfiguration, configurationDirectory, "", // no prefix for the YARN session         "").         SecurityUtils.install(new SecurityConfiguration(flinkConfiguration)).         retCode = SecurityUtils.getInstalledContext().runSecured(() -> cli.run(args)).     } catch (CliArgsException e) {         retCode = handleCliArgsException(e).     } catch (Throwable t) {         final Throwable strippedThrowable = ExceptionUtils.stripException(t, UndeclaredThrowableException.class).         retCode = handleError(strippedThrowable).     }     System.exit(retCode). }
false;private,static;3;61;;private static void runInteractiveCli(ClusterClient<?> clusterClient, YarnApplicationStatusMonitor yarnApplicationStatusMonitor, boolean readConsoleInput) {     try (BufferedReader in = new BufferedReader(new InputStreamReader(System.in))) {         boolean continueRepl = true.         int numTaskmanagers = 0.         boolean isLastStatusUnknown = true.         long unknownStatusSince = System.nanoTime().         while (continueRepl) {             final ApplicationStatus applicationStatus = yarnApplicationStatusMonitor.getApplicationStatusNow().             switch(applicationStatus) {                 case FAILED:                 case CANCELED:                     System.err.println("The Flink Yarn cluster has failed.").                     continueRepl = false.                     break.                 case UNKNOWN:                     if (!isLastStatusUnknown) {                         unknownStatusSince = System.nanoTime().                         isLastStatusUnknown = true.                     }                     if ((System.nanoTime() - unknownStatusSince) > 5L * CLIENT_POLLING_INTERVAL_MS * 1_000_000L) {                         System.err.println("The Flink Yarn cluster is in an unknown state. Please check the Yarn cluster.").                         continueRepl = false.                     } else {                         continueRepl = repStep(in, readConsoleInput).                     }                     break.                 case SUCCEEDED:                     if (isLastStatusUnknown) {                         isLastStatusUnknown = false.                     }                     // ------------------ check if there are updates by the cluster -----------                     try {                         final GetClusterStatusResponse status = clusterClient.getClusterStatus().                         if (status != null && numTaskmanagers != status.numRegisteredTaskManagers()) {                             System.err.println("Number of connected TaskManagers changed to " + status.numRegisteredTaskManagers() + ". " + "Slots available: " + status.totalNumberOfSlots()).                             numTaskmanagers = status.numRegisteredTaskManagers().                         }                     } catch (Exception e) {                         LOG.warn("Could not retrieve the current cluster status. Skipping current retrieval attempt ...", e).                     }                     printClusterMessages(clusterClient).                     continueRepl = repStep(in, readConsoleInput).             }         }     } catch (Exception e) {         LOG.warn("Exception while running the interactive command line interface.", e).     } }
false;private,static;1;9;;private static void printClusterMessages(ClusterClient clusterClient) {     final List<String> messages = clusterClient.getNewMessages().     if (!messages.isEmpty()) {         System.err.println("New messages from the YARN cluster: ").         for (String msg : messages) {             System.err.println(msg).         }     } }
true;private,static;2;31;/**  * Read-Evaluate-Print step for the REPL.  *  * @param in to read from  * @param readConsoleInput true if console input has to be read  * @return true if the REPL shall be continued, otherwise false  * @throws IOException  * @throws InterruptedException  */ ;/**  * Read-Evaluate-Print step for the REPL.  *  * @param in to read from  * @param readConsoleInput true if console input has to be read  * @return true if the REPL shall be continued, otherwise false  * @throws IOException  * @throws InterruptedException  */ private static boolean repStep(BufferedReader in, boolean readConsoleInput) throws IOException, InterruptedException {     // wait until CLIENT_POLLING_INTERVAL is over or the user entered something.     long startTime = System.currentTimeMillis().     while ((System.currentTimeMillis() - startTime) < CLIENT_POLLING_INTERVAL_MS && (!readConsoleInput || !in.ready())) {         Thread.sleep(200L).     }     if (readConsoleInput && in.ready()) {         String command = in.readLine().         switch(command) {             case "quit":             case "stop":                 return false.             case "help":                 System.err.println(YARN_SESSION_HELP).                 break.             default:                 System.err.println("Unknown command '" + command + "'. Showing help:").                 System.err.println(YARN_SESSION_HELP).                 break.         }     }     return true. }
false;private,static;2;8;;private static void writeYarnProperties(Properties properties, File propertiesFile) {     try (final OutputStream out = new FileOutputStream(propertiesFile)) {         properties.store(out, "Generated YARN properties file").     } catch (IOException e) {         throw new RuntimeException("Error writing the properties file", e).     }     // readable for all.     propertiesFile.setReadable(true, false). }
false;private,static;1;8;;private static int handleCliArgsException(CliArgsException e) {     LOG.error("Could not parse the command line arguments.", e).     System.out.println(e.getMessage()).     System.out.println().     System.out.println("Use the help option (-h or --help) to get help on the command.").     return 1. }
false;private,static;1;11;;private static int handleError(Throwable t) {     LOG.error("Error while running the Flink Yarn session.", t).     System.err.println().     System.err.println("------------------------------------------------------------").     System.err.println(" The program finished with the following exception:").     System.err.println().     t.printStackTrace().     return 1. }
false;public,static;1;14;;public static File getYarnPropertiesLocation(@Nullable String yarnPropertiesFileLocation) {     final String propertiesFileLocation.     if (yarnPropertiesFileLocation != null) {         propertiesFileLocation = yarnPropertiesFileLocation.     } else {         propertiesFileLocation = System.getProperty("java.io.tmpdir").     }     String currentUser = System.getProperty("user.name").     return new File(propertiesFileLocation, YARN_PROPERTIES_FILE + currentUser). }
false;private;3;15;;private AbstractYarnClusterDescriptor getClusterDescriptor(Configuration configuration, YarnConfiguration yarnConfiguration, String configurationDirectory) {     final YarnClient yarnClient = YarnClient.createYarnClient().     yarnClient.init(yarnConfiguration).     yarnClient.start().     return new YarnClusterDescriptor(configuration, yarnConfiguration, configurationDirectory, yarnClient, false). }
