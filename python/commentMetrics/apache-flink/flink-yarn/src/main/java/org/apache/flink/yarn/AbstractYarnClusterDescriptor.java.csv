# id;timestamp;commentText;codeText;commentWords;codeWords
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1466152678;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1466152678;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1466152678;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1466780434;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1467379351;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1467394749;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1467396766;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1468944021;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1469630409;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1472033364;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1474401809;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1476095826;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1477570902;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1478286457;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1478790006;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1479746984;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1480082300;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1482522867;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1482522867;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1483644165;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1484162264;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1484734622;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1485274812;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1486575587;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1487622556;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1488923210;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1489509047;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1490967479;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1492605405;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1492605425;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1492763444;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1493975167;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1495108913;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1495787238;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1495787238;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1495787238;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1495819079;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1498894422;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1498894422;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1498896127;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1499683297;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1501083592;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1501088110;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> protected abstract Class<?> getApplicationMasterClass()_;1501237018;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract Class<?> getApplicationMasterClass()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,class,get,application,master,class
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1511966584;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1515686359;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1515686369;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1515770043;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1515770043;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1515770044;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1515770045;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1518680659;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1518945172;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1519249745;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1519567828;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1519820825;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1520030750;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1520032158;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1521626214;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1521626214;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1522130852;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1522681180;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1523554814;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1523641287;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1524124694;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1525116069;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1527695275;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1530798894;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1531303508;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1531914688;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1539113610;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1541146016;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1541670646;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1541771328;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1546179677;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1548947871;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> public void addShipFiles(List<File> shipFiles);1549456065;Adds the given files to the list of files to ship.__<p>Note that any file matching "<tt>flink-dist*.jar</tt>" will be excluded from the upload by_{@link #uploadAndRegisterFiles(Collection, FileSystem, Path, ApplicationId, List, Map, StringBuilder)}_since we upload the Flink uber jar ourselves and do not need to deploy it multiple times.__@param shipFiles files to ship;public void addShipFiles(List<File> shipFiles) {_		this.shipFiles.addAll(shipFiles)__	};adds,the,given,files,to,the,list,of,files,to,ship,p,note,that,any,file,matching,tt,flink,dist,jar,tt,will,be,excluded,from,the,upload,by,link,upload,and,register,files,collection,file,system,path,application,id,list,map,string,builder,since,we,upload,the,flink,uber,jar,ourselves,and,do,not,need,to,deploy,it,multiple,times,param,ship,files,files,to,ship;public,void,add,ship,files,list,file,ship,files,this,ship,files,add,all,ship,files
AbstractYarnClusterDescriptor -> private Path getYarnFilesDir(final ApplicationId appId) throws IOException;1525116069;Returns the Path where the YARN application files should be uploaded to.__@param appId YARN application id;private Path getYarnFilesDir(final ApplicationId appId) throws IOException {_		final FileSystem fileSystem = FileSystem.get(yarnConfiguration)__		final Path homeDir = fileSystem.getHomeDirectory()__		return new Path(homeDir, ".flink/" + appId + '/')__	};returns,the,path,where,the,yarn,application,files,should,be,uploaded,to,param,app,id,yarn,application,id;private,path,get,yarn,files,dir,final,application,id,app,id,throws,ioexception,final,file,system,file,system,file,system,get,yarn,configuration,final,path,home,dir,file,system,get,home,directory,return,new,path,home,dir,flink,app,id
AbstractYarnClusterDescriptor -> private Path getYarnFilesDir(final ApplicationId appId) throws IOException;1527695275;Returns the Path where the YARN application files should be uploaded to.__@param appId YARN application id;private Path getYarnFilesDir(final ApplicationId appId) throws IOException {_		final FileSystem fileSystem = FileSystem.get(yarnConfiguration)__		final Path homeDir = fileSystem.getHomeDirectory()__		return new Path(homeDir, ".flink/" + appId + '/')__	};returns,the,path,where,the,yarn,application,files,should,be,uploaded,to,param,app,id,yarn,application,id;private,path,get,yarn,files,dir,final,application,id,app,id,throws,ioexception,final,file,system,file,system,file,system,get,yarn,configuration,final,path,home,dir,file,system,get,home,directory,return,new,path,home,dir,flink,app,id
AbstractYarnClusterDescriptor -> private Path getYarnFilesDir(final ApplicationId appId) throws IOException;1530798894;Returns the Path where the YARN application files should be uploaded to.__@param appId YARN application id;private Path getYarnFilesDir(final ApplicationId appId) throws IOException {_		final FileSystem fileSystem = FileSystem.get(yarnConfiguration)__		final Path homeDir = fileSystem.getHomeDirectory()__		return new Path(homeDir, ".flink/" + appId + '/')__	};returns,the,path,where,the,yarn,application,files,should,be,uploaded,to,param,app,id,yarn,application,id;private,path,get,yarn,files,dir,final,application,id,app,id,throws,ioexception,final,file,system,file,system,file,system,get,yarn,configuration,final,path,home,dir,file,system,get,home,directory,return,new,path,home,dir,flink,app,id
AbstractYarnClusterDescriptor -> private Path getYarnFilesDir(final ApplicationId appId) throws IOException;1531303508;Returns the Path where the YARN application files should be uploaded to.__@param appId YARN application id;private Path getYarnFilesDir(final ApplicationId appId) throws IOException {_		final FileSystem fileSystem = FileSystem.get(yarnConfiguration)__		final Path homeDir = fileSystem.getHomeDirectory()__		return new Path(homeDir, ".flink/" + appId + '/')__	};returns,the,path,where,the,yarn,application,files,should,be,uploaded,to,param,app,id,yarn,application,id;private,path,get,yarn,files,dir,final,application,id,app,id,throws,ioexception,final,file,system,file,system,file,system,get,yarn,configuration,final,path,home,dir,file,system,get,home,directory,return,new,path,home,dir,flink,app,id
AbstractYarnClusterDescriptor -> private Path getYarnFilesDir(final ApplicationId appId) throws IOException;1531914688;Returns the Path where the YARN application files should be uploaded to.__@param appId YARN application id;private Path getYarnFilesDir(final ApplicationId appId) throws IOException {_		final FileSystem fileSystem = FileSystem.get(yarnConfiguration)__		final Path homeDir = fileSystem.getHomeDirectory()__		return new Path(homeDir, ".flink/" + appId + '/')__	};returns,the,path,where,the,yarn,application,files,should,be,uploaded,to,param,app,id,yarn,application,id;private,path,get,yarn,files,dir,final,application,id,app,id,throws,ioexception,final,file,system,file,system,file,system,get,yarn,configuration,final,path,home,dir,file,system,get,home,directory,return,new,path,home,dir,flink,app,id
AbstractYarnClusterDescriptor -> private Path getYarnFilesDir(final ApplicationId appId) throws IOException;1539113610;Returns the Path where the YARN application files should be uploaded to.__@param appId YARN application id;private Path getYarnFilesDir(final ApplicationId appId) throws IOException {_		final FileSystem fileSystem = FileSystem.get(yarnConfiguration)__		final Path homeDir = fileSystem.getHomeDirectory()__		return new Path(homeDir, ".flink/" + appId + '/')__	};returns,the,path,where,the,yarn,application,files,should,be,uploaded,to,param,app,id,yarn,application,id;private,path,get,yarn,files,dir,final,application,id,app,id,throws,ioexception,final,file,system,file,system,file,system,get,yarn,configuration,final,path,home,dir,file,system,get,home,directory,return,new,path,home,dir,flink,app,id
AbstractYarnClusterDescriptor -> private Path getYarnFilesDir(final ApplicationId appId) throws IOException;1541146016;Returns the Path where the YARN application files should be uploaded to.__@param appId YARN application id;private Path getYarnFilesDir(final ApplicationId appId) throws IOException {_		final FileSystem fileSystem = FileSystem.get(yarnConfiguration)__		final Path homeDir = fileSystem.getHomeDirectory()__		return new Path(homeDir, ".flink/" + appId + '/')__	};returns,the,path,where,the,yarn,application,files,should,be,uploaded,to,param,app,id,yarn,application,id;private,path,get,yarn,files,dir,final,application,id,app,id,throws,ioexception,final,file,system,file,system,file,system,get,yarn,configuration,final,path,home,dir,file,system,get,home,directory,return,new,path,home,dir,flink,app,id
AbstractYarnClusterDescriptor -> private Path getYarnFilesDir(final ApplicationId appId) throws IOException;1541670646;Returns the Path where the YARN application files should be uploaded to.__@param appId YARN application id;private Path getYarnFilesDir(final ApplicationId appId) throws IOException {_		final FileSystem fileSystem = FileSystem.get(yarnConfiguration)__		final Path homeDir = fileSystem.getHomeDirectory()__		return new Path(homeDir, ".flink/" + appId + '/')__	};returns,the,path,where,the,yarn,application,files,should,be,uploaded,to,param,app,id,yarn,application,id;private,path,get,yarn,files,dir,final,application,id,app,id,throws,ioexception,final,file,system,file,system,file,system,get,yarn,configuration,final,path,home,dir,file,system,get,home,directory,return,new,path,home,dir,flink,app,id
AbstractYarnClusterDescriptor -> private Path getYarnFilesDir(final ApplicationId appId) throws IOException;1541771328;Returns the Path where the YARN application files should be uploaded to.__@param appId YARN application id;private Path getYarnFilesDir(final ApplicationId appId) throws IOException {_		final FileSystem fileSystem = FileSystem.get(yarnConfiguration)__		final Path homeDir = fileSystem.getHomeDirectory()__		return new Path(homeDir, ".flink/" + appId + '/')__	};returns,the,path,where,the,yarn,application,files,should,be,uploaded,to,param,app,id,yarn,application,id;private,path,get,yarn,files,dir,final,application,id,app,id,throws,ioexception,final,file,system,file,system,file,system,get,yarn,configuration,final,path,home,dir,file,system,get,home,directory,return,new,path,home,dir,flink,app,id
AbstractYarnClusterDescriptor -> private Path getYarnFilesDir(final ApplicationId appId) throws IOException;1546179677;Returns the Path where the YARN application files should be uploaded to.__@param appId YARN application id;private Path getYarnFilesDir(final ApplicationId appId) throws IOException {_		final FileSystem fileSystem = FileSystem.get(yarnConfiguration)__		final Path homeDir = fileSystem.getHomeDirectory()__		return new Path(homeDir, ".flink/" + appId + '/')__	};returns,the,path,where,the,yarn,application,files,should,be,uploaded,to,param,app,id,yarn,application,id;private,path,get,yarn,files,dir,final,application,id,app,id,throws,ioexception,final,file,system,file,system,file,system,get,yarn,configuration,final,path,home,dir,file,system,get,home,directory,return,new,path,home,dir,flink,app,id
AbstractYarnClusterDescriptor -> private Path getYarnFilesDir(final ApplicationId appId) throws IOException;1548947871;Returns the Path where the YARN application files should be uploaded to.__@param appId YARN application id;private Path getYarnFilesDir(final ApplicationId appId) throws IOException {_		final FileSystem fileSystem = FileSystem.get(yarnConfiguration)__		final Path homeDir = fileSystem.getHomeDirectory()__		return new Path(homeDir, ".flink/" + appId + '/')__	};returns,the,path,where,the,yarn,application,files,should,be,uploaded,to,param,app,id,yarn,application,id;private,path,get,yarn,files,dir,final,application,id,app,id,throws,ioexception,final,file,system,file,system,file,system,get,yarn,configuration,final,path,home,dir,file,system,get,home,directory,return,new,path,home,dir,flink,app,id
AbstractYarnClusterDescriptor -> private Path getYarnFilesDir(final ApplicationId appId) throws IOException;1549456065;Returns the Path where the YARN application files should be uploaded to.__@param appId YARN application id;private Path getYarnFilesDir(final ApplicationId appId) throws IOException {_		final FileSystem fileSystem = FileSystem.get(yarnConfiguration)__		final Path homeDir = fileSystem.getHomeDirectory()__		return new Path(homeDir, ".flink/" + appId + '/')__	};returns,the,path,where,the,yarn,application,files,should,be,uploaded,to,param,app,id,yarn,application,id;private,path,get,yarn,files,dir,final,application,id,app,id,throws,ioexception,final,file,system,file,system,file,system,get,yarn,configuration,final,path,home,dir,file,system,get,home,directory,return,new,path,home,dir,flink,app,id
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1466152678;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1466780434;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1467379351;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1467394749;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1467396766;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1468944021;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1469630409;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1472033364;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1474401809;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1476095826;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1477570902;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1478286457;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1478790006;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1479746984;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1480082300;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1482522867;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1482522867;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1483644165;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1484162264;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1484734622;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1485274812;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1486575587;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1487622556;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1488923210;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1489509047;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1490967479;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1492605405;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1492605425;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws IOException, YarnException;1492763444;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws IOException, YarnException {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,ioexception,yarn,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1477570902;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1478286457;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1478790006;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1479746984;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1480082300;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1482522867;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1482522867;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1483644165;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1484162264;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1484734622;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1485274812;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1486575587;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1487622556;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1488923210;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1489509047;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1490967479;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1492605405;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1492605425;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1492763444;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1493975167;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarFiles == null || userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,files,null,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1495108913;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1495787238;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1495787238;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1495787238;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for(URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1495819079;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1498894422;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1498894422;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1498896127;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1499683297;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1501083592;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1501088110;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1501237018;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1501436689;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1502357790;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1506499511;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1507281370;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1510999087;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1511813739;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1511966584;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1515686359;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1515686369;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1515770043;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1515770043;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1515770044;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1515770045;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1518680659;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1518945172;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1519249745;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1519567828;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1519820825;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1520030750;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1520032158;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1521626214;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1521626214;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1522130852;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1522681180;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1523554814;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1523641287;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1524124694;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1525116069;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1527695275;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1530798894;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1531303508;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1531914688;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1539113610;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1541146016;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1541670646;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1541771328;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1546179677;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public boolean hasUserJarFiles(List<URL> requiredJarFiles);1548947871;Returns true if the descriptor has the job jars to include in the classpath.;public boolean hasUserJarFiles(List<URL> requiredJarFiles) {_		if (userJarInclusion == YarnConfigOptions.UserJarInclusion.DISABLED) {_			return false__		}_		if (userJarFiles.size() != requiredJarFiles.size()) {_			return false__		}_		try {_			for (URL jarFile : requiredJarFiles) {_				if (!userJarFiles.contains(new File(jarFile.toURI()))) {_					return false__				}_			}_		} catch (URISyntaxException e) {_			return false__		}_		return true__	};returns,true,if,the,descriptor,has,the,job,jars,to,include,in,the,classpath;public,boolean,has,user,jar,files,list,url,required,jar,files,if,user,jar,inclusion,yarn,config,options,user,jar,inclusion,disabled,return,false,if,user,jar,files,size,required,jar,files,size,return,false,try,for,url,jar,file,required,jar,files,if,user,jar,files,contains,new,file,jar,file,to,uri,return,false,catch,urisyntax,exception,e,return,false,return,true
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1477570902;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1478286457;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1478790006;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1479746984;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1480082300;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1482522867;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1482522867;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1483644165;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1484162264;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1484734622;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1485274812;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1486575587;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1487622556;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1488923210;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1489509047;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1490967479;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1492605405;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1492605425;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1492763444;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1493975167;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		Set<File> localUserJarFiles = new HashSet<>(userJarFiles.size())__		for (URL jarFile : userJarFiles) {_			try {_				localUserJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_		this.userJarFiles = localUserJarFiles__	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,set,file,local,user,jar,files,new,hash,set,user,jar,files,size,for,url,jar,file,user,jar,files,try,local,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported,this,user,jar,files,local,user,jar,files
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1495108913;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1495787238;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1495787238;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1495787238;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1495819079;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1498894422;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1498894422;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1498896127;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1499683297;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1501083592;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1501088110;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1501237018;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1501436689;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1502357790;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1506499511;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1507281370;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1510999087;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1511813739;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1511966584;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1515686359;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1515686369;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1515770043;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1515770043;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1515770044;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1515770045;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1518680659;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1518945172;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1519249745;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1519567828;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1519820825;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1520030750;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1520032158;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1521626214;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1521626214;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1522130852;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1522681180;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1523554814;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1523641287;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1524124694;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1525116069;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1527695275;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1530798894;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1531303508;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1531914688;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1539113610;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1541146016;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1541670646;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1541771328;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1546179677;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> public void setProvidedUserJarFiles(List<URL> userJarFiles);1548947871;Sets the user jar which is included in the system classloader of all nodes.;public void setProvidedUserJarFiles(List<URL> userJarFiles) {_		for (URL jarFile : userJarFiles) {_			try {_				this.userJarFiles.add(new File(jarFile.toURI()))__			} catch (URISyntaxException e) {_				throw new IllegalArgumentException("Couldn't add local user jar: " + jarFile_					+ " Currently only file:/// URLs are supported.")__			}_		}_	};sets,the,user,jar,which,is,included,in,the,system,classloader,of,all,nodes;public,void,set,provided,user,jar,files,list,url,user,jar,files,for,url,jar,file,user,jar,files,try,this,user,jar,files,add,new,file,jar,file,to,uri,catch,urisyntax,exception,e,throw,new,illegal,argument,exception,couldn,t,add,local,user,jar,jar,file,currently,only,file,urls,are,supported
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1518680659;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1518945172;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			new Configuration(flinkConfiguration),_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,new,configuration,flink,configuration,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1519249745;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			new Configuration(flinkConfiguration),_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,new,configuration,flink,configuration,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1519567828;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			new Configuration(flinkConfiguration),_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,new,configuration,flink,configuration,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1519820825;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1520030750;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1520032158;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1521626214;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1521626214;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1495787238;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1495787238;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1495787238;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1495819079;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1498894422;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1498894422;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1498896127;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1499683297;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1501083592;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1466152678;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1466780434;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1467379351;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1467394749;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1467396766;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1468944021;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1469630409;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1472033364;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1474401809;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1476095826;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1477570902;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1478286457;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1478790006;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1479746984;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1480082300;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1482522867;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1482522867;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1483644165;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1484162264;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1484734622;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1485274812;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1486575587;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1487622556;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1488923210;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1489509047;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1490967479;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1492605405;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1492605425;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1492763444;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1493975167;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1495108913;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1495787238;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1495787238;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1495787238;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1495819079;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1498894422;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1498894422;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1498896127;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1499683297;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1501083592;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1501088110;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1501237018;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1501436689;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1502357790;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1506499511;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1507281370;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1510999087;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1511813739;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClient getYarnClient();1511966584;Gets a Hadoop Yarn client._@return Returns a YarnClient which has to be shutdown manually;protected YarnClient getYarnClient() {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;protected,yarn,client,get,yarn,client,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1510999087;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1511813739;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1511966584;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1515686359;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1515686369;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1515770043;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1515770043;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1515770044;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1515770045;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1518680659;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1518945172;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1519249745;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1519567828;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1519820825;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1520030750;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1520032158;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1521626214;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1521626214;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1522130852;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1522681180;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1523554814;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1523641287;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1524124694;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1525116069;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1527695275;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1530798894;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1531303508;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1531914688;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1539113610;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1541146016;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1541670646;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1541771328;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1546179677;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1548947871;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private static Path setupSingleLocalResource( 			String key, 			FileSystem fs, 			ApplicationId appId, 			Path localSrcPath, 			Map<String, LocalResource> localResources, 			Path targetHomeDir, 			String relativeTargetPath) throws IOException, URISyntaxException;1549456065;Uploads and registers a single resource and adds it to <tt>localResources</tt>.__@param key_the key to add the resource under_@param fs_the remote file system to upload to_@param appId_application ID_@param localSrcPath_local path to the file_@param localResources_map of resources__@return the remote path to the uploaded resource;private static Path setupSingleLocalResource(_			String key,_			FileSystem fs,_			ApplicationId appId,_			Path localSrcPath,_			Map<String, LocalResource> localResources,_			Path targetHomeDir,_			String relativeTargetPath) throws IOException, URISyntaxException {__		Tuple2<Path, LocalResource> resource = Utils.setupLocalResource(_			fs,_			appId.toString(),_			localSrcPath,_			targetHomeDir,_			relativeTargetPath)___		localResources.put(key, resource.f1)___		return resource.f0__	};uploads,and,registers,a,single,resource,and,adds,it,to,tt,local,resources,tt,param,key,the,key,to,add,the,resource,under,param,fs,the,remote,file,system,to,upload,to,param,app,id,application,id,param,local,src,path,local,path,to,the,file,param,local,resources,map,of,resources,return,the,remote,path,to,the,uploaded,resource;private,static,path,setup,single,local,resource,string,key,file,system,fs,application,id,app,id,path,local,src,path,map,string,local,resource,local,resources,path,target,home,dir,string,relative,target,path,throws,ioexception,urisyntax,exception,tuple2,path,local,resource,resource,utils,setup,local,resource,fs,app,id,to,string,local,src,path,target,home,dir,relative,target,path,local,resources,put,key,resource,f1,return,resource,f0
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1521626214;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1522130852;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1522681180;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1523554814;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1523641287;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1524124694;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1525116069;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1527695275;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1530798894;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1531303508;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1531914688;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1539113610;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1541146016;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1541670646;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1541771328;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1546179677;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1548947871;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException;1549456065;Method to validate cluster specification before deploy it, it will throw_an {@link FlinkException} if the {@link ClusterSpecification} is invalid.__@param clusterSpecification cluster specification to check against the configuration of the_AbstractYarnClusterDescriptor_@throws FlinkException if the cluster cannot be started with the provided {@link ClusterSpecification};private void validateClusterSpecification(ClusterSpecification clusterSpecification) throws FlinkException {_		try {_			final long taskManagerMemorySize = clusterSpecification.getTaskManagerMemoryMB()__			_			_			_			final long cutoff = ContaineredTaskManagerParameters.calculateCutoffMB(flinkConfiguration, taskManagerMemorySize)__			TaskManagerServices.calculateHeapSizeMB(taskManagerMemorySize - cutoff, flinkConfiguration)__		} catch (IllegalArgumentException iae) {_			throw new FlinkException("Cannot fulfill the minimum memory requirements with the provided " +_				"cluster specification. Please increase the memory of the cluster.", iae)__		}_	};method,to,validate,cluster,specification,before,deploy,it,it,will,throw,an,link,flink,exception,if,the,link,cluster,specification,is,invalid,param,cluster,specification,cluster,specification,to,check,against,the,configuration,of,the,abstract,yarn,cluster,descriptor,throws,flink,exception,if,the,cluster,cannot,be,started,with,the,provided,link,cluster,specification;private,void,validate,cluster,specification,cluster,specification,cluster,specification,throws,flink,exception,try,final,long,task,manager,memory,size,cluster,specification,get,task,manager,memory,mb,final,long,cutoff,containered,task,manager,parameters,calculate,cutoff,mb,flink,configuration,task,manager,memory,size,task,manager,services,calculate,heap,size,mb,task,manager,memory,size,cutoff,flink,configuration,catch,illegal,argument,exception,iae,throw,new,flink,exception,cannot,fulfill,the,minimum,memory,requirements,with,the,provided,cluster,specification,please,increase,the,memory,of,the,cluster,iae
AbstractYarnClusterDescriptor -> public YarnClusterClient retrieveFromConfig(org.apache.flink.configuration.Configuration config) 			throws UnsupportedOperationException;1466152678;Retrieves the Yarn application and cluster from the config_@param config The config with entries to retrieve the cluster_@return YarnClusterClient_@deprecated This should be removed in the future;public YarnClusterClient retrieveFromConfig(org.apache.flink.configuration.Configuration config)_			throws UnsupportedOperationException {_		String jobManagerHost = config.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, null)__		int jobManagerPort = config.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, -1)___		if (jobManagerHost != null && jobManagerPort != -1) {__			YarnClient yarnClient = getYarnClient()__			final List<ApplicationReport> applicationReports__			try {_				applicationReports = yarnClient.getApplications()__			} catch (Exception e) {_				throw new RuntimeException("Couldn't get Yarn application reports", e)__			}_			for (ApplicationReport report : applicationReports) {_				if (report.getHost().equals(jobManagerHost) && report.getRpcPort() == jobManagerPort) {_					LOG.info("Found application '{}' " +_						"with JobManager host name '{}' and port '{}' from Yarn properties file.",_						report.getApplicationId(), jobManagerHost, jobManagerPort)__					return retrieve(report.getApplicationId().toString())__				}_			}__		}__		LOG.warn("Couldn't retrieve Yarn cluster from Flink configuration using JobManager address '{}:{}'",_			jobManagerHost, jobManagerPort)___		throw new IllegalConfigurationException("Could not resume Yarn cluster from config.")__	};retrieves,the,yarn,application,and,cluster,from,the,config,param,config,the,config,with,entries,to,retrieve,the,cluster,return,yarn,cluster,client,deprecated,this,should,be,removed,in,the,future;public,yarn,cluster,client,retrieve,from,config,org,apache,flink,configuration,configuration,config,throws,unsupported,operation,exception,string,job,manager,host,config,get,string,config,constants,null,int,job,manager,port,config,get,integer,config,constants,1,if,job,manager,host,null,job,manager,port,1,yarn,client,yarn,client,get,yarn,client,final,list,application,report,application,reports,try,application,reports,yarn,client,get,applications,catch,exception,e,throw,new,runtime,exception,couldn,t,get,yarn,application,reports,e,for,application,report,report,application,reports,if,report,get,host,equals,job,manager,host,report,get,rpc,port,job,manager,port,log,info,found,application,with,job,manager,host,name,and,port,from,yarn,properties,file,report,get,application,id,job,manager,host,job,manager,port,return,retrieve,report,get,application,id,to,string,log,warn,couldn,t,retrieve,yarn,cluster,from,flink,configuration,using,job,manager,address,job,manager,host,job,manager,port,throw,new,illegal,configuration,exception,could,not,resume,yarn,cluster,from,config
AbstractYarnClusterDescriptor -> public YarnClusterClient retrieveFromConfig(org.apache.flink.configuration.Configuration config) 			throws UnsupportedOperationException;1466780434;Retrieves the Yarn application and cluster from the config_@param config The config with entries to retrieve the cluster_@return YarnClusterClient_@deprecated This should be removed in the future;public YarnClusterClient retrieveFromConfig(org.apache.flink.configuration.Configuration config)_			throws UnsupportedOperationException {_		String jobManagerHost = config.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, null)__		int jobManagerPort = config.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, -1)___		if (jobManagerHost != null && jobManagerPort != -1) {__			YarnClient yarnClient = getYarnClient()__			final List<ApplicationReport> applicationReports__			try {_				applicationReports = yarnClient.getApplications()__			} catch (Exception e) {_				throw new RuntimeException("Couldn't get Yarn application reports", e)__			}_			for (ApplicationReport report : applicationReports) {_				if (report.getHost().equals(jobManagerHost) && report.getRpcPort() == jobManagerPort) {_					LOG.info("Found application '{}' " +_						"with JobManager host name '{}' and port '{}' from Yarn properties file.",_						report.getApplicationId(), jobManagerHost, jobManagerPort)__					return retrieve(report.getApplicationId().toString())__				}_			}__		}__		LOG.warn("Couldn't retrieve Yarn cluster from Flink configuration using JobManager address '{}:{}'",_			jobManagerHost, jobManagerPort)___		throw new IllegalConfigurationException("Could not resume Yarn cluster from config.")__	};retrieves,the,yarn,application,and,cluster,from,the,config,param,config,the,config,with,entries,to,retrieve,the,cluster,return,yarn,cluster,client,deprecated,this,should,be,removed,in,the,future;public,yarn,cluster,client,retrieve,from,config,org,apache,flink,configuration,configuration,config,throws,unsupported,operation,exception,string,job,manager,host,config,get,string,config,constants,null,int,job,manager,port,config,get,integer,config,constants,1,if,job,manager,host,null,job,manager,port,1,yarn,client,yarn,client,get,yarn,client,final,list,application,report,application,reports,try,application,reports,yarn,client,get,applications,catch,exception,e,throw,new,runtime,exception,couldn,t,get,yarn,application,reports,e,for,application,report,report,application,reports,if,report,get,host,equals,job,manager,host,report,get,rpc,port,job,manager,port,log,info,found,application,with,job,manager,host,name,and,port,from,yarn,properties,file,report,get,application,id,job,manager,host,job,manager,port,return,retrieve,report,get,application,id,to,string,log,warn,couldn,t,retrieve,yarn,cluster,from,flink,configuration,using,job,manager,address,job,manager,host,job,manager,port,throw,new,illegal,configuration,exception,could,not,resume,yarn,cluster,from,config
AbstractYarnClusterDescriptor -> public YarnClusterClient retrieveFromConfig(org.apache.flink.configuration.Configuration config) 			throws UnsupportedOperationException;1467379351;Retrieves the Yarn application and cluster from the config_@param config The config with entries to retrieve the cluster_@return YarnClusterClient_@deprecated This should be removed in the future;public YarnClusterClient retrieveFromConfig(org.apache.flink.configuration.Configuration config)_			throws UnsupportedOperationException {_		String jobManagerHost = config.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, null)__		int jobManagerPort = config.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, -1)___		if (jobManagerHost != null && jobManagerPort != -1) {__			YarnClient yarnClient = getYarnClient()__			final List<ApplicationReport> applicationReports__			try {_				applicationReports = yarnClient.getApplications()__			} catch (Exception e) {_				throw new RuntimeException("Couldn't get Yarn application reports", e)__			}_			for (ApplicationReport report : applicationReports) {_				if (report.getHost().equals(jobManagerHost) && report.getRpcPort() == jobManagerPort) {_					LOG.info("Found application '{}' " +_						"with JobManager host name '{}' and port '{}' from Yarn properties file.",_						report.getApplicationId(), jobManagerHost, jobManagerPort)__					return retrieve(report.getApplicationId().toString())__				}_			}__		}__		LOG.warn("Couldn't retrieve Yarn cluster from Flink configuration using JobManager address '{}:{}'",_			jobManagerHost, jobManagerPort)___		throw new IllegalConfigurationException("Could not resume Yarn cluster from config.")__	};retrieves,the,yarn,application,and,cluster,from,the,config,param,config,the,config,with,entries,to,retrieve,the,cluster,return,yarn,cluster,client,deprecated,this,should,be,removed,in,the,future;public,yarn,cluster,client,retrieve,from,config,org,apache,flink,configuration,configuration,config,throws,unsupported,operation,exception,string,job,manager,host,config,get,string,config,constants,null,int,job,manager,port,config,get,integer,config,constants,1,if,job,manager,host,null,job,manager,port,1,yarn,client,yarn,client,get,yarn,client,final,list,application,report,application,reports,try,application,reports,yarn,client,get,applications,catch,exception,e,throw,new,runtime,exception,couldn,t,get,yarn,application,reports,e,for,application,report,report,application,reports,if,report,get,host,equals,job,manager,host,report,get,rpc,port,job,manager,port,log,info,found,application,with,job,manager,host,name,and,port,from,yarn,properties,file,report,get,application,id,job,manager,host,job,manager,port,return,retrieve,report,get,application,id,to,string,log,warn,couldn,t,retrieve,yarn,cluster,from,flink,configuration,using,job,manager,address,job,manager,host,job,manager,port,throw,new,illegal,configuration,exception,could,not,resume,yarn,cluster,from,config
AbstractYarnClusterDescriptor -> public YarnClusterClient retrieveFromConfig(org.apache.flink.configuration.Configuration config) 			throws UnsupportedOperationException;1467394749;Retrieves the Yarn application and cluster from the config_@param config The config with entries to retrieve the cluster_@return YarnClusterClient_@deprecated This should be removed in the future;public YarnClusterClient retrieveFromConfig(org.apache.flink.configuration.Configuration config)_			throws UnsupportedOperationException {_		String jobManagerHost = config.getString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, null)__		int jobManagerPort = config.getInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, -1)___		if (jobManagerHost != null && jobManagerPort != -1) {__			YarnClient yarnClient = getYarnClient()__			final List<ApplicationReport> applicationReports__			try {_				applicationReports = yarnClient.getApplications()__			} catch (Exception e) {_				throw new RuntimeException("Couldn't get Yarn application reports", e)__			}_			for (ApplicationReport report : applicationReports) {_				if (report.getHost().equals(jobManagerHost) && report.getRpcPort() == jobManagerPort) {_					LOG.info("Found application '{}' " +_						"with JobManager host name '{}' and port '{}' from Yarn properties file.",_						report.getApplicationId(), jobManagerHost, jobManagerPort)__					return retrieve(report.getApplicationId().toString())__				}_			}__		}__		LOG.warn("Couldn't retrieve Yarn cluster from Flink configuration using JobManager address '{}:{}'",_			jobManagerHost, jobManagerPort)___		throw new IllegalConfigurationException("Could not resume Yarn cluster from config.")__	};retrieves,the,yarn,application,and,cluster,from,the,config,param,config,the,config,with,entries,to,retrieve,the,cluster,return,yarn,cluster,client,deprecated,this,should,be,removed,in,the,future;public,yarn,cluster,client,retrieve,from,config,org,apache,flink,configuration,configuration,config,throws,unsupported,operation,exception,string,job,manager,host,config,get,string,config,constants,null,int,job,manager,port,config,get,integer,config,constants,1,if,job,manager,host,null,job,manager,port,1,yarn,client,yarn,client,get,yarn,client,final,list,application,report,application,reports,try,application,reports,yarn,client,get,applications,catch,exception,e,throw,new,runtime,exception,couldn,t,get,yarn,application,reports,e,for,application,report,report,application,reports,if,report,get,host,equals,job,manager,host,report,get,rpc,port,job,manager,port,log,info,found,application,with,job,manager,host,name,and,port,from,yarn,properties,file,report,get,application,id,job,manager,host,job,manager,port,return,retrieve,report,get,application,id,to,string,log,warn,couldn,t,retrieve,yarn,cluster,from,flink,configuration,using,job,manager,address,job,manager,host,job,manager,port,throw,new,illegal,configuration,exception,could,not,resume,yarn,cluster,from,config
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal(ClusterSpecification clusterSpecification) throws Exception;1501088110;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal(ClusterSpecification clusterSpecification) throws Exception {__		isReadyForDeployment(clusterSpecification)___		final YarnClient yarnClient = getYarnClient()___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			null,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			yarnClient,_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,throws,exception,is,ready,for,deployment,cluster,specification,final,yarn,client,yarn,client,get,yarn,client,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,null,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal(ClusterSpecification clusterSpecification) throws Exception;1501237018;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal(ClusterSpecification clusterSpecification) throws Exception {__		isReadyForDeployment(clusterSpecification)___		final YarnClient yarnClient = getYarnClient()___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			null,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			yarnClient,_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,throws,exception,is,ready,for,deployment,cluster,specification,final,yarn,client,yarn,client,get,yarn,client,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,null,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1466152678;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1466152678;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1466152678;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1466780434;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1467379351;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1467394749;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1467396766;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1468944021;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1469630409;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1472033364;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1474401809;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1476095826;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1477570902;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1478286457;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1478790006;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1479746984;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1480082300;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1482522867;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1482522867;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1483644165;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1484162264;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1484734622;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1485274812;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1486575587;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1487622556;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1488923210;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1489509047;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1490967479;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1492605405;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1492605425;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1492763444;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1493975167;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1495108913;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1495787238;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1495787238;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1495787238;Kills YARN application and stops YARN client.__Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1495819079;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1498894422;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1498894422;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1498896127;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1499683297;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1501083592;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1501088110;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1501237018;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1501436689;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1502357790;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1506499511;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1507281370;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1510999087;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1511813739;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1511966584;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1515686359;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1515686369;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1515770043;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1515770043;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1515770044;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1515770045;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1518680659;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1518945172;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1519249745;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1519567828;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1519820825;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1520030750;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1520032158;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1521626214;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1521626214;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1522130852;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1522681180;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1523554814;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1523641287;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1524124694;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1525116069;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1527695275;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1530798894;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1531303508;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1531914688;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1539113610;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1541146016;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1541670646;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1541771328;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1546179677;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1548947871;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication);1549456065;Kills YARN application and stops YARN client.__<p>Use this method to kill the App before it has been properly deployed;private void failSessionDuringDeployment(YarnClient yarnClient, YarnClientApplication yarnApplication) {_		LOG.info("Killing YARN application")___		try {_			yarnClient.killApplication(yarnApplication.getNewApplicationResponse().getApplicationId())__		} catch (Exception e) {_			_			_			LOG.debug("Error while killing YARN application", e)__		}_		yarnClient.stop()__	};kills,yarn,application,and,stops,yarn,client,p,use,this,method,to,kill,the,app,before,it,has,been,properly,deployed;private,void,fail,session,during,deployment,yarn,client,yarn,client,yarn,client,application,yarn,application,log,info,killing,yarn,application,try,yarn,client,kill,application,yarn,application,get,new,application,response,get,application,id,catch,exception,e,log,debug,error,while,killing,yarn,application,e,yarn,client,stop
AbstractYarnClusterDescriptor -> public static YarnClient getYarnClient(Configuration conf);1466152678;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;public static YarnClient getYarnClient(Configuration conf) {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;public,static,yarn,client,get,yarn,client,configuration,conf,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> public static YarnClient getYarnClient(Configuration conf);1466152678;Gets a Hadoop Yarn client_@return Returns a YarnClient which has to be shutdown manually;public static YarnClient getYarnClient(Configuration conf) {_		YarnClient yarnClient = YarnClient.createYarnClient()__		yarnClient.init(conf)__		yarnClient.start()__		return yarnClient__	};gets,a,hadoop,yarn,client,return,returns,a,yarn,client,which,has,to,be,shutdown,manually;public,static,yarn,client,get,yarn,client,configuration,conf,yarn,client,yarn,client,yarn,client,create,yarn,client,yarn,client,init,conf,yarn,client,start,return,yarn,client
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1501088110;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1501237018;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1501436689;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1502357790;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1506499511;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1507281370;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1510999087;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1511813739;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1511966584;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1515686359;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			yarnClient,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,yarn,client,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1515686369;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1515770043;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1515770043;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1515770044;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1515770045;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1518680659;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1518945172;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1519249745;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1519567828;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1519820825;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1520030750;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1520032158;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1521626214;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1521626214;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1522130852;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1522681180;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1523554814;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1523641287;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1524124694;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1525116069;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1527695275;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1530798894;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1531303508;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1531914688;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1539113610;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1541146016;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1541670646;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1541771328;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1546179677;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1548947871;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnJobClusterEntrypoint()_;1549456065;The class to start the application master with. This class runs the main_method in case of the job cluster.;protected abstract String getYarnJobClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,the,job,cluster;protected,abstract,string,get,yarn,job,cluster,entrypoint
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1523641287;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1524124694;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1525116069;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1527695275;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1530798894;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1531303508;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1531914688;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1539113610;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1541146016;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1541670646;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1541771328;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1546179677;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1548947871;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> @Deprecated 	public void setDetachedMode(boolean detachedMode);1549456065;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public void setDetachedMode(boolean detachedMode) {_		this.detached = detachedMode__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,void,set,detached,mode,boolean,detached,mode,this,detached,detached,mode
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph) throws Exception;1501436689;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param jobGraph A job graph which is deployed with the Flink cluster, null if none;protected YarnClusterClient deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		final YarnClient yarnClient = getYarnClient()___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			yarnClient,_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,null,if,none;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,final,yarn,client,yarn,client,get,yarn,client,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph) throws Exception;1502357790;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param jobGraph A job graph which is deployed with the Flink cluster, null if none;protected YarnClusterClient deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		final YarnClient yarnClient = getYarnClient()___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			yarnClient,_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,null,if,none;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,final,yarn,client,yarn,client,get,yarn,client,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph) throws Exception;1506499511;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param jobGraph A job graph which is deployed with the Flink cluster, null if none;protected YarnClusterClient deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		final YarnClient yarnClient = getYarnClient()___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			yarnClient,_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,null,if,none;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,final,yarn,client,yarn,client,get,yarn,client,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph) throws Exception;1507281370;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param jobGraph A job graph which is deployed with the Flink cluster, null if none;protected YarnClusterClient deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		final YarnClient yarnClient = getYarnClient()___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			yarnClient,_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,null,if,none;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,final,yarn,client,yarn,client,get,yarn,client,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph) throws Exception;1510999087;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param jobGraph A job graph which is deployed with the Flink cluster, null if none;protected YarnClusterClient deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		final YarnClient yarnClient = getYarnClient()___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			yarnClient,_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,null,if,none;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,final,yarn,client,yarn,client,get,yarn,client,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph) throws Exception;1511813739;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param jobGraph A job graph which is deployed with the Flink cluster, null if none;protected YarnClusterClient deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		final YarnClient yarnClient = getYarnClient()___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			yarnClient,_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,null,if,none;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,final,yarn,client,yarn,client,get,yarn,client,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph) throws Exception;1511966584;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param jobGraph A job graph which is deployed with the Flink cluster, null if none;protected YarnClusterClient deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		final YarnClient yarnClient = getYarnClient()___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			yarnClient,_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,null,if,none;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,final,yarn,client,yarn,client,get,yarn,client,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph) throws Exception;1515686359;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param jobGraph A job graph which is deployed with the Flink cluster, null if none;protected YarnClusterClient deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		final YarnClient yarnClient = getYarnClient()___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			yarnClient,_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,null,if,none;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,final,yarn,client,yarn,client,get,yarn,client,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph) throws Exception;1515686369;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param jobGraph A job graph which is deployed with the Flink cluster, null if none;protected YarnClusterClient deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,null,if,none;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph) throws Exception;1515770043;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param jobGraph A job graph which is deployed with the Flink cluster, null if none;protected YarnClusterClient deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,null,if,none;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph) throws Exception;1515770043;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param jobGraph A job graph which is deployed with the Flink cluster, null if none;protected YarnClusterClient deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,null,if,none;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal( 			ClusterSpecification clusterSpecification, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph) throws Exception;1515770044;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.__@param clusterSpecification Initial cluster specification for the to be deployed Flink cluster_@param jobGraph A job graph which is deployed with the Flink cluster, null if none;protected YarnClusterClient deployInternal(_			ClusterSpecification clusterSpecification,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph) throws Exception {__		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt("yarn.scheduler.minimum-allocation-mb", 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		ApplicationReport report = startAppMaster(_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,to,be,deployed,flink,cluster,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,null,if,none;protected,yarn,cluster,client,deploy,internal,cluster,specification,cluster,specification,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,throws,exception,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,scheduler,minimum,allocation,mb,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,application,report,report,start,app,master,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1522130852;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1522681180;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1523554814;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1523641287;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.REST_ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.REST_PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,host,flink,configuration,set,integer,rest,options,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1524124694;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1525116069;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1527695275;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1530798894;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(yarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1531303508;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1531914688;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1539113610;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			clusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			clusterSpecification.getNumberTaskManagers(),_			clusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,cluster,specification,get,number,task,managers,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1541146016;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			validClusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			validClusterSpecification.getNumberTaskManagers(),_			validClusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,valid,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,valid,cluster,specification,get,number,task,managers,valid,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1541670646;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			validClusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			validClusterSpecification.getNumberTaskManagers(),_			validClusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,valid,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,valid,cluster,specification,get,number,task,managers,valid,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1541771328;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			validClusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			validClusterSpecification.getNumberTaskManagers(),_			validClusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,valid,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,valid,cluster,specification,get,number,task,managers,valid,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1546179677;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			validClusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			validClusterSpecification.getNumberTaskManagers(),_			validClusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,valid,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,valid,cluster,specification,get,number,task,managers,valid,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1548947871;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			validClusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			validClusterSpecification.getNumberTaskManagers(),_			validClusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,valid,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,valid,cluster,specification,get,number,task,managers,valid,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected ClusterClient<ApplicationId> deployInternal( 			ClusterSpecification clusterSpecification, 			String applicationName, 			String yarnClusterEntrypoint, 			@Nullable JobGraph jobGraph, 			boolean detached) throws Exception;1549456065;This method will block until the ApplicationMaster/JobManager have been deployed on YARN.__@param clusterSpecification Initial cluster specification for the Flink cluster to be deployed_@param applicationName name of the Yarn application to start_@param yarnClusterEntrypoint Class name of the Yarn cluster entry point._@param jobGraph A job graph which is deployed with the Flink cluster, {@code null} if none_@param detached True if the cluster should be started in detached mode;protected ClusterClient<ApplicationId> deployInternal(_			ClusterSpecification clusterSpecification,_			String applicationName,_			String yarnClusterEntrypoint,_			@Nullable JobGraph jobGraph,_			boolean detached) throws Exception {__		_		validateClusterSpecification(clusterSpecification)___		if (UserGroupInformation.isSecurityEnabled()) {_			_			_			_			boolean useTicketCache = flinkConfiguration.getBoolean(SecurityOptions.KERBEROS_LOGIN_USETICKETCACHE)___			UserGroupInformation loginUser = UserGroupInformation.getCurrentUser()__			if (loginUser.getAuthenticationMethod() == UserGroupInformation.AuthenticationMethod.KERBEROS_				&& useTicketCache && !loginUser.hasKerberosCredentials()) {_				LOG.error("Hadoop security with Kerberos is enabled but the login user does not have Kerberos credentials")__				throw new RuntimeException("Hadoop security with Kerberos is enabled but the login user " +_					"does not have Kerberos credentials")__			}_		}__		isReadyForDeployment(clusterSpecification)___		__		checkYarnQueues(yarnClient)___		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		final GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()___		final ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		final int yarnMinAllocationMB = yarnConfiguration.getInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 0)___		final ClusterSpecification validClusterSpecification__		try {_			validClusterSpecification = validateClusterResources(_				clusterSpecification,_				yarnMinAllocationMB,_				maxRes,_				freeClusterMem)__		} catch (YarnDeploymentException yde) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw yde__		}__		LOG.info("Cluster specification: {}", validClusterSpecification)___		final ClusterEntrypoint.ExecutionMode executionMode = detached ?_			ClusterEntrypoint.ExecutionMode.DETACHED_			: ClusterEntrypoint.ExecutionMode.NORMAL___		flinkConfiguration.setString(ClusterEntrypoint.EXECUTION_MODE, executionMode.toString())___		ApplicationReport report = startAppMaster(_			flinkConfiguration,_			applicationName,_			yarnClusterEntrypoint,_			jobGraph,_			yarnClient,_			yarnApplication,_			validClusterSpecification)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		flinkConfiguration.setString(RestOptions.ADDRESS, host)__		flinkConfiguration.setInteger(RestOptions.PORT, port)___		_		return createYarnClusterClient(_			this,_			validClusterSpecification.getNumberTaskManagers(),_			validClusterSpecification.getSlotsPerTaskManager(),_			report,_			flinkConfiguration,_			true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn,param,cluster,specification,initial,cluster,specification,for,the,flink,cluster,to,be,deployed,param,application,name,name,of,the,yarn,application,to,start,param,yarn,cluster,entrypoint,class,name,of,the,yarn,cluster,entry,point,param,job,graph,a,job,graph,which,is,deployed,with,the,flink,cluster,code,null,if,none,param,detached,true,if,the,cluster,should,be,started,in,detached,mode;protected,cluster,client,application,id,deploy,internal,cluster,specification,cluster,specification,string,application,name,string,yarn,cluster,entrypoint,nullable,job,graph,job,graph,boolean,detached,throws,exception,validate,cluster,specification,cluster,specification,if,user,group,information,is,security,enabled,boolean,use,ticket,cache,flink,configuration,get,boolean,security,options,user,group,information,login,user,user,group,information,get,current,user,if,login,user,get,authentication,method,user,group,information,authentication,method,kerberos,use,ticket,cache,login,user,has,kerberos,credentials,log,error,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,throw,new,runtime,exception,hadoop,security,with,kerberos,is,enabled,but,the,login,user,does,not,have,kerberos,credentials,is,ready,for,deployment,cluster,specification,check,yarn,queues,yarn,client,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,yarn,client,application,yarn,application,yarn,client,create,application,final,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,final,int,yarn,min,allocation,mb,yarn,configuration,get,int,yarn,configuration,0,final,cluster,specification,valid,cluster,specification,try,valid,cluster,specification,validate,cluster,resources,cluster,specification,yarn,min,allocation,mb,max,res,free,cluster,mem,catch,yarn,deployment,exception,yde,fail,session,during,deployment,yarn,client,yarn,application,throw,yde,log,info,cluster,specification,valid,cluster,specification,final,cluster,entrypoint,execution,mode,execution,mode,detached,cluster,entrypoint,execution,mode,detached,cluster,entrypoint,execution,mode,normal,flink,configuration,set,string,cluster,entrypoint,execution,mode,to,string,application,report,report,start,app,master,flink,configuration,application,name,yarn,cluster,entrypoint,job,graph,yarn,client,yarn,application,valid,cluster,specification,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,flink,configuration,set,string,rest,options,address,host,flink,configuration,set,integer,rest,options,port,port,return,create,yarn,cluster,client,this,valid,cluster,specification,get,number,task,managers,valid,cluster,specification,get,slots,per,task,manager,report,flink,configuration,true
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1523641287;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1524124694;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1525116069;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1527695275;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1530798894;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1531303508;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1531914688;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1539113610;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1541146016;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1541670646;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1541771328;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1546179677;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1548947871;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> @Deprecated 	public boolean isDetachedMode();1549456065;@deprecated The cluster descriptor should not know about this option.;@Deprecated_	public boolean isDetachedMode() {_		return detached__	};deprecated,the,cluster,descriptor,should,not,know,about,this,option;deprecated,public,boolean,is,detached,mode,return,detached
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1511966584;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1515686359;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1515686369;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1515770043;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1515770043;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1515770044;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1515770045;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1518680659;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1518945172;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1519249745;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1519567828;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1519820825;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1520030750;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1520032158;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1521626214;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1521626214;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1522130852;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1522681180;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1523554814;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1523641287;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1524124694;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1525116069;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1527695275;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1530798894;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1531303508;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {__						if (!(file.getFileName().startsWith("flink-dist") &&_								file.getFileName().endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,if,file,get,file,name,starts,with,flink,dist,file,get,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1531914688;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {_						String fileName = file.getFileName().toString()__						if (!(fileName.startsWith("flink-dist") &&_								fileName.endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,string,file,name,file,get,file,name,to,string,if,file,name,starts,with,flink,dist,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1539113610;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {_						String fileName = file.getFileName().toString()__						if (!(fileName.startsWith("flink-dist") &&_								fileName.endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,string,file,name,file,get,file,name,to,string,if,file,name,starts,with,flink,dist,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1541146016;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {_						String fileName = file.getFileName().toString()__						if (!(fileName.startsWith("flink-dist") &&_								fileName.endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,string,file,name,file,get,file,name,to,string,if,file,name,starts,with,flink,dist,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1541670646;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {_						String fileName = file.getFileName().toString()__						if (!(fileName.startsWith("flink-dist") &&_								fileName.endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,string,file,name,file,get,file,name,to,string,if,file,name,starts,with,flink,dist,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1541771328;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {_						String fileName = file.getFileName().toString()__						if (!(fileName.startsWith("flink-dist") &&_								fileName.endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,string,file,name,file,get,file,name,to,string,if,file,name,starts,with,flink,dist,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1546179677;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {_						String fileName = file.getFileName().toString()__						if (!(fileName.startsWith("flink-dist") &&_								fileName.endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,string,file,name,file,get,file,name,to,string,if,file,name,starts,with,flink,dist,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1548947871;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {_						String fileName = file.getFileName().toString()__						if (!(fileName.startsWith("flink-dist") &&_								fileName.endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,string,file,name,file,get,file,name,to,string,if,file,name,starts,with,flink,dist,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> static List<String> uploadAndRegisterFiles( 			Collection<File> shipFiles, 			FileSystem fs, 			Path targetHomeDir, 			ApplicationId appId, 			List<Path> remotePaths, 			Map<String, LocalResource> localResources, 			StringBuilder envShipFileList) throws IOException, URISyntaxException;1549456065;Recursively uploads (and registers) any (user and system) files in <tt>shipFiles</tt> except_for files matching "<tt>flink-dist*.jar</tt>" which should be uploaded separately.__@param shipFiles_files to upload_@param fs_file system to upload to_@param targetHomeDir_remote home directory to upload to_@param appId_application ID_@param remotePaths_paths of the remote resources (uploaded resources will be added)_@param localResources_map of resources (uploaded resources will be added)_@param envShipFileList_list of shipped files in a format understood by {@link Utils#createTaskExecutorContext}__@return list of class paths with the the proper resource keys from the registration;static List<String> uploadAndRegisterFiles(_			Collection<File> shipFiles,_			FileSystem fs,_			Path targetHomeDir,_			ApplicationId appId,_			List<Path> remotePaths,_			Map<String, LocalResource> localResources,_			StringBuilder envShipFileList) throws IOException, URISyntaxException {__		final List<String> classPaths = new ArrayList<>(2 + shipFiles.size())__		for (File shipFile : shipFiles) {_			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult visitFile(java.nio.file.Path file, BasicFileAttributes attrs)_						throws IOException {_						String fileName = file.getFileName().toString()__						if (!(fileName.startsWith("flink-dist") &&_								fileName.endsWith("jar"))) {__							java.nio.file.Path relativePath = parentPath.relativize(file)___							String key = relativePath.toString()__							try {_								Path remotePath = setupSingleLocalResource(_									key,_									fs,_									appId,_									new Path(file.toUri()),_									localResources,_									targetHomeDir,_									relativePath.getParent().toString())__								remotePaths.add(remotePath)__								envShipFileList.append(key).append("=")_									.append(remotePath).append(",")___								_								classPaths.add(key)__							} catch (URISyntaxException e) {_								throw new IOException(e)__							}_						}__						return FileVisitResult.CONTINUE__					}_				})__			} else {_				if (!(shipFile.getName().startsWith("flink-dist") && shipFile.getName().endsWith("jar"))) {_					Path shipLocalPath = new Path(shipFile.toURI())__					String key = shipFile.getName()__					Path remotePath = setupSingleLocalResource(_						key, fs, appId, shipLocalPath, localResources, targetHomeDir, "")__					remotePaths.add(remotePath)__					envShipFileList.append(key).append("=").append(remotePath).append(",")___					_					classPaths.add(key)__				}_			}__		}_		return classPaths__	};recursively,uploads,and,registers,any,user,and,system,files,in,tt,ship,files,tt,except,for,files,matching,tt,flink,dist,jar,tt,which,should,be,uploaded,separately,param,ship,files,files,to,upload,param,fs,file,system,to,upload,to,param,target,home,dir,remote,home,directory,to,upload,to,param,app,id,application,id,param,remote,paths,paths,of,the,remote,resources,uploaded,resources,will,be,added,param,local,resources,map,of,resources,uploaded,resources,will,be,added,param,env,ship,file,list,list,of,shipped,files,in,a,format,understood,by,link,utils,create,task,executor,context,return,list,of,class,paths,with,the,the,proper,resource,keys,from,the,registration;static,list,string,upload,and,register,files,collection,file,ship,files,file,system,fs,path,target,home,dir,application,id,app,id,list,path,remote,paths,map,string,local,resource,local,resources,string,builder,env,ship,file,list,throws,ioexception,urisyntax,exception,final,list,string,class,paths,new,array,list,2,ship,files,size,for,file,ship,file,ship,files,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,visit,file,java,nio,file,path,file,basic,file,attributes,attrs,throws,ioexception,string,file,name,file,get,file,name,to,string,if,file,name,starts,with,flink,dist,file,name,ends,with,jar,java,nio,file,path,relative,path,parent,path,relativize,file,string,key,relative,path,to,string,try,path,remote,path,setup,single,local,resource,key,fs,app,id,new,path,file,to,uri,local,resources,target,home,dir,relative,path,get,parent,to,string,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,catch,urisyntax,exception,e,throw,new,ioexception,e,return,file,visit,result,continue,else,if,ship,file,get,name,starts,with,flink,dist,ship,file,get,name,ends,with,jar,path,ship,local,path,new,path,ship,file,to,uri,string,key,ship,file,get,name,path,remote,path,setup,single,local,resource,key,fs,app,id,ship,local,path,local,resources,target,home,dir,remote,paths,add,remote,path,env,ship,file,list,append,key,append,append,remote,path,append,class,paths,add,key,return,class,paths
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1515770045;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1518680659;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1518945172;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1519249745;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1519567828;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1519820825;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1520030750;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1520032158;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1521626214;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1521626214;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1522130852;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1522681180;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1523554814;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1523641287;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1524124694;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1525116069;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1527695275;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1530798894;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1531303508;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1531914688;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1539113610;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1541146016;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1541670646;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1541771328;Creates a YarnClusterClient_ may be overriden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1546179677;Creates a YarnClusterClient_ may be overridden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overridden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1548947871;Creates a YarnClusterClient_ may be overridden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overridden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected abstract ClusterClient<ApplicationId> createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception_;1549456065;Creates a YarnClusterClient_ may be overridden in tests.;protected abstract ClusterClient<ApplicationId> createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception_;creates,a,yarn,cluster,client,may,be,overridden,in,tests;protected,abstract,cluster,client,application,id,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1466152678;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()___		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		_		final YarnClient yarnClient = getYarnClient(conf)__		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		__		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}_		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		__		_		final String javaOpts = flinkConfiguration.getString(ConfigConstants.FLINK_JVM_OPTIONS, "")___		String logbackFile = configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME__		boolean hasLogback = new File(logbackFile).exists()__		String log4jFile = configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME___		boolean hasLog4j = new File(log4jFile).exists()__		if(hasLogback) {_			shipFiles.add(new File(logbackFile))__		}_		if(hasLog4j) {_			shipFiles.add(new File(log4jFile))__		}__		_		ContainerLaunchContext amContainer = Records.newRecord(ContainerLaunchContext.class)___		String amCommand = "$JAVA_HOME/bin/java"_			+ " -Xmx" + Utils.calculateHeapSize(jobManagerMemoryMb, flinkConfiguration)_			+ "M " + javaOpts___		if(hasLogback || hasLog4j) {_			amCommand += " -Dlog.file=\"" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.log\""___			if(hasLogback) {_				amCommand += " -Dlogback.configurationFile=file:" + CONFIG_FILE_LOGBACK_NAME__			}__			if(hasLog4j) {_				amCommand += " -Dlog4j.configuration=file:" + CONFIG_FILE_LOG4J_NAME__			}_		}__		amCommand += " " + getApplicationMasterClass().getName() + " "_			+ " 1>"_			+ ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.out"_			+ " 2>" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.err"__		amContainer.setCommands(Collections.singletonList(amCommand))___		LOG.debug("Application Master start command: " + amCommand)___		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		if (RecoveryMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		final ApplicationId appId = appContext.getApplicationId()___		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar = Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf = Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		Map<String, LocalResource> localResources = new HashMap<>(2)__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)____		_		final Path[] paths = new Path[2 + shipFiles.size()]__		StringBuilder envShipFileList = new StringBuilder()__		_		for (int i = 0_ i < shipFiles.size()_ i++) {_			File shipFile = shipFiles.get(i)__			LocalResource shipResources = Records.newRecord(LocalResource.class)__			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			paths[2 + i] = Utils.setupLocalResource(fs, appId.toString(),_				shipLocalPath, shipResources, fs.getHomeDirectory())__			localResources.put(shipFile.getName(), shipResources)___			envShipFileList.append(paths[2 + i])__			if(i+1 < shipFiles.size()) {_				envShipFileList.append(',')__			}_		}__		paths[0] = remotePathJar__		paths[1] = remotePathConf__		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		Utils.setTokensFor(amContainer, paths, conf)___		amContainer.setLocalResources(localResources)__		fs.close()___		_		Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		Utils.setupEnv(conf, appMasterEnv)__		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_USERNAME, UserGroupInformation.getCurrentUser().getShortUserName())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))___		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		int waittime = 0__		ApplicationReport report__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster: " + e.getMessage())__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					LOG.info("Deploying cluster, current state " + appState)__					if(waittime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			waittime += 1000__			Thread.sleep(1000)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()__		String trackingURL = report.getTrackingUrl()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return new YarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,conf,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,final,string,java,opts,flink,configuration,get,string,config,constants,string,logback,file,configuration,directory,file,separator,boolean,has,logback,new,file,logback,file,exists,string,log4j,file,configuration,directory,file,separator,boolean,has,log4j,new,file,log4j,file,exists,if,has,logback,ship,files,add,new,file,logback,file,if,has,log4j,ship,files,add,new,file,log4j,file,container,launch,context,am,container,records,new,record,container,launch,context,class,string,am,command,bin,java,xmx,utils,calculate,heap,size,job,manager,memory,mb,flink,configuration,m,java,opts,if,has,logback,has,log4j,am,command,dlog,file,application,constants,jobmanager,log,if,has,logback,am,command,dlogback,configuration,file,file,if,has,log4j,am,command,dlog4j,configuration,file,am,command,get,application,master,class,get,name,1,application,constants,jobmanager,out,2,application,constants,jobmanager,err,am,container,set,commands,collections,singleton,list,am,command,log,debug,application,master,start,command,am,command,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,application,submission,context,app,context,yarn,application,get,application,submission,context,if,recovery,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,application,id,app,id,app,context,get,application,id,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,map,string,local,resource,local,resources,new,hash,map,2,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,final,path,paths,new,path,2,ship,files,size,string,builder,env,ship,file,list,new,string,builder,for,int,i,0,i,ship,files,size,i,file,ship,file,ship,files,get,i,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,paths,2,i,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,local,resources,put,ship,file,get,name,ship,resources,env,ship,file,list,append,paths,2,i,if,i,1,ship,files,size,env,ship,file,list,append,paths,0,remote,path,jar,paths,1,remote,path,conf,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,utils,setup,env,conf,app,master,env,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,short,user,name,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,int,waittime,0,application,report,report,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,get,message,yarn,application,state,app,state,report,get,yarn,application,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,log,info,deploying,cluster,current,state,app,state,if,waittime,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,waittime,1000,thread,sleep,1000,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,string,tracking,url,report,get,tracking,url,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,new,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1466152678;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()___		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		_		final YarnClient yarnClient = getYarnClient(conf)__		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		__		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}_		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		__		_		final String javaOpts = flinkConfiguration.getString(ConfigConstants.FLINK_JVM_OPTIONS, "")___		String logbackFile = configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME__		boolean hasLogback = new File(logbackFile).exists()__		String log4jFile = configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME___		boolean hasLog4j = new File(log4jFile).exists()__		if(hasLogback) {_			shipFiles.add(new File(logbackFile))__		}_		if(hasLog4j) {_			shipFiles.add(new File(log4jFile))__		}__		_		ContainerLaunchContext amContainer = Records.newRecord(ContainerLaunchContext.class)___		String amCommand = "$JAVA_HOME/bin/java"_			+ " -Xmx" + Utils.calculateHeapSize(jobManagerMemoryMb, flinkConfiguration)_			+ "M " + javaOpts___		if(hasLogback || hasLog4j) {_			amCommand += " -Dlog.file=\"" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.log\""___			if(hasLogback) {_				amCommand += " -Dlogback.configurationFile=file:" + CONFIG_FILE_LOGBACK_NAME__			}__			if(hasLog4j) {_				amCommand += " -Dlog4j.configuration=file:" + CONFIG_FILE_LOG4J_NAME__			}_		}__		amCommand += " " + getApplicationMasterClass().getName() + " "_			+ " 1>"_			+ ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.out"_			+ " 2>" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.err"__		amContainer.setCommands(Collections.singletonList(amCommand))___		LOG.debug("Application Master start command: " + amCommand)___		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		if (RecoveryMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		final ApplicationId appId = appContext.getApplicationId()___		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar = Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf = Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		Map<String, LocalResource> localResources = new HashMap<>(2)__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)____		_		final Path[] paths = new Path[2 + shipFiles.size()]__		StringBuilder envShipFileList = new StringBuilder()__		_		for (int i = 0_ i < shipFiles.size()_ i++) {_			File shipFile = shipFiles.get(i)__			LocalResource shipResources = Records.newRecord(LocalResource.class)__			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			paths[2 + i] = Utils.setupLocalResource(fs, appId.toString(),_				shipLocalPath, shipResources, fs.getHomeDirectory())__			localResources.put(shipFile.getName(), shipResources)___			envShipFileList.append(paths[2 + i])__			if(i+1 < shipFiles.size()) {_				envShipFileList.append(',')__			}_		}__		paths[0] = remotePathJar__		paths[1] = remotePathConf__		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		Utils.setTokensFor(amContainer, paths, conf)___		amContainer.setLocalResources(localResources)__		fs.close()___		_		Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		Utils.setupEnv(conf, appMasterEnv)__		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_USERNAME, UserGroupInformation.getCurrentUser().getShortUserName())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))___		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		int waittime = 0__		ApplicationReport report__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster: " + e.getMessage())__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					LOG.info("Deploying cluster, current state " + appState)__					if(waittime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			waittime += 1000__			Thread.sleep(1000)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()__		String trackingURL = report.getTrackingUrl()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return new YarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,conf,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,final,string,java,opts,flink,configuration,get,string,config,constants,string,logback,file,configuration,directory,file,separator,boolean,has,logback,new,file,logback,file,exists,string,log4j,file,configuration,directory,file,separator,boolean,has,log4j,new,file,log4j,file,exists,if,has,logback,ship,files,add,new,file,logback,file,if,has,log4j,ship,files,add,new,file,log4j,file,container,launch,context,am,container,records,new,record,container,launch,context,class,string,am,command,bin,java,xmx,utils,calculate,heap,size,job,manager,memory,mb,flink,configuration,m,java,opts,if,has,logback,has,log4j,am,command,dlog,file,application,constants,jobmanager,log,if,has,logback,am,command,dlogback,configuration,file,file,if,has,log4j,am,command,dlog4j,configuration,file,am,command,get,application,master,class,get,name,1,application,constants,jobmanager,out,2,application,constants,jobmanager,err,am,container,set,commands,collections,singleton,list,am,command,log,debug,application,master,start,command,am,command,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,application,submission,context,app,context,yarn,application,get,application,submission,context,if,recovery,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,application,id,app,id,app,context,get,application,id,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,map,string,local,resource,local,resources,new,hash,map,2,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,final,path,paths,new,path,2,ship,files,size,string,builder,env,ship,file,list,new,string,builder,for,int,i,0,i,ship,files,size,i,file,ship,file,ship,files,get,i,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,paths,2,i,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,local,resources,put,ship,file,get,name,ship,resources,env,ship,file,list,append,paths,2,i,if,i,1,ship,files,size,env,ship,file,list,append,paths,0,remote,path,jar,paths,1,remote,path,conf,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,utils,setup,env,conf,app,master,env,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,short,user,name,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,int,waittime,0,application,report,report,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,get,message,yarn,application,state,app,state,report,get,yarn,application,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,log,info,deploying,cluster,current,state,app,state,if,waittime,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,waittime,1000,thread,sleep,1000,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,string,tracking,url,report,get,tracking,url,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,new,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1466152678;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()___		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		_		final YarnClient yarnClient = getYarnClient()__		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		__		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}_		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		__		_		final String javaOpts = flinkConfiguration.getString(ConfigConstants.FLINK_JVM_OPTIONS, "")___		String logbackFile = configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME__		boolean hasLogback = new File(logbackFile).exists()__		String log4jFile = configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME___		boolean hasLog4j = new File(log4jFile).exists()__		if(hasLogback) {_			shipFiles.add(new File(logbackFile))__		}_		if(hasLog4j) {_			shipFiles.add(new File(log4jFile))__		}__		_		ContainerLaunchContext amContainer = Records.newRecord(ContainerLaunchContext.class)___		String amCommand = "$JAVA_HOME/bin/java"_			+ " -Xmx" + Utils.calculateHeapSize(jobManagerMemoryMb, flinkConfiguration)_			+ "M " + javaOpts___		if(hasLogback || hasLog4j) {_			amCommand += " -Dlog.file=\"" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.log\""___			if(hasLogback) {_				amCommand += " -Dlogback.configurationFile=file:" + CONFIG_FILE_LOGBACK_NAME__			}__			if(hasLog4j) {_				amCommand += " -Dlog4j.configuration=file:" + CONFIG_FILE_LOG4J_NAME__			}_		}__		amCommand += " " + getApplicationMasterClass().getName() + " "_			+ " 1>"_			+ ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.out"_			+ " 2>" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.err"__		amContainer.setCommands(Collections.singletonList(amCommand))___		LOG.debug("Application Master start command: " + amCommand)___		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		if (RecoveryMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		final ApplicationId appId = appContext.getApplicationId()___		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar = Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf = Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		Map<String, LocalResource> localResources = new HashMap<>(2)__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)____		_		final Path[] paths = new Path[2 + shipFiles.size()]__		StringBuilder envShipFileList = new StringBuilder()__		_		for (int i = 0_ i < shipFiles.size()_ i++) {_			File shipFile = shipFiles.get(i)__			LocalResource shipResources = Records.newRecord(LocalResource.class)__			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			paths[2 + i] = Utils.setupLocalResource(fs, appId.toString(),_				shipLocalPath, shipResources, fs.getHomeDirectory())__			localResources.put(shipFile.getName(), shipResources)___			envShipFileList.append(paths[2 + i])__			if(i+1 < shipFiles.size()) {_				envShipFileList.append(',')__			}_		}__		paths[0] = remotePathJar__		paths[1] = remotePathConf__		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		Utils.setTokensFor(amContainer, paths, conf)___		amContainer.setLocalResources(localResources)__		fs.close()___		_		Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		Utils.setupEnv(conf, appMasterEnv)__		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_USERNAME, UserGroupInformation.getCurrentUser().getShortUserName())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))___		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		int waittime = 0__		ApplicationReport report__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster: " + e.getMessage())__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					LOG.info("Deploying cluster, current state " + appState)__					if(waittime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			waittime += 1000__			Thread.sleep(1000)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()__		String trackingURL = report.getTrackingUrl()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,final,string,java,opts,flink,configuration,get,string,config,constants,string,logback,file,configuration,directory,file,separator,boolean,has,logback,new,file,logback,file,exists,string,log4j,file,configuration,directory,file,separator,boolean,has,log4j,new,file,log4j,file,exists,if,has,logback,ship,files,add,new,file,logback,file,if,has,log4j,ship,files,add,new,file,log4j,file,container,launch,context,am,container,records,new,record,container,launch,context,class,string,am,command,bin,java,xmx,utils,calculate,heap,size,job,manager,memory,mb,flink,configuration,m,java,opts,if,has,logback,has,log4j,am,command,dlog,file,application,constants,jobmanager,log,if,has,logback,am,command,dlogback,configuration,file,file,if,has,log4j,am,command,dlog4j,configuration,file,am,command,get,application,master,class,get,name,1,application,constants,jobmanager,out,2,application,constants,jobmanager,err,am,container,set,commands,collections,singleton,list,am,command,log,debug,application,master,start,command,am,command,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,application,submission,context,app,context,yarn,application,get,application,submission,context,if,recovery,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,application,id,app,id,app,context,get,application,id,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,map,string,local,resource,local,resources,new,hash,map,2,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,final,path,paths,new,path,2,ship,files,size,string,builder,env,ship,file,list,new,string,builder,for,int,i,0,i,ship,files,size,i,file,ship,file,ship,files,get,i,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,paths,2,i,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,local,resources,put,ship,file,get,name,ship,resources,env,ship,file,list,append,paths,2,i,if,i,1,ship,files,size,env,ship,file,list,append,paths,0,remote,path,jar,paths,1,remote,path,conf,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,utils,setup,env,conf,app,master,env,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,short,user,name,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,int,waittime,0,application,report,report,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,get,message,yarn,application,state,app,state,report,get,yarn,application,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,log,info,deploying,cluster,current,state,app,state,if,waittime,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,waittime,1000,thread,sleep,1000,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,string,tracking,url,report,get,tracking,url,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1466780434;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()___		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		_		final YarnClient yarnClient = getYarnClient()__		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		__		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}_		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		__		_		final String javaOpts = flinkConfiguration.getString(ConfigConstants.FLINK_JVM_OPTIONS, "")___		String logbackFile = configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME__		boolean hasLogback = new File(logbackFile).exists()__		String log4jFile = configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME___		boolean hasLog4j = new File(log4jFile).exists()__		if(hasLogback) {_			shipFiles.add(new File(logbackFile))__		}_		if(hasLog4j) {_			shipFiles.add(new File(log4jFile))__		}__		_		ContainerLaunchContext amContainer = Records.newRecord(ContainerLaunchContext.class)___		String amCommand = "$JAVA_HOME/bin/java"_			+ " -Xmx" + Utils.calculateHeapSize(jobManagerMemoryMb, flinkConfiguration)_			+ "M " + javaOpts___		if(hasLogback || hasLog4j) {_			amCommand += " -Dlog.file=\"" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.log\""___			if(hasLogback) {_				amCommand += " -Dlogback.configurationFile=file:" + CONFIG_FILE_LOGBACK_NAME__			}__			if(hasLog4j) {_				amCommand += " -Dlog4j.configuration=file:" + CONFIG_FILE_LOG4J_NAME__			}_		}__		amCommand += " " + getApplicationMasterClass().getName() + " "_			+ " 1>"_			+ ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.out"_			+ " 2>" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/jobmanager.err"__		amContainer.setCommands(Collections.singletonList(amCommand))___		LOG.debug("Application Master start command: " + amCommand)___		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		if (RecoveryMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		final ApplicationId appId = appContext.getApplicationId()___		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar = Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf = Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		Map<String, LocalResource> localResources = new HashMap<>(2)__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)____		_		final Path[] paths = new Path[2 + shipFiles.size()]__		StringBuilder envShipFileList = new StringBuilder()__		_		for (int i = 0_ i < shipFiles.size()_ i++) {_			File shipFile = shipFiles.get(i)__			LocalResource shipResources = Records.newRecord(LocalResource.class)__			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			paths[2 + i] = Utils.setupLocalResource(fs, appId.toString(),_				shipLocalPath, shipResources, fs.getHomeDirectory())__			localResources.put(shipFile.getName(), shipResources)___			envShipFileList.append(paths[2 + i])__			if(i+1 < shipFiles.size()) {_				envShipFileList.append(',')__			}_		}__		paths[0] = remotePathJar__		paths[1] = remotePathConf__		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		Utils.setTokensFor(amContainer, paths, conf)___		amContainer.setLocalResources(localResources)__		fs.close()___		_		Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		Utils.setupEnv(conf, appMasterEnv)__		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_USERNAME, UserGroupInformation.getCurrentUser().getShortUserName())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))___		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster: " + e.getMessage())__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()__		String trackingURL = report.getTrackingUrl()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,final,string,java,opts,flink,configuration,get,string,config,constants,string,logback,file,configuration,directory,file,separator,boolean,has,logback,new,file,logback,file,exists,string,log4j,file,configuration,directory,file,separator,boolean,has,log4j,new,file,log4j,file,exists,if,has,logback,ship,files,add,new,file,logback,file,if,has,log4j,ship,files,add,new,file,log4j,file,container,launch,context,am,container,records,new,record,container,launch,context,class,string,am,command,bin,java,xmx,utils,calculate,heap,size,job,manager,memory,mb,flink,configuration,m,java,opts,if,has,logback,has,log4j,am,command,dlog,file,application,constants,jobmanager,log,if,has,logback,am,command,dlogback,configuration,file,file,if,has,log4j,am,command,dlog4j,configuration,file,am,command,get,application,master,class,get,name,1,application,constants,jobmanager,out,2,application,constants,jobmanager,err,am,container,set,commands,collections,singleton,list,am,command,log,debug,application,master,start,command,am,command,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,application,submission,context,app,context,yarn,application,get,application,submission,context,if,recovery,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,application,id,app,id,app,context,get,application,id,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,map,string,local,resource,local,resources,new,hash,map,2,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,final,path,paths,new,path,2,ship,files,size,string,builder,env,ship,file,list,new,string,builder,for,int,i,0,i,ship,files,size,i,file,ship,file,ship,files,get,i,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,paths,2,i,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,local,resources,put,ship,file,get,name,ship,resources,env,ship,file,list,append,paths,2,i,if,i,1,ship,files,size,env,ship,file,list,append,paths,0,remote,path,jar,paths,1,remote,path,conf,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,utils,setup,env,conf,app,master,env,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,short,user,name,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,get,message,yarn,application,state,app,state,report,get,yarn,application,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,string,tracking,url,report,get,tracking,url,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1467379351;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()___		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		__		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		addLibFolderToShipFiles(effectiveShipFiles)___		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j)___		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		if (RecoveryMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		final ApplicationId appId = appContext.getApplicationId()___		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			classPathBuilder.append(ApplicationConstants.Environment.PWD.$())__			classPathBuilder.append(File.separator)__			classPathBuilder.append(shipFile.getName())__			if (shipFile.isDirectory()) {_				_				classPathBuilder.append(File.separator).append("*")__			}_			classPathBuilder.append(File.pathSeparator)___			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append(ApplicationConstants.Environment.PWD.$()).append(File.separator)_			.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append(ApplicationConstants.Environment.PWD.$()).append(File.separator)_			.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		Utils.setTokensFor(amContainer, paths, conf)___		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_USERNAME, UserGroupInformation.getCurrentUser().getShortUserName())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))___		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster: " + e.getMessage())__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,add,lib,folder,to,ship,files,effective,ship,files,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,application,submission,context,app,context,yarn,application,get,application,submission,context,if,recovery,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,application,id,app,id,app,context,get,application,id,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,class,path,builder,append,application,constants,environment,pwd,class,path,builder,append,file,separator,class,path,builder,append,ship,file,get,name,if,ship,file,is,directory,class,path,builder,append,file,separator,append,class,path,builder,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,application,constants,environment,pwd,append,file,separator,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,application,constants,environment,pwd,append,file,separator,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,short,user,name,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,get,message,yarn,application,state,app,state,report,get,yarn,application,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1467394749;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()___		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		__		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		addLibFolderToShipFiles(effectiveShipFiles)___		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j)___		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		if (RecoveryMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		final ApplicationId appId = appContext.getApplicationId()___		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			classPathBuilder.append(shipFile.getName())__			if (shipFile.isDirectory()) {_				_				classPathBuilder.append(File.separator).append("*")__			}_			classPathBuilder.append(File.pathSeparator)___			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		Utils.setTokensFor(amContainer, paths, conf)___		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_USERNAME, UserGroupInformation.getCurrentUser().getShortUserName())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))___		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster: " + e.getMessage())__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,add,lib,folder,to,ship,files,effective,ship,files,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,application,submission,context,app,context,yarn,application,get,application,submission,context,if,recovery,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,application,id,app,id,app,context,get,application,id,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,class,path,builder,append,ship,file,get,name,if,ship,file,is,directory,class,path,builder,append,file,separator,append,class,path,builder,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,short,user,name,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,get,message,yarn,application,state,app,state,report,get,yarn,application,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1467396766;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()___		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		__		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		addLibFolderToShipFiles(effectiveShipFiles)___		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j)___		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		if (RecoveryMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		final ApplicationId appId = appContext.getApplicationId()___		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			classPathBuilder.append(shipFile.getName())__			if (shipFile.isDirectory()) {_				_				classPathBuilder.append(File.separator).append("*")__			}_			classPathBuilder.append(File.pathSeparator)___			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		Utils.setTokensFor(amContainer, paths, conf)___		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_USERNAME, UserGroupInformation.getCurrentUser().getShortUserName())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))___		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster: " + e.getMessage())__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,add,lib,folder,to,ship,files,effective,ship,files,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,application,submission,context,app,context,yarn,application,get,application,submission,context,if,recovery,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,application,id,app,id,app,context,get,application,id,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,class,path,builder,append,ship,file,get,name,if,ship,file,is,directory,class,path,builder,append,file,separator,append,class,path,builder,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,short,user,name,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,get,message,yarn,application,state,app,state,report,get,yarn,application,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1468944021;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		addLibFolderToShipFiles(effectiveShipFiles)___		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j)___		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		final ApplicationId appId = appContext.getApplicationId()___		_		String zkNamespace = getZookeeperNamespace()__		_		if (zkNamespace == null || zkNamespace.isEmpty()) {_			_			zkNamespace = flinkConfiguration.getString(ConfigConstants.ZOOKEEPER_NAMESPACE_KEY, String.valueOf(appId))__			setZookeeperNamespace(zkNamespace)__		}__		flinkConfiguration.setString(ConfigConstants.ZOOKEEPER_NAMESPACE_KEY, zkNamespace)___		if (RecoveryMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			classPathBuilder.append(shipFile.getName())__			if (shipFile.isDirectory()) {_				_				classPathBuilder.append(File.separator).append("*")__			}_			classPathBuilder.append(File.pathSeparator)___			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		Utils.setTokensFor(amContainer, paths, conf)___		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_USERNAME, UserGroupInformation.getCurrentUser().getShortUserName())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))__		appMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace())___		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster: " + e.getMessage())__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,add,lib,folder,to,ship,files,effective,ship,files,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,application,submission,context,app,context,yarn,application,get,application,submission,context,final,application,id,app,id,app,context,get,application,id,string,zk,namespace,get,zookeeper,namespace,if,zk,namespace,null,zk,namespace,is,empty,zk,namespace,flink,configuration,get,string,config,constants,string,value,of,app,id,set,zookeeper,namespace,zk,namespace,flink,configuration,set,string,config,constants,zk,namespace,if,recovery,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,class,path,builder,append,ship,file,get,name,if,ship,file,is,directory,class,path,builder,append,file,separator,append,class,path,builder,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,short,user,name,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,app,master,env,put,yarn,config,keys,get,zookeeper,namespace,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,get,message,yarn,application,state,app,state,report,get,yarn,application,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1469630409;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		addLibFolderToShipFiles(effectiveShipFiles)___		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j)___		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		final ApplicationId appId = appContext.getApplicationId()___		_		String zkNamespace = getZookeeperNamespace()__		_		if (zkNamespace == null || zkNamespace.isEmpty()) {_			_			zkNamespace = flinkConfiguration.getString(ConfigConstants.ZOOKEEPER_NAMESPACE_KEY, String.valueOf(appId))__			setZookeeperNamespace(zkNamespace)__		}__		flinkConfiguration.setString(ConfigConstants.ZOOKEEPER_NAMESPACE_KEY, zkNamespace)___		if (RecoveryMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			classPathBuilder.append(shipFile.getName())__			if (shipFile.isDirectory()) {_				_				classPathBuilder.append(File.separator).append("*")__			}_			classPathBuilder.append(File.pathSeparator)___			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		Utils.setTokensFor(amContainer, paths, conf)___		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_USERNAME, UserGroupInformation.getCurrentUser().getShortUserName())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))__		appMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace())___		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster: " + e.getMessage())__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,add,lib,folder,to,ship,files,effective,ship,files,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,application,submission,context,app,context,yarn,application,get,application,submission,context,final,application,id,app,id,app,context,get,application,id,string,zk,namespace,get,zookeeper,namespace,if,zk,namespace,null,zk,namespace,is,empty,zk,namespace,flink,configuration,get,string,config,constants,string,value,of,app,id,set,zookeeper,namespace,zk,namespace,flink,configuration,set,string,config,constants,zk,namespace,if,recovery,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,class,path,builder,append,ship,file,get,name,if,ship,file,is,directory,class,path,builder,append,file,separator,append,class,path,builder,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,short,user,name,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,app,master,env,put,yarn,config,keys,get,zookeeper,namespace,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,get,message,yarn,application,state,app,state,report,get,yarn,application,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1472033364;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		addLibFolderToShipFiles(effectiveShipFiles)___		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j)___		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		final ApplicationId appId = appContext.getApplicationId()___		_		String zkNamespace = getZookeeperNamespace()__		_		if (zkNamespace == null || zkNamespace.isEmpty()) {_			_			zkNamespace = flinkConfiguration.getString(ConfigConstants.HA_ZOOKEEPER_NAMESPACE_KEY, String.valueOf(appId))__			setZookeeperNamespace(zkNamespace)__		}__		flinkConfiguration.setString(ConfigConstants.HA_ZOOKEEPER_NAMESPACE_KEY, zkNamespace)___		if (HighAvailabilityMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			classPathBuilder.append(shipFile.getName())__			if (shipFile.isDirectory()) {_				_				classPathBuilder.append(File.separator).append("*")__			}_			classPathBuilder.append(File.pathSeparator)___			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		Utils.setTokensFor(amContainer, paths, conf)___		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_USERNAME, UserGroupInformation.getCurrentUser().getShortUserName())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))__		appMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace())___		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster: " + e.getMessage())__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,add,lib,folder,to,ship,files,effective,ship,files,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,application,submission,context,app,context,yarn,application,get,application,submission,context,final,application,id,app,id,app,context,get,application,id,string,zk,namespace,get,zookeeper,namespace,if,zk,namespace,null,zk,namespace,is,empty,zk,namespace,flink,configuration,get,string,config,constants,string,value,of,app,id,set,zookeeper,namespace,zk,namespace,flink,configuration,set,string,config,constants,zk,namespace,if,high,availability,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,class,path,builder,append,ship,file,get,name,if,ship,file,is,directory,class,path,builder,append,file,separator,append,class,path,builder,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,short,user,name,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,app,master,env,put,yarn,config,keys,get,zookeeper,namespace,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,get,message,yarn,application,state,app,state,report,get,yarn,application,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1474401809;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		_		File jaasConfigFile = new File(configurationDirectory + File.separator + SecurityContext.JAAS_CONF_FILENAME)__		if (jaasConfigFile.exists() && jaasConfigFile.isFile()) {_			effectiveShipFiles.add(jaasConfigFile)__		}__		addLibFolderToShipFiles(effectiveShipFiles)___		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		final ApplicationId appId = appContext.getApplicationId()___		_		String zkNamespace = getZookeeperNamespace()__		_		if (zkNamespace == null || zkNamespace.isEmpty()) {_			_			zkNamespace = flinkConfiguration.getString(ConfigConstants.HA_ZOOKEEPER_NAMESPACE_KEY, String.valueOf(appId))__			setZookeeperNamespace(zkNamespace)__		}__		flinkConfiguration.setString(ConfigConstants.HA_ZOOKEEPER_NAMESPACE_KEY, zkNamespace)___		if (HighAvailabilityMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			classPathBuilder.append(shipFile.getName())__			if (shipFile.isDirectory()) {_				_				classPathBuilder.append(File.separator).append("*")__			}_			classPathBuilder.append(File.pathSeparator)___			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		_		_		_		Path remoteKrb5Path = null__		Path remoteYarnSiteXmlPath = null__		boolean hasKrb5 = false__		if(System.getenv("IN_TESTS") != null) {_			String krb5Config = System.getProperty("java.security.krb5.conf")__			if(krb5Config != null && krb5Config.length() != 0) {_				File krb5 = new File(krb5Config)__				LOG.info("Adding KRB5 configuration {} to the AM container local resource bucket", krb5.getAbsolutePath())__				LocalResource krb5ConfResource = Records.newRecord(LocalResource.class)__				Path krb5ConfPath = new Path(krb5.getAbsolutePath())__				remoteKrb5Path = Utils.setupLocalResource(fs, appId.toString(), krb5ConfPath, krb5ConfResource, fs.getHomeDirectory())__				localResources.put(Utils.KRB5_FILE_NAME, krb5ConfResource)___				File f = new File(System.getenv("YARN_CONF_DIR"),Utils.YARN_SITE_FILE_NAME)__				LOG.info("Adding Yarn configuration {} to the AM container local resource bucket", f.getAbsolutePath())__				LocalResource yarnConfResource = Records.newRecord(LocalResource.class)__				Path yarnSitePath = new Path(f.getAbsolutePath())__				remoteYarnSiteXmlPath = Utils.setupLocalResource(fs, appId.toString(), yarnSitePath, yarnConfResource, fs.getHomeDirectory())__				localResources.put(Utils.YARN_SITE_FILE_NAME, yarnConfResource)___				hasKrb5 = true__			}_		}__		_		LocalResource keytabResource = null__		Path remotePathKeytab = null__		String keytab = flinkConfiguration.getString(ConfigConstants.SECURITY_KEYTAB_KEY, null)__		if(keytab != null) {_			LOG.info("Adding keytab {} to the AM container local resource bucket", keytab)__			keytabResource = Records.newRecord(LocalResource.class)__			Path keytabPath = new Path(keytab)__			remotePathKeytab = Utils.setupLocalResource(fs, appId.toString(), keytabPath, keytabResource, fs.getHomeDirectory())__			localResources.put(Utils.KEYTAB_FILE_NAME, keytabResource)__		}__		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j, hasKrb5)___		if ( UserGroupInformation.isSecurityEnabled() && keytab == null ) {_			_			LOG.info("Adding delegation token to the AM container..")__			Utils.setTokensFor(amContainer, paths, conf)__		}__		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))__		appMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace())___		_		appMasterEnv.put(YarnConfigKeys.ENV_HADOOP_USER_NAME, UserGroupInformation.getCurrentUser().getUserName())___		if(keytabResource != null) {_			appMasterEnv.put(YarnConfigKeys.KEYTAB_PATH, remotePathKeytab.toString() )__			String principal = flinkConfiguration.getString(ConfigConstants.SECURITY_PRINCIPAL_KEY, null)__			appMasterEnv.put(YarnConfigKeys.KEYTAB_PRINCIPAL, principal )__		}__		_		if(remoteYarnSiteXmlPath != null && remoteKrb5Path != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_YARN_SITE_XML_PATH, remoteYarnSiteXmlPath.toString())__			appMasterEnv.put(YarnConfigKeys.ENV_KRB5_PATH, remoteKrb5Path.toString() )__		}__		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster: " + e.getMessage())__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			LOG.debug("Application State: {}", appState)__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,file,jaas,config,file,new,file,configuration,directory,file,separator,security,context,if,jaas,config,file,exists,jaas,config,file,is,file,effective,ship,files,add,jaas,config,file,add,lib,folder,to,ship,files,effective,ship,files,application,submission,context,app,context,yarn,application,get,application,submission,context,final,application,id,app,id,app,context,get,application,id,string,zk,namespace,get,zookeeper,namespace,if,zk,namespace,null,zk,namespace,is,empty,zk,namespace,flink,configuration,get,string,config,constants,string,value,of,app,id,set,zookeeper,namespace,zk,namespace,flink,configuration,set,string,config,constants,zk,namespace,if,high,availability,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,class,path,builder,append,ship,file,get,name,if,ship,file,is,directory,class,path,builder,append,file,separator,append,class,path,builder,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,path,remote,krb5path,null,path,remote,yarn,site,xml,path,null,boolean,has,krb5,false,if,system,getenv,null,string,krb5config,system,get,property,java,security,krb5,conf,if,krb5config,null,krb5config,length,0,file,krb5,new,file,krb5config,log,info,adding,krb5,configuration,to,the,am,container,local,resource,bucket,krb5,get,absolute,path,local,resource,krb5conf,resource,records,new,record,local,resource,class,path,krb5conf,path,new,path,krb5,get,absolute,path,remote,krb5path,utils,setup,local,resource,fs,app,id,to,string,krb5conf,path,krb5conf,resource,fs,get,home,directory,local,resources,put,utils,krb5conf,resource,file,f,new,file,system,getenv,utils,log,info,adding,yarn,configuration,to,the,am,container,local,resource,bucket,f,get,absolute,path,local,resource,yarn,conf,resource,records,new,record,local,resource,class,path,yarn,site,path,new,path,f,get,absolute,path,remote,yarn,site,xml,path,utils,setup,local,resource,fs,app,id,to,string,yarn,site,path,yarn,conf,resource,fs,get,home,directory,local,resources,put,utils,yarn,conf,resource,has,krb5,true,local,resource,keytab,resource,null,path,remote,path,keytab,null,string,keytab,flink,configuration,get,string,config,constants,null,if,keytab,null,log,info,adding,keytab,to,the,am,container,local,resource,bucket,keytab,keytab,resource,records,new,record,local,resource,class,path,keytab,path,new,path,keytab,remote,path,keytab,utils,setup,local,resource,fs,app,id,to,string,keytab,path,keytab,resource,fs,get,home,directory,local,resources,put,utils,keytab,resource,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,has,krb5,if,user,group,information,is,security,enabled,keytab,null,log,info,adding,delegation,token,to,the,am,container,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,app,master,env,put,yarn,config,keys,get,zookeeper,namespace,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,user,name,if,keytab,resource,null,app,master,env,put,yarn,config,keys,remote,path,keytab,to,string,string,principal,flink,configuration,get,string,config,constants,null,app,master,env,put,yarn,config,keys,principal,if,remote,yarn,site,xml,path,null,remote,krb5path,null,app,master,env,put,yarn,config,keys,remote,yarn,site,xml,path,to,string,app,master,env,put,yarn,config,keys,remote,krb5path,to,string,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,get,message,yarn,application,state,app,state,report,get,yarn,application,state,log,debug,application,state,app,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1476095826;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		_		File jaasConfigFile = new File(configurationDirectory + File.separator + SecurityContext.JAAS_CONF_FILENAME)__		if (jaasConfigFile.exists() && jaasConfigFile.isFile()) {_			effectiveShipFiles.add(jaasConfigFile)__		}__		addLibFolderToShipFiles(effectiveShipFiles)___		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		final ApplicationId appId = appContext.getApplicationId()___		_		String zkNamespace = getZookeeperNamespace()__		_		if (zkNamespace == null || zkNamespace.isEmpty()) {_			_			zkNamespace = flinkConfiguration.getString(HighAvailabilityOptions.HA_CLUSTER_ID, String.valueOf(appId))__			setZookeeperNamespace(zkNamespace)__		}__		flinkConfiguration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, zkNamespace)___		if (HighAvailabilityMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			classPathBuilder.append(shipFile.getName())__			if (shipFile.isDirectory()) {_				_				classPathBuilder.append(File.separator).append("*")__			}_			classPathBuilder.append(File.pathSeparator)___			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		_		_		_		Path remoteKrb5Path = null__		Path remoteYarnSiteXmlPath = null__		boolean hasKrb5 = false__		if(System.getenv("IN_TESTS") != null) {_			String krb5Config = System.getProperty("java.security.krb5.conf")__			if(krb5Config != null && krb5Config.length() != 0) {_				File krb5 = new File(krb5Config)__				LOG.info("Adding KRB5 configuration {} to the AM container local resource bucket", krb5.getAbsolutePath())__				LocalResource krb5ConfResource = Records.newRecord(LocalResource.class)__				Path krb5ConfPath = new Path(krb5.getAbsolutePath())__				remoteKrb5Path = Utils.setupLocalResource(fs, appId.toString(), krb5ConfPath, krb5ConfResource, fs.getHomeDirectory())__				localResources.put(Utils.KRB5_FILE_NAME, krb5ConfResource)___				File f = new File(System.getenv("YARN_CONF_DIR"),Utils.YARN_SITE_FILE_NAME)__				LOG.info("Adding Yarn configuration {} to the AM container local resource bucket", f.getAbsolutePath())__				LocalResource yarnConfResource = Records.newRecord(LocalResource.class)__				Path yarnSitePath = new Path(f.getAbsolutePath())__				remoteYarnSiteXmlPath = Utils.setupLocalResource(fs, appId.toString(), yarnSitePath, yarnConfResource, fs.getHomeDirectory())__				localResources.put(Utils.YARN_SITE_FILE_NAME, yarnConfResource)___				hasKrb5 = true__			}_		}__		_		LocalResource keytabResource = null__		Path remotePathKeytab = null__		String keytab = flinkConfiguration.getString(ConfigConstants.SECURITY_KEYTAB_KEY, null)__		if(keytab != null) {_			LOG.info("Adding keytab {} to the AM container local resource bucket", keytab)__			keytabResource = Records.newRecord(LocalResource.class)__			Path keytabPath = new Path(keytab)__			remotePathKeytab = Utils.setupLocalResource(fs, appId.toString(), keytabPath, keytabResource, fs.getHomeDirectory())__			localResources.put(Utils.KEYTAB_FILE_NAME, keytabResource)__		}__		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j, hasKrb5)___		if ( UserGroupInformation.isSecurityEnabled() && keytab == null ) {_			_			LOG.info("Adding delegation token to the AM container..")__			Utils.setTokensFor(amContainer, paths, conf)__		}__		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))__		appMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace())___		_		appMasterEnv.put(YarnConfigKeys.ENV_HADOOP_USER_NAME, UserGroupInformation.getCurrentUser().getUserName())___		if(keytabResource != null) {_			appMasterEnv.put(YarnConfigKeys.KEYTAB_PATH, remotePathKeytab.toString() )__			String principal = flinkConfiguration.getString(ConfigConstants.SECURITY_PRINCIPAL_KEY, null)__			appMasterEnv.put(YarnConfigKeys.KEYTAB_PRINCIPAL, principal )__		}__		_		if(remoteYarnSiteXmlPath != null && remoteKrb5Path != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_YARN_SITE_XML_PATH, remoteYarnSiteXmlPath.toString())__			appMasterEnv.put(YarnConfigKeys.ENV_KRB5_PATH, remoteKrb5Path.toString() )__		}__		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster: " + e.getMessage())__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			LOG.debug("Application State: {}", appState)__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,file,jaas,config,file,new,file,configuration,directory,file,separator,security,context,if,jaas,config,file,exists,jaas,config,file,is,file,effective,ship,files,add,jaas,config,file,add,lib,folder,to,ship,files,effective,ship,files,application,submission,context,app,context,yarn,application,get,application,submission,context,final,application,id,app,id,app,context,get,application,id,string,zk,namespace,get,zookeeper,namespace,if,zk,namespace,null,zk,namespace,is,empty,zk,namespace,flink,configuration,get,string,high,availability,options,string,value,of,app,id,set,zookeeper,namespace,zk,namespace,flink,configuration,set,string,high,availability,options,zk,namespace,if,high,availability,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,class,path,builder,append,ship,file,get,name,if,ship,file,is,directory,class,path,builder,append,file,separator,append,class,path,builder,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,path,remote,krb5path,null,path,remote,yarn,site,xml,path,null,boolean,has,krb5,false,if,system,getenv,null,string,krb5config,system,get,property,java,security,krb5,conf,if,krb5config,null,krb5config,length,0,file,krb5,new,file,krb5config,log,info,adding,krb5,configuration,to,the,am,container,local,resource,bucket,krb5,get,absolute,path,local,resource,krb5conf,resource,records,new,record,local,resource,class,path,krb5conf,path,new,path,krb5,get,absolute,path,remote,krb5path,utils,setup,local,resource,fs,app,id,to,string,krb5conf,path,krb5conf,resource,fs,get,home,directory,local,resources,put,utils,krb5conf,resource,file,f,new,file,system,getenv,utils,log,info,adding,yarn,configuration,to,the,am,container,local,resource,bucket,f,get,absolute,path,local,resource,yarn,conf,resource,records,new,record,local,resource,class,path,yarn,site,path,new,path,f,get,absolute,path,remote,yarn,site,xml,path,utils,setup,local,resource,fs,app,id,to,string,yarn,site,path,yarn,conf,resource,fs,get,home,directory,local,resources,put,utils,yarn,conf,resource,has,krb5,true,local,resource,keytab,resource,null,path,remote,path,keytab,null,string,keytab,flink,configuration,get,string,config,constants,null,if,keytab,null,log,info,adding,keytab,to,the,am,container,local,resource,bucket,keytab,keytab,resource,records,new,record,local,resource,class,path,keytab,path,new,path,keytab,remote,path,keytab,utils,setup,local,resource,fs,app,id,to,string,keytab,path,keytab,resource,fs,get,home,directory,local,resources,put,utils,keytab,resource,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,has,krb5,if,user,group,information,is,security,enabled,keytab,null,log,info,adding,delegation,token,to,the,am,container,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,app,master,env,put,yarn,config,keys,get,zookeeper,namespace,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,user,name,if,keytab,resource,null,app,master,env,put,yarn,config,keys,remote,path,keytab,to,string,string,principal,flink,configuration,get,string,config,constants,null,app,master,env,put,yarn,config,keys,principal,if,remote,yarn,site,xml,path,null,remote,krb5path,null,app,master,env,put,yarn,config,keys,remote,yarn,site,xml,path,to,string,app,master,env,put,yarn,config,keys,remote,krb5path,to,string,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,get,message,yarn,application,state,app,state,report,get,yarn,application,state,log,debug,application,state,app,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1477570902;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		_		File jaasConfigFile = new File(configurationDirectory + File.separator + SecurityContext.JAAS_CONF_FILENAME)__		if (jaasConfigFile.exists() && jaasConfigFile.isFile()) {_			effectiveShipFiles.add(jaasConfigFile)__		}__		addLibFolderToShipFiles(effectiveShipFiles)___		_		if (userJarFiles != null) {_			effectiveShipFiles.addAll(userJarFiles)__		}__		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		final ApplicationId appId = appContext.getApplicationId()___		_		String zkNamespace = getZookeeperNamespace()__		_		if (zkNamespace == null || zkNamespace.isEmpty()) {_			_			zkNamespace = flinkConfiguration.getString(HighAvailabilityOptions.HA_CLUSTER_ID, String.valueOf(appId))__			setZookeeperNamespace(zkNamespace)__		}__		flinkConfiguration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, zkNamespace)___		if (HighAvailabilityMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			classPathBuilder.append(shipFile.getName())__			if (shipFile.isDirectory()) {_				_				classPathBuilder.append(File.separator).append("*")__			}_			classPathBuilder.append(File.pathSeparator)___			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		_		_		_		Path remoteKrb5Path = null__		Path remoteYarnSiteXmlPath = null__		boolean hasKrb5 = false__		if(System.getenv("IN_TESTS") != null) {_			String krb5Config = System.getProperty("java.security.krb5.conf")__			if(krb5Config != null && krb5Config.length() != 0) {_				File krb5 = new File(krb5Config)__				LOG.info("Adding KRB5 configuration {} to the AM container local resource bucket", krb5.getAbsolutePath())__				LocalResource krb5ConfResource = Records.newRecord(LocalResource.class)__				Path krb5ConfPath = new Path(krb5.getAbsolutePath())__				remoteKrb5Path = Utils.setupLocalResource(fs, appId.toString(), krb5ConfPath, krb5ConfResource, fs.getHomeDirectory())__				localResources.put(Utils.KRB5_FILE_NAME, krb5ConfResource)___				File f = new File(System.getenv("YARN_CONF_DIR"),Utils.YARN_SITE_FILE_NAME)__				LOG.info("Adding Yarn configuration {} to the AM container local resource bucket", f.getAbsolutePath())__				LocalResource yarnConfResource = Records.newRecord(LocalResource.class)__				Path yarnSitePath = new Path(f.getAbsolutePath())__				remoteYarnSiteXmlPath = Utils.setupLocalResource(fs, appId.toString(), yarnSitePath, yarnConfResource, fs.getHomeDirectory())__				localResources.put(Utils.YARN_SITE_FILE_NAME, yarnConfResource)___				hasKrb5 = true__			}_		}__		_		LocalResource keytabResource = null__		Path remotePathKeytab = null__		String keytab = flinkConfiguration.getString(ConfigConstants.SECURITY_KEYTAB_KEY, null)__		if(keytab != null) {_			LOG.info("Adding keytab {} to the AM container local resource bucket", keytab)__			keytabResource = Records.newRecord(LocalResource.class)__			Path keytabPath = new Path(keytab)__			remotePathKeytab = Utils.setupLocalResource(fs, appId.toString(), keytabPath, keytabResource, fs.getHomeDirectory())__			localResources.put(Utils.KEYTAB_FILE_NAME, keytabResource)__		}__		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j, hasKrb5)___		if ( UserGroupInformation.isSecurityEnabled() && keytab == null ) {_			_			LOG.info("Adding delegation token to the AM container..")__			Utils.setTokensFor(amContainer, paths, conf)__		}__		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))__		appMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace())___		_		appMasterEnv.put(YarnConfigKeys.ENV_HADOOP_USER_NAME, UserGroupInformation.getCurrentUser().getUserName())___		if(keytabResource != null) {_			appMasterEnv.put(YarnConfigKeys.KEYTAB_PATH, remotePathKeytab.toString() )__			String principal = flinkConfiguration.getString(ConfigConstants.SECURITY_PRINCIPAL_KEY, null)__			appMasterEnv.put(YarnConfigKeys.KEYTAB_PRINCIPAL, principal )__		}__		_		if(remoteYarnSiteXmlPath != null && remoteKrb5Path != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_YARN_SITE_XML_PATH, remoteYarnSiteXmlPath.toString())__			appMasterEnv.put(YarnConfigKeys.ENV_KRB5_PATH, remoteKrb5Path.toString() )__		}__		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster.", e)__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			LOG.debug("Application State: {}", appState)__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,file,jaas,config,file,new,file,configuration,directory,file,separator,security,context,if,jaas,config,file,exists,jaas,config,file,is,file,effective,ship,files,add,jaas,config,file,add,lib,folder,to,ship,files,effective,ship,files,if,user,jar,files,null,effective,ship,files,add,all,user,jar,files,application,submission,context,app,context,yarn,application,get,application,submission,context,final,application,id,app,id,app,context,get,application,id,string,zk,namespace,get,zookeeper,namespace,if,zk,namespace,null,zk,namespace,is,empty,zk,namespace,flink,configuration,get,string,high,availability,options,string,value,of,app,id,set,zookeeper,namespace,zk,namespace,flink,configuration,set,string,high,availability,options,zk,namespace,if,high,availability,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,class,path,builder,append,ship,file,get,name,if,ship,file,is,directory,class,path,builder,append,file,separator,append,class,path,builder,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,path,remote,krb5path,null,path,remote,yarn,site,xml,path,null,boolean,has,krb5,false,if,system,getenv,null,string,krb5config,system,get,property,java,security,krb5,conf,if,krb5config,null,krb5config,length,0,file,krb5,new,file,krb5config,log,info,adding,krb5,configuration,to,the,am,container,local,resource,bucket,krb5,get,absolute,path,local,resource,krb5conf,resource,records,new,record,local,resource,class,path,krb5conf,path,new,path,krb5,get,absolute,path,remote,krb5path,utils,setup,local,resource,fs,app,id,to,string,krb5conf,path,krb5conf,resource,fs,get,home,directory,local,resources,put,utils,krb5conf,resource,file,f,new,file,system,getenv,utils,log,info,adding,yarn,configuration,to,the,am,container,local,resource,bucket,f,get,absolute,path,local,resource,yarn,conf,resource,records,new,record,local,resource,class,path,yarn,site,path,new,path,f,get,absolute,path,remote,yarn,site,xml,path,utils,setup,local,resource,fs,app,id,to,string,yarn,site,path,yarn,conf,resource,fs,get,home,directory,local,resources,put,utils,yarn,conf,resource,has,krb5,true,local,resource,keytab,resource,null,path,remote,path,keytab,null,string,keytab,flink,configuration,get,string,config,constants,null,if,keytab,null,log,info,adding,keytab,to,the,am,container,local,resource,bucket,keytab,keytab,resource,records,new,record,local,resource,class,path,keytab,path,new,path,keytab,remote,path,keytab,utils,setup,local,resource,fs,app,id,to,string,keytab,path,keytab,resource,fs,get,home,directory,local,resources,put,utils,keytab,resource,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,has,krb5,if,user,group,information,is,security,enabled,keytab,null,log,info,adding,delegation,token,to,the,am,container,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,app,master,env,put,yarn,config,keys,get,zookeeper,namespace,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,user,name,if,keytab,resource,null,app,master,env,put,yarn,config,keys,remote,path,keytab,to,string,string,principal,flink,configuration,get,string,config,constants,null,app,master,env,put,yarn,config,keys,principal,if,remote,yarn,site,xml,path,null,remote,krb5path,null,app,master,env,put,yarn,config,keys,remote,yarn,site,xml,path,to,string,app,master,env,put,yarn,config,keys,remote,krb5path,to,string,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,yarn,application,state,app,state,report,get,yarn,application,state,log,debug,application,state,app,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1478286457;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		_		File jaasConfigFile = new File(configurationDirectory + File.separator + SecurityContext.JAAS_CONF_FILENAME)__		if (jaasConfigFile.exists() && jaasConfigFile.isFile()) {_			effectiveShipFiles.add(jaasConfigFile)__		}__		addLibFolderToShipFiles(effectiveShipFiles)___		_		if (userJarFiles != null) {_			effectiveShipFiles.addAll(userJarFiles)__		}__		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		final ApplicationId appId = appContext.getApplicationId()___		_		String zkNamespace = getZookeeperNamespace()__		_		if (zkNamespace == null || zkNamespace.isEmpty()) {_			_			zkNamespace = flinkConfiguration.getString(HighAvailabilityOptions.HA_CLUSTER_ID, String.valueOf(appId))__			setZookeeperNamespace(zkNamespace)__		}__		flinkConfiguration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, zkNamespace)___		if (HighAvailabilityMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			classPathBuilder.append(shipFile.getName())__			if (shipFile.isDirectory()) {_				_				classPathBuilder.append(File.separator).append("*")__			}_			classPathBuilder.append(File.pathSeparator)___			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		_		_		_		Path remoteKrb5Path = null__		Path remoteYarnSiteXmlPath = null__		boolean hasKrb5 = false__		if(System.getenv("IN_TESTS") != null) {_			String krb5Config = System.getProperty("java.security.krb5.conf")__			if(krb5Config != null && krb5Config.length() != 0) {_				File krb5 = new File(krb5Config)__				LOG.info("Adding KRB5 configuration {} to the AM container local resource bucket", krb5.getAbsolutePath())__				LocalResource krb5ConfResource = Records.newRecord(LocalResource.class)__				Path krb5ConfPath = new Path(krb5.getAbsolutePath())__				remoteKrb5Path = Utils.setupLocalResource(fs, appId.toString(), krb5ConfPath, krb5ConfResource, fs.getHomeDirectory())__				localResources.put(Utils.KRB5_FILE_NAME, krb5ConfResource)___				File f = new File(System.getenv("YARN_CONF_DIR"),Utils.YARN_SITE_FILE_NAME)__				LOG.info("Adding Yarn configuration {} to the AM container local resource bucket", f.getAbsolutePath())__				LocalResource yarnConfResource = Records.newRecord(LocalResource.class)__				Path yarnSitePath = new Path(f.getAbsolutePath())__				remoteYarnSiteXmlPath = Utils.setupLocalResource(fs, appId.toString(), yarnSitePath, yarnConfResource, fs.getHomeDirectory())__				localResources.put(Utils.YARN_SITE_FILE_NAME, yarnConfResource)___				hasKrb5 = true__			}_		}__		_		LocalResource keytabResource = null__		Path remotePathKeytab = null__		String keytab = flinkConfiguration.getString(ConfigConstants.SECURITY_KEYTAB_KEY, null)__		if(keytab != null) {_			LOG.info("Adding keytab {} to the AM container local resource bucket", keytab)__			keytabResource = Records.newRecord(LocalResource.class)__			Path keytabPath = new Path(keytab)__			remotePathKeytab = Utils.setupLocalResource(fs, appId.toString(), keytabPath, keytabResource, fs.getHomeDirectory())__			localResources.put(Utils.KEYTAB_FILE_NAME, keytabResource)__		}__		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j, hasKrb5)___		if ( UserGroupInformation.isSecurityEnabled() && keytab == null ) {_			_			LOG.info("Adding delegation token to the AM container..")__			Utils.setTokensFor(amContainer, paths, conf)__		}__		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))__		appMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace())___		_		appMasterEnv.put(YarnConfigKeys.ENV_HADOOP_USER_NAME, UserGroupInformation.getCurrentUser().getUserName())___		if(keytabResource != null) {_			appMasterEnv.put(YarnConfigKeys.KEYTAB_PATH, remotePathKeytab.toString() )__			String principal = flinkConfiguration.getString(ConfigConstants.SECURITY_PRINCIPAL_KEY, null)__			appMasterEnv.put(YarnConfigKeys.KEYTAB_PRINCIPAL, principal )__		}__		_		if(remoteYarnSiteXmlPath != null && remoteKrb5Path != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_YARN_SITE_XML_PATH, remoteYarnSiteXmlPath.toString())__			appMasterEnv.put(YarnConfigKeys.ENV_KRB5_PATH, remoteKrb5Path.toString() )__		}__		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster.", e)__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			LOG.debug("Application State: {}", appState)__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,file,jaas,config,file,new,file,configuration,directory,file,separator,security,context,if,jaas,config,file,exists,jaas,config,file,is,file,effective,ship,files,add,jaas,config,file,add,lib,folder,to,ship,files,effective,ship,files,if,user,jar,files,null,effective,ship,files,add,all,user,jar,files,application,submission,context,app,context,yarn,application,get,application,submission,context,final,application,id,app,id,app,context,get,application,id,string,zk,namespace,get,zookeeper,namespace,if,zk,namespace,null,zk,namespace,is,empty,zk,namespace,flink,configuration,get,string,high,availability,options,string,value,of,app,id,set,zookeeper,namespace,zk,namespace,flink,configuration,set,string,high,availability,options,zk,namespace,if,high,availability,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,class,path,builder,append,ship,file,get,name,if,ship,file,is,directory,class,path,builder,append,file,separator,append,class,path,builder,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,path,remote,krb5path,null,path,remote,yarn,site,xml,path,null,boolean,has,krb5,false,if,system,getenv,null,string,krb5config,system,get,property,java,security,krb5,conf,if,krb5config,null,krb5config,length,0,file,krb5,new,file,krb5config,log,info,adding,krb5,configuration,to,the,am,container,local,resource,bucket,krb5,get,absolute,path,local,resource,krb5conf,resource,records,new,record,local,resource,class,path,krb5conf,path,new,path,krb5,get,absolute,path,remote,krb5path,utils,setup,local,resource,fs,app,id,to,string,krb5conf,path,krb5conf,resource,fs,get,home,directory,local,resources,put,utils,krb5conf,resource,file,f,new,file,system,getenv,utils,log,info,adding,yarn,configuration,to,the,am,container,local,resource,bucket,f,get,absolute,path,local,resource,yarn,conf,resource,records,new,record,local,resource,class,path,yarn,site,path,new,path,f,get,absolute,path,remote,yarn,site,xml,path,utils,setup,local,resource,fs,app,id,to,string,yarn,site,path,yarn,conf,resource,fs,get,home,directory,local,resources,put,utils,yarn,conf,resource,has,krb5,true,local,resource,keytab,resource,null,path,remote,path,keytab,null,string,keytab,flink,configuration,get,string,config,constants,null,if,keytab,null,log,info,adding,keytab,to,the,am,container,local,resource,bucket,keytab,keytab,resource,records,new,record,local,resource,class,path,keytab,path,new,path,keytab,remote,path,keytab,utils,setup,local,resource,fs,app,id,to,string,keytab,path,keytab,resource,fs,get,home,directory,local,resources,put,utils,keytab,resource,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,has,krb5,if,user,group,information,is,security,enabled,keytab,null,log,info,adding,delegation,token,to,the,am,container,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,app,master,env,put,yarn,config,keys,get,zookeeper,namespace,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,user,name,if,keytab,resource,null,app,master,env,put,yarn,config,keys,remote,path,keytab,to,string,string,principal,flink,configuration,get,string,config,constants,null,app,master,env,put,yarn,config,keys,principal,if,remote,yarn,site,xml,path,null,remote,krb5path,null,app,master,env,put,yarn,config,keys,remote,yarn,site,xml,path,to,string,app,master,env,put,yarn,config,keys,remote,krb5path,to,string,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,yarn,application,state,app,state,report,get,yarn,application,state,log,debug,application,state,app,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1478790006;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		_		File jaasConfigFile = new File(configurationDirectory + File.separator + SecurityContext.JAAS_CONF_FILENAME)__		if (jaasConfigFile.exists() && jaasConfigFile.isFile()) {_			effectiveShipFiles.add(jaasConfigFile)__		}__		addLibFolderToShipFiles(effectiveShipFiles)___		_		if (userJarFiles != null) {_			effectiveShipFiles.addAll(userJarFiles)__		}__		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		final ApplicationId appId = appContext.getApplicationId()___		_		String zkNamespace = getZookeeperNamespace()__		_		if (zkNamespace == null || zkNamespace.isEmpty()) {_			_			zkNamespace = flinkConfiguration.getString(HighAvailabilityOptions.HA_CLUSTER_ID, String.valueOf(appId))__			setZookeeperNamespace(zkNamespace)__		}__		flinkConfiguration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, zkNamespace)___		if (HighAvailabilityMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult preVisitDirectory(java.nio.file.Path dir, BasicFileAttributes attrs)_							throws IOException {_						super.preVisitDirectory(dir, attrs)___						java.nio.file.Path relativePath = parentPath.relativize(dir)___						classPathBuilder_							.append(relativePath)_							.append(File.separator)_							.append("*")_							.append(File.pathSeparator)___						return FileVisitResult.CONTINUE__					}_				})__			} else {_				_				classPathBuilder.append(shipFile.getName()).append(File.pathSeparator)__			}__			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		_		_		_		Path remoteKrb5Path = null__		Path remoteYarnSiteXmlPath = null__		boolean hasKrb5 = false__		if(System.getenv("IN_TESTS") != null) {_			String krb5Config = System.getProperty("java.security.krb5.conf")__			if(krb5Config != null && krb5Config.length() != 0) {_				File krb5 = new File(krb5Config)__				LOG.info("Adding KRB5 configuration {} to the AM container local resource bucket", krb5.getAbsolutePath())__				LocalResource krb5ConfResource = Records.newRecord(LocalResource.class)__				Path krb5ConfPath = new Path(krb5.getAbsolutePath())__				remoteKrb5Path = Utils.setupLocalResource(fs, appId.toString(), krb5ConfPath, krb5ConfResource, fs.getHomeDirectory())__				localResources.put(Utils.KRB5_FILE_NAME, krb5ConfResource)___				File f = new File(System.getenv("YARN_CONF_DIR"),Utils.YARN_SITE_FILE_NAME)__				LOG.info("Adding Yarn configuration {} to the AM container local resource bucket", f.getAbsolutePath())__				LocalResource yarnConfResource = Records.newRecord(LocalResource.class)__				Path yarnSitePath = new Path(f.getAbsolutePath())__				remoteYarnSiteXmlPath = Utils.setupLocalResource(fs, appId.toString(), yarnSitePath, yarnConfResource, fs.getHomeDirectory())__				localResources.put(Utils.YARN_SITE_FILE_NAME, yarnConfResource)___				hasKrb5 = true__			}_		}__		_		LocalResource keytabResource = null__		Path remotePathKeytab = null__		String keytab = flinkConfiguration.getString(ConfigConstants.SECURITY_KEYTAB_KEY, null)__		if(keytab != null) {_			LOG.info("Adding keytab {} to the AM container local resource bucket", keytab)__			keytabResource = Records.newRecord(LocalResource.class)__			Path keytabPath = new Path(keytab)__			remotePathKeytab = Utils.setupLocalResource(fs, appId.toString(), keytabPath, keytabResource, fs.getHomeDirectory())__			localResources.put(Utils.KEYTAB_FILE_NAME, keytabResource)__		}__		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j, hasKrb5)___		if ( UserGroupInformation.isSecurityEnabled() && keytab == null ) {_			_			LOG.info("Adding delegation token to the AM container..")__			Utils.setTokensFor(amContainer, paths, conf)__		}__		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))__		appMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace())___		_		appMasterEnv.put(YarnConfigKeys.ENV_HADOOP_USER_NAME, UserGroupInformation.getCurrentUser().getUserName())___		if(keytabResource != null) {_			appMasterEnv.put(YarnConfigKeys.KEYTAB_PATH, remotePathKeytab.toString() )__			String principal = flinkConfiguration.getString(ConfigConstants.SECURITY_PRINCIPAL_KEY, null)__			appMasterEnv.put(YarnConfigKeys.KEYTAB_PRINCIPAL, principal )__		}__		_		if(remoteYarnSiteXmlPath != null && remoteKrb5Path != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_YARN_SITE_XML_PATH, remoteYarnSiteXmlPath.toString())__			appMasterEnv.put(YarnConfigKeys.ENV_KRB5_PATH, remoteKrb5Path.toString() )__		}__		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster.", e)__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			LOG.debug("Application State: {}", appState)__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,file,jaas,config,file,new,file,configuration,directory,file,separator,security,context,if,jaas,config,file,exists,jaas,config,file,is,file,effective,ship,files,add,jaas,config,file,add,lib,folder,to,ship,files,effective,ship,files,if,user,jar,files,null,effective,ship,files,add,all,user,jar,files,application,submission,context,app,context,yarn,application,get,application,submission,context,final,application,id,app,id,app,context,get,application,id,string,zk,namespace,get,zookeeper,namespace,if,zk,namespace,null,zk,namespace,is,empty,zk,namespace,flink,configuration,get,string,high,availability,options,string,value,of,app,id,set,zookeeper,namespace,zk,namespace,flink,configuration,set,string,high,availability,options,zk,namespace,if,high,availability,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,pre,visit,directory,java,nio,file,path,dir,basic,file,attributes,attrs,throws,ioexception,super,pre,visit,directory,dir,attrs,java,nio,file,path,relative,path,parent,path,relativize,dir,class,path,builder,append,relative,path,append,file,separator,append,append,file,path,separator,return,file,visit,result,continue,else,class,path,builder,append,ship,file,get,name,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,path,remote,krb5path,null,path,remote,yarn,site,xml,path,null,boolean,has,krb5,false,if,system,getenv,null,string,krb5config,system,get,property,java,security,krb5,conf,if,krb5config,null,krb5config,length,0,file,krb5,new,file,krb5config,log,info,adding,krb5,configuration,to,the,am,container,local,resource,bucket,krb5,get,absolute,path,local,resource,krb5conf,resource,records,new,record,local,resource,class,path,krb5conf,path,new,path,krb5,get,absolute,path,remote,krb5path,utils,setup,local,resource,fs,app,id,to,string,krb5conf,path,krb5conf,resource,fs,get,home,directory,local,resources,put,utils,krb5conf,resource,file,f,new,file,system,getenv,utils,log,info,adding,yarn,configuration,to,the,am,container,local,resource,bucket,f,get,absolute,path,local,resource,yarn,conf,resource,records,new,record,local,resource,class,path,yarn,site,path,new,path,f,get,absolute,path,remote,yarn,site,xml,path,utils,setup,local,resource,fs,app,id,to,string,yarn,site,path,yarn,conf,resource,fs,get,home,directory,local,resources,put,utils,yarn,conf,resource,has,krb5,true,local,resource,keytab,resource,null,path,remote,path,keytab,null,string,keytab,flink,configuration,get,string,config,constants,null,if,keytab,null,log,info,adding,keytab,to,the,am,container,local,resource,bucket,keytab,keytab,resource,records,new,record,local,resource,class,path,keytab,path,new,path,keytab,remote,path,keytab,utils,setup,local,resource,fs,app,id,to,string,keytab,path,keytab,resource,fs,get,home,directory,local,resources,put,utils,keytab,resource,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,has,krb5,if,user,group,information,is,security,enabled,keytab,null,log,info,adding,delegation,token,to,the,am,container,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,app,master,env,put,yarn,config,keys,get,zookeeper,namespace,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,user,name,if,keytab,resource,null,app,master,env,put,yarn,config,keys,remote,path,keytab,to,string,string,principal,flink,configuration,get,string,config,constants,null,app,master,env,put,yarn,config,keys,principal,if,remote,yarn,site,xml,path,null,remote,krb5path,null,app,master,env,put,yarn,config,keys,remote,yarn,site,xml,path,to,string,app,master,env,put,yarn,config,keys,remote,krb5path,to,string,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,yarn,application,state,app,state,report,get,yarn,application,state,log,debug,application,state,app,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1479746984;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		_		File jaasConfigFile = new File(configurationDirectory + File.separator + SecurityContext.JAAS_CONF_FILENAME)__		if (jaasConfigFile.exists() && jaasConfigFile.isFile()) {_			effectiveShipFiles.add(jaasConfigFile)__		}__		addLibFolderToShipFiles(effectiveShipFiles)___		_		if (userJarFiles != null) {_			effectiveShipFiles.addAll(userJarFiles)__		}__		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		final ApplicationId appId = appContext.getApplicationId()___		_		String zkNamespace = getZookeeperNamespace()__		_		if (zkNamespace == null || zkNamespace.isEmpty()) {_			_			zkNamespace = flinkConfiguration.getString(HighAvailabilityOptions.HA_CLUSTER_ID, String.valueOf(appId))__			setZookeeperNamespace(zkNamespace)__		}__		flinkConfiguration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, zkNamespace)___		if (HighAvailabilityMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult preVisitDirectory(java.nio.file.Path dir, BasicFileAttributes attrs)_							throws IOException {_						super.preVisitDirectory(dir, attrs)___						java.nio.file.Path relativePath = parentPath.relativize(dir)___						classPathBuilder_							.append(relativePath)_							.append(File.separator)_							.append("*")_							.append(File.pathSeparator)___						return FileVisitResult.CONTINUE__					}_				})__			} else {_				_				classPathBuilder.append(shipFile.getName()).append(File.pathSeparator)__			}__			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		_		_		_		Path remoteKrb5Path = null__		Path remoteYarnSiteXmlPath = null__		boolean hasKrb5 = false__		if(System.getenv("IN_TESTS") != null) {_			String krb5Config = System.getProperty("java.security.krb5.conf")__			if(krb5Config != null && krb5Config.length() != 0) {_				File krb5 = new File(krb5Config)__				LOG.info("Adding KRB5 configuration {} to the AM container local resource bucket", krb5.getAbsolutePath())__				LocalResource krb5ConfResource = Records.newRecord(LocalResource.class)__				Path krb5ConfPath = new Path(krb5.getAbsolutePath())__				remoteKrb5Path = Utils.setupLocalResource(fs, appId.toString(), krb5ConfPath, krb5ConfResource, fs.getHomeDirectory())__				localResources.put(Utils.KRB5_FILE_NAME, krb5ConfResource)___				File f = new File(System.getenv("YARN_CONF_DIR"),Utils.YARN_SITE_FILE_NAME)__				LOG.info("Adding Yarn configuration {} to the AM container local resource bucket", f.getAbsolutePath())__				LocalResource yarnConfResource = Records.newRecord(LocalResource.class)__				Path yarnSitePath = new Path(f.getAbsolutePath())__				remoteYarnSiteXmlPath = Utils.setupLocalResource(fs, appId.toString(), yarnSitePath, yarnConfResource, fs.getHomeDirectory())__				localResources.put(Utils.YARN_SITE_FILE_NAME, yarnConfResource)___				hasKrb5 = true__			}_		}__		_		LocalResource keytabResource = null__		Path remotePathKeytab = null__		String keytab = flinkConfiguration.getString(ConfigConstants.SECURITY_KEYTAB_KEY, null)__		if(keytab != null) {_			LOG.info("Adding keytab {} to the AM container local resource bucket", keytab)__			keytabResource = Records.newRecord(LocalResource.class)__			Path keytabPath = new Path(keytab)__			remotePathKeytab = Utils.setupLocalResource(fs, appId.toString(), keytabPath, keytabResource, fs.getHomeDirectory())__			localResources.put(Utils.KEYTAB_FILE_NAME, keytabResource)__		}__		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j, hasKrb5)___		if ( UserGroupInformation.isSecurityEnabled() && keytab == null ) {_			_			LOG.info("Adding delegation token to the AM container..")__			Utils.setTokensFor(amContainer, paths, conf)__		}__		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))__		appMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace())___		_		appMasterEnv.put(YarnConfigKeys.ENV_HADOOP_USER_NAME, UserGroupInformation.getCurrentUser().getUserName())___		if(keytabResource != null) {_			appMasterEnv.put(YarnConfigKeys.KEYTAB_PATH, remotePathKeytab.toString() )__			String principal = flinkConfiguration.getString(ConfigConstants.SECURITY_PRINCIPAL_KEY, null)__			appMasterEnv.put(YarnConfigKeys.KEYTAB_PRINCIPAL, principal )__		}__		_		if(remoteYarnSiteXmlPath != null && remoteKrb5Path != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_YARN_SITE_XML_PATH, remoteYarnSiteXmlPath.toString())__			appMasterEnv.put(YarnConfigKeys.ENV_KRB5_PATH, remoteKrb5Path.toString() )__		}__		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster.", e)__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			LOG.debug("Application State: {}", appState)__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,file,jaas,config,file,new,file,configuration,directory,file,separator,security,context,if,jaas,config,file,exists,jaas,config,file,is,file,effective,ship,files,add,jaas,config,file,add,lib,folder,to,ship,files,effective,ship,files,if,user,jar,files,null,effective,ship,files,add,all,user,jar,files,application,submission,context,app,context,yarn,application,get,application,submission,context,final,application,id,app,id,app,context,get,application,id,string,zk,namespace,get,zookeeper,namespace,if,zk,namespace,null,zk,namespace,is,empty,zk,namespace,flink,configuration,get,string,high,availability,options,string,value,of,app,id,set,zookeeper,namespace,zk,namespace,flink,configuration,set,string,high,availability,options,zk,namespace,if,high,availability,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,pre,visit,directory,java,nio,file,path,dir,basic,file,attributes,attrs,throws,ioexception,super,pre,visit,directory,dir,attrs,java,nio,file,path,relative,path,parent,path,relativize,dir,class,path,builder,append,relative,path,append,file,separator,append,append,file,path,separator,return,file,visit,result,continue,else,class,path,builder,append,ship,file,get,name,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,path,remote,krb5path,null,path,remote,yarn,site,xml,path,null,boolean,has,krb5,false,if,system,getenv,null,string,krb5config,system,get,property,java,security,krb5,conf,if,krb5config,null,krb5config,length,0,file,krb5,new,file,krb5config,log,info,adding,krb5,configuration,to,the,am,container,local,resource,bucket,krb5,get,absolute,path,local,resource,krb5conf,resource,records,new,record,local,resource,class,path,krb5conf,path,new,path,krb5,get,absolute,path,remote,krb5path,utils,setup,local,resource,fs,app,id,to,string,krb5conf,path,krb5conf,resource,fs,get,home,directory,local,resources,put,utils,krb5conf,resource,file,f,new,file,system,getenv,utils,log,info,adding,yarn,configuration,to,the,am,container,local,resource,bucket,f,get,absolute,path,local,resource,yarn,conf,resource,records,new,record,local,resource,class,path,yarn,site,path,new,path,f,get,absolute,path,remote,yarn,site,xml,path,utils,setup,local,resource,fs,app,id,to,string,yarn,site,path,yarn,conf,resource,fs,get,home,directory,local,resources,put,utils,yarn,conf,resource,has,krb5,true,local,resource,keytab,resource,null,path,remote,path,keytab,null,string,keytab,flink,configuration,get,string,config,constants,null,if,keytab,null,log,info,adding,keytab,to,the,am,container,local,resource,bucket,keytab,keytab,resource,records,new,record,local,resource,class,path,keytab,path,new,path,keytab,remote,path,keytab,utils,setup,local,resource,fs,app,id,to,string,keytab,path,keytab,resource,fs,get,home,directory,local,resources,put,utils,keytab,resource,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,has,krb5,if,user,group,information,is,security,enabled,keytab,null,log,info,adding,delegation,token,to,the,am,container,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,app,master,env,put,yarn,config,keys,get,zookeeper,namespace,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,user,name,if,keytab,resource,null,app,master,env,put,yarn,config,keys,remote,path,keytab,to,string,string,principal,flink,configuration,get,string,config,constants,null,app,master,env,put,yarn,config,keys,principal,if,remote,yarn,site,xml,path,null,remote,krb5path,null,app,master,env,put,yarn,config,keys,remote,yarn,site,xml,path,to,string,app,master,env,put,yarn,config,keys,remote,krb5path,to,string,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,yarn,application,state,app,state,report,get,yarn,application,state,log,debug,application,state,app,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1480082300;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		try {_			org.apache.flink.core.fs.FileSystem.setDefaultScheme(flinkConfiguration)__		} catch (IOException e) {_			throw new IOException("Error while setting the default " +_				"filesystem scheme from configuration.", e)__		}__		_		_		_		final FileSystem fs = FileSystem.get(conf)___		_		if (!fs.getClass().getSimpleName().equals("GoogleHadoopFileSystem") &&_			fs.getScheme().startsWith("file")) {_			LOG.warn("The file system scheme is '" + fs.getScheme() + "'. This indicates that the "_				+ "specified Hadoop configuration path is wrong and the system is using the default Hadoop configuration values."_				+ "The Flink YARN client needs to store its files in a distributed file system")__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		Set<File> effectiveShipFiles = new HashSet<>(shipFiles.size())__		for (File file : shipFiles) {_			effectiveShipFiles.add(file.getAbsoluteFile())__		}__		_		File logbackFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOGBACK_NAME)__		final boolean hasLogback = logbackFile.exists()__		if (hasLogback) {_			effectiveShipFiles.add(logbackFile)__		}__		File log4jFile = new File(configurationDirectory + File.separator + CONFIG_FILE_LOG4J_NAME)__		final boolean hasLog4j = log4jFile.exists()__		if (hasLog4j) {_			effectiveShipFiles.add(log4jFile)__			if (hasLogback) {_				_				LOG.warn("The configuration directory ('" + configurationDirectory + "') contains both LOG4J and " +_					"Logback configuration files. Please delete or rename one of them.")__			}_		}__		_		File jaasConfigFile = new File(configurationDirectory + File.separator + SecurityUtils.JAAS_CONF_FILENAME)__		if (jaasConfigFile.exists() && jaasConfigFile.isFile()) {_			effectiveShipFiles.add(jaasConfigFile)__		}__		addLibFolderToShipFiles(effectiveShipFiles)___		_		if (userJarFiles != null) {_			effectiveShipFiles.addAll(userJarFiles)__		}__		_		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		final ApplicationId appId = appContext.getApplicationId()___		_		String zkNamespace = getZookeeperNamespace()__		_		if (zkNamespace == null || zkNamespace.isEmpty()) {_			_			zkNamespace = flinkConfiguration.getString(HighAvailabilityOptions.HA_CLUSTER_ID, String.valueOf(appId))__			setZookeeperNamespace(zkNamespace)__		}__		flinkConfiguration.setString(HighAvailabilityOptions.HA_CLUSTER_ID, zkNamespace)___		if (HighAvailabilityMode.isHighAvailabilityModeActivated(flinkConfiguration)) {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS))___			activateHighAvailabilitySupport(appContext)__		} else {_			_			appContext.setMaxAppAttempts(_				flinkConfiguration.getInteger(_					ConfigConstants.YARN_APPLICATION_ATTEMPTS,_					1))__		}__		_		final Map<String, LocalResource> localResources = new HashMap<>(2 + effectiveShipFiles.size())__		_		final List<Path> paths = new ArrayList<>(2 + effectiveShipFiles.size())__		_		final StringBuilder classPathBuilder = new StringBuilder()__		_		StringBuilder envShipFileList = new StringBuilder()___		_		for (File shipFile : effectiveShipFiles) {_			LocalResource shipResources = Records.newRecord(LocalResource.class)___			Path shipLocalPath = new Path("file://" + shipFile.getAbsolutePath())__			Path remotePath =_				Utils.setupLocalResource(fs, appId.toString(), shipLocalPath, shipResources, fs.getHomeDirectory())___			paths.add(remotePath)___			localResources.put(shipFile.getName(), shipResources)___			if (shipFile.isDirectory()) {_				_				java.nio.file.Path shipPath = shipFile.toPath()__				final java.nio.file.Path parentPath = shipPath.getParent()___				Files.walkFileTree(shipPath, new SimpleFileVisitor<java.nio.file.Path>() {_					@Override_					public FileVisitResult preVisitDirectory(java.nio.file.Path dir, BasicFileAttributes attrs)_							throws IOException {_						super.preVisitDirectory(dir, attrs)___						java.nio.file.Path relativePath = parentPath.relativize(dir)___						classPathBuilder_							.append(relativePath)_							.append(File.separator)_							.append("*")_							.append(File.pathSeparator)___						return FileVisitResult.CONTINUE__					}_				})__			} else {_				_				classPathBuilder.append(shipFile.getName()).append(File.pathSeparator)__			}__			envShipFileList.append(remotePath).append(",")__		}__		_		LocalResource appMasterJar = Records.newRecord(LocalResource.class)__		LocalResource flinkConf = Records.newRecord(LocalResource.class)__		Path remotePathJar =_			Utils.setupLocalResource(fs, appId.toString(), flinkJarPath, appMasterJar, fs.getHomeDirectory())__		Path remotePathConf =_			Utils.setupLocalResource(fs, appId.toString(), flinkConfigurationPath, flinkConf, fs.getHomeDirectory())__		localResources.put("flink.jar", appMasterJar)__		localResources.put("flink-conf.yaml", flinkConf)___		paths.add(remotePathJar)__		classPathBuilder.append("flink.jar").append(File.pathSeparator)__		paths.add(remotePathConf)__		classPathBuilder.append("flink-conf.yaml").append(File.pathSeparator)___		sessionFilesDir = new Path(fs.getHomeDirectory(), ".flink/" + appId.toString() + "/")___		FsPermission permission = new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE)__		fs.setPermission(sessionFilesDir, permission)_ __		_		_		_		_		Path remoteKrb5Path = null__		Path remoteYarnSiteXmlPath = null__		boolean hasKrb5 = false__		if(System.getenv("IN_TESTS") != null) {_			String krb5Config = System.getProperty("java.security.krb5.conf")__			if(krb5Config != null && krb5Config.length() != 0) {_				File krb5 = new File(krb5Config)__				LOG.info("Adding KRB5 configuration {} to the AM container local resource bucket", krb5.getAbsolutePath())__				LocalResource krb5ConfResource = Records.newRecord(LocalResource.class)__				Path krb5ConfPath = new Path(krb5.getAbsolutePath())__				remoteKrb5Path = Utils.setupLocalResource(fs, appId.toString(), krb5ConfPath, krb5ConfResource, fs.getHomeDirectory())__				localResources.put(Utils.KRB5_FILE_NAME, krb5ConfResource)___				File f = new File(System.getenv("YARN_CONF_DIR"),Utils.YARN_SITE_FILE_NAME)__				LOG.info("Adding Yarn configuration {} to the AM container local resource bucket", f.getAbsolutePath())__				LocalResource yarnConfResource = Records.newRecord(LocalResource.class)__				Path yarnSitePath = new Path(f.getAbsolutePath())__				remoteYarnSiteXmlPath = Utils.setupLocalResource(fs, appId.toString(), yarnSitePath, yarnConfResource, fs.getHomeDirectory())__				localResources.put(Utils.YARN_SITE_FILE_NAME, yarnConfResource)___				hasKrb5 = true__			}_		}__		_		LocalResource keytabResource = null__		Path remotePathKeytab = null__		String keytab = flinkConfiguration.getString(ConfigConstants.SECURITY_KEYTAB_KEY, null)__		if(keytab != null) {_			LOG.info("Adding keytab {} to the AM container local resource bucket", keytab)__			keytabResource = Records.newRecord(LocalResource.class)__			Path keytabPath = new Path(keytab)__			remotePathKeytab = Utils.setupLocalResource(fs, appId.toString(), keytabPath, keytabResource, fs.getHomeDirectory())__			localResources.put(Utils.KEYTAB_FILE_NAME, keytabResource)__		}__		final ContainerLaunchContext amContainer = setupApplicationMasterContainer(hasLogback, hasLog4j, hasKrb5)___		if ( UserGroupInformation.isSecurityEnabled() && keytab == null ) {_			_			LOG.info("Adding delegation token to the AM container..")__			Utils.setTokensFor(amContainer, paths, conf)__		}__		amContainer.setLocalResources(localResources)__		fs.close()___		_		final Map<String, String> appMasterEnv = new HashMap<>()__		_		appMasterEnv.putAll(Utils.getEnvironmentVariables(ConfigConstants.YARN_APPLICATION_MASTER_ENV_PREFIX, flinkConfiguration))__		_		appMasterEnv.put(YarnConfigKeys.ENV_FLINK_CLASSPATH, classPathBuilder.toString())___		_		appMasterEnv.put(YarnConfigKeys.ENV_TM_COUNT, String.valueOf(taskManagerCount))__		appMasterEnv.put(YarnConfigKeys.ENV_TM_MEMORY, String.valueOf(taskManagerMemoryMb))__		appMasterEnv.put(YarnConfigKeys.FLINK_JAR_PATH, remotePathJar.toString() )__		appMasterEnv.put(YarnConfigKeys.ENV_APP_ID, appId.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_HOME_DIR, fs.getHomeDirectory().toString())__		appMasterEnv.put(YarnConfigKeys.ENV_CLIENT_SHIP_FILES, envShipFileList.toString())__		appMasterEnv.put(YarnConfigKeys.ENV_SLOTS, String.valueOf(slots))__		appMasterEnv.put(YarnConfigKeys.ENV_DETACHED, String.valueOf(detached))__		appMasterEnv.put(YarnConfigKeys.ENV_ZOOKEEPER_NAMESPACE, getZookeeperNamespace())___		_		appMasterEnv.put(YarnConfigKeys.ENV_HADOOP_USER_NAME, UserGroupInformation.getCurrentUser().getUserName())___		if(keytabResource != null) {_			appMasterEnv.put(YarnConfigKeys.KEYTAB_PATH, remotePathKeytab.toString() )__			String principal = flinkConfiguration.getString(ConfigConstants.SECURITY_PRINCIPAL_KEY, null)__			appMasterEnv.put(YarnConfigKeys.KEYTAB_PRINCIPAL, principal )__		}__		_		if(remoteYarnSiteXmlPath != null && remoteKrb5Path != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_YARN_SITE_XML_PATH, remoteYarnSiteXmlPath.toString())__			appMasterEnv.put(YarnConfigKeys.ENV_KRB5_PATH, remoteKrb5Path.toString() )__		}__		if(dynamicPropertiesEncoded != null) {_			appMasterEnv.put(YarnConfigKeys.ENV_DYNAMIC_PROPERTIES, dynamicPropertiesEncoded)__		}__		_		Utils.setupYarnClassPath(conf, appMasterEnv)___		amContainer.setEnvironment(appMasterEnv)___		_		Resource capability = Records.newRecord(Resource.class)__		capability.setMemory(jobManagerMemoryMb)__		capability.setVirtualCores(1)___		String name__		if(customName == null) {_			name = "Flink session with " + taskManagerCount + " TaskManagers"__			if(detached) {_				name += " (detached)"__			}_		} else {_			name = customName__		}__		appContext.setApplicationName(name)_ _		appContext.setApplicationType("Apache Flink")__		appContext.setAMContainerSpec(amContainer)__		appContext.setResource(capability)__		if(yarnQueue != null) {_			appContext.setQueue(yarnQueue)__		}__		_		Thread deploymentFailureHook = new DeploymentFailureHook(yarnClient, yarnApplication)__		Runtime.getRuntime().addShutdownHook(deploymentFailureHook)__		LOG.info("Submitting application master " + appId)__		yarnClient.submitApplication(appContext)___		LOG.info("Waiting for the cluster to be allocated")__		final long startTime = System.currentTimeMillis()__		ApplicationReport report__		YarnApplicationState lastAppState = YarnApplicationState.NEW__		loop: while( true ) {_			try {_				report = yarnClient.getApplicationReport(appId)__			} catch (IOException e) {_				throw new YarnDeploymentException("Failed to deploy the cluster.", e)__			}_			YarnApplicationState appState = report.getYarnApplicationState()__			LOG.debug("Application State: {}", appState)__			switch(appState) {_				case FAILED:_				case FINISHED:_				case KILLED:_					throw new YarnDeploymentException("The YARN application unexpectedly switched to state "_						+ appState + " during deployment. \n" +_						"Diagnostics from YARN: " + report.getDiagnostics() + "\n" +_						"If log aggregation is enabled on your cluster, use this command to further investigate the issue:\n" +_						"yarn logs -applicationId " + appId)__					_				case RUNNING:_					LOG.info("YARN application has been deployed successfully.")__					break loop__				default:_					if (appState != lastAppState) {_						LOG.info("Deploying cluster, current state " + appState)__					}_					if(System.currentTimeMillis() - startTime > 60000) {_						LOG.info("Deployment took more than 60 seconds. Please check if the requested resources are available in the YARN cluster")__					}__			}_			lastAppState = appState__			Thread.sleep(250)__		}_		_		if (isDetachedMode()) {_			LOG.info("The Flink YARN client has been started in detached mode. In order to stop " +_					"Flink on YARN, use the following command or a YARN web interface to stop " +_					"it:\nyarn application -kill " + appId + "\nPlease also note that the " +_					"temporary files of the YARN session in the home directoy will not be removed.")__		}_		_		try {_			Runtime.getRuntime().removeShutdownHook(deploymentFailureHook)__		} catch (IllegalStateException e) {_			_		}__		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,try,org,apache,flink,core,fs,file,system,set,default,scheme,flink,configuration,catch,ioexception,e,throw,new,ioexception,error,while,setting,the,default,filesystem,scheme,from,configuration,e,final,file,system,fs,file,system,get,conf,if,fs,get,class,get,simple,name,equals,google,hadoop,file,system,fs,get,scheme,starts,with,file,log,warn,the,file,system,scheme,is,fs,get,scheme,this,indicates,that,the,specified,hadoop,configuration,path,is,wrong,and,the,system,is,using,the,default,hadoop,configuration,values,the,flink,yarn,client,needs,to,store,its,files,in,a,distributed,file,system,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,set,file,effective,ship,files,new,hash,set,ship,files,size,for,file,file,ship,files,effective,ship,files,add,file,get,absolute,file,file,logback,file,new,file,configuration,directory,file,separator,final,boolean,has,logback,logback,file,exists,if,has,logback,effective,ship,files,add,logback,file,file,log4j,file,new,file,configuration,directory,file,separator,final,boolean,has,log4j,log4j,file,exists,if,has,log4j,effective,ship,files,add,log4j,file,if,has,logback,log,warn,the,configuration,directory,configuration,directory,contains,both,log4j,and,logback,configuration,files,please,delete,or,rename,one,of,them,file,jaas,config,file,new,file,configuration,directory,file,separator,security,utils,if,jaas,config,file,exists,jaas,config,file,is,file,effective,ship,files,add,jaas,config,file,add,lib,folder,to,ship,files,effective,ship,files,if,user,jar,files,null,effective,ship,files,add,all,user,jar,files,application,submission,context,app,context,yarn,application,get,application,submission,context,final,application,id,app,id,app,context,get,application,id,string,zk,namespace,get,zookeeper,namespace,if,zk,namespace,null,zk,namespace,is,empty,zk,namespace,flink,configuration,get,string,high,availability,options,string,value,of,app,id,set,zookeeper,namespace,zk,namespace,flink,configuration,set,string,high,availability,options,zk,namespace,if,high,availability,mode,is,high,availability,mode,activated,flink,configuration,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,yarn,configuration,activate,high,availability,support,app,context,else,app,context,set,max,app,attempts,flink,configuration,get,integer,config,constants,1,final,map,string,local,resource,local,resources,new,hash,map,2,effective,ship,files,size,final,list,path,paths,new,array,list,2,effective,ship,files,size,final,string,builder,class,path,builder,new,string,builder,string,builder,env,ship,file,list,new,string,builder,for,file,ship,file,effective,ship,files,local,resource,ship,resources,records,new,record,local,resource,class,path,ship,local,path,new,path,file,ship,file,get,absolute,path,path,remote,path,utils,setup,local,resource,fs,app,id,to,string,ship,local,path,ship,resources,fs,get,home,directory,paths,add,remote,path,local,resources,put,ship,file,get,name,ship,resources,if,ship,file,is,directory,java,nio,file,path,ship,path,ship,file,to,path,final,java,nio,file,path,parent,path,ship,path,get,parent,files,walk,file,tree,ship,path,new,simple,file,visitor,java,nio,file,path,override,public,file,visit,result,pre,visit,directory,java,nio,file,path,dir,basic,file,attributes,attrs,throws,ioexception,super,pre,visit,directory,dir,attrs,java,nio,file,path,relative,path,parent,path,relativize,dir,class,path,builder,append,relative,path,append,file,separator,append,append,file,path,separator,return,file,visit,result,continue,else,class,path,builder,append,ship,file,get,name,append,file,path,separator,env,ship,file,list,append,remote,path,append,local,resource,app,master,jar,records,new,record,local,resource,class,local,resource,flink,conf,records,new,record,local,resource,class,path,remote,path,jar,utils,setup,local,resource,fs,app,id,to,string,flink,jar,path,app,master,jar,fs,get,home,directory,path,remote,path,conf,utils,setup,local,resource,fs,app,id,to,string,flink,configuration,path,flink,conf,fs,get,home,directory,local,resources,put,flink,jar,app,master,jar,local,resources,put,flink,conf,yaml,flink,conf,paths,add,remote,path,jar,class,path,builder,append,flink,jar,append,file,path,separator,paths,add,remote,path,conf,class,path,builder,append,flink,conf,yaml,append,file,path,separator,session,files,dir,new,path,fs,get,home,directory,flink,app,id,to,string,fs,permission,permission,new,fs,permission,fs,action,all,fs,action,none,fs,action,none,fs,set,permission,session,files,dir,permission,path,remote,krb5path,null,path,remote,yarn,site,xml,path,null,boolean,has,krb5,false,if,system,getenv,null,string,krb5config,system,get,property,java,security,krb5,conf,if,krb5config,null,krb5config,length,0,file,krb5,new,file,krb5config,log,info,adding,krb5,configuration,to,the,am,container,local,resource,bucket,krb5,get,absolute,path,local,resource,krb5conf,resource,records,new,record,local,resource,class,path,krb5conf,path,new,path,krb5,get,absolute,path,remote,krb5path,utils,setup,local,resource,fs,app,id,to,string,krb5conf,path,krb5conf,resource,fs,get,home,directory,local,resources,put,utils,krb5conf,resource,file,f,new,file,system,getenv,utils,log,info,adding,yarn,configuration,to,the,am,container,local,resource,bucket,f,get,absolute,path,local,resource,yarn,conf,resource,records,new,record,local,resource,class,path,yarn,site,path,new,path,f,get,absolute,path,remote,yarn,site,xml,path,utils,setup,local,resource,fs,app,id,to,string,yarn,site,path,yarn,conf,resource,fs,get,home,directory,local,resources,put,utils,yarn,conf,resource,has,krb5,true,local,resource,keytab,resource,null,path,remote,path,keytab,null,string,keytab,flink,configuration,get,string,config,constants,null,if,keytab,null,log,info,adding,keytab,to,the,am,container,local,resource,bucket,keytab,keytab,resource,records,new,record,local,resource,class,path,keytab,path,new,path,keytab,remote,path,keytab,utils,setup,local,resource,fs,app,id,to,string,keytab,path,keytab,resource,fs,get,home,directory,local,resources,put,utils,keytab,resource,final,container,launch,context,am,container,setup,application,master,container,has,logback,has,log4j,has,krb5,if,user,group,information,is,security,enabled,keytab,null,log,info,adding,delegation,token,to,the,am,container,utils,set,tokens,for,am,container,paths,conf,am,container,set,local,resources,local,resources,fs,close,final,map,string,string,app,master,env,new,hash,map,app,master,env,put,all,utils,get,environment,variables,config,constants,flink,configuration,app,master,env,put,yarn,config,keys,class,path,builder,to,string,app,master,env,put,yarn,config,keys,string,value,of,task,manager,count,app,master,env,put,yarn,config,keys,string,value,of,task,manager,memory,mb,app,master,env,put,yarn,config,keys,remote,path,jar,to,string,app,master,env,put,yarn,config,keys,app,id,to,string,app,master,env,put,yarn,config,keys,fs,get,home,directory,to,string,app,master,env,put,yarn,config,keys,env,ship,file,list,to,string,app,master,env,put,yarn,config,keys,string,value,of,slots,app,master,env,put,yarn,config,keys,string,value,of,detached,app,master,env,put,yarn,config,keys,get,zookeeper,namespace,app,master,env,put,yarn,config,keys,user,group,information,get,current,user,get,user,name,if,keytab,resource,null,app,master,env,put,yarn,config,keys,remote,path,keytab,to,string,string,principal,flink,configuration,get,string,config,constants,null,app,master,env,put,yarn,config,keys,principal,if,remote,yarn,site,xml,path,null,remote,krb5path,null,app,master,env,put,yarn,config,keys,remote,yarn,site,xml,path,to,string,app,master,env,put,yarn,config,keys,remote,krb5path,to,string,if,dynamic,properties,encoded,null,app,master,env,put,yarn,config,keys,dynamic,properties,encoded,utils,setup,yarn,class,path,conf,app,master,env,am,container,set,environment,app,master,env,resource,capability,records,new,record,resource,class,capability,set,memory,job,manager,memory,mb,capability,set,virtual,cores,1,string,name,if,custom,name,null,name,flink,session,with,task,manager,count,task,managers,if,detached,name,detached,else,name,custom,name,app,context,set,application,name,name,app,context,set,application,type,apache,flink,app,context,set,amcontainer,spec,am,container,app,context,set,resource,capability,if,yarn,queue,null,app,context,set,queue,yarn,queue,thread,deployment,failure,hook,new,deployment,failure,hook,yarn,client,yarn,application,runtime,get,runtime,add,shutdown,hook,deployment,failure,hook,log,info,submitting,application,master,app,id,yarn,client,submit,application,app,context,log,info,waiting,for,the,cluster,to,be,allocated,final,long,start,time,system,current,time,millis,application,report,report,yarn,application,state,last,app,state,yarn,application,state,new,loop,while,true,try,report,yarn,client,get,application,report,app,id,catch,ioexception,e,throw,new,yarn,deployment,exception,failed,to,deploy,the,cluster,e,yarn,application,state,app,state,report,get,yarn,application,state,log,debug,application,state,app,state,switch,app,state,case,failed,case,finished,case,killed,throw,new,yarn,deployment,exception,the,yarn,application,unexpectedly,switched,to,state,app,state,during,deployment,n,diagnostics,from,yarn,report,get,diagnostics,n,if,log,aggregation,is,enabled,on,your,cluster,use,this,command,to,further,investigate,the,issue,n,yarn,logs,application,id,app,id,case,running,log,info,yarn,application,has,been,deployed,successfully,break,loop,default,if,app,state,last,app,state,log,info,deploying,cluster,current,state,app,state,if,system,current,time,millis,start,time,60000,log,info,deployment,took,more,than,60,seconds,please,check,if,the,requested,resources,are,available,in,the,yarn,cluster,last,app,state,app,state,thread,sleep,250,if,is,detached,mode,log,info,the,flink,yarn,client,has,been,started,in,detached,mode,in,order,to,stop,flink,on,yarn,use,the,following,command,or,a,yarn,web,interface,to,stop,it,nyarn,application,kill,app,id,n,please,also,note,that,the,temporary,files,of,the,yarn,session,in,the,home,directoy,will,not,be,removed,try,runtime,get,runtime,remove,shutdown,hook,deployment,failure,hook,catch,illegal,state,exception,e,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1482522867;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()__		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,application,submission,context,app,context,yarn,application,get,application,submission,context,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1482522867;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()__		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,application,submission,context,app,context,yarn,application,get,application,submission,context,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1483644165;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()__		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,application,submission,context,app,context,yarn,application,get,application,submission,context,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1484162264;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()__		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,application,submission,context,app,context,yarn,application,get,application,submission,context,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1484734622;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()__		ApplicationSubmissionContext appContext = yarnApplication.getApplicationSubmissionContext()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,application,submission,context,app,context,yarn,application,get,application,submission,context,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1485274812;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1486575587;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1487622556;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1488923210;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1489509047;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1490967479;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1492605405;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1492605425;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1492763444;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1493975167;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1495108913;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, sessionFilesDir, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,session,files,dir,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1495787238;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1495787238;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1495787238;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()____		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch(Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if(LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if(jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if(jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if(taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String NOTE = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if(jobManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + NOTE)__		}__		if(taskManagerMemoryMb > maxRes.getMemory() ) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + NOTE)__		}__		final String NOTE_RSC = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if(freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + NOTE_RSC)___		}_		if(taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}_		if(jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + NOTE_RSC)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if(!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + NOTE_RSC)__		}_		_		for(int i = 0_ i < taskManagerCount_ i++) {_			if(!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + NOTE_RSC )__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1495819079;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()___		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch (Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if (LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if (jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if (jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if (taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String note = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if (jobManagerMemoryMb > maxRes.getMemory()) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + note)__		}__		if (taskManagerMemoryMb > maxRes.getMemory()) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + note)__		}__		final String noteRsc = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if (freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + noteRsc)___		}_		if (taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + noteRsc)__		}_		if (jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + noteRsc)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if (!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + noteRsc)__		}_		_		for (int i = 0_ i < taskManagerCount_ i++) {_			if (!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + noteRsc)__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,note,rsc,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,note,rsc,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,note,rsc,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,note,rsc,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,note,rsc,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,note,rsc,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1498894422;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()___		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch (Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if (LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if (jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if (jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if (taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String note = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if (jobManagerMemoryMb > maxRes.getMemory()) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + note)__		}__		if (taskManagerMemoryMb > maxRes.getMemory()) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + note)__		}__		final String noteRsc = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if (freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + noteRsc)___		}_		if (taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + noteRsc)__		}_		if (jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + noteRsc)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if (!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + noteRsc)__		}_		_		for (int i = 0_ i < taskManagerCount_ i++) {_			if (!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + noteRsc)__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,note,rsc,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,note,rsc,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,note,rsc,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,note,rsc,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,note,rsc,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,note,rsc,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1498894422;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()___		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch (Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if (LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if (jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if (jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if (taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String note = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if (jobManagerMemoryMb > maxRes.getMemory()) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + note)__		}__		if (taskManagerMemoryMb > maxRes.getMemory()) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + note)__		}__		final String noteRsc = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		if (freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + noteRsc)___		}_		if (taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + noteRsc)__		}_		if (jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + noteRsc)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if (!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + noteRsc)__		}_		_		for (int i = 0_ i < taskManagerCount_ i++) {_			if (!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + noteRsc)__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,note,rsc,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,get,current,free,cluster,resources,yarn,client,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,note,rsc,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,note,rsc,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,note,rsc,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,note,rsc,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,note,rsc,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1498896127;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()___		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch (Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if (LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if (jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if (jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if (taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String note = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if (jobManagerMemoryMb > maxRes.getMemory()) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + note)__		}__		if (taskManagerMemoryMb > maxRes.getMemory()) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + note)__		}__		final String noteRsc = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		if (freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + noteRsc)___		}_		if (taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + noteRsc)__		}_		if (jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + noteRsc)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if (!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + noteRsc)__		}_		_		for (int i = 0_ i < taskManagerCount_ i++) {_			if (!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + noteRsc)__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(ConfigConstants.JOB_MANAGER_IPC_ADDRESS_KEY, host)__		flinkConfiguration.setInteger(ConfigConstants.JOB_MANAGER_IPC_PORT_KEY, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,note,rsc,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,note,rsc,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,note,rsc,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,note,rsc,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,note,rsc,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,note,rsc,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,config,constants,host,flink,configuration,set,integer,config,constants,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1499683297;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()___		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch (Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if (LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if (jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if (jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if (taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String note = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if (jobManagerMemoryMb > maxRes.getMemory()) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + note)__		}__		if (taskManagerMemoryMb > maxRes.getMemory()) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + note)__		}__		final String noteRsc = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		if (freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + noteRsc)___		}_		if (taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + noteRsc)__		}_		if (jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + noteRsc)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if (!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + noteRsc)__		}_		_		for (int i = 0_ i < taskManagerCount_ i++) {_			if (!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + noteRsc)__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,note,rsc,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,note,rsc,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,note,rsc,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,note,rsc,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,note,rsc,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,note,rsc,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient deployInternal() throws Exception;1501083592;This method will block until the ApplicationMaster/JobManager have been_deployed on YARN.;protected YarnClusterClient deployInternal() throws Exception {_		isReadyForDeployment()__		LOG.info("Using values:")__		LOG.info("\tTaskManager count = {}", taskManagerCount)__		LOG.info("\tJobManager memory = {}", jobManagerMemoryMb)__		LOG.info("\tTaskManager memory = {}", taskManagerMemoryMb)___		final YarnClient yarnClient = getYarnClient()___		__		try {_			List<QueueInfo> queues = yarnClient.getAllQueues()__			if (queues.size() > 0 && this.yarnQueue != null) { _				boolean queueFound = false__				for (QueueInfo queue : queues) {_					if (queue.getQueueName().equals(this.yarnQueue)) {_						queueFound = true__						break__					}_				}_				if (!queueFound) {_					String queueNames = ""__					for (QueueInfo queue : queues) {_						queueNames += queue.getQueueName() + ", "__					}_					LOG.warn("The specified queue '" + this.yarnQueue + "' does not exist. " +_						"Available queues: " + queueNames)__				}_			} else {_				LOG.debug("The YARN cluster does not have any queues configured")__			}_		} catch (Throwable e) {_			LOG.warn("Error while getting queue information from YARN: " + e.getMessage())__			if (LOG.isDebugEnabled()) {_				LOG.debug("Error details", e)__			}_		}__		_		Map<String, String> dynProperties = getDynamicProperties(dynamicPropertiesEncoded)__		for (Map.Entry<String, String> dynProperty : dynProperties.entrySet()) {_			flinkConfiguration.setString(dynProperty.getKey(), dynProperty.getValue())__		}__		__		_		_		final int yarnMinAllocationMB = conf.getInt("yarn.scheduler.minimum-allocation-mb", 0)__		if (jobManagerMemoryMb < yarnMinAllocationMB || taskManagerMemoryMb < yarnMinAllocationMB) {_			LOG.warn("The JobManager or TaskManager memory is below the smallest possible YARN Container size. "_				+ "The value of 'yarn.scheduler.minimum-allocation-mb' is '" + yarnMinAllocationMB + "'. Please increase the memory size." +_				"YARN will allocate the smaller containers but the scheduler will account for the minimum-allocation-mb, maybe not all instances " +_				"you requested will start.")__		}__		_		if (jobManagerMemoryMb < yarnMinAllocationMB) {_			jobManagerMemoryMb =  yarnMinAllocationMB__		}_		if (taskManagerMemoryMb < yarnMinAllocationMB) {_			taskManagerMemoryMb =  yarnMinAllocationMB__		}__		_		final YarnClientApplication yarnApplication = yarnClient.createApplication()__		GetNewApplicationResponse appResponse = yarnApplication.getNewApplicationResponse()___		Resource maxRes = appResponse.getMaximumResourceCapability()__		final String note = "Please check the 'yarn.scheduler.maximum-allocation-mb' and the 'yarn.nodemanager.resource.memory-mb' configuration values\n"__		if (jobManagerMemoryMb > maxRes.getMemory()) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the JobManager available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + "MB Requested: " + jobManagerMemoryMb + "MB. " + note)__		}__		if (taskManagerMemoryMb > maxRes.getMemory()) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("The cluster does not have the requested resources for the TaskManagers available!\n"_				+ "Maximum Memory: " + maxRes.getMemory() + " Requested: " + taskManagerMemoryMb + "MB. " + note)__		}__		final String noteRsc = "\nThe Flink YARN client will try to allocate the YARN session, but maybe not all TaskManagers are " +_			"connecting from the beginning because the resources are currently not available in the cluster. " +_			"The allocation might take more time than usual because the Flink YARN client needs to wait until " +_			"the resources become available."__		int totalMemoryRequired = jobManagerMemoryMb + taskManagerMemoryMb * taskManagerCount__		ClusterResourceDescription freeClusterMem__		try {_			freeClusterMem = getCurrentFreeClusterResources(yarnClient)__		} catch (YarnException | IOException e) {_			failSessionDuringDeployment(yarnClient, yarnApplication)__			throw new YarnDeploymentException("Could not retrieve information about free cluster resources.", e)__		}__		if (freeClusterMem.totalFreeMemory < totalMemoryRequired) {_			LOG.warn("This YARN session requires " + totalMemoryRequired + "MB of memory in the cluster. "_				+ "There are currently only " + freeClusterMem.totalFreeMemory + "MB available." + noteRsc)___		}_		if (taskManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the TaskManagers (" + taskManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + noteRsc)__		}_		if (jobManagerMemoryMb > freeClusterMem.containerLimit) {_			LOG.warn("The requested amount of memory for the JobManager (" + jobManagerMemoryMb + "MB) is more than "_				+ "the largest possible YARN container: " + freeClusterMem.containerLimit + noteRsc)__		}__		__		int[] nmFree = Arrays.copyOf(freeClusterMem.nodeManagersFree, freeClusterMem.nodeManagersFree.length)__		_		if (!allocateResource(nmFree, jobManagerMemoryMb)) {_			LOG.warn("Unable to find a NodeManager that can fit the JobManager/Application master. " +_				"The JobManager requires " + jobManagerMemoryMb + "MB. NodeManagers available: " +_				Arrays.toString(freeClusterMem.nodeManagersFree) + noteRsc)__		}_		_		for (int i = 0_ i < taskManagerCount_ i++) {_			if (!allocateResource(nmFree, taskManagerMemoryMb)) {_				LOG.warn("There is not enough memory available in the YARN cluster. " +_					"The TaskManager(s) require " + taskManagerMemoryMb + "MB each. " +_					"NodeManagers available: " + Arrays.toString(freeClusterMem.nodeManagersFree) + "\n" +_					"After allocating the JobManager (" + jobManagerMemoryMb + "MB) and (" + i + "/" + taskManagerCount + ") TaskManagers, " +_					"the following NodeManagers are available: " + Arrays.toString(nmFree)  + noteRsc)__			}_		}__		ApplicationReport report = startAppMaster(null, yarnClient, yarnApplication)___		String host = report.getHost()__		int port = report.getRpcPort()___		_		flinkConfiguration.setString(JobManagerOptions.ADDRESS, host)__		flinkConfiguration.setInteger(JobManagerOptions.PORT, port)___		_		return createYarnClusterClient(this, yarnClient, report, flinkConfiguration, true)__	};this,method,will,block,until,the,application,master,job,manager,have,been,deployed,on,yarn;protected,yarn,cluster,client,deploy,internal,throws,exception,is,ready,for,deployment,log,info,using,values,log,info,t,task,manager,count,task,manager,count,log,info,t,job,manager,memory,job,manager,memory,mb,log,info,t,task,manager,memory,task,manager,memory,mb,final,yarn,client,yarn,client,get,yarn,client,try,list,queue,info,queues,yarn,client,get,all,queues,if,queues,size,0,this,yarn,queue,null,boolean,queue,found,false,for,queue,info,queue,queues,if,queue,get,queue,name,equals,this,yarn,queue,queue,found,true,break,if,queue,found,string,queue,names,for,queue,info,queue,queues,queue,names,queue,get,queue,name,log,warn,the,specified,queue,this,yarn,queue,does,not,exist,available,queues,queue,names,else,log,debug,the,yarn,cluster,does,not,have,any,queues,configured,catch,throwable,e,log,warn,error,while,getting,queue,information,from,yarn,e,get,message,if,log,is,debug,enabled,log,debug,error,details,e,map,string,string,dyn,properties,get,dynamic,properties,dynamic,properties,encoded,for,map,entry,string,string,dyn,property,dyn,properties,entry,set,flink,configuration,set,string,dyn,property,get,key,dyn,property,get,value,final,int,yarn,min,allocation,mb,conf,get,int,yarn,scheduler,minimum,allocation,mb,0,if,job,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,log,warn,the,job,manager,or,task,manager,memory,is,below,the,smallest,possible,yarn,container,size,the,value,of,yarn,scheduler,minimum,allocation,mb,is,yarn,min,allocation,mb,please,increase,the,memory,size,yarn,will,allocate,the,smaller,containers,but,the,scheduler,will,account,for,the,minimum,allocation,mb,maybe,not,all,instances,you,requested,will,start,if,job,manager,memory,mb,yarn,min,allocation,mb,job,manager,memory,mb,yarn,min,allocation,mb,if,task,manager,memory,mb,yarn,min,allocation,mb,task,manager,memory,mb,yarn,min,allocation,mb,final,yarn,client,application,yarn,application,yarn,client,create,application,get,new,application,response,app,response,yarn,application,get,new,application,response,resource,max,res,app,response,get,maximum,resource,capability,final,string,note,please,check,the,yarn,scheduler,maximum,allocation,mb,and,the,yarn,nodemanager,resource,memory,mb,configuration,values,n,if,job,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,job,manager,available,n,maximum,memory,max,res,get,memory,mb,requested,job,manager,memory,mb,mb,note,if,task,manager,memory,mb,max,res,get,memory,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,the,cluster,does,not,have,the,requested,resources,for,the,task,managers,available,n,maximum,memory,max,res,get,memory,requested,task,manager,memory,mb,mb,note,final,string,note,rsc,n,the,flink,yarn,client,will,try,to,allocate,the,yarn,session,but,maybe,not,all,task,managers,are,connecting,from,the,beginning,because,the,resources,are,currently,not,available,in,the,cluster,the,allocation,might,take,more,time,than,usual,because,the,flink,yarn,client,needs,to,wait,until,the,resources,become,available,int,total,memory,required,job,manager,memory,mb,task,manager,memory,mb,task,manager,count,cluster,resource,description,free,cluster,mem,try,free,cluster,mem,get,current,free,cluster,resources,yarn,client,catch,yarn,exception,ioexception,e,fail,session,during,deployment,yarn,client,yarn,application,throw,new,yarn,deployment,exception,could,not,retrieve,information,about,free,cluster,resources,e,if,free,cluster,mem,total,free,memory,total,memory,required,log,warn,this,yarn,session,requires,total,memory,required,mb,of,memory,in,the,cluster,there,are,currently,only,free,cluster,mem,total,free,memory,mb,available,note,rsc,if,task,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,task,managers,task,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,note,rsc,if,job,manager,memory,mb,free,cluster,mem,container,limit,log,warn,the,requested,amount,of,memory,for,the,job,manager,job,manager,memory,mb,mb,is,more,than,the,largest,possible,yarn,container,free,cluster,mem,container,limit,note,rsc,int,nm,free,arrays,copy,of,free,cluster,mem,node,managers,free,free,cluster,mem,node,managers,free,length,if,allocate,resource,nm,free,job,manager,memory,mb,log,warn,unable,to,find,a,node,manager,that,can,fit,the,job,manager,application,master,the,job,manager,requires,job,manager,memory,mb,mb,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,note,rsc,for,int,i,0,i,task,manager,count,i,if,allocate,resource,nm,free,task,manager,memory,mb,log,warn,there,is,not,enough,memory,available,in,the,yarn,cluster,the,task,manager,s,require,task,manager,memory,mb,mb,each,node,managers,available,arrays,to,string,free,cluster,mem,node,managers,free,n,after,allocating,the,job,manager,job,manager,memory,mb,mb,and,i,task,manager,count,task,managers,the,following,node,managers,are,available,arrays,to,string,nm,free,note,rsc,application,report,report,start,app,master,null,yarn,client,yarn,application,string,host,report,get,host,int,port,report,get,rpc,port,flink,configuration,set,string,job,manager,options,address,host,flink,configuration,set,integer,job,manager,options,port,port,return,create,yarn,cluster,client,this,yarn,client,report,flink,configuration,true
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws Exception;1493975167;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			YarnClient yarnClient, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			Path sessionFilesDir, 			boolean perJobCluster) throws Exception;1495108913;Creates a YarnClusterClient_ may be overriden in tests;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			YarnClient yarnClient,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			Path sessionFilesDir,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			yarnClient,_			report,_			flinkConfiguration,_			sessionFilesDir,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,yarn,client,yarn,client,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,path,session,files,dir,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,yarn,client,report,flink,configuration,session,files,dir,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1515686369;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1515770043;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1515770043;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected YarnClusterClient createYarnClusterClient( 			AbstractYarnClusterDescriptor descriptor, 			int numberTaskManagers, 			int slotsPerTaskManager, 			ApplicationReport report, 			org.apache.flink.configuration.Configuration flinkConfiguration, 			boolean perJobCluster) throws Exception;1515770044;Creates a YarnClusterClient_ may be overriden in tests.;protected YarnClusterClient createYarnClusterClient(_			AbstractYarnClusterDescriptor descriptor,_			int numberTaskManagers,_			int slotsPerTaskManager,_			ApplicationReport report,_			org.apache.flink.configuration.Configuration flinkConfiguration,_			boolean perJobCluster) throws Exception {_		return new YarnClusterClient(_			descriptor,_			numberTaskManagers,_			slotsPerTaskManager,_			report,_			flinkConfiguration,_			perJobCluster)__	};creates,a,yarn,cluster,client,may,be,overriden,in,tests;protected,yarn,cluster,client,create,yarn,cluster,client,abstract,yarn,cluster,descriptor,descriptor,int,number,task,managers,int,slots,per,task,manager,application,report,report,org,apache,flink,configuration,configuration,flink,configuration,boolean,per,job,cluster,throws,exception,return,new,yarn,cluster,client,descriptor,number,task,managers,slots,per,task,manager,report,flink,configuration,per,job,cluster
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1501436689;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1502357790;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1506499511;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1507281370;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1510999087;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1511813739;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1511966584;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1515686359;The class to bootstrap the application master of the Yarn cluster (runs main method).;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,bootstrap,the,application,master,of,the,yarn,cluster,runs,main,method;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1515686369;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1515770043;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1515770043;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1515770044;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1515770045;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1518680659;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1518945172;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1519249745;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1519567828;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1519820825;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1520030750;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1520032158;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1521626214;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1521626214;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1522130852;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1522681180;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1523554814;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1523641287;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1524124694;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1525116069;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1527695275;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1530798894;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1531303508;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1531914688;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1539113610;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1541146016;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1541670646;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1541771328;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1546179677;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1548947871;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
AbstractYarnClusterDescriptor -> protected abstract String getYarnSessionClusterEntrypoint()_;1549456065;The class to start the application master with. This class runs the main_method in case of session cluster.;protected abstract String getYarnSessionClusterEntrypoint()_;the,class,to,start,the,application,master,with,this,class,runs,the,main,method,in,case,of,session,cluster;protected,abstract,string,get,yarn,session,cluster,entrypoint
