commented;modifiers;parameterAmount;loc;comment;code
false;public;0;3;;public Map<String, String> toMap() {     return parameters. }
false;public,static;1;3;;public static String getScriptName(ExecutionConfig.GlobalJobParameters parameters) {     return parameters.toMap().get(KEY_SCRIPT_NAME). }
false;private,static;1;13;;private static void registerJythonSerializers(StreamExecutionEnvironment env) {     env.registerTypeWithKryoSerializer(PyBoolean.class, PyBooleanSerializer.class).     env.registerTypeWithKryoSerializer(PyFloat.class, PyFloatSerializer.class).     env.registerTypeWithKryoSerializer(PyInteger.class, PyIntegerSerializer.class).     env.registerTypeWithKryoSerializer(PyLong.class, PyLongSerializer.class).     env.registerTypeWithKryoSerializer(PyString.class, PyStringSerializer.class).     env.registerTypeWithKryoSerializer(PyUnicode.class, PyObjectSerializer.class).     env.registerTypeWithKryoSerializer(PyTuple.class, PyObjectSerializer.class).     env.registerTypeWithKryoSerializer(PyObjectDerived.class, PyObjectSerializer.class).     env.registerTypeWithKryoSerializer(PyInstance.class, PyObjectSerializer.class). }
false;public;1;3;;public PythonDataStream create_python_source(SourceFunction<Object> src) throws Exception {     return new PythonDataStream<>(env.addSource(new PythonGeneratorFunction(src)).map(new AdapterMap<>())). }
true;public;1;3;/**  * Add a java source to the streaming topology. The source expected to be an java based  * implementation (.e.g. Kafka connector).  *  * @param src A native java source (e.g. PythonFlinkKafkaConsumer09)  * @return Python data stream  */ ;/**  * Add a java source to the streaming topology. The source expected to be an java based  * implementation (.e.g. Kafka connector).  *  * @param src A native java source (e.g. PythonFlinkKafkaConsumer09)  * @return Python data stream  */ public PythonDataStream add_java_source(SourceFunction<Object> src) {     return new PythonDataStream<>(env.addSource(src).map(new AdapterMap<>())). }
true;public;1;3;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#fromElements(java.lang.Object[])}.  *  * @param elements The array of PyObject elements to create the data stream from.  * @return The data stream representing the given array of elements  */ ;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#fromElements(java.lang.Object[])}.  *  * @param elements The array of PyObject elements to create the data stream from.  * @return The data stream representing the given array of elements  */ public PythonDataStream from_elements(PyObject... elements) {     return new PythonDataStream<>(env.fromElements(elements)). }
true;public;1;3;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#fromCollection(java.util.Collection)}  *  * <p>The input {@code Collection} is of type {@code Object}, because it is a collection  * of Python elements. * There type is determined in runtime, by the Jython framework.</p>  *  * @param collection The collection of python elements to create the data stream from.  * @return The data stream representing the given collection  */ ;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#fromCollection(java.util.Collection)}  *  * <p>The input {@code Collection} is of type {@code Object}, because it is a collection  * of Python elements. * There type is determined in runtime, by the Jython framework.</p>  *  * @param collection The collection of python elements to create the data stream from.  * @return The data stream representing the given collection  */ public PythonDataStream from_collection(Collection<Object> collection) {     return new PythonDataStream<>(env.fromCollection(collection).map(new AdapterMap<>())). }
true;public;1;4;/**  * Creates a python data stream from the given iterator.  *  * <p>Note that this operation will result in a non-parallel data stream source, i.e.,  * a data stream source with a parallelism of one.</p>  *  * @param iter The iterator of elements to create the data stream from  * @return The data stream representing the elements in the iterator  * @see StreamExecutionEnvironment#fromCollection(java.util.Iterator, org.apache.flink.api.common.typeinfo.TypeInformation)  */ ;/**  * Creates a python data stream from the given iterator.  *  * <p>Note that this operation will result in a non-parallel data stream source, i.e.,  * a data stream source with a parallelism of one.</p>  *  * @param iter The iterator of elements to create the data stream from  * @return The data stream representing the elements in the iterator  * @see StreamExecutionEnvironment#fromCollection(java.util.Iterator, org.apache.flink.api.common.typeinfo.TypeInformation)  */ public PythonDataStream from_collection(Iterator<Object> iter) throws Exception {     return new PythonDataStream<>(env.addSource(new PythonIteratorFunction(iter), TypeExtractor.getForClass(Object.class)).map(new AdapterMap<>())). }
true;public;2;3;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#generateSequence(long, long)}.  *  * @param from The number to start at (inclusive)  * @param to The number to stop at (inclusive)  * @return A python data stream, containing all number in the [from, to] interval  */ ;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#generateSequence(long, long)}.  *  * @param from The number to start at (inclusive)  * @param to The number to stop at (inclusive)  * @return A python data stream, containing all number in the [from, to] interval  */ public PythonDataStream generate_sequence(long from, long to) {     return new PythonDataStream<>(env.generateSequence(from, to).map(new AdapterMap<>())). }
false;public;1;3;;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#readTextFile(java.lang.String)}.  *  * @param path The path of the file, as a URI (e.g., "file:///some/local/file" or "hdfs://host:port/file/path").  * @return The data stream that represents the data read from the given file as text lines  * @throws IOException  */ public PythonDataStream read_text_file(String path) throws IOException {     return new PythonDataStream<>(env.readTextFile(path).map(new AdapterMap<String>())). }
true;public;2;3;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#socketTextStream(java.lang.String, int)}.  *  * @param host The host name which a server socket binds  * @param port The port number which a server socket binds. A port number of 0 means that the port number is automatically  * allocated.  * @return A python data stream containing the strings received from the socket  */ ;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#socketTextStream(java.lang.String, int)}.  *  * @param host The host name which a server socket binds  * @param port The port number which a server socket binds. A port number of 0 means that the port number is automatically  * allocated.  * @return A python data stream containing the strings received from the socket  */ public PythonDataStream socket_text_stream(String host, int port) {     return new PythonDataStream<>(env.socketTextStream(host, port).map(new AdapterMap<String>())). }
true;public;1;4;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#enableCheckpointing(long)}.  *  * @param interval Time interval between state checkpoints in milliseconds.  * @return The same {@code PythonStreamExecutionEnvironment} instance of the caller  */ ;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#enableCheckpointing(long)}.  *  * @param interval Time interval between state checkpoints in milliseconds.  * @return The same {@code PythonStreamExecutionEnvironment} instance of the caller  */ public PythonStreamExecutionEnvironment enable_checkpointing(long interval) {     this.env.enableCheckpointing(interval).     return this. }
true;public;2;4;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#enableCheckpointing(long, CheckpointingMode)}.  *  * @param interval Time interval between state checkpoints in milliseconds.  * @param mode The checkpointing mode, selecting between "exactly once" and "at least once" guaranteed.  * @return The same {@code PythonStreamExecutionEnvironment} instance of the caller  */ ;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#enableCheckpointing(long, CheckpointingMode)}.  *  * @param interval Time interval between state checkpoints in milliseconds.  * @param mode The checkpointing mode, selecting between "exactly once" and "at least once" guaranteed.  * @return The same {@code PythonStreamExecutionEnvironment} instance of the caller  */ public PythonStreamExecutionEnvironment enable_checkpointing(long interval, CheckpointingMode mode) {     this.env.enableCheckpointing(interval, mode).     return this. }
true;public;1;4;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#setParallelism(int)}.  *  * @param parallelism The parallelism  * @return The same {@code PythonStreamExecutionEnvironment} instance of the caller  */ ;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#setParallelism(int)}.  *  * @param parallelism The parallelism  * @return The same {@code PythonStreamExecutionEnvironment} instance of the caller  */ public PythonStreamExecutionEnvironment set_parallelism(int parallelism) {     this.env.setParallelism(parallelism).     return this. }
true;public;0;5;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#execute()}.  *  * @return The result of the job execution  */ ;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#execute()}.  *  * @return The result of the job execution  */ public JobExecutionResult execute() throws Exception {     distributeFiles().     JobExecutionResult result = this.env.execute().     return result. }
true;public;1;5;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#execute(java.lang.String)}.  *  * @return The result of the job execution, containing elapsed time and accumulators.  * @throws Exception which occurs during job execution.  */ ;/**  * A thin wrapper layer over {@link StreamExecutionEnvironment#execute(java.lang.String)}.  *  * @return The result of the job execution, containing elapsed time and accumulators.  * @throws Exception which occurs during job execution.  */ public JobExecutionResult execute(String job_name) throws Exception {     distributeFiles().     JobExecutionResult result = this.env.execute(job_name).     return result. }
false;private;0;3;;private void distributeFiles() throws IOException {     this.env.registerCachedFile(pythonTmpCachePath.getPath(), PythonConstants.FLINK_PYTHON_DC_ID). }
