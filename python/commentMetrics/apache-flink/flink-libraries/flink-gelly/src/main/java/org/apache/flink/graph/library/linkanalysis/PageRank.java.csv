commented;modifiers;parameterAmount;loc;comment;code
true;public;1;5;/**  * This PageRank implementation properly handles both source and sink  * vertices which have, respectively, only outgoing and incoming edges.  *  * <p>Setting this flag includes "zero-degree" vertices in the PageRank  * computation and result. These vertices are handled the same as other  * "source" vertices (with a consistent score of  * <code>(1 - damping factor) / number of vertices</code>) but only  * affect the scores of other vertices indirectly through the taking of  * this proportional portion of the "random jump" score.  *  * <p>The cost to include zero-degree vertices is a reduce for uniqueness  * on the vertex set followed by an outer join on the vertex degree  * DataSet.  *  * @param includeZeroDegreeVertices whether to include zero-degree vertices in the iterative computation  * @return this  */ ;/**  * This PageRank implementation properly handles both source and sink  * vertices which have, respectively, only outgoing and incoming edges.  *  * <p>Setting this flag includes "zero-degree" vertices in the PageRank  * computation and result. These vertices are handled the same as other  * "source" vertices (with a consistent score of  * <code>(1 - damping factor) / number of vertices</code>) but only  * affect the scores of other vertices indirectly through the taking of  * this proportional portion of the "random jump" score.  *  * <p>The cost to include zero-degree vertices is a reduce for uniqueness  * on the vertex set followed by an outer join on the vertex degree  * DataSet.  *  * @param includeZeroDegreeVertices whether to include zero-degree vertices in the iterative computation  * @return this  */ public PageRank<K, VV, EV> setIncludeZeroDegreeVertices(boolean includeZeroDegreeVertices) {     this.includeZeroDegreeVertices = includeZeroDegreeVertices.     return this. }
false;protected;1;11;;@Override protected boolean canMergeConfigurationWith(GraphAlgorithmWrappingBase other) {     if (!super.canMergeConfigurationWith(other)) {         return false.     }     PageRank rhs = (PageRank) other.     return dampingFactor == rhs.dampingFactor && includeZeroDegreeVertices == rhs.includeZeroDegreeVertices. }
false;protected;1;9;;@Override protected void mergeConfiguration(GraphAlgorithmWrappingBase other) {     super.mergeConfiguration(other).     PageRank rhs = (PageRank) other.     maxIterations = Math.max(maxIterations, rhs.maxIterations).     convergenceThreshold = Math.min(convergenceThreshold, rhs.convergenceThreshold). }
false;public;1;89;;@Override public DataSet<Result<K>> runInternal(Graph<K, VV, EV> input) throws Exception {     // vertex degree     DataSet<Vertex<K, Degrees>> vertexDegree = input.run(new VertexDegrees<K, VV, EV>().setIncludeZeroDegreeVertices(includeZeroDegreeVertices).setParallelism(parallelism)).     // vertex count     DataSet<LongValue> vertexCount = GraphUtils.count(vertexDegree).     // s, t, d(s)     DataSet<Edge<K, LongValue>> edgeSourceDegree = input.run(new EdgeSourceDegrees<K, VV, EV>().setParallelism(parallelism)).map(new ExtractSourceDegree<>()).setParallelism(parallelism).name("Extract source degree").     // vertices with zero in-edges     DataSet<Tuple2<K, DoubleValue>> sourceVertices = vertexDegree.flatMap(new InitializeSourceVertices<>()).setParallelism(parallelism).name("Initialize source vertex scores").     // s, initial pagerank(s)     DataSet<Tuple2<K, DoubleValue>> initialScores = vertexDegree.map(new InitializeVertexScores<>()).withBroadcastSet(vertexCount, VERTEX_COUNT).setParallelism(parallelism).name("Initialize scores").     IterativeDataSet<Tuple2<K, DoubleValue>> iterative = initialScores.iterate(maxIterations).setParallelism(parallelism).     // s, projected pagerank(s)     DataSet<Tuple2<K, DoubleValue>> vertexScores = iterative.coGroup(edgeSourceDegree).where(0).equalTo(0).with(new SendScore<>()).setParallelism(parallelism).name("Send score").groupBy(0).reduce(new SumScore<>()).setCombineHint(CombineHint.HASH).setParallelism(parallelism).name("Sum").     // ignored ID, total pagerank     DataSet<Tuple2<K, DoubleValue>> sumOfScores = vertexScores.reduce(new SumVertexScores<>()).setParallelism(parallelism).name("Sum").     // s, adjusted pagerank(s)     DataSet<Tuple2<K, DoubleValue>> adjustedScores = vertexScores.union(sourceVertices).name("Union with source vertices").map(new AdjustScores<>(dampingFactor)).withBroadcastSet(sumOfScores, SUM_OF_SCORES).withBroadcastSet(vertexCount, VERTEX_COUNT).setParallelism(parallelism).name("Adjust scores").     DataSet<Tuple2<K, DoubleValue>> passThrough.     if (convergenceThreshold < Double.MAX_VALUE) {         passThrough = iterative.join(adjustedScores).where(0).equalTo(0).with(new ChangeInScores<>()).setParallelism(parallelism).name("Change in scores").         iterative.registerAggregationConvergenceCriterion(CHANGE_IN_SCORES, new DoubleSumAggregator(), new ScoreConvergence(convergenceThreshold)).     } else {         passThrough = adjustedScores.     }     return iterative.closeWith(passThrough).map(new TranslateResult<>()).setParallelism(parallelism).name("Map result"). }
false;public;1;8;;@Override public Edge<T, LongValue> map(Edge<T, Tuple2<ET, Degrees>> edge) throws Exception {     output.f0 = edge.f0.     output.f1 = edge.f1.     output.f2 = edge.f2.f1.getOutDegree().     return output. }
false;public;2;8;;@Override public void flatMap(Vertex<T, Degrees> vertex, Collector<Tuple2<T, DoubleValue>> out) throws Exception {     if (vertex.f1.getInDegree().getValue() == 0) {         output.f0 = vertex.f0.         out.collect(output).     } }
false;public;1;9;;@Override public void open(Configuration parameters) throws Exception {     super.open(parameters).     Collection<LongValue> vertexCount = getRuntimeContext().getBroadcastVariable(VERTEX_COUNT).     Iterator<LongValue> vertexCountIterator = vertexCount.iterator().     output.f1 = new DoubleValue(vertexCountIterator.hasNext() ? 1.0 / vertexCountIterator.next().getValue() : Double.NaN). }
false;public;1;6;;@Override public Tuple2<T, DoubleValue> map(Vertex<T, Degrees> vertex) throws Exception {     output.f0 = vertex.f0.     return output. }
false;public;3;19;;@Override public void coGroup(Iterable<Tuple2<T, DoubleValue>> vertex, Iterable<Edge<T, LongValue>> edges, Collector<Tuple2<T, DoubleValue>> out) throws Exception {     Iterator<Edge<T, LongValue>> edgeIterator = edges.iterator().     if (edgeIterator.hasNext()) {         Edge<T, LongValue> edge = edgeIterator.next().         output.f0 = edge.f1.         output.f1.setValue(vertex.iterator().next().f1.getValue() / edge.f2.getValue()).         out.collect(output).         while (edgeIterator.hasNext()) {             edge = edgeIterator.next().             output.f0 = edge.f1.             out.collect(output).         }     } }
false;public;2;6;;@Override public Tuple2<T, DoubleValue> reduce(Tuple2<T, DoubleValue> first, Tuple2<T, DoubleValue> second) throws Exception {     first.f1.setValue(first.f1.getValue() + second.f1.getValue()).     return first. }
false;public;1;15;;@Override public void open(Configuration parameters) throws Exception {     super.open(parameters).     Collection<Tuple2<T, DoubleValue>> sumOfScores = getRuntimeContext().getBroadcastVariable(SUM_OF_SCORES).     Iterator<Tuple2<T, DoubleValue>> sumOfScoresIterator = sumOfScores.iterator().     // floating point precision error is also included in sumOfSinks     double sumOfSinks = 1 - (sumOfScoresIterator.hasNext() ? sumOfScoresIterator.next().f1.getValue() : 0).     Collection<LongValue> vertexCount = getRuntimeContext().getBroadcastVariable(VERTEX_COUNT).     Iterator<LongValue> vertexCountIterator = vertexCount.iterator().     this.vertexCount = vertexCountIterator.hasNext() ? vertexCountIterator.next().getValue() : 0.     this.uniformlyDistributedScore = ((1 - dampingFactor) + dampingFactor * sumOfSinks) / this.vertexCount. }
false;public;1;5;;@Override public Tuple2<T, DoubleValue> map(Tuple2<T, DoubleValue> value) throws Exception {     value.f1.setValue(uniformlyDistributedScore + (dampingFactor * value.f1.getValue())).     return value. }
false;public;1;6;;@Override public void open(Configuration parameters) throws Exception {     super.open(parameters).     changeInScores = 0.0. }
false;public;0;8;;@Override public void close() throws Exception {     super.close().     DoubleSumAggregator agg = getIterationRuntimeContext().getIterationAggregator(CHANGE_IN_SCORES).     agg.aggregate(changeInScores). }
false;public;2;6;;@Override public Tuple2<T, DoubleValue> join(Tuple2<T, DoubleValue> first, Tuple2<T, DoubleValue> second) throws Exception {     changeInScores += Math.abs(second.f1.getValue() - first.f1.getValue()).     return second. }
false;public;2;5;;@Override public boolean isConverged(int iteration, DoubleValue value) {     double val = value.getValue().     return (val <= convergenceThreshold). }
false;public;1;6;;@Override public Result<T> map(Tuple2<T, DoubleValue> value) throws Exception {     output.setVertexId0(value.f0).     output.setPageRankScore(value.f1).     return output. }
true;public;0;3;/**  * Get the PageRank score.  *  * @return the PageRank score  */ ;/**  * Get the PageRank score.  *  * @return the PageRank score  */ public DoubleValue getPageRankScore() {     return pageRankScore. }
true;public;1;3;/**  * Set the PageRank score.  *  * @param pageRankScore the PageRank score  */ ;/**  * Set the PageRank score.  *  * @param pageRankScore the PageRank score  */ public void setPageRankScore(DoubleValue pageRankScore) {     this.pageRankScore = pageRankScore. }
false;public;0;6;;@Override public String toString() {     return "(" + getVertexId0() + "," + pageRankScore + ")". }
false;public;0;5;;@Override public String toPrintableString() {     return "Vertex ID: " + getVertexId0() + ", PageRank score: " + pageRankScore. }
false;public;0;11;;@Override public int hashCode() {     if (hasher == null) {         hasher = new MurmurHash(HASH_SEED).     }     return hasher.reset().hash(getVertexId0().hashCode()).hash(pageRankScore.getValue()).hash(). }
