commented;modifiers;parameterAmount;loc;comment;code
false;public,static;0;12;;@BeforeClass public static void setup() throws Exception {     zkServer = new TestingServer().     storageDir = FOLDER.newFolder().getAbsolutePath().     // startYARNWithConfig should be implemented by subclass     YARN_CONFIGURATION.setClass(YarnConfiguration.RM_SCHEDULER, CapacityScheduler.class, ResourceScheduler.class).     YARN_CONFIGURATION.set(YarnTestBase.TEST_CLUSTER_NAME_KEY, LOG_DIR).     YARN_CONFIGURATION.setInt(YarnConfiguration.NM_PMEM_MB, 4096).     startYARNWithConfig(YARN_CONFIGURATION). }
false;public,static;0;7;;@AfterClass public static void teardown() throws Exception {     if (zkServer != null) {         zkServer.stop().         zkServer = null.     } }
false;public;0;4;;@Before public void setUp() throws Exception {     initJobGraph(). }
false;private;0;10;;private void initJobGraph() throws IOException {     stopJobSignal = YarnTestJob.StopJobSignal.usingMarkerFile(FOLDER.newFile().toPath()).     job = YarnTestJob.stoppableJob(stopJobSignal).     final File testingJar = YarnTestBase.findFile("..", new YarnTestUtils.TestJarFinder("flink-yarn-tests")).     assertThat(testingJar, notNullValue()).     job.addJar(new org.apache.flink.core.fs.Path(testingJar.toURI())). }
true;public;0;27;/**  * Tests that Yarn will restart a killed {@link YarnSessionClusterEntrypoint} which will then resume  * a persisted {@link JobGraph}.  */ ;/**  * Tests that Yarn will restart a killed {@link YarnSessionClusterEntrypoint} which will then resume  * a persisted {@link JobGraph}.  */ @Test public void testKillYarnSessionClusterEntrypoint() throws Exception {     assumeTrue("This test kills processes via the pkill command. Thus, it only runs on Linux, Mac OS, Free BSD and Solaris.", OperatingSystem.isLinux() || OperatingSystem.isMac() || OperatingSystem.isFreeBSD() || OperatingSystem.isSolaris()).     final YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor().     yarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles())).     final RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor).     try {         final JobID jobId = submitJob(restClusterClient).         final ApplicationId id = restClusterClient.getClusterId().         waitUntilJobIsRunning(restClusterClient, jobId).         killApplicationMaster(yarnClusterDescriptor.getYarnSessionClusterEntrypoint()).         waitForApplicationAttempt(id, 2).         waitForJobTermination(restClusterClient, jobId).         killApplicationAndWait(id).     } finally {         restClusterClient.shutdown().     } }
false;public;0;20;;@Test public void testJobRecoversAfterKillingTaskManager() throws Exception {     final YarnClusterDescriptor yarnClusterDescriptor = setupYarnClusterDescriptor().     yarnClusterDescriptor.addShipFiles(Arrays.asList(flinkShadedHadoopDir.listFiles())).     final RestClusterClient<ApplicationId> restClusterClient = deploySessionCluster(yarnClusterDescriptor).     try {         final JobID jobId = submitJob(restClusterClient).         waitUntilJobIsRunning(restClusterClient, jobId).         stopTaskManagerContainer().         waitUntilJobIsRestarted(restClusterClient, jobId, 1).         waitForJobTermination(restClusterClient, jobId).         killApplicationAndWait(restClusterClient.getClusterId()).     } finally {         restClusterClient.shutdown().     } }
false;private;2;9;;private void waitForApplicationAttempt(final ApplicationId applicationId, final int attemptId) throws Exception {     final YarnClient yarnClient = getYarnClient().     checkState(yarnClient != null, "yarnClient must be initialized").     CommonTestUtils.waitUntilCondition(() -> {         final ApplicationReport applicationReport = yarnClient.getApplicationReport(applicationId).         return applicationReport.getCurrentApplicationAttemptId().getAttemptId() >= attemptId.     }, Deadline.fromNow(TIMEOUT)). }
true;private;0;33;/**  * Stops a container running {@link YarnTaskExecutorRunner}.  */ ;/**  * Stops a container running {@link YarnTaskExecutorRunner}.  */ private void stopTaskManagerContainer() throws Exception {     // find container id of taskManager:     ContainerId taskManagerContainer = null.     NodeManager nodeManager = null.     NMTokenIdentifier nmIdent = null.     UserGroupInformation remoteUgi = UserGroupInformation.getCurrentUser().     for (int nmId = 0. nmId < NUM_NODEMANAGERS. nmId++) {         NodeManager nm = yarnCluster.getNodeManager(nmId).         ConcurrentMap<ContainerId, Container> containers = nm.getNMContext().getContainers().         for (Map.Entry<ContainerId, Container> entry : containers.entrySet()) {             String command = StringUtils.join(entry.getValue().getLaunchContext().getCommands(), " ").             if (command.contains(YarnTaskExecutorRunner.class.getSimpleName())) {                 taskManagerContainer = entry.getKey().                 nodeManager = nm.                 nmIdent = new NMTokenIdentifier(taskManagerContainer.getApplicationAttemptId(), null, "", 0).                 // allow myself to do stuff with the container                 // remoteUgi.addCredentials(entry.getValue().getCredentials()).                 remoteUgi.addTokenIdentifier(nmIdent).             }         }     }     assertNotNull("Unable to find container with TaskManager", taskManagerContainer).     assertNotNull("Illegal state", nodeManager).     StopContainersRequest scr = StopContainersRequest.newInstance(Collections.singletonList(taskManagerContainer)).     nodeManager.getNMContext().getContainerManager().stopContainers(scr).     // cleanup auth for the subsequent tests.     remoteUgi.getTokenIdentifiers().remove(nmIdent). }
false;private;1;9;;private void killApplicationAndWait(final ApplicationId id) throws Exception {     final YarnClient yarnClient = getYarnClient().     checkState(yarnClient != null, "yarnClient must be initialized").     yarnClient.killApplication(id).     CommonTestUtils.waitUntilCondition(() -> !yarnClient.getApplications(EnumSet.of(YarnApplicationState.KILLED, YarnApplicationState.FINISHED)).isEmpty(), Deadline.fromNow(TIMEOUT)). }
false;private;2;7;;private void waitForJobTermination(final RestClusterClient<ApplicationId> restClusterClient, final JobID jobId) throws Exception {     stopJobSignal.signal().     final CompletableFuture<JobResult> jobResult = restClusterClient.requestJobResult(jobId).     jobResult.get(TIMEOUT.toMillis(), TimeUnit.MILLISECONDS). }
false;private;0;17;;@Nonnull private YarnClusterDescriptor setupYarnClusterDescriptor() {     final Configuration flinkConfiguration = new Configuration().     flinkConfiguration.setString(YarnConfigOptions.APPLICATION_ATTEMPTS, "10").     flinkConfiguration.setString(HighAvailabilityOptions.HA_MODE, "zookeeper").     flinkConfiguration.setString(HighAvailabilityOptions.HA_STORAGE_PATH, storageDir).     flinkConfiguration.setString(HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zkServer.getConnectString()).     flinkConfiguration.setInteger(HighAvailabilityOptions.ZOOKEEPER_SESSION_TIMEOUT, 1000).     flinkConfiguration.setString(ConfigConstants.RESTART_STRATEGY, "fixed-delay").     flinkConfiguration.setInteger(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_ATTEMPTS, Integer.MAX_VALUE).     final int minMemory = 100.     flinkConfiguration.setInteger(ResourceManagerOptions.CONTAINERIZED_HEAP_CUTOFF_MIN, minMemory).     return createYarnClusterDescriptor(flinkConfiguration). }
false;private;1;12;;private RestClusterClient<ApplicationId> deploySessionCluster(YarnClusterDescriptor yarnClusterDescriptor) throws ClusterDeploymentException {     final int containerMemory = 256.     final ClusterClient<ApplicationId> yarnClusterClient = yarnClusterDescriptor.deploySessionCluster(new ClusterSpecification.ClusterSpecificationBuilder().setMasterMemoryMB(containerMemory).setTaskManagerMemoryMB(containerMemory).setSlotsPerTaskManager(1).createClusterSpecification()).     assertThat(yarnClusterClient, is(instanceOf(RestClusterClient.class))).     return (RestClusterClient<ApplicationId>) yarnClusterClient. }
false;private;1;7;;private JobID submitJob(RestClusterClient<ApplicationId> restClusterClient) throws InterruptedException, java.util.concurrent.ExecutionException {     final CompletableFuture<JobSubmissionResult> jobSubmissionResultCompletableFuture = restClusterClient.submitJob(job).     final JobSubmissionResult jobSubmissionResult = jobSubmissionResultCompletableFuture.get().     return jobSubmissionResult.getJobID(). }
false;private;1;4;;private void killApplicationMaster(final String processName) throws IOException, InterruptedException {     final Process exec = Runtime.getRuntime().exec("pkill -f " + processName).     assertThat(exec.waitFor(), is(0)). }
false;private,static;2;11;;private static void waitUntilJobIsRunning(RestClusterClient<ApplicationId> restClusterClient, JobID jobId) throws Exception {     CommonTestUtils.waitUntilCondition(() -> {         final JobDetailsInfo jobDetails = restClusterClient.getJobDetails(jobId).get().         return jobDetails.getJobVertexInfos().stream().map(toExecutionState()).allMatch(isRunning()).     }, Deadline.fromNow(TIMEOUT)). }
false;private,static;0;3;;private static Function<JobDetailsInfo.JobVertexDetailsInfo, ExecutionState> toExecutionState() {     return JobDetailsInfo.JobVertexDetailsInfo::getExecutionState. }
false;private,static;0;3;;private static Predicate<ExecutionState> isRunning() {     return executionState -> executionState == ExecutionState.RUNNING. }
false;private,static;3;8;;private static void waitUntilJobIsRestarted(final RestClusterClient<ApplicationId> restClusterClient, final JobID jobId, final int expectedFullRestarts) throws Exception {     CommonTestUtils.waitUntilCondition(() -> getJobFullRestarts(restClusterClient, jobId) >= expectedFullRestarts, Deadline.fromNow(TIMEOUT)). }
false;private,static;2;9;;private static int getJobFullRestarts(final RestClusterClient<ApplicationId> restClusterClient, final JobID jobId) throws Exception {     return getJobMetric(restClusterClient, jobId, "fullRestarts").map(Metric::getValue).map(Integer::parseInt).orElse(0). }
false;private,static;3;18;;private static Optional<Metric> getJobMetric(final RestClusterClient<ApplicationId> restClusterClient, final JobID jobId, final String metricName) throws Exception {     final JobMetricsMessageParameters messageParameters = new JobMetricsMessageParameters().     messageParameters.jobPathParameter.resolve(jobId).     messageParameters.metricsFilterParameter.resolveFromString(metricName).     final Collection<Metric> metrics = restClusterClient.sendRequest(JobMetricsHeaders.getInstance(), messageParameters, EmptyRequestBody.getInstance()).get().getMetrics().     final Metric metric = Iterables.getOnlyElement(metrics, null).     checkState(metric == null || metric.getId().equals(metricName)).     return Optional.ofNullable(metric). }
