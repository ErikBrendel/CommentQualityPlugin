# id;timestamp;commentText;codeText;commentWords;codeWords
StateMachineExample -> public static void main(String[] args) throws Exception;1518989074;Main entry point for the program.__@param args The command line arguments.;public static void main(String[] args) throws Exception {__		__		System.out.println("Usage with built-in data generator: StateMachineExample [--error-rate <probability-of-invalid-transition>] [--sleep <sleep-per-record-in-ms>]")__		System.out.println("Usage with Kafka: StateMachineExample --kafka-topic <topic> [--brokers <brokers>]")__		System.out.println()___		__		final SourceFunction<Event> source__		final ParameterTool params = ParameterTool.fromArgs(args)___		if (params.has("kafka-topic")) {_			_			String kafkaTopic = params.get("kafka-topic")__			String brokers = params.get("brokers", "localhost:9092")___			System.out.printf("Reading from kafka topic %s @ %s\n", kafkaTopic, brokers)__			System.out.println()___			Properties kafkaProps = new Properties()__			kafkaProps.setProperty("bootstrap.servers", brokers)___			FlinkKafkaConsumer010<Event> kafka = new FlinkKafkaConsumer010<>(kafkaTopic, new EventDeSerializer(), kafkaProps)__			kafka.setStartFromLatest()__			kafka.setCommitOffsetsOnCheckpoints(false)__			source = kafka__		}_		else {_			double errorRate = params.getDouble("error-rate", 0.0)__			int sleep = params.getInt("sleep", 1)___			System.out.printf("Using standalone source with error rate %f and sleep delay %s millis\n", errorRate, sleep)__			System.out.println()___			source = new EventsGeneratorSource(errorRate, sleep)__		}__		__		_		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.enableCheckpointing(5000)___		DataStream<Event> events = env.addSource(source)___		DataStream<Alert> alerts = events_				_				_				.keyBy(Event::sourceAddress)__				_				.flatMap(new StateMachineMapper())___		_		alerts.print()___		_		env.execute()__	};main,entry,point,for,the,program,param,args,the,command,line,arguments;public,static,void,main,string,args,throws,exception,system,out,println,usage,with,built,in,data,generator,state,machine,example,error,rate,probability,of,invalid,transition,sleep,sleep,per,record,in,ms,system,out,println,usage,with,kafka,state,machine,example,kafka,topic,topic,brokers,brokers,system,out,println,final,source,function,event,source,final,parameter,tool,params,parameter,tool,from,args,args,if,params,has,kafka,topic,string,kafka,topic,params,get,kafka,topic,string,brokers,params,get,brokers,localhost,9092,system,out,printf,reading,from,kafka,topic,s,s,n,kafka,topic,brokers,system,out,println,properties,kafka,props,new,properties,kafka,props,set,property,bootstrap,servers,brokers,flink,kafka,consumer010,event,kafka,new,flink,kafka,consumer010,kafka,topic,new,event,de,serializer,kafka,props,kafka,set,start,from,latest,kafka,set,commit,offsets,on,checkpoints,false,source,kafka,else,double,error,rate,params,get,double,error,rate,0,0,int,sleep,params,get,int,sleep,1,system,out,printf,using,standalone,source,with,error,rate,f,and,sleep,delay,s,millis,n,error,rate,sleep,system,out,println,source,new,events,generator,source,error,rate,sleep,final,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,enable,checkpointing,5000,data,stream,event,events,env,add,source,source,data,stream,alert,alerts,events,key,by,event,source,address,flat,map,new,state,machine,mapper,alerts,print,env,execute
StateMachineExample -> public static void main(String[] args) throws Exception;1522044831;Main entry point for the program.__@param args The command line arguments.;public static void main(String[] args) throws Exception {__		__		System.out.println("Usage with built-in data generator: StateMachineExample [--error-rate <probability-of-invalid-transition>] [--sleep <sleep-per-record-in-ms>]")__		System.out.println("Usage with Kafka: StateMachineExample --kafka-topic <topic> [--brokers <brokers>]")__		System.out.println()___		__		final SourceFunction<Event> source__		final ParameterTool params = ParameterTool.fromArgs(args)___		if (params.has("kafka-topic")) {_			_			String kafkaTopic = params.get("kafka-topic")__			String brokers = params.get("brokers", "localhost:9092")___			System.out.printf("Reading from kafka topic %s @ %s\n", kafkaTopic, brokers)__			System.out.println()___			Properties kafkaProps = new Properties()__			kafkaProps.setProperty("bootstrap.servers", brokers)___			FlinkKafkaConsumer010<Event> kafka = new FlinkKafkaConsumer010<>(kafkaTopic, new EventDeSerializer(), kafkaProps)__			kafka.setStartFromLatest()__			kafka.setCommitOffsetsOnCheckpoints(false)__			source = kafka__		}_		else {_			double errorRate = params.getDouble("error-rate", 0.0)__			int sleep = params.getInt("sleep", 1)___			System.out.printf("Using standalone source with error rate %f and sleep delay %s millis\n", errorRate, sleep)__			System.out.println()___			source = new EventsGeneratorSource(errorRate, sleep)__		}__		__		_		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.enableCheckpointing(5000)___		DataStream<Event> events = env.addSource(source)___		DataStream<Alert> alerts = events_				_				_				.keyBy(Event::sourceAddress)__				_				.flatMap(new StateMachineMapper())___		_		alerts.print()___		_		env.execute("State machine job")__	};main,entry,point,for,the,program,param,args,the,command,line,arguments;public,static,void,main,string,args,throws,exception,system,out,println,usage,with,built,in,data,generator,state,machine,example,error,rate,probability,of,invalid,transition,sleep,sleep,per,record,in,ms,system,out,println,usage,with,kafka,state,machine,example,kafka,topic,topic,brokers,brokers,system,out,println,final,source,function,event,source,final,parameter,tool,params,parameter,tool,from,args,args,if,params,has,kafka,topic,string,kafka,topic,params,get,kafka,topic,string,brokers,params,get,brokers,localhost,9092,system,out,printf,reading,from,kafka,topic,s,s,n,kafka,topic,brokers,system,out,println,properties,kafka,props,new,properties,kafka,props,set,property,bootstrap,servers,brokers,flink,kafka,consumer010,event,kafka,new,flink,kafka,consumer010,kafka,topic,new,event,de,serializer,kafka,props,kafka,set,start,from,latest,kafka,set,commit,offsets,on,checkpoints,false,source,kafka,else,double,error,rate,params,get,double,error,rate,0,0,int,sleep,params,get,int,sleep,1,system,out,printf,using,standalone,source,with,error,rate,f,and,sleep,delay,s,millis,n,error,rate,sleep,system,out,println,source,new,events,generator,source,error,rate,sleep,final,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,enable,checkpointing,5000,data,stream,event,events,env,add,source,source,data,stream,alert,alerts,events,key,by,event,source,address,flat,map,new,state,machine,mapper,alerts,print,env,execute,state,machine,job
StateMachineExample -> public static void main(String[] args) throws Exception;1522749453;Main entry point for the program.__@param args The command line arguments.;public static void main(String[] args) throws Exception {__		__		System.out.println("Usage with built-in data generator: StateMachineExample [--error-rate <probability-of-invalid-transition>] [--sleep <sleep-per-record-in-ms>]")__		System.out.println("Usage with Kafka: StateMachineExample --kafka-topic <topic> [--brokers <brokers>]")__		System.out.println("Options for both the above setups: ")__		System.out.println("\t[--backend <file|rocks>]")__		System.out.println("\t[--checkpoint-dir <filepath>]")__		System.out.println("\t[--async-checkpoints <true|false>]")__		System.out.println("\t[--incremental-checkpoints <true|false>]")__		System.out.println("\t[--output <filepath> OR null for stdout]")__		System.out.println()___		__		final SourceFunction<Event> source__		final ParameterTool params = ParameterTool.fromArgs(args)___		if (params.has("kafka-topic")) {_			_			String kafkaTopic = params.get("kafka-topic")__			String brokers = params.get("brokers", "localhost:9092")___			System.out.printf("Reading from kafka topic %s @ %s\n", kafkaTopic, brokers)__			System.out.println()___			Properties kafkaProps = new Properties()__			kafkaProps.setProperty("bootstrap.servers", brokers)___			FlinkKafkaConsumer010<Event> kafka = new FlinkKafkaConsumer010<>(kafkaTopic, new EventDeSerializer(), kafkaProps)__			kafka.setStartFromLatest()__			kafka.setCommitOffsetsOnCheckpoints(false)__			source = kafka__		}_		else {_			double errorRate = params.getDouble("error-rate", 0.0)__			int sleep = params.getInt("sleep", 1)___			System.out.printf("Using standalone source with error rate %f and sleep delay %s millis\n", errorRate, sleep)__			System.out.println()___			source = new EventsGeneratorSource(errorRate, sleep)__		}__		__		_		final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment()__		env.enableCheckpointing(2000L)___		final String stateBackend = params.get("backend", "memory")__		if ("file".equals(stateBackend)) {_			final String checkpointDir = params.get("checkpoint-dir")__			boolean asyncCheckpoints = params.getBoolean("async-checkpoints", false)__			env.setStateBackend(new FsStateBackend(checkpointDir, asyncCheckpoints))__		} else if ("rocks".equals(stateBackend)) {_			final String checkpointDir = params.get("checkpoint-dir")__			boolean incrementalCheckpoints = params.getBoolean("incremental-checkpoints", false)__			env.setStateBackend(new RocksDBStateBackend(checkpointDir, incrementalCheckpoints))__		}__		final String outputFile = params.get("output")___		_		env.getConfig().setGlobalJobParameters(params)___		DataStream<Event> events = env.addSource(source)___		DataStream<Alert> alerts = events_				_				_				.keyBy(Event::sourceAddress)__				_				.flatMap(new StateMachineMapper())___		_		if (outputFile == null) {_			alerts.print()__		} else {_			alerts_				.writeAsText(outputFile, FileSystem.WriteMode.OVERWRITE)_				.setParallelism(1)__		}__		_		env.execute("State machine job")__	};main,entry,point,for,the,program,param,args,the,command,line,arguments;public,static,void,main,string,args,throws,exception,system,out,println,usage,with,built,in,data,generator,state,machine,example,error,rate,probability,of,invalid,transition,sleep,sleep,per,record,in,ms,system,out,println,usage,with,kafka,state,machine,example,kafka,topic,topic,brokers,brokers,system,out,println,options,for,both,the,above,setups,system,out,println,t,backend,file,rocks,system,out,println,t,checkpoint,dir,filepath,system,out,println,t,async,checkpoints,true,false,system,out,println,t,incremental,checkpoints,true,false,system,out,println,t,output,filepath,or,null,for,stdout,system,out,println,final,source,function,event,source,final,parameter,tool,params,parameter,tool,from,args,args,if,params,has,kafka,topic,string,kafka,topic,params,get,kafka,topic,string,brokers,params,get,brokers,localhost,9092,system,out,printf,reading,from,kafka,topic,s,s,n,kafka,topic,brokers,system,out,println,properties,kafka,props,new,properties,kafka,props,set,property,bootstrap,servers,brokers,flink,kafka,consumer010,event,kafka,new,flink,kafka,consumer010,kafka,topic,new,event,de,serializer,kafka,props,kafka,set,start,from,latest,kafka,set,commit,offsets,on,checkpoints,false,source,kafka,else,double,error,rate,params,get,double,error,rate,0,0,int,sleep,params,get,int,sleep,1,system,out,printf,using,standalone,source,with,error,rate,f,and,sleep,delay,s,millis,n,error,rate,sleep,system,out,println,source,new,events,generator,source,error,rate,sleep,final,stream,execution,environment,env,stream,execution,environment,get,execution,environment,env,enable,checkpointing,2000l,final,string,state,backend,params,get,backend,memory,if,file,equals,state,backend,final,string,checkpoint,dir,params,get,checkpoint,dir,boolean,async,checkpoints,params,get,boolean,async,checkpoints,false,env,set,state,backend,new,fs,state,backend,checkpoint,dir,async,checkpoints,else,if,rocks,equals,state,backend,final,string,checkpoint,dir,params,get,checkpoint,dir,boolean,incremental,checkpoints,params,get,boolean,incremental,checkpoints,false,env,set,state,backend,new,rocks,dbstate,backend,checkpoint,dir,incremental,checkpoints,final,string,output,file,params,get,output,env,get,config,set,global,job,parameters,params,data,stream,event,events,env,add,source,source,data,stream,alert,alerts,events,key,by,event,source,address,flat,map,new,state,machine,mapper,if,output,file,null,alerts,print,else,alerts,write,as,text,output,file,file,system,write,mode,overwrite,set,parallelism,1,env,execute,state,machine,job
