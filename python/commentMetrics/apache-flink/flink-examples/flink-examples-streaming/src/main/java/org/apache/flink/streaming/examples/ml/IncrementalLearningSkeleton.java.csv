commented;modifiers;parameterAmount;loc;comment;code
false;public,static;1;31;;// ************************************************************************* // PROGRAM // ************************************************************************* public static void main(String[] args) throws Exception {     // Checking input parameters     final ParameterTool params = ParameterTool.fromArgs(args).     StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment().     env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime).     DataStream<Integer> trainingData = env.addSource(new FiniteTrainingDataSource()).     DataStream<Integer> newData = env.addSource(new FiniteNewDataSource()).     // build new model on every second of new data     DataStream<Double[]> model = trainingData.assignTimestampsAndWatermarks(new LinearTimestamp()).timeWindowAll(Time.of(5000, TimeUnit.MILLISECONDS)).apply(new PartialModelBuilder()).     // use partial model for newData     DataStream<Integer> prediction = newData.connect(model).map(new Predictor()).     // emit result     if (params.has("output")) {         prediction.writeAsText(params.get("output")).     } else {         System.out.println("Printing result to stdout. Use --output to specify output path.").         prediction.print().     }     // execute program     env.execute("Streaming Incremental Learning"). }
false;public;1;7;;@Override public void run(SourceContext<Integer> ctx) throws Exception {     Thread.sleep(15).     while (counter < 50) {         ctx.collect(getNewData()).     } }
false;public;0;4;;@Override public void cancel() { // No cleanup needed }
false;private;0;5;;private Integer getNewData() throws InterruptedException {     Thread.sleep(5).     counter++.     return 1. }
false;public;1;6;;@Override public void run(SourceContext<Integer> collector) throws Exception {     while (counter < 8200) {         collector.collect(getTrainingData()).     } }
false;public;0;4;;@Override public void cancel() { // No cleanup needed }
false;private;0;4;;private Integer getTrainingData() throws InterruptedException {     counter++.     return 1. }
false;public;2;4;;@Override public long extractTimestamp(Integer element, long previousElementTimestamp) {     return counter += 10L. }
false;public;2;4;;@Override public Watermark checkAndGetNextWatermark(Integer lastElement, long extractedTimestamp) {     return new Watermark(counter - 1). }
false;protected;1;3;;protected Double[] buildPartialModel(Iterable<Integer> values) {     return new Double[] { 1. }. }
false;public;3;4;;@Override public void apply(TimeWindow window, Iterable<Integer> values, Collector<Double[]> out) throws Exception {     out.collect(buildPartialModel(values)). }
false;public;1;5;;@Override public Integer map1(Integer value) {     // Return newData     return predict(value). }
false;public;1;7;;@Override public Integer map2(Double[] value) {     // Update model     partialModel = value.     batchModel = getBatchModel().     return 1. }
true;protected;0;3;// pulls model built with batch-job on the old training data ;// pulls model built with batch-job on the old training data protected Double[] getBatchModel() {     return new Double[] { 0. }. }
true;protected;1;3;// performs newData using the two models ;// performs newData using the two models protected Integer predict(Integer inTuple) {     return 0. }
