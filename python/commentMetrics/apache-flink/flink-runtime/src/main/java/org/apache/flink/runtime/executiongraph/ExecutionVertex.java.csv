commented;modifiers;parameterAmount;loc;comment;code
false;public;0;3;;// -------------------------------------------------------------------------------------------- // Properties // -------------------------------------------------------------------------------------------- public JobID getJobId() {     return this.jobVertex.getJobId(). }
false;public;0;3;;public ExecutionJobVertex getJobVertex() {     return jobVertex. }
false;public;0;3;;public JobVertexID getJobvertexId() {     return this.jobVertex.getJobVertexId(). }
false;public;0;3;;public String getTaskName() {     return this.jobVertex.getJobVertex().getName(). }
true;public;0;4;/**  * Creates a simple name representation in the style 'taskname (x/y)', where  * 'taskname' is the name as returned by {@link #getTaskName()}, 'x' is the parallel  * subtask index as returned by {@link #getParallelSubtaskIndex()}{@code + 1}, and 'y' is the total  * number of tasks, as returned by {@link #getTotalNumberOfParallelSubtasks()}.  *  * @return A simple name representation in the form 'myTask (2/7)'  */ ;/**  * Creates a simple name representation in the style 'taskname (x/y)', where  * 'taskname' is the name as returned by {@link #getTaskName()}, 'x' is the parallel  * subtask index as returned by {@link #getParallelSubtaskIndex()}{@code + 1}, and 'y' is the total  * number of tasks, as returned by {@link #getTotalNumberOfParallelSubtasks()}.  *  * @return A simple name representation in the form 'myTask (2/7)'  */ @Override public String getTaskNameWithSubtaskIndex() {     return this.taskNameWithSubtask. }
false;public;0;3;;public int getTotalNumberOfParallelSubtasks() {     return this.jobVertex.getParallelism(). }
false;public;0;3;;public int getMaxParallelism() {     return this.jobVertex.getMaxParallelism(). }
false;public;0;4;;@Override public int getParallelSubtaskIndex() {     return this.subTaskIndex. }
false;public;0;3;;public int getNumberOfInputs() {     return this.inputEdges.length. }
false;public;1;6;;public ExecutionEdge[] getInputEdges(int input) {     if (input < 0 || input >= this.inputEdges.length) {         throw new IllegalArgumentException(String.format("Input %d is out of range [0..%d)", input, this.inputEdges.length)).     }     return inputEdges[input]. }
false;public;0;3;;public CoLocationConstraint getLocationConstraint() {     return locationConstraint. }
false;public;0;4;;@Override public Execution getCurrentExecutionAttempt() {     return currentExecution. }
false;public;0;4;;@Override public ExecutionState getExecutionState() {     return currentExecution.getState(). }
false;public;1;4;;@Override public long getStateTimestamp(ExecutionState state) {     return currentExecution.getStateTimestamp(state). }
false;public;0;4;;@Override public String getFailureCauseAsString() {     return ExceptionUtils.stringifyException(getFailureCause()). }
false;public;0;3;;public Throwable getFailureCause() {     return currentExecution.getFailureCause(). }
false;public;0;3;;public CompletableFuture<TaskManagerLocation> getCurrentTaskManagerLocationFuture() {     return currentExecution.getTaskManagerLocationFuture(). }
false;public;0;3;;public LogicalSlot getCurrentAssignedResource() {     return currentExecution.getAssignedResource(). }
false;public;0;4;;@Override public TaskManagerLocation getCurrentAssignedResourceLocation() {     return currentExecution.getAssignedResourceLocation(). }
false;public;1;10;;@Override public ArchivedExecution getPriorExecutionAttempt(int attemptNumber) {     synchronized (priorExecutions) {         if (attemptNumber >= 0 && attemptNumber < priorExecutions.size()) {             return priorExecutions.get(attemptNumber).         } else {             throw new IllegalArgumentException("attempt does not exist").         }     } }
false;public;0;11;;public ArchivedExecution getLatestPriorExecution() {     synchronized (priorExecutions) {         final int size = priorExecutions.size().         if (size > 0) {             return priorExecutions.get(size - 1).         } else {             return null.         }     } }
true;public;0;4;/**  * Gets the location where the latest completed/canceled/failed execution of the vertex's  * task happened.  *  * @return The latest prior execution location, or null, if there is none, yet.  */ ;/**  * Gets the location where the latest completed/canceled/failed execution of the vertex's  * task happened.  *  * @return The latest prior execution location, or null, if there is none, yet.  */ public TaskManagerLocation getLatestPriorLocation() {     ArchivedExecution latestPriorExecution = getLatestPriorExecution().     return latestPriorExecution != null ? latestPriorExecution.getAssignedResourceLocation() : null. }
false;public;0;4;;public AllocationID getLatestPriorAllocation() {     ArchivedExecution latestPriorExecution = getLatestPriorExecution().     return latestPriorExecution != null ? latestPriorExecution.getAssignedAllocationID() : null. }
false;;0;5;;EvictingBoundedList<ArchivedExecution> getCopyOfPriorExecutionsList() {     synchronized (priorExecutions) {         return new EvictingBoundedList<>(priorExecutions).     } }
false;public;0;3;;public ExecutionGraph getExecutionGraph() {     return this.jobVertex.getGraph(). }
false;public;0;3;;public Map<IntermediateResultPartitionID, IntermediateResultPartition> getProducedPartitions() {     return resultPartitions. }
false;public;0;3;;public InputDependencyConstraint getInputDependencyConstraint() {     return getJobVertex().getInputDependencyConstraint(). }
false;public;4;30;;// -------------------------------------------------------------------------------------------- // Graph building // -------------------------------------------------------------------------------------------- public void connectSource(int inputNumber, IntermediateResult source, JobEdge edge, int consumerNumber) {     final DistributionPattern pattern = edge.getDistributionPattern().     final IntermediateResultPartition[] sourcePartitions = source.getPartitions().     ExecutionEdge[] edges.     switch(pattern) {         case POINTWISE:             edges = connectPointwise(sourcePartitions, inputNumber).             break.         case ALL_TO_ALL:             edges = connectAllToAll(sourcePartitions, inputNumber).             break.         default:             throw new RuntimeException("Unrecognized distribution pattern.").     }     this.inputEdges[inputNumber] = edges.     // edges as the execution graph     for (ExecutionEdge ee : edges) {         ee.getSource().addConsumer(ee, consumerNumber).     } }
false;private;2;10;;private ExecutionEdge[] connectAllToAll(IntermediateResultPartition[] sourcePartitions, int inputNumber) {     ExecutionEdge[] edges = new ExecutionEdge[sourcePartitions.length].     for (int i = 0. i < sourcePartitions.length. i++) {         IntermediateResultPartition irp = sourcePartitions[i].         edges[i] = new ExecutionEdge(irp, this, inputNumber).     }     return edges. }
false;private;2;56;;private ExecutionEdge[] connectPointwise(IntermediateResultPartition[] sourcePartitions, int inputNumber) {     final int numSources = sourcePartitions.length.     final int parallelism = getTotalNumberOfParallelSubtasks().     // simple case same number of sources as targets     if (numSources == parallelism) {         return new ExecutionEdge[] { new ExecutionEdge(sourcePartitions[subTaskIndex], this, inputNumber) }.     } else if (numSources < parallelism) {         int sourcePartition.         // we use int arithmetics for regular, and floating point with rounding for irregular         if (parallelism % numSources == 0) {             // same number of targets per source             int factor = parallelism / numSources.             sourcePartition = subTaskIndex / factor.         } else {             // different number of targets per source             float factor = ((float) parallelism) / numSources.             sourcePartition = (int) (subTaskIndex / factor).         }         return new ExecutionEdge[] { new ExecutionEdge(sourcePartitions[sourcePartition], this, inputNumber) }.     } else {         if (numSources % parallelism == 0) {             // same number of targets per source             int factor = numSources / parallelism.             int startIndex = subTaskIndex * factor.             ExecutionEdge[] edges = new ExecutionEdge[factor].             for (int i = 0. i < factor. i++) {                 edges[i] = new ExecutionEdge(sourcePartitions[startIndex + i], this, inputNumber).             }             return edges.         } else {             float factor = ((float) numSources) / parallelism.             int start = (int) (subTaskIndex * factor).             int end = (subTaskIndex == getTotalNumberOfParallelSubtasks() - 1) ? sourcePartitions.length : (int) ((subTaskIndex + 1) * factor).             ExecutionEdge[] edges = new ExecutionEdge[end - start].             for (int i = 0. i < edges.length. i++) {                 edges[i] = new ExecutionEdge(sourcePartitions[start + i], this, inputNumber).             }             return edges.         }     } }
true;public;0;4;/**  * Gets the overall preferred execution location for this vertex's current execution.  * The preference is determined as follows:  *  * <ol>  *     <li>If the task execution has state to load (from a checkpoint), then the location preference  *         is the location of the previous execution (if there is a previous execution attempt).  *     <li>If the task execution has no state or no previous location, then the location preference  *         is based on the task's inputs.  * </ol>  *  * <p>These rules should result in the following behavior:  *  * <ul>  *     <li>Stateless tasks are always scheduled based on co-location with inputs.  *     <li>Stateful tasks are on their initial attempt executed based on co-location with inputs.  *     <li>Repeated executions of stateful tasks try to co-locate the execution with its state.  * </ul>  *  * @see #getPreferredLocationsBasedOnState()  * @see #getPreferredLocationsBasedOnInputs()  *  * @return The preferred execution locations for the execution attempt.  */ ;/**  * Gets the overall preferred execution location for this vertex's current execution.  * The preference is determined as follows:  *  * <ol>  *     <li>If the task execution has state to load (from a checkpoint), then the location preference  *         is the location of the previous execution (if there is a previous execution attempt).  *     <li>If the task execution has no state or no previous location, then the location preference  *         is based on the task's inputs.  * </ol>  *  * <p>These rules should result in the following behavior:  *  * <ul>  *     <li>Stateless tasks are always scheduled based on co-location with inputs.  *     <li>Stateful tasks are on their initial attempt executed based on co-location with inputs.  *     <li>Repeated executions of stateful tasks try to co-locate the execution with its state.  * </ul>  *  * @see #getPreferredLocationsBasedOnState()  * @see #getPreferredLocationsBasedOnInputs()  *  * @return The preferred execution locations for the execution attempt.  */ public Collection<CompletableFuture<TaskManagerLocation>> getPreferredLocations() {     Collection<CompletableFuture<TaskManagerLocation>> basedOnState = getPreferredLocationsBasedOnState().     return basedOnState != null ? basedOnState : getPreferredLocationsBasedOnInputs(). }
true;public;0;9;/**  * Gets the preferred location to execute the current task execution attempt, based on the state  * that the execution attempt will resume.  *  * @return A size-one collection with the location preference, or null, if there is no  *         location preference based on the state.  */ ;/**  * Gets the preferred location to execute the current task execution attempt, based on the state  * that the execution attempt will resume.  *  * @return A size-one collection with the location preference, or null, if there is no  *         location preference based on the state.  */ public Collection<CompletableFuture<TaskManagerLocation>> getPreferredLocationsBasedOnState() {     TaskManagerLocation priorLocation.     if (currentExecution.getTaskRestore() != null && (priorLocation = getLatestPriorLocation()) != null) {         return Collections.singleton(CompletableFuture.completedFuture(priorLocation)).     } else {         return null.     } }
true;public;0;39;/**  * Gets the location preferences of the vertex's current task execution, as determined by the locations  * of the predecessors from which it receives input data.  * If there are more than MAX_DISTINCT_LOCATIONS_TO_CONSIDER different locations of source data, this  * method returns {@code null} to indicate no location preference.  *  * @return The preferred locations based in input streams, or an empty iterable,  *         if there is no input-based preference.  */ ;/**  * Gets the location preferences of the vertex's current task execution, as determined by the locations  * of the predecessors from which it receives input data.  * If there are more than MAX_DISTINCT_LOCATIONS_TO_CONSIDER different locations of source data, this  * method returns {@code null} to indicate no location preference.  *  * @return The preferred locations based in input streams, or an empty iterable,  *         if there is no input-based preference.  */ public Collection<CompletableFuture<TaskManagerLocation>> getPreferredLocationsBasedOnInputs() {     // otherwise, base the preferred locations on the input connections     if (inputEdges == null) {         return Collections.emptySet().     } else {         Set<CompletableFuture<TaskManagerLocation>> locations = new HashSet<>(getTotalNumberOfParallelSubtasks()).         Set<CompletableFuture<TaskManagerLocation>> inputLocations = new HashSet<>(getTotalNumberOfParallelSubtasks()).         // go over all inputs         for (int i = 0. i < inputEdges.length. i++) {             inputLocations.clear().             ExecutionEdge[] sources = inputEdges[i].             if (sources != null) {                 // go over all input sources                 for (int k = 0. k < sources.length. k++) {                     // look-up assigned slot of input source                     CompletableFuture<TaskManagerLocation> locationFuture = sources[k].getSource().getProducer().getCurrentTaskManagerLocationFuture().                     // add input location                     inputLocations.add(locationFuture).                     // inputs which have too many distinct sources are not considered                     if (inputLocations.size() > MAX_DISTINCT_LOCATIONS_TO_CONSIDER) {                         inputLocations.clear().                         break.                     }                 }             }             // keep the locations of the input with the least preferred locations             if (// nothing assigned yet             locations.isEmpty() || (!inputLocations.isEmpty() && inputLocations.size() < locations.size())) {                 // current input has fewer preferred locations                 locations.clear().                 locations.addAll(inputLocations).             }         }         return locations.isEmpty() ? Collections.emptyList() : locations.     } }
true;public;2;50;/**  * Archives the current Execution and creates a new Execution for this vertex.  *  * <p>This method atomically checks if the ExecutionGraph is still of an expected  * global mod. version and replaces the execution if that is the case. If the ExecutionGraph  * has increased its global mod. version in the meantime, this operation fails.  *  * <p>This mechanism can be used to prevent conflicts between various concurrent recovery and  * reconfiguration actions in a similar way as "optimistic concurrency control".  *  * @param timestamp  *             The creation timestamp for the new Execution  * @param originatingGlobalModVersion  *  * @return Returns the new created Execution.  *  * @throws GlobalModVersionMismatch Thrown, if the execution graph has a new global mod  *                                  version than the one passed to this message.  */ ;// -------------------------------------------------------------------------------------------- // Actions // -------------------------------------------------------------------------------------------- /**  * Archives the current Execution and creates a new Execution for this vertex.  *  * <p>This method atomically checks if the ExecutionGraph is still of an expected  * global mod. version and replaces the execution if that is the case. If the ExecutionGraph  * has increased its global mod. version in the meantime, this operation fails.  *  * <p>This mechanism can be used to prevent conflicts between various concurrent recovery and  * reconfiguration actions in a similar way as "optimistic concurrency control".  *  * @param timestamp  *             The creation timestamp for the new Execution  * @param originatingGlobalModVersion  *  * @return Returns the new created Execution.  *  * @throws GlobalModVersionMismatch Thrown, if the execution graph has a new global mod  *                                  version than the one passed to this message.  */ public Execution resetForNewExecution(final long timestamp, final long originatingGlobalModVersion) throws GlobalModVersionMismatch {     LOG.debug("Resetting execution vertex {} for new execution.", getTaskNameWithSubtaskIndex()).     synchronized (priorExecutions) {         // check if another global modification has been triggered since the         // action that originally caused this reset/restart happened         final long actualModVersion = getExecutionGraph().getGlobalModVersion().         if (actualModVersion > originatingGlobalModVersion) {             // global change happened since, reject this action             throw new GlobalModVersionMismatch(originatingGlobalModVersion, actualModVersion).         }         final Execution oldExecution = currentExecution.         final ExecutionState oldState = oldExecution.getState().         if (oldState.isTerminal()) {             priorExecutions.add(oldExecution.archive()).             final Execution newExecution = new Execution(getExecutionGraph().getFutureExecutor(), this, oldExecution.getAttemptNumber() + 1, originatingGlobalModVersion, timestamp, timeout).             this.currentExecution = newExecution.             CoLocationGroup grp = jobVertex.getCoLocationGroup().             if (grp != null) {                 this.locationConstraint = grp.getLocationConstraint(subTaskIndex).             }             // register this execution at the execution graph, to receive call backs             getExecutionGraph().registerExecution(newExecution).             // we take one step back on the road to reaching global FINISHED             if (oldState == FINISHED) {                 getExecutionGraph().vertexUnFinished().             }             return newExecution.         } else {             throw new IllegalStateException("Cannot reset a vertex that is in non-terminal state " + oldState).         }     } }
true;public;4;11;/**  * Schedules the current execution of this ExecutionVertex.  *  * @param slotProvider to allocate the slots from  * @param queued if the allocation can be queued  * @param locationPreferenceConstraint constraint for the location preferences  * @param allPreviousExecutionGraphAllocationIds set with all previous allocation ids in the job graph.  *                                                 Can be empty if the allocation ids are not required for scheduling.  * @return Future which is completed once the execution is deployed. The future  * can also completed exceptionally.  */ ;/**  * Schedules the current execution of this ExecutionVertex.  *  * @param slotProvider to allocate the slots from  * @param queued if the allocation can be queued  * @param locationPreferenceConstraint constraint for the location preferences  * @param allPreviousExecutionGraphAllocationIds set with all previous allocation ids in the job graph.  *                                                 Can be empty if the allocation ids are not required for scheduling.  * @return Future which is completed once the execution is deployed. The future  * can also completed exceptionally.  */ public CompletableFuture<Void> scheduleForExecution(SlotProvider slotProvider, boolean queued, LocationPreferenceConstraint locationPreferenceConstraint, @Nonnull Set<AllocationID> allPreviousExecutionGraphAllocationIds) {     return this.currentExecution.scheduleForExecution(slotProvider, queued, locationPreferenceConstraint, allPreviousExecutionGraphAllocationIds). }
false;public;1;9;;@VisibleForTesting public void deployToSlot(LogicalSlot slot) throws JobException {     if (this.currentExecution.tryAssignResource(slot)) {         this.currentExecution.deploy().     } else {         throw new IllegalStateException("Could not assign resource " + slot + " to current execution " + currentExecution + '.').     } }
true;public;0;7;/**  * Cancels this ExecutionVertex.  *  * @return A future that completes once the execution has reached its final state.  */ ;/**  * Cancels this ExecutionVertex.  *  * @return A future that completes once the execution has reached its final state.  */ public CompletableFuture<?> cancel() {     // to avoid any case of mixup in the presence of concurrent calls,     // we copy a reference to the stack to make sure both calls go to the same Execution     final Execution exec = this.currentExecution.     exec.cancel().     return exec.getReleaseFuture(). }
false;public;0;3;;public CompletableFuture<?> suspend() {     return currentExecution.suspend(). }
false;public;0;3;;public void stop() {     this.currentExecution.stop(). }
false;public;1;3;;public void fail(Throwable t) {     this.currentExecution.fail(t). }
true;;1;26;/**  * Schedules or updates the consumer tasks of the result partition with the given ID.  */ ;/**  * Schedules or updates the consumer tasks of the result partition with the given ID.  */ void scheduleOrUpdateConsumers(ResultPartitionID partitionId) {     final Execution execution = currentExecution.     // Abort this request if there was a concurrent reset     if (!partitionId.getProducerId().equals(execution.getAttemptId())) {         return.     }     final IntermediateResultPartition partition = resultPartitions.get(partitionId.getPartitionId()).     if (partition == null) {         throw new IllegalStateException("Unknown partition " + partitionId + ".").     }     partition.markDataProduced().     if (partition.getIntermediateResult().getResultType().isPipelined()) {         // Schedule or update receivers of this partition         execution.scheduleOrUpdateConsumers(partition.getConsumers()).     } else {         throw new IllegalArgumentException("ScheduleOrUpdateConsumers msg is only valid for" + "pipelined partitions.").     } }
false;public;1;3;;public void cachePartitionInfo(PartialInputChannelDeploymentDescriptor partitionInfo) {     getCurrentExecutionAttempt().cachePartitionInfo(partitionInfo). }
false;;0;3;;void sendPartitionInfos() {     currentExecution.sendPartitionInfos(). }
true;;0;20;/**  * Returns all blocking result partitions whose receivers can be scheduled/updated.  */ ;/**  * Returns all blocking result partitions whose receivers can be scheduled/updated.  */ List<IntermediateResultPartition> finishAllBlockingPartitions() {     List<IntermediateResultPartition> finishedBlockingPartitions = null.     for (IntermediateResultPartition partition : resultPartitions.values()) {         if (partition.getResultType().isBlocking() && partition.markFinished()) {             if (finishedBlockingPartitions == null) {                 finishedBlockingPartitions = new LinkedList<IntermediateResultPartition>().             }             finishedBlockingPartitions.add(partition).         }     }     if (finishedBlockingPartitions == null) {         return Collections.emptyList().     } else {         return finishedBlockingPartitions.     } }
true;;0;9;/**  * Check whether the InputDependencyConstraint is satisfied for this vertex.  *  * @return whether the input constraint is satisfied  */ ;/**  * Check whether the InputDependencyConstraint is satisfied for this vertex.  *  * @return whether the input constraint is satisfied  */ boolean checkInputDependencyConstraints() {     if (getInputDependencyConstraint() == InputDependencyConstraint.ANY) {         // InputDependencyConstraint == ANY         return IntStream.range(0, inputEdges.length).anyMatch(this::isInputConsumable).     } else {         // InputDependencyConstraint == ALL         return IntStream.range(0, inputEdges.length).allMatch(this::isInputConsumable).     } }
true;;1;4;/**  * Get whether an input of the vertex is consumable.  * An input is consumable when when any partition in it is consumable.  *  * Note that a BLOCKING result partition is only consumable when all partitions in the result are FINISHED.  *  * @return whether the input is consumable  */ ;/**  * Get whether an input of the vertex is consumable.  * An input is consumable when when any partition in it is consumable.  *  * Note that a BLOCKING result partition is only consumable when all partitions in the result are FINISHED.  *  * @return whether the input is consumable  */ boolean isInputConsumable(int inputNumber) {     return Arrays.stream(inputEdges[inputNumber]).map(ExecutionEdge::getSource).anyMatch(IntermediateResultPartition::isConsumable). }
false;;1;3;;// -------------------------------------------------------------------------------------------- // Notifications from the Execution Attempt // -------------------------------------------------------------------------------------------- void executionFinished(Execution execution) {     getExecutionGraph().vertexFinished(). }
false;;1;3;;void executionCanceled(Execution execution) { // nothing to do }
false;;2;3;;void executionFailed(Execution execution, Throwable cause) { // nothing to do }
true;;3;7;/**  * Simply forward this notification.  */ ;// -------------------------------------------------------------------------------------------- // Miscellaneous // -------------------------------------------------------------------------------------------- /**  * Simply forward this notification.  */ void notifyStateTransition(Execution execution, ExecutionState newState, Throwable error) {     // otherwise we have an outdated execution     if (currentExecution == execution) {         getExecutionGraph().notifyExecutionChange(execution, newState, error).     } }
true;;4;96;/**  * Creates a task deployment descriptor to deploy a subtask to the given target slot.  * TODO: This should actually be in the EXECUTION  */ ;/**  * Creates a task deployment descriptor to deploy a subtask to the given target slot.  * TODO: This should actually be in the EXECUTION  */ TaskDeploymentDescriptor createDeploymentDescriptor(ExecutionAttemptID executionId, LogicalSlot targetSlot, @Nullable JobManagerTaskRestore taskRestore, int attemptNumber) throws ExecutionGraphException {     // Produced intermediate results     List<ResultPartitionDeploymentDescriptor> producedPartitions = new ArrayList<>(resultPartitions.size()).     // Consumed intermediate results     List<InputGateDeploymentDescriptor> consumedPartitions = new ArrayList<>(inputEdges.length).     boolean lazyScheduling = getExecutionGraph().getScheduleMode().allowLazyDeployment().     for (IntermediateResultPartition partition : resultPartitions.values()) {         List<List<ExecutionEdge>> consumers = partition.getConsumers().         if (consumers.isEmpty()) {             // TODO this case only exists for test, currently there has to be exactly one consumer in real jobs!             producedPartitions.add(ResultPartitionDeploymentDescriptor.from(partition, KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM, lazyScheduling)).         } else {             Preconditions.checkState(1 == consumers.size(), "Only one consumer supported in the current implementation! Found: " + consumers.size()).             List<ExecutionEdge> consumer = consumers.get(0).             ExecutionJobVertex vertex = consumer.get(0).getTarget().getJobVertex().             int maxParallelism = vertex.getMaxParallelism().             producedPartitions.add(ResultPartitionDeploymentDescriptor.from(partition, maxParallelism, lazyScheduling)).         }     }     for (ExecutionEdge[] edges : inputEdges) {         InputChannelDeploymentDescriptor[] partitions = InputChannelDeploymentDescriptor.fromEdges(edges, targetSlot.getTaskManagerLocation().getResourceID(), lazyScheduling).         // If the produced partition has multiple consumers registered, we         // need to request the one matching our sub task index.         // TODO Refactor after removing the consumers from the intermediate result partitions         int numConsumerEdges = edges[0].getSource().getConsumers().get(0).size().         int queueToRequest = subTaskIndex % numConsumerEdges.         IntermediateResult consumedIntermediateResult = edges[0].getSource().getIntermediateResult().         final IntermediateDataSetID resultId = consumedIntermediateResult.getId().         final ResultPartitionType partitionType = consumedIntermediateResult.getResultType().         consumedPartitions.add(new InputGateDeploymentDescriptor(resultId, partitionType, queueToRequest, partitions)).     }     final Either<SerializedValue<JobInformation>, PermanentBlobKey> jobInformationOrBlobKey = getExecutionGraph().getJobInformationOrBlobKey().     final TaskDeploymentDescriptor.MaybeOffloaded<JobInformation> serializedJobInformation.     if (jobInformationOrBlobKey.isLeft()) {         serializedJobInformation = new TaskDeploymentDescriptor.NonOffloaded<>(jobInformationOrBlobKey.left()).     } else {         serializedJobInformation = new TaskDeploymentDescriptor.Offloaded<>(jobInformationOrBlobKey.right()).     }     final Either<SerializedValue<TaskInformation>, PermanentBlobKey> taskInformationOrBlobKey.     try {         taskInformationOrBlobKey = jobVertex.getTaskInformationOrBlobKey().     } catch (IOException e) {         throw new ExecutionGraphException("Could not create a serialized JobVertexInformation for " + jobVertex.getJobVertexId(), e).     }     final TaskDeploymentDescriptor.MaybeOffloaded<TaskInformation> serializedTaskInformation.     if (taskInformationOrBlobKey.isLeft()) {         serializedTaskInformation = new TaskDeploymentDescriptor.NonOffloaded<>(taskInformationOrBlobKey.left()).     } else {         serializedTaskInformation = new TaskDeploymentDescriptor.Offloaded<>(taskInformationOrBlobKey.right()).     }     return new TaskDeploymentDescriptor(getJobId(), serializedJobInformation, serializedTaskInformation, executionId, targetSlot.getAllocationId(), subTaskIndex, attemptNumber, targetSlot.getPhysicalSlotNumber(), taskRestore, producedPartitions, consumedPartitions). }
false;public;0;4;;// -------------------------------------------------------------------------------------------- // Utilities // -------------------------------------------------------------------------------------------- @Override public String toString() {     return getTaskNameWithSubtaskIndex(). }
false;public;0;4;;@Override public ArchivedExecutionVertex archive() {     return new ArchivedExecutionVertex(this). }
