commented;modifiers;parameterAmount;loc;comment;code
true;public;1;6;/**  * Start the rpc service and begin to run the job.  *  * @param newJobMasterId The necessary fencing token to run the job  * @return Future acknowledge if the job could be started. Otherwise the future contains an exception  */ ;// ---------------------------------------------------------------------------------------------- // Lifecycle management // ---------------------------------------------------------------------------------------------- /**  * Start the rpc service and begin to run the job.  *  * @param newJobMasterId The necessary fencing token to run the job  * @return Future acknowledge if the job could be started. Otherwise the future contains an exception  */ public CompletableFuture<Acknowledge> start(final JobMasterId newJobMasterId) throws Exception {     // make sure we receive RPC and async calls     start().     return callAsyncWithoutFencing(() -> startJobExecution(newJobMasterId), RpcUtils.INF_TIMEOUT). }
true;public;1;7;/**  * Suspending job, all the running tasks will be cancelled, and communication with other components  * will be disposed.  *  * <p>Mostly job is suspended because of the leadership has been revoked, one can be restart this job by  * calling the {@link #start(JobMasterId)} method once we take the leadership back again.  *  * <p>This method is executed asynchronously  *  * @param cause The reason of why this job been suspended.  * @return Future acknowledge indicating that the job has been suspended. Otherwise the future contains an exception  */ ;/**  * Suspending job, all the running tasks will be cancelled, and communication with other components  * will be disposed.  *  * <p>Mostly job is suspended because of the leadership has been revoked, one can be restart this job by  * calling the {@link #start(JobMasterId)} method once we take the leadership back again.  *  * <p>This method is executed asynchronously  *  * @param cause The reason of why this job been suspended.  * @return Future acknowledge indicating that the job has been suspended. Otherwise the future contains an exception  */ public CompletableFuture<Acknowledge> suspend(final Exception cause) {     CompletableFuture<Acknowledge> suspendFuture = callAsyncWithoutFencing(() -> suspendExecution(cause), RpcUtils.INF_TIMEOUT).     return suspendFuture.whenComplete((acknowledge, throwable) -> stop()). }
true;public;0;32;/**  * Suspend the job and shutdown all other services including rpc.  */ ;/**  * Suspend the job and shutdown all other services including rpc.  */ @Override public CompletableFuture<Void> onStop() {     log.info("Stopping the JobMaster for job {}({}).", jobGraph.getName(), jobGraph.getJobID()).     // disconnect from all registered TaskExecutors     final Set<ResourceID> taskManagerResourceIds = new HashSet<>(registeredTaskManagers.keySet()).     final FlinkException cause = new FlinkException("Stopping JobMaster for job " + jobGraph.getName() + '(' + jobGraph.getJobID() + ").").     for (ResourceID taskManagerResourceId : taskManagerResourceIds) {         disconnectTaskManager(taskManagerResourceId, cause).     }     taskManagerHeartbeatManager.stop().     resourceManagerHeartbeatManager.stop().     // make sure there is a graceful exit     suspendExecution(new FlinkException("JobManager is shutting down.")).     // shut down will internally release all registered slots     slotPool.close().     final CompletableFuture<Void> disposeInternalSavepointFuture.     if (lastInternalSavepoint != null) {         disposeInternalSavepointFuture = CompletableFuture.runAsync(() -> disposeSavepoint(lastInternalSavepoint)).     } else {         disposeInternalSavepointFuture = CompletableFuture.completedFuture(null).     }     return FutureUtils.completeAll(Collections.singletonList(disposeInternalSavepointFuture)). }
false;public;1;6;;// ---------------------------------------------------------------------------------------------- // RPC methods // ---------------------------------------------------------------------------------------------- @Override public CompletableFuture<Acknowledge> cancel(Time timeout) {     executionGraph.cancel().     return CompletableFuture.completedFuture(Acknowledge.get()). }
false;public;1;10;;@Override public CompletableFuture<Acknowledge> stop(Time timeout) {     try {         executionGraph.stop().     } catch (StoppingException e) {         return FutureUtils.completedExceptionally(e).     }     return CompletableFuture.completedFuture(Acknowledge.get()). }
false;public;3;13;;@Override public CompletableFuture<Acknowledge> rescaleJob(int newParallelism, RescalingBehaviour rescalingBehaviour, Time timeout) {     final ArrayList<JobVertexID> allOperators = new ArrayList<>(jobGraph.getNumberOfVertices()).     for (JobVertex jobVertex : jobGraph.getVertices()) {         allOperators.add(jobVertex.getID()).     }     return rescaleOperators(allOperators, newParallelism, rescalingBehaviour, timeout). }
false;public;4;109;;@Override public CompletableFuture<Acknowledge> rescaleOperators(Collection<JobVertexID> operators, int newParallelism, RescalingBehaviour rescalingBehaviour, Time timeout) {     if (newParallelism <= 0) {         return FutureUtils.completedExceptionally(new JobModificationException("The target parallelism of a rescaling operation must be larger than 0.")).     }     // 1. Check whether we can rescale the job & rescale the respective vertices     try {         rescaleJobGraph(operators, newParallelism, rescalingBehaviour).     } catch (FlinkException e) {         final String msg = String.format("Cannot rescale job %s.", jobGraph.getName()).         log.info(msg, e).         return FutureUtils.completedExceptionally(new JobModificationException(msg, e)).     }     final ExecutionGraph currentExecutionGraph = executionGraph.     final JobManagerJobMetricGroup newJobManagerJobMetricGroup = jobMetricGroupFactory.create(jobGraph).     final ExecutionGraph newExecutionGraph.     try {         newExecutionGraph = createExecutionGraph(newJobManagerJobMetricGroup).     } catch (JobExecutionException | JobException e) {         return FutureUtils.completedExceptionally(new JobModificationException("Could not create rescaled ExecutionGraph.", e)).     }     // 3. disable checkpoint coordinator to suppress subsequent checkpoints     final CheckpointCoordinator checkpointCoordinator = currentExecutionGraph.getCheckpointCoordinator().     checkpointCoordinator.stopCheckpointScheduler().     // 4. take a savepoint     final CompletableFuture<String> savepointFuture = getJobModificationSavepoint(timeout).     final CompletableFuture<ExecutionGraph> executionGraphFuture = restoreExecutionGraphFromRescalingSavepoint(newExecutionGraph, savepointFuture).handleAsync((ExecutionGraph executionGraph, Throwable failure) -> {         if (failure != null) {             // coordinator and abort the rescaling operation             if (checkpointCoordinator.isPeriodicCheckpointingConfigured()) {                 checkpointCoordinator.startCheckpointScheduler().             }             throw new CompletionException(ExceptionUtils.stripCompletionException(failure)).         } else {             return executionGraph.         }     }, getMainThreadExecutor()).     // 5. suspend the current job     final CompletableFuture<JobStatus> terminationFuture = executionGraphFuture.thenComposeAsync((ExecutionGraph ignored) -> {         suspendExecutionGraph(new FlinkException("Job is being rescaled.")).         return currentExecutionGraph.getTerminationFuture().     }, getMainThreadExecutor()).     final CompletableFuture<Void> suspendedFuture = terminationFuture.thenAccept((JobStatus jobStatus) -> {         if (jobStatus != JobStatus.SUSPENDED) {             final String msg = String.format("Job %s rescaling failed because we could not suspend the execution graph.", jobGraph.getName()).             log.info(msg).             throw new CompletionException(new JobModificationException(msg)).         }     }).     // 6. resume the new execution graph from the taken savepoint     final CompletableFuture<Acknowledge> rescalingFuture = suspendedFuture.thenCombineAsync(executionGraphFuture, (Void ignored, ExecutionGraph restoredExecutionGraph) -> {         // check if the ExecutionGraph is still the same         if (executionGraph == currentExecutionGraph) {             clearExecutionGraphFields().             assignExecutionGraph(restoredExecutionGraph, newJobManagerJobMetricGroup).             scheduleExecutionGraph().             return Acknowledge.get().         } else {             throw new CompletionException(new JobModificationException("Detected concurrent modification of ExecutionGraph. Aborting the rescaling.")).         }     }, getMainThreadExecutor()).     rescalingFuture.whenCompleteAsync((Acknowledge ignored, Throwable throwable) -> {         if (throwable != null) {             // fail the newly created execution graph             newExecutionGraph.failGlobal(new SuppressRestartsException(new FlinkException(String.format("Failed to rescale the job %s.", jobGraph.getJobID()), throwable))).         }     }, getMainThreadExecutor()).     return rescalingFuture. }
true;public;1;13;/**  * Updates the task execution state for a given task.  *  * @param taskExecutionState New task execution state for a given task  * @return Acknowledge the task execution state update  */ ;/**  * Updates the task execution state for a given task.  *  * @param taskExecutionState New task execution state for a given task  * @return Acknowledge the task execution state update  */ @Override public CompletableFuture<Acknowledge> updateTaskExecutionState(final TaskExecutionState taskExecutionState) {     checkNotNull(taskExecutionState, "taskExecutionState").     if (executionGraph.updateState(taskExecutionState)) {         return CompletableFuture.completedFuture(Acknowledge.get()).     } else {         return FutureUtils.completedExceptionally(new ExecutionGraphException("The execution attempt " + taskExecutionState.getID() + " was not found.")).     } }
false;public;2;48;;@Override public CompletableFuture<SerializedInputSplit> requestNextInputSplit(final JobVertexID vertexID, final ExecutionAttemptID executionAttempt) {     final Execution execution = executionGraph.getRegisteredExecutions().get(executionAttempt).     if (execution == null) {         // but TaskManager get some delay to aware of that situation         if (log.isDebugEnabled()) {             log.debug("Can not find Execution for attempt {}.", executionAttempt).         }         // but we should TaskManager be aware of this         return FutureUtils.completedExceptionally(new Exception("Can not find Execution for attempt " + executionAttempt)).     }     final ExecutionJobVertex vertex = executionGraph.getJobVertex(vertexID).     if (vertex == null) {         log.error("Cannot find execution vertex for vertex ID {}.", vertexID).         return FutureUtils.completedExceptionally(new Exception("Cannot find execution vertex for vertex ID " + vertexID)).     }     final InputSplitAssigner splitAssigner = vertex.getSplitAssigner().     if (splitAssigner == null) {         log.error("No InputSplitAssigner for vertex ID {}.", vertexID).         return FutureUtils.completedExceptionally(new Exception("No InputSplitAssigner for vertex ID " + vertexID)).     }     final LogicalSlot slot = execution.getAssignedResource().     final int taskId = execution.getVertex().getParallelSubtaskIndex().     final String host = slot != null ? slot.getTaskManagerLocation().getHostname() : null.     final InputSplit nextInputSplit = splitAssigner.getNextInputSplit(host, taskId).     if (log.isDebugEnabled()) {         log.debug("Send next input split {}.", nextInputSplit).     }     try {         final byte[] serializedInputSplit = InstantiationUtil.serializeObject(nextInputSplit).         return CompletableFuture.completedFuture(new SerializedInputSplit(serializedInputSplit)).     } catch (Exception ex) {         log.error("Could not serialize the next input split of class {}.", nextInputSplit.getClass(), ex).         IOException reason = new IOException("Could not serialize the next input split of class " + nextInputSplit.getClass() + ".", ex).         vertex.fail(reason).         return FutureUtils.completedExceptionally(reason).     } }
false;public;2;31;;@Override public CompletableFuture<ExecutionState> requestPartitionState(final IntermediateDataSetID intermediateResultId, final ResultPartitionID resultPartitionId) {     final Execution execution = executionGraph.getRegisteredExecutions().get(resultPartitionId.getProducerId()).     if (execution != null) {         return CompletableFuture.completedFuture(execution.getState()).     } else {         final IntermediateResult intermediateResult = executionGraph.getAllIntermediateResults().get(intermediateResultId).         if (intermediateResult != null) {             // Try to find the producing execution             Execution producerExecution = intermediateResult.getPartitionById(resultPartitionId.getPartitionId()).getProducer().getCurrentExecutionAttempt().             if (producerExecution.getAttemptId().equals(resultPartitionId.getProducerId())) {                 return CompletableFuture.completedFuture(producerExecution.getState()).             } else {                 return FutureUtils.completedExceptionally(new PartitionProducerDisposedException(resultPartitionId)).             }         } else {             return FutureUtils.completedExceptionally(new IllegalArgumentException("Intermediate data set with ID " + intermediateResultId + " not found.")).         }     } }
false;public;2;11;;@Override public CompletableFuture<Acknowledge> scheduleOrUpdateConsumers(final ResultPartitionID partitionID, final Time timeout) {     try {         executionGraph.scheduleOrUpdateConsumers(partitionID).         return CompletableFuture.completedFuture(Acknowledge.get()).     } catch (Exception e) {         return FutureUtils.completedExceptionally(e).     } }
false;public;2;15;;@Override public CompletableFuture<Acknowledge> disconnectTaskManager(final ResourceID resourceID, final Exception cause) {     log.debug("Disconnect TaskExecutor {} because: {}", resourceID, cause.getMessage()).     taskManagerHeartbeatManager.unmonitorTarget(resourceID).     slotPool.releaseTaskManager(resourceID, cause).     Tuple2<TaskManagerLocation, TaskExecutorGateway> taskManagerConnection = registeredTaskManagers.remove(resourceID).     if (taskManagerConnection != null) {         taskManagerConnection.f1.disconnectJobManager(jobGraph.getJobID(), cause).     }     return CompletableFuture.completedFuture(Acknowledge.get()). }
true;public;5;33;// TODO: This method needs a leader session ID ;// TODO: This method needs a leader session ID @Override public void acknowledgeCheckpoint(final JobID jobID, final ExecutionAttemptID executionAttemptID, final long checkpointId, final CheckpointMetrics checkpointMetrics, final TaskStateSnapshot checkpointState) {     final CheckpointCoordinator checkpointCoordinator = executionGraph.getCheckpointCoordinator().     final AcknowledgeCheckpoint ackMessage = new AcknowledgeCheckpoint(jobID, executionAttemptID, checkpointId, checkpointMetrics, checkpointState).     if (checkpointCoordinator != null) {         getRpcService().execute(() -> {             try {                 checkpointCoordinator.receiveAcknowledgeMessage(ackMessage).             } catch (Throwable t) {                 log.warn("Error while processing checkpoint acknowledgement message", t).             }         }).     } else {         String errorMessage = "Received AcknowledgeCheckpoint message for job {} with no CheckpointCoordinator".         if (executionGraph.getState() == JobStatus.RUNNING) {             log.error(errorMessage, jobGraph.getJobID()).         } else {             log.debug(errorMessage, jobGraph.getJobID()).         }     } }
true;public;1;21;// TODO: This method needs a leader session ID ;// TODO: This method needs a leader session ID @Override public void declineCheckpoint(DeclineCheckpoint decline) {     final CheckpointCoordinator checkpointCoordinator = executionGraph.getCheckpointCoordinator().     if (checkpointCoordinator != null) {         getRpcService().execute(() -> {             try {                 checkpointCoordinator.receiveDeclineMessage(decline).             } catch (Exception e) {                 log.error("Error in CheckpointCoordinator while processing {}", decline, e).             }         }).     } else {         String errorMessage = "Received DeclineCheckpoint message for job {} with no CheckpointCoordinator".         if (executionGraph.getState() == JobStatus.RUNNING) {             log.error(errorMessage, jobGraph.getJobID()).         } else {             log.debug(errorMessage, jobGraph.getJobID()).         }     } }
false;public;2;23;;@Override public CompletableFuture<KvStateLocation> requestKvStateLocation(final JobID jobId, final String registrationName) {     // sanity check for the correct JobID     if (jobGraph.getJobID().equals(jobId)) {         if (log.isDebugEnabled()) {             log.debug("Lookup key-value state for job {} with registration " + "name {}.", jobGraph.getJobID(), registrationName).         }         final KvStateLocationRegistry registry = executionGraph.getKvStateLocationRegistry().         final KvStateLocation location = registry.getKvStateLocation(registrationName).         if (location != null) {             return CompletableFuture.completedFuture(location).         } else {             return FutureUtils.completedExceptionally(new UnknownKvStateLocation(registrationName)).         }     } else {         if (log.isDebugEnabled()) {             log.debug("Request of key-value state location for unknown job {} received.", jobId).         }         return FutureUtils.completedExceptionally(new FlinkJobNotFoundException(jobId)).     } }
false;public;6;30;;@Override public CompletableFuture<Acknowledge> notifyKvStateRegistered(final JobID jobId, final JobVertexID jobVertexId, final KeyGroupRange keyGroupRange, final String registrationName, final KvStateID kvStateId, final InetSocketAddress kvStateServerAddress) {     if (jobGraph.getJobID().equals(jobId)) {         if (log.isDebugEnabled()) {             log.debug("Key value state registered for job {} under name {}.", jobGraph.getJobID(), registrationName).         }         try {             executionGraph.getKvStateLocationRegistry().notifyKvStateRegistered(jobVertexId, keyGroupRange, registrationName, kvStateId, kvStateServerAddress).             return CompletableFuture.completedFuture(Acknowledge.get()).         } catch (Exception e) {             log.error("Failed to notify KvStateRegistry about registration {}.", registrationName, e).             return FutureUtils.completedExceptionally(e).         }     } else {         if (log.isDebugEnabled()) {             log.debug("Notification about key-value state registration for unknown job {} received.", jobId).         }         return FutureUtils.completedExceptionally(new FlinkJobNotFoundException(jobId)).     } }
false;public;4;28;;@Override public CompletableFuture<Acknowledge> notifyKvStateUnregistered(JobID jobId, JobVertexID jobVertexId, KeyGroupRange keyGroupRange, String registrationName) {     if (jobGraph.getJobID().equals(jobId)) {         if (log.isDebugEnabled()) {             log.debug("Key value state unregistered for job {} under name {}.", jobGraph.getJobID(), registrationName).         }         try {             executionGraph.getKvStateLocationRegistry().notifyKvStateUnregistered(jobVertexId, keyGroupRange, registrationName).             return CompletableFuture.completedFuture(Acknowledge.get()).         } catch (Exception e) {             log.error("Failed to notify KvStateRegistry about unregistration {}.", registrationName, e).             return FutureUtils.completedExceptionally(e).         }     } else {         if (log.isDebugEnabled()) {             log.debug("Notification about key-value state deregistration for unknown job {} received.", jobId).         }         return FutureUtils.completedExceptionally(new FlinkJobNotFoundException(jobId)).     } }
false;public;3;23;;@Override public CompletableFuture<Collection<SlotOffer>> offerSlots(final ResourceID taskManagerId, final Collection<SlotOffer> slots, final Time timeout) {     Tuple2<TaskManagerLocation, TaskExecutorGateway> taskManager = registeredTaskManagers.get(taskManagerId).     if (taskManager == null) {         return FutureUtils.completedExceptionally(new Exception("Unknown TaskManager " + taskManagerId)).     }     final TaskManagerLocation taskManagerLocation = taskManager.f0.     final TaskExecutorGateway taskExecutorGateway = taskManager.f1.     final RpcTaskManagerGateway rpcTaskManagerGateway = new RpcTaskManagerGateway(taskExecutorGateway, getFencingToken()).     return CompletableFuture.completedFuture(slotPool.offerSlots(taskManagerLocation, rpcTaskManagerGateway, slots)). }
false;public;3;13;;@Override public void failSlot(final ResourceID taskManagerId, final AllocationID allocationId, final Exception cause) {     if (registeredTaskManagers.containsKey(taskManagerId)) {         internalFailAllocation(allocationId, cause).     } else {         log.warn("Cannot fail slot " + allocationId + " because the TaskManager " + taskManagerId + " is unknown.").     } }
false;private;2;4;;private void internalFailAllocation(AllocationID allocationId, Exception cause) {     final Optional<ResourceID> resourceIdOptional = slotPool.failAllocation(allocationId, cause).     resourceIdOptional.ifPresent(this::releaseEmptyTaskManager). }
false;private;1;3;;private void releaseEmptyTaskManager(ResourceID resourceId) {     disconnectTaskManager(resourceId, new FlinkException(String.format("No more slots registered at JobMaster %s.", resourceId))). }
false;public;2;4;;@Override public void receiveHeartbeat(ResourceID resourceID, Void payload) { // the task manager will not request heartbeat, so this method will never be called currently }
false;public;2;4;;@Override public void requestHeartbeat(ResourceID resourceID, Void payload) {     taskExecutorGateway.heartbeatFromJobManager(resourceID). }
false;public;3;41;;@Override public CompletableFuture<RegistrationResponse> registerTaskManager(final String taskManagerRpcAddress, final TaskManagerLocation taskManagerLocation, final Time timeout) {     final ResourceID taskManagerId = taskManagerLocation.getResourceID().     if (registeredTaskManagers.containsKey(taskManagerId)) {         final RegistrationResponse response = new JMTMRegistrationSuccess(resourceId).         return CompletableFuture.completedFuture(response).     } else {         return getRpcService().connect(taskManagerRpcAddress, TaskExecutorGateway.class).handleAsync((TaskExecutorGateway taskExecutorGateway, Throwable throwable) -> {             if (throwable != null) {                 return new RegistrationResponse.Decline(throwable.getMessage()).             }             slotPool.registerTaskManager(taskManagerId).             registeredTaskManagers.put(taskManagerId, Tuple2.of(taskManagerLocation, taskExecutorGateway)).             // monitor the task manager as heartbeat target             taskManagerHeartbeatManager.monitorTarget(taskManagerId, new HeartbeatTarget<Void>() {                  @Override                 public void receiveHeartbeat(ResourceID resourceID, Void payload) {                 // the task manager will not request heartbeat, so this method will never be called currently                 }                  @Override                 public void requestHeartbeat(ResourceID resourceID, Void payload) {                     taskExecutorGateway.heartbeatFromJobManager(resourceID).                 }             }).             return new JMTMRegistrationSuccess(resourceId).         }, getMainThreadExecutor()).     } }
false;public;2;9;;@Override public void disconnectResourceManager(final ResourceManagerId resourceManagerId, final Exception cause) {     if (isConnectingToResourceManager(resourceManagerId)) {         reconnectToResourceManager(cause).     } }
false;private;1;4;;private boolean isConnectingToResourceManager(ResourceManagerId resourceManagerId) {     return resourceManagerAddress != null && resourceManagerAddress.getResourceManagerId().equals(resourceManagerId). }
false;public;2;4;;@Override public void heartbeatFromTaskManager(final ResourceID resourceID, AccumulatorReport accumulatorReport) {     taskManagerHeartbeatManager.receiveHeartbeat(resourceID, accumulatorReport). }
false;public;1;4;;@Override public void heartbeatFromResourceManager(final ResourceID resourceID) {     resourceManagerHeartbeatManager.requestHeartbeat(resourceID, null). }
false;public;1;5;;@Override public CompletableFuture<JobDetails> requestJobDetails(Time timeout) {     final ExecutionGraph currentExecutionGraph = executionGraph.     return CompletableFuture.supplyAsync(() -> WebMonitorUtils.createDetailsForJob(currentExecutionGraph), scheduledExecutorService). }
false;public;1;4;;@Override public CompletableFuture<JobStatus> requestJobStatus(Time timeout) {     return CompletableFuture.completedFuture(executionGraph.getState()). }
false;public;1;4;;@Override public CompletableFuture<ArchivedExecutionGraph> requestJob(Time timeout) {     return CompletableFuture.completedFuture(ArchivedExecutionGraph.createFrom(executionGraph)). }
false;public;3;38;;@Override public CompletableFuture<String> triggerSavepoint(@Nullable final String targetDirectory, final boolean cancelJob, final Time timeout) {     final CheckpointCoordinator checkpointCoordinator = executionGraph.getCheckpointCoordinator().     if (checkpointCoordinator == null) {         return FutureUtils.completedExceptionally(new IllegalStateException(String.format("Job %s is not a streaming job.", jobGraph.getJobID()))).     } else if (targetDirectory == null && !checkpointCoordinator.getCheckpointStorage().hasDefaultSavepointLocation()) {         log.info("Trying to cancel job {} with savepoint, but no savepoint directory configured.", jobGraph.getJobID()).         return FutureUtils.completedExceptionally(new IllegalStateException("No savepoint directory configured. You can either specify a directory " + "while cancelling via -s :targetDirectory or configure a cluster-wide " + "default via key '" + CheckpointingOptions.SAVEPOINT_DIRECTORY.key() + "'.")).     }     if (cancelJob) {         checkpointCoordinator.stopCheckpointScheduler().     }     return checkpointCoordinator.triggerSavepoint(System.currentTimeMillis(), targetDirectory).thenApply(CompletedCheckpoint::getExternalPointer).handleAsync((path, throwable) -> {         if (throwable != null) {             if (cancelJob) {                 startCheckpointScheduler(checkpointCoordinator).             }             throw new CompletionException(throwable).         } else if (cancelJob) {             log.info("Savepoint stored in {}. Now cancelling {}.", path, jobGraph.getJobID()).             cancel(timeout).         }         return path.     }, getMainThreadExecutor()). }
false;private;1;9;;private void startCheckpointScheduler(final CheckpointCoordinator checkpointCoordinator) {     if (checkpointCoordinator.isPeriodicCheckpointingConfigured()) {         try {             checkpointCoordinator.startCheckpointScheduler().         } catch (IllegalStateException ignored) {         // Concurrent shut down of the coordinator         }     } }
false;public;1;13;;@Override public CompletableFuture<OperatorBackPressureStatsResponse> requestOperatorBackPressureStats(final JobVertexID jobVertexId) {     final ExecutionJobVertex jobVertex = executionGraph.getJobVertex(jobVertexId).     if (jobVertex == null) {         return FutureUtils.completedExceptionally(new FlinkException("JobVertexID not found " + jobVertexId)).     }     final Optional<OperatorBackPressureStats> operatorBackPressureStats = backPressureStatsTracker.getOperatorBackPressureStats(jobVertex).     return CompletableFuture.completedFuture(OperatorBackPressureStatsResponse.of(operatorBackPressureStats.orElse(null))). }
false;public;2;4;;@Override public void notifyAllocationFailure(AllocationID allocationID, Exception cause) {     internalFailAllocation(allocationID, cause). }
false;public;3;19;;@Override public CompletableFuture<Object> updateGlobalAggregate(String aggregateName, Object aggregand, byte[] serializedAggregateFunction) {     AggregateFunction aggregateFunction = null.     try {         aggregateFunction = InstantiationUtil.deserializeObject(serializedAggregateFunction, userCodeLoader).     } catch (Exception e) {         log.error("Error while attempting to deserialize user AggregateFunction.").         return FutureUtils.completedExceptionally(e).     }     Object accumulator = accumulators.get(aggregateName).     if (null == accumulator) {         accumulator = aggregateFunction.createAccumulator().     }     accumulator = aggregateFunction.add(aggregand, accumulator).     accumulators.put(aggregateName, accumulator).     return CompletableFuture.completedFuture(aggregateFunction.getResult(accumulator)). }
false;private;1;22;;// ---------------------------------------------------------------------------------------------- // Internal methods // ---------------------------------------------------------------------------------------------- // -- job starting and stopping  ----------------------------------------------------------------- private Acknowledge startJobExecution(JobMasterId newJobMasterId) throws Exception {     validateRunsInMainThread().     checkNotNull(newJobMasterId, "The new JobMasterId must not be null.").     if (Objects.equals(getFencingToken(), newJobMasterId)) {         log.info("Already started the job execution with JobMasterId {}.", newJobMasterId).         return Acknowledge.get().     }     setNewFencingToken(newJobMasterId).     startJobMasterServices().     log.info("Starting execution of job {} ({}) under job master id {}.", jobGraph.getName(), jobGraph.getJobID(), newJobMasterId).     resetAndScheduleExecutionGraph().     return Acknowledge.get(). }
false;private;0;15;;private void startJobMasterServices() throws Exception {     // start the slot pool make sure the slot pool now accepts messages for this leader     slotPool.start(getFencingToken(), getAddress(), getMainThreadExecutor()).     scheduler.start(getMainThreadExecutor()).     // TODO: Remove once the ZooKeeperLeaderRetrieval returns the stored address upon start     // try to reconnect to previously known leader     reconnectToResourceManager(new FlinkException("Starting JobMaster component.")).     // job is ready to go, try to establish connection with resource manager     // - activate leader retrieval for the resource manager     // - on notification of the leader, the connection will be established and     // the slot pool will start requesting slots     resourceManagerLeaderRetriever.start(new ResourceManagerLeaderListener()). }
false;private;1;12;;private void setNewFencingToken(JobMasterId newJobMasterId) {     if (getFencingToken() != null) {         log.info("Restarting old job with JobMasterId {}. The new JobMasterId is {}.", getFencingToken(), newJobMasterId).         // first we have to suspend the current execution         suspendExecution(new FlinkException("Old job with JobMasterId " + getFencingToken() + " is restarted with a new JobMasterId " + newJobMasterId + '.')).     }     // set new leader id     setFencingToken(newJobMasterId). }
true;private;1;28;/**  * Suspending job, all the running tasks will be cancelled, and communication with other components  * will be disposed.  *  * <p>Mostly job is suspended because of the leadership has been revoked, one can be restart this job by  * calling the {@link #start(JobMasterId)} method once we take the leadership back again.  *  * @param cause The reason of why this job been suspended.  */ ;/**  * Suspending job, all the running tasks will be cancelled, and communication with other components  * will be disposed.  *  * <p>Mostly job is suspended because of the leadership has been revoked, one can be restart this job by  * calling the {@link #start(JobMasterId)} method once we take the leadership back again.  *  * @param cause The reason of why this job been suspended.  */ private Acknowledge suspendExecution(final Exception cause) {     validateRunsInMainThread().     if (getFencingToken() == null) {         log.debug("Job has already been suspended or shutdown.").         return Acknowledge.get().     }     // not leader anymore --> set the JobMasterId to null     setFencingToken(null).     try {         resourceManagerLeaderRetriever.stop().         resourceManagerAddress = null.     } catch (Throwable t) {         log.warn("Failed to stop resource manager leader retriever when suspending.", t).     }     suspendAndClearExecutionGraphFields(cause).     // the slot pool stops receiving messages and clears its pooled slots     slotPool.suspend().     // disconnect from resource manager:     closeResourceManagerConnection(cause).     return Acknowledge.get(). }
false;private;2;10;;private void assignExecutionGraph(ExecutionGraph newExecutionGraph, JobManagerJobMetricGroup newJobManagerJobMetricGroup) {     validateRunsInMainThread().     checkState(executionGraph.getState().isTerminalState()).     checkState(jobManagerJobMetricGroup == null).     executionGraph = newExecutionGraph.     jobManagerJobMetricGroup = newJobManagerJobMetricGroup. }
false;private;0;23;;private void resetAndScheduleExecutionGraph() throws Exception {     validateRunsInMainThread().     final CompletableFuture<Void> executionGraphAssignedFuture.     if (executionGraph.getState() == JobStatus.CREATED) {         executionGraphAssignedFuture = CompletableFuture.completedFuture(null).         executionGraph.start(getMainThreadExecutor()).     } else {         suspendAndClearExecutionGraphFields(new FlinkException("ExecutionGraph is being reset in order to be rescheduled.")).         final JobManagerJobMetricGroup newJobManagerJobMetricGroup = jobMetricGroupFactory.create(jobGraph).         final ExecutionGraph newExecutionGraph = createAndRestoreExecutionGraph(newJobManagerJobMetricGroup).         executionGraphAssignedFuture = executionGraph.getTerminationFuture().handle((JobStatus ignored, Throwable throwable) -> {             newExecutionGraph.start(getMainThreadExecutor()).             assignExecutionGraph(newExecutionGraph, newJobManagerJobMetricGroup).             return null.         }).     }     executionGraphAssignedFuture.thenRun(this::scheduleExecutionGraph). }
false;private;0;13;;private void scheduleExecutionGraph() {     checkState(jobStatusListener == null).     // register self as job status change listener     jobStatusListener = new JobManagerJobStatusListener().     executionGraph.registerJobStatusListener(jobStatusListener).     try {         executionGraph.scheduleForExecution().     } catch (Throwable t) {         executionGraph.failGlobal(t).     } }
false;private;1;20;;private ExecutionGraph createAndRestoreExecutionGraph(JobManagerJobMetricGroup currentJobManagerJobMetricGroup) throws Exception {     ExecutionGraph newExecutionGraph = createExecutionGraph(currentJobManagerJobMetricGroup).     final CheckpointCoordinator checkpointCoordinator = newExecutionGraph.getCheckpointCoordinator().     if (checkpointCoordinator != null) {         // check whether we find a valid checkpoint         if (!checkpointCoordinator.restoreLatestCheckpointedState(newExecutionGraph.getAllVertices(), false, false)) {             // check whether we can restore from a savepoint             tryRestoreExecutionGraphFromSavepoint(newExecutionGraph, jobGraph.getSavepointRestoreSettings()).         }     }     return newExecutionGraph. }
false;private;1;17;;private ExecutionGraph createExecutionGraph(JobManagerJobMetricGroup currentJobManagerJobMetricGroup) throws JobExecutionException, JobException {     return ExecutionGraphBuilder.buildGraph(null, jobGraph, jobMasterConfiguration.getConfiguration(), scheduledExecutorService, scheduledExecutorService, scheduler, userCodeLoader, highAvailabilityServices.getCheckpointRecoveryFactory(), rpcTimeout, restartStrategy, currentJobManagerJobMetricGroup, blobWriter, jobMasterConfiguration.getSlotRequestTimeout(), log). }
false;private;1;4;;private void suspendAndClearExecutionGraphFields(Exception cause) {     suspendExecutionGraph(cause).     clearExecutionGraphFields(). }
false;private;1;11;;private void suspendExecutionGraph(Exception cause) {     executionGraph.suspend(cause).     if (jobManagerJobMetricGroup != null) {         jobManagerJobMetricGroup.close().     }     if (jobStatusListener != null) {         jobStatusListener.stop().     } }
false;private;0;4;;private void clearExecutionGraphFields() {     jobManagerJobMetricGroup = null.     jobStatusListener = null. }
true;private;1;12;/**  * Dispose the savepoint stored under the given path.  *  * @param savepointPath path where the savepoint is stored  */ ;/**  * Dispose the savepoint stored under the given path.  *  * @param savepointPath path where the savepoint is stored  */ private void disposeSavepoint(String savepointPath) {     try {         // delete the temporary savepoint         Checkpoints.disposeSavepoint(savepointPath, jobMasterConfiguration.getConfiguration(), userCodeLoader, log).     } catch (FlinkException | IOException e) {         log.info("Could not dispose temporary rescaling savepoint under {}.", savepointPath, e).     } }
true;private;2;12;/**  * Tries to restore the given {@link ExecutionGraph} from the provided {@link SavepointRestoreSettings}.  *  * @param executionGraphToRestore {@link ExecutionGraph} which is supposed to be restored  * @param savepointRestoreSettings {@link SavepointRestoreSettings} containing information about the savepoint to restore from  * @throws Exception if the {@link ExecutionGraph} could not be restored  */ ;/**  * Tries to restore the given {@link ExecutionGraph} from the provided {@link SavepointRestoreSettings}.  *  * @param executionGraphToRestore {@link ExecutionGraph} which is supposed to be restored  * @param savepointRestoreSettings {@link SavepointRestoreSettings} containing information about the savepoint to restore from  * @throws Exception if the {@link ExecutionGraph} could not be restored  */ private void tryRestoreExecutionGraphFromSavepoint(ExecutionGraph executionGraphToRestore, SavepointRestoreSettings savepointRestoreSettings) throws Exception {     if (savepointRestoreSettings.restoreSavepoint()) {         final CheckpointCoordinator checkpointCoordinator = executionGraphToRestore.getCheckpointCoordinator().         if (checkpointCoordinator != null) {             checkpointCoordinator.restoreSavepoint(savepointRestoreSettings.getRestorePath(), savepointRestoreSettings.allowNonRestoredState(), executionGraphToRestore.getAllVertices(), userCodeLoader).         }     } }
false;private;1;9;;// ---------------------------------------------------------------------------------------------- private void handleJobMasterError(final Throwable cause) {     if (ExceptionUtils.isJvmFatalError(cause)) {         log.error("Fatal error occurred on JobManager.", cause).         // The fatal error handler implementation should make sure that this call is non-blocking         fatalErrorHandler.onFatalError(cause).     } else {         jobCompletionActions.jobMasterFailed(cause).     } }
false;private;3;11;;private void jobStatusChanged(final JobStatus newJobStatus, long timestamp, @Nullable final Throwable error) {     validateRunsInMainThread().     if (newJobStatus.isGloballyTerminalState()) {         final ArchivedExecutionGraph archivedExecutionGraph = ArchivedExecutionGraph.createFrom(executionGraph).         scheduledExecutorService.execute(() -> jobCompletionActions.jobReachedGloballyTerminalState(archivedExecutionGraph)).     } }
false;private;2;5;;private void notifyOfNewResourceManagerLeader(final String newResourceManagerAddress, final ResourceManagerId resourceManagerId) {     resourceManagerAddress = createResourceManagerAddress(newResourceManagerAddress, resourceManagerId).     reconnectToResourceManager(new FlinkException(String.format("ResourceManager leader changed to new address %s", resourceManagerAddress))). }
false;private;2;10;;@Nullable private ResourceManagerAddress createResourceManagerAddress(@Nullable String newResourceManagerAddress, @Nullable ResourceManagerId resourceManagerId) {     if (newResourceManagerAddress != null) {         // the contract is: address == null <=> id == null         checkNotNull(resourceManagerId).         return new ResourceManagerAddress(newResourceManagerAddress, resourceManagerId).     } else {         return null.     } }
false;private;1;4;;private void reconnectToResourceManager(Exception cause) {     closeResourceManagerConnection(cause).     tryConnectToResourceManager(). }
false;private;0;5;;private void tryConnectToResourceManager() {     if (resourceManagerAddress != null) {         connectToResourceManager().     } }
false;private;0;19;;private void connectToResourceManager() {     assert (resourceManagerAddress != null).     assert (resourceManagerConnection == null).     assert (establishedResourceManagerConnection == null).     log.info("Connecting to ResourceManager {}", resourceManagerAddress).     resourceManagerConnection = new ResourceManagerConnection(log, jobGraph.getJobID(), resourceId, getAddress(), getFencingToken(), resourceManagerAddress.getAddress(), resourceManagerAddress.getResourceManagerId(), scheduledExecutorService).     resourceManagerConnection.start(). }
false;public;2;4;;@Override public void receiveHeartbeat(ResourceID resourceID, Void payload) {     resourceManagerGateway.heartbeatFromJobManager(resourceID). }
false;public;2;4;;@Override public void requestHeartbeat(ResourceID resourceID, Void payload) { // request heartbeat will never be called on the job manager side }
false;private;1;35;;private void establishResourceManagerConnection(final JobMasterRegistrationSuccess success) {     final ResourceManagerId resourceManagerId = success.getResourceManagerId().     // verify the response with current connection     if (resourceManagerConnection != null && Objects.equals(resourceManagerConnection.getTargetLeaderId(), resourceManagerId)) {         log.info("JobManager successfully registered at ResourceManager, leader id: {}.", resourceManagerId).         final ResourceManagerGateway resourceManagerGateway = resourceManagerConnection.getTargetGateway().         final ResourceID resourceManagerResourceId = success.getResourceManagerResourceId().         establishedResourceManagerConnection = new EstablishedResourceManagerConnection(resourceManagerGateway, resourceManagerResourceId).         slotPool.connectToResourceManager(resourceManagerGateway).         resourceManagerHeartbeatManager.monitorTarget(resourceManagerResourceId, new HeartbeatTarget<Void>() {              @Override             public void receiveHeartbeat(ResourceID resourceID, Void payload) {                 resourceManagerGateway.heartbeatFromJobManager(resourceID).             }              @Override             public void requestHeartbeat(ResourceID resourceID, Void payload) {             // request heartbeat will never be called on the job manager side             }         }).     } else {         log.debug("Ignoring resource manager connection to {} because it's duplicated or outdated.", resourceManagerId).     } }
false;private;1;12;;private void closeResourceManagerConnection(Exception cause) {     if (establishedResourceManagerConnection != null) {         dissolveResourceManagerConnection(establishedResourceManagerConnection, cause).         establishedResourceManagerConnection = null.     }     if (resourceManagerConnection != null) {         // stop a potentially ongoing registration process         resourceManagerConnection.close().         resourceManagerConnection = null.     } }
false;private;2;15;;private void dissolveResourceManagerConnection(EstablishedResourceManagerConnection establishedResourceManagerConnection, Exception cause) {     final ResourceID resourceManagerResourceID = establishedResourceManagerConnection.getResourceManagerResourceID().     if (log.isDebugEnabled()) {         log.debug("Close ResourceManager connection {}.", resourceManagerResourceID, cause).     } else {         log.info("Close ResourceManager connection {}: {}.", resourceManagerResourceID, cause.getMessage()).     }     resourceManagerHeartbeatManager.unmonitorTarget(resourceManagerResourceID).     ResourceManagerGateway resourceManagerGateway = establishedResourceManagerConnection.getResourceManagerGateway().     resourceManagerGateway.disconnectJobManager(jobGraph.getJobID(), cause).     slotPool.disconnectResourceManager(). }
true;private;2;45;/**  * Restore the given {@link ExecutionGraph} from the rescaling savepoint. If the {@link ExecutionGraph} could  * be restored, then this savepoint will be recorded as the latest successful modification savepoint. A previous  * savepoint will be disposed. If the rescaling savepoint is empty, the job will be restored from the initially  * provided savepoint.  *  * @param newExecutionGraph to restore  * @param savepointFuture containing the path to the internal modification savepoint  * @return Future which is completed with the restored {@link ExecutionGraph}  */ ;/**  * Restore the given {@link ExecutionGraph} from the rescaling savepoint. If the {@link ExecutionGraph} could  * be restored, then this savepoint will be recorded as the latest successful modification savepoint. A previous  * savepoint will be disposed. If the rescaling savepoint is empty, the job will be restored from the initially  * provided savepoint.  *  * @param newExecutionGraph to restore  * @param savepointFuture containing the path to the internal modification savepoint  * @return Future which is completed with the restored {@link ExecutionGraph}  */ private CompletableFuture<ExecutionGraph> restoreExecutionGraphFromRescalingSavepoint(ExecutionGraph newExecutionGraph, CompletableFuture<String> savepointFuture) {     return savepointFuture.thenApplyAsync((@Nullable String savepointPath) -> {         if (savepointPath != null) {             try {                 tryRestoreExecutionGraphFromSavepoint(newExecutionGraph, SavepointRestoreSettings.forPath(savepointPath, false)).             } catch (Exception e) {                 final String message = String.format("Could not restore from temporary rescaling savepoint. This might indicate " + "that the savepoint %s got corrupted. Deleting this savepoint as a precaution.", savepointPath).                 log.info(message).                 CompletableFuture.runAsync(() -> {                     if (savepointPath.equals(lastInternalSavepoint)) {                         lastInternalSavepoint = null.                     }                 }, getMainThreadExecutor()).thenRunAsync(() -> disposeSavepoint(savepointPath), scheduledExecutorService).                 throw new CompletionException(new JobModificationException(message, e)).             }         } else {             // No rescaling savepoint, restart from the initial savepoint or none             try {                 tryRestoreExecutionGraphFromSavepoint(newExecutionGraph, jobGraph.getSavepointRestoreSettings()).             } catch (Exception e) {                 final String message = String.format("Could not restore from initial savepoint. This might indicate " + "that the savepoint %s got corrupted.", jobGraph.getSavepointRestoreSettings().getRestorePath()).                 log.info(message).                 throw new CompletionException(new JobModificationException(message, e)).             }         }         return newExecutionGraph.     }, scheduledExecutorService). }
true;private;1;36;/**  * Takes an internal savepoint for job modification purposes. If the savepoint was not successful because  * not all tasks were running, it returns the last successful modification savepoint.  *  * @param timeout for the operation  * @return Future which is completed with the savepoint path or the last successful modification savepoint if the  * former was not successful  */ ;/**  * Takes an internal savepoint for job modification purposes. If the savepoint was not successful because  * not all tasks were running, it returns the last successful modification savepoint.  *  * @param timeout for the operation  * @return Future which is completed with the savepoint path or the last successful modification savepoint if the  * former was not successful  */ private CompletableFuture<String> getJobModificationSavepoint(Time timeout) {     return triggerSavepoint(null, false, timeout).handleAsync((String savepointPath, Throwable throwable) -> {         if (throwable != null) {             final Throwable strippedThrowable = ExceptionUtils.stripCompletionException(throwable).             if (strippedThrowable instanceof CheckpointTriggerException) {                 final CheckpointTriggerException checkpointTriggerException = (CheckpointTriggerException) strippedThrowable.                 if (checkpointTriggerException.getCheckpointDeclineReason() == CheckpointDeclineReason.NOT_ALL_REQUIRED_TASKS_RUNNING) {                     return lastInternalSavepoint.                 } else {                     throw new CompletionException(checkpointTriggerException).                 }             } else {                 throw new CompletionException(strippedThrowable).             }         } else {             final String savepointToDispose = lastInternalSavepoint.             lastInternalSavepoint = savepointPath.             if (savepointToDispose != null) {                 // dispose the old savepoint asynchronously                 CompletableFuture.runAsync(() -> disposeSavepoint(savepointToDispose), scheduledExecutorService).             }             return lastInternalSavepoint.         }     }, getMainThreadExecutor()). }
true;private;3;14;/**  * Rescales the given operators of the {@link JobGraph} of this {@link JobMaster} with respect to given  * parallelism and {@link RescalingBehaviour}.  *  * @param operators to rescale  * @param newParallelism new parallelism for these operators  * @param rescalingBehaviour of the rescaling operation  * @throws FlinkException if the {@link JobGraph} could not be rescaled  */ ;/**  * Rescales the given operators of the {@link JobGraph} of this {@link JobMaster} with respect to given  * parallelism and {@link RescalingBehaviour}.  *  * @param operators to rescale  * @param newParallelism new parallelism for these operators  * @param rescalingBehaviour of the rescaling operation  * @throws FlinkException if the {@link JobGraph} could not be rescaled  */ private void rescaleJobGraph(Collection<JobVertexID> operators, int newParallelism, RescalingBehaviour rescalingBehaviour) throws FlinkException {     for (JobVertexID jobVertexId : operators) {         final JobVertex jobVertex = jobGraph.findVertexByID(jobVertexId).         // update max parallelism in case that it has not been configured         final ExecutionJobVertex executionJobVertex = executionGraph.getJobVertex(jobVertexId).         if (executionJobVertex != null) {             jobVertex.setMaxParallelism(executionJobVertex.getMaxParallelism()).         }         rescalingBehaviour.accept(jobVertex, newParallelism).     } }
false;public;0;4;;// ---------------------------------------------------------------------------------------------- // Service methods // ---------------------------------------------------------------------------------------------- @Override public JobMasterGateway getGateway() {     return getSelfGateway(JobMasterGateway.class). }
false;public;2;7;;@Override public void notifyLeaderAddress(final String leaderAddress, final UUID leaderSessionID) {     runAsync(() -> notifyOfNewResourceManagerLeader(leaderAddress, ResourceManagerId.fromUuidOrNull(leaderSessionID))). }
false;public;1;4;;@Override public void handleError(final Exception exception) {     handleJobMasterError(new Exception("Fatal error in the ResourceManager leader service", exception)). }
false;protected;3;12;;@Override protected CompletableFuture<RegistrationResponse> invokeRegistration(ResourceManagerGateway gateway, ResourceManagerId fencingToken, long timeoutMillis) {     Time timeout = Time.milliseconds(timeoutMillis).     return gateway.registerJobManager(jobMasterId, jobManagerResourceID, jobManagerRpcAddress, jobID, timeout). }
false;protected;0;25;;@Override protected RetryingRegistration<ResourceManagerId, ResourceManagerGateway, JobMasterRegistrationSuccess> generateRegistration() {     return new RetryingRegistration<ResourceManagerId, ResourceManagerGateway, JobMasterRegistrationSuccess>(log, getRpcService(), "ResourceManager", ResourceManagerGateway.class, getTargetAddress(), getTargetLeaderId(), jobMasterConfiguration.getRetryingRegistrationConfiguration()) {          @Override         protected CompletableFuture<RegistrationResponse> invokeRegistration(ResourceManagerGateway gateway, ResourceManagerId fencingToken, long timeoutMillis) {             Time timeout = Time.milliseconds(timeoutMillis).             return gateway.registerJobManager(jobMasterId, jobManagerResourceID, jobManagerRpcAddress, jobID, timeout).         }     }. }
false;protected;1;10;;@Override protected void onRegistrationSuccess(final JobMasterRegistrationSuccess success) {     runAsync(() -> {         // noinspection ObjectEquality         if (this == resourceManagerConnection) {             establishResourceManagerConnection(success).         }     }). }
false;protected;1;4;;@Override protected void onRegistrationFailure(final Throwable failure) {     handleJobMasterError(failure). }
false;public;4;12;;@Override public void jobStatusChanges(final JobID jobId, final JobStatus newJobStatus, final long timestamp, final Throwable error) {     if (running) {         // run in rpc thread to avoid concurrency         runAsync(() -> jobStatusChanged(newJobStatus, timestamp, error)).     } }
false;private;0;3;;private void stop() {     running = false. }
false;public;1;6;;@Override public void notifyHeartbeatTimeout(ResourceID resourceID) {     jobMasterGateway.disconnectTaskManager(resourceID, new TimeoutException("Heartbeat of TaskManager with id " + resourceID + " timed out.")). }
false;public;2;6;;@Override public void reportPayload(ResourceID resourceID, AccumulatorReport payload) {     for (AccumulatorSnapshot snapshot : payload.getAccumulatorSnapshots()) {         executionGraph.updateAccumulators(snapshot).     } }
false;public;1;4;;@Override public CompletableFuture<Void> retrievePayload(ResourceID resourceID) {     return CompletableFuture.completedFuture(null). }
false;public;1;12;;@Override public void notifyHeartbeatTimeout(final ResourceID resourceId) {     runAsync(() -> {         log.info("The heartbeat of ResourceManager with id {} timed out.", resourceId).         if (establishedResourceManagerConnection != null && establishedResourceManagerConnection.getResourceManagerResourceID().equals(resourceId)) {             reconnectToResourceManager(new JobMasterException(String.format("The heartbeat of ResourceManager with id %s timed out.", resourceId))).         }     }). }
false;public;2;4;;@Override public void reportPayload(ResourceID resourceID, Void payload) { // nothing to do since the payload is of type Void }
false;public;1;4;;@Override public CompletableFuture<Void> retrievePayload(ResourceID resourceID) {     return CompletableFuture.completedFuture(null). }
false;;0;4;;@VisibleForTesting RestartStrategy getRestartStrategy() {     return restartStrategy. }
false;;0;4;;@VisibleForTesting ExecutionGraph getExecutionGraph() {     return executionGraph. }
