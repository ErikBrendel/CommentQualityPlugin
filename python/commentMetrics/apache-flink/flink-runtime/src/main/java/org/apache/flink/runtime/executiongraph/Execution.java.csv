commented;modifiers;parameterAmount;loc;comment;code
false;public;0;3;;// -------------------------------------------------------------------------------------------- // Properties // -------------------------------------------------------------------------------------------- public ExecutionVertex getVertex() {     return vertex. }
false;public;0;4;;@Override public ExecutionAttemptID getAttemptId() {     return attemptId. }
false;public;0;4;;@Override public int getAttemptNumber() {     return attemptNumber. }
false;public;0;4;;@Override public ExecutionState getState() {     return state. }
false;public;0;4;;@Nullable public AllocationID getAssignedAllocationID() {     return assignedAllocationID. }
true;public;0;3;/**  * Gets the global modification version of the execution graph when this execution was created.  *  * <p>This version is bumped in the ExecutionGraph whenever a global failover happens. It is used  * to resolve conflicts between concurrent modification by global and local failover actions.  */ ;/**  * Gets the global modification version of the execution graph when this execution was created.  *  * <p>This version is bumped in the ExecutionGraph whenever a global failover happens. It is used  * to resolve conflicts between concurrent modification by global and local failover actions.  */ public long getGlobalModVersion() {     return globalModVersion. }
false;public;0;3;;public CompletableFuture<TaskManagerLocation> getTaskManagerLocationFuture() {     return taskManagerLocationFuture. }
false;public;0;3;;public LogicalSlot getAssignedResource() {     return assignedResource. }
true;;1;35;/**  * Tries to assign the given slot to the execution. The assignment works only if the  * Execution is in state SCHEDULED. Returns true, if the resource could be assigned.  *  * @param logicalSlot to assign to this execution  * @return true if the slot could be assigned to the execution, otherwise false  */ ;/**  * Tries to assign the given slot to the execution. The assignment works only if the  * Execution is in state SCHEDULED. Returns true, if the resource could be assigned.  *  * @param logicalSlot to assign to this execution  * @return true if the slot could be assigned to the execution, otherwise false  */ @VisibleForTesting boolean tryAssignResource(final LogicalSlot logicalSlot) {     assertRunningInJobMasterMainThread().     checkNotNull(logicalSlot).     // note: we also accept resource assignment when being in state CREATED for testing purposes     if (state == SCHEDULED || state == CREATED) {         if (ASSIGNED_SLOT_UPDATER.compareAndSet(this, null, logicalSlot)) {             if (logicalSlot.tryAssignPayload(this)) {                 // check for concurrent modification (e.g. cancelling call)                 if ((state == SCHEDULED || state == CREATED) && !taskManagerLocationFuture.isDone()) {                     taskManagerLocationFuture.complete(logicalSlot.getTaskManagerLocation()).                     assignedAllocationID = logicalSlot.getAllocationId().                     return true.                 } else {                     // free assigned resource and return false                     ASSIGNED_SLOT_UPDATER.set(this, null).                     return false.                 }             } else {                 ASSIGNED_SLOT_UPDATER.set(this, null).                 return false.             }         } else {             // the slot already has another slot assigned             return false.         }     } else {         // do not allow resource assignment if we are not in state SCHEDULED         return false.     } }
false;public;0;6;;@Override public TaskManagerLocation getAssignedResourceLocation() {     // returns non-null only when a location is already assigned     final LogicalSlot currentAssignedResource = assignedResource.     return currentAssignedResource != null ? currentAssignedResource.getTaskManagerLocation() : null. }
false;public;0;3;;public Throwable getFailureCause() {     return failureCause. }
false;public;0;4;;@Override public String getFailureCauseAsString() {     return ExceptionUtils.stringifyException(getFailureCause()). }
false;public;0;4;;@Override public long[] getStateTimestamps() {     return stateTimestamps. }
false;public;1;4;;@Override public long getStateTimestamp(ExecutionState state) {     return this.stateTimestamps[state.ordinal()]. }
false;public;0;3;;public boolean isFinished() {     return state.isTerminal(). }
false;public;0;4;;@Nullable public JobManagerTaskRestore getTaskRestore() {     return taskRestore. }
true;public;1;4;/**  * Sets the initial state for the execution. The serialized state is then shipped via the  * {@link TaskDeploymentDescriptor} to the TaskManagers.  *  * @param taskRestore information to restore the state  */ ;/**  * Sets the initial state for the execution. The serialized state is then shipped via the  * {@link TaskDeploymentDescriptor} to the TaskManagers.  *  * @param taskRestore information to restore the state  */ public void setInitialState(@Nullable JobManagerTaskRestore taskRestore) {     checkState(state == CREATED, "Can only assign operator state when execution attempt is in CREATED").     this.taskRestore = taskRestore. }
true;public;0;4;/**  * Gets a future that completes once the task execution reaches a terminal state.  * The future will be completed with specific state that the execution reached.  * This future is always completed from the job master's main thread.  *  * @return A future which is completed once the execution reaches a terminal state  */ ;/**  * Gets a future that completes once the task execution reaches a terminal state.  * The future will be completed with specific state that the execution reached.  * This future is always completed from the job master's main thread.  *  * @return A future which is completed once the execution reaches a terminal state  */ @Override public CompletableFuture<ExecutionState> getTerminalStateFuture() {     return terminalStateFuture. }
true;public;0;3;/**  * Gets the release future which is completed once the execution reaches a terminal  * state and the assigned resource has been released.  * This future is always completed from the job master's main thread.  *  * @return A future which is completed once the assigned resource has been released  */ ;/**  * Gets the release future which is completed once the execution reaches a terminal  * state and the assigned resource has been released.  * This future is always completed from the job master's main thread.  *  * @return A future which is completed once the assigned resource has been released  */ public CompletableFuture<?> getReleaseFuture() {     return releaseFuture. }
false;public;0;10;;// -------------------------------------------------------------------------------------------- // Actions // -------------------------------------------------------------------------------------------- public CompletableFuture<Void> scheduleForExecution() {     final ExecutionGraph executionGraph = getVertex().getExecutionGraph().     final SlotProvider resourceProvider = executionGraph.getSlotProvider().     final boolean allowQueued = executionGraph.isQueuedSchedulingAllowed().     return scheduleForExecution(resourceProvider, allowQueued, LocationPreferenceConstraint.ANY, Collections.emptySet()). }
true;public;4;48;/**  * NOTE: This method only throws exceptions if it is in an illegal state to be scheduled, or if the tasks needs  *       to be scheduled immediately and no resource is available. If the task is accepted by the schedule, any  *       error sets the vertex state to failed and triggers the recovery logic.  *  * @param slotProvider The slot provider to use to allocate slot for this execution attempt.  * @param queued Flag to indicate whether the scheduler may queue this task if it cannot  *               immediately deploy it.  * @param locationPreferenceConstraint constraint for the location preferences  * @param allPreviousExecutionGraphAllocationIds set with all previous allocation ids in the job graph.  *                                                 Can be empty if the allocation ids are not required for scheduling.  * @return Future which is completed once the Execution has been deployed  */ ;/**  * NOTE: This method only throws exceptions if it is in an illegal state to be scheduled, or if the tasks needs  *       to be scheduled immediately and no resource is available. If the task is accepted by the schedule, any  *       error sets the vertex state to failed and triggers the recovery logic.  *  * @param slotProvider The slot provider to use to allocate slot for this execution attempt.  * @param queued Flag to indicate whether the scheduler may queue this task if it cannot  *               immediately deploy it.  * @param locationPreferenceConstraint constraint for the location preferences  * @param allPreviousExecutionGraphAllocationIds set with all previous allocation ids in the job graph.  *                                                 Can be empty if the allocation ids are not required for scheduling.  * @return Future which is completed once the Execution has been deployed  */ public CompletableFuture<Void> scheduleForExecution(SlotProvider slotProvider, boolean queued, LocationPreferenceConstraint locationPreferenceConstraint, @Nonnull Set<AllocationID> allPreviousExecutionGraphAllocationIds) {     assertRunningInJobMasterMainThread().     final ExecutionGraph executionGraph = vertex.getExecutionGraph().     final Time allocationTimeout = executionGraph.getAllocationTimeout().     try {         final CompletableFuture<Execution> allocationFuture = allocateAndAssignSlotForExecution(slotProvider, queued, locationPreferenceConstraint, allPreviousExecutionGraphAllocationIds, allocationTimeout).         final CompletableFuture<Void> deploymentFuture.         if (allocationFuture.isDone() || queued) {             deploymentFuture = allocationFuture.thenRun(ThrowingRunnable.unchecked(this::deploy)).         } else {             deploymentFuture = FutureUtils.completedExceptionally(new IllegalArgumentException("The slot allocation future has not been completed yet.")).         }         deploymentFuture.whenComplete((Void ignored, Throwable failure) -> {             if (failure != null) {                 final Throwable stripCompletionException = ExceptionUtils.stripCompletionException(failure).                 final Throwable schedulingFailureCause.                 if (stripCompletionException instanceof TimeoutException) {                     schedulingFailureCause = new NoResourceAvailableException("Could not allocate enough slots within timeout of " + allocationTimeout + " to run the job. " + "Please make sure that the cluster has enough resources.").                 } else {                     schedulingFailureCause = stripCompletionException.                 }                 markFailed(schedulingFailureCause).             }         }).         return deploymentFuture.     } catch (IllegalExecutionStateException e) {         return FutureUtils.completedExceptionally(e).     } }
true;public;5;90;/**  * Allocates and assigns a slot obtained from the slot provider to the execution.  *  * @param slotProvider to obtain a new slot from  * @param queued if the allocation can be queued  * @param locationPreferenceConstraint constraint for the location preferences  * @param allPreviousExecutionGraphAllocationIds set with all previous allocation ids in the job graph.  *                                                 Can be empty if the allocation ids are not required for scheduling.  * @param allocationTimeout rpcTimeout for allocating a new slot  * @return Future which is completed with this execution once the slot has been assigned  * 			or with an exception if an error occurred.  * @throws IllegalExecutionStateException if this method has been called while not being in the CREATED state  */ ;/**  * Allocates and assigns a slot obtained from the slot provider to the execution.  *  * @param slotProvider to obtain a new slot from  * @param queued if the allocation can be queued  * @param locationPreferenceConstraint constraint for the location preferences  * @param allPreviousExecutionGraphAllocationIds set with all previous allocation ids in the job graph.  *                                                 Can be empty if the allocation ids are not required for scheduling.  * @param allocationTimeout rpcTimeout for allocating a new slot  * @return Future which is completed with this execution once the slot has been assigned  * 			or with an exception if an error occurred.  * @throws IllegalExecutionStateException if this method has been called while not being in the CREATED state  */ public CompletableFuture<Execution> allocateAndAssignSlotForExecution(SlotProvider slotProvider, boolean queued, LocationPreferenceConstraint locationPreferenceConstraint, @Nonnull Set<AllocationID> allPreviousExecutionGraphAllocationIds, Time allocationTimeout) throws IllegalExecutionStateException {     checkNotNull(slotProvider).     assertRunningInJobMasterMainThread().     final SlotSharingGroup sharingGroup = vertex.getJobVertex().getSlotSharingGroup().     final CoLocationConstraint locationConstraint = vertex.getLocationConstraint().     // sanity check     if (locationConstraint != null && sharingGroup == null) {         throw new IllegalStateException("Trying to schedule with co-location constraint but without slot sharing allowed.").     }     // this method only works if the execution is in the state 'CREATED'     if (transitionState(CREATED, SCHEDULED)) {         final SlotSharingGroupId slotSharingGroupId = sharingGroup != null ? sharingGroup.getSlotSharingGroupId() : null.         ScheduledUnit toSchedule = locationConstraint == null ? new ScheduledUnit(this, slotSharingGroupId) : new ScheduledUnit(this, slotSharingGroupId, locationConstraint).         // try to extract previous allocation ids, if applicable, so that we can reschedule to the same slot         ExecutionVertex executionVertex = getVertex().         AllocationID lastAllocation = executionVertex.getLatestPriorAllocation().         Collection<AllocationID> previousAllocationIDs = lastAllocation != null ? Collections.singletonList(lastAllocation) : Collections.emptyList().         // calculate the preferred locations         final CompletableFuture<Collection<TaskManagerLocation>> preferredLocationsFuture = calculatePreferredLocations(locationPreferenceConstraint).         final SlotRequestId slotRequestId = new SlotRequestId().         final CompletableFuture<LogicalSlot> logicalSlotFuture = preferredLocationsFuture.thenCompose((Collection<TaskManagerLocation> preferredLocations) -> slotProvider.allocateSlot(slotRequestId, toSchedule, new SlotProfile(ResourceProfile.UNKNOWN, preferredLocations, previousAllocationIDs, allPreviousExecutionGraphAllocationIds), queued, allocationTimeout)).         // register call back to cancel slot request in case that the execution gets canceled         releaseFuture.whenComplete((Object ignored, Throwable throwable) -> {             if (logicalSlotFuture.cancel(false)) {                 slotProvider.cancelSlotRequest(slotRequestId, slotSharingGroupId, new FlinkException("Execution " + this + " was released.")).             }         }).         // This forces calls to the slot pool back into the main thread, for normal and exceptional completion         return logicalSlotFuture.handle((LogicalSlot logicalSlot, Throwable failure) -> {             if (failure != null) {                 throw new CompletionException(failure).             }             if (tryAssignResource(logicalSlot)) {                 return this.             } else {                 // release the slot                 logicalSlot.releaseSlot(new FlinkException("Could not assign logical slot to execution " + this + '.')).                 throw new CompletionException(new FlinkException("Could not assign slot " + logicalSlot + " to execution " + this + " because it has already been assigned ")).             }         }).     } else {         // call race, already deployed, or already done         throw new IllegalExecutionStateException(this, CREATED, state).     } }
true;public;0;89;/**  * Deploys the execution to the previously assigned resource.  *  * @throws JobException if the execution cannot be deployed to the assigned resource  */ ;/**  * Deploys the execution to the previously assigned resource.  *  * @throws JobException if the execution cannot be deployed to the assigned resource  */ public void deploy() throws JobException {     assertRunningInJobMasterMainThread().     final LogicalSlot slot = assignedResource.     checkNotNull(slot, "In order to deploy the execution we first have to assign a resource via tryAssignResource.").     // The more general check is the rpcTimeout of the deployment call     if (!slot.isAlive()) {         throw new JobException("Target slot (TaskManager) for deployment is no longer alive.").     }     // make sure exactly one deployment call happens from the correct state     // note: the transition from CREATED to DEPLOYING is for testing purposes only     ExecutionState previous = this.state.     if (previous == SCHEDULED || previous == CREATED) {         if (!transitionState(previous, DEPLOYING)) {             // this should actually not happen and indicates a race somewhere else             throw new IllegalStateException("Cannot deploy task: Concurrent deployment call race.").         }     } else {         // vertex may have been cancelled, or it was already scheduled         throw new IllegalStateException("The vertex must be in CREATED or SCHEDULED state to be deployed. Found state " + previous).     }     if (this != slot.getPayload()) {         throw new IllegalStateException(String.format("The execution %s has not been assigned to the assigned slot.", this)).     }     try {         // race double check, did we fail/cancel and do we need to release the slot?         if (this.state != DEPLOYING) {             slot.releaseSlot(new FlinkException("Actual state of execution " + this + " (" + state + ") does not match expected state DEPLOYING.")).             return.         }         if (LOG.isInfoEnabled()) {             LOG.info(String.format("Deploying %s (attempt #%d) to %s", vertex.getTaskNameWithSubtaskIndex(), attemptNumber, getAssignedResourceLocation())).         }         final TaskDeploymentDescriptor deployment = vertex.createDeploymentDescriptor(attemptId, slot, taskRestore, attemptNumber).         // null taskRestore to let it be GC'ed         taskRestore = null.         final TaskManagerGateway taskManagerGateway = slot.getTaskManagerGateway().         final ComponentMainThreadExecutor jobMasterMainThreadExecutor = vertex.getExecutionGraph().getJobMasterMainThreadExecutor().         // We run the submission in the future executor so that the serialization of large TDDs does not block         // the main thread and sync back to the main thread once submission is completed.         CompletableFuture.supplyAsync(() -> taskManagerGateway.submitTask(deployment, rpcTimeout), executor).thenCompose(Function.identity()).whenCompleteAsync((ack, failure) -> {             // only respond to the failure case             if (failure != null) {                 if (failure instanceof TimeoutException) {                     String taskname = vertex.getTaskNameWithSubtaskIndex() + " (" + attemptId + ')'.                     markFailed(new Exception("Cannot deploy task " + taskname + " - TaskManager (" + getAssignedResourceLocation() + ") not responding after a rpcTimeout of " + rpcTimeout, failure)).                 } else {                     markFailed(failure).                 }             }         }, jobMasterMainThreadExecutor).     } catch (Throwable t) {         markFailed(t).         ExceptionUtils.rethrow(t).     } }
true;public;0;19;/**  * Sends stop RPC call.  */ ;/**  * Sends stop RPC call.  */ public void stop() {     assertRunningInJobMasterMainThread().     final LogicalSlot slot = assignedResource.     if (slot != null) {         final TaskManagerGateway taskManagerGateway = slot.getTaskManagerGateway().         CompletableFuture<Acknowledge> stopResultFuture = FutureUtils.retry(() -> taskManagerGateway.stopTask(attemptId, rpcTimeout), NUM_STOP_CALL_TRIES, vertex.getExecutionGraph().getJobMasterMainThreadExecutor()).         stopResultFuture.exceptionally(failure -> {             LOG.info("Stopping task was not successful.", failure).             return null.         }).     } }
false;public;0;44;;public void cancel() {     // depending on the previous state, we go directly to cancelled (no cancel call necessary)     // -- or to canceling (cancel call needs to be sent to the task manager)     // because of several possibly previous states, we need to again loop until we make a     // successful atomic state transition     assertRunningInJobMasterMainThread().     while (true) {         ExecutionState current = this.state.         if (current == CANCELING || current == CANCELED) {             // already taken care of, no need to cancel again             return.         } else // these two are the common cases where we need to send a cancel call         if (current == RUNNING || current == DEPLOYING) {             // try to transition to canceling, if successful, send the cancel call             if (startCancelling(NUM_CANCEL_CALL_TRIES)) {                 return.             }         // else: fall through the loop         } else if (current == FINISHED || current == FAILED) {             // nothing to do any more. finished failed before it could be cancelled.             // in any case, the task is removed from the TaskManager already             sendFailIntermediateResultPartitionsRpcCall().             return.         } else if (current == CREATED || current == SCHEDULED) {             // from here, we can directly switch to cancelled, because no task has been deployed             if (cancelAtomically()) {                 return.             }         // else: fall through the loop         } else {             throw new IllegalStateException(current.name()).         }     } }
false;public;0;26;;public CompletableFuture<?> suspend() {     switch(state) {         case RUNNING:         case DEPLOYING:         case CREATED:         case SCHEDULED:             if (!cancelAtomically()) {                 throw new IllegalStateException(String.format("Could not directly go to %s from %s.", CANCELED.name(), state.name())).             }             break.         case CANCELING:             completeCancelling().             break.         case FINISHED:         case FAILED:             sendFailIntermediateResultPartitionsRpcCall().             break.         case CANCELED:             break.         default:             throw new IllegalStateException(state.name()).     }     return releaseFuture. }
false;private;1;13;;private void scheduleConsumer(ExecutionVertex consumerVertex) {     try {         final ExecutionGraph executionGraph = consumerVertex.getExecutionGraph().         consumerVertex.scheduleForExecution(executionGraph.getSlotProvider(), executionGraph.isQueuedSchedulingAllowed(), // there must be at least one known location         LocationPreferenceConstraint.ANY, Collections.emptySet()).     } catch (Throwable t) {         consumerVertex.fail(new IllegalStateException("Could not schedule consumer " + "vertex " + consumerVertex, t)).     } }
false;;1;117;;void scheduleOrUpdateConsumers(List<List<ExecutionEdge>> allConsumers) {     assertRunningInJobMasterMainThread().     final int numConsumers = allConsumers.size().     if (numConsumers > 1) {         fail(new IllegalStateException("Currently, only a single consumer group per partition is supported.")).     } else if (numConsumers == 0) {         return.     }     for (ExecutionEdge edge : allConsumers.get(0)) {         final ExecutionVertex consumerVertex = edge.getTarget().         final Execution consumer = consumerVertex.getCurrentExecutionAttempt().         final ExecutionState consumerState = consumer.getState().         final IntermediateResultPartition partition = edge.getSource().         // ----------------------------------------------------------------         if (consumerState == CREATED) {             final Execution partitionExecution = partition.getProducer().getCurrentExecutionAttempt().             consumerVertex.cachePartitionInfo(PartialInputChannelDeploymentDescriptor.fromEdge(partition, partitionExecution)).             // as we do not want the default scheduling performance to be affected.             if (consumerVertex.getInputDependencyConstraint() == InputDependencyConstraint.ANY || consumerVertex.checkInputDependencyConstraints()) {                 scheduleConsumer(consumerVertex).             }             // double check to resolve race conditions             if (consumerVertex.getExecutionState() == RUNNING) {                 consumerVertex.sendPartitionInfos().             }         } else // ----------------------------------------------------------------         // Consumer is running => send update message now         // ----------------------------------------------------------------         {             if (consumerState == RUNNING) {                 final LogicalSlot consumerSlot = consumer.getAssignedResource().                 if (consumerSlot == null) {                     // The consumer has been reset concurrently                     continue.                 }                 final TaskManagerLocation partitionTaskManagerLocation = partition.getProducer().getCurrentAssignedResource().getTaskManagerLocation().                 final ResourceID partitionTaskManager = partitionTaskManagerLocation.getResourceID().                 final ResourceID consumerTaskManager = consumerSlot.getTaskManagerLocation().getResourceID().                 final ResultPartitionID partitionId = new ResultPartitionID(partition.getPartitionId(), attemptId).                 final ResultPartitionLocation partitionLocation.                 if (consumerTaskManager.equals(partitionTaskManager)) {                     // Consuming task is deployed to the same instance as the partition => local                     partitionLocation = ResultPartitionLocation.createLocal().                 } else {                     // Different instances => remote                     final ConnectionID connectionId = new ConnectionID(partitionTaskManagerLocation, partition.getIntermediateResult().getConnectionIndex()).                     partitionLocation = ResultPartitionLocation.createRemote(connectionId).                 }                 final InputChannelDeploymentDescriptor descriptor = new InputChannelDeploymentDescriptor(partitionId, partitionLocation).                 consumer.sendUpdatePartitionInfoRpcCall(Collections.singleton(new PartitionInfo(partition.getIntermediateResult().getId(), descriptor))).             } else // ----------------------------------------------------------------             if (consumerState == SCHEDULED || consumerState == DEPLOYING) {                 final Execution partitionExecution = partition.getProducer().getCurrentExecutionAttempt().                 consumerVertex.cachePartitionInfo(PartialInputChannelDeploymentDescriptor.fromEdge(partition, partitionExecution)).                 // double check to resolve race conditions                 if (consumerVertex.getExecutionState() == RUNNING) {                     consumerVertex.sendPartitionInfos().                 }             }         }     } }
true;public;1;4;/**  * This method fails the vertex due to an external condition. The task will move to state FAILED.  * If the task was in state RUNNING or DEPLOYING before, it will send a cancel call to the TaskManager.  *  * @param t The exception that caused the task to fail.  */ ;/**  * This method fails the vertex due to an external condition. The task will move to state FAILED.  * If the task was in state RUNNING or DEPLOYING before, it will send a cancel call to the TaskManager.  *  * @param t The exception that caused the task to fail.  */ @Override public void fail(Throwable t) {     processFail(t, false). }
true;public;5;23;/**  * Request a stack trace sample from the task of this execution.  *  * @param sampleId of the stack trace sample  * @param numSamples the sample should contain  * @param delayBetweenSamples to wait  * @param maxStackTraceDepth of the samples  * @param timeout until the request times out  * @return Future stack trace sample response  */ ;/**  * Request a stack trace sample from the task of this execution.  *  * @param sampleId of the stack trace sample  * @param numSamples the sample should contain  * @param delayBetweenSamples to wait  * @param maxStackTraceDepth of the samples  * @param timeout until the request times out  * @return Future stack trace sample response  */ public CompletableFuture<StackTraceSampleResponse> requestStackTraceSample(int sampleId, int numSamples, Time delayBetweenSamples, int maxStackTraceDepth, Time timeout) {     final LogicalSlot slot = assignedResource.     if (slot != null) {         final TaskManagerGateway taskManagerGateway = slot.getTaskManagerGateway().         return taskManagerGateway.requestStackTraceSample(attemptId, sampleId, numSamples, delayBetweenSamples, maxStackTraceDepth, timeout).     } else {         return FutureUtils.completedExceptionally(new Exception("The execution has no slot assigned.")).     } }
true;public;2;12;/**  * Notify the task of this execution about a completed checkpoint.  *  * @param checkpointId of the completed checkpoint  * @param timestamp of the completed checkpoint  */ ;/**  * Notify the task of this execution about a completed checkpoint.  *  * @param checkpointId of the completed checkpoint  * @param timestamp of the completed checkpoint  */ public void notifyCheckpointComplete(long checkpointId, long timestamp) {     final LogicalSlot slot = assignedResource.     if (slot != null) {         final TaskManagerGateway taskManagerGateway = slot.getTaskManagerGateway().         taskManagerGateway.notifyCheckpointComplete(attemptId, getVertex().getJobId(), checkpointId, timestamp).     } else {         LOG.debug("The execution has no slot assigned. This indicates that the execution is " + "no longer running.").     } }
true;public;3;12;/**  * Trigger a new checkpoint on the task of this execution.  *  * @param checkpointId of th checkpoint to trigger  * @param timestamp of the checkpoint to trigger  * @param checkpointOptions of the checkpoint to trigger  */ ;/**  * Trigger a new checkpoint on the task of this execution.  *  * @param checkpointId of th checkpoint to trigger  * @param timestamp of the checkpoint to trigger  * @param checkpointOptions of the checkpoint to trigger  */ public void triggerCheckpoint(long checkpointId, long timestamp, CheckpointOptions checkpointOptions) {     final LogicalSlot slot = assignedResource.     if (slot != null) {         final TaskManagerGateway taskManagerGateway = slot.getTaskManagerGateway().         taskManagerGateway.triggerCheckpoint(attemptId, getVertex().getJobId(), checkpointId, timestamp, checkpointOptions).     } else {         LOG.debug("The execution has no slot assigned. This indicates that the execution is " + "no longer running.").     } }
true;;1;3;/**  * This method marks the task as failed, but will make no attempt to remove task execution from the task manager.  * It is intended for cases where the task is known not to be running, or then the TaskManager reports failure  * (in which case it has already removed the task).  *  * @param t The exception that caused the task to fail.  */ ;// -------------------------------------------------------------------------------------------- // Callbacks // -------------------------------------------------------------------------------------------- /**  * This method marks the task as failed, but will make no attempt to remove task execution from the task manager.  * It is intended for cases where the task is known not to be running, or then the TaskManager reports failure  * (in which case it has already removed the task).  *  * @param t The exception that caused the task to fail.  */ void markFailed(Throwable t) {     processFail(t, true). }
false;;3;3;;void markFailed(Throwable t, Map<String, Accumulator<?, ?>> userAccumulators, IOMetrics metrics) {     processFail(t, true, userAccumulators, metrics). }
false;;0;3;;void markFinished() {     markFinished(null, null). }
false;;2;54;;void markFinished(Map<String, Accumulator<?, ?>> userAccumulators, IOMetrics metrics) {     assertRunningInJobMasterMainThread().     // this call usually comes during RUNNING, but may also come while still in deploying (very fast tasks!)     while (true) {         ExecutionState current = this.state.         if (current == RUNNING || current == DEPLOYING) {             if (transitionState(current, FINISHED)) {                 try {                     for (IntermediateResultPartition finishedPartition : getVertex().finishAllBlockingPartitions()) {                         IntermediateResultPartition[] allPartitions = finishedPartition.getIntermediateResult().getPartitions().                         for (IntermediateResultPartition partition : allPartitions) {                             scheduleOrUpdateConsumers(partition.getConsumers()).                         }                     }                     updateAccumulatorsAndMetrics(userAccumulators, metrics).                     releaseAssignedResource(null).                     vertex.getExecutionGraph().deregisterExecution(this).                 } finally {                     vertex.executionFinished(this).                 }                 return.             }         } else if (current == CANCELING) {             // we sent a cancel call, and the task manager finished before it arrived. We             // will never get a CANCELED call back from the job manager             completeCancelling(userAccumulators, metrics).             return.         } else if (current == CANCELED || current == FAILED) {             if (LOG.isDebugEnabled()) {                 LOG.debug("Task FINISHED, but concurrently went to state " + state).             }             return.         } else {             // this should not happen, we need to fail this             markFailed(new Exception("Vertex received FINISHED message while being in state " + state)).             return.         }     } }
false;private;0;8;;private boolean cancelAtomically() {     if (startCancelling(0)) {         completeCancelling().         return true.     } else {         return false.     } }
false;private;1;9;;private boolean startCancelling(int numberCancelRetries) {     if (transitionState(state, CANCELING)) {         taskManagerLocationFuture.cancel(false).         sendCancelRpcCall(numberCancelRetries).         return true.     } else {         return false.     } }
false;;0;3;;void completeCancelling() {     completeCancelling(null, null). }
false;;2;36;;void completeCancelling(Map<String, Accumulator<?, ?>> userAccumulators, IOMetrics metrics) {     while (true) {         ExecutionState current = this.state.         if (current == CANCELED) {             return.         } else if (current == CANCELING || current == RUNNING || current == DEPLOYING) {             updateAccumulatorsAndMetrics(userAccumulators, metrics).             if (transitionState(current, CANCELED)) {                 finishCancellation().                 return.             }         // else fall through the loop         } else {             // anything else is a serious problem !!!             if (current != FAILED) {                 String message = String.format("Asynchronous race: Found %s in state %s after successful cancel call.", vertex.getTaskNameWithSubtaskIndex(), state).                 LOG.error(message).                 vertex.getExecutionGraph().failGlobal(new Exception(message)).             }             return.         }     } }
false;private;0;8;;private void finishCancellation() {     try {         releaseAssignedResource(new FlinkException("Execution " + this + " was cancelled.")).         vertex.getExecutionGraph().deregisterExecution(this).     } finally {         vertex.executionCanceled(this).     } }
false;;1;3;;void cachePartitionInfo(PartialInputChannelDeploymentDescriptor partitionInfo) {     partialInputChannelDeploymentDescriptors.add(partitionInfo). }
false;;0;19;;void sendPartitionInfos() {     // partial partition infos queue     if (partialInputChannelDeploymentDescriptors != null && !partialInputChannelDeploymentDescriptors.isEmpty()) {         PartialInputChannelDeploymentDescriptor partialInputChannelDeploymentDescriptor.         List<PartitionInfo> partitionInfos = new ArrayList<>(partialInputChannelDeploymentDescriptors.size()).         while ((partialInputChannelDeploymentDescriptor = partialInputChannelDeploymentDescriptors.poll()) != null) {             partitionInfos.add(new PartitionInfo(partialInputChannelDeploymentDescriptor.getResultId(), partialInputChannelDeploymentDescriptor.createInputChannelDeploymentDescriptor(this))).         }         sendUpdatePartitionInfoRpcCall(partitionInfos).     } }
false;private;2;3;;// -------------------------------------------------------------------------------------------- // Internal Actions // -------------------------------------------------------------------------------------------- private boolean processFail(Throwable t, boolean isCallback) {     return processFail(t, isCallback, null, null). }
false;private;4;62;;private boolean processFail(Throwable t, boolean isCallback, Map<String, Accumulator<?, ?>> userAccumulators, IOMetrics metrics) {     // damn, we failed. This means only that we keep our books and notify our parent JobExecutionVertex     // the actual computation on the task manager is cleaned up by the TaskManager that noticed the failure     // we may need to loop multiple times (in the presence of concurrent calls) in order to     // atomically switch to failed     assertRunningInJobMasterMainThread().     while (true) {         ExecutionState current = this.state.         if (current == FAILED) {             // already failed. It is enough to remember once that we failed (its sad enough)             return false.         }         if (current == CANCELED || current == FINISHED) {             // we are already aborting or are already aborted or we are already finished             if (LOG.isDebugEnabled()) {                 LOG.debug("Ignoring transition of vertex {} to {} while being {}.", getVertexWithAttempt(), FAILED, current).             }             return false.         }         if (current == CANCELING) {             completeCancelling(userAccumulators, metrics).             return false.         }         if (transitionState(current, FAILED, t)) {             // success (in a manner of speaking)             this.failureCause = t.             updateAccumulatorsAndMetrics(userAccumulators, metrics).             try {                 releaseAssignedResource(t).                 vertex.getExecutionGraph().deregisterExecution(this).             } finally {                 vertex.executionFailed(this, t).             }             if (!isCallback && (current == RUNNING || current == DEPLOYING)) {                 if (LOG.isDebugEnabled()) {                     LOG.debug("Sending out cancel request, to remove task execution from TaskManager.").                 }                 try {                     if (assignedResource != null) {                         sendCancelRpcCall(NUM_CANCEL_CALL_TRIES).                     }                 } catch (Throwable tt) {                     // no reason this should ever happen, but log it to be safe                     LOG.error("Error triggering cancel call while marking task {} as failed.", getVertex().getTaskNameWithSubtaskIndex(), tt).                 }             }             // leave the loop             return true.         }     } }
false;;0;45;;boolean switchToRunning() {     if (transitionState(DEPLOYING, RUNNING)) {         sendPartitionInfos().         return true.     } else {         // something happened while the call was in progress.         // it can mean:         // - canceling, while deployment was in progress. state is now canceling, or canceled, if the response overtook         // - finishing (execution and finished call overtook the deployment answer, which is possible and happens for fast tasks)         // - failed (execution, failure, and failure message overtook the deployment answer)         ExecutionState currentState = this.state.         if (currentState == FINISHED || currentState == CANCELED) {         // do nothing, the task was really fast (nice)         // or it was canceled really fast         } else if (currentState == CANCELING || currentState == FAILED) {             if (LOG.isDebugEnabled()) {                 // this log statement is guarded because the 'getVertexWithAttempt()' method                 // performs string concatenations                 LOG.debug("Concurrent canceling/failing of {} while deployment was in progress.", getVertexWithAttempt()).             }             sendCancelRpcCall(NUM_CANCEL_CALL_TRIES).         } else {             String message = String.format("Concurrent unexpected state transition of task %s to %s while deployment was in progress.", getVertexWithAttempt(), currentState).             if (LOG.isDebugEnabled()) {                 LOG.debug(message).             }             // undo the deployment             sendCancelRpcCall(NUM_CANCEL_CALL_TRIES).             // record the failure             markFailed(new Exception(message)).         }         return false.     } }
true;private;1;21;/**  * This method sends a CancelTask message to the instance of the assigned slot.  *  * <p>The sending is tried up to NUM_CANCEL_CALL_TRIES times.  */ ;/**  * This method sends a CancelTask message to the instance of the assigned slot.  *  * <p>The sending is tried up to NUM_CANCEL_CALL_TRIES times.  */ private void sendCancelRpcCall(int numberRetries) {     final LogicalSlot slot = assignedResource.     if (slot != null) {         final TaskManagerGateway taskManagerGateway = slot.getTaskManagerGateway().         final ComponentMainThreadExecutor jobMasterMainThreadExecutor = getVertex().getExecutionGraph().getJobMasterMainThreadExecutor().         CompletableFuture<Acknowledge> cancelResultFuture = FutureUtils.retry(() -> taskManagerGateway.cancelTask(attemptId, rpcTimeout), numberRetries, jobMasterMainThreadExecutor).         cancelResultFuture.whenComplete((ack, failure) -> {             if (failure != null) {                 fail(new Exception("Task could not be canceled.", failure)).             }         }).     } }
false;private;0;10;;private void sendFailIntermediateResultPartitionsRpcCall() {     final LogicalSlot slot = assignedResource.     if (slot != null) {         final TaskManagerGateway taskManagerGateway = slot.getTaskManagerGateway().         // TODO For some tests this could be a problem when querying too early if all resources were released         taskManagerGateway.failPartition(attemptId).     } }
true;private;1;21;/**  * Update the partition infos on the assigned resource.  *  * @param partitionInfos for the remote task  */ ;/**  * Update the partition infos on the assigned resource.  *  * @param partitionInfos for the remote task  */ private void sendUpdatePartitionInfoRpcCall(final Iterable<PartitionInfo> partitionInfos) {     final LogicalSlot slot = assignedResource.     if (slot != null) {         final TaskManagerGateway taskManagerGateway = slot.getTaskManagerGateway().         final TaskManagerLocation taskManagerLocation = slot.getTaskManagerLocation().         CompletableFuture<Acknowledge> updatePartitionsResultFuture = taskManagerGateway.updatePartitions(attemptId, partitionInfos, rpcTimeout).         updatePartitionsResultFuture.whenCompleteAsync((ack, failure) -> {             // fail if there was a failure             if (failure != null) {                 fail(new IllegalStateException("Update task on TaskManager " + taskManagerLocation + " failed due to:", failure)).             }         }, getVertex().getExecutionGraph().getJobMasterMainThreadExecutor()).     } }
true;private;1;24;/**  * Releases the assigned resource and completes the release future  * once the assigned resource has been successfully released.  *  * @param cause for the resource release, null if none  */ ;/**  * Releases the assigned resource and completes the release future  * once the assigned resource has been successfully released.  *  * @param cause for the resource release, null if none  */ private void releaseAssignedResource(@Nullable Throwable cause) {     assertRunningInJobMasterMainThread().     final LogicalSlot slot = assignedResource.     if (slot != null) {         ComponentMainThreadExecutor jobMasterMainThreadExecutor = getVertex().getExecutionGraph().getJobMasterMainThreadExecutor().         slot.releaseSlot(cause).whenComplete((Object ignored, Throwable throwable) -> {             jobMasterMainThreadExecutor.assertRunningInMainThread().             if (throwable != null) {                 releaseFuture.completeExceptionally(throwable).             } else {                 releaseFuture.complete(null).             }         }).     } else {         // no assigned resource --> we can directly complete the release future         releaseFuture.complete(null).     } }
true;public;1;32;/**  * Calculates the preferred locations based on the location preference constraint.  *  * @param locationPreferenceConstraint constraint for the location preference  * @return Future containing the collection of preferred locations. This might not be completed if not all inputs  * 		have been a resource assigned.  */ ;// -------------------------------------------------------------------------------------------- // Miscellaneous // -------------------------------------------------------------------------------------------- /**  * Calculates the preferred locations based on the location preference constraint.  *  * @param locationPreferenceConstraint constraint for the location preference  * @return Future containing the collection of preferred locations. This might not be completed if not all inputs  * 		have been a resource assigned.  */ @VisibleForTesting public CompletableFuture<Collection<TaskManagerLocation>> calculatePreferredLocations(LocationPreferenceConstraint locationPreferenceConstraint) {     final Collection<CompletableFuture<TaskManagerLocation>> preferredLocationFutures = getVertex().getPreferredLocations().     final CompletableFuture<Collection<TaskManagerLocation>> preferredLocationsFuture.     switch(locationPreferenceConstraint) {         case ALL:             preferredLocationsFuture = FutureUtils.combineAll(preferredLocationFutures).             break.         case ANY:             final ArrayList<TaskManagerLocation> completedTaskManagerLocations = new ArrayList<>(preferredLocationFutures.size()).             for (CompletableFuture<TaskManagerLocation> preferredLocationFuture : preferredLocationFutures) {                 if (preferredLocationFuture.isDone() && !preferredLocationFuture.isCompletedExceptionally()) {                     final TaskManagerLocation taskManagerLocation = preferredLocationFuture.getNow(null).                     if (taskManagerLocation == null) {                         throw new FlinkRuntimeException("TaskManagerLocationFuture was completed with null. This indicates a programming bug.").                     }                     completedTaskManagerLocations.add(taskManagerLocation).                 }             }             preferredLocationsFuture = CompletableFuture.completedFuture(completedTaskManagerLocations).             break.         default:             throw new RuntimeException("Unknown LocationPreferenceConstraint " + locationPreferenceConstraint + '.').     }     return preferredLocationsFuture. }
false;private;2;3;;private boolean transitionState(ExecutionState currentState, ExecutionState targetState) {     return transitionState(currentState, targetState, null). }
false;private;3;33;;private boolean transitionState(ExecutionState currentState, ExecutionState targetState, Throwable error) {     // sanity check     if (currentState.isTerminal()) {         throw new IllegalStateException("Cannot leave terminal state " + currentState + " to transition to " + targetState + '.').     }     if (STATE_UPDATER.compareAndSet(this, currentState, targetState)) {         markTimestamp(targetState).         if (error == null) {             LOG.info("{} ({}) switched from {} to {}.", getVertex().getTaskNameWithSubtaskIndex(), getAttemptId(), currentState, targetState).         } else {             LOG.info("{} ({}) switched from {} to {}.", getVertex().getTaskNameWithSubtaskIndex(), getAttemptId(), currentState, targetState, error).         }         if (targetState.isTerminal()) {             // complete the terminal state future             terminalStateFuture.complete(targetState).         }         // potential errors (in listeners may not affect the main logic)         try {             vertex.notifyStateTransition(this, targetState, error).         } catch (Throwable t) {             LOG.error("Error while notifying execution graph of execution state transition.", t).         }         return true.     } else {         return false.     } }
false;private;1;3;;private void markTimestamp(ExecutionState state) {     markTimestamp(state, System.currentTimeMillis()). }
false;private;2;3;;private void markTimestamp(ExecutionState state, long timestamp) {     this.stateTimestamps[state.ordinal()] = timestamp. }
false;public;0;3;;public String getVertexWithAttempt() {     return vertex.getTaskNameWithSubtaskIndex() + " - execution #" + attemptNumber. }
true;public;1;7;/**  * Update accumulators (discarded when the Execution has already been terminated).  * @param userAccumulators the user accumulators  */ ;// ------------------------------------------------------------------------ // Accumulators // ------------------------------------------------------------------------ /**  * Update accumulators (discarded when the Execution has already been terminated).  * @param userAccumulators the user accumulators  */ public void setAccumulators(Map<String, Accumulator<?, ?>> userAccumulators) {     synchronized (accumulatorLock) {         if (!state.isTerminal()) {             this.userAccumulators = userAccumulators.         }     } }
false;public;0;3;;public Map<String, Accumulator<?, ?>> getUserAccumulators() {     return userAccumulators. }
false;public;0;10;;@Override public StringifiedAccumulatorResult[] getUserAccumulatorsStringified() {     Map<String, OptionalFailure<Accumulator<?, ?>>> accumulators = userAccumulators == null ? null : userAccumulators.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, entry -> OptionalFailure.of(entry.getValue()))).     return StringifiedAccumulatorResult.stringifyAccumulatorResults(accumulators). }
false;public;0;4;;@Override public int getParallelSubtaskIndex() {     return getVertex().getParallelSubtaskIndex(). }
false;public;0;4;;@Override public IOMetrics getIOMetrics() {     return ioMetrics. }
false;private;2;10;;private void updateAccumulatorsAndMetrics(Map<String, Accumulator<?, ?>> userAccumulators, IOMetrics metrics) {     if (userAccumulators != null) {         synchronized (accumulatorLock) {             this.userAccumulators = userAccumulators.         }     }     if (metrics != null) {         this.ioMetrics = metrics.     } }
false;public;0;7;;// ------------------------------------------------------------------------ // Standard utilities // ------------------------------------------------------------------------ @Override public String toString() {     final LogicalSlot slot = assignedResource.     return String.format("Attempt #%d (%s) @ %s - [%s]", attemptNumber, vertex.getTaskNameWithSubtaskIndex(), (slot == null ? "(unassigned)" : slot), state). }
false;public;0;4;;@Override public ArchivedExecution archive() {     return new ArchivedExecution(this). }
false;private;0;3;;private void assertRunningInJobMasterMainThread() {     vertex.getExecutionGraph().assertRunningInJobMasterMainThread(). }
