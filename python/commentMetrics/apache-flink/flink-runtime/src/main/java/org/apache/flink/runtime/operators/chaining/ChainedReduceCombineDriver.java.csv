commented;modifiers;parameterAmount;loc;comment;code
false;public;0;4;;// ------------------------------------------------------------------------ @Override public Function getStub() {     return reducer. }
false;public;0;4;;@Override public String getTaskName() {     return taskName. }
false;public;1;10;;@Override public void setup(AbstractInvokable parent) {     this.parent = parent.     running = true.     strategy = config.getDriverStrategy().     reducer = BatchTask.instantiateUserCode(config, userCodeClassLoader, ReduceFunction.class).     FunctionUtils.setFunctionRuntimeContext(reducer, getUdfRuntimeContext()). }
false;public;0;33;;@Override public void openTask() throws Exception {     // open the stub first     final Configuration stubConfig = config.getStubParameters().     BatchTask.openUserCode(reducer, stubConfig).     // instantiate the serializer / comparator     serializer = config.<T>getInputSerializer(0, userCodeClassLoader).getSerializer().     comparator = config.<T>getDriverComparator(0, userCodeClassLoader).createComparator().     MemoryManager memManager = parent.getEnvironment().getMemoryManager().     final int numMemoryPages = memManager.computeNumberOfPages(config.getRelativeMemoryDriver()).     memory = memManager.allocatePages(parent, numMemoryPages).     LOG.debug("ChainedReduceCombineDriver object reuse: " + (objectReuseEnabled ? "ENABLED" : "DISABLED") + ".").     switch(strategy) {         case SORTED_PARTIAL_REDUCE:             // instantiate a fix-length in-place sorter, if possible, otherwise the out-of-place sorter             if (comparator.supportsSerializationWithKeyNormalization() && serializer.getLength() > 0 && serializer.getLength() <= THRESHOLD_FOR_IN_PLACE_SORTING) {                 sorter = new FixedLengthRecordSorter<T>(serializer, comparator.duplicate(), memory).             } else {                 sorter = new NormalizedKeySorter<T>(serializer, comparator.duplicate(), memory).             }             break.         case HASHED_PARTIAL_REDUCE:             table = new InPlaceMutableHashTable<T>(serializer, comparator, memory).             table.open().             reduceFacade = table.new ReduceFacade(reducer, outputCollector, objectReuseEnabled).             break.     } }
false;public;1;15;;@Override public void collect(T record) {     try {         switch(strategy) {             case SORTED_PARTIAL_REDUCE:                 collectSorted(record).                 break.             case HASHED_PARTIAL_REDUCE:                 collectHashed(record).                 break.         }     } catch (Exception ex) {         throw new ExceptionInChainedStubException(taskName, ex).     } }
false;private;1;15;;private void collectSorted(T record) throws Exception {     // try writing to the sorter first     if (!sorter.write(record)) {         // it didn't succeed. sorter is full         // do the actual sorting, combining, and data writing         sortAndCombine().         sorter.reset().         // write the value again         if (!sorter.write(record)) {             throw new IOException("Cannot write record to fresh sort buffer. Record too large.").         }     } }
false;private;1;10;;private void collectHashed(T record) throws Exception {     try {         reduceFacade.updateTableEntryWithReduce(record).     } catch (EOFException ex) {         // the table has run out of memory         reduceFacade.emitAndReset().         // try again         reduceFacade.updateTableEntryWithReduce(record).     } }
false;private;0;79;;private void sortAndCombine() throws Exception {     final InMemorySorter<T> sorter = this.sorter.     if (!sorter.isEmpty()) {         sortAlgo.sort(sorter).         final TypeSerializer<T> serializer = this.serializer.         final TypeComparator<T> comparator = this.comparator.         final ReduceFunction<T> function = this.reducer.         final Collector<T> output = this.outputCollector.         final MutableObjectIterator<T> input = sorter.getIterator().         if (objectReuseEnabled) {             // We only need two objects. The first reference stores results and is             // eventually collected. New values are read into the second.             //              // The output value must have the same key fields as the input values.             T reuse1 = input.next().             T reuse2 = serializer.createInstance().             T value = reuse1.             // iterate over key groups             while (running && value != null) {                 comparator.setReference(value).                 // iterate within a key group                 while ((reuse2 = input.next(reuse2)) != null) {                     if (comparator.equalToReference(reuse2)) {                         // same group, reduce                         value = function.reduce(value, reuse2).                         // by the user, so swap the reuse objects                         if (value == reuse2) {                             T tmp = reuse1.                             reuse1 = reuse2.                             reuse2 = tmp.                         }                     } else {                         // new key group                         break.                     }                 }                 output.collect(value).                 // swap the value from the new key group into the first object                 T tmp = reuse1.                 reuse1 = reuse2.                 reuse2 = tmp.                 value = reuse1.             }         } else {             T value = input.next().             // iterate over key groups             while (running && value != null) {                 comparator.setReference(value).                 T res = value.                 // iterate within a key group                 while ((value = input.next()) != null) {                     if (comparator.equalToReference(value)) {                         // same group, reduce                         res = function.reduce(res, value).                     } else {                         // new key group                         break.                     }                 }                 output.collect(res).             }         }     } }
false;public;0;18;;@Override public void close() {     // send the final batch     try {         switch(strategy) {             case SORTED_PARTIAL_REDUCE:                 sortAndCombine().                 break.             case HASHED_PARTIAL_REDUCE:                 reduceFacade.emit().                 break.         }     } catch (Exception ex2) {         throw new ExceptionInChainedStubException(taskName, ex2).     }     outputCollector.close(). }
false;public;0;11;;@Override public void closeTask() throws Exception {     if (sorter != null) {         sorter.dispose().     }     if (table != null) {         table.close().     }     parent.getEnvironment().getMemoryManager().release(memory).     BatchTask.closeUserCode(reducer). }
false;public;0;17;;@Override public void cancelTask() {     running = false.     try {         if (sorter != null) {             sorter.dispose().         }         if (table != null) {             table.close().         }     } catch (Exception e) {     // may happen during concurrent modification     }     parent.getEnvironment().getMemoryManager().release(memory). }
