commented;modifiers;parameterAmount;loc;comment;code
true;public;0;3;/**  * Returns a list containing the IDs of all operators contained in this execution job vertex.  *  * @return list containing the IDs of all contained operators  */ ;/**  * Returns a list containing the IDs of all operators contained in this execution job vertex.  *  * @return list containing the IDs of all contained operators  */ public List<OperatorID> getOperatorIDs() {     return operatorIDs. }
true;public;0;3;/**  * Returns a list containing the alternative IDs of all operators contained in this execution job vertex.  *  * @return list containing alternative the IDs of all contained operators  */ ;/**  * Returns a list containing the alternative IDs of all operators contained in this execution job vertex.  *  * @return list containing alternative the IDs of all contained operators  */ public List<OperatorID> getUserDefinedOperatorIDs() {     return userDefinedOperatorIds. }
false;public;1;8;;public void setMaxParallelism(int maxParallelismDerived) {     Preconditions.checkState(!maxParallelismConfigured, "Attempt to override a configured max parallelism. Configured: " + this.maxParallelism + ", argument: " + maxParallelismDerived).     setMaxParallelismInternal(maxParallelismDerived). }
false;private;1;12;;private void setMaxParallelismInternal(int maxParallelism) {     if (maxParallelism == ExecutionConfig.PARALLELISM_AUTO_MAX) {         maxParallelism = KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM.     }     Preconditions.checkArgument(maxParallelism > 0 && maxParallelism <= KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM, "Overriding max parallelism is not in valid bounds (1..%s), found: %s", KeyGroupRangeAssignment.UPPER_BOUND_MAX_PARALLELISM, maxParallelism).     this.maxParallelism = maxParallelism. }
false;public;0;3;;public ExecutionGraph getGraph() {     return graph. }
false;public;0;3;;public JobVertex getJobVertex() {     return jobVertex. }
false;public;0;4;;@Override public String getName() {     return getJobVertex().getName(). }
false;public;0;4;;@Override public int getParallelism() {     return parallelism. }
false;public;0;4;;@Override public int getMaxParallelism() {     return maxParallelism. }
false;public;0;3;;public boolean isMaxParallelismConfigured() {     return maxParallelismConfigured. }
false;public;0;3;;public JobID getJobId() {     return graph.getJobID(). }
false;public;0;4;;@Override public JobVertexID getJobVertexId() {     return jobVertex.getID(). }
false;public;0;4;;@Override public ExecutionVertex[] getTaskVertices() {     return taskVertices. }
false;public;0;3;;public IntermediateResult[] getProducedDataSets() {     return producedDataSets. }
false;public;0;3;;public InputSplitAssigner getSplitAssigner() {     return splitAssigner. }
false;public;0;3;;public SlotSharingGroup getSlotSharingGroup() {     return slotSharingGroup. }
false;public;0;3;;public CoLocationGroup getCoLocationGroup() {     return coLocationGroup. }
false;public;0;3;;public List<IntermediateResult> getInputs() {     return inputs. }
false;public;0;3;;public InputDependencyConstraint getInputDependencyConstraint() {     return getJobVertex().getInputDependencyConstraint(). }
false;public;0;24;;public Either<SerializedValue<TaskInformation>, PermanentBlobKey> getTaskInformationOrBlobKey() throws IOException {     // serialize the task information!     synchronized (stateMonitor) {         if (taskInformationOrBlobKey == null) {             final BlobWriter blobWriter = graph.getBlobWriter().             final TaskInformation taskInformation = new TaskInformation(jobVertex.getID(), jobVertex.getName(), parallelism, maxParallelism, jobVertex.getInvokableClassName(), jobVertex.getConfiguration()).             taskInformationOrBlobKey = BlobWriter.serializeAndTryOffload(taskInformation, getJobId(), blobWriter).         }         return taskInformationOrBlobKey.     } }
false;public;0;9;;@Override public ExecutionState getAggregateState() {     int[] num = new int[ExecutionState.values().length].     for (ExecutionVertex vertex : this.taskVertices) {         num[vertex.getExecutionState().ordinal()]++.     }     return getAggregateJobVertexState(num, parallelism). }
false;private;0;10;;private String generateDebugString() {     return "ExecutionJobVertex" + "(" + jobVertex.getName() + " | " + jobVertex.getID() + ")" + "{" + "parallelism=" + parallelism + ", maxParallelism=" + getMaxParallelism() + ", maxParallelismConfigured=" + maxParallelismConfigured + '}'. }
false;public;1;39;;// --------------------------------------------------------------------------------------------- public void connectToPredecessors(Map<IntermediateDataSetID, IntermediateResult> intermediateDataSets) throws JobException {     List<JobEdge> inputs = jobVertex.getInputs().     if (LOG.isDebugEnabled()) {         LOG.debug(String.format("Connecting ExecutionJobVertex %s (%s) to %d predecessors.", jobVertex.getID(), jobVertex.getName(), inputs.size())).     }     for (int num = 0. num < inputs.size(). num++) {         JobEdge edge = inputs.get(num).         if (LOG.isDebugEnabled()) {             if (edge.getSource() == null) {                 LOG.debug(String.format("Connecting input %d of vertex %s (%s) to intermediate result referenced via ID %s.", num, jobVertex.getID(), jobVertex.getName(), edge.getSourceId())).             } else {                 LOG.debug(String.format("Connecting input %d of vertex %s (%s) to intermediate result referenced via predecessor %s (%s).", num, jobVertex.getID(), jobVertex.getName(), edge.getSource().getProducer().getID(), edge.getSource().getProducer().getName())).             }         }         // fetch the intermediate result via ID. if it does not exist, then it either has not been created, or the order         // in which this method is called for the job vertices is not a topological order         IntermediateResult ires = intermediateDataSets.get(edge.getSourceId()).         if (ires == null) {             throw new JobException("Cannot connect this job graph to the previous graph. No previous intermediate result found for ID " + edge.getSourceId()).         }         this.inputs.add(ires).         int consumerIndex = ires.registerConsumer().         for (int i = 0. i < parallelism. i++) {             ExecutionVertex ev = taskVertices[i].             ev.connectSource(num, ires, edge, consumerIndex).         }     } }
true;public;4;21;/**  * Schedules all execution vertices of this ExecutionJobVertex.  *  * @param slotProvider to allocate the slots from  * @param queued if the allocations can be queued  * @param locationPreferenceConstraint constraint for the location preferences  * @param allPreviousExecutionGraphAllocationIds set with all previous allocation ids in the job graph.  *                                                 Can be empty if the allocation ids are not required for scheduling.  * @return Future which is completed once all {@link Execution} could be deployed  */ ;// --------------------------------------------------------------------------------------------- // Actions // --------------------------------------------------------------------------------------------- /**  * Schedules all execution vertices of this ExecutionJobVertex.  *  * @param slotProvider to allocate the slots from  * @param queued if the allocations can be queued  * @param locationPreferenceConstraint constraint for the location preferences  * @param allPreviousExecutionGraphAllocationIds set with all previous allocation ids in the job graph.  *                                                 Can be empty if the allocation ids are not required for scheduling.  * @return Future which is completed once all {@link Execution} could be deployed  */ public CompletableFuture<Void> scheduleAll(SlotProvider slotProvider, boolean queued, LocationPreferenceConstraint locationPreferenceConstraint, @Nonnull Set<AllocationID> allPreviousExecutionGraphAllocationIds) {     final ExecutionVertex[] vertices = this.taskVertices.     final ArrayList<CompletableFuture<Void>> scheduleFutures = new ArrayList<>(vertices.length).     // kick off the tasks     for (ExecutionVertex ev : vertices) {         scheduleFutures.add(ev.scheduleForExecution(slotProvider, queued, locationPreferenceConstraint, allPreviousExecutionGraphAllocationIds)).     }     return FutureUtils.waitForAll(scheduleFutures). }
true;public;5;28;/**  * Acquires a slot for all the execution vertices of this ExecutionJobVertex. The method returns  * pairs of the slots and execution attempts, to ease correlation between vertices and execution  * attempts.  *  * <p>If this method throws an exception, it makes sure to release all so far requested slots.  *  * @param resourceProvider The resource provider from whom the slots are requested.  * @param queued if the allocation can be queued  * @param locationPreferenceConstraint constraint for the location preferences  * @param allPreviousExecutionGraphAllocationIds the allocation ids of all previous executions in the execution job graph.  * @param allocationTimeout timeout for allocating the individual slots  */ ;/**  * Acquires a slot for all the execution vertices of this ExecutionJobVertex. The method returns  * pairs of the slots and execution attempts, to ease correlation between vertices and execution  * attempts.  *  * <p>If this method throws an exception, it makes sure to release all so far requested slots.  *  * @param resourceProvider The resource provider from whom the slots are requested.  * @param queued if the allocation can be queued  * @param locationPreferenceConstraint constraint for the location preferences  * @param allPreviousExecutionGraphAllocationIds the allocation ids of all previous executions in the execution job graph.  * @param allocationTimeout timeout for allocating the individual slots  */ public Collection<CompletableFuture<Execution>> allocateResourcesForAll(SlotProvider resourceProvider, boolean queued, LocationPreferenceConstraint locationPreferenceConstraint, @Nonnull Set<AllocationID> allPreviousExecutionGraphAllocationIds, Time allocationTimeout) {     final ExecutionVertex[] vertices = this.taskVertices.     @SuppressWarnings("unchecked")     final CompletableFuture<Execution>[] slots = new CompletableFuture[vertices.length].     // we store the execution with the future just to be on the safe side     for (int i = 0. i < vertices.length. i++) {         // allocate the next slot (future)         final Execution exec = vertices[i].getCurrentExecutionAttempt().         final CompletableFuture<Execution> allocationFuture = exec.allocateAndAssignSlotForExecution(resourceProvider, queued, locationPreferenceConstraint, allPreviousExecutionGraphAllocationIds, allocationTimeout).         slots[i] = allocationFuture.     }     // all good, we acquired all slots     return Arrays.asList(slots). }
true;public;0;5;/**  * Cancels all currently running vertex executions.  */ ;/**  * Cancels all currently running vertex executions.  */ public void cancel() {     for (ExecutionVertex ev : getTaskVertices()) {         ev.cancel().     } }
true;public;0;3;/**  * Cancels all currently running vertex executions.  *  * @return A future that is complete once all tasks have canceled.  */ ;/**  * Cancels all currently running vertex executions.  *  * @return A future that is complete once all tasks have canceled.  */ public CompletableFuture<Void> cancelWithFuture() {     return FutureUtils.waitForAll(mapExecutionVertices(ExecutionVertex::cancel)). }
false;public;0;3;;public CompletableFuture<Void> suspend() {     return FutureUtils.waitForAll(mapExecutionVertices(ExecutionVertex::suspend)). }
false;private;1;6;;@Nonnull private Collection<CompletableFuture<?>> mapExecutionVertices(final Function<ExecutionVertex, CompletableFuture<?>> mapFunction) {     return Arrays.stream(getTaskVertices()).map(mapFunction).collect(Collectors.toList()). }
false;public;1;5;;public void fail(Throwable t) {     for (ExecutionVertex ev : getTaskVertices()) {         ev.fail(t).     } }
false;public;2;32;;public void resetForNewExecution(final long timestamp, final long expectedGlobalModVersion) throws GlobalModVersionMismatch {     synchronized (stateMonitor) {         // check and reset the sharing groups with scheduler hints         if (slotSharingGroup != null) {             slotSharingGroup.clearTaskAssignment().         }         for (int i = 0. i < parallelism. i++) {             taskVertices[i].resetForNewExecution(timestamp, expectedGlobalModVersion).         }         // set up the input splits again         try {             if (this.inputSplits != null) {                 // lazy assignment                 @SuppressWarnings("unchecked")                 InputSplitSource<InputSplit> splitSource = (InputSplitSource<InputSplit>) jobVertex.getInputSplitSource().                 this.splitAssigner = splitSource.getInputSplitAssigner(this.inputSplits).             }         } catch (Throwable t) {             throw new RuntimeException("Re-creating the input split assigner failed: " + t.getMessage(), t).         }         // Reset intermediate results         for (IntermediateResult result : producedDataSets) {             result.resetForNewExecution().         }     } }
false;public;0;12;;// -------------------------------------------------------------------------------------------- // Accumulators / Metrics // -------------------------------------------------------------------------------------------- public StringifiedAccumulatorResult[] getAggregatedUserAccumulatorsStringified() {     Map<String, OptionalFailure<Accumulator<?, ?>>> userAccumulators = new HashMap<>().     for (ExecutionVertex vertex : taskVertices) {         Map<String, Accumulator<?, ?>> next = vertex.getCurrentExecutionAttempt().getUserAccumulators().         if (next != null) {             AccumulatorHelper.mergeInto(userAccumulators, next).         }     }     return StringifiedAccumulatorResult.stringifyAccumulatorResults(userAccumulators). }
false;public;0;4;;// -------------------------------------------------------------------------------------------- // Archiving // -------------------------------------------------------------------------------------------- @Override public ArchivedExecutionJobVertex archive() {     return new ArchivedExecutionJobVertex(this). }
true;public,static;2;26;/**  * A utility function that computes an "aggregated" state for the vertex.  *  * <p>This state is not used anywhere in the  coordination, but can be used for display  * in dashboards to as a summary for how the particular parallel operation represented by  * this ExecutionJobVertex is currently behaving.  *  * <p>For example, if at least one parallel task is failed, the aggregate state is failed.  * If not, and at least one parallel task is cancelling (or cancelled), the aggregate state  * is cancelling (or cancelled). If all tasks are finished, the aggregate state is finished,  * and so on.  *  * @param verticesPerState The number of vertices in each state (indexed by the ordinal of  *                         the ExecutionState values).  * @param parallelism The parallelism of the ExecutionJobVertex  *  * @return The aggregate state of this ExecutionJobVertex.  */ ;// ------------------------------------------------------------------------ // Static Utilities // ------------------------------------------------------------------------ /**  * A utility function that computes an "aggregated" state for the vertex.  *  * <p>This state is not used anywhere in the  coordination, but can be used for display  * in dashboards to as a summary for how the particular parallel operation represented by  * this ExecutionJobVertex is currently behaving.  *  * <p>For example, if at least one parallel task is failed, the aggregate state is failed.  * If not, and at least one parallel task is cancelling (or cancelled), the aggregate state  * is cancelling (or cancelled). If all tasks are finished, the aggregate state is finished,  * and so on.  *  * @param verticesPerState The number of vertices in each state (indexed by the ordinal of  *                         the ExecutionState values).  * @param parallelism The parallelism of the ExecutionJobVertex  *  * @return The aggregate state of this ExecutionJobVertex.  */ public static ExecutionState getAggregateJobVertexState(int[] verticesPerState, int parallelism) {     if (verticesPerState == null || verticesPerState.length != ExecutionState.values().length) {         throw new IllegalArgumentException("Must provide an array as large as there are execution states.").     }     if (verticesPerState[ExecutionState.FAILED.ordinal()] > 0) {         return ExecutionState.FAILED.     }     if (verticesPerState[ExecutionState.CANCELING.ordinal()] > 0) {         return ExecutionState.CANCELING.     } else if (verticesPerState[ExecutionState.CANCELED.ordinal()] > 0) {         return ExecutionState.CANCELED.     } else if (verticesPerState[ExecutionState.RUNNING.ordinal()] > 0) {         return ExecutionState.RUNNING.     } else if (verticesPerState[ExecutionState.FINISHED.ordinal()] > 0) {         return verticesPerState[ExecutionState.FINISHED.ordinal()] == parallelism ? ExecutionState.FINISHED : ExecutionState.RUNNING.     } else {         // all else collapses under created         return ExecutionState.CREATED.     } }
false;public,static;1;24;;public static Map<JobVertexID, ExecutionJobVertex> includeLegacyJobVertexIDs(Map<JobVertexID, ExecutionJobVertex> tasks) {     Map<JobVertexID, ExecutionJobVertex> expanded = new HashMap<>(2 * tasks.size()).     // first include all new ids     expanded.putAll(tasks).     // now expand and add legacy ids     for (ExecutionJobVertex executionJobVertex : tasks.values()) {         if (null != executionJobVertex) {             JobVertex jobVertex = executionJobVertex.getJobVertex().             if (null != jobVertex) {                 List<JobVertexID> alternativeIds = jobVertex.getIdAlternatives().                 for (JobVertexID jobVertexID : alternativeIds) {                     ExecutionJobVertex old = expanded.put(jobVertexID, executionJobVertex).                     Preconditions.checkState(null == old || old.equals(executionJobVertex), "Ambiguous jobvertex id detected during expansion to legacy ids.").                 }             }         }     }     return expanded. }
false;public,static;1;23;;public static Map<OperatorID, ExecutionJobVertex> includeAlternativeOperatorIDs(Map<OperatorID, ExecutionJobVertex> operatorMapping) {     Map<OperatorID, ExecutionJobVertex> expanded = new HashMap<>(2 * operatorMapping.size()).     // first include all existing ids     expanded.putAll(operatorMapping).     // now expand and add user-defined ids     for (ExecutionJobVertex executionJobVertex : operatorMapping.values()) {         if (executionJobVertex != null) {             JobVertex jobVertex = executionJobVertex.getJobVertex().             if (jobVertex != null) {                 for (OperatorID operatorID : jobVertex.getUserDefinedOperatorIDs()) {                     if (operatorID != null) {                         expanded.put(operatorID, executionJobVertex).                     }                 }             }         }     }     return expanded. }
