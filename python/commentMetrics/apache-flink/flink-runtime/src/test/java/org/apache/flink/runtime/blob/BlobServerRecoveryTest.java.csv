# id;timestamp;commentText;codeText;commentWords;codeWords
BlobServerRecoveryTest -> public static void testBlobServerRecovery(final Configuration config, final BlobStore blobStore) throws IOException;1507212387;Helper to test that the {@link BlobServer} recovery from its HA store works.__<p>Uploads two BLOBs to one {@link BlobServer} and expects a second one to be able to retrieve_them via a shared HA store upon request of a {@link BlobCache}.__@param config_blob server configuration (including HA settings like {@link HighAvailabilityOptions#HA_STORAGE_PATH}_and {@link HighAvailabilityOptions#HA_CLUSTER_ID}) used to set up <tt>blobStore</tt>_@param blobStore_shared HA blob store to use__@throws IOException_in case of failures;public static void testBlobServerRecovery(final Configuration config, final BlobStore blobStore) throws IOException {_		final String clusterId = config.getString(HighAvailabilityOptions.HA_CLUSTER_ID)__		String storagePath = config.getString(HighAvailabilityOptions.HA_STORAGE_PATH) + "/" + clusterId__		Random rand = new Random()___		try (_			BlobServer server0 = new BlobServer(config, blobStore)__			BlobServer server1 = new BlobServer(config, blobStore)__			_			BlobCache cache1 = new BlobCache(_				new InetSocketAddress("localhost", server1.getPort()), config,_				new VoidBlobStore())) {__			server0.start()__			server1.start()___			_			byte[] expected = new byte[1024]__			rand.nextBytes(expected)__			byte[] expected2 = Arrays.copyOfRange(expected, 32, 288)___			BlobKey[] keys = new BlobKey[2]__			BlobKey nonHAKey___			_			JobID[] jobId = new JobID[] { new JobID(), new JobID() }__			keys[0] = put(server0, jobId[0], expected, true)_ _			keys[1] = put(server0, jobId[1], expected2, true)_ __			_			nonHAKey = put(server0, jobId[0], expected2, false)__			assertEquals(keys[1], nonHAKey)___			_			final Path blobServerPath = new Path(storagePath, "blob")__			FileSystem fs = blobServerPath.getFileSystem()__			assertTrue("Unknown storage dir: " + blobServerPath, fs.exists(blobServerPath))___			_			verifyContents(cache1, jobId[0], keys[0], expected, true)__			verifyContents(cache1, jobId[1], keys[1], expected2, true)___			_			verifyDeleted(cache1, jobId[0], nonHAKey, true)___			_			server1.cleanupJob(jobId[0])__			server1.cleanupJob(jobId[1])___			_			assertTrue("HA storage directory does not exist", fs.exists(new Path(storagePath)))__			if (fs.exists(blobServerPath)) {_				final org.apache.flink.core.fs.FileStatus[] recoveryFiles =_					fs.listStatus(blobServerPath)__				ArrayList<String> filenames = new ArrayList<>(recoveryFiles.length)__				for (org.apache.flink.core.fs.FileStatus file: recoveryFiles) {_					filenames.add(file.toString())__				}_				fail("Unclean state backend: " + filenames)__			}_		}_	};helper,to,test,that,the,link,blob,server,recovery,from,its,ha,store,works,p,uploads,two,blobs,to,one,link,blob,server,and,expects,a,second,one,to,be,able,to,retrieve,them,via,a,shared,ha,store,upon,request,of,a,link,blob,cache,param,config,blob,server,configuration,including,ha,settings,like,link,high,availability,options,and,link,high,availability,options,used,to,set,up,tt,blob,store,tt,param,blob,store,shared,ha,blob,store,to,use,throws,ioexception,in,case,of,failures;public,static,void,test,blob,server,recovery,final,configuration,config,final,blob,store,blob,store,throws,ioexception,final,string,cluster,id,config,get,string,high,availability,options,string,storage,path,config,get,string,high,availability,options,cluster,id,random,rand,new,random,try,blob,server,server0,new,blob,server,config,blob,store,blob,server,server1,new,blob,server,config,blob,store,blob,cache,cache1,new,blob,cache,new,inet,socket,address,localhost,server1,get,port,config,new,void,blob,store,server0,start,server1,start,byte,expected,new,byte,1024,rand,next,bytes,expected,byte,expected2,arrays,copy,of,range,expected,32,288,blob,key,keys,new,blob,key,2,blob,key,non,hakey,job,id,job,id,new,job,id,new,job,id,new,job,id,keys,0,put,server0,job,id,0,expected,true,keys,1,put,server0,job,id,1,expected2,true,non,hakey,put,server0,job,id,0,expected2,false,assert,equals,keys,1,non,hakey,final,path,blob,server,path,new,path,storage,path,blob,file,system,fs,blob,server,path,get,file,system,assert,true,unknown,storage,dir,blob,server,path,fs,exists,blob,server,path,verify,contents,cache1,job,id,0,keys,0,expected,true,verify,contents,cache1,job,id,1,keys,1,expected2,true,verify,deleted,cache1,job,id,0,non,hakey,true,server1,cleanup,job,job,id,0,server1,cleanup,job,job,id,1,assert,true,ha,storage,directory,does,not,exist,fs,exists,new,path,storage,path,if,fs,exists,blob,server,path,final,org,apache,flink,core,fs,file,status,recovery,files,fs,list,status,blob,server,path,array,list,string,filenames,new,array,list,recovery,files,length,for,org,apache,flink,core,fs,file,status,file,recovery,files,filenames,add,file,to,string,fail,unclean,state,backend,filenames
BlobServerRecoveryTest -> public static void testBlobServerRecovery(final Configuration config, final BlobStore blobStore) throws IOException;1507212387;Helper to test that the {@link BlobServer} recovery from its HA store works.__<p>Uploads two BLOBs to one {@link BlobServer} and expects a second one to be able to retrieve_them via a shared HA store upon request of a {@link BlobCacheService}.__@param config_blob server configuration (including HA settings like {@link HighAvailabilityOptions#HA_STORAGE_PATH}_and {@link HighAvailabilityOptions#HA_CLUSTER_ID}) used to set up <tt>blobStore</tt>_@param blobStore_shared HA blob store to use__@throws IOException_in case of failures;public static void testBlobServerRecovery(final Configuration config, final BlobStore blobStore) throws IOException {_		final String clusterId = config.getString(HighAvailabilityOptions.HA_CLUSTER_ID)__		String storagePath = config.getString(HighAvailabilityOptions.HA_STORAGE_PATH) + "/" + clusterId__		Random rand = new Random()___		try (_			BlobServer server0 = new BlobServer(config, blobStore)__			BlobServer server1 = new BlobServer(config, blobStore)__			_			BlobCacheService cache1 = new BlobCacheService(_				new InetSocketAddress("localhost", server1.getPort()), config,_				new VoidBlobStore())) {__			server0.start()__			server1.start()___			_			byte[] expected = new byte[1024]__			rand.nextBytes(expected)__			byte[] expected2 = Arrays.copyOfRange(expected, 32, 288)___			BlobKey[] keys = new BlobKey[2]__			BlobKey nonHAKey___			_			JobID[] jobId = new JobID[] { new JobID(), new JobID() }__			keys[0] = put(server0, jobId[0], expected, PERMANENT_BLOB)_ _			keys[1] = put(server0, jobId[1], expected2, PERMANENT_BLOB)_ __			_			nonHAKey = put(server0, jobId[0], expected2, TRANSIENT_BLOB)__			assertNotEquals(keys[1], nonHAKey)__			assertThat(keys[1].getHash(), equalTo(nonHAKey.getHash()))___			_			final Path blobServerPath = new Path(storagePath, "blob")__			FileSystem fs = blobServerPath.getFileSystem()__			assertTrue("Unknown storage dir: " + blobServerPath, fs.exists(blobServerPath))___			_			verifyContents(cache1, jobId[0], keys[0], expected)__			verifyContents(cache1, jobId[1], keys[1], expected2)___			_			verifyDeleted(cache1, jobId[0], nonHAKey)___			_			server1.cleanupJob(jobId[0])__			server1.cleanupJob(jobId[1])___			_			assertTrue("HA storage directory does not exist", fs.exists(new Path(storagePath)))__			if (fs.exists(blobServerPath)) {_				final org.apache.flink.core.fs.FileStatus[] recoveryFiles =_					fs.listStatus(blobServerPath)__				ArrayList<String> filenames = new ArrayList<>(recoveryFiles.length)__				for (org.apache.flink.core.fs.FileStatus file: recoveryFiles) {_					filenames.add(file.toString())__				}_				fail("Unclean state backend: " + filenames)__			}_		}_	};helper,to,test,that,the,link,blob,server,recovery,from,its,ha,store,works,p,uploads,two,blobs,to,one,link,blob,server,and,expects,a,second,one,to,be,able,to,retrieve,them,via,a,shared,ha,store,upon,request,of,a,link,blob,cache,service,param,config,blob,server,configuration,including,ha,settings,like,link,high,availability,options,and,link,high,availability,options,used,to,set,up,tt,blob,store,tt,param,blob,store,shared,ha,blob,store,to,use,throws,ioexception,in,case,of,failures;public,static,void,test,blob,server,recovery,final,configuration,config,final,blob,store,blob,store,throws,ioexception,final,string,cluster,id,config,get,string,high,availability,options,string,storage,path,config,get,string,high,availability,options,cluster,id,random,rand,new,random,try,blob,server,server0,new,blob,server,config,blob,store,blob,server,server1,new,blob,server,config,blob,store,blob,cache,service,cache1,new,blob,cache,service,new,inet,socket,address,localhost,server1,get,port,config,new,void,blob,store,server0,start,server1,start,byte,expected,new,byte,1024,rand,next,bytes,expected,byte,expected2,arrays,copy,of,range,expected,32,288,blob,key,keys,new,blob,key,2,blob,key,non,hakey,job,id,job,id,new,job,id,new,job,id,new,job,id,keys,0,put,server0,job,id,0,expected,keys,1,put,server0,job,id,1,expected2,non,hakey,put,server0,job,id,0,expected2,assert,not,equals,keys,1,non,hakey,assert,that,keys,1,get,hash,equal,to,non,hakey,get,hash,final,path,blob,server,path,new,path,storage,path,blob,file,system,fs,blob,server,path,get,file,system,assert,true,unknown,storage,dir,blob,server,path,fs,exists,blob,server,path,verify,contents,cache1,job,id,0,keys,0,expected,verify,contents,cache1,job,id,1,keys,1,expected2,verify,deleted,cache1,job,id,0,non,hakey,server1,cleanup,job,job,id,0,server1,cleanup,job,job,id,1,assert,true,ha,storage,directory,does,not,exist,fs,exists,new,path,storage,path,if,fs,exists,blob,server,path,final,org,apache,flink,core,fs,file,status,recovery,files,fs,list,status,blob,server,path,array,list,string,filenames,new,array,list,recovery,files,length,for,org,apache,flink,core,fs,file,status,file,recovery,files,filenames,add,file,to,string,fail,unclean,state,backend,filenames
BlobServerRecoveryTest -> public static void testBlobServerRecovery(final Configuration config, final BlobStore blobStore) throws IOException;1508138617;Helper to test that the {@link BlobServer} recovery from its HA store works.__<p>Uploads two BLOBs to one {@link BlobServer} and expects a second one to be able to retrieve_them via a shared HA store upon request of a {@link BlobCacheService}.__@param config_blob server configuration (including HA settings like {@link HighAvailabilityOptions#HA_STORAGE_PATH}_and {@link HighAvailabilityOptions#HA_CLUSTER_ID}) used to set up <tt>blobStore</tt>_@param blobStore_shared HA blob store to use__@throws IOException_in case of failures;public static void testBlobServerRecovery(final Configuration config, final BlobStore blobStore) throws IOException {_		final String clusterId = config.getString(HighAvailabilityOptions.HA_CLUSTER_ID)__		String storagePath = config.getString(HighAvailabilityOptions.HA_STORAGE_PATH) + "/" + clusterId__		Random rand = new Random()___		try (_			BlobServer server0 = new BlobServer(config, blobStore)__			BlobServer server1 = new BlobServer(config, blobStore)__			_			BlobCacheService cache1 = new BlobCacheService(_				new InetSocketAddress("localhost", server1.getPort()), config,_				new VoidBlobStore())) {__			server0.start()__			server1.start()___			_			byte[] expected = new byte[1024]__			rand.nextBytes(expected)__			byte[] expected2 = Arrays.copyOfRange(expected, 32, 288)___			BlobKey[] keys = new BlobKey[2]__			BlobKey nonHAKey___			_			JobID[] jobId = new JobID[] { new JobID(), new JobID() }__			keys[0] = put(server0, jobId[0], expected, PERMANENT_BLOB)_ _			keys[1] = put(server0, jobId[1], expected2, PERMANENT_BLOB)_ __			_			nonHAKey = put(server0, jobId[0], expected2, TRANSIENT_BLOB)__			verifyKeyDifferentHashEquals(keys[1], nonHAKey)___			_			final Path blobServerPath = new Path(storagePath, "blob")__			FileSystem fs = blobServerPath.getFileSystem()__			assertTrue("Unknown storage dir: " + blobServerPath, fs.exists(blobServerPath))___			_			verifyContents(cache1, jobId[0], keys[0], expected)__			verifyContents(cache1, jobId[1], keys[1], expected2)___			_			verifyDeleted(cache1, jobId[0], nonHAKey)___			_			server1.cleanupJob(jobId[0])__			server1.cleanupJob(jobId[1])___			_			assertTrue("HA storage directory does not exist", fs.exists(new Path(storagePath)))__			if (fs.exists(blobServerPath)) {_				final org.apache.flink.core.fs.FileStatus[] recoveryFiles =_					fs.listStatus(blobServerPath)__				ArrayList<String> filenames = new ArrayList<>(recoveryFiles.length)__				for (org.apache.flink.core.fs.FileStatus file: recoveryFiles) {_					filenames.add(file.toString())__				}_				fail("Unclean state backend: " + filenames)__			}_		}_	};helper,to,test,that,the,link,blob,server,recovery,from,its,ha,store,works,p,uploads,two,blobs,to,one,link,blob,server,and,expects,a,second,one,to,be,able,to,retrieve,them,via,a,shared,ha,store,upon,request,of,a,link,blob,cache,service,param,config,blob,server,configuration,including,ha,settings,like,link,high,availability,options,and,link,high,availability,options,used,to,set,up,tt,blob,store,tt,param,blob,store,shared,ha,blob,store,to,use,throws,ioexception,in,case,of,failures;public,static,void,test,blob,server,recovery,final,configuration,config,final,blob,store,blob,store,throws,ioexception,final,string,cluster,id,config,get,string,high,availability,options,string,storage,path,config,get,string,high,availability,options,cluster,id,random,rand,new,random,try,blob,server,server0,new,blob,server,config,blob,store,blob,server,server1,new,blob,server,config,blob,store,blob,cache,service,cache1,new,blob,cache,service,new,inet,socket,address,localhost,server1,get,port,config,new,void,blob,store,server0,start,server1,start,byte,expected,new,byte,1024,rand,next,bytes,expected,byte,expected2,arrays,copy,of,range,expected,32,288,blob,key,keys,new,blob,key,2,blob,key,non,hakey,job,id,job,id,new,job,id,new,job,id,new,job,id,keys,0,put,server0,job,id,0,expected,keys,1,put,server0,job,id,1,expected2,non,hakey,put,server0,job,id,0,expected2,verify,key,different,hash,equals,keys,1,non,hakey,final,path,blob,server,path,new,path,storage,path,blob,file,system,fs,blob,server,path,get,file,system,assert,true,unknown,storage,dir,blob,server,path,fs,exists,blob,server,path,verify,contents,cache1,job,id,0,keys,0,expected,verify,contents,cache1,job,id,1,keys,1,expected2,verify,deleted,cache1,job,id,0,non,hakey,server1,cleanup,job,job,id,0,server1,cleanup,job,job,id,1,assert,true,ha,storage,directory,does,not,exist,fs,exists,new,path,storage,path,if,fs,exists,blob,server,path,final,org,apache,flink,core,fs,file,status,recovery,files,fs,list,status,blob,server,path,array,list,string,filenames,new,array,list,recovery,files,length,for,org,apache,flink,core,fs,file,status,file,recovery,files,filenames,add,file,to,string,fail,unclean,state,backend,filenames
BlobServerRecoveryTest -> public static void testBlobServerRecovery(final Configuration config, final BlobStore blobStore) throws IOException;1517915730;Helper to test that the {@link BlobServer} recovery from its HA store works.__<p>Uploads two BLOBs to one {@link BlobServer} and expects a second one to be able to retrieve_them via a shared HA store upon request of a {@link BlobCacheService}.__@param config_blob server configuration (including HA settings like {@link HighAvailabilityOptions#HA_STORAGE_PATH}_and {@link HighAvailabilityOptions#HA_CLUSTER_ID}) used to set up <tt>blobStore</tt>_@param blobStore_shared HA blob store to use__@throws IOException_in case of failures;public static void testBlobServerRecovery(final Configuration config, final BlobStore blobStore) throws IOException {_		final String clusterId = config.getString(HighAvailabilityOptions.HA_CLUSTER_ID)__		String storagePath = config.getString(HighAvailabilityOptions.HA_STORAGE_PATH) + "/" + clusterId__		Random rand = new Random()___		try (_			BlobServer server0 = new BlobServer(config, blobStore)__			BlobServer server1 = new BlobServer(config, blobStore)__			_			BlobCacheService cache1 = new BlobCacheService(_				config, new VoidBlobStore(), new InetSocketAddress("localhost", server1.getPort())_			)) {__			server0.start()__			server1.start()___			_			byte[] expected = new byte[1024]__			rand.nextBytes(expected)__			byte[] expected2 = Arrays.copyOfRange(expected, 32, 288)___			BlobKey[] keys = new BlobKey[2]__			BlobKey nonHAKey___			_			JobID[] jobId = new JobID[] { new JobID(), new JobID() }__			keys[0] = put(server0, jobId[0], expected, PERMANENT_BLOB)_ _			keys[1] = put(server0, jobId[1], expected2, PERMANENT_BLOB)_ __			_			nonHAKey = put(server0, jobId[0], expected2, TRANSIENT_BLOB)__			verifyKeyDifferentHashEquals(keys[1], nonHAKey)___			_			final Path blobServerPath = new Path(storagePath, "blob")__			FileSystem fs = blobServerPath.getFileSystem()__			assertTrue("Unknown storage dir: " + blobServerPath, fs.exists(blobServerPath))___			_			verifyContents(cache1, jobId[0], keys[0], expected)__			verifyContents(cache1, jobId[1], keys[1], expected2)___			_			verifyDeleted(cache1, jobId[0], nonHAKey)___			_			server1.cleanupJob(jobId[0])__			server1.cleanupJob(jobId[1])___			_			assertTrue("HA storage directory does not exist", fs.exists(new Path(storagePath)))__			if (fs.exists(blobServerPath)) {_				final org.apache.flink.core.fs.FileStatus[] recoveryFiles =_					fs.listStatus(blobServerPath)__				ArrayList<String> filenames = new ArrayList<>(recoveryFiles.length)__				for (org.apache.flink.core.fs.FileStatus file: recoveryFiles) {_					filenames.add(file.toString())__				}_				fail("Unclean state backend: " + filenames)__			}_		}_	};helper,to,test,that,the,link,blob,server,recovery,from,its,ha,store,works,p,uploads,two,blobs,to,one,link,blob,server,and,expects,a,second,one,to,be,able,to,retrieve,them,via,a,shared,ha,store,upon,request,of,a,link,blob,cache,service,param,config,blob,server,configuration,including,ha,settings,like,link,high,availability,options,and,link,high,availability,options,used,to,set,up,tt,blob,store,tt,param,blob,store,shared,ha,blob,store,to,use,throws,ioexception,in,case,of,failures;public,static,void,test,blob,server,recovery,final,configuration,config,final,blob,store,blob,store,throws,ioexception,final,string,cluster,id,config,get,string,high,availability,options,string,storage,path,config,get,string,high,availability,options,cluster,id,random,rand,new,random,try,blob,server,server0,new,blob,server,config,blob,store,blob,server,server1,new,blob,server,config,blob,store,blob,cache,service,cache1,new,blob,cache,service,config,new,void,blob,store,new,inet,socket,address,localhost,server1,get,port,server0,start,server1,start,byte,expected,new,byte,1024,rand,next,bytes,expected,byte,expected2,arrays,copy,of,range,expected,32,288,blob,key,keys,new,blob,key,2,blob,key,non,hakey,job,id,job,id,new,job,id,new,job,id,new,job,id,keys,0,put,server0,job,id,0,expected,keys,1,put,server0,job,id,1,expected2,non,hakey,put,server0,job,id,0,expected2,verify,key,different,hash,equals,keys,1,non,hakey,final,path,blob,server,path,new,path,storage,path,blob,file,system,fs,blob,server,path,get,file,system,assert,true,unknown,storage,dir,blob,server,path,fs,exists,blob,server,path,verify,contents,cache1,job,id,0,keys,0,expected,verify,contents,cache1,job,id,1,keys,1,expected2,verify,deleted,cache1,job,id,0,non,hakey,server1,cleanup,job,job,id,0,server1,cleanup,job,job,id,1,assert,true,ha,storage,directory,does,not,exist,fs,exists,new,path,storage,path,if,fs,exists,blob,server,path,final,org,apache,flink,core,fs,file,status,recovery,files,fs,list,status,blob,server,path,array,list,string,filenames,new,array,list,recovery,files,length,for,org,apache,flink,core,fs,file,status,file,recovery,files,filenames,add,file,to,string,fail,unclean,state,backend,filenames
BlobServerRecoveryTest -> public static void testBlobServerRecovery(final Configuration config, final BlobStore blobStore) throws IOException;1526549506;Helper to test that the {@link BlobServer} recovery from its HA store works.__<p>Uploads two BLOBs to one {@link BlobServer} and expects a second one to be able to retrieve_them via a shared HA store upon request of a {@link BlobCacheService}.__@param config_blob server configuration (including HA settings like {@link HighAvailabilityOptions#HA_STORAGE_PATH}_and {@link HighAvailabilityOptions#HA_CLUSTER_ID}) used to set up <tt>blobStore</tt>_@param blobStore_shared HA blob store to use__@throws IOException_in case of failures;public static void testBlobServerRecovery(final Configuration config, final BlobStore blobStore) throws IOException {_		final String clusterId = config.getString(HighAvailabilityOptions.HA_CLUSTER_ID)__		String storagePath = config.getString(HighAvailabilityOptions.HA_STORAGE_PATH) + "/" + clusterId__		Random rand = new Random()___		try (_			BlobServer server0 = new BlobServer(config, blobStore)__			BlobServer server1 = new BlobServer(config, blobStore)__			_			BlobCacheService cache1 = new BlobCacheService(_				config, new VoidBlobStore(), new InetSocketAddress("localhost", server1.getPort())_			)) {__			server0.start()__			server1.start()___			_			byte[] expected = new byte[1024]__			rand.nextBytes(expected)__			byte[] expected2 = Arrays.copyOfRange(expected, 32, 288)___			BlobKey[] keys = new BlobKey[2]__			BlobKey nonHAKey___			_			JobID[] jobId = new JobID[] { new JobID(), new JobID() }__			keys[0] = put(server0, jobId[0], expected, PERMANENT_BLOB)_ _			keys[1] = put(server0, jobId[1], expected2, PERMANENT_BLOB)_ __			_			nonHAKey = put(server0, jobId[0], expected2, TRANSIENT_BLOB)__			verifyKeyDifferentHashEquals(keys[1], nonHAKey)___			_			final Path blobServerPath = new Path(storagePath, "blob")__			FileSystem fs = blobServerPath.getFileSystem()__			assertTrue("Unknown storage dir: " + blobServerPath, fs.exists(blobServerPath))___			_			verifyContents(cache1, jobId[0], keys[0], expected)__			verifyContents(cache1, jobId[1], keys[1], expected2)___			_			verifyDeleted(cache1, jobId[0], nonHAKey)___			_			server1.cleanupJob(jobId[0], true)__			server1.cleanupJob(jobId[1], true)___			_			assertTrue("HA storage directory does not exist", fs.exists(new Path(storagePath)))__			if (fs.exists(blobServerPath)) {_				final org.apache.flink.core.fs.FileStatus[] recoveryFiles =_					fs.listStatus(blobServerPath)__				ArrayList<String> filenames = new ArrayList<>(recoveryFiles.length)__				for (org.apache.flink.core.fs.FileStatus file: recoveryFiles) {_					filenames.add(file.toString())__				}_				fail("Unclean state backend: " + filenames)__			}_		}_	};helper,to,test,that,the,link,blob,server,recovery,from,its,ha,store,works,p,uploads,two,blobs,to,one,link,blob,server,and,expects,a,second,one,to,be,able,to,retrieve,them,via,a,shared,ha,store,upon,request,of,a,link,blob,cache,service,param,config,blob,server,configuration,including,ha,settings,like,link,high,availability,options,and,link,high,availability,options,used,to,set,up,tt,blob,store,tt,param,blob,store,shared,ha,blob,store,to,use,throws,ioexception,in,case,of,failures;public,static,void,test,blob,server,recovery,final,configuration,config,final,blob,store,blob,store,throws,ioexception,final,string,cluster,id,config,get,string,high,availability,options,string,storage,path,config,get,string,high,availability,options,cluster,id,random,rand,new,random,try,blob,server,server0,new,blob,server,config,blob,store,blob,server,server1,new,blob,server,config,blob,store,blob,cache,service,cache1,new,blob,cache,service,config,new,void,blob,store,new,inet,socket,address,localhost,server1,get,port,server0,start,server1,start,byte,expected,new,byte,1024,rand,next,bytes,expected,byte,expected2,arrays,copy,of,range,expected,32,288,blob,key,keys,new,blob,key,2,blob,key,non,hakey,job,id,job,id,new,job,id,new,job,id,new,job,id,keys,0,put,server0,job,id,0,expected,keys,1,put,server0,job,id,1,expected2,non,hakey,put,server0,job,id,0,expected2,verify,key,different,hash,equals,keys,1,non,hakey,final,path,blob,server,path,new,path,storage,path,blob,file,system,fs,blob,server,path,get,file,system,assert,true,unknown,storage,dir,blob,server,path,fs,exists,blob,server,path,verify,contents,cache1,job,id,0,keys,0,expected,verify,contents,cache1,job,id,1,keys,1,expected2,verify,deleted,cache1,job,id,0,non,hakey,server1,cleanup,job,job,id,0,true,server1,cleanup,job,job,id,1,true,assert,true,ha,storage,directory,does,not,exist,fs,exists,new,path,storage,path,if,fs,exists,blob,server,path,final,org,apache,flink,core,fs,file,status,recovery,files,fs,list,status,blob,server,path,array,list,string,filenames,new,array,list,recovery,files,length,for,org,apache,flink,core,fs,file,status,file,recovery,files,filenames,add,file,to,string,fail,unclean,state,backend,filenames
BlobServerRecoveryTest -> @Test 	public void testBlobServerRecovery() throws Exception;1507212387;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		Configuration config = new Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(CoreOptions.STATE_BACKEND, "FILESYSTEM")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, temporaryFolder.newFolder().getPath())___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			testBlobServerRecovery(config, blobStoreService)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,configuration,config,new,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,core,options,filesystem,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,temporary,folder,new,folder,get,path,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,test,blob,server,recovery,config,blob,store,service,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
BlobServerRecoveryTest -> @Test 	public void testBlobServerRecovery() throws Exception;1507212387;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		Configuration config = new Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, temporaryFolder.newFolder().getPath())___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			testBlobServerRecovery(config, blobStoreService)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,configuration,config,new,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,temporary,folder,new,folder,get,path,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,test,blob,server,recovery,config,blob,store,service,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
BlobServerRecoveryTest -> @Test 	public void testBlobServerRecovery() throws Exception;1508138617;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		Configuration config = new Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, temporaryFolder.newFolder().getPath())___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			testBlobServerRecovery(config, blobStoreService)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,configuration,config,new,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,temporary,folder,new,folder,get,path,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,test,blob,server,recovery,config,blob,store,service,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
BlobServerRecoveryTest -> @Test 	public void testBlobServerRecovery() throws Exception;1517915730;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		Configuration config = new Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, temporaryFolder.newFolder().getPath())___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			testBlobServerRecovery(config, blobStoreService)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,configuration,config,new,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,temporary,folder,new,folder,get,path,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,test,blob,server,recovery,config,blob,store,service,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
BlobServerRecoveryTest -> @Test 	public void testBlobServerRecovery() throws Exception;1526549506;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		Configuration config = new Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, temporaryFolder.newFolder().getPath())___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			testBlobServerRecovery(config, blobStoreService)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,configuration,config,new,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,temporary,folder,new,folder,get,path,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,test,blob,server,recovery,config,blob,store,service,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
