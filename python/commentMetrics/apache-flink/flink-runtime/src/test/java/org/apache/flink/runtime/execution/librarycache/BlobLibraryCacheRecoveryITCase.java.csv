commented;modifiers;parameterAmount;loc;comment;code
true;public;0;121;/**  * Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any  * participating BlobLibraryCacheManager.  */ ;/**  * Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any  * participating BlobLibraryCacheManager.  */ @Test public void testRecoveryRegisterAndDownload() throws Exception {     Random rand = new Random().     BlobServer[] server = new BlobServer[2].     InetSocketAddress[] serverAddress = new InetSocketAddress[2].     BlobLibraryCacheManager[] libServer = new BlobLibraryCacheManager[2].     PermanentBlobCache cache = null.     BlobStoreService blobStoreService = null.     Configuration config = new Configuration().     config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER").     config.setString(BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath()).     config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, temporaryFolder.newFolder().getAbsolutePath()).     config.setLong(BlobServerOptions.CLEANUP_INTERVAL, 3_600L).     try {         blobStoreService = BlobUtils.createBlobStoreFromConfig(config).         for (int i = 0. i < server.length. i++) {             server[i] = new BlobServer(config, blobStoreService).             server[i].start().             serverAddress[i] = new InetSocketAddress("localhost", server[i].getPort()).             libServer[i] = new BlobLibraryCacheManager(server[i], FlinkUserCodeClassLoaders.ResolveOrder.CHILD_FIRST, new String[0]).         }         // Random data         byte[] expected = new byte[1024].         rand.nextBytes(expected).         ArrayList<PermanentBlobKey> keys = new ArrayList<>(2).         JobID jobId = new JobID().         // Upload some data (libraries)         // Request 1         keys.add(server[0].putPermanent(jobId, expected)).         byte[] expected2 = Arrays.copyOfRange(expected, 32, 288).         // Request 2         keys.add(server[0].putPermanent(jobId, expected2)).         // The cache         cache = new PermanentBlobCache(config, blobStoreService, serverAddress[0]).         // Register uploaded libraries         ExecutionAttemptID executionId = new ExecutionAttemptID().         libServer[0].registerTask(jobId, executionId, keys, Collections.<URL>emptyList()).         // Verify key 1         File f = cache.getFile(jobId, keys.get(0)).         assertEquals(expected.length, f.length()).         try (FileInputStream fis = new FileInputStream(f)) {             for (int i = 0. i < expected.length && fis.available() > 0. i++) {                 assertEquals(expected[i], (byte) fis.read()).             }             assertEquals(0, fis.available()).         }         // Shutdown cache and start with other server         cache.close().         cache = new PermanentBlobCache(config, blobStoreService, serverAddress[1]).         // Verify key 1         f = cache.getFile(jobId, keys.get(0)).         assertEquals(expected.length, f.length()).         try (FileInputStream fis = new FileInputStream(f)) {             for (int i = 0. i < expected.length && fis.available() > 0. i++) {                 assertEquals(expected[i], (byte) fis.read()).             }             assertEquals(0, fis.available()).         }         // Verify key 2         f = cache.getFile(jobId, keys.get(1)).         assertEquals(expected2.length, f.length()).         try (FileInputStream fis = new FileInputStream(f)) {             for (int i = 0. i < 256 && fis.available() > 0. i++) {                 assertEquals(expected2[i], (byte) fis.read()).             }             assertEquals(0, fis.available()).         }         // Remove blobs again         server[1].cleanupJob(jobId, true).         // Verify everything is clean below recoveryDir/<cluster_id>         final String clusterId = config.getString(HighAvailabilityOptions.HA_CLUSTER_ID).         String haBlobStorePath = config.getString(HighAvailabilityOptions.HA_STORAGE_PATH).         File haBlobStoreDir = new File(haBlobStorePath, clusterId).         File[] recoveryFiles = haBlobStoreDir.listFiles().         assertNotNull("HA storage directory does not exist", recoveryFiles).         assertEquals("Unclean state backend: " + Arrays.toString(recoveryFiles), 0, recoveryFiles.length).     } finally {         for (BlobLibraryCacheManager s : libServer) {             if (s != null) {                 s.shutdown().             }         }         for (BlobServer s : server) {             if (s != null) {                 s.close().             }         }         if (cache != null) {             cache.close().         }         if (blobStoreService != null) {             blobStoreService.closeAndCleanupAllData().         }     } }
