commented;modifiers;parameterAmount;loc;comment;code
false;private,static;0;6;;private static Configuration getFlinkConfiguration() {     Configuration config = new Configuration().     config.setString(TaskManagerOptions.MEMORY_SEGMENT_SIZE, "4096").     config.setInteger(TaskManagerOptions.NETWORK_NUM_BUFFERS, 9).     return config. }
true;public;0;91;/**  * Tests that a task waiting on an async producer/consumer that is stuck  * in a blocking buffer request can be properly cancelled.  *  * <p>This is currently required for the Flink Kafka sources, which spawn  * a separate Thread consuming from Kafka and producing the intermediate  * streams in the spawned Thread instead of the main task Thread.  */ ;/**  * Tests that a task waiting on an async producer/consumer that is stuck  * in a blocking buffer request can be properly cancelled.  *  * <p>This is currently required for the Flink Kafka sources, which spawn  * a separate Thread consuming from Kafka and producing the intermediate  * streams in the spawned Thread instead of the main task Thread.  */ @Test public void testCancelAsyncProducerAndConsumer() throws Exception {     Deadline deadline = Deadline.now().plus(Duration.ofMinutes(2)).     // Job with async producer and consumer     JobVertex producer = new JobVertex("AsyncProducer").     producer.setParallelism(1).     producer.setInvokableClass(AsyncProducer.class).     JobVertex consumer = new JobVertex("AsyncConsumer").     consumer.setParallelism(1).     consumer.setInvokableClass(AsyncConsumer.class).     consumer.connectNewDataSetAsInput(producer, DistributionPattern.POINTWISE, ResultPartitionType.PIPELINED).     SlotSharingGroup slot = new SlotSharingGroup(producer.getID(), consumer.getID()).     producer.setSlotSharingGroup(slot).     consumer.setSlotSharingGroup(slot).     JobGraph jobGraph = new JobGraph(producer, consumer).     final MiniCluster flink = MINI_CLUSTER_RESOURCE.getMiniCluster().     // Submit job and wait until running     flink.runDetached(jobGraph).     FutureUtils.retrySuccessfulWithDelay(() -> flink.getJobStatus(jobGraph.getJobID()), Time.milliseconds(10), deadline, status -> status == JobStatus.RUNNING, TestingUtils.defaultScheduledExecutor()).get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).     boolean producerBlocked = false.     for (int i = 0. i < 50. i++) {         Thread thread = ASYNC_PRODUCER_THREAD.         if (thread != null && thread.isAlive()) {             StackTraceElement[] stackTrace = thread.getStackTrace().             producerBlocked = isInBlockingBufferRequest(stackTrace).         }         if (producerBlocked) {             break.         } else {             // Retry             Thread.sleep(500L).         }     }     // Verify that async producer is in blocking request     assertTrue("Producer thread is not blocked: " + Arrays.toString(ASYNC_PRODUCER_THREAD.getStackTrace()), producerBlocked).     boolean consumerWaiting = false.     for (int i = 0. i < 50. i++) {         Thread thread = ASYNC_CONSUMER_THREAD.         if (thread != null && thread.isAlive()) {             consumerWaiting = thread.getState() == Thread.State.WAITING.         }         if (consumerWaiting) {             break.         } else {             // Retry             Thread.sleep(500L).         }     }     // Verify that async consumer is in blocking request     assertTrue("Consumer thread is not blocked.", consumerWaiting).     flink.cancelJob(jobGraph.getJobID()).get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).     // wait until the job is canceled     FutureUtils.retrySuccessfulWithDelay(() -> flink.getJobStatus(jobGraph.getJobID()), Time.milliseconds(10), deadline, status -> status == JobStatus.CANCELED, TestingUtils.defaultScheduledExecutor()).get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).     // Verify the expected Exceptions     assertNotNull(ASYNC_PRODUCER_EXCEPTION).     assertEquals(IllegalStateException.class, ASYNC_PRODUCER_EXCEPTION.getClass()).     assertNotNull(ASYNC_CONSUMER_EXCEPTION).     assertEquals(IllegalStateException.class, ASYNC_CONSUMER_EXCEPTION.getClass()). }
false;public;0;18;;@Override public void invoke() throws Exception {     Thread producer = new ProducerThread(getEnvironment().getWriter(0)).     // Publish the async producer for the main test Thread     ASYNC_PRODUCER_THREAD = producer.     producer.start().     // main Task thread and will be interrupted on cancellation.     while (producer.isAlive()) {         try {             producer.join().         } catch (InterruptedException ignored) {         }     } }
false;public;0;14;;@Override public void run() {     LongValue current = new LongValue(0).     try {         while (true) {             current.setValue(current.getValue() + 1).             recordWriter.emit(current).             recordWriter.flushAll().         }     } catch (Exception e) {         ASYNC_PRODUCER_EXCEPTION = e.     } }
false;public;0;18;;@Override public void invoke() throws Exception {     Thread consumer = new ConsumerThread(getEnvironment().getInputGate(0)).     // Publish the async consumer for the main test Thread     ASYNC_CONSUMER_THREAD = consumer.     consumer.start().     // main Task thread and will be interrupted on cancellation.     while (consumer.isAlive()) {         try {             consumer.join().         } catch (InterruptedException ignored) {         }     } }
false;public;0;10;;@Override public void run() {     try {         while (true) {             inputGate.getNextBufferOrEvent().         }     } catch (Exception e) {         ASYNC_CONSUMER_EXCEPTION = e.     } }
