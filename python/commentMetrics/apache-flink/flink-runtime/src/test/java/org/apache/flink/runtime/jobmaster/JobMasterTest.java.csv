commented;modifiers;parameterAmount;loc;comment;code
false;public,static;0;7;;@BeforeClass public static void setupClass() {     rpcService = new TestingRpcService().     fastHeartbeatServices = new TestingHeartbeatServices(fastHeartbeatInterval, fastHeartbeatTimeout, rpcService.getScheduledExecutor()).     heartbeatServices = new TestingHeartbeatServices(heartbeatInterval, heartbeatTimeout, rpcService.getScheduledExecutor()). }
false;public;0;18;;@Before public void setup() throws IOException {     configuration = new Configuration().     haServices = new TestingHighAvailabilityServices().     jobMasterId = JobMasterId.generate().     jmResourceId = ResourceID.generate().     testingFatalErrorHandler = new TestingFatalErrorHandler().     haServices.setCheckpointRecoveryFactory(new StandaloneCheckpointRecoveryFactory()).     rmLeaderRetrievalService = new SettableLeaderRetrievalService(null, null).     haServices.setResourceManagerLeaderRetriever(rmLeaderRetrievalService).     configuration.setString(BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath()). }
false;public;0;8;;@After public void teardown() throws Exception {     if (testingFatalErrorHandler != null) {         testingFatalErrorHandler.rethrowError().     }     rpcService.clearGateways(). }
false;public,static;0;7;;@AfterClass public static void teardownClass() {     if (rpcService != null) {         rpcService.stopService().         rpcService = null.     } }
false;public;1;4;;@Override public void declineCheckpoint(DeclineCheckpoint declineCheckpoint) {     declineCheckpointMessageFuture.complete(declineCheckpoint.getReason()). }
false;public;0;67;;@Test public void testDeclineCheckpointInvocationWithUserException() throws Exception {     RpcService rpcService1 = null.     RpcService rpcService2 = null.     try {         final ActorSystem actorSystem1 = AkkaUtils.createDefaultActorSystem().         final ActorSystem actorSystem2 = AkkaUtils.createDefaultActorSystem().         AkkaRpcServiceConfiguration akkaRpcServiceConfig = AkkaRpcServiceConfiguration.fromConfiguration(configuration).         rpcService1 = new AkkaRpcService(actorSystem1, akkaRpcServiceConfig).         rpcService2 = new AkkaRpcService(actorSystem2, akkaRpcServiceConfig).         final CompletableFuture<Throwable> declineCheckpointMessageFuture = new CompletableFuture<>().         final JobManagerSharedServices jobManagerSharedServices = new TestingJobManagerSharedServicesBuilder().build().         final JobMasterConfiguration jobMasterConfiguration = JobMasterConfiguration.fromConfiguration(configuration).         final JobMaster jobMaster = new JobMaster(rpcService1, jobMasterConfiguration, jmResourceId, jobGraph, haServices, DefaultSlotPoolFactory.fromConfiguration(configuration), DefaultSchedulerFactory.fromConfiguration(configuration), jobManagerSharedServices, heartbeatServices, UnregisteredJobManagerJobMetricGroupFactory.INSTANCE, new TestingOnCompletionActions(), testingFatalErrorHandler, JobMasterTest.class.getClassLoader()) {              @Override             public void declineCheckpoint(DeclineCheckpoint declineCheckpoint) {                 declineCheckpointMessageFuture.complete(declineCheckpoint.getReason()).             }         }.         jobMaster.start(jobMasterId).get().         final String className = "UserException".         final URLClassLoader userClassLoader = ClassLoaderUtils.compileAndLoadJava(temporaryFolder.newFolder(), className + ".java", String.format("public class %s extends RuntimeException { public %s() {super(\"UserMessage\").} }", className, className)).         Throwable userException = (Throwable) Class.forName(className, false, userClassLoader).newInstance().         JobMasterGateway jobMasterGateway = rpcService2.connect(jobMaster.getAddress(), jobMaster.getFencingToken(), JobMasterGateway.class).get().         RpcCheckpointResponder rpcCheckpointResponder = new RpcCheckpointResponder(jobMasterGateway).         rpcCheckpointResponder.declineCheckpoint(jobGraph.getJobID(), new ExecutionAttemptID(1, 1), 1, userException).         Throwable throwable = declineCheckpointMessageFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         assertThat(throwable, instanceOf(SerializedThrowable.class)).         assertThat(throwable.getMessage(), equalTo(userException.getMessage())).     } finally {         RpcUtils.terminateRpcServices(testingTimeout, rpcService1, rpcService2).     } }
false;public;0;49;;@Test public void testHeartbeatTimeoutWithTaskManager() throws Exception {     final CompletableFuture<ResourceID> heartbeatResourceIdFuture = new CompletableFuture<>().     final CompletableFuture<JobID> disconnectedJobManagerFuture = new CompletableFuture<>().     final TaskManagerLocation taskManagerLocation = new LocalTaskManagerLocation().     final TestingTaskExecutorGateway taskExecutorGateway = new TestingTaskExecutorGatewayBuilder().setHeartbeatJobManagerConsumer(heartbeatResourceIdFuture::complete).setDisconnectJobManagerConsumer((jobId, throwable) -> disconnectedJobManagerFuture.complete(jobId)).createTestingTaskExecutorGateway().     rpcService.registerGateway(taskExecutorGateway.getAddress(), taskExecutorGateway).     final JobManagerSharedServices jobManagerSharedServices = new TestingJobManagerSharedServicesBuilder().build().     final JobMaster jobMaster = createJobMaster(configuration, jobGraph, haServices, jobManagerSharedServices).     CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).     try {         // wait for the start to complete         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).         // register task manager will trigger monitor heartbeat target, schedule heartbeat request at interval time         CompletableFuture<RegistrationResponse> registrationResponse = jobMasterGateway.registerTaskManager(taskExecutorGateway.getAddress(), taskManagerLocation, testingTimeout).         // wait for the completion of the registration         registrationResponse.get().         final ResourceID heartbeatResourceId = heartbeatResourceIdFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         assertThat(heartbeatResourceId, Matchers.equalTo(jmResourceId)).         final JobID disconnectedJobManager = disconnectedJobManagerFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         assertThat(disconnectedJobManager, Matchers.equalTo(jobGraph.getJobID())).     } finally {         jobManagerSharedServices.shutdown().         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
false;public;0;67;;@Test public void testHeartbeatTimeoutWithResourceManager() throws Exception {     final String resourceManagerAddress = "rm".     final ResourceManagerId resourceManagerId = ResourceManagerId.generate().     final ResourceID rmResourceId = new ResourceID(resourceManagerAddress).     final TestingResourceManagerGateway resourceManagerGateway = new TestingResourceManagerGateway(resourceManagerId, rmResourceId, resourceManagerAddress, "localhost").     final CompletableFuture<Tuple3<JobMasterId, ResourceID, JobID>> jobManagerRegistrationFuture = new CompletableFuture<>().     final CompletableFuture<JobID> disconnectedJobManagerFuture = new CompletableFuture<>().     final CountDownLatch registrationAttempts = new CountDownLatch(2).     resourceManagerGateway.setRegisterJobManagerConsumer(tuple -> {         jobManagerRegistrationFuture.complete(Tuple3.of(tuple.f0, tuple.f1, tuple.f3)).         registrationAttempts.countDown().     }).     resourceManagerGateway.setDisconnectJobManagerConsumer(tuple -> disconnectedJobManagerFuture.complete(tuple.f0)).     rpcService.registerGateway(resourceManagerAddress, resourceManagerGateway).     final JobManagerSharedServices jobManagerSharedServices = new TestingJobManagerSharedServicesBuilder().build().     final JobMaster jobMaster = createJobMaster(configuration, jobGraph, haServices, jobManagerSharedServices).     CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).     try {         // wait for the start operation to complete         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         // define a leader and see that a registration happens         rmLeaderRetrievalService.notifyListener(resourceManagerAddress, resourceManagerId.toUUID()).         // register job manager success will trigger monitor heartbeat target between jm and rm         final Tuple3<JobMasterId, ResourceID, JobID> registrationInformation = jobManagerRegistrationFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         assertThat(registrationInformation.f0, Matchers.equalTo(jobMasterId)).         assertThat(registrationInformation.f1, Matchers.equalTo(jmResourceId)).         assertThat(registrationInformation.f2, Matchers.equalTo(jobGraph.getJobID())).         final JobID disconnectedJobManager = disconnectedJobManagerFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         // heartbeat timeout should trigger disconnect JobManager from ResourceManager         assertThat(disconnectedJobManager, Matchers.equalTo(jobGraph.getJobID())).         // the JobMaster should try to reconnect to the RM         registrationAttempts.await().     } finally {         jobManagerSharedServices.shutdown().         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
true;public;0;33;/**  * Tests that a JobMaster will restore the given JobGraph from its savepoint upon  * initial submission.  */ ;/**  * Tests that a JobMaster will restore the given JobGraph from its savepoint upon  * initial submission.  */ @Test public void testRestoringFromSavepoint() throws Exception {     // create savepoint data     final long savepointId = 42L.     final File savepointFile = createSavepoint(savepointId).     // set savepoint settings     final SavepointRestoreSettings savepointRestoreSettings = SavepointRestoreSettings.forPath(savepointFile.getAbsolutePath(), true).     final JobGraph jobGraph = createJobGraphWithCheckpointing(savepointRestoreSettings).     final StandaloneCompletedCheckpointStore completedCheckpointStore = new StandaloneCompletedCheckpointStore(1).     final TestingCheckpointRecoveryFactory testingCheckpointRecoveryFactory = new TestingCheckpointRecoveryFactory(completedCheckpointStore, new StandaloneCheckpointIDCounter()).     haServices.setCheckpointRecoveryFactory(testingCheckpointRecoveryFactory).     final JobMaster jobMaster = createJobMaster(configuration, jobGraph, haServices, new TestingJobManagerSharedServicesBuilder().build()).     try {         // starting the JobMaster should have read the savepoint         final CompletedCheckpoint savepointCheckpoint = completedCheckpointStore.getLatestCheckpoint().         assertThat(savepointCheckpoint, Matchers.notNullValue()).         assertThat(savepointCheckpoint.getCheckpointID(), is(savepointId)).     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
true;public;0;56;/**  * Tests that a JobMaster will only restore a modified JobGraph if non  * restored state is allowed.  */ ;/**  * Tests that a JobMaster will only restore a modified JobGraph if non  * restored state is allowed.  */ @Test public void testRestoringModifiedJobFromSavepoint() throws Exception {     // create savepoint data     final long savepointId = 42L.     final OperatorID operatorID = new OperatorID().     final File savepointFile = createSavepointWithOperatorState(savepointId, operatorID).     // set savepoint settings which don't allow non restored state     final SavepointRestoreSettings savepointRestoreSettings = SavepointRestoreSettings.forPath(savepointFile.getAbsolutePath(), false).     // create a new operator     final JobVertex jobVertex = new JobVertex("New operator").     jobVertex.setInvokableClass(NoOpInvokable.class).     final JobGraph jobGraphWithNewOperator = createJobGraphFromJobVerticesWithCheckpointing(savepointRestoreSettings, jobVertex).     final StandaloneCompletedCheckpointStore completedCheckpointStore = new StandaloneCompletedCheckpointStore(1).     final TestingCheckpointRecoveryFactory testingCheckpointRecoveryFactory = new TestingCheckpointRecoveryFactory(completedCheckpointStore, new StandaloneCheckpointIDCounter()).     haServices.setCheckpointRecoveryFactory(testingCheckpointRecoveryFactory).     try {         createJobMaster(configuration, jobGraphWithNewOperator, haServices, new TestingJobManagerSharedServicesBuilder().build()).         fail("Should fail because we cannot resume the changed JobGraph from the savepoint.").     } catch (IllegalStateException expected) {     // that was expected :-)     }     // allow for non restored state     jobGraphWithNewOperator.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointFile.getAbsolutePath(), true)).     final JobMaster jobMaster = createJobMaster(configuration, jobGraphWithNewOperator, haServices, new TestingJobManagerSharedServicesBuilder().build()).     try {         // starting the JobMaster should have read the savepoint         final CompletedCheckpoint savepointCheckpoint = completedCheckpointStore.getLatestCheckpoint().         assertThat(savepointCheckpoint, Matchers.notNullValue()).         assertThat(savepointCheckpoint.getCheckpointID(), is(savepointId)).     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
true;public;0;30;/**  * Tests that in a streaming use case where checkpointing is enabled, a  * fixed delay with Integer.MAX_VALUE retries is instantiated if no other restart  * strategy has been specified.  */ ;/**  * Tests that in a streaming use case where checkpointing is enabled, a  * fixed delay with Integer.MAX_VALUE retries is instantiated if no other restart  * strategy has been specified.  */ @Test public void testAutomaticRestartingWhenCheckpointing() throws Exception {     // create savepoint data     final long savepointId = 42L.     final File savepointFile = createSavepoint(savepointId).     // set savepoint settings     final SavepointRestoreSettings savepointRestoreSettings = SavepointRestoreSettings.forPath(savepointFile.getAbsolutePath(), true).     final JobGraph jobGraph = createJobGraphWithCheckpointing(savepointRestoreSettings).     final StandaloneCompletedCheckpointStore completedCheckpointStore = new StandaloneCompletedCheckpointStore(1).     final TestingCheckpointRecoveryFactory testingCheckpointRecoveryFactory = new TestingCheckpointRecoveryFactory(completedCheckpointStore, new StandaloneCheckpointIDCounter()).     haServices.setCheckpointRecoveryFactory(testingCheckpointRecoveryFactory).     final JobMaster jobMaster = createJobMaster(new Configuration(), jobGraph, haServices, new TestingJobManagerSharedServicesBuilder().setRestartStrategyFactory(RestartStrategyFactory.createRestartStrategyFactory(configuration)).build()).     RestartStrategy restartStrategy = jobMaster.getRestartStrategy().     assertNotNull(restartStrategy).     assertTrue(restartStrategy instanceof FixedDelayRestartStrategy). }
true;public;0;47;/**  * Tests that an existing checkpoint will have precedence over an savepoint.  */ ;/**  * Tests that an existing checkpoint will have precedence over an savepoint.  */ @Test public void testCheckpointPrecedesSavepointRecovery() throws Exception {     // create savepoint data     final long savepointId = 42L.     final File savepointFile = createSavepoint(savepointId).     // set savepoint settings     final SavepointRestoreSettings savepointRestoreSettings = SavepointRestoreSettings.forPath("" + savepointFile.getAbsolutePath(), true).     final JobGraph jobGraph = createJobGraphWithCheckpointing(savepointRestoreSettings).     final long checkpointId = 1L.     final CompletedCheckpoint completedCheckpoint = new CompletedCheckpoint(jobGraph.getJobID(), checkpointId, 1L, 1L, Collections.emptyMap(), null, CheckpointProperties.forCheckpoint(CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION), new DummyCheckpointStorageLocation()).     final StandaloneCompletedCheckpointStore completedCheckpointStore = new StandaloneCompletedCheckpointStore(1).     completedCheckpointStore.addCheckpoint(completedCheckpoint).     final TestingCheckpointRecoveryFactory testingCheckpointRecoveryFactory = new TestingCheckpointRecoveryFactory(completedCheckpointStore, new StandaloneCheckpointIDCounter()).     haServices.setCheckpointRecoveryFactory(testingCheckpointRecoveryFactory).     final JobMaster jobMaster = createJobMaster(configuration, jobGraph, haServices, new TestingJobManagerSharedServicesBuilder().build()).     try {         // starting the JobMaster should have read the savepoint         final CompletedCheckpoint savepointCheckpoint = completedCheckpointStore.getLatestCheckpoint().         assertThat(savepointCheckpoint, Matchers.notNullValue()).         assertThat(savepointCheckpoint.getCheckpointID(), is(checkpointId)).     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
true;public;0;70;/**  * Tests that the JobMaster retries the scheduling of a job  * in case of a missing slot offering from a registered TaskExecutor.  */ ;/**  * Tests that the JobMaster retries the scheduling of a job  * in case of a missing slot offering from a registered TaskExecutor.  */ @Test public void testSlotRequestTimeoutWhenNoSlotOffering() throws Exception {     final JobGraph restartingJobGraph = createSingleVertexJobWithRestartStrategy().     final long slotRequestTimeout = 10L.     configuration.setLong(JobManagerOptions.SLOT_REQUEST_TIMEOUT, slotRequestTimeout).     final JobMaster jobMaster = createJobMaster(configuration, restartingJobGraph, haServices, new TestingJobManagerSharedServicesBuilder().build(), heartbeatServices).     final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).     try {         final long start = System.nanoTime().         jobMaster.start(JobMasterId.generate()).get().         final TestingResourceManagerGateway resourceManagerGateway = createAndRegisterTestingResourceManagerGateway().         final ArrayBlockingQueue<SlotRequest> blockingQueue = new ArrayBlockingQueue<>(2).         resourceManagerGateway.setRequestSlotConsumer(blockingQueue::offer).         notifyResourceManagerLeaderListeners(resourceManagerGateway).         // wait for the first slot request         blockingQueue.take().         final CompletableFuture<TaskDeploymentDescriptor> submittedTaskFuture = new CompletableFuture<>().         final LocalTaskManagerLocation taskManagerLocation = new LocalTaskManagerLocation().         final TestingTaskExecutorGateway taskExecutorGateway = new TestingTaskExecutorGatewayBuilder().setSubmitTaskConsumer((tdd, ignored) -> {             submittedTaskFuture.complete(tdd).             return CompletableFuture.completedFuture(Acknowledge.get()).         }).createTestingTaskExecutorGateway().         rpcService.registerGateway(taskExecutorGateway.getAddress(), taskExecutorGateway).         jobMasterGateway.registerTaskManager(taskExecutorGateway.getAddress(), taskManagerLocation, testingTimeout).get().         // wait for the slot request timeout         final SlotRequest slotRequest = blockingQueue.take().         final long end = System.nanoTime().         // we rely on the slot request timeout to fail a stuck scheduling operation         assertThat((end - start) / 1_000_000L, Matchers.greaterThanOrEqualTo(slotRequestTimeout)).         assertThat(submittedTaskFuture.isDone(), is(false)).         final SlotOffer slotOffer = new SlotOffer(slotRequest.getAllocationId(), 0, ResourceProfile.UNKNOWN).         final CompletableFuture<Collection<SlotOffer>> acceptedSlotsFuture = jobMasterGateway.offerSlots(taskManagerLocation.getResourceID(), Collections.singleton(slotOffer), testingTimeout).         final Collection<SlotOffer> acceptedSlots = acceptedSlotsFuture.get().         assertThat(acceptedSlots, hasSize(1)).         final SlotOffer acceptedSlot = acceptedSlots.iterator().next().         assertThat(acceptedSlot.getAllocationId(), equalTo(slotRequest.getAllocationId())).         // wait for the deployed task         final TaskDeploymentDescriptor taskDeploymentDescriptor = submittedTaskFuture.get().         assertThat(taskDeploymentDescriptor.getAllocationId(), equalTo(slotRequest.getAllocationId())).     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
true;public;0;37;/**  * Tests that we can close an unestablished ResourceManager connection.  */ ;/**  * Tests that we can close an unestablished ResourceManager connection.  */ @Test public void testCloseUnestablishedResourceManagerConnection() throws Exception {     final JobMaster jobMaster = createJobMaster(configuration, jobGraph, haServices, new TestingJobManagerSharedServicesBuilder().build()).     try {         jobMaster.start(JobMasterId.generate()).get().         final TestingResourceManagerGateway firstResourceManagerGateway = createAndRegisterTestingResourceManagerGateway().         final TestingResourceManagerGateway secondResourceManagerGateway = createAndRegisterTestingResourceManagerGateway().         final OneShotLatch firstJobManagerRegistration = new OneShotLatch().         final OneShotLatch secondJobManagerRegistration = new OneShotLatch().         firstResourceManagerGateway.setRegisterJobManagerConsumer(jobMasterIdResourceIDStringJobIDTuple4 -> firstJobManagerRegistration.trigger()).         secondResourceManagerGateway.setRegisterJobManagerConsumer(jobMasterIdResourceIDStringJobIDTuple4 -> secondJobManagerRegistration.trigger()).         notifyResourceManagerLeaderListeners(firstResourceManagerGateway).         // wait until we have seen the first registration attempt         firstJobManagerRegistration.await().         // this should stop the connection attempts towards the first RM         notifyResourceManagerLeaderListeners(secondResourceManagerGateway).         // check that we start registering at the second RM         secondJobManagerRegistration.await().     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
true;public;0;38;/**  * Tests that we continue reconnecting to the latest known RM after a disconnection  * message.  */ ;/**  * Tests that we continue reconnecting to the latest known RM after a disconnection  * message.  */ @Test public void testReconnectionAfterDisconnect() throws Exception {     final JobMaster jobMaster = createJobMaster(configuration, jobGraph, haServices, new TestingJobManagerSharedServicesBuilder().build()).     final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).     CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).     try {         // wait for the start to complete         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         final TestingResourceManagerGateway testingResourceManagerGateway = createAndRegisterTestingResourceManagerGateway().         final BlockingQueue<JobMasterId> registrationsQueue = new ArrayBlockingQueue<>(1).         testingResourceManagerGateway.setRegisterJobManagerConsumer(jobMasterIdResourceIDStringJobIDTuple4 -> registrationsQueue.offer(jobMasterIdResourceIDStringJobIDTuple4.f0)).         final ResourceManagerId resourceManagerId = testingResourceManagerGateway.getFencingToken().         notifyResourceManagerLeaderListeners(testingResourceManagerGateway).         // wait for first registration attempt         final JobMasterId firstRegistrationAttempt = registrationsQueue.take().         assertThat(firstRegistrationAttempt, equalTo(jobMasterId)).         assertThat(registrationsQueue.isEmpty(), is(true)).         jobMasterGateway.disconnectResourceManager(resourceManagerId, new FlinkException("Test exception")).         // wait for the second registration attempt after the disconnect call         assertThat(registrationsQueue.take(), equalTo(jobMasterId)).     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
true;public;0;39;/**  * Tests that the a JM connects to the leading RM after regaining leadership.  */ ;/**  * Tests that the a JM connects to the leading RM after regaining leadership.  */ @Test public void testResourceManagerConnectionAfterRegainingLeadership() throws Exception {     final JobMaster jobMaster = createJobMaster(configuration, jobGraph, haServices, new TestingJobManagerSharedServicesBuilder().build()).     CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).     try {         // wait for the start to complete         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         final TestingResourceManagerGateway testingResourceManagerGateway = createAndRegisterTestingResourceManagerGateway().         final BlockingQueue<JobMasterId> registrationQueue = new ArrayBlockingQueue<>(1).         testingResourceManagerGateway.setRegisterJobManagerConsumer(jobMasterIdResourceIDStringJobIDTuple4 -> registrationQueue.offer(jobMasterIdResourceIDStringJobIDTuple4.f0)).         notifyResourceManagerLeaderListeners(testingResourceManagerGateway).         final JobMasterId firstRegistrationAttempt = registrationQueue.take().         assertThat(firstRegistrationAttempt, equalTo(jobMasterId)).         jobMaster.suspend(new FlinkException("Test exception.")).get().         final JobMasterId jobMasterId2 = JobMasterId.generate().         jobMaster.start(jobMasterId2).get().         final JobMasterId secondRegistrationAttempt = registrationQueue.take().         assertThat(secondRegistrationAttempt, equalTo(jobMasterId2)).     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
false;public;0;71;;@Test public void testRequestNextInputSplit() throws Exception {     final List<TestingInputSplit> expectedInputSplits = Arrays.asList(new TestingInputSplit(1), new TestingInputSplit(42), new TestingInputSplit(1337)).     // build one node JobGraph     InputSplitSource<TestingInputSplit> inputSplitSource = new TestingInputSplitSource(expectedInputSplits).     JobVertex source = new JobVertex("vertex1").     source.setParallelism(1).     source.setInputSplitSource(inputSplitSource).     source.setInvokableClass(AbstractInvokable.class).     final JobGraph testJobGraph = new JobGraph(source).     testJobGraph.setAllowQueuedScheduling(true).     configuration.setLong(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_ATTEMPTS, 1).     configuration.setString(ConfigConstants.RESTART_STRATEGY_FIXED_DELAY_DELAY, "0 s").     final JobManagerSharedServices jobManagerSharedServices = new TestingJobManagerSharedServicesBuilder().setRestartStrategyFactory(RestartStrategyFactory.createRestartStrategyFactory(configuration)).build().     final JobMaster jobMaster = createJobMaster(configuration, testJobGraph, haServices, jobManagerSharedServices).     CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).     try {         // wait for the start to complete         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).         ExecutionGraph eg = jobMaster.getExecutionGraph().         ExecutionVertex ev = eg.getAllExecutionVertices().iterator().next().         final SupplierWithException<SerializedInputSplit, Exception> inputSplitSupplier = () -> jobMasterGateway.requestNextInputSplit(source.getID(), ev.getCurrentExecutionAttempt().getAttemptId()).get().         List<InputSplit> actualInputSplits = getInputSplits(expectedInputSplits.size(), inputSplitSupplier).         final Matcher<Iterable<? extends InputSplit>> expectedInputSplitsMatcher = containsInAnyOrder(expectedInputSplits.toArray(EMPTY_TESTING_INPUT_SPLITS)).         assertThat(actualInputSplits, expectedInputSplitsMatcher).         final long maxWaitMillis = 2000L.         ExecutionGraphTestUtils.waitUntilExecutionVertexState(ev, ExecutionState.SCHEDULED, maxWaitMillis).         CompletableFuture.runAsync(() -> eg.failGlobal(new Exception("Testing exception")), eg.getJobMasterMainThreadExecutor()).get().         ExecutionGraphTestUtils.waitUntilExecutionVertexState(ev, ExecutionState.SCHEDULED, maxWaitMillis).         actualInputSplits = getInputSplits(expectedInputSplits.size(), inputSplitSupplier).         assertThat(actualInputSplits, expectedInputSplitsMatcher).     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
false;private,static;2;21;;@Nonnull private static List<InputSplit> getInputSplits(int numberInputSplits, SupplierWithException<SerializedInputSplit, Exception> nextInputSplit) throws Exception {     final List<InputSplit> actualInputSplits = new ArrayList<>(numberInputSplits).     for (int i = 0. i < numberInputSplits. i++) {         final SerializedInputSplit serializedInputSplit = nextInputSplit.get().         assertThat(serializedInputSplit.isEmpty(), is(false)).         actualInputSplits.add(InstantiationUtil.deserializeObject(serializedInputSplit.getInputSplitData(), ClassLoader.getSystemClassLoader())).     }     final SerializedInputSplit serializedInputSplit = nextInputSplit.get().     if (!serializedInputSplit.isEmpty()) {         InputSplit emptyInputSplit = InstantiationUtil.deserializeObject(serializedInputSplit.getInputSplitData(), ClassLoader.getSystemClassLoader()).         assertThat(emptyInputSplit, is(nullValue())).     }     return actualInputSplits. }
false;public;1;4;;@Override public TestingInputSplit[] createInputSplits(int minNumSplits) {     return inputSplits.toArray(EMPTY_TESTING_INPUT_SPLITS). }
false;public;1;4;;@Override public InputSplitAssigner getInputSplitAssigner(TestingInputSplit[] inputSplits) {     return new DefaultInputSplitAssigner(inputSplits). }
false;public;0;3;;public int getSplitNumber() {     return splitNumber. }
false;public;1;13;;@Override public boolean equals(Object o) {     if (this == o) {         return true.     }     if (o == null || getClass() != o.getClass()) {         return false.     }     TestingInputSplit that = (TestingInputSplit) o.     return splitNumber == that.splitNumber. }
false;public;0;4;;@Override public int hashCode() {     return Objects.hash(splitNumber). }
false;public;0;29;;@Test public void testRequestKvStateWithoutRegistration() throws Exception {     final JobGraph graph = createKvJobGraph().     final JobMaster jobMaster = createJobMaster(configuration, graph, haServices, new TestingJobManagerSharedServicesBuilder().build(), heartbeatServices).     CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).     final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).     try {         // wait for the start to complete         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         // lookup location         try {             jobMasterGateway.requestKvStateLocation(graph.getJobID(), "unknown").get().             fail("Expected to fail with UnknownKvStateLocation").         } catch (Exception e) {             assertTrue(ExceptionUtils.findThrowable(e, UnknownKvStateLocation.class).isPresent()).         }     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
false;public;0;29;;@Test public void testRequestKvStateOfWrongJob() throws Exception {     final JobGraph graph = createKvJobGraph().     final JobMaster jobMaster = createJobMaster(configuration, graph, haServices, new TestingJobManagerSharedServicesBuilder().build(), heartbeatServices).     CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).     final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).     try {         // wait for the start to complete         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         // lookup location         try {             jobMasterGateway.requestKvStateLocation(new JobID(), "unknown").get().             fail("Expected to fail with FlinkJobNotFoundException").         } catch (Exception e) {             assertTrue(ExceptionUtils.findThrowable(e, FlinkJobNotFoundException.class).isPresent()).         }     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
false;public;0;14;;@Nonnull public JobGraph createKvJobGraph() {     final JobVertex vertex1 = new JobVertex("v1").     vertex1.setParallelism(4).     vertex1.setMaxParallelism(16).     vertex1.setInvokableClass(BlockingNoOpInvokable.class).     final JobVertex vertex2 = new JobVertex("v2").     vertex2.setParallelism(4).     vertex2.setMaxParallelism(16).     vertex2.setInvokableClass(BlockingNoOpInvokable.class).     return new JobGraph(vertex1, vertex2). }
false;public;0;35;;@Test public void testRequestKvStateWithIrrelevantRegistration() throws Exception {     final JobGraph graph = createKvJobGraph().     final JobMaster jobMaster = createJobMaster(configuration, graph, haServices, new TestingJobManagerSharedServicesBuilder().build(), heartbeatServices).     CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).     final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).     try {         // wait for the start to complete         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         // register an irrelevant KvState         try {             jobMasterGateway.notifyKvStateRegistered(new JobID(), new JobVertexID(), new KeyGroupRange(0, 0), "any-name", new KvStateID(), new InetSocketAddress(InetAddress.getLocalHost(), 1233)).get().             fail("Expected to fail with FlinkJobNotFoundException.").         } catch (Exception e) {             assertTrue(ExceptionUtils.findThrowable(e, FlinkJobNotFoundException.class).isPresent()).         }     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
false;public;0;61;;@Test public void testRegisterAndUnregisterKvState() throws Exception {     final JobGraph graph = createKvJobGraph().     final List<JobVertex> jobVertices = graph.getVerticesSortedTopologicallyFromSources().     final JobVertex vertex1 = jobVertices.get(0).     final JobMaster jobMaster = createJobMaster(configuration, graph, haServices, new TestingJobManagerSharedServicesBuilder().build(), heartbeatServices).     CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).     final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).     try {         // wait for the start to complete         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         // register a KvState         final String registrationName = "register-me".         final KvStateID kvStateID = new KvStateID().         final KeyGroupRange keyGroupRange = new KeyGroupRange(0, 0).         final InetSocketAddress address = new InetSocketAddress(InetAddress.getLocalHost(), 1029).         jobMasterGateway.notifyKvStateRegistered(graph.getJobID(), vertex1.getID(), keyGroupRange, registrationName, kvStateID, address).get().         final KvStateLocation location = jobMasterGateway.requestKvStateLocation(graph.getJobID(), registrationName).get().         assertEquals(graph.getJobID(), location.getJobId()).         assertEquals(vertex1.getID(), location.getJobVertexId()).         assertEquals(vertex1.getMaxParallelism(), location.getNumKeyGroups()).         assertEquals(1, location.getNumRegisteredKeyGroups()).         assertEquals(1, keyGroupRange.getNumberOfKeyGroups()).         assertEquals(kvStateID, location.getKvStateID(keyGroupRange.getStartKeyGroup())).         assertEquals(address, location.getKvStateServerAddress(keyGroupRange.getStartKeyGroup())).         // unregister the KvState         jobMasterGateway.notifyKvStateUnregistered(graph.getJobID(), vertex1.getID(), keyGroupRange, registrationName).get().         try {             jobMasterGateway.requestKvStateLocation(graph.getJobID(), registrationName).get().             fail("Expected to fail with an UnknownKvStateLocation.").         } catch (Exception e) {             assertTrue(ExceptionUtils.findThrowable(e, UnknownKvStateLocation.class).isPresent()).         }     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
false;public;0;54;;@Test public void testDuplicatedKvStateRegistrationsFailTask() throws Exception {     final JobGraph graph = createKvJobGraph().     final List<JobVertex> jobVertices = graph.getVerticesSortedTopologicallyFromSources().     final JobVertex vertex1 = jobVertices.get(0).     final JobVertex vertex2 = jobVertices.get(1).     final JobMaster jobMaster = createJobMaster(configuration, graph, haServices, new TestingJobManagerSharedServicesBuilder().build(), heartbeatServices).     CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).     final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).     try {         // wait for the start to complete         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         // duplicate registration fails task         // register a KvState         final String registrationName = "duplicate-me".         final KvStateID kvStateID = new KvStateID().         final KeyGroupRange keyGroupRange = new KeyGroupRange(0, 0).         final InetSocketAddress address = new InetSocketAddress(InetAddress.getLocalHost(), 4396).         jobMasterGateway.notifyKvStateRegistered(graph.getJobID(), vertex1.getID(), keyGroupRange, registrationName, kvStateID, address).get().         try {             jobMasterGateway.notifyKvStateRegistered(graph.getJobID(), // <--- different operator, but...             vertex2.getID(), keyGroupRange, // ...same name             registrationName, kvStateID, address).get().             fail("Expected to fail because of clashing registration message.").         } catch (Exception e) {             assertTrue(ExceptionUtils.findThrowableWithMessage(e, "Registration name clash").isPresent()).             assertEquals(JobStatus.FAILED, jobMaster.getExecutionGraph().getState()).         }     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
true;public;0;81;/**  * Tests the {@link JobMaster#requestPartitionState(IntermediateDataSetID, ResultPartitionID)}  * call for a finished result partition.  */ ;/**  * Tests the {@link JobMaster#requestPartitionState(IntermediateDataSetID, ResultPartitionID)}  * call for a finished result partition.  */ @Test public void testRequestPartitionState() throws Exception {     final JobGraph producerConsumerJobGraph = producerConsumerJobGraph().     final JobMaster jobMaster = createJobMaster(configuration, producerConsumerJobGraph, haServices, new TestingJobManagerSharedServicesBuilder().build(), heartbeatServices).     CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).     try {         // wait for the start to complete         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         final CompletableFuture<TaskDeploymentDescriptor> tddFuture = new CompletableFuture<>().         final TestingTaskExecutorGateway testingTaskExecutorGateway = new TestingTaskExecutorGatewayBuilder().setSubmitTaskConsumer((taskDeploymentDescriptor, jobMasterId) -> {             tddFuture.complete(taskDeploymentDescriptor).             return CompletableFuture.completedFuture(Acknowledge.get()).         }).createTestingTaskExecutorGateway().         final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).         final Collection<SlotOffer> slotOffers = registerSlotsAtJobMaster(1, jobMasterGateway, testingTaskExecutorGateway).         assertThat(slotOffers, hasSize(1)).         // obtain tdd for the result partition ids         final TaskDeploymentDescriptor tdd = tddFuture.get().         assertThat(tdd.getProducedPartitions(), hasSize(1)).         final ResultPartitionDeploymentDescriptor partition = tdd.getProducedPartitions().iterator().next().         final ExecutionAttemptID executionAttemptId = tdd.getExecutionAttemptId().         final ExecutionAttemptID copiedExecutionAttemptId = new ExecutionAttemptID(executionAttemptId.getLowerPart(), executionAttemptId.getUpperPart()).         // finish the producer task         jobMasterGateway.updateTaskExecutionState(new TaskExecutionState(producerConsumerJobGraph.getJobID(), executionAttemptId, ExecutionState.FINISHED)).get().         // request the state of the result partition of the producer         final ResultPartitionID partitionId = new ResultPartitionID(partition.getPartitionId(), copiedExecutionAttemptId).         CompletableFuture<ExecutionState> partitionStateFuture = jobMasterGateway.requestPartitionState(partition.getResultId(), partitionId).         assertThat(partitionStateFuture.get(), equalTo(ExecutionState.FINISHED)).         // ask for unknown result partition         partitionStateFuture = jobMasterGateway.requestPartitionState(partition.getResultId(), new ResultPartitionID()).         try {             partitionStateFuture.get().             fail("Expected failure.").         } catch (ExecutionException e) {             assertThat(ExceptionUtils.findThrowable(e, IllegalArgumentException.class).isPresent(), is(true)).         }         // ask for wrong intermediate data set id         partitionStateFuture = jobMasterGateway.requestPartitionState(new IntermediateDataSetID(), partitionId).         try {             partitionStateFuture.get().             fail("Expected failure.").         } catch (ExecutionException e) {             assertThat(ExceptionUtils.findThrowable(e, IllegalArgumentException.class).isPresent(), is(true)).         }         // ask for "old" execution         partitionStateFuture = jobMasterGateway.requestPartitionState(partition.getResultId(), new ResultPartitionID(partition.getPartitionId(), new ExecutionAttemptID())).         try {             partitionStateFuture.get().             fail("Expected failure.").         } catch (ExecutionException e) {             assertThat(ExceptionUtils.findThrowable(e, PartitionProducerDisposedException.class).isPresent(), is(true)).         }     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
false;private;1;3;;private void notifyResourceManagerLeaderListeners(TestingResourceManagerGateway testingResourceManagerGateway) {     rmLeaderRetrievalService.notifyListener(testingResourceManagerGateway.getAddress(), testingResourceManagerGateway.getFencingToken().toUUID()). }
false;public;3;7;;@Override public CompletableFuture<String> triggerSavepoint(@Nullable final String targetDirectory, final boolean cancelJob, final Time timeout) {     return new CompletableFuture<>(). }
true;public;0;47;/**  * Tests that the timeout in {@link JobMasterGateway#triggerSavepoint(String, boolean, Time)}  * is respected.  */ ;/**  * Tests that the timeout in {@link JobMasterGateway#triggerSavepoint(String, boolean, Time)}  * is respected.  */ @Test public void testTriggerSavepointTimeout() throws Exception {     final JobMaster jobMaster = new JobMaster(rpcService, JobMasterConfiguration.fromConfiguration(configuration), jmResourceId, jobGraph, haServices, DefaultSlotPoolFactory.fromConfiguration(configuration), DefaultSchedulerFactory.fromConfiguration(configuration), new TestingJobManagerSharedServicesBuilder().build(), heartbeatServices, UnregisteredJobManagerJobMetricGroupFactory.INSTANCE, new TestingOnCompletionActions(), testingFatalErrorHandler, JobMasterTest.class.getClassLoader()) {          @Override         public CompletableFuture<String> triggerSavepoint(@Nullable final String targetDirectory, final boolean cancelJob, final Time timeout) {             return new CompletableFuture<>().         }     }.     try {         final CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).         final CompletableFuture<String> savepointFutureLowTimeout = jobMasterGateway.triggerSavepoint("/tmp", false, Time.milliseconds(1)).         final CompletableFuture<String> savepointFutureHighTimeout = jobMasterGateway.triggerSavepoint("/tmp", false, RpcUtils.INF_TIMEOUT).         try {             savepointFutureLowTimeout.get(testingTimeout.getSize(), testingTimeout.getUnit()).             fail().         } catch (final ExecutionException e) {             final Throwable cause = ExceptionUtils.stripExecutionException(e).             assertThat(cause, instanceOf(TimeoutException.class)).         }         assertThat(savepointFutureHighTimeout.isDone(), is(equalTo(false))).     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
true;public;0;45;/**  * Tests that the TaskExecutor is released if all of its slots have been freed.  */ ;/**  * Tests that the TaskExecutor is released if all of its slots have been freed.  */ @Test public void testReleasingTaskExecutorIfNoMoreSlotsRegistered() throws Exception {     final JobManagerSharedServices jobManagerSharedServices = new TestingJobManagerSharedServicesBuilder().build().     final JobGraph jobGraph = createSingleVertexJobWithRestartStrategy().     final JobMaster jobMaster = createJobMaster(configuration, jobGraph, haServices, jobManagerSharedServices, heartbeatServices).     final CompletableFuture<JobID> disconnectTaskExecutorFuture = new CompletableFuture<>().     final CompletableFuture<AllocationID> freedSlotFuture = new CompletableFuture<>().     final TestingTaskExecutorGateway testingTaskExecutorGateway = new TestingTaskExecutorGatewayBuilder().setFreeSlotFunction((allocationID, throwable) -> {         freedSlotFuture.complete(allocationID).         return CompletableFuture.completedFuture(Acknowledge.get()).     }).setDisconnectJobManagerConsumer((jobID, throwable) -> disconnectTaskExecutorFuture.complete(jobID)).createTestingTaskExecutorGateway().     try {         jobMaster.start(jobMasterId).get().         final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).         final Collection<SlotOffer> slotOffers = registerSlotsAtJobMaster(1, jobMasterGateway, testingTaskExecutorGateway).         // check that we accepted the offered slot         assertThat(slotOffers, hasSize(1)).         final AllocationID allocationId = slotOffers.iterator().next().getAllocationId().         // now fail the allocation and check that we close the connection to the TaskExecutor         jobMasterGateway.notifyAllocationFailure(allocationId, new FlinkException("Fail alloction test exception")).         // we should free the slot and then disconnect from the TaskExecutor because we use no longer slots from it         assertThat(freedSlotFuture.get(), equalTo(allocationId)).         assertThat(disconnectTaskExecutorFuture.get(), equalTo(jobGraph.getJobID())).     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
true;public;0;45;/**  * Tests the updateGlobalAggregate functionality  */ ;/**  * Tests the updateGlobalAggregate functionality  */ @Test public void testJobMasterAggregatesValuesCorrectly() throws Exception {     final JobMaster jobMaster = createJobMaster(configuration, jobGraph, haServices, new TestingJobManagerSharedServicesBuilder().build(), heartbeatServices).     CompletableFuture<Acknowledge> startFuture = jobMaster.start(jobMasterId).     final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).     try {         // wait for the start to complete         startFuture.get(testingTimeout.toMilliseconds(), TimeUnit.MILLISECONDS).         CompletableFuture<Object> updateAggregateFuture.         AggregateFunction<Integer, Integer, Integer> aggregateFunction = createAggregateFunction().         ClosureCleaner.clean(aggregateFunction, true).         byte[] serializedAggregateFunction = InstantiationUtil.serializeObject(aggregateFunction).         updateAggregateFuture = jobMasterGateway.updateGlobalAggregate("agg1", 1, serializedAggregateFunction).         assertThat(updateAggregateFuture.get(), equalTo(1)).         updateAggregateFuture = jobMasterGateway.updateGlobalAggregate("agg1", 2, serializedAggregateFunction).         assertThat(updateAggregateFuture.get(), equalTo(3)).         updateAggregateFuture = jobMasterGateway.updateGlobalAggregate("agg1", 3, serializedAggregateFunction).         assertThat(updateAggregateFuture.get(), equalTo(6)).         updateAggregateFuture = jobMasterGateway.updateGlobalAggregate("agg1", 4, serializedAggregateFunction).         assertThat(updateAggregateFuture.get(), equalTo(10)).         updateAggregateFuture = jobMasterGateway.updateGlobalAggregate("agg2", 10, serializedAggregateFunction).         assertThat(updateAggregateFuture.get(), equalTo(10)).         updateAggregateFuture = jobMasterGateway.updateGlobalAggregate("agg2", 23, serializedAggregateFunction).         assertThat(updateAggregateFuture.get(), equalTo(33)).     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
false;public;0;4;;@Override public Integer createAccumulator() {     return 0. }
false;public;2;6;;@Override public Integer add(Integer value, Integer accumulator) {     Integer _acc = (Integer) accumulator.     Integer _value = (Integer) value.     return _acc + _value. }
false;public;1;4;;@Override public Integer getResult(Integer accumulator) {     return accumulator. }
false;public;2;4;;@Override public Integer merge(Integer a, Integer b) {     return add(a, b). }
false;private;0;26;;private AggregateFunction<Integer, Integer, Integer> createAggregateFunction() {     return new AggregateFunction<Integer, Integer, Integer>() {          @Override         public Integer createAccumulator() {             return 0.         }          @Override         public Integer add(Integer value, Integer accumulator) {             Integer _acc = (Integer) accumulator.             Integer _value = (Integer) value.             return _acc + _value.         }          @Override         public Integer getResult(Integer accumulator) {             return accumulator.         }          @Override         public Integer merge(Integer a, Integer b) {             return add(a, b).         }     }. }
false;private;0;6;;@Nonnull private TestingResourceManagerGateway createAndRegisterTestingResourceManagerGateway() {     final TestingResourceManagerGateway testingResourceManagerGateway = new TestingResourceManagerGateway().     rpcService.registerGateway(testingResourceManagerGateway.getAddress(), testingResourceManagerGateway).     return testingResourceManagerGateway. }
true;public;0;9;/**  * Tests that the job execution is failed if the TaskExecutor disconnects from the  * JobMaster.  */ ;/**  * Tests that the job execution is failed if the TaskExecutor disconnects from the  * JobMaster.  */ @Test public void testJobFailureWhenGracefulTaskExecutorTermination() throws Exception {     runJobFailureWhenTaskExecutorTerminatesTest(heartbeatServices, (localTaskManagerLocation, jobMasterGateway) -> jobMasterGateway.disconnectTaskManager(localTaskManagerLocation.getResourceID(), new FlinkException("Test disconnectTaskManager exception.")), (jobMasterGateway, resourceID) -> ignored -> {     }). }
false;public;0;13;;@Test public void testJobFailureWhenTaskExecutorHeartbeatTimeout() throws Exception {     final AtomicBoolean respondToHeartbeats = new AtomicBoolean(true).     runJobFailureWhenTaskExecutorTerminatesTest(fastHeartbeatServices, (localTaskManagerLocation, jobMasterGateway) -> respondToHeartbeats.set(false), (jobMasterGateway, taskManagerResourceId) -> resourceId -> {         if (respondToHeartbeats.get()) {             jobMasterGateway.heartbeatFromTaskManager(taskManagerResourceId, new AccumulatorReport(Collections.emptyList())).         }     }). }
false;private;3;45;;private void runJobFailureWhenTaskExecutorTerminatesTest(HeartbeatServices heartbeatServices, BiConsumer<LocalTaskManagerLocation, JobMasterGateway> jobReachedRunningState, BiFunction<JobMasterGateway, ResourceID, Consumer<ResourceID>> heartbeatConsumerFunction) throws Exception {     final JobGraph jobGraph = createSingleVertexJobGraph().     final TestingOnCompletionActions onCompletionActions = new TestingOnCompletionActions().     final JobMaster jobMaster = createJobMaster(new Configuration(), jobGraph, haServices, new TestingJobManagerSharedServicesBuilder().build(), heartbeatServices, onCompletionActions).     try {         jobMaster.start(jobMasterId).get().         final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class).         final LocalTaskManagerLocation taskManagerLocation = new LocalTaskManagerLocation().         final CompletableFuture<ExecutionAttemptID> taskDeploymentFuture = new CompletableFuture<>().         final TestingTaskExecutorGateway taskExecutorGateway = new TestingTaskExecutorGatewayBuilder().setSubmitTaskConsumer((taskDeploymentDescriptor, jobMasterId) -> {             taskDeploymentFuture.complete(taskDeploymentDescriptor.getExecutionAttemptId()).             return CompletableFuture.completedFuture(Acknowledge.get()).         }).setHeartbeatJobManagerConsumer(heartbeatConsumerFunction.apply(jobMasterGateway, taskManagerLocation.getResourceID())).createTestingTaskExecutorGateway().         final Collection<SlotOffer> slotOffers = registerSlotsAtJobMaster(1, jobMasterGateway, taskExecutorGateway, taskManagerLocation).         assertThat(slotOffers, hasSize(1)).         final ExecutionAttemptID executionAttemptId = taskDeploymentFuture.get().         jobMasterGateway.updateTaskExecutionState(new TaskExecutionState(jobGraph.getJobID(), executionAttemptId, ExecutionState.RUNNING)).get().         jobReachedRunningState.accept(taskManagerLocation, jobMasterGateway).         final ArchivedExecutionGraph archivedExecutionGraph = onCompletionActions.getJobReachedGloballyTerminalStateFuture().get().         assertThat(archivedExecutionGraph.getState(), is(JobStatus.FAILED)).     } finally {         RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout).     } }
false;public;1;4;;@Override public void jobReachedGloballyTerminalState(ArchivedExecutionGraph executionGraph) {     jobReachedGloballyTerminalStateFuture.complete(executionGraph). }
false;public;0;4;;@Override public void jobFinishedByOther() {     jobFinishedByOtherFuture.complete(null). }
false;public;1;4;;@Override public void jobMasterFailed(Throwable cause) {     jobMasterFailedFuture.complete(cause). }
false;public;0;3;;public CompletableFuture<ArchivedExecutionGraph> getJobReachedGloballyTerminalStateFuture() {     return jobReachedGloballyTerminalStateFuture. }
false;private;3;10;;private Collection<SlotOffer> registerSlotsAtJobMaster(int numberSlots, JobMasterGateway jobMasterGateway, TaskExecutorGateway taskExecutorGateway) throws ExecutionException, InterruptedException {     return registerSlotsAtJobMaster(numberSlots, jobMasterGateway, taskExecutorGateway, new LocalTaskManagerLocation()). }
false;private;4;24;;private Collection<SlotOffer> registerSlotsAtJobMaster(int numberSlots, JobMasterGateway jobMasterGateway, TaskExecutorGateway taskExecutorGateway, TaskManagerLocation taskManagerLocation) throws ExecutionException, InterruptedException {     final AllocationIdsResourceManagerGateway allocationIdsResourceManagerGateway = new AllocationIdsResourceManagerGateway().     rpcService.registerGateway(allocationIdsResourceManagerGateway.getAddress(), allocationIdsResourceManagerGateway).     notifyResourceManagerLeaderListeners(allocationIdsResourceManagerGateway).     rpcService.registerGateway(taskExecutorGateway.getAddress(), taskExecutorGateway).     jobMasterGateway.registerTaskManager(taskExecutorGateway.getAddress(), taskManagerLocation, testingTimeout).get().     Collection<SlotOffer> slotOffers = IntStream.range(0, numberSlots).mapToObj(index -> {         final AllocationID allocationId = allocationIdsResourceManagerGateway.takeAllocationId().         return new SlotOffer(allocationId, index, ResourceProfile.UNKNOWN).     }).collect(Collectors.toList()).     return jobMasterGateway.offerSlots(taskManagerLocation.getResourceID(), slotOffers, testingTimeout).get(). }
false;;0;8;;AllocationID takeAllocationId() {     try {         return allocationIds.take().     } catch (InterruptedException e) {         ExceptionUtils.rethrow(e).         return null.     } }
false;private;0;13;;private JobGraph producerConsumerJobGraph() {     final JobVertex producer = new JobVertex("Producer").     producer.setInvokableClass(NoOpInvokable.class).     final JobVertex consumer = new JobVertex("Consumer").     consumer.setInvokableClass(NoOpInvokable.class).     consumer.connectNewDataSetAsInput(producer, DistributionPattern.POINTWISE, ResultPartitionType.BLOCKING).     final JobGraph jobGraph = new JobGraph(producer, consumer).     jobGraph.setAllowQueuedScheduling(true).     return jobGraph. }
false;private;1;3;;private File createSavepoint(long savepointId) throws IOException {     return createSavepointWithOperatorState(savepointId). }
false;private;2;11;;private File createSavepointWithOperatorState(long savepointId, OperatorID... operatorIds) throws IOException {     final File savepointFile = temporaryFolder.newFile().     final Collection<OperatorState> operatorStates = createOperatorState(operatorIds).     final SavepointV2 savepoint = new SavepointV2(savepointId, operatorStates, Collections.emptyList()).     try (FileOutputStream fileOutputStream = new FileOutputStream(savepointFile)) {         Checkpoints.storeCheckpointMetadata(savepoint, fileOutputStream).     }     return savepointFile. }
false;private;1;18;;private Collection<OperatorState> createOperatorState(OperatorID... operatorIds) {     Collection<OperatorState> operatorStates = new ArrayList<>(operatorIds.length).     for (OperatorID operatorId : operatorIds) {         final OperatorState operatorState = new OperatorState(operatorId, 1, 42).         final OperatorSubtaskState subtaskState = new OperatorSubtaskState(new OperatorStreamStateHandle(Collections.emptyMap(), new ByteStreamStateHandle("foobar", new byte[0])), null, null, null).         operatorState.putState(0, subtaskState).         operatorStates.add(operatorState).     }     return operatorStates. }
false;private;1;4;;@Nonnull private JobGraph createJobGraphWithCheckpointing(SavepointRestoreSettings savepointRestoreSettings) {     return createJobGraphFromJobVerticesWithCheckpointing(savepointRestoreSettings). }
false;private;2;23;;@Nonnull private JobGraph createJobGraphFromJobVerticesWithCheckpointing(SavepointRestoreSettings savepointRestoreSettings, JobVertex... jobVertices) {     final JobGraph jobGraph = new JobGraph(jobVertices).     // enable checkpointing which is required to resume from a savepoint     final CheckpointCoordinatorConfiguration checkpoinCoordinatorConfiguration = new CheckpointCoordinatorConfiguration(1000L, 1000L, 1000L, 1, CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION, true).     final JobCheckpointingSettings checkpointingSettings = new JobCheckpointingSettings(Collections.emptyList(), Collections.emptyList(), Collections.emptyList(), checkpoinCoordinatorConfiguration, null).     jobGraph.setSnapshotSettings(checkpointingSettings).     jobGraph.setSavepointRestoreSettings(savepointRestoreSettings).     return jobGraph. }
false;private;4;13;;@Nonnull private JobMaster createJobMaster(Configuration configuration, JobGraph jobGraph, HighAvailabilityServices highAvailabilityServices, JobManagerSharedServices jobManagerSharedServices) throws Exception {     return createJobMaster(configuration, jobGraph, highAvailabilityServices, jobManagerSharedServices, fastHeartbeatServices). }
false;private;5;16;;@Nonnull private JobMaster createJobMaster(Configuration configuration, JobGraph jobGraph, HighAvailabilityServices highAvailabilityServices, JobManagerSharedServices jobManagerSharedServices, HeartbeatServices heartbeatServices) throws Exception {     return createJobMaster(configuration, jobGraph, highAvailabilityServices, jobManagerSharedServices, heartbeatServices, new TestingOnCompletionActions()). }
false;private;6;25;;@Nonnull private JobMaster createJobMaster(Configuration configuration, JobGraph jobGraph, HighAvailabilityServices highAvailabilityServices, JobManagerSharedServices jobManagerSharedServices, HeartbeatServices heartbeatServices, OnCompletionActions onCompletionActions) throws Exception {     final JobMasterConfiguration jobMasterConfiguration = JobMasterConfiguration.fromConfiguration(configuration).     return new JobMaster(rpcService, jobMasterConfiguration, jmResourceId, jobGraph, highAvailabilityServices, DefaultSlotPoolFactory.fromConfiguration(configuration), DefaultSchedulerFactory.fromConfiguration(configuration), jobManagerSharedServices, heartbeatServices, UnregisteredJobManagerJobMetricGroupFactory.INSTANCE, onCompletionActions, testingFatalErrorHandler, JobMasterTest.class.getClassLoader()). }
false;private;0;9;;private JobGraph createSingleVertexJobWithRestartStrategy() throws IOException {     final JobGraph jobGraph = createSingleVertexJobGraph().     final ExecutionConfig executionConfig = new ExecutionConfig().     executionConfig.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0L)).     jobGraph.setExecutionConfig(executionConfig).     return jobGraph. }
false;private;0;9;;@Nonnull private JobGraph createSingleVertexJobGraph() {     final JobVertex jobVertex = new JobVertex("Test vertex").     jobVertex.setInvokableClass(NoOpInvokable.class).     final JobGraph jobGraph = new JobGraph(jobVertex).     jobGraph.setAllowQueuedScheduling(true).     return jobGraph. }
false;public;0;4;;@Override public String getExternalPointer() {     return null. }
false;public;0;4;;@Override public StreamStateHandle getMetadataHandle() {     return null. }
false;public;0;4;;@Override public void disposeStorageLocation() throws IOException { }
