commented;modifiers;parameterAmount;loc;comment;code
true;protected;1;3;/**  * Checks that the job information for the given ID has been offloaded successfully (if  * offloading is used).  *  * @param eg           the execution graph that was created  */ ;/**  * Checks that the job information for the given ID has been offloaded successfully (if  * offloading is used).  *  * @param eg           the execution graph that was created  */ protected void checkJobOffloaded(ExecutionGraph eg) throws Exception {     assertTrue(eg.getJobInformationOrBlobKey().isLeft()). }
true;protected;2;3;/**  * Checks that the task information for the job vertex has been offloaded successfully (if  * offloading is used).  *  * @param eg           the execution graph that was created  * @param jobVertexId  job vertex ID  */ ;/**  * Checks that the task information for the job vertex has been offloaded successfully (if  * offloading is used).  *  * @param eg           the execution graph that was created  * @param jobVertexId  job vertex ID  */ protected void checkTaskOffloaded(ExecutionGraph eg, JobVertexID jobVertexId) throws Exception {     assertTrue(eg.getJobVertex(jobVertexId).getTaskInformationOrBlobKey().isLeft()). }
false;public;0;108;;@Test public void testBuildDeploymentDescriptor() {     try {         final JobID jobId = new JobID().         final JobVertexID jid1 = new JobVertexID().         final JobVertexID jid2 = new JobVertexID().         final JobVertexID jid3 = new JobVertexID().         final JobVertexID jid4 = new JobVertexID().         JobVertex v1 = new JobVertex("v1", jid1).         JobVertex v2 = new JobVertex("v2", jid2).         JobVertex v3 = new JobVertex("v3", jid3).         JobVertex v4 = new JobVertex("v4", jid4).         v1.setParallelism(10).         v2.setParallelism(10).         v3.setParallelism(10).         v4.setParallelism(10).         v1.setInvokableClass(BatchTask.class).         v2.setInvokableClass(BatchTask.class).         v3.setInvokableClass(BatchTask.class).         v4.setInvokableClass(BatchTask.class).         v2.connectNewDataSetAsInput(v1, DistributionPattern.ALL_TO_ALL, ResultPartitionType.PIPELINED).         v3.connectNewDataSetAsInput(v2, DistributionPattern.ALL_TO_ALL, ResultPartitionType.PIPELINED).         v4.connectNewDataSetAsInput(v2, DistributionPattern.ALL_TO_ALL, ResultPartitionType.PIPELINED).         final JobInformation expectedJobInformation = new DummyJobInformation(jobId, "some job").         DirectScheduledExecutorService executor = new DirectScheduledExecutorService().         ExecutionGraph eg = new ExecutionGraph(expectedJobInformation, executor, executor, AkkaUtils.getDefaultTimeout(), new NoRestartStrategy(), new RestartAllStrategy.Factory(), new TestingSlotProvider(ignore -> new CompletableFuture<>()), ExecutionGraph.class.getClassLoader(), blobWriter, AkkaUtils.getDefaultTimeout()).         eg.start(TestingComponentMainThreadExecutorServiceAdapter.forMainThread()).         checkJobOffloaded(eg).         List<JobVertex> ordered = Arrays.asList(v1, v2, v3, v4).         eg.attachJobGraph(ordered).         ExecutionJobVertex ejv = eg.getAllVertices().get(jid2).         ExecutionVertex vertex = ejv.getTaskVertices()[3].         final SimpleAckingTaskManagerGateway taskManagerGateway = new SimpleAckingTaskManagerGateway().         final CompletableFuture<TaskDeploymentDescriptor> tdd = new CompletableFuture<>().         taskManagerGateway.setSubmitConsumer(FunctionUtils.uncheckedConsumer(taskDeploymentDescriptor -> {             taskDeploymentDescriptor.loadBigData(blobCache).             tdd.complete(taskDeploymentDescriptor).         })).         final LogicalSlot slot = new TestingLogicalSlot(taskManagerGateway).         assertEquals(ExecutionState.CREATED, vertex.getExecutionState()).         vertex.deployToSlot(slot).         assertEquals(ExecutionState.DEPLOYING, vertex.getExecutionState()).         checkTaskOffloaded(eg, vertex.getJobvertexId()).         TaskDeploymentDescriptor descr = tdd.get().         assertNotNull(descr).         JobInformation jobInformation = descr.getSerializedJobInformation().deserializeValue(getClass().getClassLoader()).         TaskInformation taskInformation = descr.getSerializedTaskInformation().deserializeValue(getClass().getClassLoader()).         assertEquals(jobId, descr.getJobId()).         assertEquals(jobId, jobInformation.getJobId()).         assertEquals(jid2, taskInformation.getJobVertexId()).         assertEquals(3, descr.getSubtaskIndex()).         assertEquals(10, taskInformation.getNumberOfSubtasks()).         assertEquals(BatchTask.class.getName(), taskInformation.getInvokableClassName()).         assertEquals("v2", taskInformation.getTaskName()).         Collection<ResultPartitionDeploymentDescriptor> producedPartitions = descr.getProducedPartitions().         Collection<InputGateDeploymentDescriptor> consumedPartitions = descr.getInputGates().         assertEquals(2, producedPartitions.size()).         assertEquals(1, consumedPartitions.size()).         Iterator<ResultPartitionDeploymentDescriptor> iteratorProducedPartitions = producedPartitions.iterator().         Iterator<InputGateDeploymentDescriptor> iteratorConsumedPartitions = consumedPartitions.iterator().         assertEquals(10, iteratorProducedPartitions.next().getNumberOfSubpartitions()).         assertEquals(10, iteratorProducedPartitions.next().getNumberOfSubpartitions()).         assertEquals(10, iteratorConsumedPartitions.next().getInputChannelDeploymentDescriptors().length).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
false;public;0;22;;@Test public void testRegistrationOfExecutionsFinishing() {     try {         final JobVertexID jid1 = new JobVertexID().         final JobVertexID jid2 = new JobVertexID().         JobVertex v1 = new JobVertex("v1", jid1).         JobVertex v2 = new JobVertex("v2", jid2).         Map<ExecutionAttemptID, Execution> executions = setupExecution(v1, 7650, v2, 2350).f1.         for (Execution e : executions.values()) {             e.markFinished().         }         assertEquals(0, executions.size()).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
false;public;0;23;;@Test public void testRegistrationOfExecutionsFailing() {     try {         final JobVertexID jid1 = new JobVertexID().         final JobVertexID jid2 = new JobVertexID().         JobVertex v1 = new JobVertex("v1", jid1).         JobVertex v2 = new JobVertex("v2", jid2).         Map<ExecutionAttemptID, Execution> executions = setupExecution(v1, 7, v2, 6).f1.         for (Execution e : executions.values()) {             e.markFailed(null).         }         assertEquals(0, executions.size()).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
false;public;0;23;;@Test public void testRegistrationOfExecutionsFailedExternally() {     try {         final JobVertexID jid1 = new JobVertexID().         final JobVertexID jid2 = new JobVertexID().         JobVertex v1 = new JobVertex("v1", jid1).         JobVertex v2 = new JobVertex("v2", jid2).         Map<ExecutionAttemptID, Execution> executions = setupExecution(v1, 7, v2, 6).f1.         for (Execution e : executions.values()) {             e.fail(null).         }         assertEquals(0, executions.size()).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
true;public;0;43;/**  * Verifies that {@link ExecutionGraph#updateState(TaskExecutionState)} updates the accumulators and metrics for an  * execution that failed or was canceled.  */ ;/**  * Verifies that {@link ExecutionGraph#updateState(TaskExecutionState)} updates the accumulators and metrics for an  * execution that failed or was canceled.  */ @Test public void testAccumulatorsAndMetricsForwarding() throws Exception {     final JobVertexID jid1 = new JobVertexID().     final JobVertexID jid2 = new JobVertexID().     JobVertex v1 = new JobVertex("v1", jid1).     JobVertex v2 = new JobVertex("v2", jid2).     Tuple2<ExecutionGraph, Map<ExecutionAttemptID, Execution>> graphAndExecutions = setupExecution(v1, 1, v2, 1).     ExecutionGraph graph = graphAndExecutions.f0.     // verify behavior for canceled executions     Execution execution1 = graphAndExecutions.f1.values().iterator().next().     IOMetrics ioMetrics = new IOMetrics(0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0).     Map<String, Accumulator<?, ?>> accumulators = new HashMap<>().     accumulators.put("acc", new IntCounter(4)).     AccumulatorSnapshot accumulatorSnapshot = new AccumulatorSnapshot(graph.getJobID(), execution1.getAttemptId(), accumulators).     TaskExecutionState state = new TaskExecutionState(graph.getJobID(), execution1.getAttemptId(), ExecutionState.CANCELED, null, accumulatorSnapshot, ioMetrics).     graph.updateState(state).     assertEquals(ioMetrics, execution1.getIOMetrics()).     assertNotNull(execution1.getUserAccumulators()).     assertEquals(4, execution1.getUserAccumulators().get("acc").getLocalValue()).     // verify behavior for failed executions     Execution execution2 = graphAndExecutions.f1.values().iterator().next().     IOMetrics ioMetrics2 = new IOMetrics(0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0).     Map<String, Accumulator<?, ?>> accumulators2 = new HashMap<>().     accumulators2.put("acc", new IntCounter(8)).     AccumulatorSnapshot accumulatorSnapshot2 = new AccumulatorSnapshot(graph.getJobID(), execution2.getAttemptId(), accumulators2).     TaskExecutionState state2 = new TaskExecutionState(graph.getJobID(), execution2.getAttemptId(), ExecutionState.FAILED, null, accumulatorSnapshot2, ioMetrics2).     graph.updateState(state2).     assertEquals(ioMetrics2, execution2.getIOMetrics()).     assertNotNull(execution2.getUserAccumulators()).     assertEquals(8, execution2.getUserAccumulators().get("acc").getLocalValue()). }
true;public;0;26;/**  * Verifies that {@link Execution#completeCancelling(Map, IOMetrics)} and {@link Execution#markFailed(Throwable, Map, IOMetrics)}  * store the given accumulators and metrics correctly.  */ ;/**  * Verifies that {@link Execution#completeCancelling(Map, IOMetrics)} and {@link Execution#markFailed(Throwable, Map, IOMetrics)}  * store the given accumulators and metrics correctly.  */ @Test public void testAccumulatorsAndMetricsStorage() throws Exception {     final JobVertexID jid1 = new JobVertexID().     final JobVertexID jid2 = new JobVertexID().     JobVertex v1 = new JobVertex("v1", jid1).     JobVertex v2 = new JobVertex("v2", jid2).     Map<ExecutionAttemptID, Execution> executions = setupExecution(v1, 1, v2, 1).f1.     IOMetrics ioMetrics = new IOMetrics(0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0).     Map<String, Accumulator<?, ?>> accumulators = Collections.emptyMap().     Execution execution1 = executions.values().iterator().next().     execution1.cancel().     execution1.completeCancelling(accumulators, ioMetrics).     assertEquals(ioMetrics, execution1.getIOMetrics()).     assertEquals(accumulators, execution1.getUserAccumulators()).     Execution execution2 = executions.values().iterator().next().     execution2.markFailed(new Throwable(), accumulators, ioMetrics).     assertEquals(ioMetrics, execution2.getIOMetrics()).     assertEquals(accumulators, execution2.getUserAccumulators()). }
false;public;0;24;;@Test public void testRegistrationOfExecutionsCanceled() {     try {         final JobVertexID jid1 = new JobVertexID().         final JobVertexID jid2 = new JobVertexID().         JobVertex v1 = new JobVertex("v1", jid1).         JobVertex v2 = new JobVertex("v2", jid2).         Map<ExecutionAttemptID, Execution> executions = setupExecution(v1, 19, v2, 37).f1.         for (Execution e : executions.values()) {             e.cancel().             e.completeCancelling().         }         assertEquals(0, executions.size()).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
true;public;0;61;/**  * Tests that a blocking batch job fails if there are not enough resources left to schedule the  * succeeding tasks. This test case is related to [FLINK-4296] where finished producing tasks  * swallow the fail exception when scheduling a consumer task.  */ ;/**  * Tests that a blocking batch job fails if there are not enough resources left to schedule the  * succeeding tasks. This test case is related to [FLINK-4296] where finished producing tasks  * swallow the fail exception when scheduling a consumer task.  */ @Test public void testNoResourceAvailableFailure() throws Exception {     final JobID jobId = new JobID().     JobVertex v1 = new JobVertex("source").     JobVertex v2 = new JobVertex("sink").     int dop1 = 1.     int dop2 = 1.     v1.setParallelism(dop1).     v2.setParallelism(dop2).     v1.setInvokableClass(BatchTask.class).     v2.setInvokableClass(BatchTask.class).     v2.connectNewDataSetAsInput(v1, DistributionPattern.POINTWISE, ResultPartitionType.BLOCKING).     final ArrayDeque<CompletableFuture<LogicalSlot>> slotFutures = new ArrayDeque<>().     for (int i = 0. i < dop1. i++) {         slotFutures.addLast(CompletableFuture.completedFuture(new TestingLogicalSlot())).     }     final SlotProvider slotProvider = new TestingSlotProvider(ignore -> slotFutures.removeFirst()).     final JobInformation jobInformation = new DummyJobInformation(jobId, "failing test job").     DirectScheduledExecutorService directExecutor = new DirectScheduledExecutorService().     // execution graph that executes actions synchronously     ExecutionGraph eg = new ExecutionGraph(jobInformation, directExecutor, TestingUtils.defaultExecutor(), AkkaUtils.getDefaultTimeout(), new NoRestartStrategy(), new RestartAllStrategy.Factory(), slotProvider, ExecutionGraph.class.getClassLoader(), blobWriter, AkkaUtils.getDefaultTimeout()).     eg.start(TestingComponentMainThreadExecutorServiceAdapter.forMainThread()).     checkJobOffloaded(eg).     eg.setQueuedSchedulingAllowed(false).     List<JobVertex> ordered = Arrays.asList(v1, v2).     eg.attachJobGraph(ordered).     // schedule, this triggers mock deployment     eg.scheduleForExecution().     ExecutionAttemptID attemptID = eg.getJobVertex(v1.getID()).getTaskVertices()[0].getCurrentExecutionAttempt().getAttemptId().     eg.updateState(new TaskExecutionState(jobId, attemptID, ExecutionState.RUNNING)).     eg.updateState(new TaskExecutionState(jobId, attemptID, ExecutionState.FINISHED, null)).     assertEquals(JobStatus.FAILED, eg.getState()). }
false;public;0;9;;// ------------------------------------------------------------------------ // retained checkpoints config test // ------------------------------------------------------------------------ @Test public void testSettingDefaultMaxNumberOfCheckpointsToRetain() throws Exception {     final Configuration jobManagerConfig = new Configuration().     final ExecutionGraph eg = createExecutionGraph(jobManagerConfig).     assertEquals(CheckpointingOptions.MAX_RETAINED_CHECKPOINTS.defaultValue().intValue(), eg.getCheckpointCoordinator().getCheckpointStore().getMaxNumberOfRetainedCheckpoints()). }
false;public;0;13;;@Test public void testSettingMaxNumberOfCheckpointsToRetain() throws Exception {     final int maxNumberOfCheckpointsToRetain = 10.     final Configuration jobManagerConfig = new Configuration().     jobManagerConfig.setInteger(CheckpointingOptions.MAX_RETAINED_CHECKPOINTS, maxNumberOfCheckpointsToRetain).     final ExecutionGraph eg = createExecutionGraph(jobManagerConfig).     assertEquals(maxNumberOfCheckpointsToRetain, eg.getCheckpointCoordinator().getCheckpointStore().getMaxNumberOfRetainedCheckpoints()). }
false;private;4;51;;private Tuple2<ExecutionGraph, Map<ExecutionAttemptID, Execution>> setupExecution(JobVertex v1, int dop1, JobVertex v2, int dop2) throws Exception {     final JobID jobId = new JobID().     v1.setParallelism(dop1).     v2.setParallelism(dop2).     v1.setInvokableClass(BatchTask.class).     v2.setInvokableClass(BatchTask.class).     final ArrayDeque<CompletableFuture<LogicalSlot>> slotFutures = new ArrayDeque<>().     for (int i = 0. i < dop1 + dop2. i++) {         slotFutures.addLast(CompletableFuture.completedFuture(new TestingLogicalSlot())).     }     final SlotProvider slotProvider = new TestingSlotProvider(ignore -> slotFutures.removeFirst()).     final JobInformation jobInformation = new DummyJobInformation(jobId, "some job").     DirectScheduledExecutorService executorService = new DirectScheduledExecutorService().     // execution graph that executes actions synchronously     ExecutionGraph eg = new ExecutionGraph(jobInformation, executorService, TestingUtils.defaultExecutor(), AkkaUtils.getDefaultTimeout(), new NoRestartStrategy(), new RestartAllStrategy.Factory(), slotProvider, ExecutionGraph.class.getClassLoader(), blobWriter, AkkaUtils.getDefaultTimeout()).     checkJobOffloaded(eg).     eg.start(TestingComponentMainThreadExecutorServiceAdapter.forMainThread()).     eg.setQueuedSchedulingAllowed(false).     List<JobVertex> ordered = Arrays.asList(v1, v2).     eg.attachJobGraph(ordered).     // schedule, this triggers mock deployment     eg.scheduleForExecution().     Map<ExecutionAttemptID, Execution> executions = eg.getRegisteredExecutions().     assertEquals(dop1 + dop2, executions.size()).     return new Tuple2<>(eg, executions). }
false;public;0;17;;@Test public void testSettingIllegalMaxNumberOfCheckpointsToRetain() throws Exception {     final int negativeMaxNumberOfCheckpointsToRetain = -10.     final Configuration jobManagerConfig = new Configuration().     jobManagerConfig.setInteger(CheckpointingOptions.MAX_RETAINED_CHECKPOINTS, negativeMaxNumberOfCheckpointsToRetain).     final ExecutionGraph eg = createExecutionGraph(jobManagerConfig).     assertNotEquals(negativeMaxNumberOfCheckpointsToRetain, eg.getCheckpointCoordinator().getCheckpointStore().getMaxNumberOfRetainedCheckpoints()).     assertEquals(CheckpointingOptions.MAX_RETAINED_CHECKPOINTS.defaultValue().intValue(), eg.getCheckpointCoordinator().getCheckpointStore().getMaxNumberOfRetainedCheckpoints()). }
true;public;0;84;/**  * Tests that eager scheduling will wait until all input locations have been set before  * scheduling a task.  */ ;/**  * Tests that eager scheduling will wait until all input locations have been set before  * scheduling a task.  */ @Test public void testEagerSchedulingWaitsOnAllInputPreferredLocations() throws Exception {     final int parallelism = 2.     final ProgrammedSlotProvider slotProvider = new ProgrammedSlotProvider(parallelism).     final Time timeout = Time.hours(1L).     final JobVertexID sourceVertexId = new JobVertexID().     final JobVertex sourceVertex = new JobVertex("Test source", sourceVertexId).     sourceVertex.setInvokableClass(NoOpInvokable.class).     sourceVertex.setParallelism(parallelism).     final JobVertexID sinkVertexId = new JobVertexID().     final JobVertex sinkVertex = new JobVertex("Test sink", sinkVertexId).     sinkVertex.setInvokableClass(NoOpInvokable.class).     sinkVertex.setParallelism(parallelism).     sinkVertex.connectNewDataSetAsInput(sourceVertex, DistributionPattern.ALL_TO_ALL, ResultPartitionType.PIPELINED).     final Map<JobVertexID, CompletableFuture<LogicalSlot>[]> slotFutures = new HashMap<>(2).     for (JobVertexID jobVertexID : Arrays.asList(sourceVertexId, sinkVertexId)) {         CompletableFuture<LogicalSlot>[] slotFutureArray = new CompletableFuture[parallelism].         for (int i = 0. i < parallelism. i++) {             slotFutureArray[i] = new CompletableFuture<>().         }         slotFutures.put(jobVertexID, slotFutureArray).         slotProvider.addSlots(jobVertexID, slotFutureArray).     }     final ScheduledExecutorService scheduledExecutorService = new ScheduledThreadPoolExecutor(3).     final ExecutionGraph executionGraph = ExecutionGraphTestUtils.createExecutionGraph(new JobID(), slotProvider, new NoRestartStrategy(), scheduledExecutorService, timeout, sourceVertex, sinkVertex).     executionGraph.start(TestingComponentMainThreadExecutorServiceAdapter.forMainThread()).     executionGraph.setScheduleMode(ScheduleMode.EAGER).     executionGraph.scheduleForExecution().     // all tasks should be in state SCHEDULED     for (ExecutionVertex executionVertex : executionGraph.getAllExecutionVertices()) {         assertEquals(ExecutionState.SCHEDULED, executionVertex.getCurrentExecutionAttempt().getState()).     }     // wait until the source vertex slots have been requested     assertTrue(slotProvider.getSlotRequestedFuture(sourceVertexId, 0).get()).     assertTrue(slotProvider.getSlotRequestedFuture(sourceVertexId, 1).get()).     // check that the sinks have not requested their slots because they need the location     // information of the sources     assertFalse(slotProvider.getSlotRequestedFuture(sinkVertexId, 0).isDone()).     assertFalse(slotProvider.getSlotRequestedFuture(sinkVertexId, 1).isDone()).     final TaskManagerLocation localTaskManagerLocation = new LocalTaskManagerLocation().     final SimpleSlot sourceSlot1 = createSlot(localTaskManagerLocation, 0).     final SimpleSlot sourceSlot2 = createSlot(localTaskManagerLocation, 1).     final SimpleSlot sinkSlot1 = createSlot(localTaskManagerLocation, 0).     final SimpleSlot sinkSlot2 = createSlot(localTaskManagerLocation, 1).     slotFutures.get(sourceVertexId)[0].complete(sourceSlot1).     slotFutures.get(sourceVertexId)[1].complete(sourceSlot2).     // wait until the sink vertex slots have been requested after we completed the source slots     assertTrue(slotProvider.getSlotRequestedFuture(sinkVertexId, 0).get()).     assertTrue(slotProvider.getSlotRequestedFuture(sinkVertexId, 1).get()).     slotFutures.get(sinkVertexId)[0].complete(sinkSlot1).     slotFutures.get(sinkVertexId)[1].complete(sinkSlot2).     for (ExecutionVertex executionVertex : executionGraph.getAllExecutionVertices()) {         ExecutionGraphTestUtils.waitUntilExecutionState(executionVertex.getCurrentExecutionAttempt(), ExecutionState.DEPLOYING, 5000L).     } }
false;private;2;7;;private SimpleSlot createSlot(TaskManagerLocation taskManagerLocation, int index) {     return new SimpleSlot(mock(SlotOwner.class), taskManagerLocation, index, new SimpleAckingTaskManagerGateway()). }
false;public;1;4;;@Override public void finalizeOnMaster(ClassLoader cl) throws Exception {     throw new Exception(). }
false;private;1;37;;private ExecutionGraph createExecutionGraph(Configuration configuration) throws Exception {     final ScheduledExecutorService executor = TestingUtils.defaultExecutor().     final JobID jobId = new JobID().     final JobGraph jobGraph = new JobGraph(jobId, "test").     jobGraph.setSnapshotSettings(new JobCheckpointingSettings(Collections.<JobVertexID>emptyList(), Collections.<JobVertexID>emptyList(), Collections.<JobVertexID>emptyList(), new CheckpointCoordinatorConfiguration(100, 10 * 60 * 1000, 0, 1, CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION, false), null)).     final Time timeout = Time.seconds(10L).     return ExecutionGraphBuilder.buildGraph(null, jobGraph, configuration, executor, executor, new ProgrammedSlotProvider(1), getClass().getClassLoader(), new StandaloneCheckpointRecoveryFactory(), timeout, new NoRestartStrategy(), new UnregisteredMetricsGroup(), 1, blobWriter, timeout, LoggerFactory.getLogger(getClass())). }
