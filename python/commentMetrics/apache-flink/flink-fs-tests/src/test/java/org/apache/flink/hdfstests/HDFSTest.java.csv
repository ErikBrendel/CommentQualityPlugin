# id;timestamp;commentText;codeText;commentWords;codeWords
HDFSTest -> @Test 	public void testBlobServerCorruptedFile() throws Exception;1507212387;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed corrupted JARs are_recognised during the download via a {@link org.apache.flink.runtime.blob.BlobServer}.;@Test_	public void testBlobServerCorruptedFile() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(CoreOptions.STATE_BACKEND, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			BlobServerCorruptionTest.testGetFailsFromCorruptFile(config, blobStoreService, exception)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,corrupted,jars,are,recognised,during,the,download,via,a,link,org,apache,flink,runtime,blob,blob,server;test,public,void,test,blob,server,corrupted,file,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,core,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,blob,server,corruption,test,test,get,fails,from,corrupt,file,config,blob,store,service,exception,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobServerCorruptedFile() throws Exception;1507212387;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed corrupted JARs are_recognised during the download via a {@link org.apache.flink.runtime.blob.BlobServer}.;@Test_	public void testBlobServerCorruptedFile() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___		try {_			BlobServerCorruptionTest.testGetFailsFromCorruptFile(config, blobStoreService, exception)__		} finally {_			blobStoreService.closeAndCleanupAllData()__		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,corrupted,jars,are,recognised,during,the,download,via,a,link,org,apache,flink,runtime,blob,blob,server;test,public,void,test,blob,server,corrupted,file,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,blob,utils,create,blob,store,from,config,config,try,blob,server,corruption,test,test,get,fails,from,corrupt,file,config,blob,store,service,exception,finally,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobServerCorruptedFile() throws Exception;1509723634;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed corrupted JARs are_recognised during the download via a {@link org.apache.flink.runtime.blob.BlobServer}.;@Test_	public void testBlobServerCorruptedFile() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___		try {_			BlobServerCorruptionTest.testGetFailsFromCorruptFile(config, blobStoreService, exception)__		} finally {_			blobStoreService.closeAndCleanupAllData()__		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,corrupted,jars,are,recognised,during,the,download,via,a,link,org,apache,flink,runtime,blob,blob,server;test,public,void,test,blob,server,corrupted,file,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,blob,utils,create,blob,store,from,config,config,try,blob,server,corruption,test,test,get,fails,from,corrupt,file,config,blob,store,service,exception,finally,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobCacheCorruptedFile() throws Exception;1507212387;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed corrupted JARs are_recognised during the download via a {@link org.apache.flink.runtime.blob.BlobCache}.;@Test_	public void testBlobCacheCorruptedFile() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(CoreOptions.STATE_BACKEND, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			BlobCacheCorruptionTest.testGetFailsFromCorruptFile(new JobID(), true, true, config, blobStoreService, exception)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,corrupted,jars,are,recognised,during,the,download,via,a,link,org,apache,flink,runtime,blob,blob,cache;test,public,void,test,blob,cache,corrupted,file,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,core,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,blob,cache,corruption,test,test,get,fails,from,corrupt,file,new,job,id,true,true,config,blob,store,service,exception,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobCacheCorruptedFile() throws Exception;1507212387;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed corrupted JARs are_recognised during the download via a BLOB cache.;@Test_	public void testBlobCacheCorruptedFile() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___		try {_			BlobCacheCorruptionTest_				.testGetFailsFromCorruptFile(new JobID(), config, blobStoreService, exception)__		} finally {_			blobStoreService.closeAndCleanupAllData()__		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,corrupted,jars,are,recognised,during,the,download,via,a,blob,cache;test,public,void,test,blob,cache,corrupted,file,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,blob,utils,create,blob,store,from,config,config,try,blob,cache,corruption,test,test,get,fails,from,corrupt,file,new,job,id,config,blob,store,service,exception,finally,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobCacheCorruptedFile() throws Exception;1509723634;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed corrupted JARs are_recognised during the download via a BLOB cache.;@Test_	public void testBlobCacheCorruptedFile() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___		try {_			BlobCacheCorruptionTest_				.testGetFailsFromCorruptFile(new JobID(), config, blobStoreService, exception)__		} finally {_			blobStoreService.closeAndCleanupAllData()__		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,corrupted,jars,are,recognised,during,the,download,via,a,blob,cache;test,public,void,test,blob,cache,corrupted,file,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,blob,utils,create,blob,store,from,config,config,try,blob,cache,corruption,test,test,get,fails,from,corrupt,file,new,job,id,config,blob,store,service,exception,finally,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testDeletePathIfEmpty() throws IOException;1481644337;Test that {@link FileUtils#deletePathIfEmpty(FileSystem, Path)} deletes the path if it is_empty. A path can only be empty if it is a directory which does not contain any_files/directories.;@Test_	public void testDeletePathIfEmpty() throws IOException {_		final Path basePath = new Path(hdfsURI)__		final Path directory = new Path(basePath, UUID.randomUUID().toString())__		final Path directoryFile = new Path(directory, UUID.randomUUID().toString())__		final Path singleFile = new Path(basePath, UUID.randomUUID().toString())___		FileSystem fs = basePath.getFileSystem()___		fs.mkdirs(directory)___		byte[] data = "HDFSTest#testDeletePathIfEmpty".getBytes()___		for (Path file: Arrays.asList(singleFile, directoryFile)) {_			org.apache.flink.core.fs.FSDataOutputStream outputStream = fs.create(file, true)__			outputStream.write(data)__			outputStream.close()__		}__		_		assertTrue(fs.exists(singleFile))__		assertTrue(fs.exists(directoryFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile))__		assertTrue(fs.exists(singleFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, directory))__		assertTrue(fs.exists(directory))___		_		assertTrue(fs.delete(directoryFile, false))___		_		assertTrue(FileUtils.deletePathIfEmpty(fs, directory))__		assertFalse(fs.exists(directory))__	};test,that,link,file,utils,delete,path,if,empty,file,system,path,deletes,the,path,if,it,is,empty,a,path,can,only,be,empty,if,it,is,a,directory,which,does,not,contain,any,files,directories;test,public,void,test,delete,path,if,empty,throws,ioexception,final,path,base,path,new,path,hdfs,uri,final,path,directory,new,path,base,path,uuid,random,uuid,to,string,final,path,directory,file,new,path,directory,uuid,random,uuid,to,string,final,path,single,file,new,path,base,path,uuid,random,uuid,to,string,file,system,fs,base,path,get,file,system,fs,mkdirs,directory,byte,data,hdfstest,test,delete,path,if,empty,get,bytes,for,path,file,arrays,as,list,single,file,directory,file,org,apache,flink,core,fs,fsdata,output,stream,output,stream,fs,create,file,true,output,stream,write,data,output,stream,close,assert,true,fs,exists,single,file,assert,true,fs,exists,directory,file,assert,false,file,utils,delete,path,if,empty,fs,single,file,assert,true,fs,exists,single,file,assert,false,file,utils,delete,path,if,empty,fs,directory,assert,true,fs,exists,directory,assert,true,fs,delete,directory,file,false,assert,true,file,utils,delete,path,if,empty,fs,directory,assert,false,fs,exists,directory
HDFSTest -> @Test 	public void testDeletePathIfEmpty() throws IOException;1485510281;Test that {@link FileUtils#deletePathIfEmpty(FileSystem, Path)} deletes the path if it is_empty. A path can only be empty if it is a directory which does not contain any_files/directories.;@Test_	public void testDeletePathIfEmpty() throws IOException {_		final Path basePath = new Path(hdfsURI)__		final Path directory = new Path(basePath, UUID.randomUUID().toString())__		final Path directoryFile = new Path(directory, UUID.randomUUID().toString())__		final Path singleFile = new Path(basePath, UUID.randomUUID().toString())___		FileSystem fs = basePath.getFileSystem()___		fs.mkdirs(directory)___		byte[] data = "HDFSTest#testDeletePathIfEmpty".getBytes()___		for (Path file: Arrays.asList(singleFile, directoryFile)) {_			org.apache.flink.core.fs.FSDataOutputStream outputStream = fs.create(file, true)__			outputStream.write(data)__			outputStream.close()__		}__		_		assertTrue(fs.exists(singleFile))__		assertTrue(fs.exists(directoryFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile))__		assertTrue(fs.exists(singleFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, directory))__		assertTrue(fs.exists(directory))___		_		assertTrue(fs.delete(directoryFile, false))___		_		assertTrue(FileUtils.deletePathIfEmpty(fs, directory))__		assertFalse(fs.exists(directory))__	};test,that,link,file,utils,delete,path,if,empty,file,system,path,deletes,the,path,if,it,is,empty,a,path,can,only,be,empty,if,it,is,a,directory,which,does,not,contain,any,files,directories;test,public,void,test,delete,path,if,empty,throws,ioexception,final,path,base,path,new,path,hdfs,uri,final,path,directory,new,path,base,path,uuid,random,uuid,to,string,final,path,directory,file,new,path,directory,uuid,random,uuid,to,string,final,path,single,file,new,path,base,path,uuid,random,uuid,to,string,file,system,fs,base,path,get,file,system,fs,mkdirs,directory,byte,data,hdfstest,test,delete,path,if,empty,get,bytes,for,path,file,arrays,as,list,single,file,directory,file,org,apache,flink,core,fs,fsdata,output,stream,output,stream,fs,create,file,true,output,stream,write,data,output,stream,close,assert,true,fs,exists,single,file,assert,true,fs,exists,directory,file,assert,false,file,utils,delete,path,if,empty,fs,single,file,assert,true,fs,exists,single,file,assert,false,file,utils,delete,path,if,empty,fs,directory,assert,true,fs,exists,directory,assert,true,fs,delete,directory,file,false,assert,true,file,utils,delete,path,if,empty,fs,directory,assert,false,fs,exists,directory
HDFSTest -> @Test 	public void testDeletePathIfEmpty() throws IOException;1487622556;Test that {@link FileUtils#deletePathIfEmpty(FileSystem, Path)} deletes the path if it is_empty. A path can only be empty if it is a directory which does not contain any_files/directories.;@Test_	public void testDeletePathIfEmpty() throws IOException {_		final Path basePath = new Path(hdfsURI)__		final Path directory = new Path(basePath, UUID.randomUUID().toString())__		final Path directoryFile = new Path(directory, UUID.randomUUID().toString())__		final Path singleFile = new Path(basePath, UUID.randomUUID().toString())___		FileSystem fs = basePath.getFileSystem()___		fs.mkdirs(directory)___		byte[] data = "HDFSTest#testDeletePathIfEmpty".getBytes()___		for (Path file: Arrays.asList(singleFile, directoryFile)) {_			org.apache.flink.core.fs.FSDataOutputStream outputStream = fs.create(file, true)__			outputStream.write(data)__			outputStream.close()__		}__		_		assertTrue(fs.exists(singleFile))__		assertTrue(fs.exists(directoryFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile))__		assertTrue(fs.exists(singleFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, directory))__		assertTrue(fs.exists(directory))___		_		assertTrue(fs.delete(directoryFile, false))___		_		assertTrue(FileUtils.deletePathIfEmpty(fs, directory))__		assertFalse(fs.exists(directory))__	};test,that,link,file,utils,delete,path,if,empty,file,system,path,deletes,the,path,if,it,is,empty,a,path,can,only,be,empty,if,it,is,a,directory,which,does,not,contain,any,files,directories;test,public,void,test,delete,path,if,empty,throws,ioexception,final,path,base,path,new,path,hdfs,uri,final,path,directory,new,path,base,path,uuid,random,uuid,to,string,final,path,directory,file,new,path,directory,uuid,random,uuid,to,string,final,path,single,file,new,path,base,path,uuid,random,uuid,to,string,file,system,fs,base,path,get,file,system,fs,mkdirs,directory,byte,data,hdfstest,test,delete,path,if,empty,get,bytes,for,path,file,arrays,as,list,single,file,directory,file,org,apache,flink,core,fs,fsdata,output,stream,output,stream,fs,create,file,true,output,stream,write,data,output,stream,close,assert,true,fs,exists,single,file,assert,true,fs,exists,directory,file,assert,false,file,utils,delete,path,if,empty,fs,single,file,assert,true,fs,exists,single,file,assert,false,file,utils,delete,path,if,empty,fs,directory,assert,true,fs,exists,directory,assert,true,fs,delete,directory,file,false,assert,true,file,utils,delete,path,if,empty,fs,directory,assert,false,fs,exists,directory
HDFSTest -> @Test 	public void testDeletePathIfEmpty() throws IOException;1489060855;Test that {@link FileUtils#deletePathIfEmpty(FileSystem, Path)} deletes the path if it is_empty. A path can only be empty if it is a directory which does not contain any_files/directories.;@Test_	public void testDeletePathIfEmpty() throws IOException {_		final Path basePath = new Path(hdfsURI)__		final Path directory = new Path(basePath, UUID.randomUUID().toString())__		final Path directoryFile = new Path(directory, UUID.randomUUID().toString())__		final Path singleFile = new Path(basePath, UUID.randomUUID().toString())___		FileSystem fs = basePath.getFileSystem()___		fs.mkdirs(directory)___		byte[] data = "HDFSTest#testDeletePathIfEmpty".getBytes(ConfigConstants.DEFAULT_CHARSET)___		for (Path file: Arrays.asList(singleFile, directoryFile)) {_			org.apache.flink.core.fs.FSDataOutputStream outputStream = fs.create(file, true)__			outputStream.write(data)__			outputStream.close()__		}__		_		assertTrue(fs.exists(singleFile))__		assertTrue(fs.exists(directoryFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile))__		assertTrue(fs.exists(singleFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, directory))__		assertTrue(fs.exists(directory))___		_		assertTrue(fs.delete(directoryFile, false))___		_		assertTrue(FileUtils.deletePathIfEmpty(fs, directory))__		assertFalse(fs.exists(directory))__	};test,that,link,file,utils,delete,path,if,empty,file,system,path,deletes,the,path,if,it,is,empty,a,path,can,only,be,empty,if,it,is,a,directory,which,does,not,contain,any,files,directories;test,public,void,test,delete,path,if,empty,throws,ioexception,final,path,base,path,new,path,hdfs,uri,final,path,directory,new,path,base,path,uuid,random,uuid,to,string,final,path,directory,file,new,path,directory,uuid,random,uuid,to,string,final,path,single,file,new,path,base,path,uuid,random,uuid,to,string,file,system,fs,base,path,get,file,system,fs,mkdirs,directory,byte,data,hdfstest,test,delete,path,if,empty,get,bytes,config,constants,for,path,file,arrays,as,list,single,file,directory,file,org,apache,flink,core,fs,fsdata,output,stream,output,stream,fs,create,file,true,output,stream,write,data,output,stream,close,assert,true,fs,exists,single,file,assert,true,fs,exists,directory,file,assert,false,file,utils,delete,path,if,empty,fs,single,file,assert,true,fs,exists,single,file,assert,false,file,utils,delete,path,if,empty,fs,directory,assert,true,fs,exists,directory,assert,true,fs,delete,directory,file,false,assert,true,file,utils,delete,path,if,empty,fs,directory,assert,false,fs,exists,directory
HDFSTest -> @Test 	public void testDeletePathIfEmpty() throws IOException;1495001929;Test that {@link FileUtils#deletePathIfEmpty(FileSystem, Path)} deletes the path if it is_empty. A path can only be empty if it is a directory which does not contain any_files/directories.;@Test_	public void testDeletePathIfEmpty() throws IOException {_		final Path basePath = new Path(hdfsURI)__		final Path directory = new Path(basePath, UUID.randomUUID().toString())__		final Path directoryFile = new Path(directory, UUID.randomUUID().toString())__		final Path singleFile = new Path(basePath, UUID.randomUUID().toString())___		FileSystem fs = basePath.getFileSystem()___		fs.mkdirs(directory)___		byte[] data = "HDFSTest#testDeletePathIfEmpty".getBytes(ConfigConstants.DEFAULT_CHARSET)___		for (Path file: Arrays.asList(singleFile, directoryFile)) {_			org.apache.flink.core.fs.FSDataOutputStream outputStream = fs.create(file, true)__			outputStream.write(data)__			outputStream.close()__		}__		_		assertTrue(fs.exists(singleFile))__		assertTrue(fs.exists(directoryFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile))__		assertTrue(fs.exists(singleFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, directory))__		assertTrue(fs.exists(directory))___		_		assertTrue(fs.delete(directoryFile, false))___		_		assertTrue(FileUtils.deletePathIfEmpty(fs, directory))__		assertFalse(fs.exists(directory))__	};test,that,link,file,utils,delete,path,if,empty,file,system,path,deletes,the,path,if,it,is,empty,a,path,can,only,be,empty,if,it,is,a,directory,which,does,not,contain,any,files,directories;test,public,void,test,delete,path,if,empty,throws,ioexception,final,path,base,path,new,path,hdfs,uri,final,path,directory,new,path,base,path,uuid,random,uuid,to,string,final,path,directory,file,new,path,directory,uuid,random,uuid,to,string,final,path,single,file,new,path,base,path,uuid,random,uuid,to,string,file,system,fs,base,path,get,file,system,fs,mkdirs,directory,byte,data,hdfstest,test,delete,path,if,empty,get,bytes,config,constants,for,path,file,arrays,as,list,single,file,directory,file,org,apache,flink,core,fs,fsdata,output,stream,output,stream,fs,create,file,true,output,stream,write,data,output,stream,close,assert,true,fs,exists,single,file,assert,true,fs,exists,directory,file,assert,false,file,utils,delete,path,if,empty,fs,single,file,assert,true,fs,exists,single,file,assert,false,file,utils,delete,path,if,empty,fs,directory,assert,true,fs,exists,directory,assert,true,fs,delete,directory,file,false,assert,true,file,utils,delete,path,if,empty,fs,directory,assert,false,fs,exists,directory
HDFSTest -> @Test 	public void testDeletePathIfEmpty() throws IOException;1495813291;Test that {@link FileUtils#deletePathIfEmpty(FileSystem, Path)} deletes the path if it is_empty. A path can only be empty if it is a directory which does not contain any_files/directories.;@Test_	public void testDeletePathIfEmpty() throws IOException {_		final Path basePath = new Path(hdfsURI)__		final Path directory = new Path(basePath, UUID.randomUUID().toString())__		final Path directoryFile = new Path(directory, UUID.randomUUID().toString())__		final Path singleFile = new Path(basePath, UUID.randomUUID().toString())___		FileSystem fs = basePath.getFileSystem()___		fs.mkdirs(directory)___		byte[] data = "HDFSTest#testDeletePathIfEmpty".getBytes(ConfigConstants.DEFAULT_CHARSET)___		for (Path file: Arrays.asList(singleFile, directoryFile)) {_			org.apache.flink.core.fs.FSDataOutputStream outputStream = fs.create(file, true)__			outputStream.write(data)__			outputStream.close()__		}__		_		assertTrue(fs.exists(singleFile))__		assertTrue(fs.exists(directoryFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile))__		assertTrue(fs.exists(singleFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, directory))__		assertTrue(fs.exists(directory))___		_		assertTrue(fs.delete(directoryFile, false))___		_		assertTrue(FileUtils.deletePathIfEmpty(fs, directory))__		assertFalse(fs.exists(directory))__	};test,that,link,file,utils,delete,path,if,empty,file,system,path,deletes,the,path,if,it,is,empty,a,path,can,only,be,empty,if,it,is,a,directory,which,does,not,contain,any,files,directories;test,public,void,test,delete,path,if,empty,throws,ioexception,final,path,base,path,new,path,hdfs,uri,final,path,directory,new,path,base,path,uuid,random,uuid,to,string,final,path,directory,file,new,path,directory,uuid,random,uuid,to,string,final,path,single,file,new,path,base,path,uuid,random,uuid,to,string,file,system,fs,base,path,get,file,system,fs,mkdirs,directory,byte,data,hdfstest,test,delete,path,if,empty,get,bytes,config,constants,for,path,file,arrays,as,list,single,file,directory,file,org,apache,flink,core,fs,fsdata,output,stream,output,stream,fs,create,file,true,output,stream,write,data,output,stream,close,assert,true,fs,exists,single,file,assert,true,fs,exists,directory,file,assert,false,file,utils,delete,path,if,empty,fs,single,file,assert,true,fs,exists,single,file,assert,false,file,utils,delete,path,if,empty,fs,directory,assert,true,fs,exists,directory,assert,true,fs,delete,directory,file,false,assert,true,file,utils,delete,path,if,empty,fs,directory,assert,false,fs,exists,directory
HDFSTest -> @Test 	public void testDeletePathIfEmpty() throws IOException;1498220069;Test that {@link FileUtils#deletePathIfEmpty(FileSystem, Path)} deletes the path if it is_empty. A path can only be empty if it is a directory which does not contain any_files/directories.;@Test_	public void testDeletePathIfEmpty() throws IOException {_		final Path basePath = new Path(hdfsURI)__		final Path directory = new Path(basePath, UUID.randomUUID().toString())__		final Path directoryFile = new Path(directory, UUID.randomUUID().toString())__		final Path singleFile = new Path(basePath, UUID.randomUUID().toString())___		FileSystem fs = basePath.getFileSystem()___		fs.mkdirs(directory)___		byte[] data = "HDFSTest#testDeletePathIfEmpty".getBytes(ConfigConstants.DEFAULT_CHARSET)___		for (Path file: Arrays.asList(singleFile, directoryFile)) {_			org.apache.flink.core.fs.FSDataOutputStream outputStream = fs.create(file, FileSystem.WriteMode.OVERWRITE)__			outputStream.write(data)__			outputStream.close()__		}__		_		assertTrue(fs.exists(singleFile))__		assertTrue(fs.exists(directoryFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile))__		assertTrue(fs.exists(singleFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, directory))__		assertTrue(fs.exists(directory))___		_		assertTrue(fs.delete(directoryFile, false))___		_		assertTrue(FileUtils.deletePathIfEmpty(fs, directory))__		assertFalse(fs.exists(directory))__	};test,that,link,file,utils,delete,path,if,empty,file,system,path,deletes,the,path,if,it,is,empty,a,path,can,only,be,empty,if,it,is,a,directory,which,does,not,contain,any,files,directories;test,public,void,test,delete,path,if,empty,throws,ioexception,final,path,base,path,new,path,hdfs,uri,final,path,directory,new,path,base,path,uuid,random,uuid,to,string,final,path,directory,file,new,path,directory,uuid,random,uuid,to,string,final,path,single,file,new,path,base,path,uuid,random,uuid,to,string,file,system,fs,base,path,get,file,system,fs,mkdirs,directory,byte,data,hdfstest,test,delete,path,if,empty,get,bytes,config,constants,for,path,file,arrays,as,list,single,file,directory,file,org,apache,flink,core,fs,fsdata,output,stream,output,stream,fs,create,file,file,system,write,mode,overwrite,output,stream,write,data,output,stream,close,assert,true,fs,exists,single,file,assert,true,fs,exists,directory,file,assert,false,file,utils,delete,path,if,empty,fs,single,file,assert,true,fs,exists,single,file,assert,false,file,utils,delete,path,if,empty,fs,directory,assert,true,fs,exists,directory,assert,true,fs,delete,directory,file,false,assert,true,file,utils,delete,path,if,empty,fs,directory,assert,false,fs,exists,directory
HDFSTest -> @Test 	public void testDeletePathIfEmpty() throws IOException;1498894422;Test that {@link FileUtils#deletePathIfEmpty(FileSystem, Path)} deletes the path if it is_empty. A path can only be empty if it is a directory which does not contain any_files/directories.;@Test_	public void testDeletePathIfEmpty() throws IOException {_		final Path basePath = new Path(hdfsURI)__		final Path directory = new Path(basePath, UUID.randomUUID().toString())__		final Path directoryFile = new Path(directory, UUID.randomUUID().toString())__		final Path singleFile = new Path(basePath, UUID.randomUUID().toString())___		FileSystem fs = basePath.getFileSystem()___		fs.mkdirs(directory)___		byte[] data = "HDFSTest#testDeletePathIfEmpty".getBytes(ConfigConstants.DEFAULT_CHARSET)___		for (Path file: Arrays.asList(singleFile, directoryFile)) {_			org.apache.flink.core.fs.FSDataOutputStream outputStream = fs.create(file, FileSystem.WriteMode.OVERWRITE)__			outputStream.write(data)__			outputStream.close()__		}__		_		assertTrue(fs.exists(singleFile))__		assertTrue(fs.exists(directoryFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile))__		assertTrue(fs.exists(singleFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, directory))__		assertTrue(fs.exists(directory))___		_		assertTrue(fs.delete(directoryFile, false))___		_		assertTrue(FileUtils.deletePathIfEmpty(fs, directory))__		assertFalse(fs.exists(directory))__	};test,that,link,file,utils,delete,path,if,empty,file,system,path,deletes,the,path,if,it,is,empty,a,path,can,only,be,empty,if,it,is,a,directory,which,does,not,contain,any,files,directories;test,public,void,test,delete,path,if,empty,throws,ioexception,final,path,base,path,new,path,hdfs,uri,final,path,directory,new,path,base,path,uuid,random,uuid,to,string,final,path,directory,file,new,path,directory,uuid,random,uuid,to,string,final,path,single,file,new,path,base,path,uuid,random,uuid,to,string,file,system,fs,base,path,get,file,system,fs,mkdirs,directory,byte,data,hdfstest,test,delete,path,if,empty,get,bytes,config,constants,for,path,file,arrays,as,list,single,file,directory,file,org,apache,flink,core,fs,fsdata,output,stream,output,stream,fs,create,file,file,system,write,mode,overwrite,output,stream,write,data,output,stream,close,assert,true,fs,exists,single,file,assert,true,fs,exists,directory,file,assert,false,file,utils,delete,path,if,empty,fs,single,file,assert,true,fs,exists,single,file,assert,false,file,utils,delete,path,if,empty,fs,directory,assert,true,fs,exists,directory,assert,true,fs,delete,directory,file,false,assert,true,file,utils,delete,path,if,empty,fs,directory,assert,false,fs,exists,directory
HDFSTest -> @Test 	public void testDeletePathIfEmpty() throws IOException;1502100084;Test that {@link FileUtils#deletePathIfEmpty(FileSystem, Path)} deletes the path if it is_empty. A path can only be empty if it is a directory which does not contain any_files/directories.;@Test_	public void testDeletePathIfEmpty() throws IOException {_		final Path basePath = new Path(hdfsURI)__		final Path directory = new Path(basePath, UUID.randomUUID().toString())__		final Path directoryFile = new Path(directory, UUID.randomUUID().toString())__		final Path singleFile = new Path(basePath, UUID.randomUUID().toString())___		FileSystem fs = basePath.getFileSystem()___		fs.mkdirs(directory)___		byte[] data = "HDFSTest#testDeletePathIfEmpty".getBytes(ConfigConstants.DEFAULT_CHARSET)___		for (Path file: Arrays.asList(singleFile, directoryFile)) {_			org.apache.flink.core.fs.FSDataOutputStream outputStream = fs.create(file, FileSystem.WriteMode.OVERWRITE)__			outputStream.write(data)__			outputStream.close()__		}__		_		assertTrue(fs.exists(singleFile))__		assertTrue(fs.exists(directoryFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile))__		assertTrue(fs.exists(singleFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, directory))__		assertTrue(fs.exists(directory))___		_		assertTrue(fs.delete(directoryFile, false))___		_		assertTrue(FileUtils.deletePathIfEmpty(fs, directory))__		assertFalse(fs.exists(directory))__	};test,that,link,file,utils,delete,path,if,empty,file,system,path,deletes,the,path,if,it,is,empty,a,path,can,only,be,empty,if,it,is,a,directory,which,does,not,contain,any,files,directories;test,public,void,test,delete,path,if,empty,throws,ioexception,final,path,base,path,new,path,hdfs,uri,final,path,directory,new,path,base,path,uuid,random,uuid,to,string,final,path,directory,file,new,path,directory,uuid,random,uuid,to,string,final,path,single,file,new,path,base,path,uuid,random,uuid,to,string,file,system,fs,base,path,get,file,system,fs,mkdirs,directory,byte,data,hdfstest,test,delete,path,if,empty,get,bytes,config,constants,for,path,file,arrays,as,list,single,file,directory,file,org,apache,flink,core,fs,fsdata,output,stream,output,stream,fs,create,file,file,system,write,mode,overwrite,output,stream,write,data,output,stream,close,assert,true,fs,exists,single,file,assert,true,fs,exists,directory,file,assert,false,file,utils,delete,path,if,empty,fs,single,file,assert,true,fs,exists,single,file,assert,false,file,utils,delete,path,if,empty,fs,directory,assert,true,fs,exists,directory,assert,true,fs,delete,directory,file,false,assert,true,file,utils,delete,path,if,empty,fs,directory,assert,false,fs,exists,directory
HDFSTest -> @Test 	public void testDeletePathIfEmpty() throws IOException;1507212387;Test that {@link FileUtils#deletePathIfEmpty(FileSystem, Path)} deletes the path if it is_empty. A path can only be empty if it is a directory which does not contain any_files/directories.;@Test_	public void testDeletePathIfEmpty() throws IOException {_		final Path basePath = new Path(hdfsURI)__		final Path directory = new Path(basePath, UUID.randomUUID().toString())__		final Path directoryFile = new Path(directory, UUID.randomUUID().toString())__		final Path singleFile = new Path(basePath, UUID.randomUUID().toString())___		FileSystem fs = basePath.getFileSystem()___		fs.mkdirs(directory)___		byte[] data = "HDFSTest#testDeletePathIfEmpty".getBytes(ConfigConstants.DEFAULT_CHARSET)___		for (Path file: Arrays.asList(singleFile, directoryFile)) {_			org.apache.flink.core.fs.FSDataOutputStream outputStream = fs.create(file, FileSystem.WriteMode.OVERWRITE)__			outputStream.write(data)__			outputStream.close()__		}__		_		assertTrue(fs.exists(singleFile))__		assertTrue(fs.exists(directoryFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile))__		assertTrue(fs.exists(singleFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, directory))__		assertTrue(fs.exists(directory))___		_		assertTrue(fs.delete(directoryFile, false))___		_		assertTrue(FileUtils.deletePathIfEmpty(fs, directory))__		assertFalse(fs.exists(directory))__	};test,that,link,file,utils,delete,path,if,empty,file,system,path,deletes,the,path,if,it,is,empty,a,path,can,only,be,empty,if,it,is,a,directory,which,does,not,contain,any,files,directories;test,public,void,test,delete,path,if,empty,throws,ioexception,final,path,base,path,new,path,hdfs,uri,final,path,directory,new,path,base,path,uuid,random,uuid,to,string,final,path,directory,file,new,path,directory,uuid,random,uuid,to,string,final,path,single,file,new,path,base,path,uuid,random,uuid,to,string,file,system,fs,base,path,get,file,system,fs,mkdirs,directory,byte,data,hdfstest,test,delete,path,if,empty,get,bytes,config,constants,for,path,file,arrays,as,list,single,file,directory,file,org,apache,flink,core,fs,fsdata,output,stream,output,stream,fs,create,file,file,system,write,mode,overwrite,output,stream,write,data,output,stream,close,assert,true,fs,exists,single,file,assert,true,fs,exists,directory,file,assert,false,file,utils,delete,path,if,empty,fs,single,file,assert,true,fs,exists,single,file,assert,false,file,utils,delete,path,if,empty,fs,directory,assert,true,fs,exists,directory,assert,true,fs,delete,directory,file,false,assert,true,file,utils,delete,path,if,empty,fs,directory,assert,false,fs,exists,directory
HDFSTest -> @Test 	public void testDeletePathIfEmpty() throws IOException;1507212387;Test that {@link FileUtils#deletePathIfEmpty(FileSystem, Path)} deletes the path if it is_empty. A path can only be empty if it is a directory which does not contain any_files/directories.;@Test_	public void testDeletePathIfEmpty() throws IOException {_		final Path basePath = new Path(hdfsURI)__		final Path directory = new Path(basePath, UUID.randomUUID().toString())__		final Path directoryFile = new Path(directory, UUID.randomUUID().toString())__		final Path singleFile = new Path(basePath, UUID.randomUUID().toString())___		FileSystem fs = basePath.getFileSystem()___		fs.mkdirs(directory)___		byte[] data = "HDFSTest#testDeletePathIfEmpty".getBytes(ConfigConstants.DEFAULT_CHARSET)___		for (Path file: Arrays.asList(singleFile, directoryFile)) {_			org.apache.flink.core.fs.FSDataOutputStream outputStream = fs.create(file, FileSystem.WriteMode.OVERWRITE)__			outputStream.write(data)__			outputStream.close()__		}__		_		assertTrue(fs.exists(singleFile))__		assertTrue(fs.exists(directoryFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile))__		assertTrue(fs.exists(singleFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, directory))__		assertTrue(fs.exists(directory))___		_		assertTrue(fs.delete(directoryFile, false))___		_		assertTrue(FileUtils.deletePathIfEmpty(fs, directory))__		assertFalse(fs.exists(directory))__	};test,that,link,file,utils,delete,path,if,empty,file,system,path,deletes,the,path,if,it,is,empty,a,path,can,only,be,empty,if,it,is,a,directory,which,does,not,contain,any,files,directories;test,public,void,test,delete,path,if,empty,throws,ioexception,final,path,base,path,new,path,hdfs,uri,final,path,directory,new,path,base,path,uuid,random,uuid,to,string,final,path,directory,file,new,path,directory,uuid,random,uuid,to,string,final,path,single,file,new,path,base,path,uuid,random,uuid,to,string,file,system,fs,base,path,get,file,system,fs,mkdirs,directory,byte,data,hdfstest,test,delete,path,if,empty,get,bytes,config,constants,for,path,file,arrays,as,list,single,file,directory,file,org,apache,flink,core,fs,fsdata,output,stream,output,stream,fs,create,file,file,system,write,mode,overwrite,output,stream,write,data,output,stream,close,assert,true,fs,exists,single,file,assert,true,fs,exists,directory,file,assert,false,file,utils,delete,path,if,empty,fs,single,file,assert,true,fs,exists,single,file,assert,false,file,utils,delete,path,if,empty,fs,directory,assert,true,fs,exists,directory,assert,true,fs,delete,directory,file,false,assert,true,file,utils,delete,path,if,empty,fs,directory,assert,false,fs,exists,directory
HDFSTest -> @Test 	public void testDeletePathIfEmpty() throws IOException;1509723634;Test that {@link FileUtils#deletePathIfEmpty(FileSystem, Path)} deletes the path if it is_empty. A path can only be empty if it is a directory which does not contain any_files/directories.;@Test_	public void testDeletePathIfEmpty() throws IOException {_		final Path basePath = new Path(hdfsURI)__		final Path directory = new Path(basePath, UUID.randomUUID().toString())__		final Path directoryFile = new Path(directory, UUID.randomUUID().toString())__		final Path singleFile = new Path(basePath, UUID.randomUUID().toString())___		FileSystem fs = basePath.getFileSystem()___		fs.mkdirs(directory)___		byte[] data = "HDFSTest#testDeletePathIfEmpty".getBytes(ConfigConstants.DEFAULT_CHARSET)___		for (Path file: Arrays.asList(singleFile, directoryFile)) {_			org.apache.flink.core.fs.FSDataOutputStream outputStream = fs.create(file, FileSystem.WriteMode.OVERWRITE)__			outputStream.write(data)__			outputStream.close()__		}__		_		assertTrue(fs.exists(singleFile))__		assertTrue(fs.exists(directoryFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile))__		assertTrue(fs.exists(singleFile))___		_		assertFalse(FileUtils.deletePathIfEmpty(fs, directory))__		assertTrue(fs.exists(directory))___		_		assertTrue(fs.delete(directoryFile, false))___		_		assertTrue(FileUtils.deletePathIfEmpty(fs, directory))__		assertFalse(fs.exists(directory))__	};test,that,link,file,utils,delete,path,if,empty,file,system,path,deletes,the,path,if,it,is,empty,a,path,can,only,be,empty,if,it,is,a,directory,which,does,not,contain,any,files,directories;test,public,void,test,delete,path,if,empty,throws,ioexception,final,path,base,path,new,path,hdfs,uri,final,path,directory,new,path,base,path,uuid,random,uuid,to,string,final,path,directory,file,new,path,directory,uuid,random,uuid,to,string,final,path,single,file,new,path,base,path,uuid,random,uuid,to,string,file,system,fs,base,path,get,file,system,fs,mkdirs,directory,byte,data,hdfstest,test,delete,path,if,empty,get,bytes,config,constants,for,path,file,arrays,as,list,single,file,directory,file,org,apache,flink,core,fs,fsdata,output,stream,output,stream,fs,create,file,file,system,write,mode,overwrite,output,stream,write,data,output,stream,close,assert,true,fs,exists,single,file,assert,true,fs,exists,directory,file,assert,false,file,utils,delete,path,if,empty,fs,single,file,assert,true,fs,exists,single,file,assert,false,file,utils,delete,path,if,empty,fs,directory,assert,true,fs,exists,directory,assert,true,fs,delete,directory,file,false,assert,true,file,utils,delete,path,if,empty,fs,directory,assert,false,fs,exists,directory
HDFSTest -> @Test 	public void testBlobCacheRecovery() throws Exception;1507212387;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer when uploaded via a {@link org.apache.flink.runtime.blob.BlobCache}.;@Test_	public void testBlobCacheRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(CoreOptions.STATE_BACKEND, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			BlobCacheRecoveryTest.testBlobCacheRecovery(config, blobStoreService)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server,when,uploaded,via,a,link,org,apache,flink,runtime,blob,blob,cache;test,public,void,test,blob,cache,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,core,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,blob,cache,recovery,test,test,blob,cache,recovery,config,blob,store,service,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobCacheRecovery() throws Exception;1507212387;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer when uploaded via a BLOB cache.;@Test_	public void testBlobCacheRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___		try {_			BlobCacheRecoveryTest.testBlobCacheRecovery(config, blobStoreService)__		} finally {_			blobStoreService.closeAndCleanupAllData()__		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server,when,uploaded,via,a,blob,cache;test,public,void,test,blob,cache,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,blob,utils,create,blob,store,from,config,config,try,blob,cache,recovery,test,test,blob,cache,recovery,config,blob,store,service,finally,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobCacheRecovery() throws Exception;1509723634;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer when uploaded via a BLOB cache.;@Test_	public void testBlobCacheRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___		try {_			BlobCacheRecoveryTest.testBlobCacheRecovery(config, blobStoreService)__		} finally {_			blobStoreService.closeAndCleanupAllData()__		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server,when,uploaded,via,a,blob,cache;test,public,void,test,blob,cache,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,blob,utils,create,blob,store,from,config,config,try,blob,cache,recovery,test,test,blob,cache,recovery,config,blob,store,service,finally,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobServerRecovery() throws Exception;1485510281;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(ConfigConstants.STATE_BACKEND, "ZOOKEEPER")__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobRecoveryITCase.testBlobServerRecovery(config)__	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,config,constants,zookeeper,config,set,string,high,availability,options,hdfs,uri,blob,recovery,itcase,test,blob,server,recovery,config
HDFSTest -> @Test 	public void testBlobServerRecovery() throws Exception;1487622556;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(CoreOptions.STATE_BACKEND, "ZOOKEEPER")__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobRecoveryITCase.testBlobServerRecovery(config)__	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,core,options,zookeeper,config,set,string,high,availability,options,hdfs,uri,blob,recovery,itcase,test,blob,server,recovery,config
HDFSTest -> @Test 	public void testBlobServerRecovery() throws Exception;1489060855;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(CoreOptions.STATE_BACKEND, "ZOOKEEPER")__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobRecoveryITCase.testBlobServerRecovery(config)__	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,core,options,zookeeper,config,set,string,high,availability,options,hdfs,uri,blob,recovery,itcase,test,blob,server,recovery,config
HDFSTest -> @Test 	public void testBlobServerRecovery() throws Exception;1495001929;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(CoreOptions.STATE_BACKEND, "ZOOKEEPER")__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			BlobRecoveryITCase.testBlobServerRecovery(config, blobStoreService)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,core,options,zookeeper,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,blob,recovery,itcase,test,blob,server,recovery,config,blob,store,service,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobServerRecovery() throws Exception;1495813291;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(CoreOptions.STATE_BACKEND, "ZOOKEEPER")__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			BlobRecoveryITCase.testBlobServerRecovery(config, blobStoreService)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,core,options,zookeeper,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,blob,recovery,itcase,test,blob,server,recovery,config,blob,store,service,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobServerRecovery() throws Exception;1498220069;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(CoreOptions.STATE_BACKEND, "ZOOKEEPER")__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			BlobRecoveryITCase.testBlobServerRecovery(config, blobStoreService)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,core,options,zookeeper,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,blob,recovery,itcase,test,blob,server,recovery,config,blob,store,service,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobServerRecovery() throws Exception;1498894422;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(CoreOptions.STATE_BACKEND, "ZOOKEEPER")__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			BlobRecoveryITCase.testBlobServerRecovery(config, blobStoreService)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,core,options,zookeeper,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,blob,recovery,itcase,test,blob,server,recovery,config,blob,store,service,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobServerRecovery() throws Exception;1502100084;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer.;@Test_	public void testBlobServerRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(CoreOptions.STATE_BACKEND, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			BlobRecoveryITCase.testBlobServerRecovery(config, blobStoreService)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server;test,public,void,test,blob,server,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,core,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,blob,recovery,itcase,test,blob,server,recovery,config,blob,store,service,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobServerRecovery() throws Exception;1507212387;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer when talking to the {@link org.apache.flink.runtime.blob.BlobServer} directly.;@Test_	public void testBlobServerRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(CoreOptions.STATE_BACKEND, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = null___		try {_			blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___			BlobServerRecoveryTest.testBlobServerRecovery(config, blobStoreService)__		} finally {_			if (blobStoreService != null) {_				blobStoreService.closeAndCleanupAllData()__			}_		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server,when,talking,to,the,link,org,apache,flink,runtime,blob,blob,server,directly;test,public,void,test,blob,server,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,core,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,null,try,blob,store,service,blob,utils,create,blob,store,from,config,config,blob,server,recovery,test,test,blob,server,recovery,config,blob,store,service,finally,if,blob,store,service,null,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobServerRecovery() throws Exception;1507212387;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer when talking to the {@link org.apache.flink.runtime.blob.BlobServer} directly.;@Test_	public void testBlobServerRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___		try {_			BlobServerRecoveryTest.testBlobServerRecovery(config, blobStoreService)__		} finally {_			blobStoreService.closeAndCleanupAllData()__		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server,when,talking,to,the,link,org,apache,flink,runtime,blob,blob,server,directly;test,public,void,test,blob,server,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,blob,utils,create,blob,store,from,config,config,try,blob,server,recovery,test,test,blob,server,recovery,config,blob,store,service,finally,blob,store,service,close,and,cleanup,all,data
HDFSTest -> @Test 	public void testBlobServerRecovery() throws Exception;1509723634;Tests that with {@link HighAvailabilityMode#ZOOKEEPER} distributed JARs are recoverable from any_participating BlobServer when talking to the {@link org.apache.flink.runtime.blob.BlobServer} directly.;@Test_	public void testBlobServerRecovery() throws Exception {_		org.apache.flink.configuration.Configuration_			config = new org.apache.flink.configuration.Configuration()__		config.setString(HighAvailabilityOptions.HA_MODE, "ZOOKEEPER")__		config.setString(BlobServerOptions.STORAGE_DIRECTORY,_			temporaryFolder.newFolder().getAbsolutePath())__		config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI)___		BlobStoreService blobStoreService = BlobUtils.createBlobStoreFromConfig(config)___		try {_			BlobServerRecoveryTest.testBlobServerRecovery(config, blobStoreService)__		} finally {_			blobStoreService.closeAndCleanupAllData()__		}_	};tests,that,with,link,high,availability,mode,zookeeper,distributed,jars,are,recoverable,from,any,participating,blob,server,when,talking,to,the,link,org,apache,flink,runtime,blob,blob,server,directly;test,public,void,test,blob,server,recovery,throws,exception,org,apache,flink,configuration,configuration,config,new,org,apache,flink,configuration,configuration,config,set,string,high,availability,options,zookeeper,config,set,string,blob,server,options,temporary,folder,new,folder,get,absolute,path,config,set,string,high,availability,options,hdfs,uri,blob,store,service,blob,store,service,blob,utils,create,blob,store,from,config,config,try,blob,server,recovery,test,test,blob,server,recovery,config,blob,store,service,finally,blob,store,service,close,and,cleanup,all,data
