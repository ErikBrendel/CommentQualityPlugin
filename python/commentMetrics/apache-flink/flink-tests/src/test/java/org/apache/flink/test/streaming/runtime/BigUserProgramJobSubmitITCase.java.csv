commented;modifiers;parameterAmount;loc;comment;code
false;public;1;4;;@Override public String map(Integer value) throws Exception {     return "x " + value + " " + data[value]. }
true;public;0;47;/**  * Use a map function that references a 100MB byte array.  */ ;/**  * Use a map function that references a 100MB byte array.  */ @Test public void bigDataInMap() throws Exception {     // 16 MB     final byte[] data = new byte[16 * 1024 * 1024].     // use random data so that Java does not optimise it away     rnd.nextBytes(data).     data[1] = 0.     data[3] = 0.     data[5] = 0.     CollectingSink resultSink = new CollectingSink().     StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment().     env.setParallelism(1).     DataStream<Integer> src = env.fromElements(1, 3, 5).     src.map(new MapFunction<Integer, String>() {          private static final long serialVersionUID = 1L.          @Override         public String map(Integer value) throws Exception {             return "x " + value + " " + data[value].         }     }).addSink(resultSink).     JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph()).     final RestClusterClient<StandaloneClusterId> restClusterClient = new RestClusterClient<>(MINI_CLUSTER_RESOURCE.getClientConfiguration(), StandaloneClusterId.getInstance()).     try {         restClusterClient.setDetached(false).         restClusterClient.submitJob(jobGraph, BigUserProgramJobSubmitITCase.class.getClassLoader()).         List<String> expected = Arrays.asList("x 1 0", "x 3 0", "x 5 0").         List<String> result = CollectingSink.result.         Collections.sort(expected).         Collections.sort(result).         assertEquals(expected, result).     } finally {         restClusterClient.shutdown().     } }
false;public;2;3;;public void invoke(String value, Context context) throws Exception {     result.add(value). }
