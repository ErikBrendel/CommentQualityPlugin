commented;modifiers;parameterAmount;loc;comment;code
false;public,static;0;26;;@BeforeClass public static void setUp() throws Exception {     Configuration config = new Configuration().     // we need to use the "filesystem" state backend to ensure FLINK-2543 is not happening again.     config.setString(CheckpointingOptions.STATE_BACKEND, "filesystem").     config.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, FOLDER.newFolder().getAbsoluteFile().toURI().toString()).     // Savepoint path     config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, FOLDER.newFolder().getAbsoluteFile().toURI().toString()).     // required as we otherwise run out of memory     config.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, "80m").     miniClusterResource = new MiniClusterResource(new MiniClusterResourceConfiguration.Builder().setNumberTaskManagers(2).setNumberSlotsPerTaskManager(2).setConfiguration(config).build()).     miniClusterResource.before(). }
false;public,static;0;6;;@AfterClass public static void tearDownClass() {     if (miniClusterResource != null) {         miniClusterResource.after().     } }
false;public;0;5;;@After public void tearDown() {     TestStreamEnvironment.unsetAsContext().     TestEnvironment.unsetAsContext(). }
false;public;0;13;;@Test public void testCustomSplitJobWithCustomClassLoaderJar() throws IOException, ProgramInvocationException {     PackagedProgram inputSplitTestProg = new PackagedProgram(new File(INPUT_SPLITS_PROG_JAR_FILE)).     TestEnvironment.setAsContext(miniClusterResource.getMiniCluster(), parallelism, Collections.singleton(new Path(INPUT_SPLITS_PROG_JAR_FILE)), Collections.<URL>emptyList()).     inputSplitTestProg.invokeInteractiveModeForExecution(). }
false;public;0;12;;@Test public void testStreamingCustomSplitJobWithCustomClassLoader() throws IOException, ProgramInvocationException {     PackagedProgram streamingInputSplitTestProg = new PackagedProgram(new File(STREAMING_INPUT_SPLITS_PROG_JAR_FILE)).     TestStreamEnvironment.setAsContext(miniClusterResource.getMiniCluster(), parallelism, Collections.singleton(new Path(STREAMING_INPUT_SPLITS_PROG_JAR_FILE)), Collections.<URL>emptyList()).     streamingInputSplitTestProg.invokeInteractiveModeForExecution(). }
false;public;0;13;;@Test public void testCustomSplitJobWithCustomClassLoaderPath() throws IOException, ProgramInvocationException {     URL classpath = new File(INPUT_SPLITS_PROG_JAR_FILE).toURI().toURL().     PackagedProgram inputSplitTestProg2 = new PackagedProgram(new File(INPUT_SPLITS_PROG_JAR_FILE)).     TestEnvironment.setAsContext(miniClusterResource.getMiniCluster(), parallelism, Collections.<Path>emptyList(), Collections.singleton(classpath)).     inputSplitTestProg2.invokeInteractiveModeForExecution(). }
false;public;0;13;;@Test public void testStreamingClassloaderJobWithCustomClassLoader() throws IOException, ProgramInvocationException {     // regular streaming job     PackagedProgram streamingProg = new PackagedProgram(new File(STREAMING_PROG_JAR_FILE)).     TestStreamEnvironment.setAsContext(miniClusterResource.getMiniCluster(), parallelism, Collections.singleton(new Path(STREAMING_PROG_JAR_FILE)), Collections.<URL>emptyList()).     streamingProg.invokeInteractiveModeForExecution(). }
false;public;0;34;;@Test public void testCheckpointedStreamingClassloaderJobWithCustomClassLoader() throws IOException, ProgramInvocationException {     // checkpointed streaming job with custom classes for the checkpoint (FLINK-2543)     // the test also ensures that user specific exceptions are serializable between JobManager <--> JobClient.     PackagedProgram streamingCheckpointedProg = new PackagedProgram(new File(STREAMING_CHECKPOINTED_PROG_JAR_FILE)).     TestStreamEnvironment.setAsContext(miniClusterResource.getMiniCluster(), parallelism, Collections.singleton(new Path(STREAMING_CHECKPOINTED_PROG_JAR_FILE)), Collections.<URL>emptyList()).     try {         streamingCheckpointedProg.invokeInteractiveModeForExecution().     } catch (Exception e) {         // the deserialization of the exception should thus fail here         try {             Optional<Throwable> exception = ExceptionUtils.findThrowable(e, candidate -> candidate.getClass().getCanonicalName().equals("org.apache.flink.test.classloading.jar.CheckpointedStreamingProgram.SuccessException")).             // or the deserialization of the user-exception did not fail             if (!exception.isPresent()) {                 throw e.             } else {                 Assert.fail("Deserialization of user exception should have failed.").             }         } catch (NoClassDefFoundError expected) {         // expected         }     } }
false;public;0;18;;@Test public void testKMeansJobWithCustomClassLoader() throws IOException, ProgramInvocationException {     PackagedProgram kMeansProg = new PackagedProgram(new File(KMEANS_JAR_PATH), new String[] { KMeansData.DATAPOINTS, KMeansData.INITIAL_CENTERS, "25" }).     TestEnvironment.setAsContext(miniClusterResource.getMiniCluster(), parallelism, Collections.singleton(new Path(KMEANS_JAR_PATH)), Collections.<URL>emptyList()).     kMeansProg.invokeInteractiveModeForExecution(). }
false;public;0;12;;@Test public void testUserCodeTypeJobWithCustomClassLoader() throws IOException, ProgramInvocationException {     PackagedProgram userCodeTypeProg = new PackagedProgram(new File(USERCODETYPE_JAR_PATH)).     TestEnvironment.setAsContext(miniClusterResource.getMiniCluster(), parallelism, Collections.singleton(new Path(USERCODETYPE_JAR_PATH)), Collections.<URL>emptyList()).     userCodeTypeProg.invokeInteractiveModeForExecution(). }
false;public;0;23;;@Test public void testCheckpointingCustomKvStateJobWithCustomClassLoader() throws IOException, ProgramInvocationException {     File checkpointDir = FOLDER.newFolder().     File outputDir = FOLDER.newFolder().     final PackagedProgram program = new PackagedProgram(new File(CHECKPOINTING_CUSTOM_KV_STATE_JAR_PATH), new String[] { checkpointDir.toURI().toString(), outputDir.toURI().toString() }).     TestStreamEnvironment.setAsContext(miniClusterResource.getMiniCluster(), parallelism, Collections.singleton(new Path(CHECKPOINTING_CUSTOM_KV_STATE_JAR_PATH)), Collections.<URL>emptyList()).     expectedException.expectCause(Matchers.<Throwable>hasProperty("cause", isA(SuccessException.class))).     program.invokeInteractiveModeForExecution(). }
false;public;0;11;;@Override public void run() {     try {         program.invokeInteractiveModeForExecution().     } catch (ProgramInvocationException ignored) {         if (ignored.getCause() == null || !(ignored.getCause() instanceof JobCancellationException)) {             ignored.printStackTrace().         }     } }
true;public;0;90;/**  * Tests disposal of a savepoint, which contains custom user code KvState.  */ ;/**  * Tests disposal of a savepoint, which contains custom user code KvState.  */ @Test public void testDisposeSavepointWithCustomKvState() throws Exception {     ClusterClient<?> clusterClient = new MiniClusterClient(new Configuration(), miniClusterResource.getMiniCluster()).     Deadline deadline = new FiniteDuration(100, TimeUnit.SECONDS).fromNow().     File checkpointDir = FOLDER.newFolder().     File outputDir = FOLDER.newFolder().     final PackagedProgram program = new PackagedProgram(new File(CUSTOM_KV_STATE_JAR_PATH), new String[] { String.valueOf(parallelism), checkpointDir.toURI().toString(), "5000", outputDir.toURI().toString() }).     TestStreamEnvironment.setAsContext(miniClusterResource.getMiniCluster(), parallelism, Collections.singleton(new Path(CUSTOM_KV_STATE_JAR_PATH)), Collections.<URL>emptyList()).     // Execute detached     Thread invokeThread = new Thread(new Runnable() {          @Override         public void run() {             try {                 program.invokeInteractiveModeForExecution().             } catch (ProgramInvocationException ignored) {                 if (ignored.getCause() == null || !(ignored.getCause() instanceof JobCancellationException)) {                     ignored.printStackTrace().                 }             }         }     }).     LOG.info("Starting program invoke thread").     invokeThread.start().     // The job ID     JobID jobId = null.     LOG.info("Waiting for job status running.").     // Wait for running job     while (jobId == null && deadline.hasTimeLeft()) {         Collection<JobStatusMessage> jobs = clusterClient.listJobs().get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).         for (JobStatusMessage job : jobs) {             if (job.getJobState() == JobStatus.RUNNING) {                 jobId = job.getJobId().                 LOG.info("Job running. ID: " + jobId).                 break.             }         }         // Retry if job is not available yet         if (jobId == null) {             Thread.sleep(100L).         }     }     // Trigger savepoint     String savepointPath = null.     for (int i = 0. i < 20. i++) {         LOG.info("Triggering savepoint (" + (i + 1) + "/20).").         try {             savepointPath = clusterClient.triggerSavepoint(jobId, null).get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).         } catch (Exception cause) {             LOG.info("Failed to trigger savepoint. Retrying...", cause).             // This can fail if the operators are not opened yet             Thread.sleep(500).         }     }     assertNotNull("Failed to trigger savepoint", savepointPath).     clusterClient.disposeSavepoint(savepointPath).get().     clusterClient.cancel(jobId).     // make sure, the execution is finished to not influence other test methods     invokeThread.join(deadline.timeLeft().toMillis()).     assertFalse("Program invoke thread still running", invokeThread.isAlive()). }
