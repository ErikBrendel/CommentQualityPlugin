commented;modifiers;parameterAmount;loc;comment;code
false;public;0;11;;@Before public void setUp() throws Exception {     final File testRoot = folder.newFolder().     checkpointDir = new File(testRoot, "checkpoints").     savepointDir = new File(testRoot, "savepoints").     if (!checkpointDir.mkdir() || !savepointDir.mkdirs()) {         fail("Test setup failed: failed to create temporary directories.").     } }
true;public;0;16;/**  * Triggers a savepoint for a job that uses the FsStateBackend. We expect  * that all checkpoint files are written to a new savepoint directory.  *  * <ol>  * <li>Submit job, wait for some progress</li>  * <li>Trigger savepoint and verify that savepoint has been created</li>  * <li>Shut down the cluster, re-submit the job from the savepoint,  * verify that the initial state has been reset, and  * all tasks are running again</li>  * <li>Cancel job, dispose the savepoint, and verify that everything  * has been cleaned up</li>  * </ol>  */ ;/**  * Triggers a savepoint for a job that uses the FsStateBackend. We expect  * that all checkpoint files are written to a new savepoint directory.  *  * <ol>  * <li>Submit job, wait for some progress</li>  * <li>Trigger savepoint and verify that savepoint has been created</li>  * <li>Shut down the cluster, re-submit the job from the savepoint,  * verify that the initial state has been reset, and  * all tasks are running again</li>  * <li>Cancel job, dispose the savepoint, and verify that everything  * has been cleaned up</li>  * </ol>  */ @Test public void testTriggerSavepointAndResumeWithFileBasedCheckpoints() throws Exception {     final int numTaskManagers = 2.     final int numSlotsPerTaskManager = 2.     final int parallelism = numTaskManagers * numSlotsPerTaskManager.     final MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(numTaskManagers, numSlotsPerTaskManager, getFileBasedCheckpointsConfig()).     final String savepointPath = submitJobAndTakeSavepoint(clusterFactory, parallelism).     verifySavepoint(parallelism, savepointPath).     restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism). }
false;public;0;16;;@Test public void testShouldAddEntropyToSavepointPath() throws Exception {     final int numTaskManagers = 2.     final int numSlotsPerTaskManager = 2.     final int parallelism = numTaskManagers * numSlotsPerTaskManager.     final MiniClusterResourceFactory clusterFactory = new MiniClusterResourceFactory(numTaskManagers, numSlotsPerTaskManager, getCheckpointingWithEntropyConfig()).     final String savepointPath = submitJobAndTakeSavepoint(clusterFactory, parallelism).     assertThat(savepointDir, hasEntropyInFileStateHandlePaths()).     restoreJobAndVerifyState(savepointPath, clusterFactory, parallelism). }
false;private;0;6;;private Configuration getCheckpointingWithEntropyConfig() {     final String savepointPathWithEntropyPlaceholder = new File(savepointDir, EntropyInjectingTestFileSystem.ENTROPY_INJECTION_KEY).getPath().     final Configuration config = getFileBasedCheckpointsConfig("test-entropy://" + savepointPathWithEntropyPlaceholder).     config.setString("s3.entropy.key", EntropyInjectingTestFileSystem.ENTROPY_INJECTION_KEY).     return config. }
false;private;2;21;;private String submitJobAndTakeSavepoint(MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {     final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000).     final JobID jobId = jobGraph.getJobID().     StatefulCounter.resetForTest(parallelism).     MiniClusterWithClientResource cluster = clusterFactory.get().     cluster.before().     ClusterClient<?> client = cluster.getClusterClient().     try {         client.setDetached(true).         client.submitJob(jobGraph, SavepointITCase.class.getClassLoader()).         StatefulCounter.getProgressLatch().await().         return client.cancelWithSavepoint(jobId, null).     } finally {         cluster.after().         StatefulCounter.resetForTest(parallelism).     } }
false;private;2;18;;private void verifySavepoint(final int parallelism, final String savepointPath) throws URISyntaxException {     // Only one savepoint should exist     File savepointDir = new File(new URI(savepointPath)).     assertTrue("Savepoint directory does not exist.", savepointDir.exists()).     assertTrue("Savepoint did not create self-contained directory.", savepointDir.isDirectory()).     File[] savepointFiles = savepointDir.listFiles().     if (savepointFiles != null) {         // Expect one metadata file and one checkpoint file per stateful         // parallel subtask         String errMsg = "Did not write expected number of savepoint/checkpoint files to directory: " + Arrays.toString(savepointFiles).         assertEquals(errMsg, 1 + parallelism, savepointFiles.length).     } else {         fail(String.format("Returned savepoint path (%s) is not valid.", savepointPath)).     } }
false;private;3;39;;private void restoreJobAndVerifyState(String savepointPath, MiniClusterResourceFactory clusterFactory, int parallelism) throws Exception {     final JobGraph jobGraph = createJobGraph(parallelism, 0, 1000).     jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath)).     final JobID jobId = jobGraph.getJobID().     StatefulCounter.resetForTest(parallelism).     MiniClusterWithClientResource cluster = clusterFactory.get().     cluster.before().     ClusterClient<?> client = cluster.getClusterClient().     try {         client.setDetached(true).         client.submitJob(jobGraph, SavepointITCase.class.getClassLoader()).         // Await state is restored         StatefulCounter.getRestoreLatch().await().         // Await some progress after restore         StatefulCounter.getProgressLatch().await().         client.cancel(jobId).         FutureUtils.retrySuccessfulWithDelay(() -> client.getJobStatus(jobId), Time.milliseconds(50), Deadline.now().plus(Duration.ofSeconds(30)), status -> status == JobStatus.CANCELED, TestingUtils.defaultScheduledExecutor()).         client.disposeSavepoint(savepointPath).get().         assertFalse("Savepoint not properly cleaned up.", new File(savepointPath).exists()).     } finally {         cluster.after().         StatefulCounter.resetForTest(parallelism).     } }
false;public;0;31;;@Test public void testTriggerSavepointForNonExistingJob() throws Exception {     // Config     final int numTaskManagers = 1.     final int numSlotsPerTaskManager = 1.     final Configuration config = new Configuration().     config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString()).     final MiniClusterWithClientResource cluster = new MiniClusterWithClientResource(new MiniClusterResourceConfiguration.Builder().setConfiguration(config).setNumberTaskManagers(numTaskManagers).setNumberSlotsPerTaskManager(numSlotsPerTaskManager).build()).     cluster.before().     final ClusterClient<?> client = cluster.getClusterClient().     final JobID jobID = new JobID().     try {         client.triggerSavepoint(jobID, null).get().         fail().     } catch (ExecutionException e) {         assertTrue(ExceptionUtils.findThrowable(e, FlinkJobNotFoundException.class).isPresent()).         assertTrue(ExceptionUtils.findThrowableWithMessage(e, jobID.toString()).isPresent()).     } finally {         cluster.after().     } }
false;public;0;38;;@Test public void testTriggerSavepointWithCheckpointingDisabled() throws Exception {     // Config     final int numTaskManagers = 1.     final int numSlotsPerTaskManager = 1.     final Configuration config = new Configuration().     final MiniClusterWithClientResource cluster = new MiniClusterWithClientResource(new MiniClusterResourceConfiguration.Builder().setConfiguration(config).setNumberTaskManagers(numTaskManagers).setNumberSlotsPerTaskManager(numSlotsPerTaskManager).build()).     cluster.before().     final ClusterClient<?> client = cluster.getClusterClient().     final JobVertex vertex = new JobVertex("Blocking vertex").     vertex.setInvokableClass(BlockingNoOpInvokable.class).     vertex.setParallelism(1).     final JobGraph graph = new JobGraph(vertex).     try {         client.setDetached(true).         client.submitJob(graph, SavepointITCase.class.getClassLoader()).         client.triggerSavepoint(graph.getJobID(), null).get().         fail().     } catch (ExecutionException e) {         assertTrue(ExceptionUtils.findThrowable(e, IllegalStateException.class).isPresent()).         assertTrue(ExceptionUtils.findThrowableWithMessage(e, graph.getJobID().toString()).isPresent()).         assertTrue(ExceptionUtils.findThrowableWithMessage(e, "is not a streaming job").isPresent()).     } finally {         cluster.after().     } }
false;public;0;48;;@Test public void testSubmitWithUnknownSavepointPath() throws Exception {     // Config     int numTaskManagers = 1.     int numSlotsPerTaskManager = 1.     int parallelism = numTaskManagers * numSlotsPerTaskManager.     final Configuration config = new Configuration().     config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString()).     MiniClusterWithClientResource cluster = new MiniClusterWithClientResource(new MiniClusterResourceConfiguration.Builder().setConfiguration(config).setNumberTaskManagers(numTaskManagers).setNumberSlotsPerTaskManager(numSlotsPerTaskManager).build()).     cluster.before().     ClusterClient<?> client = cluster.getClusterClient().     try {         // High value to ensure timeouts if restarted.         int numberOfRetries = 1000.         // Submit the job         // Long delay to ensure that the test times out if the job         // manager tries to restart the job.         final JobGraph jobGraph = createJobGraph(parallelism, numberOfRetries, 3600000).         // Set non-existing savepoint path         jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath("unknown path")).         assertEquals("unknown path", jobGraph.getSavepointRestoreSettings().getRestorePath()).         LOG.info("Submitting job " + jobGraph.getJobID() + " in detached mode.").         try {             client.setDetached(false).             client.submitJob(jobGraph, SavepointITCase.class.getClassLoader()).         } catch (Exception e) {             Optional<JobExecutionException> expectedJobExecutionException = ExceptionUtils.findThrowable(e, JobExecutionException.class).             Optional<FileNotFoundException> expectedFileNotFoundException = ExceptionUtils.findThrowable(e, FileNotFoundException.class).             if (!(expectedJobExecutionException.isPresent() && expectedFileNotFoundException.isPresent())) {                 throw e.             }         }     } finally {         cluster.after().     } }
true;public;0;109;/**  * FLINK-5985  *  * <p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern  * stateless operators.  */ ;/**  * FLINK-5985  *  * <p>This test ensures we can restore from a savepoint under modifications to the job graph that only concern  * stateless operators.  */ @Test public void testCanRestoreWithModifiedStatelessOperators() throws Exception {     // Config     int numTaskManagers = 2.     int numSlotsPerTaskManager = 2.     int parallelism = 2.     // Test deadline     final Deadline deadline = Deadline.now().plus(Duration.ofMinutes(5)).     // Flink configuration     final Configuration config = new Configuration().     config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir.toURI().toString()).     String savepointPath.     LOG.info("Flink configuration: " + config + ".").     // Start Flink     MiniClusterWithClientResource cluster = new MiniClusterWithClientResource(new MiniClusterResourceConfiguration.Builder().setConfiguration(config).setNumberTaskManagers(numTaskManagers).setNumberSlotsPerTaskManager(numSlotsPerTaskManager).build()).     LOG.info("Shutting down Flink cluster.").     cluster.before().     ClusterClient<?> client = cluster.getClusterClient().     try {         final StatefulCounter statefulCounter = new StatefulCounter().         StatefulCounter.resetForTest(parallelism).         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment().         env.setParallelism(parallelism).         env.addSource(new InfiniteTestSource()).shuffle().map(value -> 4 * value).shuffle().map(statefulCounter).uid("statefulCounter").shuffle().map(value -> 2 * value).addSink(new DiscardingSink<>()).         JobGraph originalJobGraph = env.getStreamGraph().getJobGraph().         client.setDetached(true).         JobSubmissionResult submissionResult = client.submitJob(originalJobGraph, SavepointITCase.class.getClassLoader()).         JobID jobID = submissionResult.getJobID().         // wait for the Tasks to be ready         StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).         savepointPath = client.triggerSavepoint(jobID, null).get().         LOG.info("Retrieved savepoint: " + savepointPath + ".").     } finally {         // Shut down the Flink cluster (thereby canceling the job)         LOG.info("Shutting down Flink cluster.").         cluster.after().     }     // create a new MiniCluster to make sure we start with completely     // new resources     cluster = new MiniClusterWithClientResource(new MiniClusterResourceConfiguration.Builder().setConfiguration(config).setNumberTaskManagers(numTaskManagers).setNumberSlotsPerTaskManager(numSlotsPerTaskManager).build()).     LOG.info("Restarting Flink cluster.").     cluster.before().     client = cluster.getClusterClient().     try {         // Reset static test helpers         StatefulCounter.resetForTest(parallelism).         // Gather all task deployment descriptors         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment().         env.setParallelism(parallelism).         // generate a modified job graph that adds a stateless op         env.addSource(new InfiniteTestSource()).shuffle().map(new StatefulCounter()).uid("statefulCounter").shuffle().map(value -> value).addSink(new DiscardingSink<>()).         JobGraph modifiedJobGraph = env.getStreamGraph().getJobGraph().         // Set the savepoint path         modifiedJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath)).         LOG.info("Resubmitting job " + modifiedJobGraph.getJobID() + " with " + "savepoint path " + savepointPath + " in detached mode.").         // Submit the job         client.setDetached(true).         client.submitJob(modifiedJobGraph, SavepointITCase.class.getClassLoader()).         // Await state is restored         StatefulCounter.getRestoreLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).         // Await some progress after restore         StatefulCounter.getProgressLatch().await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS).     } finally {         cluster.after().     } }
true;private;3;20;/**  * Creates a streaming JobGraph from the StreamEnvironment.  */ ;// ------------------------------------------------------------------------ // Test program // ------------------------------------------------------------------------ /**  * Creates a streaming JobGraph from the StreamEnvironment.  */ private JobGraph createJobGraph(int parallelism, int numberOfRetries, long restartDelay) {     StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment().     env.setParallelism(parallelism).     env.disableOperatorChaining().     env.getConfig().setRestartStrategy(RestartStrategies.fixedDelayRestart(numberOfRetries, restartDelay)).     env.getConfig().disableSysoutLogging().     DataStream<Integer> stream = env.addSource(new InfiniteTestSource()).shuffle().map(new StatefulCounter()).     stream.addSink(new DiscardingSink<>()).     return env.getStreamGraph().getJobGraph(). }
false;public;1;9;;@Override public void run(SourceContext<Integer> ctx) throws Exception {     while (running) {         synchronized (ctx.getCheckpointLock()) {             ctx.collect(1).         }         Thread.sleep(1).     } }
false;public;0;4;;@Override public void cancel() {     running = false. }
false;public;1;9;;@Override public void open(Configuration parameters) throws Exception {     if (data == null) {         // We need this to be large, because we want to test with files         Random rand = new Random(getRuntimeContext().getIndexOfThisSubtask()).         data = new byte[CheckpointingOptions.FS_SMALL_FILE_THRESHOLD.defaultValue() + 1].         rand.nextBytes(data).     } }
false;public;1;12;;@Override public Integer map(Integer value) throws Exception {     for (int i = 0. i < data.length. i++) {         data[i] += 1.     }     if (numCollectedElements++ > 10) {         progressLatch.countDown().     }     return value. }
false;public;2;4;;@Override public List<byte[]> snapshotState(long checkpointId, long timestamp) throws Exception {     return Collections.singletonList(data). }
false;public;1;9;;@Override public void restoreState(List<byte[]> state) throws Exception {     if (state.isEmpty() || state.size() > 1) {         throw new RuntimeException("Test failed due to unexpected recovered state size " + state.size()).     }     this.data = state.get(0).     restoreLatch.countDown(). }
false;static;0;3;;// -------------------------------------------------------------------- static CountDownLatch getProgressLatch() {     return progressLatch. }
false;static;0;3;;static CountDownLatch getRestoreLatch() {     return restoreLatch. }
false;static;1;4;;static void resetForTest(int parallelism) {     progressLatch = new CountDownLatch(parallelism).     restoreLatch = new CountDownLatch(parallelism). }
false;public;1;4;;@Override public Object getKey(Integer value) throws Exception {     return value. }
false;public;2;4;;@Override public void flatMap(Integer in, Collector<Integer> clctr) throws Exception {     clctr.collect(in). }
false;public;1;4;;@Override public Integer map(Integer value) throws Exception {     return value. }
false;public;0;99;;@Test public void testSavepointForJobWithIteration() throws Exception {     for (int i = 0. i < ITER_TEST_PARALLELISM. ++i) {         iterTestSnapshotWait[i] = new OneShotLatch().         iterTestRestoreWait[i] = new OneShotLatch().         iterTestCheckpointVerify[i] = 0.     }     final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment().     final IntegerStreamSource source = new IntegerStreamSource().     IterativeStream<Integer> iteration = env.addSource(source).flatMap(new RichFlatMapFunction<Integer, Integer>() {          private static final long serialVersionUID = 1L.          @Override         public void flatMap(Integer in, Collector<Integer> clctr) throws Exception {             clctr.collect(in).         }     }).setParallelism(ITER_TEST_PARALLELISM).keyBy(new KeySelector<Integer, Object>() {          private static final long serialVersionUID = 1L.          @Override         public Object getKey(Integer value) throws Exception {             return value.         }     }).flatMap(new DuplicateFilter()).setParallelism(ITER_TEST_PARALLELISM).iterate().     DataStream<Integer> iterationBody = iteration.map(new MapFunction<Integer, Integer>() {          private static final long serialVersionUID = 1L.          @Override         public Integer map(Integer value) throws Exception {             return value.         }     }).setParallelism(ITER_TEST_PARALLELISM).     iteration.closeWith(iterationBody).     StreamGraph streamGraph = env.getStreamGraph().     streamGraph.setJobName("Test").     JobGraph jobGraph = streamGraph.getJobGraph().     Configuration config = getFileBasedCheckpointsConfig().     config.addAll(jobGraph.getJobConfiguration()).     config.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, "0").     MiniClusterWithClientResource cluster = new MiniClusterWithClientResource(new MiniClusterResourceConfiguration.Builder().setConfiguration(config).setNumberTaskManagers(1).setNumberSlotsPerTaskManager(2 * jobGraph.getMaximumParallelism()).build()).     cluster.before().     ClusterClient<?> client = cluster.getClusterClient().     String savepointPath = null.     try {         client.setDetached(true).         client.submitJob(jobGraph, SavepointITCase.class.getClassLoader()).         for (OneShotLatch latch : iterTestSnapshotWait) {             latch.await().         }         savepointPath = client.triggerSavepoint(jobGraph.getJobID(), null).get().         client.cancel(jobGraph.getJobID()).         while (!client.getJobStatus(jobGraph.getJobID()).get().isGloballyTerminalState()) {             Thread.sleep(100).         }         jobGraph = streamGraph.getJobGraph().         jobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath)).         client.setDetached(true).         client.submitJob(jobGraph, SavepointITCase.class.getClassLoader()).         for (OneShotLatch latch : iterTestRestoreWait) {             latch.await().         }         client.cancel(jobGraph.getJobID()).         while (!client.getJobStatus(jobGraph.getJobID()).get().isGloballyTerminalState()) {             Thread.sleep(100).         }     } finally {         if (null != savepointPath) {             client.disposeSavepoint(savepointPath).         }         cluster.after().     } }
false;public;1;16;;@Override public void run(SourceContext<Integer> ctx) throws Exception {     while (running) {         synchronized (ctx.getCheckpointLock()) {             ctx.collect(emittedCount).         }         if (emittedCount < 100) {             ++emittedCount.         } else {             emittedCount = 0.         }         Thread.sleep(1).     } }
false;public;0;4;;@Override public void cancel() {     running = false. }
false;public;2;5;;@Override public List<Integer> snapshotState(long checkpointId, long timestamp) throws Exception {     iterTestCheckpointVerify[getRuntimeContext().getIndexOfThisSubtask()] = emittedCount.     return Collections.singletonList(emittedCount). }
false;public;1;8;;@Override public void restoreState(List<Integer> state) throws Exception {     if (!state.isEmpty()) {         this.emittedCount = state.get(0).     }     Assert.assertEquals(iterTestCheckpointVerify[getRuntimeContext().getIndexOfThisSubtask()], emittedCount).     iterTestRestoreWait[getRuntimeContext().getIndexOfThisSubtask()].trigger(). }
false;public;1;4;;@Override public void open(Configuration configuration) {     operatorState = this.getRuntimeContext().getState(DESCRIPTOR). }
false;public;2;11;;@Override public void flatMap(Integer value, Collector<Integer> out) throws Exception {     if (!operatorState.value()) {         out.collect(value).         operatorState.update(true).     }     if (30 == value) {         iterTestSnapshotWait[getRuntimeContext().getIndexOfThisSubtask()].trigger().     } }
false;;0;8;;MiniClusterWithClientResource get() {     return new MiniClusterWithClientResource(new MiniClusterResourceConfiguration.Builder().setConfiguration(config).setNumberTaskManagers(numTaskManagers).setNumberSlotsPerTaskManager(numSlotsPerTaskManager).build()). }
false;private;1;8;;private Configuration getFileBasedCheckpointsConfig(final String savepointDir) {     final Configuration config = new Configuration().     config.setString(CheckpointingOptions.STATE_BACKEND, "filesystem").     config.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir.toURI().toString()).     config.setInteger(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, 0).     config.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir).     return config. }
false;private;0;3;;private Configuration getFileBasedCheckpointsConfig() {     return getFileBasedCheckpointsConfig(savepointDir.toURI().toString()). }
false;protected;2;23;;@Override protected boolean matchesSafely(final File savepointDir, final Description mismatchDescription) {     if (savepointDir == null) {         mismatchDescription.appendText("savepoint dir must not be null").         return false.     }     final List<Path> filesWithoutEntropy = listRecursively(savepointDir.toPath().resolve(EntropyInjectingTestFileSystem.ENTROPY_INJECTION_KEY)).     final Path savepointDirWithEntropy = savepointDir.toPath().resolve(EntropyInjectingTestFileSystem.ENTROPY).     final List<Path> filesWithEntropy = listRecursively(savepointDirWithEntropy).     if (!filesWithoutEntropy.isEmpty()) {         mismatchDescription.appendText("there are savepoint files with unresolved entropy placeholders").         return false.     }     if (!Files.exists(savepointDirWithEntropy) || filesWithEntropy.isEmpty()) {         mismatchDescription.appendText("there are no savepoint files with added entropy").         return false.     }     return true. }
false;public;1;4;;@Override public void describeTo(final Description description) {     description.appendText("all savepoint files should have added entropy"). }
false;private,static;0;33;;private static Matcher<File> hasEntropyInFileStateHandlePaths() {     return new TypeSafeDiagnosingMatcher<File>() {          @Override         protected boolean matchesSafely(final File savepointDir, final Description mismatchDescription) {             if (savepointDir == null) {                 mismatchDescription.appendText("savepoint dir must not be null").                 return false.             }             final List<Path> filesWithoutEntropy = listRecursively(savepointDir.toPath().resolve(EntropyInjectingTestFileSystem.ENTROPY_INJECTION_KEY)).             final Path savepointDirWithEntropy = savepointDir.toPath().resolve(EntropyInjectingTestFileSystem.ENTROPY).             final List<Path> filesWithEntropy = listRecursively(savepointDirWithEntropy).             if (!filesWithoutEntropy.isEmpty()) {                 mismatchDescription.appendText("there are savepoint files with unresolved entropy placeholders").                 return false.             }             if (!Files.exists(savepointDirWithEntropy) || filesWithEntropy.isEmpty()) {                 mismatchDescription.appendText("there are no savepoint files with added entropy").                 return false.             }             return true.         }          @Override         public void describeTo(final Description description) {             description.appendText("all savepoint files should have added entropy").         }     }. }
false;private,static;1;13;;private static List<Path> listRecursively(final Path dir) {     try {         if (!Files.exists(dir)) {             return Collections.emptyList().         } else {             try (Stream<Path> files = Files.walk(dir, FileVisitOption.FOLLOW_LINKS)) {                 return files.filter(Files::isRegularFile).collect(Collectors.toList()).             }         }     } catch (IOException e) {         throw new RuntimeException(e).     } }
