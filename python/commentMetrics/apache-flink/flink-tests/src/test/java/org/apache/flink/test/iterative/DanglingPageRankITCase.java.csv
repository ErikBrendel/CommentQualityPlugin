commented;modifiers;parameterAmount;loc;comment;code
false;public;1;4;;@Override public boolean filter(Tuple2<Long, Boolean> value) {     return value.f1. }
false;public;1;4;;@Override public PageWithRankAndDangling map(Tuple2<Long, Boolean> value) {     return new PageWithRankAndDangling(value.f0, 1.0 / numVertices, value.f1). }
false;public;3;13;;@Override public void join(PageWithRankAndDangling page, PageWithLinks links, Collector<PageWithRank> out) {     double rankToDistribute = page.rank / (double) links.targets.length.     PageWithRank output = new PageWithRank(0L, rankToDistribute).     for (long target : links.targets) {         output.pageId = target.         out.collect(output).     } }
false;public;1;15;;@Override public void open(Configuration parameters) throws Exception {     int currentIteration = getIterationRuntimeContext().getSuperstepNumber().     aggregator = getIterationRuntimeContext().getIterationAggregator(AGGREGATOR_NAME).     if (currentIteration == 1) {         danglingRankFactor = BETA * (double) numDanglingVertices / ((double) numVertices * (double) numVertices).     } else {         PageRankStats previousAggregate = getIterationRuntimeContext().getPreviousIterationAggregate(AGGREGATOR_NAME).         danglingRankFactor = BETA * previousAggregate.danglingRank() / (double) numVertices.     } }
false;public;3;28;;@Override public void coGroup(Iterable<PageWithRankAndDangling> currentPages, Iterable<PageWithRank> partialRanks, Collector<PageWithRankAndDangling> out) {     // compute the next rank     long edges = 0.     double summedRank = 0.     for (PageWithRank partial : partialRanks) {         summedRank += partial.rank.         edges++.     }     double rank = BETA * summedRank + randomJump + danglingRankFactor.     // current rank, for stats and convergence     PageWithRankAndDangling currentPage = currentPages.iterator().next().     double currentRank = currentPage.rank.     boolean isDangling = currentPage.dangling.     // maintain statistics to compensate for probability loss on dangling nodes     double danglingRankToAggregate = isDangling ? rank : 0.     long danglingVerticesToAggregate = isDangling ? 1 : 0.     double diff = Math.abs(currentRank - rank).     aggregator.aggregate(diff, rank, danglingRankToAggregate, danglingVerticesToAggregate, 1, edges).     currentPage.rank = rank.     out.collect(currentPage). }
false;public;0;139;;@Test public void testDanglingPageRank() {     try {         final int numIterations = 25.         final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().         DataSet<Tuple2<Long, Boolean>> vertices = env.fromElements(new Tuple2<>(1L, false), new Tuple2<>(2L, false), new Tuple2<>(5L, false), new Tuple2<>(3L, true), new Tuple2<>(4L, false)).         DataSet<PageWithLinks> edges = env.fromElements(new PageWithLinks(2L, new long[] { 1 }), new PageWithLinks(5L, new long[] { 2, 4 }), new PageWithLinks(4L, new long[] { 3, 2 }), new PageWithLinks(1L, new long[] { 4, 2, 3 })).         final long numVertices = vertices.count().         final long numDanglingVertices = vertices.filter(new FilterFunction<Tuple2<Long, Boolean>>() {              @Override             public boolean filter(Tuple2<Long, Boolean> value) {                 return value.f1.             }         }).count().         DataSet<PageWithRankAndDangling> verticesWithInitialRank = vertices.map(new MapFunction<Tuple2<Long, Boolean>, PageWithRankAndDangling>() {              @Override             public PageWithRankAndDangling map(Tuple2<Long, Boolean> value) {                 return new PageWithRankAndDangling(value.f0, 1.0 / numVertices, value.f1).             }         }).         IterativeDataSet<PageWithRankAndDangling> iteration = verticesWithInitialRank.iterate(numIterations).         iteration.getAggregators().registerAggregationConvergenceCriterion(AGGREGATOR_NAME, new PageRankStatsAggregator(), new DiffL1NormConvergenceCriterion()).         DataSet<PageWithRank> partialRanks = iteration.join(edges).where("pageId").equalTo("pageId").with(new FlatJoinFunction<PageWithRankAndDangling, PageWithLinks, PageWithRank>() {              @Override             public void join(PageWithRankAndDangling page, PageWithLinks links, Collector<PageWithRank> out) {                 double rankToDistribute = page.rank / (double) links.targets.length.                 PageWithRank output = new PageWithRank(0L, rankToDistribute).                 for (long target : links.targets) {                     output.pageId = target.                     out.collect(output).                 }             }         }).         DataSet<PageWithRankAndDangling> newRanks = iteration.coGroup(partialRanks).where("pageId").equalTo("pageId").with(new RichCoGroupFunction<PageWithRankAndDangling, PageWithRank, PageWithRankAndDangling>() {              private static final double BETA = 0.85.              private final double randomJump = (1.0 - BETA) / numVertices.              private PageRankStatsAggregator aggregator.              private double danglingRankFactor.              @Override             public void open(Configuration parameters) throws Exception {                 int currentIteration = getIterationRuntimeContext().getSuperstepNumber().                 aggregator = getIterationRuntimeContext().getIterationAggregator(AGGREGATOR_NAME).                 if (currentIteration == 1) {                     danglingRankFactor = BETA * (double) numDanglingVertices / ((double) numVertices * (double) numVertices).                 } else {                     PageRankStats previousAggregate = getIterationRuntimeContext().getPreviousIterationAggregate(AGGREGATOR_NAME).                     danglingRankFactor = BETA * previousAggregate.danglingRank() / (double) numVertices.                 }             }              @Override             public void coGroup(Iterable<PageWithRankAndDangling> currentPages, Iterable<PageWithRank> partialRanks, Collector<PageWithRankAndDangling> out) {                 // compute the next rank                 long edges = 0.                 double summedRank = 0.                 for (PageWithRank partial : partialRanks) {                     summedRank += partial.rank.                     edges++.                 }                 double rank = BETA * summedRank + randomJump + danglingRankFactor.                 // current rank, for stats and convergence                 PageWithRankAndDangling currentPage = currentPages.iterator().next().                 double currentRank = currentPage.rank.                 boolean isDangling = currentPage.dangling.                 // maintain statistics to compensate for probability loss on dangling nodes                 double danglingRankToAggregate = isDangling ? rank : 0.                 long danglingVerticesToAggregate = isDangling ? 1 : 0.                 double diff = Math.abs(currentRank - rank).                 aggregator.aggregate(diff, rank, danglingRankToAggregate, danglingVerticesToAggregate, 1, edges).                 currentPage.rank = rank.                 out.collect(currentPage).             }         }).         List<PageWithRankAndDangling> result = iteration.closeWith(newRanks).collect().         double totalRank = 0.0.         for (PageWithRankAndDangling r : result) {             totalRank += r.rank.             assertTrue(r.pageId >= 1 && r.pageId <= 5).             assertTrue(r.pageId != 3 || r.dangling).         }         assertEquals(1.0, totalRank, 0.001).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
false;public;0;8;;@Override public String toString() {     return "PageWithRankAndDangling{" + "pageId=" + pageId + ", rank=" + rank + ", dangling=" + dangling + '}'. }
false;public;0;3;;public double diff() {     return diff. }
false;public;0;3;;public double rank() {     return rank. }
false;public;0;3;;public double danglingRank() {     return danglingRank. }
false;public;0;3;;public long numDanglingVertices() {     return numDanglingVertices. }
false;public;0;3;;public long numVertices() {     return numVertices. }
false;public;0;3;;public long edges() {     return edges. }
false;public;1;9;;@Override public void write(DataOutputView out) throws IOException {     out.writeDouble(diff).     out.writeDouble(rank).     out.writeDouble(danglingRank).     out.writeLong(numDanglingVertices).     out.writeLong(numVertices).     out.writeLong(edges). }
false;public;1;9;;@Override public void read(DataInputView in) throws IOException {     diff = in.readDouble().     rank = in.readDouble().     danglingRank = in.readDouble().     numDanglingVertices = in.readLong().     numVertices = in.readLong().     edges = in.readLong(). }
false;public;0;6;;@Override public String toString() {     return "PageRankStats: diff [" + diff + "], rank [" + rank + "], danglingRank [" + danglingRank + "], numDanglingVertices [" + numDanglingVertices + "], numVertices [" + numVertices + "], edges [" + edges + "]". }
false;public;0;4;;@Override public PageRankStats getAggregate() {     return new PageRankStats(diff, rank, danglingRank, numDanglingVertices, numVertices, edges). }
false;public;6;9;;public void aggregate(double diffDelta, double rankDelta, double danglingRankDelta, long danglingVerticesDelta, long verticesDelta, long edgesDelta) {     diff += diffDelta.     rank += rankDelta.     danglingRank += danglingRankDelta.     numDanglingVertices += danglingVerticesDelta.     numVertices += verticesDelta.     edges += edgesDelta. }
false;public;1;9;;@Override public void aggregate(PageRankStats pageRankStats) {     diff += pageRankStats.diff().     rank += pageRankStats.rank().     danglingRank += pageRankStats.danglingRank().     numDanglingVertices += pageRankStats.numDanglingVertices().     numVertices += pageRankStats.numVertices().     edges += pageRankStats.edges(). }
false;public;0;9;;@Override public void reset() {     diff = 0.     rank = 0.     danglingRank = 0.     numDanglingVertices = 0.     numVertices = 0.     edges = 0. }
false;public;2;4;;@Override public boolean isConverged(int iteration, PageRankStats pageRankStats) {     return pageRankStats.diff() < EPSILON. }
