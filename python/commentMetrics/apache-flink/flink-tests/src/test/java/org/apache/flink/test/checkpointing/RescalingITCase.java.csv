# id;timestamp;commentText;codeText;commentWords;codeWords
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartitionedState() throws Exception;1472663071;Tests that a a job with purely partitioned state can be restarted from a savepoint_with a different parallelism.;@Test_	public void testSavepointRescalingWithPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedStateJobGraph(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			HashKeyGroupAssigner<Integer> keyGroupAssigner = new HashKeyGroupAssigner<>(maxParallelism)___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = keyGroupAssigner.getKeyGroupIndex(key)___				expectedResult.add(Tuple2.of(keyGroupIndex % parallelism, numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedStateJobGraph(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			HashKeyGroupAssigner<Integer> keyGroupAssigner2 = new HashKeyGroupAssigner<>(maxParallelism)___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = keyGroupAssigner2.getKeyGroupIndex(key)__				expectedResult2.add(Tuple2.of(keyGroupIndex % parallelism2, key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;test,public,void,test,savepoint,rescaling,with,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,state,job,graph,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,hash,key,group,assigner,integer,key,group,assigner,new,hash,key,group,assigner,max,parallelism,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,assigner,get,key,group,index,key,expected,result,add,tuple2,of,key,group,index,parallelism,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,state,job,graph,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,hash,key,group,assigner,integer,key,group,assigner2,new,hash,key,group,assigner,max,parallelism,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,assigner2,get,key,group,index,key,expected,result2,add,tuple2,of,key,group,index,parallelism2,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartitionedState() throws Exception;1472663401;Tests that a a job with purely partitioned state can be restarted from a savepoint_with a different parallelism.;@Test_	public void testSavepointRescalingWithPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedStateJobGraph(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			HashKeyGroupAssigner<Integer> keyGroupAssigner = new HashKeyGroupAssigner<>(maxParallelism)___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = keyGroupAssigner.getKeyGroupIndex(key)___				expectedResult.add(Tuple2.of(KeyGroupRange.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedStateJobGraph(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			HashKeyGroupAssigner<Integer> keyGroupAssigner2 = new HashKeyGroupAssigner<>(maxParallelism)___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = keyGroupAssigner2.getKeyGroupIndex(key)__				expectedResult2.add(Tuple2.of(KeyGroupRange.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;test,public,void,test,savepoint,rescaling,with,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,state,job,graph,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,hash,key,group,assigner,integer,key,group,assigner,new,hash,key,group,assigner,max,parallelism,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,assigner,get,key,group,index,key,expected,result,add,tuple2,of,key,group,range,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,state,job,graph,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,hash,key,group,assigner,integer,key,group,assigner2,new,hash,key,group,assigner,max,parallelism,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,assigner2,get,key,group,index,key,expected,result2,add,tuple2,of,key,group,range,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartitionedState() throws Exception;1472663401;Tests that a a job with purely partitioned state can be restarted from a savepoint_with a different parallelism.;@Test_	public void testSavepointRescalingWithPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedStateJobGraph(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			HashKeyGroupAssigner<Integer> keyGroupAssigner = new HashKeyGroupAssigner<>(maxParallelism)___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = keyGroupAssigner.getKeyGroupIndex(key)___				expectedResult.add(Tuple2.of(KeyGroupRange.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedStateJobGraph(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			HashKeyGroupAssigner<Integer> keyGroupAssigner2 = new HashKeyGroupAssigner<>(maxParallelism)___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = keyGroupAssigner2.getKeyGroupIndex(key)__				expectedResult2.add(Tuple2.of(KeyGroupRange.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;test,public,void,test,savepoint,rescaling,with,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,state,job,graph,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,hash,key,group,assigner,integer,key,group,assigner,new,hash,key,group,assigner,max,parallelism,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,assigner,get,key,group,index,key,expected,result,add,tuple2,of,key,group,range,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,state,job,graph,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,hash,key,group,assigner,integer,key,group,assigner2,new,hash,key,group,assigner,max,parallelism,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,assigner2,get,key,group,index,key,expected,result2,add,tuple2,of,key,group,range,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartitionedState() throws Exception;1472663401;Tests that a a job with purely partitioned state can be restarted from a savepoint_with a different parallelism.;@Test_	public void testSavepointRescalingWithPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedStateJobGraph(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedStateJobGraph(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;test,public,void,test,savepoint,rescaling,with,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,state,job,graph,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,state,job,graph,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartitionedState() throws Exception;1472821521;Tests that a a job with purely partitioned state can be restarted from a savepoint_with a different parallelism.;@Test_	public void testSavepointRescalingWithPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedStateJobGraph(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedStateJobGraph(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;test,public,void,test,savepoint,rescaling,with,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,state,job,graph,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,state,job,graph,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartitionedState() throws Exception;1473347848;Tests that a a job with purely partitioned state can be restarted from a savepoint_with a different parallelism.;@Test_	public void testSavepointRescalingWithPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedStateJobGraph(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedStateJobGraph(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;test,public,void,test,savepoint,rescaling,with,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,state,job,graph,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,state,job,graph,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartitionedState() throws Exception;1474473213;Tests that a a job with purely partitioned state can be restarted from a savepoint_with a different parallelism.;@Test_	public void testSavepointRescalingWithPartitionedState() throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedStateJobGraph(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedStateJobGraph(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;test,public,void,test,savepoint,rescaling,with,partitioned,state,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,state,job,graph,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,state,job,graph,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception;1472663071;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			HashKeyGroupAssigner<Integer> keyGroupAssigner = new HashKeyGroupAssigner<>(maxParallelism)___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = keyGroupAssigner.getKeyGroupIndex(key)___				expectedResult.add(Tuple2.of(keyGroupIndex % parallelism, numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			HashKeyGroupAssigner<Integer> keyGroupAssigner2 = new HashKeyGroupAssigner<>(maxParallelism)___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = keyGroupAssigner2.getKeyGroupIndex(key)__				expectedResult2.add(Tuple2.of(keyGroupIndex % parallelism2, key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,partially,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,hash,key,group,assigner,integer,key,group,assigner,new,hash,key,group,assigner,max,parallelism,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,assigner,get,key,group,index,key,expected,result,add,tuple2,of,key,group,index,parallelism,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,hash,key,group,assigner,integer,key,group,assigner2,new,hash,key,group,assigner,max,parallelism,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,assigner2,get,key,group,index,key,expected,result2,add,tuple2,of,key,group,index,parallelism2,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception;1472663401;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			HashKeyGroupAssigner<Integer> keyGroupAssigner = new HashKeyGroupAssigner<>(maxParallelism)___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = keyGroupAssigner.getKeyGroupIndex(key)____				expectedResult.add(Tuple2.of(KeyGroupRange.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			HashKeyGroupAssigner<Integer> keyGroupAssigner2 = new HashKeyGroupAssigner<>(maxParallelism)___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = keyGroupAssigner2.getKeyGroupIndex(key)__				expectedResult2.add(Tuple2.of(KeyGroupRange.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,partially,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,hash,key,group,assigner,integer,key,group,assigner,new,hash,key,group,assigner,max,parallelism,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,assigner,get,key,group,index,key,expected,result,add,tuple2,of,key,group,range,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,hash,key,group,assigner,integer,key,group,assigner2,new,hash,key,group,assigner,max,parallelism,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,assigner2,get,key,group,index,key,expected,result2,add,tuple2,of,key,group,range,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception;1472663401;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			HashKeyGroupAssigner<Integer> keyGroupAssigner = new HashKeyGroupAssigner<>(maxParallelism)___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = keyGroupAssigner.getKeyGroupIndex(key)___				expectedResult.add(Tuple2.of(KeyGroupRange.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			HashKeyGroupAssigner<Integer> keyGroupAssigner2 = new HashKeyGroupAssigner<>(maxParallelism)___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = keyGroupAssigner2.getKeyGroupIndex(key)__				expectedResult2.add(Tuple2.of(KeyGroupRange.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,partially,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,hash,key,group,assigner,integer,key,group,assigner,new,hash,key,group,assigner,max,parallelism,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,assigner,get,key,group,index,key,expected,result,add,tuple2,of,key,group,range,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,hash,key,group,assigner,integer,key,group,assigner2,new,hash,key,group,assigner,max,parallelism,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,assigner2,get,key,group,index,key,expected,result2,add,tuple2,of,key,group,range,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception;1472663401;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,partially,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception;1472821521;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,partially,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception;1473347848;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,partially,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception;1474473213;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithPartiallyNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createPartitionedNonPartitionedStateJobGraph(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,partially,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,partitioned,non,partitioned,state,job,graph,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut) throws Exception;1475842467;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__		PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, true)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, true)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_				sumExp += c__			}__			for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_				sumAct += c__			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,true,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,true,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut) throws Exception;1476432306;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__		PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, true)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, true)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_				sumExp += c__			}__			for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_				sumAct += c__			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,true,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,true,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut) throws Exception;1476870086;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__		PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, true)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, true)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_				sumExp += c__			}__			for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_				sumAct += c__			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,true,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,true,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception;1472663071;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception {_		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createNonPartitionedStateJobGraph(parallelism, maxParallelism, 500)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Future<Object> allTasksRunning = jobManager.ask(new TestingJobManagerMessages.WaitForAllVerticesToBeRunning(jobID), deadline.timeLeft())___			Await.ready(allTasksRunning, deadline.timeLeft())___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			Object savepointResponse = Await.result(savepointPathFuture, deadline.timeLeft())___			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createNonPartitionedStateJobGraph(parallelism2, maxParallelism, 500)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof SuppressRestartsException) {_				SuppressRestartsException suppressRestartsException = (SuppressRestartsException) exception.getCause()___				if (suppressRestartsException.getCause() instanceof IllegalStateException) {_					_					_					_				} else {_					throw exception__				}_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,failure,with,non,partitioned,state,throws,exception,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,non,partitioned,state,job,graph,parallelism,max,parallelism,500,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,future,object,all,tasks,running,job,manager,ask,new,testing,job,manager,messages,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,tasks,running,deadline,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,object,savepoint,response,await,result,savepoint,path,future,deadline,time,left,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,non,partitioned,state,job,graph,parallelism2,max,parallelism,500,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,exception,get,cause,if,suppress,restarts,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception;1472663401;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception {_		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createNonPartitionedStateJobGraph(parallelism, maxParallelism, 500)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Future<Object> allTasksRunning = jobManager.ask(new TestingJobManagerMessages.WaitForAllVerticesToBeRunning(jobID), deadline.timeLeft())___			Await.ready(allTasksRunning, deadline.timeLeft())___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			Object savepointResponse = Await.result(savepointPathFuture, deadline.timeLeft())___			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createNonPartitionedStateJobGraph(parallelism2, maxParallelism, 500)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof SuppressRestartsException) {_				SuppressRestartsException suppressRestartsException = (SuppressRestartsException) exception.getCause()___				if (suppressRestartsException.getCause() instanceof IllegalStateException) {_					_					_					_				} else {_					throw exception__				}_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,failure,with,non,partitioned,state,throws,exception,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,non,partitioned,state,job,graph,parallelism,max,parallelism,500,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,future,object,all,tasks,running,job,manager,ask,new,testing,job,manager,messages,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,tasks,running,deadline,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,object,savepoint,response,await,result,savepoint,path,future,deadline,time,left,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,non,partitioned,state,job,graph,parallelism2,max,parallelism,500,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,exception,get,cause,if,suppress,restarts,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception;1472663401;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception {_		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createNonPartitionedStateJobGraph(parallelism, maxParallelism, 500)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Future<Object> allTasksRunning = jobManager.ask(new TestingJobManagerMessages.WaitForAllVerticesToBeRunning(jobID), deadline.timeLeft())___			Await.ready(allTasksRunning, deadline.timeLeft())___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			Object savepointResponse = Await.result(savepointPathFuture, deadline.timeLeft())___			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createNonPartitionedStateJobGraph(parallelism2, maxParallelism, 500)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof SuppressRestartsException) {_				SuppressRestartsException suppressRestartsException = (SuppressRestartsException) exception.getCause()___				if (suppressRestartsException.getCause() instanceof IllegalStateException) {_					_					_					_				} else {_					throw exception__				}_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,failure,with,non,partitioned,state,throws,exception,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,non,partitioned,state,job,graph,parallelism,max,parallelism,500,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,future,object,all,tasks,running,job,manager,ask,new,testing,job,manager,messages,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,tasks,running,deadline,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,object,savepoint,response,await,result,savepoint,path,future,deadline,time,left,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,non,partitioned,state,job,graph,parallelism2,max,parallelism,500,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,exception,get,cause,if,suppress,restarts,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception;1472663401;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception {_		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createNonPartitionedStateJobGraph(parallelism, maxParallelism, 500)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Future<Object> allTasksRunning = jobManager.ask(new TestingJobManagerMessages.WaitForAllVerticesToBeRunning(jobID), deadline.timeLeft())___			Await.ready(allTasksRunning, deadline.timeLeft())___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			Object savepointResponse = Await.result(savepointPathFuture, deadline.timeLeft())___			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createNonPartitionedStateJobGraph(parallelism2, maxParallelism, 500)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof SuppressRestartsException) {_				SuppressRestartsException suppressRestartsException = (SuppressRestartsException) exception.getCause()___				if (suppressRestartsException.getCause() instanceof IllegalStateException) {_					_					_					_				} else {_					throw exception__				}_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,failure,with,non,partitioned,state,throws,exception,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,non,partitioned,state,job,graph,parallelism,max,parallelism,500,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,future,object,all,tasks,running,job,manager,ask,new,testing,job,manager,messages,wait,for,all,vertices,to,be,running,job,id,deadline,time,left,await,ready,all,tasks,running,deadline,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,object,savepoint,response,await,result,savepoint,path,future,deadline,time,left,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,non,partitioned,state,job,graph,parallelism2,max,parallelism,500,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,exception,get,cause,if,suppress,restarts,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception;1472821521;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception {_		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createNonPartitionedStateJobGraph(parallelism, maxParallelism, 500)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___				savepointResponse = Await.result(savepointPathFuture, deadline.timeLeft())___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createNonPartitionedStateJobGraph(parallelism2, maxParallelism, 500)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof SuppressRestartsException) {_				SuppressRestartsException suppressRestartsException = (SuppressRestartsException) exception.getCause()___				if (suppressRestartsException.getCause() instanceof IllegalStateException) {_					_					_					_				} else {_					throw exception__				}_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,failure,with,non,partitioned,state,throws,exception,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,non,partitioned,state,job,graph,parallelism,max,parallelism,500,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,savepoint,response,await,result,savepoint,path,future,deadline,time,left,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,non,partitioned,state,job,graph,parallelism2,max,parallelism,500,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,exception,get,cause,if,suppress,restarts,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception;1473347848;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception {_		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createNonPartitionedStateJobGraph(parallelism, maxParallelism, 500)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___				savepointResponse = Await.result(savepointPathFuture, deadline.timeLeft())___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createNonPartitionedStateJobGraph(parallelism2, maxParallelism, 500)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof SuppressRestartsException) {_				SuppressRestartsException suppressRestartsException = (SuppressRestartsException) exception.getCause()___				if (suppressRestartsException.getCause() instanceof IllegalStateException) {_					_					_					_				} else {_					throw exception__				}_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,failure,with,non,partitioned,state,throws,exception,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,non,partitioned,state,job,graph,parallelism,max,parallelism,500,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,savepoint,response,await,result,savepoint,path,future,deadline,time,left,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,non,partitioned,state,job,graph,parallelism2,max,parallelism,500,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,exception,get,cause,if,suppress,restarts,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception;1474473213;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingFailureWithNonPartitionedState() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createNonPartitionedStateJobGraph(parallelism, maxParallelism, 500)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			NonPartitionedStateSource.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createNonPartitionedStateJobGraph(parallelism2, maxParallelism, 500)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof SuppressRestartsException) {_				SuppressRestartsException suppressRestartsException = (SuppressRestartsException) exception.getCause()___				if (suppressRestartsException.getCause() instanceof IllegalStateException) {_					_					_					_				} else {_					throw exception__				}_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,failure,with,non,partitioned,state,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,non,partitioned,state,job,graph,parallelism,max,parallelism,500,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,non,partitioned,state,source,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,non,partitioned,state,job,graph,parallelism2,max,parallelism,500,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,exception,get,cause,if,suppress,restarts,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1475842467;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, false)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, false)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof SuppressRestartsException) {_				SuppressRestartsException suppressRestartsException = (SuppressRestartsException) exception.getCause()___				if (suppressRestartsException.getCause() instanceof IllegalStateException) {_					_					_					_				} else {_					throw exception__				}_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,false,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,false,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,exception,get,cause,if,suppress,restarts,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1476432306;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, false)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {_				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, false)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof SuppressRestartsException) {_				SuppressRestartsException suppressRestartsException = (SuppressRestartsException) exception.getCause()___				if (suppressRestartsException.getCause() instanceof IllegalStateException) {_					_					_					_				} else {_					throw exception__				}_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,false,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,false,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,suppress,restarts,exception,exception,get,cause,if,suppress,restarts,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1476870086;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, false)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {_				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, false)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,false,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,false,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1476972861;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {_				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1477069385;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {_				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1477517188;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {_				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1477918979;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1478068461;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1479853012;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1479914009;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1484302853;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1484339359;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1484339359;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1484866642;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1485269495;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1487622556;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1492569128;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1492569209;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1495630287;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1499156246;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1499314317;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1499789965;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1499899067;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1503598628;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1509404699;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1509404700;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1516295283;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1519039304;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1519568061;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__			FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__			savepointResponse = Await.result(savepointPathFuture, waitingTime)___			assertTrue(String.valueOf(savepointResponse), savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,assert,true,string,value,of,savepoint,response,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1521828709;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {_			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			StateSourceBase.workStartedLatch.await()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			_			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())__		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,state,source,base,work,started,latch,await,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1522217463;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {_			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			StateSourceBase.workStartedLatch.await()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			_			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())__		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,state,source,base,work,started,latch,await,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1529682304;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {_			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			StateSourceBase.workStartedLatch.await()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			_			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())__		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,state,source,base,work,started,latch,await,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1529682304;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {_			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			StateSourceBase.workStartedLatch.await()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			_			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())__		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,state,source,base,work,started,latch,await,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception
RescalingITCase -> @Test 	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception;1540389860;Tests that a job cannot be restarted from a savepoint with a different parallelism if the_rescaled operator has non-partitioned state.__@throws Exception;@Test_	public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {_		final int parallelism = numSlots / 2__		final int parallelism2 = numSlots__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {_			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			StateSourceBase.workStartedLatch.await()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			_			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())__		} catch (JobExecutionException exception) {_			if (exception.getCause() instanceof IllegalStateException) {_				_				_				_			} else {_				throw exception__			}_		}_	};tests,that,a,job,cannot,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,rescaled,operator,has,non,partitioned,state,throws,exception;test,public,void,test,savepoint,rescaling,non,partitioned,state,causes,exception,throws,exception,final,int,parallelism,num,slots,2,final,int,parallelism2,num,slots,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,operator,checkpoint,method,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,state,source,base,work,started,latch,await,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,operator,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,catch,job,execution,exception,exception,if,exception,get,cause,instanceof,illegal,state,exception,else,throw,exception
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1475842467;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1476432306;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1476870086;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1476972861;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1477069385;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1477517188;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1477918979;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1478068461;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1479853012;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1479914009;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1484302853;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1484339359;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1484339359;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception;1484866642;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, maxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1476972861;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1477069385;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1477517188;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1477918979;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1478068461;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1479853012;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1479914009;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1484302853;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if(checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1484339359;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1484339359;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1484866642;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1485269495;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1487622556;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1492569128;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1492569209;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1495630287;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1499156246;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1499314317;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1499789965;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSource.CHECK_CORRECT_RESTORE = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT = new int[counterSize]__			PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_SNAPSHOT) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.CHECK_CORRECT_RESTORE) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,new,int,counter,size,partitioned,state,source,new,int,counter,size,else,partitioned,state,source,list,checkpointed,new,int,counter,size,partitioned,state,source,list,checkpointed,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,sum,exp,c,for,int,c,partitioned,state,source,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1499899067;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSource.checkCorrectRestore = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,check,correct,snapshot,new,int,counter,size,partitioned,state,source,check,correct,restore,new,int,counter,size,else,partitioned,state,source,list,checkpointed,check,correct,snapshot,new,int,counter,size,partitioned,state,source,list,checkpointed,check,correct,restore,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,check,correct,restore,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1503598628;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSource.checkCorrectRestore = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,check,correct,snapshot,new,int,counter,size,partitioned,state,source,check,correct,restore,new,int,counter,size,else,partitioned,state,source,list,checkpointed,check,correct,snapshot,new,int,counter,size,partitioned,state,source,list,checkpointed,check,correct,restore,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,check,correct,restore,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1509404699;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSource.checkCorrectRestore = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,check,correct,snapshot,new,int,counter,size,partitioned,state,source,check,correct,restore,new,int,counter,size,else,partitioned,state,source,list,checkpointed,check,correct,snapshot,new,int,counter,size,partitioned,state,source,list,checkpointed,check,correct,restore,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,check,correct,restore,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1509404700;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSource.checkCorrectRestore = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,check,correct,snapshot,new,int,counter,size,partitioned,state,source,check,correct,restore,new,int,counter,size,else,partitioned,state,source,list,checkpointed,check,correct,snapshot,new,int,counter,size,partitioned,state,source,list,checkpointed,check,correct,restore,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,check,correct,restore,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1516295283;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSource.checkCorrectRestore = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,check,correct,snapshot,new,int,counter,size,partitioned,state,source,check,correct,restore,new,int,counter,size,else,partitioned,state,source,list,checkpointed,check,correct,snapshot,new,int,counter,size,partitioned,state,source,list,checkpointed,check,correct,restore,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,check,correct,restore,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1519039304;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSource.checkCorrectRestore = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_				System.out.println(savepointResponse)__			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,check,correct,snapshot,new,int,counter,size,partitioned,state,source,check,correct,restore,new,int,counter,size,else,partitioned,state,source,list,checkpointed,check,correct,snapshot,new,int,counter,size,partitioned,state,source,list,checkpointed,check,correct,restore,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,system,out,println,savepoint,response,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,check,correct,restore,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1519568061;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		JobID jobID = null__		ActorGateway jobManager = null___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSource.checkCorrectRestore = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize]__		}__		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			Object savepointResponse = null___			_			StateSourceBase.workStartedLatch.await()___			while (deadline.hasTimeLeft()) {__				Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())__				FiniteDuration waitingTime = new FiniteDuration(10, TimeUnit.SECONDS)__				savepointResponse = Await.result(savepointPathFuture, waitingTime)___				if (savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess) {_					break__				}_			}__			assertTrue(savepointResponse instanceof JobManagerMessages.TriggerSavepointSuccess)___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess) savepointResponse).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			_			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__			jobID = null___		} finally {_			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,job,id,job,id,null,actor,gateway,job,manager,null,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,check,correct,snapshot,new,int,counter,size,partitioned,state,source,check,correct,restore,new,int,counter,size,else,partitioned,state,source,list,checkpointed,check,correct,snapshot,new,int,counter,size,partitioned,state,source,list,checkpointed,check,correct,restore,new,int,counter,size,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,object,savepoint,response,null,state,source,base,work,started,latch,await,while,deadline,has,time,left,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,finite,duration,waiting,time,new,finite,duration,10,time,unit,seconds,savepoint,response,await,result,savepoint,path,future,waiting,time,if,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,break,assert,true,savepoint,response,instanceof,job,manager,messages,trigger,savepoint,success,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,savepoint,response,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,check,correct,restore,sum,act,c,assert,equals,sum,exp,sum,act,job,id,null,finally,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1521828709;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSource.checkCorrectRestore = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize]__		}__		try {_			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			StateSourceBase.workStartedLatch.await()___			CompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(_				() -> {_					try {_						return client.triggerSavepoint(jobID, null)__					} catch (FlinkException e) {_						return FutureUtils.completedExceptionally(e)__					}_				},_				(int) deadline.timeLeft().getSeconds() / 10,_				Time.seconds(10),_				(throwable) -> true,_				TestingUtils.defaultScheduledExecutor()_			)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__		} finally {_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,check,correct,snapshot,new,int,counter,size,partitioned,state,source,check,correct,restore,new,int,counter,size,else,partitioned,state,source,list,checkpointed,check,correct,snapshot,new,int,counter,size,partitioned,state,source,list,checkpointed,check,correct,restore,new,int,counter,size,try,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,state,source,base,work,started,latch,await,completable,future,string,savepoint,path,future,future,utils,retry,with,delay,try,return,client,trigger,savepoint,job,id,null,catch,flink,exception,e,return,future,utils,completed,exceptionally,e,int,deadline,time,left,get,seconds,10,time,seconds,10,throwable,true,testing,utils,default,scheduled,executor,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,check,correct,restore,sum,act,c,assert,equals,sum,exp,sum,act,finally
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1522217463;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSource.checkCorrectRestore = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize]__		}__		try {_			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			StateSourceBase.workStartedLatch.await()___			CompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(_				() -> {_					try {_						return client.triggerSavepoint(jobID, null)__					} catch (FlinkException e) {_						return FutureUtils.completedExceptionally(e)__					}_				},_				(int) deadline.timeLeft().getSeconds() / 10,_				Time.seconds(10),_				(throwable) -> true,_				TestingUtils.defaultScheduledExecutor()_			)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__		} finally {_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,check,correct,snapshot,new,int,counter,size,partitioned,state,source,check,correct,restore,new,int,counter,size,else,partitioned,state,source,list,checkpointed,check,correct,snapshot,new,int,counter,size,partitioned,state,source,list,checkpointed,check,correct,restore,new,int,counter,size,try,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,state,source,base,work,started,latch,await,completable,future,string,savepoint,path,future,future,utils,retry,with,delay,try,return,client,trigger,savepoint,job,id,null,catch,flink,exception,e,return,future,utils,completed,exceptionally,e,int,deadline,time,left,get,seconds,10,time,seconds,10,throwable,true,testing,utils,default,scheduled,executor,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,check,correct,restore,sum,act,c,assert,equals,sum,exp,sum,act,finally
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1529682304;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSource.checkCorrectRestore = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize]__		}__		try {_			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			StateSourceBase.workStartedLatch.await()___			CompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(_				() -> {_					try {_						return client.triggerSavepoint(jobID, null)__					} catch (FlinkException e) {_						return FutureUtils.completedExceptionally(e)__					}_				},_				(int) deadline.timeLeft().getSeconds() / 10,_				Time.seconds(10),_				(throwable) -> true,_				TestingUtils.defaultScheduledExecutor()_			)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__		} finally {_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,check,correct,snapshot,new,int,counter,size,partitioned,state,source,check,correct,restore,new,int,counter,size,else,partitioned,state,source,list,checkpointed,check,correct,snapshot,new,int,counter,size,partitioned,state,source,list,checkpointed,check,correct,restore,new,int,counter,size,try,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,state,source,base,work,started,latch,await,completable,future,string,savepoint,path,future,future,utils,retry,with,delay,try,return,client,trigger,savepoint,job,id,null,catch,flink,exception,e,return,future,utils,completed,exceptionally,e,int,deadline,time,left,get,seconds,10,time,seconds,10,throwable,true,testing,utils,default,scheduled,executor,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,check,correct,restore,sum,act,c,assert,equals,sum,exp,sum,act,finally
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1529682304;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSource.checkCorrectRestore = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize]__		}__		try {_			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			StateSourceBase.workStartedLatch.await()___			CompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(_				() -> {_					try {_						return client.triggerSavepoint(jobID, null)__					} catch (FlinkException e) {_						return FutureUtils.completedExceptionally(e)__					}_				},_				(int) deadline.timeLeft().getSeconds() / 10,_				Time.seconds(10),_				(throwable) -> true,_				TestingUtils.defaultScheduledExecutor()_			)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__		} finally {_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,check,correct,snapshot,new,int,counter,size,partitioned,state,source,check,correct,restore,new,int,counter,size,else,partitioned,state,source,list,checkpointed,check,correct,snapshot,new,int,counter,size,partitioned,state,source,list,checkpointed,check,correct,restore,new,int,counter,size,try,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,state,source,base,work,started,latch,await,completable,future,string,savepoint,path,future,future,utils,retry,with,delay,try,return,client,trigger,savepoint,job,id,null,catch,flink,exception,e,return,future,utils,completed,exceptionally,e,int,deadline,time,left,get,seconds,10,time,seconds,10,throwable,true,testing,utils,default,scheduled,executor,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,check,correct,restore,sum,act,c,assert,equals,sum,exp,sum,act,finally
RescalingITCase -> public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception;1540389860;Tests rescaling of partitioned operator state. More specific, we test the mechanism with {@link ListCheckpointed}_as it subsumes {@link org.apache.flink.streaming.api.checkpoint.CheckpointedFunction}.;public void testSavepointRescalingPartitionedOperatorState(boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {_		final int parallelism = scaleOut ? numSlots : numSlots / 2__		final int parallelism2 = scaleOut ? numSlots / 2 : numSlots__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		int counterSize = Math.max(parallelism, parallelism2)___		if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION ||_				checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_			PartitionedStateSource.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSource.checkCorrectRestore = new int[counterSize]__		} else {_			PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize]__			PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize]__		}__		try {_			JobGraph jobGraph = createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			StateSourceBase.workStartedLatch.await()___			CompletableFuture<String> savepointPathFuture = FutureUtils.retryWithDelay(_				() -> {_					try {_						return client.triggerSavepoint(jobID, null)__					} catch (FlinkException e) {_						return FutureUtils.completedExceptionally(e)__					}_				},_				(int) deadline.timeLeft().getSeconds() / 10,_				Time.seconds(10),_				(throwable) -> true,_				TestingUtils.defaultScheduledExecutor()_			)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			JobGraph scaledJobGraph = createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			int sumExp = 0__			int sumAct = 0___			if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}_			} else if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {_				for (int c : PartitionedStateSource.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSource.checkCorrectRestore) {_					sumAct += c__				}__				sumExp *= parallelism2__			} else {_				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {_					sumExp += c__				}__				for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {_					sumAct += c__				}_			}__			assertEquals(sumExp, sumAct)__		} finally {_		}_	};tests,rescaling,of,partitioned,operator,state,more,specific,we,test,the,mechanism,with,link,list,checkpointed,as,it,subsumes,link,org,apache,flink,streaming,api,checkpoint,checkpointed,function;public,void,test,savepoint,rescaling,partitioned,operator,state,boolean,scale,out,operator,checkpoint,method,checkpoint,method,throws,exception,final,int,parallelism,scale,out,num,slots,num,slots,2,final,int,parallelism2,scale,out,num,slots,2,num,slots,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,int,counter,size,math,max,parallelism,parallelism2,if,checkpoint,method,operator,checkpoint,method,checkpoint,method,operator,checkpoint,method,partitioned,state,source,check,correct,snapshot,new,int,counter,size,partitioned,state,source,check,correct,restore,new,int,counter,size,else,partitioned,state,source,list,checkpointed,check,correct,snapshot,new,int,counter,size,partitioned,state,source,list,checkpointed,check,correct,restore,new,int,counter,size,try,job,graph,job,graph,create,job,graph,with,operator,state,parallelism,max,parallelism,checkpoint,method,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,state,source,base,work,started,latch,await,completable,future,string,savepoint,path,future,future,utils,retry,with,delay,try,return,client,trigger,savepoint,job,id,null,catch,flink,exception,e,return,future,utils,completed,exceptionally,e,int,deadline,time,left,get,seconds,10,time,seconds,10,throwable,true,testing,utils,default,scheduled,executor,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,operator,state,parallelism2,max,parallelism,checkpoint,method,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,int,sum,exp,0,int,sum,act,0,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,else,if,checkpoint,method,operator,checkpoint,method,for,int,c,partitioned,state,source,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,check,correct,restore,sum,act,c,sum,exp,parallelism2,else,for,int,c,partitioned,state,source,list,checkpointed,check,correct,snapshot,sum,exp,c,for,int,c,partitioned,state,source,list,checkpointed,check,correct,restore,sum,act,c,assert,equals,sum,exp,sum,act,finally
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1475842467;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1476432306;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1476870086;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1476972861;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1477069385;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1477517188;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1477918979;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointPath(savepointPath)___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1478068461;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1479853012;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1479914009;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1484302853;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			 jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements,_				false,_				100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex) , numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_				Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_				parallelism2,_				maxParallelism,_				parallelism,_				numberKeys,_				numberElements + numberElements2,_				true,_				100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1484339359;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1484339359;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1484866642;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1485269495;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1487622556;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1492569128;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1492569209;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1495630287;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1499156246;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1499314317;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1499789965;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1499899067;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1503598628;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1509404699;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1509404700;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1516295283;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1519039304;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1519568061;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1521828709;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {__			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()__		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1522217463;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {__			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()__		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1529682304;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {__			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()__		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1529682304;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {__			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()__		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set
RescalingITCase -> @Test 	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception;1540389860;Tests that a job with non partitioned state can be restarted from a savepoint with a_different parallelism if the operator with non-partitioned state are not rescaled.__@throws Exception;@Test_	public void testSavepointRescalingWithKeyedAndNonPartitionedState() throws Exception {_		int numberKeys = 42__		int numberElements = 1000__		int numberElements2 = 500__		int parallelism = numSlots / 2__		int parallelism2 = numSlots__		int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {__			JobGraph jobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements,_					false,_					100)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			JobGraph scaledJobGraph = createJobGraphWithKeyedAndNonPartitionedOperatorState(_					parallelism2,_					maxParallelism,_					parallelism,_					numberKeys,_					numberElements + numberElements2,_					true,_					100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()__		}_	};tests,that,a,job,with,non,partitioned,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism,if,the,operator,with,non,partitioned,state,are,not,rescaled,throws,exception;test,public,void,test,savepoint,rescaling,with,keyed,and,non,partitioned,state,throws,exception,int,number,keys,42,int,number,elements,1000,int,number,elements2,500,int,parallelism,num,slots,2,int,parallelism2,num,slots,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism,max,parallelism,parallelism,number,keys,number,elements,false,100,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,job,graph,scaled,job,graph,create,job,graph,with,keyed,and,non,partitioned,operator,state,parallelism2,max,parallelism,parallelism,number,keys,number,elements,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1485269495;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1487622556;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1492569128;Tests that a a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1492569209;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1495630287;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1499156246;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1499314317;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1499789965;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)____		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1499899067;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1503598628;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1509404699;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1509404700;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1516295283;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1519039304;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1519568061;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		FiniteDuration timeout = new FiniteDuration(3, TimeUnit.MINUTES)__		Deadline deadline = timeout.fromNow()___		ActorGateway jobManager = null__		JobID jobID = null___		try {_			jobManager = cluster.getLeaderGateway(deadline.timeLeft())___			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			jobID = jobGraph.getJobID()___			cluster.submitJobDetached(jobGraph)___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			Future<Object> savepointPathFuture = jobManager.ask(new JobManagerMessages.TriggerSavepoint(jobID, Option.<String>empty()), deadline.timeLeft())___			final String savepointPath = ((JobManagerMessages.TriggerSavepointSuccess)_					Await.result(savepointPathFuture, deadline.timeLeft())).savepointPath()___			Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), deadline.timeLeft())___			Future<Object> cancellationResponseFuture = jobManager.ask(new JobManagerMessages.CancelJob(jobID), deadline.timeLeft())___			Object cancellationResponse = Await.result(cancellationResponseFuture, deadline.timeLeft())___			assertTrue(cancellationResponse instanceof JobManagerMessages.CancellationSuccess)___			Await.ready(jobRemovedFuture, deadline.timeLeft())___			jobID = null___			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			jobID = scaledJobGraph.getJobID()___			cluster.submitJobAndWait(scaledJobGraph, false)___			jobID = null___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()___			_			if (jobID != null && jobManager != null) {_				Future<Object> jobRemovedFuture = jobManager.ask(new TestingJobManagerMessages.NotifyWhenJobRemoved(jobID), timeout)___				try {_					Await.ready(jobRemovedFuture, timeout)__				} catch (TimeoutException | InterruptedException ie) {_					fail("Failed while cleaning up the cluster.")__				}_			}_		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,finite,duration,timeout,new,finite,duration,3,time,unit,minutes,deadline,deadline,timeout,from,now,actor,gateway,job,manager,null,job,id,job,id,null,try,job,manager,cluster,get,leader,gateway,deadline,time,left,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,job,id,job,graph,get,job,id,cluster,submit,job,detached,job,graph,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,future,object,savepoint,path,future,job,manager,ask,new,job,manager,messages,trigger,savepoint,job,id,option,string,empty,deadline,time,left,final,string,savepoint,path,job,manager,messages,trigger,savepoint,success,await,result,savepoint,path,future,deadline,time,left,savepoint,path,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,deadline,time,left,future,object,cancellation,response,future,job,manager,ask,new,job,manager,messages,cancel,job,job,id,deadline,time,left,object,cancellation,response,await,result,cancellation,response,future,deadline,time,left,assert,true,cancellation,response,instanceof,job,manager,messages,cancellation,success,await,ready,job,removed,future,deadline,time,left,job,id,null,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,job,id,scaled,job,graph,get,job,id,cluster,submit,job,and,wait,scaled,job,graph,false,job,id,null,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set,if,job,id,null,job,manager,null,future,object,job,removed,future,job,manager,ask,new,testing,job,manager,messages,notify,when,job,removed,job,id,timeout,try,await,ready,job,removed,future,timeout,catch,timeout,exception,interrupted,exception,ie,fail,failed,while,cleaning,up,the,cluster
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1521828709;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {_			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()__		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1522217463;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {_			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()__		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1529682304;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {_			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()__		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1529682304;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {_			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()__		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set
RescalingITCase -> public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception;1540389860;Tests that a job with purely keyed state can be restarted from a savepoint_with a different parallelism.;public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism) throws Exception {_		final int numberKeys = 42__		final int numberElements = 1000__		final int numberElements2 = 500__		final int parallelism = scaleOut ? numSlots / 2 : numSlots__		final int parallelism2 = scaleOut ? numSlots : numSlots / 2__		final int maxParallelism = 13___		Duration timeout = Duration.ofMinutes(3)__		Deadline deadline = Deadline.now().plus(timeout)___		ClusterClient<?> client = cluster.getClusterClient()___		try {_			JobGraph jobGraph = createJobGraphWithKeyedState(parallelism, maxParallelism, numberKeys, numberElements, false, 100)___			final JobID jobID = jobGraph.getJobID()___			client.setDetached(true)__			client.submitJob(jobGraph, RescalingITCase.class.getClassLoader())___			_			SubtaskIndexFlatMapper.workCompletedLatch.await(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			__			Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)___				expectedResult.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism, keyGroupIndex), numberElements * key))__			}__			assertEquals(expectedResult, actualResult)___			_			CollectionSink.clearElementsSet()___			CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null)___			final String savepointPath = savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)___			client.cancel(jobID)___			while (!getRunningJobs(client).isEmpty()) {_				Thread.sleep(50)__			}__			int restoreMaxParallelism = deriveMaxParallelism ? ExecutionJobVertex.VALUE_NOT_SET : maxParallelism___			JobGraph scaledJobGraph = createJobGraphWithKeyedState(parallelism2, restoreMaxParallelism, numberKeys, numberElements2, true, 100)___			scaledJobGraph.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath))___			client.setDetached(false)__			client.submitJob(scaledJobGraph, RescalingITCase.class.getClassLoader())___			Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet()___			Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>()___			for (int key = 0_ key < numberKeys_ key++) {_				int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism)__				expectedResult2.add(Tuple2.of(KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(maxParallelism, parallelism2, keyGroupIndex), key * (numberElements + numberElements2)))__			}__			assertEquals(expectedResult2, actualResult2)___		} finally {_			_			CollectionSink.clearElementsSet()__		}_	};tests,that,a,job,with,purely,keyed,state,can,be,restarted,from,a,savepoint,with,a,different,parallelism;public,void,test,savepoint,rescaling,keyed,state,boolean,scale,out,boolean,derive,max,parallelism,throws,exception,final,int,number,keys,42,final,int,number,elements,1000,final,int,number,elements2,500,final,int,parallelism,scale,out,num,slots,2,num,slots,final,int,parallelism2,scale,out,num,slots,num,slots,2,final,int,max,parallelism,13,duration,timeout,duration,of,minutes,3,deadline,deadline,deadline,now,plus,timeout,cluster,client,client,cluster,get,cluster,client,try,job,graph,job,graph,create,job,graph,with,keyed,state,parallelism,max,parallelism,number,keys,number,elements,false,100,final,job,id,job,id,job,graph,get,job,id,client,set,detached,true,client,submit,job,job,graph,rescaling,itcase,class,get,class,loader,subtask,index,flat,mapper,work,completed,latch,await,deadline,time,left,to,millis,time,unit,milliseconds,set,tuple2,integer,integer,actual,result,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism,key,group,index,number,elements,key,assert,equals,expected,result,actual,result,collection,sink,clear,elements,set,completable,future,string,savepoint,path,future,client,trigger,savepoint,job,id,null,final,string,savepoint,path,savepoint,path,future,get,deadline,time,left,to,millis,time,unit,milliseconds,client,cancel,job,id,while,get,running,jobs,client,is,empty,thread,sleep,50,int,restore,max,parallelism,derive,max,parallelism,execution,job,vertex,max,parallelism,job,graph,scaled,job,graph,create,job,graph,with,keyed,state,parallelism2,restore,max,parallelism,number,keys,number,elements2,true,100,scaled,job,graph,set,savepoint,restore,settings,savepoint,restore,settings,for,path,savepoint,path,client,set,detached,false,client,submit,job,scaled,job,graph,rescaling,itcase,class,get,class,loader,set,tuple2,integer,integer,actual,result2,collection,sink,get,elements,set,set,tuple2,integer,integer,expected,result2,new,hash,set,for,int,key,0,key,number,keys,key,int,key,group,index,key,group,range,assignment,assign,to,key,group,key,max,parallelism,expected,result2,add,tuple2,of,key,group,range,assignment,compute,operator,index,for,key,group,max,parallelism,parallelism2,key,group,index,key,number,elements,number,elements2,assert,equals,expected,result2,actual,result2,finally,collection,sink,clear,elements,set
