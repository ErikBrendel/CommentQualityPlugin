commented;modifiers;parameterAmount;loc;comment;code
false;public,static;0;4;;@BeforeClass public static void beforeClass() {     SavepointSerializers.setFailWhenLegacyStateDetected(false). }
false;public;0;12;;@Test public void testMigrationAndRestore() throws Throwable {     ClassLoader classLoader = this.getClass().getClassLoader().     ClusterClient<?> clusterClient = MINI_CLUSTER_RESOURCE.getClusterClient().     clusterClient.setDetached(true).     final Deadline deadline = Deadline.now().plus(TEST_TIMEOUT).     // submit job with old version savepoint and create a migrated savepoint in the new version     String savepointPath = migrateJob(classLoader, clusterClient, deadline).     // restore from migrated new version savepoint     restoreJob(classLoader, clusterClient, deadline, savepointPath). }
false;private;3;59;;private String migrateJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline) throws Throwable {     URL savepointResource = AbstractOperatorRestoreTestBase.class.getClassLoader().getResource("operatorstate/" + getMigrationSavepointName()).     if (savepointResource == null) {         throw new IllegalArgumentException("Savepoint file does not exist.").     }     JobGraph jobToMigrate = createJobGraph(ExecutionMode.MIGRATE).     jobToMigrate.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointResource.getFile())).     assertNotNull(jobToMigrate.getJobID()).     clusterClient.submitJob(jobToMigrate, classLoader).     CompletableFuture<JobStatus> jobRunningFuture = FutureUtils.retrySuccessfulWithDelay(() -> clusterClient.getJobStatus(jobToMigrate.getJobID()), Time.milliseconds(50), deadline, (jobStatus) -> jobStatus == JobStatus.RUNNING, TestingUtils.defaultScheduledExecutor()).     assertEquals(JobStatus.RUNNING, jobRunningFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)).     // Trigger savepoint     File targetDirectory = tmpFolder.newFolder().     String savepointPath = null.     // TODO: The retry logic should be removed once the StreamTask lifecycle has been fixed (see FLINK-4714)     while (deadline.hasTimeLeft() && savepointPath == null) {         try {             savepointPath = clusterClient.cancelWithSavepoint(jobToMigrate.getJobID(), targetDirectory.getAbsolutePath()).         } catch (Exception e) {             String exceptionString = ExceptionUtils.stringifyException(e).             if (!(// legacy             exceptionString.matches("(.*\n)*.*savepoint for the job .* failed(.*\n)*") || exceptionString.matches("(.*\n)*.*was not running(.*\n)*") || // new             exceptionString.matches("(.*\n)*.*Not all required tasks are currently running(.*\n)*") || exceptionString.matches("(.*\n)*.*Checkpoint was declined \\(tasks not ready\\)(.*\n)*"))) {                 // new                 throw e.             }         }     }     assertNotNull("Could not take savepoint.", savepointPath).     CompletableFuture<JobStatus> jobCanceledFuture = FutureUtils.retrySuccessfulWithDelay(() -> clusterClient.getJobStatus(jobToMigrate.getJobID()), Time.milliseconds(50), deadline, (jobStatus) -> jobStatus == JobStatus.CANCELED, TestingUtils.defaultScheduledExecutor()).     assertEquals(JobStatus.CANCELED, jobCanceledFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)).     return savepointPath. }
false;private;4;18;;private void restoreJob(ClassLoader classLoader, ClusterClient<?> clusterClient, Deadline deadline, String savepointPath) throws Exception {     JobGraph jobToRestore = createJobGraph(ExecutionMode.RESTORE).     jobToRestore.setSavepointRestoreSettings(SavepointRestoreSettings.forPath(savepointPath, allowNonRestoredState)).     assertNotNull("Job doesn't have a JobID.", jobToRestore.getJobID()).     clusterClient.submitJob(jobToRestore, classLoader).     CompletableFuture<JobStatus> jobStatusFuture = FutureUtils.retrySuccessfulWithDelay(() -> clusterClient.getJobStatus(jobToRestore.getJobID()), Time.milliseconds(50), deadline, (jobStatus) -> jobStatus == JobStatus.FINISHED, TestingUtils.defaultScheduledExecutor()).     assertEquals(JobStatus.FINISHED, jobStatusFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS)). }
false;private;1;17;;private JobGraph createJobGraph(ExecutionMode mode) {     StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment().     env.enableCheckpointing(500, CheckpointingMode.EXACTLY_ONCE).     env.setRestartStrategy(RestartStrategies.noRestart()).     env.setStateBackend((StateBackend) new MemoryStateBackend()).     switch(mode) {         case MIGRATE:             createMigrationJob(env).             break.         case RESTORE:             createRestoredJob(env).             break.     }     return StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph()). }
true;protected,abstract;1;1;/**  * Recreates the job used to create the new version savepoint.  *  * @param env StreamExecutionEnvironment to use  */ ;/**  * Recreates the job used to create the new version savepoint.  *  * @param env StreamExecutionEnvironment to use  */ protected abstract void createMigrationJob(StreamExecutionEnvironment env).
true;protected,abstract;1;1;/**  * Creates a modified version of the job used to create the new version savepoint.  *  * @param env StreamExecutionEnvironment to use  */ ;/**  * Creates a modified version of the job used to create the new version savepoint.  *  * @param env StreamExecutionEnvironment to use  */ protected abstract void createRestoredJob(StreamExecutionEnvironment env).
true;protected,abstract;0;1;/**  * Returns the name of the savepoint directory to use, relative to "resources/operatorstate".  *  * @return savepoint directory to use  */ ;/**  * Returns the name of the savepoint directory to use, relative to "resources/operatorstate".  *  * @return savepoint directory to use  */ protected abstract String getMigrationSavepointName().
