commented;modifiers;parameterAmount;loc;comment;code
true;public;1;3;/**  * Sets the flag whether to reuse the Avro value instance for all records.  * By default, the input format reuses the Avro value.  *  * @param reuseAvroValue True, if the input format should reuse the Avro value instance, false otherwise.  */ ;/**  * Sets the flag whether to reuse the Avro value instance for all records.  * By default, the input format reuses the Avro value.  *  * @param reuseAvroValue True, if the input format should reuse the Avro value instance, false otherwise.  */ public void setReuseAvroValue(boolean reuseAvroValue) {     this.reuseAvroValue = reuseAvroValue. }
true;public;1;3;/**  * If set, the InputFormat will only read entire files.  */ ;/**  * If set, the InputFormat will only read entire files.  */ public void setUnsplittable(boolean unsplittable) {     this.unsplittable = unsplittable. }
false;public;0;4;;// -------------------------------------------------------------------------------------------- // Typing // -------------------------------------------------------------------------------------------- @Override public TypeInformation<E> getProducedType() {     return TypeExtractor.getForClass(this.avroValueType). }
false;public;1;7;;// -------------------------------------------------------------------------------------------- // Input Format Methods // -------------------------------------------------------------------------------------------- @Override public void open(FileInputSplit split) throws IOException {     super.open(split).     dataFileReader = initReader(split).     dataFileReader.sync(split.getStart()).     lastSync = dataFileReader.previousSync(). }
false;private;1;24;;private DataFileReader<E> initReader(FileInputSplit split) throws IOException {     DatumReader<E> datumReader.     if (org.apache.avro.generic.GenericRecord.class == avroValueType) {         datumReader = new GenericDatumReader<E>().     } else {         datumReader = org.apache.avro.specific.SpecificRecordBase.class.isAssignableFrom(avroValueType) ? new SpecificDatumReader<E>(avroValueType) : new ReflectDatumReader<E>(avroValueType).     }     if (LOG.isInfoEnabled()) {         LOG.info("Opening split {}", split).     }     SeekableInput in = new FSDataInputStreamWrapper(stream, split.getPath().getFileSystem().getFileStatus(split.getPath()).getLen()).     DataFileReader<E> dataFileReader = (DataFileReader) DataFileReader.openReader(in, datumReader).     if (LOG.isDebugEnabled()) {         LOG.debug("Loaded SCHEMA: {}", dataFileReader.getSchema()).     }     end = split.getStart() + split.getLength().     recordsReadSinceLastSync = 0.     return dataFileReader. }
false;public;0;4;;@Override public boolean reachedEnd() throws IOException {     return !dataFileReader.hasNext() || dataFileReader.pastSync(end). }
false;public;0;3;;public long getRecordsReadFromBlock() {     return this.recordsReadSinceLastSync. }
false;public;1;24;;@Override public E nextRecord(E reuseValue) throws IOException {     if (reachedEnd()) {         return null.     }     // restart the counter.     if (dataFileReader.previousSync() != lastSync) {         lastSync = dataFileReader.previousSync().         recordsReadSinceLastSync = 0.     }     recordsReadSinceLastSync++.     if (reuseAvroValue) {         return dataFileReader.next(reuseValue).     } else {         if (GenericRecord.class == avroValueType) {             return dataFileReader.next().         } else {             return dataFileReader.next(InstantiationUtil.instantiate(avroValueType, Object.class)).         }     } }
false;public;0;4;;@Override public boolean supportsMultiPaths() {     return true. }
false;public;0;4;;// -------------------------------------------------------------------------------------------- // Checkpointing // -------------------------------------------------------------------------------------------- @Override public Tuple2<Long, Long> getCurrentState() throws IOException {     return new Tuple2<>(this.lastSync, this.recordsReadSinceLastSync). }
false;public;2;23;;@Override public void reopen(FileInputSplit split, Tuple2<Long, Long> state) throws IOException {     Preconditions.checkNotNull(split, "reopen() cannot be called on a null split.").     Preconditions.checkNotNull(state, "reopen() cannot be called with a null initial state.").     try {         this.open(split).     } finally {         if (state.f0 != -1) {             lastSync = state.f0.             recordsReadSinceLastSync = state.f1.         }     }     if (lastSync != -1) {         // open and read until the record we were before         // the checkpoint and discard the values         dataFileReader.seek(lastSync).         for (int i = 0. i < recordsReadSinceLastSync. i++) {             dataFileReader.next(null).         }     } }
