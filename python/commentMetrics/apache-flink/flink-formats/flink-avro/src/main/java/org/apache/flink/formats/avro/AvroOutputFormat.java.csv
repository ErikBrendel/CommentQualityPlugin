commented;modifiers;parameterAmount;loc;comment;code
false;private;0;3;;private byte getCodecByte() {     return codecByte. }
false;private;0;3;;private CodecFactory getCodecFactory() {     return codecFactory. }
false;private,static;1;8;;private static Codec forCodecByte(byte codecByte) {     for (final Codec codec : Codec.values()) {         if (codec.getCodecByte() == codecByte) {             return codec.         }     }     throw new IllegalArgumentException("no codec for codecByte: " + codecByte). }
false;protected;1;4;;@Override protected String getDirectoryFileName(int taskNumber) {     return super.getDirectoryFileName(taskNumber) + ".avro". }
false;public;1;3;;public void setSchema(Schema schema) {     this.userDefinedSchema = schema. }
true;public;1;3;/**  * Set avro codec for compression.  *  * @param codec avro codec.  */ ;/**  * Set avro codec for compression.  *  * @param codec avro codec.  */ public void setCodec(final Codec codec) {     this.codec = checkNotNull(codec, "codec can not be null"). }
false;public;1;4;;@Override public void writeRecord(E record) throws IOException {     dataFileWriter.append(record). }
false;public;2;33;;@Override public void open(int taskNumber, int numTasks) throws IOException {     super.open(taskNumber, numTasks).     DatumWriter<E> datumWriter.     Schema schema.     if (org.apache.avro.specific.SpecificRecordBase.class.isAssignableFrom(avroValueType)) {         datumWriter = new SpecificDatumWriter<E>(avroValueType).         try {             schema = ((org.apache.avro.specific.SpecificRecordBase) avroValueType.newInstance()).getSchema().         } catch (InstantiationException | IllegalAccessException e) {             throw new RuntimeException(e.getMessage()).         }     } else if (org.apache.avro.generic.GenericRecord.class.isAssignableFrom(avroValueType)) {         if (userDefinedSchema == null) {             throw new IllegalStateException("Schema must be set when using Generic Record").         }         datumWriter = new GenericDatumWriter<E>(userDefinedSchema).         schema = userDefinedSchema.     } else {         datumWriter = new ReflectDatumWriter<E>(avroValueType).         schema = ReflectData.get().getSchema(avroValueType).     }     dataFileWriter = new DataFileWriter<E>(datumWriter).     if (codec != null) {         dataFileWriter.setCodec(codec.getCodecFactory()).     }     if (userDefinedSchema == null) {         dataFileWriter.create(schema, stream).     } else {         dataFileWriter.create(userDefinedSchema, stream).     } }
false;private;1;17;;private void writeObject(java.io.ObjectOutputStream out) throws IOException {     out.defaultWriteObject().     if (codec != null) {         out.writeByte(codec.getCodecByte()).     } else {         out.writeByte(-1).     }     if (userDefinedSchema != null) {         byte[] json = userDefinedSchema.toString().getBytes(ConfigConstants.DEFAULT_CHARSET).         out.writeInt(json.length).         out.write(json).     } else {         out.writeInt(0).     } }
false;private;1;17;;private void readObject(java.io.ObjectInputStream in) throws IOException, ClassNotFoundException {     in.defaultReadObject().     byte codecByte = in.readByte().     if (codecByte >= 0) {         setCodec(Codec.forCodecByte(codecByte)).     }     int length = in.readInt().     if (length != 0) {         byte[] json = new byte[length].         in.readFully(json).         Schema schema = new Schema.Parser().parse(new String(json, ConfigConstants.DEFAULT_CHARSET)).         setSchema(schema).     } }
false;public;0;6;;@Override public void close() throws IOException {     dataFileWriter.flush().     dataFileWriter.close().     super.close(). }
