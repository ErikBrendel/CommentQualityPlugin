commented;modifiers;parameterAmount;loc;comment;code
true;private;0;7;/**  * Creates a thread pool for the query execution.  * @return Thread pool for query execution  */ ;/**  * Creates a thread pool for the query execution.  * @return Thread pool for query execution  */ private ExecutorService createQueryExecutor() {     ThreadFactory threadFactory = new ThreadFactoryBuilder().setDaemon(true).setNameFormat("Flink " + getServerName() + " Thread %d").build().     return Executors.newFixedThreadPool(numQueryThreads, threadFactory). }
true;protected;0;3;/**  * Returns the thread-pool responsible for processing incoming requests.  */ ;/**  * Returns the thread-pool responsible for processing incoming requests.  */ protected ExecutorService getQueryExecutor() {     return queryExecutor. }
true;public;0;3;/**  * Gets the name of the server. This is useful for debugging.  * @return The name of the server.  */ ;/**  * Gets the name of the server. This is useful for debugging.  * @return The name of the server.  */ public String getServerName() {     return serverName. }
true;public,abstract;0;1;/**  * Returns the {@link AbstractServerHandler handler} to be used for  * serving the incoming requests.  */ ;/**  * Returns the {@link AbstractServerHandler handler} to be used for  * serving the incoming requests.  */ public abstract AbstractServerHandler<REQ, RESP> initializeHandler().
true;public;0;4;/**  * Returns the address of this server.  *  * @return AbstractServerBase address  * @throws IllegalStateException If server has not been started yet  */ ;/**  * Returns the address of this server.  *  * @return AbstractServerBase address  * @throws IllegalStateException If server has not been started yet  */ public InetSocketAddress getServerAddress() {     Preconditions.checkState(serverAddress != null, "Server " + serverName + " has not been started.").     return serverAddress. }
true;public;0;14;/**  * Starts the server by binding to the configured bind address (blocking).  * @throws Exception If something goes wrong during the bind operation.  */ ;/**  * Starts the server by binding to the configured bind address (blocking).  * @throws Exception If something goes wrong during the bind operation.  */ public void start() throws Throwable {     Preconditions.checkState(serverAddress == null && serverShutdownFuture.get() == null, serverName + " is already running @ " + serverAddress + ". ").     Iterator<Integer> portIterator = bindPortRange.iterator().     while (portIterator.hasNext() && !attemptToBind(portIterator.next())) {     }     if (serverAddress != null) {         log.info("Started {} @ {}.", serverName, serverAddress).     } else {         log.info("Unable to start {}. All ports in provided range ({}) are occupied.", serverName, bindPortRange).         throw new FlinkRuntimeException("Unable to start " + serverName + ". All ports in provided range are occupied.").     } }
true;private;1;69;/**  * Tries to start the server at the provided port.  *  * <p>This, in conjunction with {@link #start()}, try to start the  * server on a free port among the port range provided at the constructor.  *  * @param port the port to try to bind the server to.  * @throws Exception If something goes wrong during the bind operation.  */ ;/**  * Tries to start the server at the provided port.  *  * <p>This, in conjunction with {@link #start()}, try to start the  * server on a free port among the port range provided at the constructor.  *  * @param port the port to try to bind the server to.  * @throws Exception If something goes wrong during the bind operation.  */ private boolean attemptToBind(final int port) throws Throwable {     log.debug("Attempting to start {} on port {}.", serverName, port).     this.queryExecutor = createQueryExecutor().     this.handler = initializeHandler().     final NettyBufferPool bufferPool = new NettyBufferPool(numEventLoopThreads).     final ThreadFactory threadFactory = new ThreadFactoryBuilder().setDaemon(true).setNameFormat("Flink " + serverName + " EventLoop Thread %d").build().     final NioEventLoopGroup nioGroup = new NioEventLoopGroup(numEventLoopThreads, threadFactory).     this.bootstrap = new ServerBootstrap().localAddress(bindAddress, port).group(nioGroup).channel(NioServerSocketChannel.class).option(ChannelOption.ALLOCATOR, bufferPool).childOption(ChannelOption.ALLOCATOR, bufferPool).childHandler(new ServerChannelInitializer<>(handler)).     // from DefaultChannelConfig (not exposed)     final int defaultHighWaterMark = 64 * 1024.     // (ignore warning here to make this flexible in case the configuration values change)     if (LOW_WATER_MARK > defaultHighWaterMark) {         bootstrap.childOption(ChannelOption.WRITE_BUFFER_HIGH_WATER_MARK, HIGH_WATER_MARK).         bootstrap.childOption(ChannelOption.WRITE_BUFFER_LOW_WATER_MARK, LOW_WATER_MARK).     } else {         // including (newHighWaterMark < defaultLowWaterMark)         bootstrap.childOption(ChannelOption.WRITE_BUFFER_LOW_WATER_MARK, LOW_WATER_MARK).         bootstrap.childOption(ChannelOption.WRITE_BUFFER_HIGH_WATER_MARK, HIGH_WATER_MARK).     }     try {         final ChannelFuture future = bootstrap.bind().sync().         if (future.isSuccess()) {             final InetSocketAddress localAddress = (InetSocketAddress) future.channel().localAddress().             serverAddress = new InetSocketAddress(localAddress.getAddress(), localAddress.getPort()).             return true.         }         throw future.cause().     } catch (BindException e) {         log.debug("Failed to start {} on port {}: {}.", serverName, port, e.getMessage()).         try {             // we shutdown the server but we reset the future every time because in             // case of failure to bind, we will call attemptToBind() here, and not resetting             // the flag will interfere with future shutdown attempts.             shutdownServer().whenComplete((ignoredV, ignoredT) -> serverShutdownFuture.getAndSet(null)).get().         } catch (Exception r) {             // Here we were seeing this problem:             // https://github.com/netty/netty/issues/4357 if we do a get().             // this is why we now simply wait a bit so that everything is shut down.             log.warn("Problem while shutting down {}: {}", serverName, r.getMessage()).         }     }     // any other type of exception we let it bubble up.     return false. }
true;public;0;55;/**  * Shuts down the server and all related thread pools.  * @return A {@link CompletableFuture} that will be completed upon termination of the shutdown process.  */ ;/**  * Shuts down the server and all related thread pools.  * @return A {@link CompletableFuture} that will be completed upon termination of the shutdown process.  */ public CompletableFuture<Void> shutdownServer() {     CompletableFuture<Void> shutdownFuture = new CompletableFuture<>().     if (serverShutdownFuture.compareAndSet(null, shutdownFuture)) {         log.info("Shutting down {} @ {}", serverName, serverAddress).         final CompletableFuture<Void> groupShutdownFuture = new CompletableFuture<>().         if (bootstrap != null) {             EventLoopGroup group = bootstrap.group().             if (group != null && !group.isShutdown()) {                 group.shutdownGracefully(0L, 0L, TimeUnit.MILLISECONDS).addListener(finished -> {                     if (finished.isSuccess()) {                         groupShutdownFuture.complete(null).                     } else {                         groupShutdownFuture.completeExceptionally(finished.cause()).                     }                 }).             } else {                 groupShutdownFuture.complete(null).             }         } else {             groupShutdownFuture.complete(null).         }         final CompletableFuture<Void> handlerShutdownFuture = new CompletableFuture<>().         if (handler == null) {             handlerShutdownFuture.complete(null).         } else {             handler.shutdown().whenComplete((result, throwable) -> {                 if (throwable != null) {                     handlerShutdownFuture.completeExceptionally(throwable).                 } else {                     handlerShutdownFuture.complete(null).                 }             }).         }         final CompletableFuture<Void> queryExecShutdownFuture = CompletableFuture.runAsync(() -> {             if (queryExecutor != null) {                 ExecutorUtils.gracefulShutdown(10L, TimeUnit.MINUTES, queryExecutor).             }         }).         CompletableFuture.allOf(queryExecShutdownFuture, groupShutdownFuture, handlerShutdownFuture).whenComplete((result, throwable) -> {             if (throwable != null) {                 shutdownFuture.completeExceptionally(throwable).             } else {                 shutdownFuture.complete(null).             }         }).     }     return serverShutdownFuture.get(). }
false;protected;1;7;;@Override protected void initChannel(SocketChannel channel) throws Exception {     channel.pipeline().addLast(new ChunkedWriteHandler()).addLast(new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4)).addLast(sharedRequestHandler). }
false;public;0;4;;@VisibleForTesting public boolean isEventGroupShutdown() {     return bootstrap == null || bootstrap.group().isTerminated(). }
