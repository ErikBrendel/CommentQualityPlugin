commented;modifiers;parameterAmount;loc;comment;code
false;public;0;35;;@Test public void testSolutionSetDeltaDependsOnBroadcastVariable() {     try {         ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().         DataSet<Tuple2<Long, Long>> source = env.generateSequence(1, 1000).map(new DuplicateValueScalar<Long>()).         DataSet<Tuple2<Long, Long>> invariantInput = env.generateSequence(1, 1000).map(new DuplicateValueScalar<Long>()).         // iteration from here         DeltaIteration<Tuple2<Long, Long>, Tuple2<Long, Long>> iter = source.iterateDelta(source, 1000, 1).         DataSet<Tuple2<Long, Long>> result = invariantInput.map(new IdentityMapper<Tuple2<Long, Long>>()).withBroadcastSet(iter.getWorkset(), "bc data").join(iter.getSolutionSet()).where(0).equalTo(1).projectFirst(1).projectSecond(1).         iter.closeWith(result.map(new IdentityMapper<Tuple2<Long, Long>>()), result).output(new DiscardingOutputFormat<Tuple2<Long, Long>>()).         OptimizedPlan p = compileNoStats(env.createProgramPlan()).         // check that the JSON generator accepts this plan         new PlanJSONDumpGenerator().getOptimizerPlanAsJSON(p).         // check that the JobGraphGenerator accepts the plan         new JobGraphGenerator().compileJobGraph(p).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
false;public;0;41;;@Test public void testTwoIterationsWithMapperInbetween() throws Exception {     try {         ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().         env.setParallelism(8).         DataSet<Tuple2<Long, Long>> verticesWithInitialId = env.fromElements(new Tuple2<Long, Long>(1L, 2L)).         DataSet<Tuple2<Long, Long>> edges = env.fromElements(new Tuple2<Long, Long>(1L, 2L)).         DataSet<Tuple2<Long, Long>> bulkResult = doBulkIteration(verticesWithInitialId, edges).         DataSet<Tuple2<Long, Long>> mappedBulk = bulkResult.map(new DummyMap()).         DataSet<Tuple2<Long, Long>> depResult = doDeltaIteration(mappedBulk, edges).         depResult.output(new DiscardingOutputFormat<Tuple2<Long, Long>>()).         Plan p = env.createProgramPlan().         OptimizedPlan op = compileNoStats(p).         assertEquals(1, op.getDataSinks().size()).         assertTrue(op.getDataSinks().iterator().next().getInput().getSource() instanceof WorksetIterationPlanNode).         WorksetIterationPlanNode wipn = (WorksetIterationPlanNode) op.getDataSinks().iterator().next().getInput().getSource().         assertEquals(ShipStrategyType.PARTITION_HASH, wipn.getInput1().getShipStrategy()).         assertEquals(TempMode.NONE, wipn.getInput1().getTempMode()).         assertEquals(TempMode.NONE, wipn.getInput2().getTempMode()).         assertEquals(DataExchangeMode.BATCH, wipn.getInput1().getDataExchangeMode()).         assertEquals(DataExchangeMode.BATCH, wipn.getInput2().getDataExchangeMode()).         new JobGraphGenerator().compileJobGraph(op).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
false;public;0;47;;@Test public void testTwoIterationsDirectlyChained() throws Exception {     try {         ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().         env.setParallelism(8).         DataSet<Tuple2<Long, Long>> verticesWithInitialId = env.fromElements(new Tuple2<Long, Long>(1L, 2L)).         DataSet<Tuple2<Long, Long>> edges = env.fromElements(new Tuple2<Long, Long>(1L, 2L)).         DataSet<Tuple2<Long, Long>> bulkResult = doBulkIteration(verticesWithInitialId, edges).         DataSet<Tuple2<Long, Long>> depResult = doDeltaIteration(bulkResult, edges).         depResult.output(new DiscardingOutputFormat<Tuple2<Long, Long>>()).         Plan p = env.createProgramPlan().         OptimizedPlan op = compileNoStats(p).         assertEquals(1, op.getDataSinks().size()).         assertTrue(op.getDataSinks().iterator().next().getInput().getSource() instanceof WorksetIterationPlanNode).         WorksetIterationPlanNode wipn = (WorksetIterationPlanNode) op.getDataSinks().iterator().next().getInput().getSource().         BulkIterationPlanNode bipn = (BulkIterationPlanNode) wipn.getInput1().getSource().         // the hash partitioning has been pushed out of the delta iteration into the bulk iteration         assertEquals(ShipStrategyType.FORWARD, wipn.getInput1().getShipStrategy()).         // since the work has been pushed out of the bulk iteration, it has to guarantee the hash partitioning         for (Channel c : bipn.getRootOfStepFunction().getInputs()) {             assertEquals(ShipStrategyType.PARTITION_HASH, c.getShipStrategy()).         }         assertEquals(DataExchangeMode.BATCH, wipn.getInput1().getDataExchangeMode()).         assertEquals(DataExchangeMode.BATCH, wipn.getInput2().getDataExchangeMode()).         assertEquals(TempMode.NONE, wipn.getInput1().getTempMode()).         assertEquals(TempMode.NONE, wipn.getInput2().getTempMode()).         new JobGraphGenerator().compileJobGraph(op).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
false;public;0;39;;@Test public void testTwoWorksetIterationsDirectlyChained() throws Exception {     try {         ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().         env.setParallelism(8).         DataSet<Tuple2<Long, Long>> verticesWithInitialId = env.fromElements(new Tuple2<Long, Long>(1L, 2L)).         DataSet<Tuple2<Long, Long>> edges = env.fromElements(new Tuple2<Long, Long>(1L, 2L)).         DataSet<Tuple2<Long, Long>> firstResult = doDeltaIteration(verticesWithInitialId, edges).         DataSet<Tuple2<Long, Long>> secondResult = doDeltaIteration(firstResult, edges).         secondResult.output(new DiscardingOutputFormat<Tuple2<Long, Long>>()).         Plan p = env.createProgramPlan().         OptimizedPlan op = compileNoStats(p).         assertEquals(1, op.getDataSinks().size()).         assertTrue(op.getDataSinks().iterator().next().getInput().getSource() instanceof WorksetIterationPlanNode).         WorksetIterationPlanNode wipn = (WorksetIterationPlanNode) op.getDataSinks().iterator().next().getInput().getSource().         assertEquals(ShipStrategyType.FORWARD, wipn.getInput1().getShipStrategy()).         assertEquals(DataExchangeMode.BATCH, wipn.getInput1().getDataExchangeMode()).         assertEquals(DataExchangeMode.BATCH, wipn.getInput2().getDataExchangeMode()).         assertEquals(TempMode.NONE, wipn.getInput1().getTempMode()).         assertEquals(TempMode.NONE, wipn.getInput2().getTempMode()).         new JobGraphGenerator().compileJobGraph(op).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
false;public;0;42;;@Test public void testIterationPushingWorkOut() throws Exception {     try {         ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().         env.setParallelism(8).         DataSet<Tuple2<Long, Long>> input1 = env.readCsvFile("/some/file/path").types(Long.class).map(new DuplicateValue()).         DataSet<Tuple2<Long, Long>> input2 = env.readCsvFile("/some/file/path").types(Long.class, Long.class).         // we do two join operations with input1 which is the partial solution         // it is cheaper to push the partitioning out so that the feedback channel and the         // initial input do the partitioning         doBulkIteration(input1, input2).output(new DiscardingOutputFormat<Tuple2<Long, Long>>()).         Plan p = env.createProgramPlan().         OptimizedPlan op = compileNoStats(p).         assertEquals(1, op.getDataSinks().size()).         assertTrue(op.getDataSinks().iterator().next().getInput().getSource() instanceof BulkIterationPlanNode).         BulkIterationPlanNode bipn = (BulkIterationPlanNode) op.getDataSinks().iterator().next().getInput().getSource().         // check that work has been pushed out         for (Channel c : bipn.getPartialSolutionPlanNode().getOutgoingChannels()) {             assertEquals(ShipStrategyType.FORWARD, c.getShipStrategy()).         }         // the end of the step function has to produce the necessary properties         for (Channel c : bipn.getRootOfStepFunction().getInputs()) {             assertEquals(ShipStrategyType.PARTITION_HASH, c.getShipStrategy()).         }         assertEquals(ShipStrategyType.PARTITION_HASH, bipn.getInput().getShipStrategy()).         new JobGraphGenerator().compileJobGraph(op).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
false;public;0;37;;@Test public void testIterationNotPushingWorkOut() throws Exception {     try {         ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().         env.setParallelism(8).         DataSet<Tuple2<Long, Long>> input1 = env.readCsvFile("/some/file/path").types(Long.class).map(new DuplicateValue()).         DataSet<Tuple2<Long, Long>> input2 = env.readCsvFile("/some/file/path").types(Long.class, Long.class).         // Use input1 as partial solution. Partial solution is used in a single join operation --> it is cheaper         // to do the hash partitioning between the partial solution node and the join node         // instead of pushing the partitioning out         doSimpleBulkIteration(input1, input2).output(new DiscardingOutputFormat<Tuple2<Long, Long>>()).         Plan p = env.createProgramPlan().         OptimizedPlan op = compileNoStats(p).         assertEquals(1, op.getDataSinks().size()).         assertTrue(op.getDataSinks().iterator().next().getInput().getSource() instanceof BulkIterationPlanNode).         BulkIterationPlanNode bipn = (BulkIterationPlanNode) op.getDataSinks().iterator().next().getInput().getSource().         // check that work has not been pushed out         for (Channel c : bipn.getPartialSolutionPlanNode().getOutgoingChannels()) {             assertEquals(ShipStrategyType.PARTITION_HASH, c.getShipStrategy()).         }         assertEquals(ShipStrategyType.FORWARD, bipn.getInput().getShipStrategy()).         new JobGraphGenerator().compileJobGraph(op).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
false;public;0;31;;@Test public void testWorksetIterationPipelineBreakerPlacement() {     try {         ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().         env.setParallelism(8).         // the workset (input two of the delta iteration) is the same as what is consumed be the successive join         DataSet<Tuple2<Long, Long>> initialWorkset = env.readCsvFile("/some/file/path").types(Long.class).map(new DuplicateValue()).         DataSet<Tuple2<Long, Long>> initialSolutionSet = env.readCsvFile("/some/file/path").types(Long.class).map(new DuplicateValue()).         // trivial iteration, since we are interested in the inputs to the iteration         DeltaIteration<Tuple2<Long, Long>, Tuple2<Long, Long>> iteration = initialSolutionSet.iterateDelta(initialWorkset, 100, 0).         DataSet<Tuple2<Long, Long>> next = iteration.getWorkset().map(new IdentityMapper<Tuple2<Long, Long>>()).         DataSet<Tuple2<Long, Long>> result = iteration.closeWith(next, next).         initialWorkset.join(result, JoinHint.REPARTITION_HASH_FIRST).where(0).equalTo(0).output(new DiscardingOutputFormat<Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>()).         Plan p = env.createProgramPlan().         compileNoStats(p).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
false;public;2;1;;public Long join(Long first, Long second) {     return null. }
false;public;1;1;;public Long map(Long value) {     return null. }
false;public;0;43;;@Test public void testResetPartialSolution() {     try {         ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().         DataSet<Long> width = env.generateSequence(1, 10).         DataSet<Long> update = env.generateSequence(1, 10).         DataSet<Long> lastGradient = env.generateSequence(1, 10).         DataSet<Long> init = width.union(update).union(lastGradient).         IterativeDataSet<Long> iteration = init.iterate(10).         width = iteration.filter(new IdFilter<Long>()).         update = iteration.filter(new IdFilter<Long>()).         lastGradient = iteration.filter(new IdFilter<Long>()).         DataSet<Long> gradient = width.map(new IdentityMapper<Long>()).         DataSet<Long> term = gradient.join(lastGradient).where(new IdentityKeyExtractor<Long>()).equalTo(new IdentityKeyExtractor<Long>()).with(new JoinFunction<Long, Long, Long>() {              public Long join(Long first, Long second) {                 return null.             }         }).         update = update.map(new RichMapFunction<Long, Long>() {              public Long map(Long value) {                 return null.             }         }).withBroadcastSet(term, "some-name").         DataSet<Long> result = iteration.closeWith(width.union(update).union(lastGradient)).         result.output(new DiscardingOutputFormat<Long>()).         Plan p = env.createProgramPlan().         OptimizedPlan op = compileNoStats(p).         new JobGraphGenerator().compileJobGraph(op).     } catch (Exception e) {         e.printStackTrace().         fail(e.getMessage()).     } }
false;public;1;4;;@Override public Tuple1<Long> map(Long value) throws Exception {     return new Tuple1<>(value). }
false;public;1;4;;@Override public Tuple1<Long> map(Long value) throws Exception {     return new Tuple1<>(value). }
false;public;3;11;;@Override public void coGroup(Iterable<Tuple1<Long>> first, Iterable<Tuple1<Long>> second, Collector<Tuple1<Long>> out) throws Exception {     Iterator<Tuple1<Long>> it = first.iterator().     if (it.hasNext()) {         out.collect(it.next()).     } }
true;public;0;49;/**  * Tests that interesting properties can be pushed out of the bulk iteration. This requires  * that a NoOp node is appended to the step function which re-establishes the properties of  * the initial input. If this does not work, then Flink won't find a plan, because the optimizer  * will not consider plans where the partitioning is done after the partial solution node in  * this case (because of pruning).  * @throws Exception  */ ;/**  * Tests that interesting properties can be pushed out of the bulk iteration. This requires  * that a NoOp node is appended to the step function which re-establishes the properties of  * the initial input. If this does not work, then Flink won't find a plan, because the optimizer  * will not consider plans where the partitioning is done after the partial solution node in  * this case (because of pruning).  * @throws Exception  */ @Test public void testBulkIterationWithPartialSolutionProperties() throws Exception {     ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment().     DataSet<Tuple1<Long>> input1 = env.generateSequence(1, 10).map(new MapFunction<Long, Tuple1<Long>>() {          @Override         public Tuple1<Long> map(Long value) throws Exception {             return new Tuple1<>(value).         }     }).     DataSet<Tuple1<Long>> input2 = env.generateSequence(1, 10).map(new MapFunction<Long, Tuple1<Long>>() {          @Override         public Tuple1<Long> map(Long value) throws Exception {             return new Tuple1<>(value).         }     }).     DataSet<Tuple1<Long>> distinctInput = input1.distinct().     IterativeDataSet<Tuple1<Long>> iteration = distinctInput.iterate(10).     DataSet<Tuple1<Long>> iterationStep = iteration.coGroup(input2).where(0).equalTo(0).with(new CoGroupFunction<Tuple1<Long>, Tuple1<Long>, Tuple1<Long>>() {          @Override         public void coGroup(Iterable<Tuple1<Long>> first, Iterable<Tuple1<Long>> second, Collector<Tuple1<Long>> out) throws Exception {             Iterator<Tuple1<Long>> it = first.iterator().             if (it.hasNext()) {                 out.collect(it.next()).             }         }     }).     DataSet<Tuple1<Long>> iterationResult = iteration.closeWith(iterationStep).     iterationResult.output(new DiscardingOutputFormat<Tuple1<Long>>()).     Plan p = env.createProgramPlan().     OptimizedPlan op = compileNoStats(p).     new JobGraphGenerator().compileJobGraph(op). }
false;public,static;2;14;;// -------------------------------------------------------------------------------------------- public static DataSet<Tuple2<Long, Long>> doBulkIteration(DataSet<Tuple2<Long, Long>> vertices, DataSet<Tuple2<Long, Long>> edges) {     // open a bulk iteration     IterativeDataSet<Tuple2<Long, Long>> iteration = vertices.iterate(20).     DataSet<Tuple2<Long, Long>> changes = iteration.join(edges).where(0).equalTo(0).with(new Join222()).groupBy(0).aggregate(Aggregations.MIN, 1).join(iteration).where(0).equalTo(0).flatMap(new FlatMapJoin()).     // close the bulk iteration     return iteration.closeWith(changes). }
false;public,static;2;12;;public static DataSet<Tuple2<Long, Long>> doSimpleBulkIteration(DataSet<Tuple2<Long, Long>> vertices, DataSet<Tuple2<Long, Long>> edges) {     // open a bulk iteration     IterativeDataSet<Tuple2<Long, Long>> iteration = vertices.iterate(20).     DataSet<Tuple2<Long, Long>> changes = iteration.join(edges).where(0).equalTo(0).flatMap(new FlatMapJoin()).     // close the bulk iteration     return iteration.closeWith(changes). }
false;public,static;2;26;;public static DataSet<Tuple2<Long, Long>> doDeltaIteration(DataSet<Tuple2<Long, Long>> vertices, DataSet<Tuple2<Long, Long>> edges) {     DeltaIteration<Tuple2<Long, Long>, Tuple2<Long, Long>> depIteration = vertices.iterateDelta(vertices, 100, 0).     DataSet<Tuple1<Long>> candidates = depIteration.getWorkset().join(edges).where(0).equalTo(0).projectSecond(1).     DataSet<Tuple1<Long>> grouped = candidates.groupBy(0).reduceGroup(new Reduce101()).     DataSet<Tuple2<Long, Long>> candidatesDependencies = grouped.join(edges).where(0).equalTo(1).projectSecond(0, 1).     DataSet<Tuple2<Long, Long>> verticesWithNewComponents = candidatesDependencies.join(depIteration.getSolutionSet()).where(0).equalTo(0).with(new Join222()).groupBy(0).aggregate(Aggregations.MIN, 1).     DataSet<Tuple2<Long, Long>> updatedComponentId = verticesWithNewComponents.join(depIteration.getSolutionSet()).where(0).equalTo(0).flatMap(new FlatMapJoin()).     DataSet<Tuple2<Long, Long>> depResult = depIteration.closeWith(updatedComponentId, updatedComponentId).     return depResult. }
false;public;2;4;;@Override public Tuple2<Long, Long> join(Tuple2<Long, Long> vertexWithComponent, Tuple2<Long, Long> edge) {     return null. }
false;public;2;2;;@Override public void flatMap(Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>> value, Collector<Tuple2<Long, Long>> out) { }
false;public;1;4;;@Override public Tuple2<Long, Long> map(Tuple2<Long, Long> value) throws Exception {     return value. }
false;public;2;2;;@Override public void reduce(Iterable<Tuple1<Long>> values, Collector<Tuple1<Long>> out) { }
false;public;1;4;;@Override public Tuple2<Long, Long> map(Tuple1<Long> value) throws Exception {     return new Tuple2<Long, Long>(value.f0, value.f0). }
false;public;1;4;;@Override public Tuple2<T, T> map(T value) {     return new Tuple2<T, T>(value, value). }
false;public;1;4;;@Override public boolean filter(T value) {     return true. }
