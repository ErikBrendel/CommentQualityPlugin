commented;modifiers;parameterAmount;loc;comment;code
false;protected;4;26;;@Nonnull @Override protected RunnableFuture<SnapshotResult<KeyedStateHandle>> doSnapshot(long checkpointId, long checkpointTimestamp, @Nonnull CheckpointStreamFactory checkpointStreamFactory, @Nonnull CheckpointOptions checkpointOptions) throws Exception {     final SnapshotDirectory snapshotDirectory = prepareLocalSnapshotDirectory(checkpointId).     LOG.trace("Local RocksDB checkpoint goes to backup path {}.", snapshotDirectory).     final List<StateMetaInfoSnapshot> stateMetaInfoSnapshots = new ArrayList<>(kvStateInformation.size()).     final Set<StateHandleID> baseSstFiles = snapshotMetaData(checkpointId, stateMetaInfoSnapshots).     takeDBNativeCheckpoint(snapshotDirectory).     final RocksDBIncrementalSnapshotOperation snapshotOperation = new RocksDBIncrementalSnapshotOperation(checkpointId, checkpointStreamFactory, snapshotDirectory, baseSstFiles, stateMetaInfoSnapshots).     return snapshotOperation.toAsyncSnapshotFutureTask(cancelStreamRegistry). }
false;public;1;9;;@Override public void notifyCheckpointComplete(long completedCheckpointId) {     synchronized (materializedSstFiles) {         if (completedCheckpointId > lastCompletedCheckpointId) {             materializedSstFiles.keySet().removeIf(checkpointId -> checkpointId < completedCheckpointId).             lastCompletedCheckpointId = completedCheckpointId.         }     } }
false;private;1;37;;@Nonnull private SnapshotDirectory prepareLocalSnapshotDirectory(long checkpointId) throws IOException {     if (localRecoveryConfig.isLocalRecoveryEnabled()) {         // create a "permanent" snapshot directory for local recovery.         LocalRecoveryDirectoryProvider directoryProvider = localRecoveryConfig.getLocalStateDirectoryProvider().         File directory = directoryProvider.subtaskSpecificCheckpointDirectory(checkpointId).         if (directory.exists()) {             FileUtils.deleteDirectory(directory).         }         if (!directory.mkdirs()) {             throw new IOException("Local state base directory for checkpoint " + checkpointId + " already exists: " + directory).         }         // introduces an extra directory because RocksDB wants a non-existing directory for native checkpoints.         File rdbSnapshotDir = new File(directory, "rocks_db").         Path path = new Path(rdbSnapshotDir.toURI()).         // create a "permanent" snapshot directory because local recovery is active.         try {             return SnapshotDirectory.permanent(path).         } catch (IOException ex) {             try {                 FileUtils.deleteDirectory(directory).             } catch (IOException delEx) {                 ex = ExceptionUtils.firstOrSuppressed(delEx, ex).             }             throw ex.         }     } else {         // create a "temporary" snapshot directory because local recovery is inactive.         Path path = new Path(instanceBasePath.getAbsolutePath(), "chk-" + checkpointId).         return SnapshotDirectory.temporary(path).     } }
false;private;2;21;;private Set<StateHandleID> snapshotMetaData(long checkpointId, @Nonnull List<StateMetaInfoSnapshot> stateMetaInfoSnapshots) {     final long lastCompletedCheckpoint.     final Set<StateHandleID> baseSstFiles.     // use the last completed checkpoint as the comparison base.     synchronized (materializedSstFiles) {         lastCompletedCheckpoint = lastCompletedCheckpointId.         baseSstFiles = materializedSstFiles.get(lastCompletedCheckpoint).     }     LOG.trace("Taking incremental snapshot for checkpoint {}. Snapshot is based on last completed checkpoint {} " + "assuming the following (shared) files as base: {}.", checkpointId, lastCompletedCheckpoint, baseSstFiles).     // snapshot meta data to save     for (Map.Entry<String, RocksDbKvStateInfo> stateMetaInfoEntry : kvStateInformation.entrySet()) {         stateMetaInfoSnapshots.add(stateMetaInfoEntry.getValue().metaInfo.snapshot()).     }     return baseSstFiles. }
false;private;1;15;;private void takeDBNativeCheckpoint(@Nonnull SnapshotDirectory outputDirectory) throws Exception {     // create hard links of living files in the output path     try (ResourceGuard.Lease ignored = rocksDBResourceGuard.acquireResource().         Checkpoint checkpoint = Checkpoint.create(db)) {         checkpoint.createCheckpoint(outputDirectory.getDirectory().getPath()).     } catch (Exception ex) {         try {             outputDirectory.cleanup().         } catch (IOException cleanupEx) {             ex = ExceptionUtils.firstOrSuppressed(cleanupEx, ex).         }         throw ex.     } }
false;protected;0;68;;@Override protected SnapshotResult<KeyedStateHandle> callInternal() throws Exception {     boolean completed = false.     // Handle to the meta data file     SnapshotResult<StreamStateHandle> metaStateHandle = null.     // Handles to new sst files since the last completed checkpoint will go here     final Map<StateHandleID, StreamStateHandle> sstFiles = new HashMap<>().     // Handles to the misc files in the current snapshot will go here     final Map<StateHandleID, StreamStateHandle> miscFiles = new HashMap<>().     try {         metaStateHandle = materializeMetaData().         // Sanity checks - they should never fail         Preconditions.checkNotNull(metaStateHandle, "Metadata was not properly created.").         Preconditions.checkNotNull(metaStateHandle.getJobManagerOwnedSnapshot(), "Metadata for job manager was not properly created.").         uploadSstFiles(sstFiles, miscFiles).         synchronized (materializedSstFiles) {             materializedSstFiles.put(checkpointId, sstFiles.keySet()).         }         final IncrementalRemoteKeyedStateHandle jmIncrementalKeyedStateHandle = new IncrementalRemoteKeyedStateHandle(backendUID, keyGroupRange, checkpointId, sstFiles, miscFiles, metaStateHandle.getJobManagerOwnedSnapshot()).         final DirectoryStateHandle directoryStateHandle = localBackupDirectory.completeSnapshotAndGetHandle().         final SnapshotResult<KeyedStateHandle> snapshotResult.         if (directoryStateHandle != null && metaStateHandle.getTaskLocalSnapshot() != null) {             IncrementalLocalKeyedStateHandle localDirKeyedStateHandle = new IncrementalLocalKeyedStateHandle(backendUID, checkpointId, directoryStateHandle, keyGroupRange, metaStateHandle.getTaskLocalSnapshot(), sstFiles.keySet()).             snapshotResult = SnapshotResult.withLocalState(jmIncrementalKeyedStateHandle, localDirKeyedStateHandle).         } else {             snapshotResult = SnapshotResult.of(jmIncrementalKeyedStateHandle).         }         completed = true.         return snapshotResult.     } finally {         if (!completed) {             final List<StateObject> statesToDiscard = new ArrayList<>(1 + miscFiles.size() + sstFiles.size()).             statesToDiscard.add(metaStateHandle).             statesToDiscard.addAll(miscFiles.values()).             statesToDiscard.addAll(sstFiles.values()).             cleanupIncompleteSnapshot(statesToDiscard).         }     } }
false;protected;0;15;;@Override protected void cleanupProvidedResources() {     try {         if (localBackupDirectory.exists()) {             LOG.trace("Running cleanup for local RocksDB backup directory {}.", localBackupDirectory).             boolean cleanupOk = localBackupDirectory.cleanup().             if (!cleanupOk) {                 LOG.debug("Could not properly cleanup local RocksDB backup directory.").             }         }     } catch (IOException e) {         LOG.warn("Could not properly cleanup local RocksDB backup directory.", e).     } }
false;protected;1;4;;@Override protected void logAsyncSnapshotComplete(long startTime) {     logAsyncCompleted(checkpointStreamFactory, startTime). }
false;private;1;20;;private void cleanupIncompleteSnapshot(@Nonnull List<StateObject> statesToDiscard) {     try {         StateUtil.bestEffortDiscardAllStateObjects(statesToDiscard).     } catch (Exception e) {         LOG.warn("Could not properly discard states.", e).     }     if (localBackupDirectory.isSnapshotCompleted()) {         try {             DirectoryStateHandle directoryStateHandle = localBackupDirectory.completeSnapshotAndGetHandle().             if (directoryStateHandle != null) {                 directoryStateHandle.discardState().             }         } catch (Exception e) {             LOG.warn("Could not properly discard local state.", e).         }     } }
false;private;2;24;;private void uploadSstFiles(@Nonnull Map<StateHandleID, StreamStateHandle> sstFiles, @Nonnull Map<StateHandleID, StreamStateHandle> miscFiles) throws Exception {     // write state data     Preconditions.checkState(localBackupDirectory.exists()).     Map<StateHandleID, Path> sstFilePaths = new HashMap<>().     Map<StateHandleID, Path> miscFilePaths = new HashMap<>().     FileStatus[] fileStatuses = localBackupDirectory.listStatus().     if (fileStatuses != null) {         createUploadFilePaths(fileStatuses, sstFiles, sstFilePaths, miscFilePaths).         sstFiles.putAll(stateUploader.uploadFilesToCheckpointFs(sstFilePaths, checkpointStreamFactory, snapshotCloseableRegistry)).         miscFiles.putAll(stateUploader.uploadFilesToCheckpointFs(miscFilePaths, checkpointStreamFactory, snapshotCloseableRegistry)).     } }
false;private;4;25;;private void createUploadFilePaths(FileStatus[] fileStatuses, Map<StateHandleID, StreamStateHandle> sstFiles, Map<StateHandleID, Path> sstFilePaths, Map<StateHandleID, Path> miscFilePaths) {     for (FileStatus fileStatus : fileStatuses) {         final Path filePath = fileStatus.getPath().         final String fileName = filePath.getName().         final StateHandleID stateHandleID = new StateHandleID(fileName).         if (fileName.endsWith(SST_FILE_SUFFIX)) {             final boolean existsAlready = baseSstFiles != null && baseSstFiles.contains(stateHandleID).             if (existsAlready) {                 // we introduce a placeholder state handle, that is replaced with the                 // original from the shared state registry (created from a previous checkpoint)                 sstFiles.put(stateHandleID, new PlaceholderStreamStateHandle()).             } else {                 sstFilePaths.put(stateHandleID, filePath).             }         } else {             miscFilePaths.put(stateHandleID, filePath).         }     } }
false;private;0;48;;@Nonnull private SnapshotResult<StreamStateHandle> materializeMetaData() throws Exception {     CheckpointStreamWithResultProvider streamWithResultProvider = localRecoveryConfig.isLocalRecoveryEnabled() ? CheckpointStreamWithResultProvider.createDuplicatingStream(checkpointId, CheckpointedStateScope.EXCLUSIVE, checkpointStreamFactory, localRecoveryConfig.getLocalStateDirectoryProvider()) : CheckpointStreamWithResultProvider.createSimpleStream(CheckpointedStateScope.EXCLUSIVE, checkpointStreamFactory).     snapshotCloseableRegistry.registerCloseable(streamWithResultProvider).     try {         // no need for compression scheme support because sst-files are already compressed         KeyedBackendSerializationProxy<K> serializationProxy = new KeyedBackendSerializationProxy<>(keySerializer, stateMetaInfoSnapshots, false).         DataOutputView out = new DataOutputViewStreamWrapper(streamWithResultProvider.getCheckpointOutputStream()).         serializationProxy.write(out).         if (snapshotCloseableRegistry.unregisterCloseable(streamWithResultProvider)) {             SnapshotResult<StreamStateHandle> result = streamWithResultProvider.closeAndFinalizeCheckpointStreamResult().             streamWithResultProvider = null.             return result.         } else {             throw new IOException("Stream already closed and cannot return a handle.").         }     } finally {         if (streamWithResultProvider != null) {             if (snapshotCloseableRegistry.unregisterCloseable(streamWithResultProvider)) {                 IOUtils.closeQuietly(streamWithResultProvider).             }         }     } }
