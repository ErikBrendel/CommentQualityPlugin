# id;timestamp;commentText;codeText;commentWords;codeWords
RocksDBIncrementalRestoreOperation -> @Override 	public RocksDBRestoreResult restore() throws Exception;1550863001;Root method that branches for different implementations of {@link KeyedStateHandle}.;@Override_	public RocksDBRestoreResult restore() throws Exception {__		if (restoreStateHandles == null || restoreStateHandles.isEmpty()) {_			return null__		}__		final KeyedStateHandle theFirstStateHandle = restoreStateHandles.iterator().next()___		boolean isRescaling = (restoreStateHandles.size() > 1 ||_			!Objects.equals(theFirstStateHandle.getKeyGroupRange(), keyGroupRange))___		if (isRescaling) {_			restoreWithRescaling(restoreStateHandles)__		} else {_			restoreWithoutRescaling(theFirstStateHandle)__		}_		return new RocksDBRestoreResult(this.db, defaultColumnFamilyHandle,_			nativeMetricMonitor, lastCompletedCheckpointId, backendUID, restoredSstFiles)__	};root,method,that,branches,for,different,implementations,of,link,keyed,state,handle;override,public,rocks,dbrestore,result,restore,throws,exception,if,restore,state,handles,null,restore,state,handles,is,empty,return,null,final,keyed,state,handle,the,first,state,handle,restore,state,handles,iterator,next,boolean,is,rescaling,restore,state,handles,size,1,objects,equals,the,first,state,handle,get,key,group,range,key,group,range,if,is,rescaling,restore,with,rescaling,restore,state,handles,else,restore,without,rescaling,the,first,state,handle,return,new,rocks,dbrestore,result,this,db,default,column,family,handle,native,metric,monitor,last,completed,checkpoint,id,backend,uid,restored,sst,files
RocksDBIncrementalRestoreOperation -> @Override 	public RocksDBRestoreResult restore() throws Exception;1551262623;Root method that branches for different implementations of {@link KeyedStateHandle}.;@Override_	public RocksDBRestoreResult restore() throws Exception {__		if (restoreStateHandles == null || restoreStateHandles.isEmpty()) {_			return null__		}__		final KeyedStateHandle theFirstStateHandle = restoreStateHandles.iterator().next()___		boolean isRescaling = (restoreStateHandles.size() > 1 ||_			!Objects.equals(theFirstStateHandle.getKeyGroupRange(), keyGroupRange))___		if (isRescaling) {_			restoreWithRescaling(restoreStateHandles)__		} else {_			restoreWithoutRescaling(theFirstStateHandle)__		}_		return new RocksDBRestoreResult(this.db, defaultColumnFamilyHandle,_			nativeMetricMonitor, lastCompletedCheckpointId, backendUID, restoredSstFiles)__	};root,method,that,branches,for,different,implementations,of,link,keyed,state,handle;override,public,rocks,dbrestore,result,restore,throws,exception,if,restore,state,handles,null,restore,state,handles,is,empty,return,null,final,keyed,state,handle,the,first,state,handle,restore,state,handles,iterator,next,boolean,is,rescaling,restore,state,handles,size,1,objects,equals,the,first,state,handle,get,key,group,range,key,group,range,if,is,rescaling,restore,with,rescaling,restore,state,handles,else,restore,without,rescaling,the,first,state,handle,return,new,rocks,dbrestore,result,this,db,default,column,family,handle,native,metric,monitor,last,completed,checkpoint,id,backend,uid,restored,sst,files
RocksDBIncrementalRestoreOperation -> @Override 	public RocksDBRestoreResult restore() throws Exception;1551262623;Root method that branches for different implementations of {@link KeyedStateHandle}.;@Override_	public RocksDBRestoreResult restore() throws Exception {__		if (restoreStateHandles == null || restoreStateHandles.isEmpty()) {_			return null__		}__		final KeyedStateHandle theFirstStateHandle = restoreStateHandles.iterator().next()___		boolean isRescaling = (restoreStateHandles.size() > 1 ||_			!Objects.equals(theFirstStateHandle.getKeyGroupRange(), keyGroupRange))___		if (isRescaling) {_			restoreWithRescaling(restoreStateHandles)__		} else {_			restoreWithoutRescaling(theFirstStateHandle)__		}_		return new RocksDBRestoreResult(this.db, defaultColumnFamilyHandle,_			nativeMetricMonitor, lastCompletedCheckpointId, backendUID, restoredSstFiles)__	};root,method,that,branches,for,different,implementations,of,link,keyed,state,handle;override,public,rocks,dbrestore,result,restore,throws,exception,if,restore,state,handles,null,restore,state,handles,is,empty,return,null,final,keyed,state,handle,the,first,state,handle,restore,state,handles,iterator,next,boolean,is,rescaling,restore,state,handles,size,1,objects,equals,the,first,state,handle,get,key,group,range,key,group,range,if,is,rescaling,restore,with,rescaling,restore,state,handles,else,restore,without,rescaling,the,first,state,handle,return,new,rocks,dbrestore,result,this,db,default,column,family,handle,native,metric,monitor,last,completed,checkpoint,id,backend,uid,restored,sst,files
RocksDBIncrementalRestoreOperation -> @Override 	public RocksDBRestoreResult restore() throws Exception;1551262623;Root method that branches for different implementations of {@link KeyedStateHandle}.;@Override_	public RocksDBRestoreResult restore() throws Exception {__		if (restoreStateHandles == null || restoreStateHandles.isEmpty()) {_			return null__		}__		final KeyedStateHandle theFirstStateHandle = restoreStateHandles.iterator().next()___		boolean isRescaling = (restoreStateHandles.size() > 1 ||_			!Objects.equals(theFirstStateHandle.getKeyGroupRange(), keyGroupRange))___		if (isRescaling) {_			restoreWithRescaling(restoreStateHandles)__		} else {_			restoreWithoutRescaling(theFirstStateHandle)__		}_		return new RocksDBRestoreResult(this.db, defaultColumnFamilyHandle,_			nativeMetricMonitor, lastCompletedCheckpointId, backendUID, restoredSstFiles)__	};root,method,that,branches,for,different,implementations,of,link,keyed,state,handle;override,public,rocks,dbrestore,result,restore,throws,exception,if,restore,state,handles,null,restore,state,handles,is,empty,return,null,final,keyed,state,handle,the,first,state,handle,restore,state,handles,iterator,next,boolean,is,rescaling,restore,state,handles,size,1,objects,equals,the,first,state,handle,get,key,group,range,key,group,range,if,is,rescaling,restore,with,rescaling,restore,state,handles,else,restore,without,rescaling,the,first,state,handle,return,new,rocks,dbrestore,result,this,db,default,column,family,handle,native,metric,monitor,last,completed,checkpoint,id,backend,uid,restored,sst,files
RocksDBIncrementalRestoreOperation -> private void restoreWithRescaling(Collection<KeyedStateHandle> restoreStateHandles) throws Exception;1551262623;Recovery from multi incremental states with rescaling. For rescaling, this method creates a temporary_RocksDB instance for a key-groups shard. All contents from the temporary instance are copied into the_real restore instance and then the temporary instance is discarded.;private void restoreWithRescaling(Collection<KeyedStateHandle> restoreStateHandles) throws Exception {_		_		initDBWithRescaling(restoreStateHandles)__		_		byte[] startKeyGroupPrefixBytes = new byte[keyGroupPrefixBytes]__		RocksDBKeySerializationUtils.serializeKeyGroup(keyGroupRange.getStartKeyGroup(), startKeyGroupPrefixBytes)___		byte[] stopKeyGroupPrefixBytes = new byte[keyGroupPrefixBytes]__		RocksDBKeySerializationUtils.serializeKeyGroup(keyGroupRange.getEndKeyGroup() + 1, stopKeyGroupPrefixBytes)___		for (KeyedStateHandle rawStateHandle : restoreStateHandles) {__			if (!(rawStateHandle instanceof IncrementalKeyedStateHandle)) {_				throw new IllegalStateException("Unexpected state handle type, " +_					"expected " + IncrementalKeyedStateHandle.class +_					", but found " + rawStateHandle.getClass())__			}__			Path temporaryRestoreInstancePath = new Path(instanceBasePath.getAbsolutePath() + UUID.randomUUID().toString())__			try (RestoredDBInstance tmpRestoreDBInfo = restoreDBInstanceFromStateHandle(_				(IncrementalKeyedStateHandle) rawStateHandle,_				temporaryRestoreInstancePath)__				RocksDBWriteBatchWrapper writeBatchWrapper = new RocksDBWriteBatchWrapper(this.db)) {__				List<ColumnFamilyDescriptor> tmpColumnFamilyDescriptors = tmpRestoreDBInfo.columnFamilyDescriptors__				List<ColumnFamilyHandle> tmpColumnFamilyHandles = tmpRestoreDBInfo.columnFamilyHandles___				_				for (int i = 0_ i < tmpColumnFamilyDescriptors.size()_ ++i) {_					ColumnFamilyHandle tmpColumnFamilyHandle = tmpColumnFamilyHandles.get(i)___					ColumnFamilyHandle targetColumnFamilyHandle = getOrRegisterStateColumnFamilyHandle(_						null, tmpRestoreDBInfo.stateMetaInfoSnapshots.get(i))_						.columnFamilyHandle___					try (RocksIteratorWrapper iterator = RocksDBOperationUtils.getRocksIterator(tmpRestoreDBInfo.db, tmpColumnFamilyHandle)) {__						iterator.seek(startKeyGroupPrefixBytes)___						while (iterator.isValid()) {__							if (RocksDBIncrementalCheckpointUtils.beforeThePrefixBytes(iterator.key(), stopKeyGroupPrefixBytes)) {_								writeBatchWrapper.put(targetColumnFamilyHandle, iterator.key(), iterator.value())__							} else {_								_								_								break__							}__							iterator.next()__						}_					} _				}_			} finally {_				cleanUpPathQuietly(temporaryRestoreInstancePath)__			}_		}_	};recovery,from,multi,incremental,states,with,rescaling,for,rescaling,this,method,creates,a,temporary,rocks,db,instance,for,a,key,groups,shard,all,contents,from,the,temporary,instance,are,copied,into,the,real,restore,instance,and,then,the,temporary,instance,is,discarded;private,void,restore,with,rescaling,collection,keyed,state,handle,restore,state,handles,throws,exception,init,dbwith,rescaling,restore,state,handles,byte,start,key,group,prefix,bytes,new,byte,key,group,prefix,bytes,rocks,dbkey,serialization,utils,serialize,key,group,key,group,range,get,start,key,group,start,key,group,prefix,bytes,byte,stop,key,group,prefix,bytes,new,byte,key,group,prefix,bytes,rocks,dbkey,serialization,utils,serialize,key,group,key,group,range,get,end,key,group,1,stop,key,group,prefix,bytes,for,keyed,state,handle,raw,state,handle,restore,state,handles,if,raw,state,handle,instanceof,incremental,keyed,state,handle,throw,new,illegal,state,exception,unexpected,state,handle,type,expected,incremental,keyed,state,handle,class,but,found,raw,state,handle,get,class,path,temporary,restore,instance,path,new,path,instance,base,path,get,absolute,path,uuid,random,uuid,to,string,try,restored,dbinstance,tmp,restore,dbinfo,restore,dbinstance,from,state,handle,incremental,keyed,state,handle,raw,state,handle,temporary,restore,instance,path,rocks,dbwrite,batch,wrapper,write,batch,wrapper,new,rocks,dbwrite,batch,wrapper,this,db,list,column,family,descriptor,tmp,column,family,descriptors,tmp,restore,dbinfo,column,family,descriptors,list,column,family,handle,tmp,column,family,handles,tmp,restore,dbinfo,column,family,handles,for,int,i,0,i,tmp,column,family,descriptors,size,i,column,family,handle,tmp,column,family,handle,tmp,column,family,handles,get,i,column,family,handle,target,column,family,handle,get,or,register,state,column,family,handle,null,tmp,restore,dbinfo,state,meta,info,snapshots,get,i,column,family,handle,try,rocks,iterator,wrapper,iterator,rocks,dboperation,utils,get,rocks,iterator,tmp,restore,dbinfo,db,tmp,column,family,handle,iterator,seek,start,key,group,prefix,bytes,while,iterator,is,valid,if,rocks,dbincremental,checkpoint,utils,before,the,prefix,bytes,iterator,key,stop,key,group,prefix,bytes,write,batch,wrapper,put,target,column,family,handle,iterator,key,iterator,value,else,break,iterator,next,finally,clean,up,path,quietly,temporary,restore,instance,path
RocksDBIncrementalRestoreOperation -> private void restoreWithRescaling(Collection<KeyedStateHandle> restoreStateHandles) throws Exception;1551262623;Recovery from multi incremental states with rescaling. For rescaling, this method creates a temporary_RocksDB instance for a key-groups shard. All contents from the temporary instance are copied into the_real restore instance and then the temporary instance is discarded.;private void restoreWithRescaling(Collection<KeyedStateHandle> restoreStateHandles) throws Exception {__		_		KeyedStateHandle initialHandle = RocksDBIncrementalCheckpointUtils.chooseTheBestStateHandleForInitial(_			restoreStateHandles, keyGroupRange)___		_		if (initialHandle != null) {_			restoreStateHandles.remove(initialHandle)__			initDBWithRescaling(initialHandle)__		} else {_			openDB()__		}__		_		byte[] startKeyGroupPrefixBytes = new byte[keyGroupPrefixBytes]__		RocksDBKeySerializationUtils.serializeKeyGroup(keyGroupRange.getStartKeyGroup(), startKeyGroupPrefixBytes)___		byte[] stopKeyGroupPrefixBytes = new byte[keyGroupPrefixBytes]__		RocksDBKeySerializationUtils.serializeKeyGroup(keyGroupRange.getEndKeyGroup() + 1, stopKeyGroupPrefixBytes)___		for (KeyedStateHandle rawStateHandle : restoreStateHandles) {__			if (!(rawStateHandle instanceof IncrementalKeyedStateHandle)) {_				throw new IllegalStateException("Unexpected state handle type, " +_					"expected " + IncrementalKeyedStateHandle.class +_					", but found " + rawStateHandle.getClass())__			}__			Path temporaryRestoreInstancePath = new Path(instanceBasePath.getAbsolutePath() + UUID.randomUUID().toString())__			try (RestoredDBInstance tmpRestoreDBInfo = restoreDBInstanceFromStateHandle(_				(IncrementalKeyedStateHandle) rawStateHandle,_				temporaryRestoreInstancePath)__				RocksDBWriteBatchWrapper writeBatchWrapper = new RocksDBWriteBatchWrapper(this.db)) {__				List<ColumnFamilyDescriptor> tmpColumnFamilyDescriptors = tmpRestoreDBInfo.columnFamilyDescriptors__				List<ColumnFamilyHandle> tmpColumnFamilyHandles = tmpRestoreDBInfo.columnFamilyHandles___				_				for (int i = 0_ i < tmpColumnFamilyDescriptors.size()_ ++i) {_					ColumnFamilyHandle tmpColumnFamilyHandle = tmpColumnFamilyHandles.get(i)___					ColumnFamilyHandle targetColumnFamilyHandle = getOrRegisterStateColumnFamilyHandle(_						null, tmpRestoreDBInfo.stateMetaInfoSnapshots.get(i))_						.columnFamilyHandle___					try (RocksIteratorWrapper iterator = RocksDBOperationUtils.getRocksIterator(tmpRestoreDBInfo.db, tmpColumnFamilyHandle)) {__						iterator.seek(startKeyGroupPrefixBytes)___						while (iterator.isValid()) {__							if (RocksDBIncrementalCheckpointUtils.beforeThePrefixBytes(iterator.key(), stopKeyGroupPrefixBytes)) {_								writeBatchWrapper.put(targetColumnFamilyHandle, iterator.key(), iterator.value())__							} else {_								_								_								break__							}__							iterator.next()__						}_					} _				}_			} finally {_				cleanUpPathQuietly(temporaryRestoreInstancePath)__			}_		}_	};recovery,from,multi,incremental,states,with,rescaling,for,rescaling,this,method,creates,a,temporary,rocks,db,instance,for,a,key,groups,shard,all,contents,from,the,temporary,instance,are,copied,into,the,real,restore,instance,and,then,the,temporary,instance,is,discarded;private,void,restore,with,rescaling,collection,keyed,state,handle,restore,state,handles,throws,exception,keyed,state,handle,initial,handle,rocks,dbincremental,checkpoint,utils,choose,the,best,state,handle,for,initial,restore,state,handles,key,group,range,if,initial,handle,null,restore,state,handles,remove,initial,handle,init,dbwith,rescaling,initial,handle,else,open,db,byte,start,key,group,prefix,bytes,new,byte,key,group,prefix,bytes,rocks,dbkey,serialization,utils,serialize,key,group,key,group,range,get,start,key,group,start,key,group,prefix,bytes,byte,stop,key,group,prefix,bytes,new,byte,key,group,prefix,bytes,rocks,dbkey,serialization,utils,serialize,key,group,key,group,range,get,end,key,group,1,stop,key,group,prefix,bytes,for,keyed,state,handle,raw,state,handle,restore,state,handles,if,raw,state,handle,instanceof,incremental,keyed,state,handle,throw,new,illegal,state,exception,unexpected,state,handle,type,expected,incremental,keyed,state,handle,class,but,found,raw,state,handle,get,class,path,temporary,restore,instance,path,new,path,instance,base,path,get,absolute,path,uuid,random,uuid,to,string,try,restored,dbinstance,tmp,restore,dbinfo,restore,dbinstance,from,state,handle,incremental,keyed,state,handle,raw,state,handle,temporary,restore,instance,path,rocks,dbwrite,batch,wrapper,write,batch,wrapper,new,rocks,dbwrite,batch,wrapper,this,db,list,column,family,descriptor,tmp,column,family,descriptors,tmp,restore,dbinfo,column,family,descriptors,list,column,family,handle,tmp,column,family,handles,tmp,restore,dbinfo,column,family,handles,for,int,i,0,i,tmp,column,family,descriptors,size,i,column,family,handle,tmp,column,family,handle,tmp,column,family,handles,get,i,column,family,handle,target,column,family,handle,get,or,register,state,column,family,handle,null,tmp,restore,dbinfo,state,meta,info,snapshots,get,i,column,family,handle,try,rocks,iterator,wrapper,iterator,rocks,dboperation,utils,get,rocks,iterator,tmp,restore,dbinfo,db,tmp,column,family,handle,iterator,seek,start,key,group,prefix,bytes,while,iterator,is,valid,if,rocks,dbincremental,checkpoint,utils,before,the,prefix,bytes,iterator,key,stop,key,group,prefix,bytes,write,batch,wrapper,put,target,column,family,handle,iterator,key,iterator,value,else,break,iterator,next,finally,clean,up,path,quietly,temporary,restore,instance,path
RocksDBIncrementalRestoreOperation -> private void restoreWithRescaling(Collection<KeyedStateHandle> restoreStateHandles) throws Exception;1551262623;Recovery from multi incremental states with rescaling. For rescaling, this method creates a temporary_RocksDB instance for a key-groups shard. All contents from the temporary instance are copied into the_real restore instance and then the temporary instance is discarded.;private void restoreWithRescaling(Collection<KeyedStateHandle> restoreStateHandles) throws Exception {__		_		KeyedStateHandle initialHandle = RocksDBIncrementalCheckpointUtils.chooseTheBestStateHandleForInitial(_			restoreStateHandles, keyGroupRange)___		_		if (initialHandle != null) {_			restoreStateHandles.remove(initialHandle)__			initDBWithRescaling(initialHandle)__		} else {_			openDB()__		}__		_		byte[] startKeyGroupPrefixBytes = new byte[keyGroupPrefixBytes]__		RocksDBKeySerializationUtils.serializeKeyGroup(keyGroupRange.getStartKeyGroup(), startKeyGroupPrefixBytes)___		byte[] stopKeyGroupPrefixBytes = new byte[keyGroupPrefixBytes]__		RocksDBKeySerializationUtils.serializeKeyGroup(keyGroupRange.getEndKeyGroup() + 1, stopKeyGroupPrefixBytes)___		for (KeyedStateHandle rawStateHandle : restoreStateHandles) {__			if (!(rawStateHandle instanceof IncrementalRemoteKeyedStateHandle)) {_				throw new IllegalStateException("Unexpected state handle type, " +_					"expected " + IncrementalRemoteKeyedStateHandle.class +_					", but found " + rawStateHandle.getClass())__			}__			Path temporaryRestoreInstancePath = new Path(instanceBasePath.getAbsolutePath() + UUID.randomUUID().toString())__			try (RestoredDBInstance tmpRestoreDBInfo = restoreDBInstanceFromStateHandle(_				(IncrementalRemoteKeyedStateHandle) rawStateHandle,_				temporaryRestoreInstancePath)__				RocksDBWriteBatchWrapper writeBatchWrapper = new RocksDBWriteBatchWrapper(this.db)) {__				List<ColumnFamilyDescriptor> tmpColumnFamilyDescriptors = tmpRestoreDBInfo.columnFamilyDescriptors__				List<ColumnFamilyHandle> tmpColumnFamilyHandles = tmpRestoreDBInfo.columnFamilyHandles___				_				for (int i = 0_ i < tmpColumnFamilyDescriptors.size()_ ++i) {_					ColumnFamilyHandle tmpColumnFamilyHandle = tmpColumnFamilyHandles.get(i)___					ColumnFamilyHandle targetColumnFamilyHandle = getOrRegisterStateColumnFamilyHandle(_						null, tmpRestoreDBInfo.stateMetaInfoSnapshots.get(i))_						.columnFamilyHandle___					try (RocksIteratorWrapper iterator = RocksDBOperationUtils.getRocksIterator(tmpRestoreDBInfo.db, tmpColumnFamilyHandle)) {__						iterator.seek(startKeyGroupPrefixBytes)___						while (iterator.isValid()) {__							if (RocksDBIncrementalCheckpointUtils.beforeThePrefixBytes(iterator.key(), stopKeyGroupPrefixBytes)) {_								writeBatchWrapper.put(targetColumnFamilyHandle, iterator.key(), iterator.value())__							} else {_								_								_								break__							}__							iterator.next()__						}_					} _				}_			} finally {_				cleanUpPathQuietly(temporaryRestoreInstancePath)__			}_		}_	};recovery,from,multi,incremental,states,with,rescaling,for,rescaling,this,method,creates,a,temporary,rocks,db,instance,for,a,key,groups,shard,all,contents,from,the,temporary,instance,are,copied,into,the,real,restore,instance,and,then,the,temporary,instance,is,discarded;private,void,restore,with,rescaling,collection,keyed,state,handle,restore,state,handles,throws,exception,keyed,state,handle,initial,handle,rocks,dbincremental,checkpoint,utils,choose,the,best,state,handle,for,initial,restore,state,handles,key,group,range,if,initial,handle,null,restore,state,handles,remove,initial,handle,init,dbwith,rescaling,initial,handle,else,open,db,byte,start,key,group,prefix,bytes,new,byte,key,group,prefix,bytes,rocks,dbkey,serialization,utils,serialize,key,group,key,group,range,get,start,key,group,start,key,group,prefix,bytes,byte,stop,key,group,prefix,bytes,new,byte,key,group,prefix,bytes,rocks,dbkey,serialization,utils,serialize,key,group,key,group,range,get,end,key,group,1,stop,key,group,prefix,bytes,for,keyed,state,handle,raw,state,handle,restore,state,handles,if,raw,state,handle,instanceof,incremental,remote,keyed,state,handle,throw,new,illegal,state,exception,unexpected,state,handle,type,expected,incremental,remote,keyed,state,handle,class,but,found,raw,state,handle,get,class,path,temporary,restore,instance,path,new,path,instance,base,path,get,absolute,path,uuid,random,uuid,to,string,try,restored,dbinstance,tmp,restore,dbinfo,restore,dbinstance,from,state,handle,incremental,remote,keyed,state,handle,raw,state,handle,temporary,restore,instance,path,rocks,dbwrite,batch,wrapper,write,batch,wrapper,new,rocks,dbwrite,batch,wrapper,this,db,list,column,family,descriptor,tmp,column,family,descriptors,tmp,restore,dbinfo,column,family,descriptors,list,column,family,handle,tmp,column,family,handles,tmp,restore,dbinfo,column,family,handles,for,int,i,0,i,tmp,column,family,descriptors,size,i,column,family,handle,tmp,column,family,handle,tmp,column,family,handles,get,i,column,family,handle,target,column,family,handle,get,or,register,state,column,family,handle,null,tmp,restore,dbinfo,state,meta,info,snapshots,get,i,column,family,handle,try,rocks,iterator,wrapper,iterator,rocks,dboperation,utils,get,rocks,iterator,tmp,restore,dbinfo,db,tmp,column,family,handle,iterator,seek,start,key,group,prefix,bytes,while,iterator,is,valid,if,rocks,dbincremental,checkpoint,utils,before,the,prefix,bytes,iterator,key,stop,key,group,prefix,bytes,write,batch,wrapper,put,target,column,family,handle,iterator,key,iterator,value,else,break,iterator,next,finally,clean,up,path,quietly,temporary,restore,instance,path
RocksDBIncrementalRestoreOperation -> private List<ColumnFamilyDescriptor> createAndRegisterColumnFamilyDescriptors( 		List<StateMetaInfoSnapshot> stateMetaInfoSnapshots, 		boolean registerTtlCompactFilter);1550863001;This method recreates and registers all {@link ColumnFamilyDescriptor} from Flink's state meta data snapshot.;private List<ColumnFamilyDescriptor> createAndRegisterColumnFamilyDescriptors(_		List<StateMetaInfoSnapshot> stateMetaInfoSnapshots,_		boolean registerTtlCompactFilter) {__		List<ColumnFamilyDescriptor> columnFamilyDescriptors =_			new ArrayList<>(stateMetaInfoSnapshots.size())___		for (StateMetaInfoSnapshot stateMetaInfoSnapshot : stateMetaInfoSnapshots) {_			ColumnFamilyOptions options = RocksDBOperationUtils.createColumnFamilyOptions(_				columnFamilyOptionsFactory, stateMetaInfoSnapshot.getName())__			if (registerTtlCompactFilter) {_				ttlCompactFiltersManager.setAndRegisterCompactFilterIfStateTtl(ttlTimeProvider,_					stateMetaInfoSnapshot, options)__			}_			ColumnFamilyDescriptor columnFamilyDescriptor = new ColumnFamilyDescriptor(_				stateMetaInfoSnapshot.getName().getBytes(ConfigConstants.DEFAULT_CHARSET),_				options)___			columnFamilyDescriptors.add(columnFamilyDescriptor)__		}_		return columnFamilyDescriptors__	};this,method,recreates,and,registers,all,link,column,family,descriptor,from,flink,s,state,meta,data,snapshot;private,list,column,family,descriptor,create,and,register,column,family,descriptors,list,state,meta,info,snapshot,state,meta,info,snapshots,boolean,register,ttl,compact,filter,list,column,family,descriptor,column,family,descriptors,new,array,list,state,meta,info,snapshots,size,for,state,meta,info,snapshot,state,meta,info,snapshot,state,meta,info,snapshots,column,family,options,options,rocks,dboperation,utils,create,column,family,options,column,family,options,factory,state,meta,info,snapshot,get,name,if,register,ttl,compact,filter,ttl,compact,filters,manager,set,and,register,compact,filter,if,state,ttl,ttl,time,provider,state,meta,info,snapshot,options,column,family,descriptor,column,family,descriptor,new,column,family,descriptor,state,meta,info,snapshot,get,name,get,bytes,config,constants,options,column,family,descriptors,add,column,family,descriptor,return,column,family,descriptors
RocksDBIncrementalRestoreOperation -> private List<ColumnFamilyDescriptor> createAndRegisterColumnFamilyDescriptors( 		List<StateMetaInfoSnapshot> stateMetaInfoSnapshots, 		boolean registerTtlCompactFilter);1551262623;This method recreates and registers all {@link ColumnFamilyDescriptor} from Flink's state meta data snapshot.;private List<ColumnFamilyDescriptor> createAndRegisterColumnFamilyDescriptors(_		List<StateMetaInfoSnapshot> stateMetaInfoSnapshots,_		boolean registerTtlCompactFilter) {__		List<ColumnFamilyDescriptor> columnFamilyDescriptors =_			new ArrayList<>(stateMetaInfoSnapshots.size())___		for (StateMetaInfoSnapshot stateMetaInfoSnapshot : stateMetaInfoSnapshots) {_			ColumnFamilyOptions options = RocksDBOperationUtils.createColumnFamilyOptions(_				columnFamilyOptionsFactory, stateMetaInfoSnapshot.getName())__			if (registerTtlCompactFilter) {_				ttlCompactFiltersManager.setAndRegisterCompactFilterIfStateTtl(ttlTimeProvider,_					stateMetaInfoSnapshot, options)__			}_			ColumnFamilyDescriptor columnFamilyDescriptor = new ColumnFamilyDescriptor(_				stateMetaInfoSnapshot.getName().getBytes(ConfigConstants.DEFAULT_CHARSET),_				options)___			columnFamilyDescriptors.add(columnFamilyDescriptor)__		}_		return columnFamilyDescriptors__	};this,method,recreates,and,registers,all,link,column,family,descriptor,from,flink,s,state,meta,data,snapshot;private,list,column,family,descriptor,create,and,register,column,family,descriptors,list,state,meta,info,snapshot,state,meta,info,snapshots,boolean,register,ttl,compact,filter,list,column,family,descriptor,column,family,descriptors,new,array,list,state,meta,info,snapshots,size,for,state,meta,info,snapshot,state,meta,info,snapshot,state,meta,info,snapshots,column,family,options,options,rocks,dboperation,utils,create,column,family,options,column,family,options,factory,state,meta,info,snapshot,get,name,if,register,ttl,compact,filter,ttl,compact,filters,manager,set,and,register,compact,filter,if,state,ttl,ttl,time,provider,state,meta,info,snapshot,options,column,family,descriptor,column,family,descriptor,new,column,family,descriptor,state,meta,info,snapshot,get,name,get,bytes,config,constants,options,column,family,descriptors,add,column,family,descriptor,return,column,family,descriptors
RocksDBIncrementalRestoreOperation -> private List<ColumnFamilyDescriptor> createAndRegisterColumnFamilyDescriptors( 		List<StateMetaInfoSnapshot> stateMetaInfoSnapshots, 		boolean registerTtlCompactFilter);1551262623;This method recreates and registers all {@link ColumnFamilyDescriptor} from Flink's state meta data snapshot.;private List<ColumnFamilyDescriptor> createAndRegisterColumnFamilyDescriptors(_		List<StateMetaInfoSnapshot> stateMetaInfoSnapshots,_		boolean registerTtlCompactFilter) {__		List<ColumnFamilyDescriptor> columnFamilyDescriptors =_			new ArrayList<>(stateMetaInfoSnapshots.size())___		for (StateMetaInfoSnapshot stateMetaInfoSnapshot : stateMetaInfoSnapshots) {_			ColumnFamilyOptions options = RocksDBOperationUtils.createColumnFamilyOptions(_				columnFamilyOptionsFactory, stateMetaInfoSnapshot.getName())__			if (registerTtlCompactFilter) {_				ttlCompactFiltersManager.setAndRegisterCompactFilterIfStateTtl(ttlTimeProvider,_					stateMetaInfoSnapshot, options)__			}_			ColumnFamilyDescriptor columnFamilyDescriptor = new ColumnFamilyDescriptor(_				stateMetaInfoSnapshot.getName().getBytes(ConfigConstants.DEFAULT_CHARSET),_				options)___			columnFamilyDescriptors.add(columnFamilyDescriptor)__		}_		return columnFamilyDescriptors__	};this,method,recreates,and,registers,all,link,column,family,descriptor,from,flink,s,state,meta,data,snapshot;private,list,column,family,descriptor,create,and,register,column,family,descriptors,list,state,meta,info,snapshot,state,meta,info,snapshots,boolean,register,ttl,compact,filter,list,column,family,descriptor,column,family,descriptors,new,array,list,state,meta,info,snapshots,size,for,state,meta,info,snapshot,state,meta,info,snapshot,state,meta,info,snapshots,column,family,options,options,rocks,dboperation,utils,create,column,family,options,column,family,options,factory,state,meta,info,snapshot,get,name,if,register,ttl,compact,filter,ttl,compact,filters,manager,set,and,register,compact,filter,if,state,ttl,ttl,time,provider,state,meta,info,snapshot,options,column,family,descriptor,column,family,descriptor,new,column,family,descriptor,state,meta,info,snapshot,get,name,get,bytes,config,constants,options,column,family,descriptors,add,column,family,descriptor,return,column,family,descriptors
RocksDBIncrementalRestoreOperation -> private List<ColumnFamilyDescriptor> createAndRegisterColumnFamilyDescriptors( 		List<StateMetaInfoSnapshot> stateMetaInfoSnapshots, 		boolean registerTtlCompactFilter);1551262623;This method recreates and registers all {@link ColumnFamilyDescriptor} from Flink's state meta data snapshot.;private List<ColumnFamilyDescriptor> createAndRegisterColumnFamilyDescriptors(_		List<StateMetaInfoSnapshot> stateMetaInfoSnapshots,_		boolean registerTtlCompactFilter) {__		List<ColumnFamilyDescriptor> columnFamilyDescriptors =_			new ArrayList<>(stateMetaInfoSnapshots.size())___		for (StateMetaInfoSnapshot stateMetaInfoSnapshot : stateMetaInfoSnapshots) {_			ColumnFamilyOptions options = RocksDBOperationUtils.createColumnFamilyOptions(_				columnFamilyOptionsFactory, stateMetaInfoSnapshot.getName())__			if (registerTtlCompactFilter) {_				ttlCompactFiltersManager.setAndRegisterCompactFilterIfStateTtl(ttlTimeProvider,_					stateMetaInfoSnapshot, options)__			}_			ColumnFamilyDescriptor columnFamilyDescriptor = new ColumnFamilyDescriptor(_				stateMetaInfoSnapshot.getName().getBytes(ConfigConstants.DEFAULT_CHARSET),_				options)___			columnFamilyDescriptors.add(columnFamilyDescriptor)__		}_		return columnFamilyDescriptors__	};this,method,recreates,and,registers,all,link,column,family,descriptor,from,flink,s,state,meta,data,snapshot;private,list,column,family,descriptor,create,and,register,column,family,descriptors,list,state,meta,info,snapshot,state,meta,info,snapshots,boolean,register,ttl,compact,filter,list,column,family,descriptor,column,family,descriptors,new,array,list,state,meta,info,snapshots,size,for,state,meta,info,snapshot,state,meta,info,snapshot,state,meta,info,snapshots,column,family,options,options,rocks,dboperation,utils,create,column,family,options,column,family,options,factory,state,meta,info,snapshot,get,name,if,register,ttl,compact,filter,ttl,compact,filters,manager,set,and,register,compact,filter,if,state,ttl,ttl,time,provider,state,meta,info,snapshot,options,column,family,descriptor,column,family,descriptor,new,column,family,descriptor,state,meta,info,snapshot,get,name,get,bytes,config,constants,options,column,family,descriptors,add,column,family,descriptor,return,column,family,descriptors
RocksDBIncrementalRestoreOperation -> private void restoreWithoutRescaling(KeyedStateHandle rawStateHandle) throws Exception;1551262623;Recovery from a single remote incremental state without rescaling.;private void restoreWithoutRescaling(KeyedStateHandle rawStateHandle) throws Exception {_		_		Path temporaryRestoreInstancePath = new Path(_			instanceBasePath.getAbsolutePath(),_			UUID.randomUUID().toString())_ _		RocksDBIncrementalRestorePrepareResult prepareResult = prepareFiles(rawStateHandle, temporaryRestoreInstancePath)__		Path restoreSourcePath = prepareResult.getLocalKeyedStateHandle().getDirectoryStateHandle().getDirectory()__		if (rawStateHandle instanceof IncrementalKeyedStateHandle) {_			backendUID = ((IncrementalKeyedStateHandle) rawStateHandle).getBackendIdentifier()__		} else {_			backendUID = ((IncrementalLocalKeyedStateHandle) rawStateHandle).getBackendIdentifier()__		}_		LOG.debug("Restoring keyed backend uid in operator {} from incremental snapshot to {}.",_			this.operatorIdentifier, this.backendUID)__		if (!instanceRocksDBPath.mkdirs()) {_			String errMsg = "Could not create RocksDB data directory: " + instanceBasePath.getAbsolutePath()__			LOG.error(errMsg)__			throw new IOException(errMsg)__		}_		try {_			restoreInstanceDirectoryFromPath(restoreSourcePath, dbPath)__		} finally {_			cleanUpPathQuietly(restoreSourcePath)__		}_		_		openDB()__		_		IncrementalLocalKeyedStateHandle restoreStateHandle = prepareResult.getLocalKeyedStateHandle()__		restoredSstFiles.put(_			restoreStateHandle.getCheckpointId(),_			restoreStateHandle.getSharedStateHandleIDs())__		lastCompletedCheckpointId = restoreStateHandle.getCheckpointId()__		_		registerCFHandles(prepareResult.getStateMetaInfoSnapshots())__	};recovery,from,a,single,remote,incremental,state,without,rescaling;private,void,restore,without,rescaling,keyed,state,handle,raw,state,handle,throws,exception,path,temporary,restore,instance,path,new,path,instance,base,path,get,absolute,path,uuid,random,uuid,to,string,rocks,dbincremental,restore,prepare,result,prepare,result,prepare,files,raw,state,handle,temporary,restore,instance,path,path,restore,source,path,prepare,result,get,local,keyed,state,handle,get,directory,state,handle,get,directory,if,raw,state,handle,instanceof,incremental,keyed,state,handle,backend,uid,incremental,keyed,state,handle,raw,state,handle,get,backend,identifier,else,backend,uid,incremental,local,keyed,state,handle,raw,state,handle,get,backend,identifier,log,debug,restoring,keyed,backend,uid,in,operator,from,incremental,snapshot,to,this,operator,identifier,this,backend,uid,if,instance,rocks,dbpath,mkdirs,string,err,msg,could,not,create,rocks,db,data,directory,instance,base,path,get,absolute,path,log,error,err,msg,throw,new,ioexception,err,msg,try,restore,instance,directory,from,path,restore,source,path,db,path,finally,clean,up,path,quietly,restore,source,path,open,db,incremental,local,keyed,state,handle,restore,state,handle,prepare,result,get,local,keyed,state,handle,restored,sst,files,put,restore,state,handle,get,checkpoint,id,restore,state,handle,get,shared,state,handle,ids,last,completed,checkpoint,id,restore,state,handle,get,checkpoint,id,register,cfhandles,prepare,result,get,state,meta,info,snapshots
RocksDBIncrementalRestoreOperation -> private void restoreWithoutRescaling(KeyedStateHandle rawStateHandle) throws Exception;1551262623;Recovery from a single remote incremental state without rescaling.;private void restoreWithoutRescaling(KeyedStateHandle rawStateHandle) throws Exception {_		if (rawStateHandle instanceof IncrementalKeyedStateHandle) {_			IncrementalKeyedStateHandle incrementalKeyedStateHandle = (IncrementalKeyedStateHandle) rawStateHandle__			restorePreviousIncrementalFilesStatus(incrementalKeyedStateHandle)__			restoreFromRemoteState(incrementalKeyedStateHandle)__		} else if (rawStateHandle instanceof IncrementalLocalKeyedStateHandle) {_			IncrementalLocalKeyedStateHandle incrementalLocalKeyedStateHandle =_				(IncrementalLocalKeyedStateHandle) rawStateHandle__			restorePreviousIncrementalFilesStatus(incrementalLocalKeyedStateHandle)__			restoreFromLocalState(incrementalLocalKeyedStateHandle)__		} else {_			throw new BackendBuildingException("Unexpected state handle type, " +_				"expected " + IncrementalKeyedStateHandle.class + " or " + IncrementalLocalKeyedStateHandle.class +_				", but found " + rawStateHandle.getClass())__		}_	};recovery,from,a,single,remote,incremental,state,without,rescaling;private,void,restore,without,rescaling,keyed,state,handle,raw,state,handle,throws,exception,if,raw,state,handle,instanceof,incremental,keyed,state,handle,incremental,keyed,state,handle,incremental,keyed,state,handle,incremental,keyed,state,handle,raw,state,handle,restore,previous,incremental,files,status,incremental,keyed,state,handle,restore,from,remote,state,incremental,keyed,state,handle,else,if,raw,state,handle,instanceof,incremental,local,keyed,state,handle,incremental,local,keyed,state,handle,incremental,local,keyed,state,handle,incremental,local,keyed,state,handle,raw,state,handle,restore,previous,incremental,files,status,incremental,local,keyed,state,handle,restore,from,local,state,incremental,local,keyed,state,handle,else,throw,new,backend,building,exception,unexpected,state,handle,type,expected,incremental,keyed,state,handle,class,or,incremental,local,keyed,state,handle,class,but,found,raw,state,handle,get,class
RocksDBIncrementalRestoreOperation -> private KeyedBackendSerializationProxy<K> readMetaData(StreamStateHandle metaStateHandle) throws Exception;1550863001;Reads Flink's state meta data file from the state handle.;private KeyedBackendSerializationProxy<K> readMetaData(StreamStateHandle metaStateHandle) throws Exception {__		FSDataInputStream inputStream = null___		try {_			inputStream = metaStateHandle.openInputStream()__			cancelStreamRegistry.registerCloseable(inputStream)__			DataInputView in = new DataInputViewStreamWrapper(inputStream)__			KeyedBackendSerializationProxy<K> serializationProxy = readMetaData(in)__			return serializationProxy__		} finally {_			if (cancelStreamRegistry.unregisterCloseable(inputStream)) {_				inputStream.close()__			}_		}_	};reads,flink,s,state,meta,data,file,from,the,state,handle;private,keyed,backend,serialization,proxy,k,read,meta,data,stream,state,handle,meta,state,handle,throws,exception,fsdata,input,stream,input,stream,null,try,input,stream,meta,state,handle,open,input,stream,cancel,stream,registry,register,closeable,input,stream,data,input,view,in,new,data,input,view,stream,wrapper,input,stream,keyed,backend,serialization,proxy,k,serialization,proxy,read,meta,data,in,return,serialization,proxy,finally,if,cancel,stream,registry,unregister,closeable,input,stream,input,stream,close
RocksDBIncrementalRestoreOperation -> private KeyedBackendSerializationProxy<K> readMetaData(StreamStateHandle metaStateHandle) throws Exception;1551262623;Reads Flink's state meta data file from the state handle.;private KeyedBackendSerializationProxy<K> readMetaData(StreamStateHandle metaStateHandle) throws Exception {__		FSDataInputStream inputStream = null___		try {_			inputStream = metaStateHandle.openInputStream()__			cancelStreamRegistry.registerCloseable(inputStream)__			DataInputView in = new DataInputViewStreamWrapper(inputStream)__			return readMetaData(in)__		} finally {_			if (cancelStreamRegistry.unregisterCloseable(inputStream)) {_				inputStream.close()__			}_		}_	};reads,flink,s,state,meta,data,file,from,the,state,handle;private,keyed,backend,serialization,proxy,k,read,meta,data,stream,state,handle,meta,state,handle,throws,exception,fsdata,input,stream,input,stream,null,try,input,stream,meta,state,handle,open,input,stream,cancel,stream,registry,register,closeable,input,stream,data,input,view,in,new,data,input,view,stream,wrapper,input,stream,return,read,meta,data,in,finally,if,cancel,stream,registry,unregister,closeable,input,stream,input,stream,close
RocksDBIncrementalRestoreOperation -> private KeyedBackendSerializationProxy<K> readMetaData(StreamStateHandle metaStateHandle) throws Exception;1551262623;Reads Flink's state meta data file from the state handle.;private KeyedBackendSerializationProxy<K> readMetaData(StreamStateHandle metaStateHandle) throws Exception {__		FSDataInputStream inputStream = null___		try {_			inputStream = metaStateHandle.openInputStream()__			cancelStreamRegistry.registerCloseable(inputStream)__			DataInputView in = new DataInputViewStreamWrapper(inputStream)__			return readMetaData(in)__		} finally {_			if (cancelStreamRegistry.unregisterCloseable(inputStream)) {_				inputStream.close()__			}_		}_	};reads,flink,s,state,meta,data,file,from,the,state,handle;private,keyed,backend,serialization,proxy,k,read,meta,data,stream,state,handle,meta,state,handle,throws,exception,fsdata,input,stream,input,stream,null,try,input,stream,meta,state,handle,open,input,stream,cancel,stream,registry,register,closeable,input,stream,data,input,view,in,new,data,input,view,stream,wrapper,input,stream,return,read,meta,data,in,finally,if,cancel,stream,registry,unregister,closeable,input,stream,input,stream,close
RocksDBIncrementalRestoreOperation -> private KeyedBackendSerializationProxy<K> readMetaData(StreamStateHandle metaStateHandle) throws Exception;1551262623;Reads Flink's state meta data file from the state handle.;private KeyedBackendSerializationProxy<K> readMetaData(StreamStateHandle metaStateHandle) throws Exception {__		FSDataInputStream inputStream = null___		try {_			inputStream = metaStateHandle.openInputStream()__			cancelStreamRegistry.registerCloseable(inputStream)__			DataInputView in = new DataInputViewStreamWrapper(inputStream)__			return readMetaData(in)__		} finally {_			if (cancelStreamRegistry.unregisterCloseable(inputStream)) {_				inputStream.close()__			}_		}_	};reads,flink,s,state,meta,data,file,from,the,state,handle;private,keyed,backend,serialization,proxy,k,read,meta,data,stream,state,handle,meta,state,handle,throws,exception,fsdata,input,stream,input,stream,null,try,input,stream,meta,state,handle,open,input,stream,cancel,stream,registry,register,closeable,input,stream,data,input,view,in,new,data,input,view,stream,wrapper,input,stream,return,read,meta,data,in,finally,if,cancel,stream,registry,unregister,closeable,input,stream,input,stream,close
RocksDBIncrementalRestoreOperation -> private void restoreInstanceDirectoryFromPath(Path source, String instanceRocksDBPath) throws IOException;1551262623;This recreates the new working directory of the recovered RocksDB instance and links/copies the contents from_a local state.;private void restoreInstanceDirectoryFromPath(Path source, String instanceRocksDBPath) throws IOException {__		FileSystem fileSystem = source.getFileSystem()___		final FileStatus[] fileStatuses = fileSystem.listStatus(source)___		if (fileStatuses == null) {_			throw new IOException("Cannot list file statues. Directory " + source + " does not exist.")__		}__		for (FileStatus fileStatus : fileStatuses) {_			final Path filePath = fileStatus.getPath()__			final String fileName = filePath.getName()__			File restoreFile = new File(source.getPath(), fileName)__			File targetFile = new File(instanceRocksDBPath, fileName)__			if (fileName.endsWith(SST_FILE_SUFFIX)) {_				_				Files.createLink(targetFile.toPath(), restoreFile.toPath())__			} else {_				_				Files.copy(restoreFile.toPath(), targetFile.toPath(), StandardCopyOption.REPLACE_EXISTING)__			}_		}_	};this,recreates,the,new,working,directory,of,the,recovered,rocks,db,instance,and,links,copies,the,contents,from,a,local,state;private,void,restore,instance,directory,from,path,path,source,string,instance,rocks,dbpath,throws,ioexception,file,system,file,system,source,get,file,system,final,file,status,file,statuses,file,system,list,status,source,if,file,statuses,null,throw,new,ioexception,cannot,list,file,statues,directory,source,does,not,exist,for,file,status,file,status,file,statuses,final,path,file,path,file,status,get,path,final,string,file,name,file,path,get,name,file,restore,file,new,file,source,get,path,file,name,file,target,file,new,file,instance,rocks,dbpath,file,name,if,file,name,ends,with,files,create,link,target,file,to,path,restore,file,to,path,else,files,copy,restore,file,to,path,target,file,to,path,standard,copy,option
RocksDBIncrementalRestoreOperation -> private void restoreInstanceDirectoryFromPath(Path source, String instanceRocksDBPath) throws IOException;1551262623;This recreates the new working directory of the recovered RocksDB instance and links/copies the contents from_a local state.;private void restoreInstanceDirectoryFromPath(Path source, String instanceRocksDBPath) throws IOException {__		FileSystem fileSystem = source.getFileSystem()___		final FileStatus[] fileStatuses = fileSystem.listStatus(source)___		if (fileStatuses == null) {_			throw new IOException("Cannot list file statues. Directory " + source + " does not exist.")__		}__		for (FileStatus fileStatus : fileStatuses) {_			final Path filePath = fileStatus.getPath()__			final String fileName = filePath.getName()__			File restoreFile = new File(source.getPath(), fileName)__			File targetFile = new File(instanceRocksDBPath, fileName)__			if (fileName.endsWith(SST_FILE_SUFFIX)) {_				_				Files.createLink(targetFile.toPath(), restoreFile.toPath())__			} else {_				_				Files.copy(restoreFile.toPath(), targetFile.toPath(), StandardCopyOption.REPLACE_EXISTING)__			}_		}_	};this,recreates,the,new,working,directory,of,the,recovered,rocks,db,instance,and,links,copies,the,contents,from,a,local,state;private,void,restore,instance,directory,from,path,path,source,string,instance,rocks,dbpath,throws,ioexception,file,system,file,system,source,get,file,system,final,file,status,file,statuses,file,system,list,status,source,if,file,statuses,null,throw,new,ioexception,cannot,list,file,statues,directory,source,does,not,exist,for,file,status,file,status,file,statuses,final,path,file,path,file,status,get,path,final,string,file,name,file,path,get,name,file,restore,file,new,file,source,get,path,file,name,file,target,file,new,file,instance,rocks,dbpath,file,name,if,file,name,ends,with,files,create,link,target,file,to,path,restore,file,to,path,else,files,copy,restore,file,to,path,target,file,to,path,standard,copy,option
RocksDBIncrementalRestoreOperation -> private void restoreInstanceDirectoryFromPath(Path source, String instanceRocksDBPath) throws IOException;1551262623;This recreates the new working directory of the recovered RocksDB instance and links/copies the contents from_a local state.;private void restoreInstanceDirectoryFromPath(Path source, String instanceRocksDBPath) throws IOException {__		FileSystem fileSystem = source.getFileSystem()___		final FileStatus[] fileStatuses = fileSystem.listStatus(source)___		if (fileStatuses == null) {_			throw new IOException("Cannot list file statues. Directory " + source + " does not exist.")__		}__		for (FileStatus fileStatus : fileStatuses) {_			final Path filePath = fileStatus.getPath()__			final String fileName = filePath.getName()__			File restoreFile = new File(source.getPath(), fileName)__			File targetFile = new File(instanceRocksDBPath, fileName)__			if (fileName.endsWith(SST_FILE_SUFFIX)) {_				_				Files.createLink(targetFile.toPath(), restoreFile.toPath())__			} else {_				_				Files.copy(restoreFile.toPath(), targetFile.toPath(), StandardCopyOption.REPLACE_EXISTING)__			}_		}_	};this,recreates,the,new,working,directory,of,the,recovered,rocks,db,instance,and,links,copies,the,contents,from,a,local,state;private,void,restore,instance,directory,from,path,path,source,string,instance,rocks,dbpath,throws,ioexception,file,system,file,system,source,get,file,system,final,file,status,file,statuses,file,system,list,status,source,if,file,statuses,null,throw,new,ioexception,cannot,list,file,statues,directory,source,does,not,exist,for,file,status,file,status,file,statuses,final,path,file,path,file,status,get,path,final,string,file,name,file,path,get,name,file,restore,file,new,file,source,get,path,file,name,file,target,file,new,file,instance,rocks,dbpath,file,name,if,file,name,ends,with,files,create,link,target,file,to,path,restore,file,to,path,else,files,copy,restore,file,to,path,target,file,to,path,standard,copy,option
