commented;modifiers;parameterAmount;loc;comment;code
false;public,static;0;4;;@BeforeClass public static void setup() {     clusterClient = MINI_CLUSTER_RESOURCE.getClusterClient(). }
false;private,static;0;8;;private static Configuration getConfig() {     Configuration config = new Configuration().     config.setString(TaskManagerOptions.MANAGED_MEMORY_SIZE, "4m").     config.setInteger(ConfigConstants.LOCAL_NUMBER_TASK_MANAGER, NUM_TMS).     config.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, NUM_SLOTS_PER_TM).     config.setBoolean(WebOptions.SUBMIT_ENABLE, false).     return config. }
false;public;0;42;;@Test public void testValidateSession() throws Exception {     final Executor executor = createDefaultExecutor(clusterClient).     final SessionContext session = new SessionContext("test-session", new Environment()).     executor.validateSession(session).     session.addView(ViewEntry.create("AdditionalView1", "SELECT 1")).     session.addView(ViewEntry.create("AdditionalView2", "SELECT * FROM AdditionalView1")).     executor.validateSession(session).     List<String> actualTables = executor.listTables(session).     List<String> expectedTables = Arrays.asList("AdditionalView1", "AdditionalView2", "TableNumber1", "TableNumber2", "TableSourceSink", "TestView1", "TestView2").     assertEquals(expectedTables, actualTables).     session.removeView("AdditionalView1").     try {         executor.validateSession(session).         fail().     } catch (SqlExecutionException e) {     // AdditionalView2 needs AdditionalView1     }     session.removeView("AdditionalView2").     executor.validateSession(session).     actualTables = executor.listTables(session).     expectedTables = Arrays.asList("TableNumber1", "TableNumber2", "TableSourceSink", "TestView1", "TestView2").     assertEquals(expectedTables, actualTables). }
false;public;0;15;;@Test public void testListTables() throws Exception {     final Executor executor = createDefaultExecutor(clusterClient).     final SessionContext session = new SessionContext("test-session", new Environment()).     final List<String> actualTables = executor.listTables(session).     final List<String> expectedTables = Arrays.asList("TableNumber1", "TableNumber2", "TableSourceSink", "TestView1", "TestView2").     assertEquals(expectedTables, actualTables). }
false;public;0;10;;@Test public void testListUserDefinedFunctions() throws Exception {     final Executor executor = createDefaultExecutor(clusterClient).     final SessionContext session = new SessionContext("test-session", new Environment()).     final List<String> actualTables = executor.listUserDefinedFunctions(session).     final List<String> expectedTables = Arrays.asList("aggregateUDF", "tableUDF", "scalarUDF").     assertEquals(expectedTables, actualTables). }
false;public;0;32;;@Test public void testGetSessionProperties() throws Exception {     final Executor executor = createDefaultExecutor(clusterClient).     final SessionContext session = new SessionContext("test-session", new Environment()).     session.setSessionProperty("execution.result-mode", "changelog").     executor.getSessionProperties(session).     // modify defaults     session.setSessionProperty("execution.result-mode", "table").     final Map<String, String> actualProperties = executor.getSessionProperties(session).     final Map<String, String> expectedProperties = new HashMap<>().     expectedProperties.put("execution.type", "batch").     expectedProperties.put("execution.time-characteristic", "event-time").     expectedProperties.put("execution.periodic-watermarks-interval", "99").     expectedProperties.put("execution.parallelism", "1").     expectedProperties.put("execution.max-parallelism", "16").     expectedProperties.put("execution.max-idle-state-retention", "0").     expectedProperties.put("execution.min-idle-state-retention", "0").     expectedProperties.put("execution.result-mode", "table").     expectedProperties.put("execution.max-table-result-rows", "100").     expectedProperties.put("execution.restart-strategy.type", "failure-rate").     expectedProperties.put("execution.restart-strategy.max-failures-per-interval", "10").     expectedProperties.put("execution.restart-strategy.failure-rate-interval", "99000").     expectedProperties.put("execution.restart-strategy.delay", "1000").     expectedProperties.put("deployment.response-timeout", "5000").     assertEquals(expectedProperties, actualProperties). }
false;public;0;13;;@Test public void testTableSchema() throws Exception {     final Executor executor = createDefaultExecutor(clusterClient).     final SessionContext session = new SessionContext("test-session", new Environment()).     final TableSchema actualTableSchema = executor.getTableSchema(session, "TableNumber2").     final TableSchema expectedTableSchema = new TableSchema(new String[] { "IntegerField2", "StringField2" }, new TypeInformation[] { Types.INT, Types.STRING }).     assertEquals(expectedTableSchema, actualTableSchema). }
false;public;0;18;;@Test public void testCompleteStatement() throws Exception {     final Executor executor = createDefaultExecutor(clusterClient).     final SessionContext session = new SessionContext("test-session", new Environment()).     final List<String> expectedTableHints = Arrays.asList("TABLE", "TableNumber1", "TableNumber2", "TableSourceSink").     assertEquals(expectedTableHints, executor.completeStatement(session, "SELECT * FROM Ta", 16)).     final List<String> expectedClause = Collections.singletonList("WHERE").     assertEquals(expectedClause, executor.completeStatement(session, "SELECT * FROM TableNumber2 WH", 29)).     final List<String> expectedField = Arrays.asList("INTERVAL", "IntegerField1").     assertEquals(expectedField, executor.completeStatement(session, "SELECT * FROM TableNumber1 WHERE Inte", 37)). }
false;public;0;38;;@Test(timeout = 30_000L) public void testStreamQueryExecutionChangelog() throws Exception {     final URL url = getClass().getClassLoader().getResource("test-data.csv").     Objects.requireNonNull(url).     final Map<String, String> replaceVars = new HashMap<>().     replaceVars.put("$VAR_SOURCE_PATH1", url.getPath()).     replaceVars.put("$VAR_EXECUTION_TYPE", "streaming").     replaceVars.put("$VAR_RESULT_MODE", "changelog").     replaceVars.put("$VAR_UPDATE_MODE", "update-mode: append").     replaceVars.put("$VAR_MAX_ROWS", "100").     final Executor executor = createModifiedExecutor(clusterClient, replaceVars).     final SessionContext session = new SessionContext("test-session", new Environment()).     try {         // start job and retrieval         final ResultDescriptor desc = executor.executeQuery(session, "SELECT scalarUDF(IntegerField1), StringField1 FROM TableNumber1").         assertFalse(desc.isMaterialized()).         final List<String> actualResults = retrieveChangelogResult(executor, session, desc.getResultId()).         final List<String> expectedResults = new ArrayList<>().         expectedResults.add("(true,47,Hello World)").         expectedResults.add("(true,27,Hello World)").         expectedResults.add("(true,37,Hello World)").         expectedResults.add("(true,37,Hello World)").         expectedResults.add("(true,47,Hello World)").         expectedResults.add("(true,57,Hello World!!!!)").         TestBaseUtils.compareResultCollections(expectedResults, actualResults, Comparator.naturalOrder()).     } finally {         executor.stop(session).     } }
false;public;0;24;;@Test(timeout = 30_000L) public void testStreamQueryExecutionTable() throws Exception {     final URL url = getClass().getClassLoader().getResource("test-data.csv").     Objects.requireNonNull(url).     final Map<String, String> replaceVars = new HashMap<>().     replaceVars.put("$VAR_SOURCE_PATH1", url.getPath()).     replaceVars.put("$VAR_EXECUTION_TYPE", "streaming").     replaceVars.put("$VAR_RESULT_MODE", "table").     replaceVars.put("$VAR_UPDATE_MODE", "update-mode: append").     replaceVars.put("$VAR_MAX_ROWS", "100").     final String query = "SELECT scalarUDF(IntegerField1), StringField1 FROM TableNumber1".     final List<String> expectedResults = new ArrayList<>().     expectedResults.add("47,Hello World").     expectedResults.add("27,Hello World").     expectedResults.add("37,Hello World").     expectedResults.add("37,Hello World").     expectedResults.add("47,Hello World").     expectedResults.add("57,Hello World!!!!").     executeStreamQueryTable(replaceVars, query, expectedResults). }
false;public;0;19;;@Test(timeout = 30_000L) public void testStreamQueryExecutionLimitedTable() throws Exception {     final URL url = getClass().getClassLoader().getResource("test-data.csv").     Objects.requireNonNull(url).     final Map<String, String> replaceVars = new HashMap<>().     replaceVars.put("$VAR_SOURCE_PATH1", url.getPath()).     replaceVars.put("$VAR_EXECUTION_TYPE", "streaming").     replaceVars.put("$VAR_RESULT_MODE", "table").     replaceVars.put("$VAR_UPDATE_MODE", "update-mode: append").     replaceVars.put("$VAR_MAX_ROWS", "1").     final String query = "SELECT COUNT(*), StringField1 FROM TableNumber1 GROUP BY StringField1".     final List<String> expectedResults = new ArrayList<>().     expectedResults.add("1,Hello World!!!!").     executeStreamQueryTable(replaceVars, query, expectedResults). }
false;public;0;34;;@Test(timeout = 30_000L) public void testBatchQueryExecution() throws Exception {     final URL url = getClass().getClassLoader().getResource("test-data.csv").     Objects.requireNonNull(url).     final Map<String, String> replaceVars = new HashMap<>().     replaceVars.put("$VAR_SOURCE_PATH1", url.getPath()).     replaceVars.put("$VAR_EXECUTION_TYPE", "batch").     replaceVars.put("$VAR_RESULT_MODE", "table").     replaceVars.put("$VAR_UPDATE_MODE", "").     replaceVars.put("$VAR_MAX_ROWS", "100").     final Executor executor = createModifiedExecutor(clusterClient, replaceVars).     final SessionContext session = new SessionContext("test-session", new Environment()).     try {         final ResultDescriptor desc = executor.executeQuery(session, "SELECT * FROM TestView1").         assertTrue(desc.isMaterialized()).         final List<String> actualResults = retrieveTableResult(executor, session, desc.getResultId()).         final List<String> expectedResults = new ArrayList<>().         expectedResults.add("47").         expectedResults.add("27").         expectedResults.add("37").         expectedResults.add("37").         expectedResults.add("47").         expectedResults.add("57").         TestBaseUtils.compareResultCollections(expectedResults, actualResults, Comparator.naturalOrder()).     } finally {         executor.stop(session).     } }
false;public;0;42;;@Test(timeout = 30_000L) public void testStreamQueryExecutionSink() throws Exception {     final String csvOutputPath = new File(tempFolder.newFolder().getAbsolutePath(), "test-out.csv").toURI().toString().     final URL url = getClass().getClassLoader().getResource("test-data.csv").     Objects.requireNonNull(url).     final Map<String, String> replaceVars = new HashMap<>().     replaceVars.put("$VAR_SOURCE_PATH1", url.getPath()).     replaceVars.put("$VAR_EXECUTION_TYPE", "streaming").     replaceVars.put("$VAR_SOURCE_SINK_PATH", csvOutputPath).     replaceVars.put("$VAR_UPDATE_MODE", "update-mode: append").     replaceVars.put("$VAR_MAX_ROWS", "100").     final Executor executor = createModifiedExecutor(clusterClient, replaceVars).     final SessionContext session = new SessionContext("test-session", new Environment()).     try {         // start job         final ProgramTargetDescriptor targetDescriptor = executor.executeUpdate(session, "INSERT INTO TableSourceSink SELECT IntegerField1 = 42, StringField1 FROM TableNumber1").         // wait for job completion and verify result         boolean isRunning = true.         while (isRunning) {             // slow the processing down             Thread.sleep(50).             final JobStatus jobStatus = clusterClient.getJobStatus(JobID.fromHexString(targetDescriptor.getJobId())).get().             switch(jobStatus) {                 case CREATED:                 case RUNNING:                     continue.                 case FINISHED:                     isRunning = false.                     verifySinkResult(csvOutputPath).                     break.                 default:                     fail("Unexpected job status.").             }         }     } finally {         executor.stop(session).     } }
false;private;3;21;;private void executeStreamQueryTable(Map<String, String> replaceVars, String query, List<String> expectedResults) throws Exception {     final Executor executor = createModifiedExecutor(clusterClient, replaceVars).     final SessionContext session = new SessionContext("test-session", new Environment()).     try {         // start job and retrieval         final ResultDescriptor desc = executor.executeQuery(session, query).         assertTrue(desc.isMaterialized()).         final List<String> actualResults = retrieveTableResult(executor, session, desc.getResultId()).         TestBaseUtils.compareResultCollections(expectedResults, actualResults, Comparator.naturalOrder()).     } finally {         executor.stop(session).     } }
false;private;1;12;;private void verifySinkResult(String path) throws IOException {     final List<String> actualResults = new ArrayList<>().     TestBaseUtils.readAllResultLines(actualResults, path).     final List<String> expectedResults = new ArrayList<>().     expectedResults.add("true,Hello World").     expectedResults.add("false,Hello World").     expectedResults.add("false,Hello World").     expectedResults.add("false,Hello World").     expectedResults.add("true,Hello World").     expectedResults.add("false,Hello World!!!!").     TestBaseUtils.compareResultCollections(expectedResults, actualResults, Comparator.naturalOrder()). }
false;private;1;11;;private <T> LocalExecutor createDefaultExecutor(ClusterClient<T> clusterClient) throws Exception {     final Map<String, String> replaceVars = new HashMap<>().     replaceVars.put("$VAR_EXECUTION_TYPE", "batch").     replaceVars.put("$VAR_UPDATE_MODE", "").     replaceVars.put("$VAR_MAX_ROWS", "100").     return new LocalExecutor(EnvironmentFileUtil.parseModified(DEFAULTS_ENVIRONMENT_FILE, replaceVars), Collections.emptyList(), clusterClient.getFlinkConfiguration(), new DummyCustomCommandLine<T>(clusterClient)). }
false;private;2;7;;private <T> LocalExecutor createModifiedExecutor(ClusterClient<T> clusterClient, Map<String, String> replaceVars) throws Exception {     return new LocalExecutor(EnvironmentFileUtil.parseModified(DEFAULTS_ENVIRONMENT_FILE, replaceVars), Collections.emptyList(), clusterClient.getFlinkConfiguration(), new DummyCustomCommandLine<T>(clusterClient)). }
false;private;3;23;;private List<String> retrieveTableResult(Executor executor, SessionContext session, String resultID) throws InterruptedException {     final List<String> actualResults = new ArrayList<>().     while (true) {         // slow the processing down         Thread.sleep(50).         final TypedResult<Integer> result = executor.snapshotResult(session, resultID, 2).         if (result.getType() == TypedResult.ResultType.PAYLOAD) {             actualResults.clear().             IntStream.rangeClosed(1, result.getPayload()).forEach((page) -> {                 for (Row row : executor.retrieveResultPage(resultID, page)) {                     actualResults.add(row.toString()).                 }             }).         } else if (result.getType() == TypedResult.ResultType.EOS) {             break.         }     }     return actualResults. }
false;private;3;20;;private List<String> retrieveChangelogResult(Executor executor, SessionContext session, String resultID) throws InterruptedException {     final List<String> actualResults = new ArrayList<>().     while (true) {         // slow the processing down         Thread.sleep(50).         final TypedResult<List<Tuple2<Boolean, Row>>> result = executor.retrieveResultChanges(session, resultID).         if (result.getType() == TypedResult.ResultType.PAYLOAD) {             for (Tuple2<Boolean, Row> change : result.getPayload()) {                 actualResults.add(change.toString()).             }         } else if (result.getType() == TypedResult.ResultType.EOS) {             break.         }     }     return actualResults. }
