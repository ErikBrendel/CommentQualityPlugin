commented;modifiers;parameterAmount;loc;comment;code
false;public;0;3;;public SessionContext getSessionContext() {     return sessionContext. }
false;public;0;3;;public ClassLoader getClassLoader() {     return classLoader. }
false;public;0;3;;public Environment getMergedEnvironment() {     return mergedEnv. }
false;public;0;3;;public ClusterSpecification getClusterSpec() {     return clusterSpec. }
false;public;0;3;;public T getClusterId() {     return clusterId. }
false;public;0;3;;public ClusterDescriptor<T> createClusterDescriptor() throws Exception {     return activeCommandLine.createClusterDescriptor(commandLine). }
false;public;0;8;;public EnvironmentInstance createEnvironmentInstance() {     try {         return new EnvironmentInstance().     } catch (Throwable t) {         // catch everything such that a wrong environment does not affect invocations         throw new SqlExecutionException("Could not create environment instance.", t).     } }
false;public;0;3;;public Map<String, TableSource<?>> getTableSources() {     return tableSources. }
false;public;0;3;;public Map<String, TableSink<?>> getTableSinks() {     return tableSinks. }
true;public;1;9;/**  * Executes the given supplier using the execution context's classloader as thread classloader.  */ ;/**  * Executes the given supplier using the execution context's classloader as thread classloader.  */ public <R> R wrapClassLoader(Supplier<R> supplier) {     final ClassLoader previousClassloader = Thread.currentThread().getContextClassLoader().     Thread.currentThread().setContextClassLoader(classLoader).     try {         return supplier.get().     } finally {         Thread.currentThread().setContextClassLoader(previousClassloader).     } }
false;private,static;2;7;;// -------------------------------------------------------------------------------------------- private static CommandLine createCommandLine(DeploymentEntry deployment, Options commandLineOptions) {     try {         return deployment.getCommandLine(commandLineOptions).     } catch (Exception e) {         throw new SqlExecutionException("Invalid deployment options.", e).     } }
false;private,static;2;9;;@SuppressWarnings("unchecked") private static <T> CustomCommandLine<T> findActiveCommandLine(List<CustomCommandLine<?>> availableCommandLines, CommandLine commandLine) {     for (CustomCommandLine<?> cli : availableCommandLines) {         if (cli.isActive(commandLine)) {             return (CustomCommandLine<T>) cli.         }     }     throw new SqlExecutionException("Could not find a matching deployment."). }
false;private,static;1;7;;private static RunOptions createRunOptions(CommandLine commandLine) {     try {         return new RunOptions(commandLine).     } catch (CliArgsException e) {         throw new SqlExecutionException("Invalid deployment run options.", e).     } }
false;private,static;2;7;;private static ClusterSpecification createClusterSpecification(CustomCommandLine<?> activeCommandLine, CommandLine commandLine) {     try {         return activeCommandLine.getClusterSpecification(commandLine).     } catch (FlinkException e) {         throw new SqlExecutionException("Could not create cluster specification for the given deployment.", e).     } }
false;private,static;3;12;;private static TableSource<?> createTableSource(ExecutionEntry execution, Map<String, String> sourceProperties, ClassLoader classLoader) {     if (execution.isStreamingExecution()) {         final StreamTableSourceFactory<?> factory = (StreamTableSourceFactory<?>) TableFactoryService.find(StreamTableSourceFactory.class, sourceProperties, classLoader).         return factory.createStreamTableSource(sourceProperties).     } else if (execution.isBatchExecution()) {         final BatchTableSourceFactory<?> factory = (BatchTableSourceFactory<?>) TableFactoryService.find(BatchTableSourceFactory.class, sourceProperties, classLoader).         return factory.createBatchTableSource(sourceProperties).     }     throw new SqlExecutionException("Unsupported execution type for sources."). }
false;private,static;3;12;;private static TableSink<?> createTableSink(ExecutionEntry execution, Map<String, String> sinkProperties, ClassLoader classLoader) {     if (execution.isStreamingExecution()) {         final StreamTableSinkFactory<?> factory = (StreamTableSinkFactory<?>) TableFactoryService.find(StreamTableSinkFactory.class, sinkProperties, classLoader).         return factory.createStreamTableSink(sinkProperties).     } else if (execution.isBatchExecution()) {         final BatchTableSinkFactory<?> factory = (BatchTableSinkFactory<?>) TableFactoryService.find(BatchTableSinkFactory.class, sinkProperties, classLoader).         return factory.createBatchTableSink(sinkProperties).     }     throw new SqlExecutionException("Unsupported execution type for sinks."). }
false;public;0;3;;public QueryConfig getQueryConfig() {     return queryConfig. }
false;public;0;3;;public ExecutionEnvironment getExecutionEnvironment() {     return execEnv. }
false;public;0;3;;public StreamExecutionEnvironment getStreamExecutionEnvironment() {     return streamExecEnv. }
false;public;0;3;;public TableEnvironment getTableEnvironment() {     return tableEnv. }
false;public;0;7;;public ExecutionConfig getExecutionConfig() {     if (streamExecEnv != null) {         return streamExecEnv.getConfig().     } else {         return execEnv.getConfig().     } }
false;public;1;9;;public JobGraph createJobGraph(String name) {     final FlinkPlan plan = createPlan(name, flinkConfig).     return ClusterClient.getJobGraph(flinkConfig, plan, dependencies, runOptions.getClasspaths(), runOptions.getSavepointRestoreSettings()). }
false;private;2;13;;private FlinkPlan createPlan(String name, Configuration flinkConfig) {     if (streamExecEnv != null) {         final StreamGraph graph = streamExecEnv.getStreamGraph().         graph.setJobName(name).         return graph.     } else {         final int parallelism = execEnv.getParallelism().         final Plan unoptimizedPlan = execEnv.createProgramPlan().         unoptimizedPlan.setJobName(name).         final Optimizer compiler = new Optimizer(new DataStatistics(), new DefaultCostEstimator(), flinkConfig).         return ClusterClient.getOptimizedPlan(compiler, unoptimizedPlan, parallelism).     } }
false;private;0;6;;private ExecutionEnvironment createExecutionEnvironment() {     final ExecutionEnvironment execEnv = ExecutionEnvironment.getExecutionEnvironment().     execEnv.setRestartStrategy(mergedEnv.getExecution().getRestartStrategy()).     execEnv.setParallelism(mergedEnv.getExecution().getParallelism()).     return execEnv. }
false;private;0;11;;private StreamExecutionEnvironment createStreamExecutionEnvironment() {     final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment().     env.setRestartStrategy(mergedEnv.getExecution().getRestartStrategy()).     env.setParallelism(mergedEnv.getExecution().getParallelism()).     env.setMaxParallelism(mergedEnv.getExecution().getMaxParallelism()).     env.setStreamTimeCharacteristic(mergedEnv.getExecution().getTimeCharacteristic()).     if (env.getStreamTimeCharacteristic() == TimeCharacteristic.EventTime) {         env.getConfig().setAutoWatermarkInterval(mergedEnv.getExecution().getPeriodicWatermarksInterval()).     }     return env. }
false;private;0;11;;private QueryConfig createQueryConfig() {     if (streamExecEnv != null) {         final StreamQueryConfig config = new StreamQueryConfig().         final long minRetention = mergedEnv.getExecution().getMinStateRetention().         final long maxRetention = mergedEnv.getExecution().getMaxStateRetention().         config.withIdleStateRetentionTime(Time.milliseconds(minRetention), Time.milliseconds(maxRetention)).         return config.     } else {         return new BatchQueryConfig().     } }
false;private;0;29;;private void registerFunctions() {     if (tableEnv instanceof StreamTableEnvironment) {         StreamTableEnvironment streamTableEnvironment = (StreamTableEnvironment) tableEnv.         functions.forEach((k, v) -> {             if (v instanceof ScalarFunction) {                 streamTableEnvironment.registerFunction(k, (ScalarFunction) v).             } else if (v instanceof AggregateFunction) {                 streamTableEnvironment.registerFunction(k, (AggregateFunction<?, ?>) v).             } else if (v instanceof TableFunction) {                 streamTableEnvironment.registerFunction(k, (TableFunction<?>) v).             } else {                 throw new SqlExecutionException("Unsupported function type: " + v.getClass().getName()).             }         }).     } else {         BatchTableEnvironment batchTableEnvironment = (BatchTableEnvironment) tableEnv.         functions.forEach((k, v) -> {             if (v instanceof ScalarFunction) {                 batchTableEnvironment.registerFunction(k, (ScalarFunction) v).             } else if (v instanceof AggregateFunction) {                 batchTableEnvironment.registerFunction(k, (AggregateFunction<?, ?>) v).             } else if (v instanceof TableFunction) {                 batchTableEnvironment.registerFunction(k, (TableFunction<?>) v).             } else {                 throw new SqlExecutionException("Unsupported function type: " + v.getClass().getName()).             }         }).     } }
false;private;1;9;;private void registerView(ViewEntry viewEntry) {     try {         tableEnv.registerTable(viewEntry.getName(), tableEnv.sqlQuery(viewEntry.getQuery())).     } catch (Exception e) {         throw new SqlExecutionException("Invalid view '" + viewEntry.getName() + "' with query:\n" + viewEntry.getQuery() + "\nCause: " + e.getMessage()).     } }
false;private;1;19;;private void registerTemporalTable(TemporalTableEntry temporalTableEntry) {     try {         final Table table = tableEnv.scan(temporalTableEntry.getHistoryTable()).         final TableFunction<?> function = table.createTemporalTableFunction(temporalTableEntry.getTimeAttribute(), String.join(",", temporalTableEntry.getPrimaryKeyFields())).         if (tableEnv instanceof StreamTableEnvironment) {             StreamTableEnvironment streamTableEnvironment = (StreamTableEnvironment) tableEnv.             streamTableEnvironment.registerFunction(temporalTableEntry.getName(), function).         } else {             BatchTableEnvironment batchTableEnvironment = (BatchTableEnvironment) tableEnv.             batchTableEnvironment.registerFunction(temporalTableEntry.getName(), function).         }     } catch (Exception e) {         throw new SqlExecutionException("Invalid temporal table '" + temporalTableEntry.getName() + "' over table '" + temporalTableEntry.getHistoryTable() + ".\nCause: " + e.getMessage()).     } }
