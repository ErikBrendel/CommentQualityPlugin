commented;modifiers;parameterAmount;loc;comment;code
false;public;0;3;;public String getTopic() {     return topic. }
true;public;1;3;/**  * Sets the name of the Kafka topic used by this idempotent repository. Each functionally-separate repository  * should use a different topic.  * @param topic The topic name.  */ ;/**  * Sets the name of the Kafka topic used by this idempotent repository. Each functionally-separate repository  * should use a different topic.  * @param topic The topic name.  */ public void setTopic(String topic) {     this.topic = topic. }
false;public;0;3;;public String getBootstrapServers() {     return bootstrapServers. }
true;public;1;3;/**  * Sets the <pre>bootstrap.servers</pre> property on the internal Kafka producer and consumer. Use this as shorthand  * if not setting {@link #consumerConfig} and {@link #producerConfig}. If used, this component will apply sensible  * default configurations for the producer and consumer.  * @param bootstrapServers The <pre>bootstrap.servers</pre> value to use.  */ ;/**  * Sets the <pre>bootstrap.servers</pre> property on the internal Kafka producer and consumer. Use this as shorthand  * if not setting {@link #consumerConfig} and {@link #producerConfig}. If used, this component will apply sensible  * default configurations for the producer and consumer.  * @param bootstrapServers The <pre>bootstrap.servers</pre> value to use.  */ public void setBootstrapServers(String bootstrapServers) {     this.bootstrapServers = bootstrapServers. }
false;public;0;3;;public Properties getProducerConfig() {     return producerConfig. }
true;public;1;3;/**  * Sets the properties that will be used by the Kafka producer. Overrides {@link #bootstrapServers}, so must define  * the <pre>bootstrap.servers</pre> property itself.  *  * Prefer using {@link #bootstrapServers} for default configuration unless you specifically need non-standard  * configuration options such as SSL/SASL.  * @param producerConfig The producer configuration properties.  */ ;/**  * Sets the properties that will be used by the Kafka producer. Overrides {@link #bootstrapServers}, so must define  * the <pre>bootstrap.servers</pre> property itself.  *  * Prefer using {@link #bootstrapServers} for default configuration unless you specifically need non-standard  * configuration options such as SSL/SASL.  * @param producerConfig The producer configuration properties.  */ public void setProducerConfig(Properties producerConfig) {     this.producerConfig = producerConfig. }
false;public;0;3;;public Properties getConsumerConfig() {     return consumerConfig. }
true;public;1;3;/**  * Sets the properties that will be used by the Kafka consumer. Overrides {@link #bootstrapServers}, so must define  * the <pre>bootstrap.servers</pre> property itself.  *  * Prefer using {@link #bootstrapServers} for default configuration unless you specifically need non-standard  * configuration options such as SSL/SASL.  * @param consumerConfig The consumer configuration properties.  */ ;/**  * Sets the properties that will be used by the Kafka consumer. Overrides {@link #bootstrapServers}, so must define  * the <pre>bootstrap.servers</pre> property itself.  *  * Prefer using {@link #bootstrapServers} for default configuration unless you specifically need non-standard  * configuration options such as SSL/SASL.  * @param consumerConfig The consumer configuration properties.  */ public void setConsumerConfig(Properties consumerConfig) {     this.consumerConfig = consumerConfig. }
false;public;0;3;;public int getMaxCacheSize() {     return maxCacheSize. }
true;public;1;3;/**  * Sets the maximum size of the local key cache.  * @param maxCacheSize The maximum key cache size.  */ ;/**  * Sets the maximum size of the local key cache.  * @param maxCacheSize The maximum key cache size.  */ public void setMaxCacheSize(int maxCacheSize) {     this.maxCacheSize = maxCacheSize. }
false;public;0;3;;public int getPollDurationMs() {     return pollDurationMs. }
true;public;1;3;/**  * Sets the poll duration of the Kafka consumer. The local caches are updated immediately. this value will affect  * how far behind other peers in the cluster are, which are updating their caches from the topic, relative to the  * idempotent consumer instance issued the cache action message.  *  * The default value of this is {@link #DEFAULT_POLL_DURATION_MS}. If setting this value explicitly, be aware that  * there is a tradeoff between the remote cache liveness and the volume of network traffic between this repository's  * consumer and the Kafka brokers.  *  * The cache warmup process also depends on there being one poll that fetches nothing - this indicates that the  * stream has been consumed up to the current point. If the poll duration is excessively long for the rate at  * which messages are sent on the topic, there exists a possibility that the cache cannot be warmed up and will  * operate in an inconsistent state relative to its peers until it catches up.  * @param pollDurationMs The poll duration in milliseconds.  */ ;/**  * Sets the poll duration of the Kafka consumer. The local caches are updated immediately. this value will affect  * how far behind other peers in the cluster are, which are updating their caches from the topic, relative to the  * idempotent consumer instance issued the cache action message.  *  * The default value of this is {@link #DEFAULT_POLL_DURATION_MS}. If setting this value explicitly, be aware that  * there is a tradeoff between the remote cache liveness and the volume of network traffic between this repository's  * consumer and the Kafka brokers.  *  * The cache warmup process also depends on there being one poll that fetches nothing - this indicates that the  * stream has been consumed up to the current point. If the poll duration is excessively long for the rate at  * which messages are sent on the topic, there exists a possibility that the cache cannot be warmed up and will  * operate in an inconsistent state relative to its peers until it catches up.  * @param pollDurationMs The poll duration in milliseconds.  */ public void setPollDurationMs(int pollDurationMs) {     this.pollDurationMs = pollDurationMs. }
false;public;1;4;;@Override public void setCamelContext(CamelContext camelContext) {     this.camelContext = camelContext. }
false;public;0;4;;@Override public CamelContext getCamelContext() {     return this.camelContext. }
false;protected;0;59;;@Override @SuppressWarnings("unchecked") protected void doStart() throws Exception {     ObjectHelper.notNull(camelContext, "camelContext").     StringHelper.notEmpty(topic, "topic").     this.cache = LRUCacheFactory.newLRUCache(maxCacheSize).     if (consumerConfig == null) {         consumerConfig = new Properties().         StringHelper.notEmpty(bootstrapServers, "bootstrapServers").         consumerConfig.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers).     }     if (producerConfig == null) {         producerConfig = new Properties().         StringHelper.notEmpty(bootstrapServers, "bootstrapServers").         producerConfig.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers).     }     ObjectHelper.notNull(consumerConfig, "consumerConfig").     ObjectHelper.notNull(producerConfig, "producerConfig").     // each consumer instance must have control over its own offset, so assign a groupID at random     String groupId = UUID.randomUUID().toString().     log.debug("Creating consumer with {}[{}]", ConsumerConfig.GROUP_ID_CONFIG, groupId).     consumerConfig.put(ConsumerConfig.GROUP_ID_CONFIG, groupId).     consumerConfig.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, Boolean.TRUE.toString()).     consumerConfig.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()).     consumerConfig.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()).     consumer = new KafkaConsumer<>(consumerConfig).     producerConfig.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()).     producerConfig.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()).     // set up the producer to remove all batching on send, we want all sends to be fully synchronous     producerConfig.putIfAbsent(ProducerConfig.ACKS_CONFIG, "1").     producerConfig.putIfAbsent(ProducerConfig.BATCH_SIZE_CONFIG, "0").     producer = new KafkaProducer<>(producerConfig).     cacheReadyLatch = new CountDownLatch(1).     topicPoller = new TopicPoller(consumer, cacheReadyLatch, pollDurationMs).     // warm up the cache     executorService = camelContext.getExecutorServiceManager().newSingleThreadExecutor(this, "KafkaIdempotentRepository").     executorService.submit(topicPoller).     log.info("Warming up cache from topic {}", topic).     try {         if (cacheReadyLatch.await(30, TimeUnit.SECONDS)) {             log.info("Cache OK").         } else {             log.warn("Timeout waiting for cache warm-up from topic {}. Proceeding anyway. " + "Duplicate records may not be detected.", topic).         }     } catch (InterruptedException e) {         log.warn("Interrupted while warming up cache. This exception is ignored.", e.getMessage()).     } }
false;protected;0;18;;@Override protected void doStop() {     // stop the thread     topicPoller.setRunning(false).     try {         if (topicPoller.getShutdownLatch().await(30, TimeUnit.SECONDS)) {             log.info("Cache from topic {} shutdown successfully", topic).         } else {             log.warn("Timeout waiting for cache to shutdown from topic {}. Proceeding anyway.", topic).         }     } catch (InterruptedException e) {         log.warn("Interrupted waiting on shutting down cache due {}. This exception is ignored.", e.getMessage()).     }     camelContext.getExecutorServiceManager().shutdown(executorService).     IOHelper.close(consumer, "consumer", log).     IOHelper.close(producer, "producer", log). }
false;public;1;13;;@Override public boolean add(String key) {     if (cache.containsKey(key)) {         duplicateCount.incrementAndGet().         return false.     } else {         // update the local cache and broadcast the addition on the topic, which will be reflected         // at a later point in any peers         cache.put(key, key).         broadcastAction(key, CacheAction.add).         return true.     } }
false;private;2;8;;private void broadcastAction(String key, CacheAction action) {     try {         log.debug("Broadcasting action:{} for key:{}", action, key).         // sync send         producer.send(new ProducerRecord<>(topic, key, action.toString())).get().     } catch (ExecutionException | InterruptedException e) {         throw new RuntimeException(e).     } }
false;public;1;10;;@Override @ManagedOperation(description = "Does the store contain the given key") public boolean contains(String key) {     log.debug("Checking cache for key:{}", key).     boolean containsKey = cache.containsKey(key).     if (containsKey) {         duplicateCount.incrementAndGet().     }     return containsKey. }
false;public;1;9;;@Override @ManagedOperation(description = "Remove the key from the store") public boolean remove(String key) {     // update the local cache and broadcast the addition on the topic, which will be reflected     // at a later point in any peers     cache.remove(key, key).     broadcastAction(key, CacheAction.remove).     return true. }
false;public;1;4;;@Override public boolean confirm(String key) {     // no-op     return true. }
false;public;0;4;;@Override public void clear() {     broadcastAction(null, CacheAction.clear). }
false;public;0;4;;@ManagedOperation(description = "Number of times duplicate messages have been detected") public long getDuplicateCount() {     return duplicateCount.get(). }
false;public;0;4;;@ManagedOperation(description = "Number of times duplicate messages have been detected") public boolean isPollerRunning() {     return topicPoller.isRunning(). }
false;public;0;50;;@Override public void run() {     log.debug("Subscribing consumer to {}", topic).     consumer.subscribe(Collections.singleton(topic)).     log.debug("Seeking to beginning").     consumer.seekToBeginning(consumer.assignment()).     POLL_LOOP: while (running.get()) {         log.trace("Polling").         ConsumerRecords<String, String> consumerRecords = consumer.poll(pollDurationMs).         if (consumerRecords.isEmpty()) {             // the first time this happens, we can assume that we have consumed all             // messages up to this point             log.trace("0 messages fetched on poll").             if (cacheReadyLatch.getCount() > 0) {                 log.debug("Cache warmed up").                 cacheReadyLatch.countDown().             }         }         for (ConsumerRecord<String, String> consumerRecord : consumerRecords) {             CacheAction action.             try {                 action = CacheAction.valueOf(consumerRecord.value()).             } catch (IllegalArgumentException iax) {                 log.error("Unexpected action value:\"{}\" received on [topic:{}, partition:{}, offset:{}]. Shutting down.", consumerRecord.key(), consumerRecord.topic(), consumerRecord.partition(), consumerRecord.offset()).                 setRunning(false).                 continue POLL_LOOP.             }             String messageId = consumerRecord.key().             if (action == CacheAction.add) {                 log.debug("Adding to cache messageId:{}", messageId).                 cache.put(messageId, messageId).             } else if (action == CacheAction.remove) {                 log.debug("Removing from cache messageId:{}", messageId).                 cache.remove(messageId).             } else if (action == CacheAction.clear) {                 cache.clear().             } else {                 // this should never happen                 log.warn("No idea how to {} a record. Shutting down.", action).                 setRunning(false).                 continue POLL_LOOP.             }         }     }     log.debug("TopicPoller finished - triggering shutdown latch").     shutdownLatch.countDown(). }
false;;0;3;;CountDownLatch getShutdownLatch() {     return shutdownLatch. }
false;;1;3;;void setRunning(boolean running) {     this.running.set(running). }
false;;0;3;;boolean isRunning() {     return running.get(). }
false;public;0;4;;@Override public String toString() {     return "TopicPoller[" + topic + "]". }
