commented;modifiers;parameterAmount;loc;comment;code
false;public;0;4;;@Override public KafkaComponent getComponent() {     return (KafkaComponent) super.getComponent(). }
false;public;0;3;;public KafkaConfiguration getConfiguration() {     return configuration. }
false;public;1;3;;public void setConfiguration(KafkaConfiguration configuration) {     this.configuration = configuration. }
false;public;1;6;;@Override public Consumer createConsumer(Processor processor) throws Exception {     KafkaConsumer consumer = new KafkaConsumer(this, processor).     configureConsumer(consumer).     return consumer. }
false;public;0;9;;@Override public Producer createProducer() throws Exception {     KafkaProducer producer = createProducer(this).     if (isSynchronous()) {         return new SynchronousDelegateProducer(producer).     } else {         return producer.     } }
false;public;0;4;;@Override public boolean isSingleton() {     return true. }
false;public;0;4;;@Override public boolean isMultipleConsumersSupported() {     return true. }
false;private;2;3;;private void loadParitionerClass(ClassResolver resolver, Properties props) {     replaceWithClass(props, "partitioner.class", resolver, Partitioner.class). }
false;;3;14;;<T> Class<T> loadClass(Object o, ClassResolver resolver, Class<T> type) {     if (o == null || o instanceof Class) {         return CastUtils.cast((Class<?>) o).     }     String name = o.toString().     Class<T> c = resolver.resolveClass(name, type).     if (c == null) {         c = resolver.resolveClass(name, type, getClass().getClassLoader()).     }     if (c == null) {         c = resolver.resolveClass(name, type, org.apache.kafka.clients.producer.KafkaProducer.class.getClassLoader()).     }     return c. }
false;;4;6;;void replaceWithClass(Properties props, String key, ClassResolver resolver, Class<?> type) {     Class<?> c = loadClass(props.get(key), resolver, type).     if (c != null) {         props.put(key, c).     } }
false;public;1;29;;public void updateClassProperties(Properties props) {     try {         if (getCamelContext() != null) {             ClassResolver resolver = getCamelContext().getClassResolver().             replaceWithClass(props, ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, resolver, Serializer.class).             replaceWithClass(props, ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, resolver, Serializer.class).             replaceWithClass(props, ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, resolver, Deserializer.class).             replaceWithClass(props, ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, resolver, Deserializer.class).             try {                 // doesn't exist in old version of Kafka client so detect and only call the method if                 // the field/config actually exists                 Field f = ProducerConfig.class.getDeclaredField("PARTITIONER_CLASS_CONFIG").                 if (f != null) {                     loadParitionerClass(resolver, props).                 }             } catch (NoSuchFieldException e) {             // ignore             } catch (SecurityException e) {             // ignore             }         // doesn't work as it needs to be List<String>  :(         // replaceWithClass(props, "partition.assignment.strategy", resolver, PartitionAssignor.class).         }     } catch (Throwable t) {         // can ignore and Kafka itself might be able to handle it, if not, it will throw an exception         log.debug("Problem loading classes for Serializers", t).     } }
false;public;0;3;;public ExecutorService createExecutor() {     return getCamelContext().getExecutorServiceManager().newFixedThreadPool(this, "KafkaConsumer[" + configuration.getTopic() + "]", configuration.getConsumerStreams()). }
false;public;0;5;;public ExecutorService createProducerExecutor() {     int core = getConfiguration().getWorkerPoolCoreSize().     int max = getConfiguration().getWorkerPoolMaxSize().     return getCamelContext().getExecutorServiceManager().newThreadPool(this, "KafkaProducer[" + configuration.getTopic() + "]", core, max). }
false;public;1;17;;@SuppressWarnings("rawtypes") public Exchange createKafkaExchange(ConsumerRecord record) {     Exchange exchange = super.createExchange().     Message message = exchange.getIn().     message.setHeader(KafkaConstants.PARTITION, record.partition()).     message.setHeader(KafkaConstants.TOPIC, record.topic()).     message.setHeader(KafkaConstants.OFFSET, record.offset()).     message.setHeader(KafkaConstants.HEADERS, record.headers()).     message.setHeader(KafkaConstants.TIMESTAMP, record.timestamp()).     if (record.key() != null) {         message.setHeader(KafkaConstants.KEY, record.key()).     }     message.setBody(record.value()).     return exchange. }
false;protected;1;3;;protected KafkaProducer createProducer(KafkaEndpoint endpoint) {     return new KafkaProducer(endpoint). }
