# id;timestamp;commentText;codeText;commentWords;codeWords
HdfsConfiguration -> public void setBufferSize(int bufferSize);1430993079;The buffer size used by HDFS;public void setBufferSize(int bufferSize) {_        this.bufferSize = bufferSize__    };the,buffer,size,used,by,hdfs;public,void,set,buffer,size,int,buffer,size,this,buffer,size,buffer,size
HdfsConfiguration -> public void setBufferSize(int bufferSize);1452076589;The buffer size used by HDFS;public void setBufferSize(int bufferSize) {_        this.bufferSize = bufferSize__    };the,buffer,size,used,by,hdfs;public,void,set,buffer,size,int,buffer,size,this,buffer,size,buffer,size
HdfsConfiguration -> public void setBufferSize(int bufferSize);1463211772;The buffer size used by HDFS;public void setBufferSize(int bufferSize) {_        this.bufferSize = bufferSize__    };the,buffer,size,used,by,hdfs;public,void,set,buffer,size,int,buffer,size,this,buffer,size,buffer,size
HdfsConfiguration -> public void setBufferSize(int bufferSize);1488802432;The buffer size used by HDFS;public void setBufferSize(int bufferSize) {_        this.bufferSize = bufferSize__    };the,buffer,size,used,by,hdfs;public,void,set,buffer,size,int,buffer,size,this,buffer,size,buffer,size
HdfsConfiguration -> public void setBufferSize(int bufferSize);1504000981;The buffer size used by HDFS;public void setBufferSize(int bufferSize) {_        this.bufferSize = bufferSize__    };the,buffer,size,used,by,hdfs;public,void,set,buffer,size,int,buffer,size,this,buffer,size,buffer,size
HdfsConfiguration -> public void setBufferSize(int bufferSize);1523994367;The buffer size used by HDFS;public void setBufferSize(int bufferSize) {_        this.bufferSize = bufferSize__    };the,buffer,size,used,by,hdfs;public,void,set,buffer,size,int,buffer,size,this,buffer,size,buffer,size
HdfsConfiguration -> public void setBufferSize(int bufferSize);1547240981;The buffer size used by HDFS;public void setBufferSize(int bufferSize) {_        this.bufferSize = bufferSize__    };the,buffer,size,used,by,hdfs;public,void,set,buffer,size,int,buffer,size,this,buffer,size,buffer,size
HdfsConfiguration -> public void setPort(int port);1430993079;HDFS port to use;public void setPort(int port) {_        this.port = port__    };hdfs,port,to,use;public,void,set,port,int,port,this,port,port
HdfsConfiguration -> public void setPort(int port);1452076589;HDFS port to use;public void setPort(int port) {_        this.port = port__    };hdfs,port,to,use;public,void,set,port,int,port,this,port,port
HdfsConfiguration -> public void setPort(int port);1463211772;HDFS port to use;public void setPort(int port) {_        this.port = port__    };hdfs,port,to,use;public,void,set,port,int,port,this,port,port
HdfsConfiguration -> public void setPort(int port);1488802432;HDFS port to use;public void setPort(int port) {_        this.port = port__    };hdfs,port,to,use;public,void,set,port,int,port,this,port,port
HdfsConfiguration -> public void setPort(int port);1504000981;HDFS port to use;public void setPort(int port) {_        this.port = port__    };hdfs,port,to,use;public,void,set,port,int,port,this,port,port
HdfsConfiguration -> public void setPort(int port);1523994367;HDFS port to use;public void setPort(int port) {_        this.port = port__    };hdfs,port,to,use;public,void,set,port,int,port,this,port,port
HdfsConfiguration -> public void setPort(int port);1547240981;HDFS port to use;public void setPort(int port) {_        this.port = port__    };hdfs,port,to,use;public,void,set,port,int,port,this,port,port
HdfsConfiguration -> public void setPath(String path);1430993079;The directory path to use;public void setPath(String path) {_        this.path = path__    };the,directory,path,to,use;public,void,set,path,string,path,this,path,path
HdfsConfiguration -> public void setPath(String path);1452076589;The directory path to use;public void setPath(String path) {_        this.path = path__    };the,directory,path,to,use;public,void,set,path,string,path,this,path,path
HdfsConfiguration -> public void setPath(String path);1463211772;The directory path to use;public void setPath(String path) {_        this.path = path__    };the,directory,path,to,use;public,void,set,path,string,path,this,path,path
HdfsConfiguration -> public void setPath(String path);1488802432;The directory path to use;public void setPath(String path) {_        this.path = path__    };the,directory,path,to,use;public,void,set,path,string,path,this,path,path
HdfsConfiguration -> public void setPath(String path);1504000981;The directory path to use;public void setPath(String path) {_        this.path = path__    };the,directory,path,to,use;public,void,set,path,string,path,this,path,path
HdfsConfiguration -> public void setPath(String path);1523994367;The directory path to use;public void setPath(String path) {_        this.path = path__    };the,directory,path,to,use;public,void,set,path,string,path,this,path,path
HdfsConfiguration -> public void setPath(String path);1547240981;The directory path to use;public void setPath(String path) {_        this.path = path__    };the,directory,path,to,use;public,void,set,path,string,path,this,path,path
HdfsConfiguration -> public void setCompressionCodec(HdfsCompressionCodec compressionCodec);1430993079;The compression codec to use;public void setCompressionCodec(HdfsCompressionCodec compressionCodec) {_        this.compressionCodec = compressionCodec__    };the,compression,codec,to,use;public,void,set,compression,codec,hdfs,compression,codec,compression,codec,this,compression,codec,compression,codec
HdfsConfiguration -> public void setCompressionCodec(HdfsCompressionCodec compressionCodec);1452076589;The compression codec to use;public void setCompressionCodec(HdfsCompressionCodec compressionCodec) {_        this.compressionCodec = compressionCodec__    };the,compression,codec,to,use;public,void,set,compression,codec,hdfs,compression,codec,compression,codec,this,compression,codec,compression,codec
HdfsConfiguration -> public void setCompressionCodec(HdfsCompressionCodec compressionCodec);1463211772;The compression codec to use;public void setCompressionCodec(HdfsCompressionCodec compressionCodec) {_        this.compressionCodec = compressionCodec__    };the,compression,codec,to,use;public,void,set,compression,codec,hdfs,compression,codec,compression,codec,this,compression,codec,compression,codec
HdfsConfiguration -> public void setCompressionCodec(HdfsCompressionCodec compressionCodec);1488802432;The compression codec to use;public void setCompressionCodec(HdfsCompressionCodec compressionCodec) {_        this.compressionCodec = compressionCodec__    };the,compression,codec,to,use;public,void,set,compression,codec,hdfs,compression,codec,compression,codec,this,compression,codec,compression,codec
HdfsConfiguration -> public void setCompressionCodec(HdfsCompressionCodec compressionCodec);1504000981;The compression codec to use;public void setCompressionCodec(HdfsCompressionCodec compressionCodec) {_        this.compressionCodec = compressionCodec__    };the,compression,codec,to,use;public,void,set,compression,codec,hdfs,compression,codec,compression,codec,this,compression,codec,compression,codec
HdfsConfiguration -> public void setCompressionCodec(HdfsCompressionCodec compressionCodec);1523994367;The compression codec to use;public void setCompressionCodec(HdfsCompressionCodec compressionCodec) {_        this.compressionCodec = compressionCodec__    };the,compression,codec,to,use;public,void,set,compression,codec,hdfs,compression,codec,compression,codec,this,compression,codec,compression,codec
HdfsConfiguration -> public void setCompressionCodec(HdfsCompressionCodec compressionCodec);1547240981;The compression codec to use;public void setCompressionCodec(HdfsCompressionCodec compressionCodec) {_        this.compressionCodec = compressionCodec__    };the,compression,codec,to,use;public,void,set,compression,codec,hdfs,compression,codec,compression,codec,this,compression,codec,compression,codec
HdfsConfiguration -> public void setOverwrite(boolean overwrite);1430993079;Whether to overwrite existing files with the same name;public void setOverwrite(boolean overwrite) {_        this.overwrite = overwrite__    };whether,to,overwrite,existing,files,with,the,same,name;public,void,set,overwrite,boolean,overwrite,this,overwrite,overwrite
HdfsConfiguration -> public void setOverwrite(boolean overwrite);1452076589;Whether to overwrite existing files with the same name;public void setOverwrite(boolean overwrite) {_        this.overwrite = overwrite__    };whether,to,overwrite,existing,files,with,the,same,name;public,void,set,overwrite,boolean,overwrite,this,overwrite,overwrite
HdfsConfiguration -> public void setOverwrite(boolean overwrite);1463211772;Whether to overwrite existing files with the same name;public void setOverwrite(boolean overwrite) {_        this.overwrite = overwrite__    };whether,to,overwrite,existing,files,with,the,same,name;public,void,set,overwrite,boolean,overwrite,this,overwrite,overwrite
HdfsConfiguration -> public void setOverwrite(boolean overwrite);1488802432;Whether to overwrite existing files with the same name;public void setOverwrite(boolean overwrite) {_        this.overwrite = overwrite__    };whether,to,overwrite,existing,files,with,the,same,name;public,void,set,overwrite,boolean,overwrite,this,overwrite,overwrite
HdfsConfiguration -> public void setOverwrite(boolean overwrite);1504000981;Whether to overwrite existing files with the same name;public void setOverwrite(boolean overwrite) {_        this.overwrite = overwrite__    };whether,to,overwrite,existing,files,with,the,same,name;public,void,set,overwrite,boolean,overwrite,this,overwrite,overwrite
HdfsConfiguration -> public void setOverwrite(boolean overwrite);1523994367;Whether to overwrite existing files with the same name;public void setOverwrite(boolean overwrite) {_        this.overwrite = overwrite__    };whether,to,overwrite,existing,files,with,the,same,name;public,void,set,overwrite,boolean,overwrite,this,overwrite,overwrite
HdfsConfiguration -> public void setOverwrite(boolean overwrite);1547240981;Whether to overwrite existing files with the same name;public void setOverwrite(boolean overwrite) {_        this.overwrite = overwrite__    };whether,to,overwrite,existing,files,with,the,same,name;public,void,set,overwrite,boolean,overwrite,this,overwrite,overwrite
HdfsConfiguration -> public void setOpenedSuffix(String openedSuffix);1430993079;When a file is opened for reading/writing the file is renamed with this suffix to avoid to read it during the writing phase.;public void setOpenedSuffix(String openedSuffix) {_        this.openedSuffix = openedSuffix__    };when,a,file,is,opened,for,reading,writing,the,file,is,renamed,with,this,suffix,to,avoid,to,read,it,during,the,writing,phase;public,void,set,opened,suffix,string,opened,suffix,this,opened,suffix,opened,suffix
HdfsConfiguration -> public void setOpenedSuffix(String openedSuffix);1452076589;When a file is opened for reading/writing the file is renamed with this suffix to avoid to read it during the writing phase.;public void setOpenedSuffix(String openedSuffix) {_        this.openedSuffix = openedSuffix__    };when,a,file,is,opened,for,reading,writing,the,file,is,renamed,with,this,suffix,to,avoid,to,read,it,during,the,writing,phase;public,void,set,opened,suffix,string,opened,suffix,this,opened,suffix,opened,suffix
HdfsConfiguration -> public void setOpenedSuffix(String openedSuffix);1463211772;When a file is opened for reading/writing the file is renamed with this suffix to avoid to read it during the writing phase.;public void setOpenedSuffix(String openedSuffix) {_        this.openedSuffix = openedSuffix__    };when,a,file,is,opened,for,reading,writing,the,file,is,renamed,with,this,suffix,to,avoid,to,read,it,during,the,writing,phase;public,void,set,opened,suffix,string,opened,suffix,this,opened,suffix,opened,suffix
HdfsConfiguration -> public void setOpenedSuffix(String openedSuffix);1488802432;When a file is opened for reading/writing the file is renamed with this suffix to avoid to read it during the writing phase.;public void setOpenedSuffix(String openedSuffix) {_        this.openedSuffix = openedSuffix__    };when,a,file,is,opened,for,reading,writing,the,file,is,renamed,with,this,suffix,to,avoid,to,read,it,during,the,writing,phase;public,void,set,opened,suffix,string,opened,suffix,this,opened,suffix,opened,suffix
HdfsConfiguration -> public void setOpenedSuffix(String openedSuffix);1504000981;When a file is opened for reading/writing the file is renamed with this suffix to avoid to read it during the writing phase.;public void setOpenedSuffix(String openedSuffix) {_        this.openedSuffix = openedSuffix__    };when,a,file,is,opened,for,reading,writing,the,file,is,renamed,with,this,suffix,to,avoid,to,read,it,during,the,writing,phase;public,void,set,opened,suffix,string,opened,suffix,this,opened,suffix,opened,suffix
HdfsConfiguration -> public void setOpenedSuffix(String openedSuffix);1523994367;When a file is opened for reading/writing the file is renamed with this suffix to avoid to read it during the writing phase.;public void setOpenedSuffix(String openedSuffix) {_        this.openedSuffix = openedSuffix__    };when,a,file,is,opened,for,reading,writing,the,file,is,renamed,with,this,suffix,to,avoid,to,read,it,during,the,writing,phase;public,void,set,opened,suffix,string,opened,suffix,this,opened,suffix,opened,suffix
HdfsConfiguration -> public void setOpenedSuffix(String openedSuffix);1547240981;When a file is opened for reading/writing the file is renamed with this suffix to avoid to read it during the writing phase.;public void setOpenedSuffix(String openedSuffix) {_        this.openedSuffix = openedSuffix__    };when,a,file,is,opened,for,reading,writing,the,file,is,renamed,with,this,suffix,to,avoid,to,read,it,during,the,writing,phase;public,void,set,opened,suffix,string,opened,suffix,this,opened,suffix,opened,suffix
HdfsConfiguration -> public void setCheckIdleInterval(int checkIdleInterval);1430993079;How often (time in millis) in to run the idle checker background task. This option is only in use if the splitter strategy is IDLE.;public void setCheckIdleInterval(int checkIdleInterval) {_        this.checkIdleInterval = checkIdleInterval__    };how,often,time,in,millis,in,to,run,the,idle,checker,background,task,this,option,is,only,in,use,if,the,splitter,strategy,is,idle;public,void,set,check,idle,interval,int,check,idle,interval,this,check,idle,interval,check,idle,interval
HdfsConfiguration -> public void setCheckIdleInterval(int checkIdleInterval);1452076589;How often (time in millis) in to run the idle checker background task. This option is only in use if the splitter strategy is IDLE.;public void setCheckIdleInterval(int checkIdleInterval) {_        this.checkIdleInterval = checkIdleInterval__    };how,often,time,in,millis,in,to,run,the,idle,checker,background,task,this,option,is,only,in,use,if,the,splitter,strategy,is,idle;public,void,set,check,idle,interval,int,check,idle,interval,this,check,idle,interval,check,idle,interval
HdfsConfiguration -> public void setCheckIdleInterval(int checkIdleInterval);1463211772;How often (time in millis) in to run the idle checker background task. This option is only in use if the splitter strategy is IDLE.;public void setCheckIdleInterval(int checkIdleInterval) {_        this.checkIdleInterval = checkIdleInterval__    };how,often,time,in,millis,in,to,run,the,idle,checker,background,task,this,option,is,only,in,use,if,the,splitter,strategy,is,idle;public,void,set,check,idle,interval,int,check,idle,interval,this,check,idle,interval,check,idle,interval
HdfsConfiguration -> public void setCheckIdleInterval(int checkIdleInterval);1488802432;How often (time in millis) in to run the idle checker background task. This option is only in use if the splitter strategy is IDLE.;public void setCheckIdleInterval(int checkIdleInterval) {_        this.checkIdleInterval = checkIdleInterval__    };how,often,time,in,millis,in,to,run,the,idle,checker,background,task,this,option,is,only,in,use,if,the,splitter,strategy,is,idle;public,void,set,check,idle,interval,int,check,idle,interval,this,check,idle,interval,check,idle,interval
HdfsConfiguration -> public void setCheckIdleInterval(int checkIdleInterval);1504000981;How often (time in millis) in to run the idle checker background task. This option is only in use if the splitter strategy is IDLE.;public void setCheckIdleInterval(int checkIdleInterval) {_        this.checkIdleInterval = checkIdleInterval__    };how,often,time,in,millis,in,to,run,the,idle,checker,background,task,this,option,is,only,in,use,if,the,splitter,strategy,is,idle;public,void,set,check,idle,interval,int,check,idle,interval,this,check,idle,interval,check,idle,interval
HdfsConfiguration -> public void setCheckIdleInterval(int checkIdleInterval);1523994367;How often (time in millis) in to run the idle checker background task. This option is only in use if the splitter strategy is IDLE.;public void setCheckIdleInterval(int checkIdleInterval) {_        this.checkIdleInterval = checkIdleInterval__    };how,often,time,in,millis,in,to,run,the,idle,checker,background,task,this,option,is,only,in,use,if,the,splitter,strategy,is,idle;public,void,set,check,idle,interval,int,check,idle,interval,this,check,idle,interval,check,idle,interval
HdfsConfiguration -> public void setCheckIdleInterval(int checkIdleInterval);1547240981;How often (time in millis) in to run the idle checker background task. This option is only in use if the splitter strategy is IDLE.;public void setCheckIdleInterval(int checkIdleInterval) {_        this.checkIdleInterval = checkIdleInterval__    };how,often,time,in,millis,in,to,run,the,idle,checker,background,task,this,option,is,only,in,use,if,the,splitter,strategy,is,idle;public,void,set,check,idle,interval,int,check,idle,interval,this,check,idle,interval,check,idle,interval
HdfsConfiguration -> public void setReplication(short replication);1430993079;The HDFS replication factor;public void setReplication(short replication) {_        this.replication = replication__    };the,hdfs,replication,factor;public,void,set,replication,short,replication,this,replication,replication
HdfsConfiguration -> public void setReplication(short replication);1452076589;The HDFS replication factor;public void setReplication(short replication) {_        this.replication = replication__    };the,hdfs,replication,factor;public,void,set,replication,short,replication,this,replication,replication
HdfsConfiguration -> public void setReplication(short replication);1463211772;The HDFS replication factor;public void setReplication(short replication) {_        this.replication = replication__    };the,hdfs,replication,factor;public,void,set,replication,short,replication,this,replication,replication
HdfsConfiguration -> public void setReplication(short replication);1488802432;The HDFS replication factor;public void setReplication(short replication) {_        this.replication = replication__    };the,hdfs,replication,factor;public,void,set,replication,short,replication,this,replication,replication
HdfsConfiguration -> public void setReplication(short replication);1504000981;The HDFS replication factor;public void setReplication(short replication) {_        this.replication = replication__    };the,hdfs,replication,factor;public,void,set,replication,short,replication,this,replication,replication
HdfsConfiguration -> public void setReplication(short replication);1523994367;The HDFS replication factor;public void setReplication(short replication) {_        this.replication = replication__    };the,hdfs,replication,factor;public,void,set,replication,short,replication,this,replication,replication
HdfsConfiguration -> public void setReplication(short replication);1547240981;The HDFS replication factor;public void setReplication(short replication) {_        this.replication = replication__    };the,hdfs,replication,factor;public,void,set,replication,short,replication,this,replication,replication
HdfsConfiguration -> public void setDelay(long delay);1430993079;The interval (milliseconds) between the directory scans.;public void setDelay(long delay) {_        this.delay = delay__    };the,interval,milliseconds,between,the,directory,scans;public,void,set,delay,long,delay,this,delay,delay
HdfsConfiguration -> public void setDelay(long delay);1452076589;The interval (milliseconds) between the directory scans.;public void setDelay(long delay) {_        this.delay = delay__    };the,interval,milliseconds,between,the,directory,scans;public,void,set,delay,long,delay,this,delay,delay
HdfsConfiguration -> public void setDelay(long delay);1463211772;The interval (milliseconds) between the directory scans.;public void setDelay(long delay) {_        this.delay = delay__    };the,interval,milliseconds,between,the,directory,scans;public,void,set,delay,long,delay,this,delay,delay
HdfsConfiguration -> public void setDelay(long delay);1488802432;The interval (milliseconds) between the directory scans.;public void setDelay(long delay) {_        this.delay = delay__    };the,interval,milliseconds,between,the,directory,scans;public,void,set,delay,long,delay,this,delay,delay
HdfsConfiguration -> public void setSplitStrategy(String splitStrategy);1430993079;In the current version of Hadoop opening a file in append mode is disabled since it's not very reliable. So, for the moment,_it's only possible to create new files. The Camel HDFS endpoint tries to solve this problem in this way:_<ul>_<li>If the split strategy option has been defined, the hdfs path will be used as a directory and files will be created using the configured UuidGenerator.</li>_<li>Every time a splitting condition is met, a new file is created.</li>_</ul>_The splitStrategy option is defined as a string with the following syntax:_<br/><tt>splitStrategy=ST:value,ST:value,...</tt>_<br/>where ST can be:_<ul>_<li>BYTES a new file is created, and the old is closed when the number of written bytes is more than value</li>_<li>MESSAGES a new file is created, and the old is closed when the number of written messages is more than value</li>_<li>IDLE a new file is created, and the old is closed when no writing happened in the last value milliseconds</li>_</ul>;public void setSplitStrategy(String splitStrategy) {_        this.splitStrategy = splitStrategy__    };in,the,current,version,of,hadoop,opening,a,file,in,append,mode,is,disabled,since,it,s,not,very,reliable,so,for,the,moment,it,s,only,possible,to,create,new,files,the,camel,hdfs,endpoint,tries,to,solve,this,problem,in,this,way,ul,li,if,the,split,strategy,option,has,been,defined,the,hdfs,path,will,be,used,as,a,directory,and,files,will,be,created,using,the,configured,uuid,generator,li,li,every,time,a,splitting,condition,is,met,a,new,file,is,created,li,ul,the,split,strategy,option,is,defined,as,a,string,with,the,following,syntax,br,tt,split,strategy,st,value,st,value,tt,br,where,st,can,be,ul,li,bytes,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,bytes,is,more,than,value,li,li,messages,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,messages,is,more,than,value,li,li,idle,a,new,file,is,created,and,the,old,is,closed,when,no,writing,happened,in,the,last,value,milliseconds,li,ul;public,void,set,split,strategy,string,split,strategy,this,split,strategy,split,strategy
HdfsConfiguration -> public void setSplitStrategy(String splitStrategy);1452076589;In the current version of Hadoop opening a file in append mode is disabled since it's not very reliable. So, for the moment,_it's only possible to create new files. The Camel HDFS endpoint tries to solve this problem in this way:_<ul>_<li>If the split strategy option has been defined, the hdfs path will be used as a directory and files will be created using the configured UuidGenerator.</li>_<li>Every time a splitting condition is met, a new file is created.</li>_</ul>_The splitStrategy option is defined as a string with the following syntax:_<br/><tt>splitStrategy=ST:value,ST:value,...</tt>_<br/>where ST can be:_<ul>_<li>BYTES a new file is created, and the old is closed when the number of written bytes is more than value</li>_<li>MESSAGES a new file is created, and the old is closed when the number of written messages is more than value</li>_<li>IDLE a new file is created, and the old is closed when no writing happened in the last value milliseconds</li>_</ul>;public void setSplitStrategy(String splitStrategy) {_        this.splitStrategy = splitStrategy__    };in,the,current,version,of,hadoop,opening,a,file,in,append,mode,is,disabled,since,it,s,not,very,reliable,so,for,the,moment,it,s,only,possible,to,create,new,files,the,camel,hdfs,endpoint,tries,to,solve,this,problem,in,this,way,ul,li,if,the,split,strategy,option,has,been,defined,the,hdfs,path,will,be,used,as,a,directory,and,files,will,be,created,using,the,configured,uuid,generator,li,li,every,time,a,splitting,condition,is,met,a,new,file,is,created,li,ul,the,split,strategy,option,is,defined,as,a,string,with,the,following,syntax,br,tt,split,strategy,st,value,st,value,tt,br,where,st,can,be,ul,li,bytes,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,bytes,is,more,than,value,li,li,messages,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,messages,is,more,than,value,li,li,idle,a,new,file,is,created,and,the,old,is,closed,when,no,writing,happened,in,the,last,value,milliseconds,li,ul;public,void,set,split,strategy,string,split,strategy,this,split,strategy,split,strategy
HdfsConfiguration -> public void setSplitStrategy(String splitStrategy);1463211772;In the current version of Hadoop opening a file in append mode is disabled since it's not very reliable. So, for the moment,_it's only possible to create new files. The Camel HDFS endpoint tries to solve this problem in this way:_<ul>_<li>If the split strategy option has been defined, the hdfs path will be used as a directory and files will be created using the configured UuidGenerator.</li>_<li>Every time a splitting condition is met, a new file is created.</li>_</ul>_The splitStrategy option is defined as a string with the following syntax:_<br/><tt>splitStrategy=ST:value,ST:value,...</tt>_<br/>where ST can be:_<ul>_<li>BYTES a new file is created, and the old is closed when the number of written bytes is more than value</li>_<li>MESSAGES a new file is created, and the old is closed when the number of written messages is more than value</li>_<li>IDLE a new file is created, and the old is closed when no writing happened in the last value milliseconds</li>_</ul>;public void setSplitStrategy(String splitStrategy) {_        this.splitStrategy = splitStrategy__    };in,the,current,version,of,hadoop,opening,a,file,in,append,mode,is,disabled,since,it,s,not,very,reliable,so,for,the,moment,it,s,only,possible,to,create,new,files,the,camel,hdfs,endpoint,tries,to,solve,this,problem,in,this,way,ul,li,if,the,split,strategy,option,has,been,defined,the,hdfs,path,will,be,used,as,a,directory,and,files,will,be,created,using,the,configured,uuid,generator,li,li,every,time,a,splitting,condition,is,met,a,new,file,is,created,li,ul,the,split,strategy,option,is,defined,as,a,string,with,the,following,syntax,br,tt,split,strategy,st,value,st,value,tt,br,where,st,can,be,ul,li,bytes,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,bytes,is,more,than,value,li,li,messages,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,messages,is,more,than,value,li,li,idle,a,new,file,is,created,and,the,old,is,closed,when,no,writing,happened,in,the,last,value,milliseconds,li,ul;public,void,set,split,strategy,string,split,strategy,this,split,strategy,split,strategy
HdfsConfiguration -> public void setSplitStrategy(String splitStrategy);1488802432;In the current version of Hadoop opening a file in append mode is disabled since it's not very reliable. So, for the moment,_it's only possible to create new files. The Camel HDFS endpoint tries to solve this problem in this way:_<ul>_<li>If the split strategy option has been defined, the hdfs path will be used as a directory and files will be created using the configured UuidGenerator.</li>_<li>Every time a splitting condition is met, a new file is created.</li>_</ul>_The splitStrategy option is defined as a string with the following syntax:_<br/><tt>splitStrategy=ST:value,ST:value,...</tt>_<br/>where ST can be:_<ul>_<li>BYTES a new file is created, and the old is closed when the number of written bytes is more than value</li>_<li>MESSAGES a new file is created, and the old is closed when the number of written messages is more than value</li>_<li>IDLE a new file is created, and the old is closed when no writing happened in the last value milliseconds</li>_</ul>;public void setSplitStrategy(String splitStrategy) {_        this.splitStrategy = splitStrategy__    };in,the,current,version,of,hadoop,opening,a,file,in,append,mode,is,disabled,since,it,s,not,very,reliable,so,for,the,moment,it,s,only,possible,to,create,new,files,the,camel,hdfs,endpoint,tries,to,solve,this,problem,in,this,way,ul,li,if,the,split,strategy,option,has,been,defined,the,hdfs,path,will,be,used,as,a,directory,and,files,will,be,created,using,the,configured,uuid,generator,li,li,every,time,a,splitting,condition,is,met,a,new,file,is,created,li,ul,the,split,strategy,option,is,defined,as,a,string,with,the,following,syntax,br,tt,split,strategy,st,value,st,value,tt,br,where,st,can,be,ul,li,bytes,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,bytes,is,more,than,value,li,li,messages,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,messages,is,more,than,value,li,li,idle,a,new,file,is,created,and,the,old,is,closed,when,no,writing,happened,in,the,last,value,milliseconds,li,ul;public,void,set,split,strategy,string,split,strategy,this,split,strategy,split,strategy
HdfsConfiguration -> public void setSplitStrategy(String splitStrategy);1504000981;In the current version of Hadoop opening a file in append mode is disabled since it's not very reliable. So, for the moment,_it's only possible to create new files. The Camel HDFS endpoint tries to solve this problem in this way:_<ul>_<li>If the split strategy option has been defined, the hdfs path will be used as a directory and files will be created using the configured UuidGenerator.</li>_<li>Every time a splitting condition is met, a new file is created.</li>_</ul>_The splitStrategy option is defined as a string with the following syntax:_<br/><tt>splitStrategy=ST:value,ST:value,...</tt>_<br/>where ST can be:_<ul>_<li>BYTES a new file is created, and the old is closed when the number of written bytes is more than value</li>_<li>MESSAGES a new file is created, and the old is closed when the number of written messages is more than value</li>_<li>IDLE a new file is created, and the old is closed when no writing happened in the last value milliseconds</li>_</ul>;public void setSplitStrategy(String splitStrategy) {_        this.splitStrategy = splitStrategy__    };in,the,current,version,of,hadoop,opening,a,file,in,append,mode,is,disabled,since,it,s,not,very,reliable,so,for,the,moment,it,s,only,possible,to,create,new,files,the,camel,hdfs,endpoint,tries,to,solve,this,problem,in,this,way,ul,li,if,the,split,strategy,option,has,been,defined,the,hdfs,path,will,be,used,as,a,directory,and,files,will,be,created,using,the,configured,uuid,generator,li,li,every,time,a,splitting,condition,is,met,a,new,file,is,created,li,ul,the,split,strategy,option,is,defined,as,a,string,with,the,following,syntax,br,tt,split,strategy,st,value,st,value,tt,br,where,st,can,be,ul,li,bytes,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,bytes,is,more,than,value,li,li,messages,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,messages,is,more,than,value,li,li,idle,a,new,file,is,created,and,the,old,is,closed,when,no,writing,happened,in,the,last,value,milliseconds,li,ul;public,void,set,split,strategy,string,split,strategy,this,split,strategy,split,strategy
HdfsConfiguration -> public void setSplitStrategy(String splitStrategy);1523994367;In the current version of Hadoop opening a file in append mode is disabled since it's not very reliable. So, for the moment,_it's only possible to create new files. The Camel HDFS endpoint tries to solve this problem in this way:_<ul>_<li>If the split strategy option has been defined, the hdfs path will be used as a directory and files will be created using the configured UuidGenerator.</li>_<li>Every time a splitting condition is met, a new file is created.</li>_</ul>_The splitStrategy option is defined as a string with the following syntax:_<br/><tt>splitStrategy=ST:value,ST:value,...</tt>_<br/>where ST can be:_<ul>_<li>BYTES a new file is created, and the old is closed when the number of written bytes is more than value</li>_<li>MESSAGES a new file is created, and the old is closed when the number of written messages is more than value</li>_<li>IDLE a new file is created, and the old is closed when no writing happened in the last value milliseconds</li>_</ul>;public void setSplitStrategy(String splitStrategy) {_        this.splitStrategy = splitStrategy__    };in,the,current,version,of,hadoop,opening,a,file,in,append,mode,is,disabled,since,it,s,not,very,reliable,so,for,the,moment,it,s,only,possible,to,create,new,files,the,camel,hdfs,endpoint,tries,to,solve,this,problem,in,this,way,ul,li,if,the,split,strategy,option,has,been,defined,the,hdfs,path,will,be,used,as,a,directory,and,files,will,be,created,using,the,configured,uuid,generator,li,li,every,time,a,splitting,condition,is,met,a,new,file,is,created,li,ul,the,split,strategy,option,is,defined,as,a,string,with,the,following,syntax,br,tt,split,strategy,st,value,st,value,tt,br,where,st,can,be,ul,li,bytes,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,bytes,is,more,than,value,li,li,messages,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,messages,is,more,than,value,li,li,idle,a,new,file,is,created,and,the,old,is,closed,when,no,writing,happened,in,the,last,value,milliseconds,li,ul;public,void,set,split,strategy,string,split,strategy,this,split,strategy,split,strategy
HdfsConfiguration -> public void setSplitStrategy(String splitStrategy);1547240981;In the current version of Hadoop opening a file in append mode is disabled since it's not very reliable. So, for the moment,_it's only possible to create new files. The Camel HDFS endpoint tries to solve this problem in this way:_<ul>_<li>If the split strategy option has been defined, the hdfs path will be used as a directory and files will be created using the configured UuidGenerator.</li>_<li>Every time a splitting condition is met, a new file is created.</li>_</ul>_The splitStrategy option is defined as a string with the following syntax:_<br/><tt>splitStrategy=ST:value,ST:value,...</tt>_<br/>where ST can be:_<ul>_<li>BYTES a new file is created, and the old is closed when the number of written bytes is more than value</li>_<li>MESSAGES a new file is created, and the old is closed when the number of written messages is more than value</li>_<li>IDLE a new file is created, and the old is closed when no writing happened in the last value milliseconds</li>_</ul>;public void setSplitStrategy(String splitStrategy) {_        this.splitStrategy = splitStrategy__    };in,the,current,version,of,hadoop,opening,a,file,in,append,mode,is,disabled,since,it,s,not,very,reliable,so,for,the,moment,it,s,only,possible,to,create,new,files,the,camel,hdfs,endpoint,tries,to,solve,this,problem,in,this,way,ul,li,if,the,split,strategy,option,has,been,defined,the,hdfs,path,will,be,used,as,a,directory,and,files,will,be,created,using,the,configured,uuid,generator,li,li,every,time,a,splitting,condition,is,met,a,new,file,is,created,li,ul,the,split,strategy,option,is,defined,as,a,string,with,the,following,syntax,br,tt,split,strategy,st,value,st,value,tt,br,where,st,can,be,ul,li,bytes,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,bytes,is,more,than,value,li,li,messages,a,new,file,is,created,and,the,old,is,closed,when,the,number,of,written,messages,is,more,than,value,li,li,idle,a,new,file,is,created,and,the,old,is,closed,when,no,writing,happened,in,the,last,value,milliseconds,li,ul;public,void,set,split,strategy,string,split,strategy,this,split,strategy,split,strategy
HdfsConfiguration -> public void setConnectOnStartup(boolean connectOnStartup);1430993079;Whether to connect to the HDFS file system on starting the producer/consumer._If false then the connection is created on-demand. Notice that HDFS may take up till 15 minutes to establish_a connection, as it has hardcoded 45 x 20 sec redelivery. By setting this option to false allows your_application to startup, and not block for up till 15 minutes.;public void setConnectOnStartup(boolean connectOnStartup) {_        this.connectOnStartup = connectOnStartup__    };whether,to,connect,to,the,hdfs,file,system,on,starting,the,producer,consumer,if,false,then,the,connection,is,created,on,demand,notice,that,hdfs,may,take,up,till,15,minutes,to,establish,a,connection,as,it,has,hardcoded,45,x,20,sec,redelivery,by,setting,this,option,to,false,allows,your,application,to,startup,and,not,block,for,up,till,15,minutes;public,void,set,connect,on,startup,boolean,connect,on,startup,this,connect,on,startup,connect,on,startup
HdfsConfiguration -> public void setConnectOnStartup(boolean connectOnStartup);1452076589;Whether to connect to the HDFS file system on starting the producer/consumer._If false then the connection is created on-demand. Notice that HDFS may take up till 15 minutes to establish_a connection, as it has hardcoded 45 x 20 sec redelivery. By setting this option to false allows your_application to startup, and not block for up till 15 minutes.;public void setConnectOnStartup(boolean connectOnStartup) {_        this.connectOnStartup = connectOnStartup__    };whether,to,connect,to,the,hdfs,file,system,on,starting,the,producer,consumer,if,false,then,the,connection,is,created,on,demand,notice,that,hdfs,may,take,up,till,15,minutes,to,establish,a,connection,as,it,has,hardcoded,45,x,20,sec,redelivery,by,setting,this,option,to,false,allows,your,application,to,startup,and,not,block,for,up,till,15,minutes;public,void,set,connect,on,startup,boolean,connect,on,startup,this,connect,on,startup,connect,on,startup
HdfsConfiguration -> public void setConnectOnStartup(boolean connectOnStartup);1463211772;Whether to connect to the HDFS file system on starting the producer/consumer._If false then the connection is created on-demand. Notice that HDFS may take up till 15 minutes to establish_a connection, as it has hardcoded 45 x 20 sec redelivery. By setting this option to false allows your_application to startup, and not block for up till 15 minutes.;public void setConnectOnStartup(boolean connectOnStartup) {_        this.connectOnStartup = connectOnStartup__    };whether,to,connect,to,the,hdfs,file,system,on,starting,the,producer,consumer,if,false,then,the,connection,is,created,on,demand,notice,that,hdfs,may,take,up,till,15,minutes,to,establish,a,connection,as,it,has,hardcoded,45,x,20,sec,redelivery,by,setting,this,option,to,false,allows,your,application,to,startup,and,not,block,for,up,till,15,minutes;public,void,set,connect,on,startup,boolean,connect,on,startup,this,connect,on,startup,connect,on,startup
HdfsConfiguration -> public void setConnectOnStartup(boolean connectOnStartup);1488802432;Whether to connect to the HDFS file system on starting the producer/consumer._If false then the connection is created on-demand. Notice that HDFS may take up till 15 minutes to establish_a connection, as it has hardcoded 45 x 20 sec redelivery. By setting this option to false allows your_application to startup, and not block for up till 15 minutes.;public void setConnectOnStartup(boolean connectOnStartup) {_        this.connectOnStartup = connectOnStartup__    };whether,to,connect,to,the,hdfs,file,system,on,starting,the,producer,consumer,if,false,then,the,connection,is,created,on,demand,notice,that,hdfs,may,take,up,till,15,minutes,to,establish,a,connection,as,it,has,hardcoded,45,x,20,sec,redelivery,by,setting,this,option,to,false,allows,your,application,to,startup,and,not,block,for,up,till,15,minutes;public,void,set,connect,on,startup,boolean,connect,on,startup,this,connect,on,startup,connect,on,startup
HdfsConfiguration -> public void setConnectOnStartup(boolean connectOnStartup);1504000981;Whether to connect to the HDFS file system on starting the producer/consumer._If false then the connection is created on-demand. Notice that HDFS may take up till 15 minutes to establish_a connection, as it has hardcoded 45 x 20 sec redelivery. By setting this option to false allows your_application to startup, and not block for up till 15 minutes.;public void setConnectOnStartup(boolean connectOnStartup) {_        this.connectOnStartup = connectOnStartup__    };whether,to,connect,to,the,hdfs,file,system,on,starting,the,producer,consumer,if,false,then,the,connection,is,created,on,demand,notice,that,hdfs,may,take,up,till,15,minutes,to,establish,a,connection,as,it,has,hardcoded,45,x,20,sec,redelivery,by,setting,this,option,to,false,allows,your,application,to,startup,and,not,block,for,up,till,15,minutes;public,void,set,connect,on,startup,boolean,connect,on,startup,this,connect,on,startup,connect,on,startup
HdfsConfiguration -> public void setConnectOnStartup(boolean connectOnStartup);1523994367;Whether to connect to the HDFS file system on starting the producer/consumer._If false then the connection is created on-demand. Notice that HDFS may take up till 15 minutes to establish_a connection, as it has hardcoded 45 x 20 sec redelivery. By setting this option to false allows your_application to startup, and not block for up till 15 minutes.;public void setConnectOnStartup(boolean connectOnStartup) {_        this.connectOnStartup = connectOnStartup__    };whether,to,connect,to,the,hdfs,file,system,on,starting,the,producer,consumer,if,false,then,the,connection,is,created,on,demand,notice,that,hdfs,may,take,up,till,15,minutes,to,establish,a,connection,as,it,has,hardcoded,45,x,20,sec,redelivery,by,setting,this,option,to,false,allows,your,application,to,startup,and,not,block,for,up,till,15,minutes;public,void,set,connect,on,startup,boolean,connect,on,startup,this,connect,on,startup,connect,on,startup
HdfsConfiguration -> public void setConnectOnStartup(boolean connectOnStartup);1547240981;Whether to connect to the HDFS file system on starting the producer/consumer._If false then the connection is created on-demand. Notice that HDFS may take up till 15 minutes to establish_a connection, as it has hardcoded 45 x 20 sec redelivery. By setting this option to false allows your_application to startup, and not block for up till 15 minutes.;public void setConnectOnStartup(boolean connectOnStartup) {_        this.connectOnStartup = connectOnStartup__    };whether,to,connect,to,the,hdfs,file,system,on,starting,the,producer,consumer,if,false,then,the,connection,is,created,on,demand,notice,that,hdfs,may,take,up,till,15,minutes,to,establish,a,connection,as,it,has,hardcoded,45,x,20,sec,redelivery,by,setting,this,option,to,false,allows,your,application,to,startup,and,not,block,for,up,till,15,minutes;public,void,set,connect,on,startup,boolean,connect,on,startup,this,connect,on,startup,connect,on,startup
HdfsConfiguration -> public void setKeyType(WritableType keyType);1452076589;The type for the key in case of sequence or map files.;public void setKeyType(WritableType keyType) {_        this.keyType = keyType__    };the,type,for,the,key,in,case,of,sequence,or,map,files;public,void,set,key,type,writable,type,key,type,this,key,type,key,type
HdfsConfiguration -> public void setKeyType(WritableType keyType);1463211772;The type for the key in case of sequence or map files.;public void setKeyType(WritableType keyType) {_        this.keyType = keyType__    };the,type,for,the,key,in,case,of,sequence,or,map,files;public,void,set,key,type,writable,type,key,type,this,key,type,key,type
HdfsConfiguration -> public void setKeyType(WritableType keyType);1488802432;The type for the key in case of sequence or map files.;public void setKeyType(WritableType keyType) {_        this.keyType = keyType__    };the,type,for,the,key,in,case,of,sequence,or,map,files;public,void,set,key,type,writable,type,key,type,this,key,type,key,type
HdfsConfiguration -> public void setKeyType(WritableType keyType);1504000981;The type for the key in case of sequence or map files.;public void setKeyType(WritableType keyType) {_        this.keyType = keyType__    };the,type,for,the,key,in,case,of,sequence,or,map,files;public,void,set,key,type,writable,type,key,type,this,key,type,key,type
HdfsConfiguration -> public void setKeyType(WritableType keyType);1523994367;The type for the key in case of sequence or map files.;public void setKeyType(WritableType keyType) {_        this.keyType = keyType__    };the,type,for,the,key,in,case,of,sequence,or,map,files;public,void,set,key,type,writable,type,key,type,this,key,type,key,type
HdfsConfiguration -> public void setKeyType(WritableType keyType);1547240981;The type for the key in case of sequence or map files.;public void setKeyType(WritableType keyType) {_        this.keyType = keyType__    };the,type,for,the,key,in,case,of,sequence,or,map,files;public,void,set,key,type,writable,type,key,type,this,key,type,key,type
HdfsConfiguration -> public void setCompressionType(SequenceFile.CompressionType compressionType);1430993079;The compression type to use (is default not in use);public void setCompressionType(SequenceFile.CompressionType compressionType) {_        this.compressionType = compressionType__    };the,compression,type,to,use,is,default,not,in,use;public,void,set,compression,type,sequence,file,compression,type,compression,type,this,compression,type,compression,type
HdfsConfiguration -> public void setCompressionType(SequenceFile.CompressionType compressionType);1452076589;The compression type to use (is default not in use);public void setCompressionType(SequenceFile.CompressionType compressionType) {_        this.compressionType = compressionType__    };the,compression,type,to,use,is,default,not,in,use;public,void,set,compression,type,sequence,file,compression,type,compression,type,this,compression,type,compression,type
HdfsConfiguration -> public void setCompressionType(SequenceFile.CompressionType compressionType);1463211772;The compression type to use (is default not in use);public void setCompressionType(SequenceFile.CompressionType compressionType) {_        this.compressionType = compressionType__    };the,compression,type,to,use,is,default,not,in,use;public,void,set,compression,type,sequence,file,compression,type,compression,type,this,compression,type,compression,type
HdfsConfiguration -> public void setCompressionType(SequenceFile.CompressionType compressionType);1488802432;The compression type to use (is default not in use);public void setCompressionType(SequenceFile.CompressionType compressionType) {_        this.compressionType = compressionType__    };the,compression,type,to,use,is,default,not,in,use;public,void,set,compression,type,sequence,file,compression,type,compression,type,this,compression,type,compression,type
HdfsConfiguration -> public void setCompressionType(SequenceFile.CompressionType compressionType);1504000981;The compression type to use (is default not in use);public void setCompressionType(SequenceFile.CompressionType compressionType) {_        this.compressionType = compressionType__    };the,compression,type,to,use,is,default,not,in,use;public,void,set,compression,type,sequence,file,compression,type,compression,type,this,compression,type,compression,type
HdfsConfiguration -> public void setCompressionType(SequenceFile.CompressionType compressionType);1523994367;The compression type to use (is default not in use);public void setCompressionType(SequenceFile.CompressionType compressionType) {_        this.compressionType = compressionType__    };the,compression,type,to,use,is,default,not,in,use;public,void,set,compression,type,sequence,file,compression,type,compression,type,this,compression,type,compression,type
HdfsConfiguration -> public void setCompressionType(SequenceFile.CompressionType compressionType);1547240981;The compression type to use (is default not in use);public void setCompressionType(SequenceFile.CompressionType compressionType) {_        this.compressionType = compressionType__    };the,compression,type,to,use,is,default,not,in,use;public,void,set,compression,type,sequence,file,compression,type,compression,type,this,compression,type,compression,type
HdfsConfiguration -> public void setInitialDelay(long initialDelay);1430993079;For the consumer, how much to wait (milliseconds) before to start scanning the directory.;public void setInitialDelay(long initialDelay) {_        this.initialDelay = initialDelay__    };for,the,consumer,how,much,to,wait,milliseconds,before,to,start,scanning,the,directory;public,void,set,initial,delay,long,initial,delay,this,initial,delay,initial,delay
HdfsConfiguration -> public void setInitialDelay(long initialDelay);1452076589;For the consumer, how much to wait (milliseconds) before to start scanning the directory.;public void setInitialDelay(long initialDelay) {_        this.initialDelay = initialDelay__    };for,the,consumer,how,much,to,wait,milliseconds,before,to,start,scanning,the,directory;public,void,set,initial,delay,long,initial,delay,this,initial,delay,initial,delay
HdfsConfiguration -> public void setInitialDelay(long initialDelay);1463211772;For the consumer, how much to wait (milliseconds) before to start scanning the directory.;public void setInitialDelay(long initialDelay) {_        this.initialDelay = initialDelay__    };for,the,consumer,how,much,to,wait,milliseconds,before,to,start,scanning,the,directory;public,void,set,initial,delay,long,initial,delay,this,initial,delay,initial,delay
HdfsConfiguration -> public void setInitialDelay(long initialDelay);1488802432;For the consumer, how much to wait (milliseconds) before to start scanning the directory.;public void setInitialDelay(long initialDelay) {_        this.initialDelay = initialDelay__    };for,the,consumer,how,much,to,wait,milliseconds,before,to,start,scanning,the,directory;public,void,set,initial,delay,long,initial,delay,this,initial,delay,initial,delay
HdfsConfiguration -> public void setOwner(String owner);1430993079;The file owner must match this owner for the consumer to pickup the file. Otherwise the file is skipped.;public void setOwner(String owner) {_        this.owner = owner__    };the,file,owner,must,match,this,owner,for,the,consumer,to,pickup,the,file,otherwise,the,file,is,skipped;public,void,set,owner,string,owner,this,owner,owner
HdfsConfiguration -> public void setOwner(String owner);1452076589;The file owner must match this owner for the consumer to pickup the file. Otherwise the file is skipped.;public void setOwner(String owner) {_        this.owner = owner__    };the,file,owner,must,match,this,owner,for,the,consumer,to,pickup,the,file,otherwise,the,file,is,skipped;public,void,set,owner,string,owner,this,owner,owner
HdfsConfiguration -> public void setOwner(String owner);1463211772;The file owner must match this owner for the consumer to pickup the file. Otherwise the file is skipped.;public void setOwner(String owner) {_        this.owner = owner__    };the,file,owner,must,match,this,owner,for,the,consumer,to,pickup,the,file,otherwise,the,file,is,skipped;public,void,set,owner,string,owner,this,owner,owner
HdfsConfiguration -> public void setOwner(String owner);1488802432;The file owner must match this owner for the consumer to pickup the file. Otherwise the file is skipped.;public void setOwner(String owner) {_        this.owner = owner__    };the,file,owner,must,match,this,owner,for,the,consumer,to,pickup,the,file,otherwise,the,file,is,skipped;public,void,set,owner,string,owner,this,owner,owner
HdfsConfiguration -> public void setOwner(String owner);1504000981;The file owner must match this owner for the consumer to pickup the file. Otherwise the file is skipped.;public void setOwner(String owner) {_        this.owner = owner__    };the,file,owner,must,match,this,owner,for,the,consumer,to,pickup,the,file,otherwise,the,file,is,skipped;public,void,set,owner,string,owner,this,owner,owner
HdfsConfiguration -> public void setOwner(String owner);1523994367;The file owner must match this owner for the consumer to pickup the file. Otherwise the file is skipped.;public void setOwner(String owner) {_        this.owner = owner__    };the,file,owner,must,match,this,owner,for,the,consumer,to,pickup,the,file,otherwise,the,file,is,skipped;public,void,set,owner,string,owner,this,owner,owner
HdfsConfiguration -> public void setOwner(String owner);1547240981;The file owner must match this owner for the consumer to pickup the file. Otherwise the file is skipped.;public void setOwner(String owner) {_        this.owner = owner__    };the,file,owner,must,match,this,owner,for,the,consumer,to,pickup,the,file,otherwise,the,file,is,skipped;public,void,set,owner,string,owner,this,owner,owner
HdfsConfiguration -> public void setBlockSize(long blockSize);1430993079;The size of the HDFS blocks;public void setBlockSize(long blockSize) {_        this.blockSize = blockSize__    };the,size,of,the,hdfs,blocks;public,void,set,block,size,long,block,size,this,block,size,block,size
HdfsConfiguration -> public void setBlockSize(long blockSize);1452076589;The size of the HDFS blocks;public void setBlockSize(long blockSize) {_        this.blockSize = blockSize__    };the,size,of,the,hdfs,blocks;public,void,set,block,size,long,block,size,this,block,size,block,size
HdfsConfiguration -> public void setBlockSize(long blockSize);1463211772;The size of the HDFS blocks;public void setBlockSize(long blockSize) {_        this.blockSize = blockSize__    };the,size,of,the,hdfs,blocks;public,void,set,block,size,long,block,size,this,block,size,block,size
HdfsConfiguration -> public void setBlockSize(long blockSize);1488802432;The size of the HDFS blocks;public void setBlockSize(long blockSize) {_        this.blockSize = blockSize__    };the,size,of,the,hdfs,blocks;public,void,set,block,size,long,block,size,this,block,size,block,size
HdfsConfiguration -> public void setBlockSize(long blockSize);1504000981;The size of the HDFS blocks;public void setBlockSize(long blockSize) {_        this.blockSize = blockSize__    };the,size,of,the,hdfs,blocks;public,void,set,block,size,long,block,size,this,block,size,block,size
HdfsConfiguration -> public void setBlockSize(long blockSize);1523994367;The size of the HDFS blocks;public void setBlockSize(long blockSize) {_        this.blockSize = blockSize__    };the,size,of,the,hdfs,blocks;public,void,set,block,size,long,block,size,this,block,size,block,size
HdfsConfiguration -> public void setBlockSize(long blockSize);1547240981;The size of the HDFS blocks;public void setBlockSize(long blockSize) {_        this.blockSize = blockSize__    };the,size,of,the,hdfs,blocks;public,void,set,block,size,long,block,size,this,block,size,block,size
HdfsConfiguration -> public void setReadSuffix(String readSuffix);1430993079;Once the file has been read is renamed with this suffix to avoid to read it again.;public void setReadSuffix(String readSuffix) {_        this.readSuffix = readSuffix__    };once,the,file,has,been,read,is,renamed,with,this,suffix,to,avoid,to,read,it,again;public,void,set,read,suffix,string,read,suffix,this,read,suffix,read,suffix
HdfsConfiguration -> public void setReadSuffix(String readSuffix);1452076589;Once the file has been read is renamed with this suffix to avoid to read it again.;public void setReadSuffix(String readSuffix) {_        this.readSuffix = readSuffix__    };once,the,file,has,been,read,is,renamed,with,this,suffix,to,avoid,to,read,it,again;public,void,set,read,suffix,string,read,suffix,this,read,suffix,read,suffix
HdfsConfiguration -> public void setReadSuffix(String readSuffix);1463211772;Once the file has been read is renamed with this suffix to avoid to read it again.;public void setReadSuffix(String readSuffix) {_        this.readSuffix = readSuffix__    };once,the,file,has,been,read,is,renamed,with,this,suffix,to,avoid,to,read,it,again;public,void,set,read,suffix,string,read,suffix,this,read,suffix,read,suffix
HdfsConfiguration -> public void setReadSuffix(String readSuffix);1488802432;Once the file has been read is renamed with this suffix to avoid to read it again.;public void setReadSuffix(String readSuffix) {_        this.readSuffix = readSuffix__    };once,the,file,has,been,read,is,renamed,with,this,suffix,to,avoid,to,read,it,again;public,void,set,read,suffix,string,read,suffix,this,read,suffix,read,suffix
HdfsConfiguration -> public void setReadSuffix(String readSuffix);1504000981;Once the file has been read is renamed with this suffix to avoid to read it again.;public void setReadSuffix(String readSuffix) {_        this.readSuffix = readSuffix__    };once,the,file,has,been,read,is,renamed,with,this,suffix,to,avoid,to,read,it,again;public,void,set,read,suffix,string,read,suffix,this,read,suffix,read,suffix
HdfsConfiguration -> public void setReadSuffix(String readSuffix);1523994367;Once the file has been read is renamed with this suffix to avoid to read it again.;public void setReadSuffix(String readSuffix) {_        this.readSuffix = readSuffix__    };once,the,file,has,been,read,is,renamed,with,this,suffix,to,avoid,to,read,it,again;public,void,set,read,suffix,string,read,suffix,this,read,suffix,read,suffix
HdfsConfiguration -> public void setReadSuffix(String readSuffix);1547240981;Once the file has been read is renamed with this suffix to avoid to read it again.;public void setReadSuffix(String readSuffix) {_        this.readSuffix = readSuffix__    };once,the,file,has,been,read,is,renamed,with,this,suffix,to,avoid,to,read,it,again;public,void,set,read,suffix,string,read,suffix,this,read,suffix,read,suffix
HdfsConfiguration -> public void setAppend(boolean append);1430993079;Append to existing file. Notice that not all HDFS file systems support the append option.;public void setAppend(boolean append) {_        this.append = append__    };append,to,existing,file,notice,that,not,all,hdfs,file,systems,support,the,append,option;public,void,set,append,boolean,append,this,append,append
HdfsConfiguration -> public void setAppend(boolean append);1452076589;Append to existing file. Notice that not all HDFS file systems support the append option.;public void setAppend(boolean append) {_        this.append = append__    };append,to,existing,file,notice,that,not,all,hdfs,file,systems,support,the,append,option;public,void,set,append,boolean,append,this,append,append
HdfsConfiguration -> public void setAppend(boolean append);1463211772;Append to existing file. Notice that not all HDFS file systems support the append option.;public void setAppend(boolean append) {_        this.append = append__    };append,to,existing,file,notice,that,not,all,hdfs,file,systems,support,the,append,option;public,void,set,append,boolean,append,this,append,append
HdfsConfiguration -> public void setAppend(boolean append);1488802432;Append to existing file. Notice that not all HDFS file systems support the append option.;public void setAppend(boolean append) {_        this.append = append__    };append,to,existing,file,notice,that,not,all,hdfs,file,systems,support,the,append,option;public,void,set,append,boolean,append,this,append,append
HdfsConfiguration -> public void setAppend(boolean append);1504000981;Append to existing file. Notice that not all HDFS file systems support the append option.;public void setAppend(boolean append) {_        this.append = append__    };append,to,existing,file,notice,that,not,all,hdfs,file,systems,support,the,append,option;public,void,set,append,boolean,append,this,append,append
HdfsConfiguration -> public void setAppend(boolean append);1523994367;Append to existing file. Notice that not all HDFS file systems support the append option.;public void setAppend(boolean append) {_        this.append = append__    };append,to,existing,file,notice,that,not,all,hdfs,file,systems,support,the,append,option;public,void,set,append,boolean,append,this,append,append
HdfsConfiguration -> public void setAppend(boolean append);1547240981;Append to existing file. Notice that not all HDFS file systems support the append option.;public void setAppend(boolean append) {_        this.append = append__    };append,to,existing,file,notice,that,not,all,hdfs,file,systems,support,the,append,option;public,void,set,append,boolean,append,this,append,append
HdfsConfiguration -> public void setChunkSize(int chunkSize);1430993079;When reading a normal file, this is split into chunks producing a message per chunk.;public void setChunkSize(int chunkSize) {_        this.chunkSize = chunkSize__    };when,reading,a,normal,file,this,is,split,into,chunks,producing,a,message,per,chunk;public,void,set,chunk,size,int,chunk,size,this,chunk,size,chunk,size
HdfsConfiguration -> public void setChunkSize(int chunkSize);1452076589;When reading a normal file, this is split into chunks producing a message per chunk.;public void setChunkSize(int chunkSize) {_        this.chunkSize = chunkSize__    };when,reading,a,normal,file,this,is,split,into,chunks,producing,a,message,per,chunk;public,void,set,chunk,size,int,chunk,size,this,chunk,size,chunk,size
HdfsConfiguration -> public void setChunkSize(int chunkSize);1463211772;When reading a normal file, this is split into chunks producing a message per chunk.;public void setChunkSize(int chunkSize) {_        this.chunkSize = chunkSize__    };when,reading,a,normal,file,this,is,split,into,chunks,producing,a,message,per,chunk;public,void,set,chunk,size,int,chunk,size,this,chunk,size,chunk,size
HdfsConfiguration -> public void setChunkSize(int chunkSize);1488802432;When reading a normal file, this is split into chunks producing a message per chunk.;public void setChunkSize(int chunkSize) {_        this.chunkSize = chunkSize__    };when,reading,a,normal,file,this,is,split,into,chunks,producing,a,message,per,chunk;public,void,set,chunk,size,int,chunk,size,this,chunk,size,chunk,size
HdfsConfiguration -> public void setChunkSize(int chunkSize);1504000981;When reading a normal file, this is split into chunks producing a message per chunk.;public void setChunkSize(int chunkSize) {_        this.chunkSize = chunkSize__    };when,reading,a,normal,file,this,is,split,into,chunks,producing,a,message,per,chunk;public,void,set,chunk,size,int,chunk,size,this,chunk,size,chunk,size
HdfsConfiguration -> public void setChunkSize(int chunkSize);1523994367;When reading a normal file, this is split into chunks producing a message per chunk.;public void setChunkSize(int chunkSize) {_        this.chunkSize = chunkSize__    };when,reading,a,normal,file,this,is,split,into,chunks,producing,a,message,per,chunk;public,void,set,chunk,size,int,chunk,size,this,chunk,size,chunk,size
HdfsConfiguration -> public void setChunkSize(int chunkSize);1547240981;When reading a normal file, this is split into chunks producing a message per chunk.;public void setChunkSize(int chunkSize) {_        this.chunkSize = chunkSize__    };when,reading,a,normal,file,this,is,split,into,chunks,producing,a,message,per,chunk;public,void,set,chunk,size,int,chunk,size,this,chunk,size,chunk,size
HdfsConfiguration -> public void setFileType(HdfsFileType fileType);1430993079;The file type to use. For more details see Hadoop HDFS documentation about the various files types.;public void setFileType(HdfsFileType fileType) {_        this.fileType = fileType__    };the,file,type,to,use,for,more,details,see,hadoop,hdfs,documentation,about,the,various,files,types;public,void,set,file,type,hdfs,file,type,file,type,this,file,type,file,type
HdfsConfiguration -> public void setFileType(HdfsFileType fileType);1452076589;The file type to use. For more details see Hadoop HDFS documentation about the various files types.;public void setFileType(HdfsFileType fileType) {_        this.fileType = fileType__    };the,file,type,to,use,for,more,details,see,hadoop,hdfs,documentation,about,the,various,files,types;public,void,set,file,type,hdfs,file,type,file,type,this,file,type,file,type
HdfsConfiguration -> public void setFileType(HdfsFileType fileType);1463211772;The file type to use. For more details see Hadoop HDFS documentation about the various files types.;public void setFileType(HdfsFileType fileType) {_        this.fileType = fileType__    };the,file,type,to,use,for,more,details,see,hadoop,hdfs,documentation,about,the,various,files,types;public,void,set,file,type,hdfs,file,type,file,type,this,file,type,file,type
HdfsConfiguration -> public void setFileType(HdfsFileType fileType);1488802432;The file type to use. For more details see Hadoop HDFS documentation about the various files types.;public void setFileType(HdfsFileType fileType) {_        this.fileType = fileType__    };the,file,type,to,use,for,more,details,see,hadoop,hdfs,documentation,about,the,various,files,types;public,void,set,file,type,hdfs,file,type,file,type,this,file,type,file,type
HdfsConfiguration -> public void setFileType(HdfsFileType fileType);1504000981;The file type to use. For more details see Hadoop HDFS documentation about the various files types.;public void setFileType(HdfsFileType fileType) {_        this.fileType = fileType__    };the,file,type,to,use,for,more,details,see,hadoop,hdfs,documentation,about,the,various,files,types;public,void,set,file,type,hdfs,file,type,file,type,this,file,type,file,type
HdfsConfiguration -> public void setFileType(HdfsFileType fileType);1523994367;The file type to use. For more details see Hadoop HDFS documentation about the various files types.;public void setFileType(HdfsFileType fileType) {_        this.fileType = fileType__    };the,file,type,to,use,for,more,details,see,hadoop,hdfs,documentation,about,the,various,files,types;public,void,set,file,type,hdfs,file,type,file,type,this,file,type,file,type
HdfsConfiguration -> public void setFileType(HdfsFileType fileType);1547240981;The file type to use. For more details see Hadoop HDFS documentation about the various files types.;public void setFileType(HdfsFileType fileType) {_        this.fileType = fileType__    };the,file,type,to,use,for,more,details,see,hadoop,hdfs,documentation,about,the,various,files,types;public,void,set,file,type,hdfs,file,type,file,type,this,file,type,file,type
HdfsConfiguration -> public void setValueType(WritableType valueType);1452076589;The type for the key in case of sequence or map files;public void setValueType(WritableType valueType) {_        this.valueType = valueType__    };the,type,for,the,key,in,case,of,sequence,or,map,files;public,void,set,value,type,writable,type,value,type,this,value,type,value,type
HdfsConfiguration -> public void setValueType(WritableType valueType);1463211772;The type for the key in case of sequence or map files;public void setValueType(WritableType valueType) {_        this.valueType = valueType__    };the,type,for,the,key,in,case,of,sequence,or,map,files;public,void,set,value,type,writable,type,value,type,this,value,type,value,type
HdfsConfiguration -> public void setValueType(WritableType valueType);1488802432;The type for the key in case of sequence or map files;public void setValueType(WritableType valueType) {_        this.valueType = valueType__    };the,type,for,the,key,in,case,of,sequence,or,map,files;public,void,set,value,type,writable,type,value,type,this,value,type,value,type
HdfsConfiguration -> public void setValueType(WritableType valueType);1504000981;The type for the key in case of sequence or map files;public void setValueType(WritableType valueType) {_        this.valueType = valueType__    };the,type,for,the,key,in,case,of,sequence,or,map,files;public,void,set,value,type,writable,type,value,type,this,value,type,value,type
HdfsConfiguration -> public void setValueType(WritableType valueType);1523994367;The type for the key in case of sequence or map files;public void setValueType(WritableType valueType) {_        this.valueType = valueType__    };the,type,for,the,key,in,case,of,sequence,or,map,files;public,void,set,value,type,writable,type,value,type,this,value,type,value,type
HdfsConfiguration -> public void setValueType(WritableType valueType);1547240981;The type for the key in case of sequence or map files;public void setValueType(WritableType valueType) {_        this.valueType = valueType__    };the,type,for,the,key,in,case,of,sequence,or,map,files;public,void,set,value,type,writable,type,value,type,this,value,type,value,type
HdfsConfiguration -> public void setFileSystemType(HdfsFileSystemType fileSystemType);1430993079;Set to LOCAL to not use HDFS but local java.io.File instead.;public void setFileSystemType(HdfsFileSystemType fileSystemType) {_        this.fileSystemType = fileSystemType__    };set,to,local,to,not,use,hdfs,but,local,java,io,file,instead;public,void,set,file,system,type,hdfs,file,system,type,file,system,type,this,file,system,type,file,system,type
HdfsConfiguration -> public void setFileSystemType(HdfsFileSystemType fileSystemType);1452076589;Set to LOCAL to not use HDFS but local java.io.File instead.;public void setFileSystemType(HdfsFileSystemType fileSystemType) {_        this.fileSystemType = fileSystemType__    };set,to,local,to,not,use,hdfs,but,local,java,io,file,instead;public,void,set,file,system,type,hdfs,file,system,type,file,system,type,this,file,system,type,file,system,type
HdfsConfiguration -> public void setFileSystemType(HdfsFileSystemType fileSystemType);1463211772;Set to LOCAL to not use HDFS but local java.io.File instead.;public void setFileSystemType(HdfsFileSystemType fileSystemType) {_        this.fileSystemType = fileSystemType__    };set,to,local,to,not,use,hdfs,but,local,java,io,file,instead;public,void,set,file,system,type,hdfs,file,system,type,file,system,type,this,file,system,type,file,system,type
HdfsConfiguration -> public void setFileSystemType(HdfsFileSystemType fileSystemType);1488802432;Set to LOCAL to not use HDFS but local java.io.File instead.;public void setFileSystemType(HdfsFileSystemType fileSystemType) {_        this.fileSystemType = fileSystemType__    };set,to,local,to,not,use,hdfs,but,local,java,io,file,instead;public,void,set,file,system,type,hdfs,file,system,type,file,system,type,this,file,system,type,file,system,type
HdfsConfiguration -> public void setFileSystemType(HdfsFileSystemType fileSystemType);1504000981;Set to LOCAL to not use HDFS but local java.io.File instead.;public void setFileSystemType(HdfsFileSystemType fileSystemType) {_        this.fileSystemType = fileSystemType__    };set,to,local,to,not,use,hdfs,but,local,java,io,file,instead;public,void,set,file,system,type,hdfs,file,system,type,file,system,type,this,file,system,type,file,system,type
HdfsConfiguration -> public void setFileSystemType(HdfsFileSystemType fileSystemType);1523994367;Set to LOCAL to not use HDFS but local java.io.File instead.;public void setFileSystemType(HdfsFileSystemType fileSystemType) {_        this.fileSystemType = fileSystemType__    };set,to,local,to,not,use,hdfs,but,local,java,io,file,instead;public,void,set,file,system,type,hdfs,file,system,type,file,system,type,this,file,system,type,file,system,type
HdfsConfiguration -> public void setFileSystemType(HdfsFileSystemType fileSystemType);1547240981;Set to LOCAL to not use HDFS but local java.io.File instead.;public void setFileSystemType(HdfsFileSystemType fileSystemType) {_        this.fileSystemType = fileSystemType__    };set,to,local,to,not,use,hdfs,but,local,java,io,file,instead;public,void,set,file,system,type,hdfs,file,system,type,file,system,type,this,file,system,type,file,system,type
HdfsConfiguration -> public void setHostName(String hostName);1430993079;HDFS host to use;public void setHostName(String hostName) {_        this.hostName = hostName__    };hdfs,host,to,use;public,void,set,host,name,string,host,name,this,host,name,host,name
HdfsConfiguration -> public void setHostName(String hostName);1452076589;HDFS host to use;public void setHostName(String hostName) {_        this.hostName = hostName__    };hdfs,host,to,use;public,void,set,host,name,string,host,name,this,host,name,host,name
HdfsConfiguration -> public void setHostName(String hostName);1463211772;HDFS host to use;public void setHostName(String hostName) {_        this.hostName = hostName__    };hdfs,host,to,use;public,void,set,host,name,string,host,name,this,host,name,host,name
HdfsConfiguration -> public void setHostName(String hostName);1488802432;HDFS host to use;public void setHostName(String hostName) {_        this.hostName = hostName__    };hdfs,host,to,use;public,void,set,host,name,string,host,name,this,host,name,host,name
HdfsConfiguration -> public void setHostName(String hostName);1504000981;HDFS host to use;public void setHostName(String hostName) {_        this.hostName = hostName__    };hdfs,host,to,use;public,void,set,host,name,string,host,name,this,host,name,host,name
HdfsConfiguration -> public void setHostName(String hostName);1523994367;HDFS host to use;public void setHostName(String hostName) {_        this.hostName = hostName__    };hdfs,host,to,use;public,void,set,host,name,string,host,name,this,host,name,host,name
HdfsConfiguration -> public void setHostName(String hostName);1547240981;HDFS host to use;public void setHostName(String hostName) {_        this.hostName = hostName__    };hdfs,host,to,use;public,void,set,host,name,string,host,name,this,host,name,host,name
HdfsConfiguration -> public void setPattern(String pattern);1430993079;The pattern used for scanning the directory;public void setPattern(String pattern) {_        this.pattern = pattern__    };the,pattern,used,for,scanning,the,directory;public,void,set,pattern,string,pattern,this,pattern,pattern
HdfsConfiguration -> public void setPattern(String pattern);1452076589;The pattern used for scanning the directory;public void setPattern(String pattern) {_        this.pattern = pattern__    };the,pattern,used,for,scanning,the,directory;public,void,set,pattern,string,pattern,this,pattern,pattern
HdfsConfiguration -> public void setPattern(String pattern);1463211772;The pattern used for scanning the directory;public void setPattern(String pattern) {_        this.pattern = pattern__    };the,pattern,used,for,scanning,the,directory;public,void,set,pattern,string,pattern,this,pattern,pattern
HdfsConfiguration -> public void setPattern(String pattern);1488802432;The pattern used for scanning the directory;public void setPattern(String pattern) {_        this.pattern = pattern__    };the,pattern,used,for,scanning,the,directory;public,void,set,pattern,string,pattern,this,pattern,pattern
HdfsConfiguration -> public void setPattern(String pattern);1504000981;The pattern used for scanning the directory;public void setPattern(String pattern) {_        this.pattern = pattern__    };the,pattern,used,for,scanning,the,directory;public,void,set,pattern,string,pattern,this,pattern,pattern
HdfsConfiguration -> public void setPattern(String pattern);1523994367;The pattern used for scanning the directory;public void setPattern(String pattern) {_        this.pattern = pattern__    };the,pattern,used,for,scanning,the,directory;public,void,set,pattern,string,pattern,this,pattern,pattern
HdfsConfiguration -> public void setPattern(String pattern);1547240981;The pattern used for scanning the directory;public void setPattern(String pattern) {_        this.pattern = pattern__    };the,pattern,used,for,scanning,the,directory;public,void,set,pattern,string,pattern,this,pattern,pattern
