commented;modifiers;parameterAmount;loc;comment;code
false;public;0;4;;@Override public HdfsEndpoint getEndpoint() {     return (HdfsEndpoint) super.getEndpoint(). }
false;protected;0;9;;@Override protected void doStart() throws Exception {     super.doStart().     if (config.isConnectOnStartup()) {         // setup hdfs if configured to do on startup         setupHdfs(true).     } }
false;private;1;22;;private HdfsInfo setupHdfs(boolean onStartup) throws Exception {     // if we are starting up then log at info level, and if runtime then log at debug level to not flood the log     if (onStartup) {         log.info("Connecting to hdfs file-system {}:{}/{} (may take a while if connection is not available)", config.getHostName(), config.getPort(), hdfsPath).     } else {         if (log.isDebugEnabled()) {             log.debug("Connecting to hdfs file-system {}:{}/{} (may take a while if connection is not available)", config.getHostName(), config.getPort(), hdfsPath).         }     }     // hadoop will cache the connection by default so its faster to get in the poll method     HdfsInfo answer = HdfsInfoFactory.newHdfsInfo(this.hdfsPath.toString()).     if (onStartup) {         log.info("Connected to hdfs file-system {}:{}/{}", config.getHostName(), config.getPort(), hdfsPath).     } else {         if (log.isDebugEnabled()) {             log.debug("Connected to hdfs file-system {}:{}/{}", config.getHostName(), config.getPort(), hdfsPath).         }     }     return answer. }
false;protected;0;10;;@Override protected int poll() throws Exception {     // need to remember auth as Hadoop will override that, which otherwise means the Auth is broken afterwards     Configuration auth = HdfsComponent.getJAASConfiguration().     try {         return doPoll().     } finally {         HdfsComponent.setJAASConfiguration(auth).     } }
false;public;1;3;;public boolean accept(Path path) {     return !(path.toString().endsWith(config.getOpenedSuffix()) || path.toString().endsWith(config.getReadSuffix())). }
false;protected;0;82;;protected int doPoll() throws Exception {     class ExcludePathFilter implements PathFilter {          public boolean accept(Path path) {             return !(path.toString().endsWith(config.getOpenedSuffix()) || path.toString().endsWith(config.getReadSuffix())).         }     }     int numMessages = 0.     HdfsInfo info = setupHdfs(false).     FileStatus[] fileStatuses.     if (info.getFileSystem().isFile(info.getPath())) {         fileStatuses = info.getFileSystem().globStatus(info.getPath()).     } else {         Path pattern = info.getPath().suffix("/" + this.config.getPattern()).         fileStatuses = info.getFileSystem().globStatus(pattern, new ExcludePathFilter()).     }     for (FileStatus status : fileStatuses) {         if (normalFileIsDirectoryNoSuccessFile(status, info)) {             continue.         }         if (config.getOwner() != null) {             // must match owner             if (!config.getOwner().equals(status.getOwner())) {                 if (log.isDebugEnabled()) {                     log.debug("Skipping file: {} as not matching owner: {}", status.getPath(), config.getOwner()).                 }                 continue.             }         }         try {             this.rwlock.writeLock().lock().             this.istream = HdfsInputStream.createInputStream(status.getPath().toString(), this.config).             if (!this.istream.isOpened()) {                 if (log.isDebugEnabled()) {                     log.debug("Skipping file: {} because it doesn't exist anymore", status.getPath()).                 }                 continue.             }         } finally {             this.rwlock.writeLock().unlock().         }         try {             Holder<Object> key = new Holder<>().             Holder<Object> value = new Holder<>().             while (this.istream.next(key, value) >= 0) {                 Exchange exchange = this.getEndpoint().createExchange().                 Message message = new DefaultMessage(this.getEndpoint().getCamelContext()).                 String fileName = StringUtils.substringAfterLast(status.getPath().toString(), "/").                 message.setHeader(Exchange.FILE_NAME, fileName).                 if (key.value != null) {                     message.setHeader(HdfsHeader.KEY.name(), key.value).                 }                 message.setBody(value.value).                 exchange.setIn(message).                 log.debug("Processing file {}", fileName).                 try {                     processor.process(exchange).                 } catch (Exception e) {                     exchange.setException(e).                 }                 // in case of unhandled exceptions then let the exception handler handle them                 if (exchange.getException() != null) {                     getExceptionHandler().handleException(exchange.getException()).                 }                 numMessages++.             }         } finally {             IOHelper.close(istream, "input stream", log).         }     }     return numMessages. }
false;private;2;9;;private boolean normalFileIsDirectoryNoSuccessFile(FileStatus status, HdfsInfo info) throws IOException {     if (config.getFileType().equals(HdfsFileType.NORMAL_FILE) && status.isDirectory()) {         Path successPath = new Path(status.getPath().toString() + "/_SUCCESS").         if (!info.getFileSystem().exists(successPath)) {             return true.         }     }     return false. }
